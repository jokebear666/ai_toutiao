"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7065],{27733:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_CC/20251229-20260104","title":"20251229-20260104 (cs.CC)","description":"2025-12-29","source":"@site/docs/daily/cs_CC/20251229-20260104.md","sourceDirName":"daily/cs_CC","slug":"/daily/cscc/20251229-20260104","permalink":"/ai_toutiao/daily/cscc/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767093755000,"frontMatter":{"slug":"/daily/cscc/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.CC)","permalink":"/ai_toutiao/daily/cscc/20251222-20251228"},"next":{"title":"cs.CE","permalink":"/ai_toutiao/daily/csce"}}');var r=i(74848),t=i(28453);const o={slug:"/daily/cscc/20251229-20260104"},a="20251229-20260104 (cs.CC)",l={},c=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251229-20260104-cscc",children:"20251229-20260104 (cs.CC)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] A Note on the NP-Hardness of PARTITION Via First-Order Projections"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [computational complexity theory], [NP-hardness, first-order reductions, AC0 reductions, PARTITION problem, descriptive complexity]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Pa\xfal Risco Iturralde"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Independent researcher"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21448",children:"https://arxiv.org/pdf/2512.21448"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates NP-hardness of the PARTITION problem via first-order projections, 2. Overcomes the obstacle of requiring large sums in the standard reduction by using descriptive complexity techniques, 3. Fills a gap in the literature regarding the hardness of PARTITION under restricted reductions like AC0."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b5d9f8d4b42755b482904c0cf03df329316dc9a10936a82fe27b6ce034a1e56_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b5d9f8d4b42755b482904c0cf03df329316dc9a10936a82fe27b6ce034a1e56_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This note addresses the open question of whether the PARTITION problem is NP-hard under restricted reductions like AC0. It modifies classic reductions from 3SAT to SUBSET-SUM to PARTITION, defining them using first-order logical formulas (first-order projections). The main conclusion is that PARTITION is indeed NP-hard via first-order projections, which implies hardness under polynomial-size AC0 reductions, thereby resolving the gap mentioned in prior work."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898: A Note on the NP-Hardness of PARTITION Via First-Order Projections] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[PARTITION\u7684NP-hardness\u5728\u53d7\u9650\u5f52\u7ea6\u4e0b\u662f\u5426\u6210\u7acb?/Is PARTITION NP-hard under restricted reductions?]\n    C --\x3e C1[\u4f7f\u7528\u4e00\u9636\u903b\u8f91\u516c\u5f0f\u5b9a\u4e49\u5f52\u7ea6/Define reductions using first-order logic formulas]\n    C --\x3e C2[\u4fee\u6539\u7ecf\u5178\u5f52\u7ea6(3SAT\u5230SUBSET-SUM\u5230PARTITION)/Modify classic reductions (3SAT to SUBSET-SUM to PARTITION)]\n    D --\x3e D1[PARTITION\u5bf9\u4e00\u9636\u6295\u5f71\u662fNP-hard\u7684/PARTITION is NP-hard via first-order projections]\n    D --\x3e D2[\u6697\u793a\u5bf9\u591a\u9879\u5f0f\u5927\u5c0fAC0\u5f52\u7ea6\u4e5f\u662fNP-hard\u7684/Implies NP-hard under polynomial-size AC0 reductions]\n    D --\x3e D3[\u586b\u8865\u4e86\u6587\u732e\u4e2d\u7684\u7a7a\u767d/Fills a gap in the literature]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] A Note on Avoid vs MCSP"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [computational complexity theory], [Range Avoidance Problem, Minimal Circuit Size Problem, AM \u2229 coAM, Turing reductions]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Edward A. Hirsch, Ilya Volkovich"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Ariel University, Boston College"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21764",children:"https://arxiv.org/pdf/2512.21764"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Presents an alternative approach to a known result linking languages reducible to the Range Avoidance Problem (Avoid) to the complexity class AM \u2229 coAM. 2. Proposes using the Minimal Circuit Size Problem (MCSP) as a potential avenue to derive this containment result. 3. Highlights the connection between two central problems in complexity theory (Avoid and MCSP) for understanding the power of reductions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/918e4b50a4df8fcc5a358172ac9f315b25fd82440914a13e94eb45224863b78a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/918e4b50a4df8fcc5a358172ac9f315b25fd82440914a13e94eb45224863b78a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This note explores the complexity of the Range Avoidance Problem (Avoid). It proposes a new potential method, using the Minimal Circuit Size Problem (MCSP), to show that any language reducible to Avoid via deterministic or randomized Turing reductions is contained in the complexity class AM \u2229 coAM, offering an alternative to a recent proof."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Note on Avoid vs MCSP"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Complexity of Range Avoidance (Avoid)"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Using Minimal Circuit Size Problem (MCSP)"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Languages reducible to Avoid are in AM \u2229 coAM"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Conserved active information"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [information theory], [conserved active information, No-Free-Lunch, KL divergence, search space, information conservation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yanchen Chen, Daniel Andr\xe9s D\xedaz-Pach\xf3n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Miami"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21834",children:"https://arxiv.org/pdf/2512.21834"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces conserved active information (I\u2295), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I\u2295 can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new information-theoretic measure called conserved active information (I\u2295) to quantify net information change in search problems while respecting conservation laws. It shows that I\u2295 uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Conserved active information] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem: Limitations of average-focused information measures like KL divergence]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method: Introduce conserved active information I\u2295, a symmetric extension respecting No-Free-Lunch]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results: I\u2295 reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Poincar\xe9 Duality and Multiplicative Structures on Quantum Codes"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [quantum error correction], [sheaf codes, Poincar\xe9 duality, quantum LDPC codes, transversal gates, cup/cap product]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yiming Li, Zimu Li, Zi-Wen Liu, Quynh T. Nguyen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Harvard University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21922",children:"https://arxiv.org/pdf/2512.21922"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Generalizing Poincar\xe9 duality from manifolds to sheaf-based classical and quantum codes, establishing a rigorous duality relationship between chain and cochain complexes. 2. Constructing multiplicative structures (cup and cap products) on sheaved chain complexes, leading to an explicit isomorphism between (co)homology groups. 3. Applying the framework to obtain transversal logical gates (CZ, CCZ, higher-order controlled-Z) on families of good qLDPC and quantum locally testable codes, pointing towards fault-tolerant non-Clifford gates."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fcb4213084226768ada35e1a65f3fff10489254aaaafade43391ca7096cc47_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fcb4213084226768ada35e1a65f3fff10489254aaaafade43391ca7096cc47_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper generalizes Poincar\xe9 duality and multiplicative structures from topology to sheaf-based quantum codes. The authors rigorously prove duality relationships and construct cup/cap products, leading to an isomorphism between homology groups. As an application, they demonstrate how to construct transversal logical non-Clifford gates on good quantum LDPC codes, advancing fault-tolerant quantum computing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Poincar\xe9 Duality and Multiplicative Structures on Quantum Codes<br>\u91cf\u5b50\u4ee3\u7801\u7684\u5e9e\u52a0\u83b1\u5bf9\u5076\u4e0e\u4e58\u6cd5\u7ed3\u6784")\n    Root --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("Generalize Poincar\xe9 duality to codes<br>\u5c06\u5bf9\u5076\u6027\u63a8\u5e7f\u81f3\u7f16\u7801")\n    Method --\x3e M1("Sheaf theory on cell complexes<br>\u80de\u8154\u590d\u5f62\u4e0a\u7684\u5c42\u7406\u8bba")\n    Method --\x3e M2("Build cup/cap products<br>\u6784\u5efa\u676f\u79ef/\u5361\u79ef")\n    Results --\x3e R1("Duality & isomorphism proven<br>\u8bc1\u660e\u5bf9\u5076\u4e0e\u540c\u6784")\n    Results --\x3e R2("Transversal logical gates<br>\u6a2a\u622a\u903b\u8f91\u95e8")'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] A Study of NP-Completeness and Undecidable Word Problems in Semigroups"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [computational complexity theory], [NP-completeness, undecidable word problem, associative calculus, polynomial reducibility, Turing machines]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Duaa Abdullah, Jasem Hamoud"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Moscow Institute of Physics and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22123",children:"https://arxiv.org/pdf/2512.22123"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Explores the relationship between complexity classes P and NP and the concept of polynomial reducibility. 2. Demonstrates the construction of an associative calculus (semigroup) with an algorithmically undecidable word problem. 3. Establishes a direct connection between a Turing machine computing a non-recursive function and the equivalence condition in the constructed calculus, linking computational complexity and algebraic undecidability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9ade75d90324f1eb4f6ee92ec609932e78897f10c8103547d100966beb841a9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9ade75d90324f1eb4f6ee92ec609932e78897f10c8103547d100966beb841a9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates fundamental limits in computation by studying NP-completeness and undecidable problems. It constructs an associative calculus whose word problem is undecidable, linking it to a Turing machine that computes a non-recursive function. The work highlights the intrinsic boundaries of algorithmic solutions by connecting computational complexity theory with algebraic undecidability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Study of NP-Completeness and Undecidable Word Problems in Semigroups"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Computational complexity & decidability limits"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Polynomial reducibility & Associative calculus construction"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Undecidable word problem linked to non-recursive Turing machine"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Lower bounds on pure dynamic programming for connectivity problems on graphs of bounded path-width"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [parameterized complexity], [tropical circuits, pathwidth, communication complexity, Traveling Salesperson Problem, dynamic programming]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kacper Kluk, Jesper Nederlof"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Warsaw, Utrecht University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23121",children:"https://arxiv.org/pdf/2512.23121"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proves unconditional lower bounds on the size of tropical circuits (modeling pure dynamic programming) for solving connectivity problems like TSP on graphs of bounded pathwidth. 2. Establishes a connection between tropical circuit complexity and the nondeterministic communication complexity of compatibility matrices. 3. Shows that any tropical circuit for TSP on a certain graph of pathwidth k requires at least 2^\u03a9(k log log k) gates, which is higher than known algebraic algorithms, suggesting algebra is necessary for competitive worst-case times."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86590df9819e19ad7303e5df124f5b2189c5e6ab6d542206119582e1e6c83135_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86590df9819e19ad7303e5df124f5b2189c5e6ab6d542206119582e1e6c83135_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the limitations of pure dynamic programming, modeled by tropical circuits, for solving connectivity problems like the Traveling Salesperson Problem on graphs with small pathwidth. It proves an unconditional lower bound of 2^\u03a9(k log log k) gates for any tropical circuit solving TSP on a specific graph of pathwidth k. This result, established via a link to communication complexity, suggests that algebraic techniques are unavoidable for achieving the fastest known worst-case running times for these problems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Lower bounds on pure dynamic programming for connectivity problems on graphs of bounded path-width] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8bc4\u4f30\u7eaf\u52a8\u6001\u89c4\u5212\u5bf9\u8fde\u901a\u6027\u95ee\u9898\u7684\u80fd\u529b/Assess capability of pure DP for connectivity problems]\n    C --\x3e C1[\u5c06\u70ed\u5e26\u7535\u8def\u590d\u6742\u5ea6\u4e0e\u901a\u4fe1\u590d\u6742\u6027\u5173\u8054/Link tropical circuit complexity to communication complexity]\n    D --\x3e D1[\u8bc1\u660e\u4e0b\u754c\u9ad8\u4e8e\u5df2\u77e5\u4ee3\u6570\u7b97\u6cd5/Prove lower bound higher than known algebraic algorithms]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Pseudodeterministic Algorithms for Minimum Cut Problems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [graph algorithms], [pseudodeterministic algorithms, global minimum cut, minimum s-t cut, streaming algorithms, cut-query models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aryan Agarwala, Nithin Varma"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Max-Planck-Institut f\xfcr Informatik, Saarland Informatics Campus; University of Cologne"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23468",children:"https://arxiv.org/pdf/2512.23468"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Presents efficient pseudodeterministic algorithms for the global minimum cut and minimum s-t cut problems. 2. Achieves an asymptotic running time for global minimum cut that is better than the fastest known sequential deterministic algorithm. 3. Implements the algorithm in multiple computational models (sequential, streaming, PRAM, cut-query) where efficient deterministic algorithms were previously unknown."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c06a5f7252dc9f1337880cbdb49ac90f3b180fa63fe8a5b0eb2c22a487cedbbd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c06a5f7252dc9f1337880cbdb49ac90f3b180fa63fe8a5b0eb2c22a487cedbbd_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces pseudodeterministic algorithms for finding global minimum cuts and minimum s-t cuts in graphs. The proposed method offers replicability by consistently outputting the same answer with high probability, while being faster than the best known deterministic algorithm for global minimum cut. The algorithms are also successfully adapted to work in sequential, streaming, PRAM, and cut-query models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Pseudodeterministic Algorithms for Minimum Cut Problems] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1(\u786e\u5b9a\u6027\u7b97\u6cd5\u6548\u7387\u4f4e / Deterministic algorithms are inefficient)\n    B --\x3e B2(\u968f\u673a\u7b97\u6cd5\u8f93\u51fa\u4e0d\u4e00\u81f4 / Randomized algorithms lack replicability)\n    C --\x3e C1(\u4f2a\u786e\u5b9a\u6027\u7b97\u6cd5 / Pseudodeterministic Algorithms)\n    C --\x3e C2(\u9ad8\u6982\u7387\u8f93\u51fa\u76f8\u540c\u89e3 / Outputs same solution with high probability)\n    D --\x3e D1(\u6e10\u8fd1\u66f4\u5feb / Asymptotically faster)\n    D --\x3e D2(\u591a\u6a21\u578b\u5b9e\u73b0 / Implemented in multiple models)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Coloring Hardness on Low Twin-Width Graphs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [graph theory, computational complexity], [twin-width, graph coloring, NP-hardness, computational complexity, graph classes]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," \xc9douard Bonnet"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Univ Lyon, CNRS, ENS de Lyon, Universit\xe9 Claude Bernard Lyon 1, LIP UMR5668"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23680",children:"https://arxiv.org/pdf/2512.23680"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proves that the Min Coloring problem is NP-hard on the class of graphs with twin-width at most 3 (T3). 2. Proves that for every k >= 3, the k-Coloring problem is NP-hard on the class of graphs with twin-width at most 4 (T4). 3. Provides structural observations about the T3 and T4 classes, highlighting their distinct properties and raising open questions about complexity transitions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f77a33f460e61bf2610b2bc5a51fb237df8e78440e7279dd902d4d1e4a4dbc60_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f77a33f460e61bf2610b2bc5a51fb237df8e78440e7279dd902d4d1e4a4dbc60_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the computational complexity of graph coloring problems on graphs with low twin-width. It proves that Min Coloring is NP-hard on graphs of twin-width at most 3, and that k-Coloring is NP-hard on graphs of twin-width at most 4 for all k>=3. These results establish the first hardness for a problem on T3 that is easy on simpler graph classes like trees and cographs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Coloring Hardness on Low Twin-Width Graphs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Coloring complexity on bounded twin-width graphs]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: NP-hardness proofs via reductions]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Min Coloring hard on T3, k-Coloring hard on T4]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(96540);const r={},t=s.createContext(r);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);