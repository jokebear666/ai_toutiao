"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5607],{28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(96540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}},49718:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_IR/20251215-20251221","title":"20251215-20251221 (cs.IR)","description":"2025-12-18","source":"@site/docs/daily/cs_IR/20251215-20251221.md","sourceDirName":"daily/cs_IR","slug":"/daily/cs_IR/20251215-20251221","permalink":"/ai_toutiao/daily/cs_IR/20251215-20251221","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767087759000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"cs.IR","permalink":"/ai_toutiao/category/csir"},"next":{"title":"20251222-20251228 (cs.IR)","permalink":"/ai_toutiao/daily/csir/20251222-20251228"}}');var r=i(74848),t=i(28453);const a={},o="20251215-20251221 (cs.IR)",l={},d=[{value:"2025-12-18",id:"2025-12-18",level:2},{value:"2025-12-19",id:"2025-12-19",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251215-20251221-csir",children:"20251215-20251221 (cs.IR)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-18",children:"2025-12-18"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251218] Where to Explore: A Reach and Cost-Aware Approach for Unbiased Data Collection in Recommender Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [A/B testing, cost-aware optimization, scroll-depth analysis, unbiased data collection, dedicated exploration container]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Qiang Chen, Venkatesh Ganapati Hegde"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tubi"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.14733",children:"https://arxiv.org/pdf/2512.14733"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper introduces a method for safe content exploration in recommender systems by strategically placing a "Something Completely Different" row of randomized content only in low-engagement, high-reach scroll-depth regions of the UI. This approach preserves key business metrics while collecting unbiased interaction data. The collected data, when used for downstream candidate generation, significantly improves user engagement.']}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251218] Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [large language models, knowledge graphs, viewpoint classification, fine-tuning, wikidata, semantic enrichment]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Massimiliano Fadda, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Cagliari, The Open University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.14887",children:"https://arxiv.org/pdf/2512.14887"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper improves a pipeline for analyzing political viewpoints in news by fine-tuning Large Language Models for classification and enriching claim representations with semantic actor descriptions from Wikidata. The integrated approach, evaluated on UK immigration debate data, shows that combining fine-tuned LLMs with knowledge graph context yields the best performance, particularly with models capable of processing long inputs."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251218] Topological Metric for Unsupervised Embedding Quality Evaluation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [representation learning evaluation], [persistent homology, unsupervised metric, topological data analysis, embedding quality]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aleksei Shestov, Anton Klenitskiy, Daria Denisova, Amurkhan Dzagkoev, Daniil Petrovich, Andrey Savchenko, Maksim Makarenko"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sber AI Laboratory"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15285",children:"https://arxiv.org/pdf/2512.15285"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper proposes "Persistence", a fully unsupervised metric for evaluating embedding quality based on persistent homology from topological data analysis. It captures the multi-scale geometric and topological structure of embedding spaces. Empirical results show it achieves strong correlation with downstream task performance, outperforming existing unsupervised metrics.']}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251218] Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [adaptive computation, early exit, dual-path training, image complexity classification, ConvNeXt-IC]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mikel Williams-Lekuona, Georgina Cosma"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Loughborough University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15372",children:"https://arxiv.org/pdf/2512.15372"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes ICAR, an adaptive retrieval method that reduces computation for simple images in vision-language models by using early exits, while maintaining cross-modal alignment through dual-path training. It also introduces ConvNeXt-IC, a classifier for image complexity to decide the compute depth. The method achieves a 20% practical speedup with minimal performance loss, enabling more efficient scaling of vision-language systems."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251218] BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [neural collaborative filtering, BERT, CNN, hybrid recommendation system, deep learning]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abdullah Al Munem, Sumona Yeasmin, Mohammad Rezwanul Huq"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," East West University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15526",children:"https://arxiv.org/pdf/2512.15526"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a hybrid neural collaborative filtering (NCF) model that integrates BERT and CNN to process categorical and image data for recommendations. The model was trained on a MovieLens dataset and outperformed baseline NCF and BERT-based NCF models. The results show that incorporating both categorical and image data can improve recommendation system performance."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-19",children:"2025-12-19"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] ModelTables: A Corpus of Tables about Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [table retrieval, model lakes, data lakes, unionable tables, joinable tables, dense retrieval, sparse retrieval, hybrid retrieval, benchmark construction]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhengyuan Dong, Victor Zhong, Ren\xe9e J. Miller"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Waterloo"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16106",children:"https://arxiv.org/pdf/2512.16106"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ModelTables, a benchmark corpus of structured tables describing AI models, built from sources like Hugging Face model cards and GitHub READMEs. It evaluates table search methods, finding that table-based dense retrieval performs best but leaves significant room for improvement. The work provides a foundation for better semantic retrieval and organization of structured model knowledge."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] Science Consultant Agent"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Retrieval-Augmented Generation (RAG), fine-tuning, knowledge distillation, prompting, AutoML]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Karthikeyan K, Philip Wu, Xin Tang, Alexandre Alves"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Duke University, Amazon"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16171",children:"https://arxiv.org/pdf/2512.16171"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces the Science Consultant Agent, a web-based AI tool that uses structured questionnaires, literature-backed recommendations, and prototype generation to guide practitioners in selecting optimal AI modeling strategies. It aims to prevent resource misallocation by providing evidence-based guidance, moving beyond brute-force exploration or example-induced bias to accelerate development."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] The Evolution of Reranking Models in Information Retrieval: From Heuristic Methods to Large Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [information retrieval], [reranking, cross-encoders, T5, Graph Neural Networks, knowledge distillation, Large Language Models]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tejul Pandit, Sakshi Mahendru, Meet Raval, Dhvani Upadhyay"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Palo Alto Networks, University of Southern California, Dhirubhai Ambani University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16236",children:"https://arxiv.org/pdf/2512.16236"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper provides a comprehensive survey of reranking models in information retrieval, tracing their evolution from heuristic methods to modern neural architectures and Large Language Models. It analyzes various techniques including cross-encoders, T5, and GNNs, and discusses efficiency methods like knowledge distillation. The survey concludes by synthesizing the principles, effectiveness, and trade-offs of different reranking strategies, highlighting their critical role in improving retrieval relevance, especially within RAG pipelines."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] Introducing ORKG ASK: an AI-driven Scholarly Literature Search and Exploration System Taking a Neuro-Symbolic Approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [neuro-symbolic approach, vector search, knowledge graphs, retrieval-augmented generation (RAG), large language models (LLMs)]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Allard Oelen, Mohamad Yaser Jaradeh, S\xf6ren Auer"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TIB \u2013 Leibniz Information Centre for Science and Technology, L3S Research Center, Leibniz University of Hannover"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16425",children:"https://arxiv.org/pdf/2512.16425"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ORKG ASK, a scholarly search system that uses a neuro-symbolic approach combining vector search, knowledge graphs, and LLMs with a Retrieval-Augmented Generation (RAG) framework to answer research questions. The system was evaluated for usability and found to be user-friendly, with users generally satisfied with its performance."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [fairness and bias in ai], [memory-enhanced personalization, large language models, AI agents, bias simulation, recruitment]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Himanshu Gharat, Himanshi Agrawal, Gourab K. Patro"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Phi Labs, Quantiphi Inc."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16532",children:"https://arxiv.org/pdf/2512.16532"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper simulates the behavior of memory-enhanced personalized AI agents using safety-trained LLMs in a recruitment use case. It finds that bias is systematically introduced and reinforced through personalization, highlighting the need for additional protective measures in such agents."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] Abacus: Self-Supervised Event Counting-Aligned Distributional Pretraining for Sequential User Modeling"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [display advertising], [self-supervised learning, sequential modeling, distributional pretraining, hybrid objective]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sullivan Castro, Artem Betlei, Thomas Di Martino, Nadir El Manouzi"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Criteo AI Lab, \xc9cole Nationale des Ponts et Chauss\xe9es"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16581",children:"https://arxiv.org/pdf/2512.16581"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Abacus, a self-supervised pretraining method for sequential user modeling that predicts the empirical frequency distribution of user events to align with useful counting statistics. It combines this with a hybrid objective that unites distributional prediction with sequential learning. Experiments show that this approach accelerates downstream task convergence and improves AUC by up to 6.1% compared to baselines."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] Microsoft Academic Graph Information Retrieval for Research Recommendation and Assistance"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [graph neural networks, graph attention mechanisms, retrieval-augmented generation, knowledge graphs, attention-based pruning, subgraph retrieval]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jacob Reiss, Shikshya Shiwakoti, Samuel Goldsmith, Ujjwal Pandit"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Microsoft"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16661",children:"https://arxiv.org/pdf/2512.16661"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes an Attention-Based Subgraph Retriever, a GNN-as-retriever model that uses attention pruning to extract a refined subgraph from a knowledge graph, which is then passed to a large language model for advanced reasoning. This approach aims to improve research paper recommendation by leveraging relational and structural information from graphs to enhance retrieval-augmented generation and mitigate LLM hallucinations."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [retrieval-augmented generation, deductive reasoning, conflict-aware trust-score, reasoning-trace-augmented framework, supervised fine-tuning]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shubham Mishra, Samyek Jain, Gorang Mehrishi, Shiv Tiwari, Harsh Sharma, Pratik Narang, Dhruv Kumar"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Birla Institute of Technology and Science, Pilani, Carnegie Mellon University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16795",children:"https://arxiv.org/pdf/2512.16795"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a reasoning-trace-augmented RAG framework that integrates a three-stage deductive reasoning process (document adjudication, conflict analysis, and grounded synthesis) to handle conflicting or unreliable retrieved evidence. It introduces a Conflict-Aware Trust-Score (CATS) evaluation pipeline. The method, tested with models like Qwen, shows substantial improvements in answer correctness and behavioral adherence over baseline RAG systems."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251219] LinkedOut: Linking World Knowledge Representation Out of Video LLM for Next-Generation Video Recommendation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [cross-layer knowledge fusion MoE, VLLM, world-knowledge representation, token extraction, layer-wise fusion]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haichao Zhang, Yao Lu, Lichen Wang, Yunzhe Li, Daiwei Chen, Yunpeng Xu, Yun Fu"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Northeastern University, LinkedIn, University of Wisconsin\u2013Madison"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16891",children:"https://arxiv.org/pdf/2512.16891"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces LinkedOut, a method that extracts world-knowledge-aware tokens directly from video frames using Video Large Language Models (VLLMs) and fuses features across model layers via a Mixture of Experts (MoE) for recommendation. It achieves state-of-the-art results on benchmarks by enabling low-latency, interpretable video recommendation without handcrafted labels. The approach demonstrates that leveraging VLLM priors and visual reasoning through layer-wise fusion is effective for downstream vision tasks."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);