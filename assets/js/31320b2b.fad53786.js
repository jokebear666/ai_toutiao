"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2186],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}},87817:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_GT/20260105-20260111","title":"20260105-20260111 (cs.GT)","description":"2026-01-05","source":"@site/docs/daily/cs_GT/20260105-20260111.md","sourceDirName":"daily/cs_GT","slug":"/daily/csgt/20260105-20260111","permalink":"/ai_toutiao/daily/csgt/20260105-20260111","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{"slug":"/daily/csgt/20260105-20260111"},"sidebar":"tutorialSidebar","previous":{"title":"20251229-20260104 (cs.GT)","permalink":"/ai_toutiao/daily/csgt/20251229-20260104"},"next":{"title":"cs.HC","permalink":"/ai_toutiao/category/cshc"}}');var r=i(74848),a=i(28453);const t={slug:"/daily/csgt/20260105-20260111"},o="20260105-20260111 (cs.GT)",l={},d=[{value:"2026-01-05",id:"2026-01-05",level:2}];function c(e){const n={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mermaid:"mermaid",mn:"mn",mrow:"mrow",msub:"msub",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20260105-20260111-csgt",children:"20260105-20260111 (cs.GT)"})}),"\n",(0,r.jsx)(n.h2,{id:"2026-01-05",children:"2026-01-05"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [game theory], [MinDist, opponent modeling, rule-based strategy, zero-sum game, heuristic optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Purushottam Saha, Avirup Chakraborty, Sourish Sarkar, Subhamoy Maitra, Diganta Mukherjee, Tridib Mukherjee"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Indian Statistical Institute"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00024",children:"https://arxiv.org/pdf/2601.00024"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a new hand-evaluation metric called MinDist, which quantifies the edit distance to a valid hand, improving upon the MinScore metric. 2. Designed a computationally efficient algorithm to calculate MinDist using dynamic pruning and pattern caching. 3. Integrated opponent hand-modeling within a two-player zero-sum simulation framework and validated the strategy's superiority through statistical hypothesis testing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6b73a0cbcb5f1c250c8adbb982411c12c8e09c81114767cb920146c72264f7e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6b73a0cbcb5f1c250c8adbb982411c12c8e09c81114767cb920146c72264f7e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a rule-based strategy for Classic Indian Rummy using a new hand-evaluation metric called MinDist, which measures the structural proximity to a winning hand. The method includes an efficient algorithm to compute MinDist and incorporates opponent modeling in simulations. Empirical results show that agents using this strategy achieve significantly higher win rates compared to traditional heuristic-based agents."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6e38\u620f\u7b56\u7565\u8bbe\u8ba1/Strategy Design for Rummy]\n    C --\x3e C1[\u65b0\u5ea6\u91cf\u6807\u51c6 MinDist/New Metric MinDist]\n    C --\x3e C2[\u9ad8\u6548\u7b97\u6cd5\u4e0e\u5bf9\u624b\u5efa\u6a21/Efficient Algorithm & Opponent Modeling]\n    D --\x3e D1[\u80dc\u7387\u663e\u8457\u63d0\u5347/Significant Win Rate Improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["[arXiv260105] Sparse Probabilistic Coalition Structure Generation: Bayesian Greedy Pursuit and ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsx)(n.mrow,{children:(0,r.jsxs)(n.msub,{children:[(0,r.jsx)(n.mrow,{}),(0,r.jsx)(n.mn,{children:"1"})]})}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"_1"})]})})}),(0,r.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"0.4511em",verticalAlign:"-0.15em"}}),(0,r.jsxs)(n.span,{className:"mord",children:[(0,r.jsx)(n.span,{}),(0,r.jsx)(n.span,{className:"msupsub",children:(0,r.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,r.jsxs)(n.span,{className:"vlist-r",children:[(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.3011em"},children:(0,r.jsxs)(n.span,{style:{top:"-2.55em",marginRight:"0.05em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(n.span,{className:"mord mtight",children:"1"})})]})}),(0,r.jsx)(n.span,{className:"vlist-s",children:"\u200b"})]}),(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.15em"},children:(0,r.jsx)(n.span,{})})})]})})]})]})})]})," Relaxations"]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent systems], [coalition structure generation, sparse regression, Bayesian greedy pursuit, l1 penalization, probabilistic framework]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Angshul Majumdar"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IIIT Delhi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00329",children:"https://arxiv.org/pdf/2601.00329"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel probabilistic framework for Coalition Structure Generation (CSG) where coalition values are learned from episodic observations via sparse linear regression. 2. Introduces and analyzes the Bayesian Greedy Coalition Pursuit (BGCP) algorithm, providing theoretical guarantees for exact coalition recovery under certain conditions. 3. Provides theoretical analysis for an alternative \u21131-penalized estimation scheme, deriving error bounds and translating them into welfare gap guarantees, and compares regimes where sparse methods outperform classical approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492cd85c7ccfef225059f9e637ee717227d05ec3497e1f7c70a5e2e84ad5cc35_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492cd85c7ccfef225059f9e637ee717227d05ec3497e1f7c70a5e2e84ad5cc35_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses coalition structure generation when coalition values are unknown and must be learned from noisy episodic data. It proposes a sparse probabilistic framework with two estimation methods: a Bayesian greedy pursuit algorithm and an \u21131-penalized estimator, providing theoretical recovery and error guarantees. The analysis identifies conditions under which these sparse learning approaches yield welfare-optimal structures and outperform classical methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Sparse Probabilistic Coalition Structure Generation<br>\u7a00\u758f\u6982\u7387\u8054\u76df\u7ed3\u6784\u751f\u6210"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["\u5b66\u4e60\u8054\u76df\u4ef7\u503c<br>Learning Coalition Values"]\n    Method["\u4e3b\u8981\u65b9\u6cd5<br>Key Methods"]\n    Results["\u5173\u952e\u7ed3\u679c<br>Key Results"]\n\n    Problem --\x3e P1["\u4ece\u89c2\u5bdf\u4e2d\u5b66\u4e60<br>Learn from Episodic Observations"]\n    Problem --\x3e P2["\u566a\u58f0\u7ebf\u6027\u7ec4\u5408<br>Noisy Linear Combination of Contributions"]\n\n    Method --\x3e M1["\u8d1d\u53f6\u65af\u8d2a\u5a6a\u8054\u76df\u8ffd\u8e2a (BGCP)<br>Bayesian Greedy Coalition Pursuit (BGCP)"]\n    Method --\x3e M2["\u21131 \u60e9\u7f5a\u4f30\u8ba1\u5668<br>\u21131-Penalized Estimator"]\n\n    Results --\x3e R1["BGCP: \u9ad8\u6982\u7387\u6062\u590d\u8054\u76df\u96c6<br>BGCP: Recovers Coalition Set w.h.p."]\n    Results --\x3e R2["\u21131: \u8bef\u5dee\u4e0e\u798f\u5229\u5dee\u8ddd\u754c\u9650<br>\u21131: Error & Welfare Gap Bounds"]\n    Results --\x3e R3["\u8bc6\u522b\u7a00\u758f/\u5bc6\u96c6\u4f18\u52bf\u673a\u5236<br>Identifies Sparse/Dense Regimes"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Unifying Proportional Fairness in Centroid and Non-Centroid Clustering"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [algorithmic fairness], [proportional fairness, clustering, core, fully justified representation, semi-centroid clustering]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Benjamin Cookson, Nisarg Shah, Ziqi Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Toronto"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00447",children:"https://arxiv.org/pdf/2601.00447"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),'  1. Introduces a novel "semi-centroid clustering" paradigm that generalizes both centroid and non-centroid clustering by combining their loss functions. 2. Proposes a novel polynomial-time algorithm that achieves a constant-factor approximation to the strong "core" fairness criterion, even when different distance metrics are used for centroid and non-centroid losses. 3. Derives improved results and lower bounds for more restricted loss functions and the weaker "fully justified representation (FJR)" fairness criterion.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd79b86ac8c95634d552a704a5902ceae48492dd4b145cf0737aa2d0b01ef905_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd79b86ac8c95634d552a704a5902ceae48492dd4b145cf0737aa2d0b01ef905_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper unifies two fairness paradigms in clustering by proposing a generalized "semi-centroid clustering" model where a point\'s loss is a combination of its distance to a centroid and its maximum distance to other points in its cluster. The authors develop a novel polynomial-time algorithm that provides a constant approximation guarantee for the strong "core" fairness criterion. This work bridges prior research on centroid and non-centroid clustering under proportional fairness.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Unifying Proportional Fairness in Centroid and Non-Centroid Clustering<br>\u7edf\u4e00\u8d28\u5fc3\u4e0e\u975e\u8d28\u5fc3\u805a\u7c7b\u4e2d\u7684\u6bd4\u4f8b\u516c\u5e73\u6027] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Prior work on proportional fairness in clustering is split into two separate paradigms.] --\x3e B1[\u8d28\u5fc3\u805a\u7c7b/Centroid Clustering<br>Loss = distance to centroid]\n    B --\x3e B2[\u975e\u8d28\u5fc3\u805a\u7c7b/Non-Centroid Clustering<br>Loss = max distance to cluster member]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Generalize both paradigms.] --\x3e C1[\u63d0\u51fa\u534a\u8d28\u5fc3\u805a\u7c7b/Propose Semi-Centroid Clustering<br>Loss = combination of centroid & non-centroid losses]\n    C --\x3e C2[\u7814\u7a76\u516c\u5e73\u6027\u6807\u51c6/Study Fairness Criteria<br>Core and Fully Justified Representation (FJR)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Novel polynomial-time algorithm.] --\x3e D1[\u5e38\u6570\u8fd1\u4f3c\u6838\u5fc3/Achieves constant approximation to the Core]\n    D --\x3e D2[\u4e0d\u540c\u5ea6\u91cf\u6709\u6548/Works even with different distance metrics]\n    D --\x3e D3[\u6539\u8fdb\u7ed3\u679c\u4e0e\u4e0b\u754c/Improved results & lower bounds for restricted cases]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] The CoinAlg Bind: Profitability-Fairness Tradeoffs in Collective Investment Algorithms"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [algorithmic fairness, game theory, decentralized finance], [collective investment algorithms, profitability-fairness tradeoff, arbitrage, privacy, transparency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Andr\xe9s F\xe1brega, James Austgen, Samuel Breckenridge, Jay Yu, Amy Zhao, Sarah Allen, Aditya Saraf, Ari Juels"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Cornell Tech, IC3, Pantera Capital, Ava Labs, Flashbots"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00523",children:"https://arxiv.org/pdf/2601.00523"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Formally defines the "CoinAlg Bind," a fundamental tradeoff where collective investment algorithms cannot simultaneously ensure economic fairness and avoid profit loss to arbitrage. 2. Presents a formal model of CoinAlgs with definitions of privacy and economic fairness, proving that privacy enables insider attacks while transparency enables arbitrage. 3. Empirically validates both sides of the tradeoff using data from the Uniswap decentralized exchange, quantifying arbitrage impact and demonstrating risks from covert-channel leaks.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18ee281908d18c83e757a24f60a6d4c85436fa1dd9dbccb373ae547812e6eb06_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18ee281908d18c83e757a24f60a6d4c85436fa1dd9dbccb373ae547812e6eb06_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies a fundamental tradeoff in Collective Investment Algorithms (CoinAlgs), called the CoinAlg Bind, where algorithms must choose between privacy (risking unfair insider value extraction) and transparency (risking profit erosion from arbitrage). The authors present a formal model and game-theoretic proofs to demonstrate this bind and empirically validate it using data from Uniswap. The main conclusion is that CoinAlgs inherently cannot guarantee both economic fairness and full profitability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[The CoinAlg Bind: Profitability-Fairness Tradeoffs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[CoinAlgs cannot ensure fairness without losing profit/CoinAlgs\u65e0\u6cd5\u5728\u4e0d\u635f\u5931\u5229\u6da6\u7684\u60c5\u51b5\u4e0b\u786e\u4fdd\u516c\u5e73]\n    C --\x3e C1[Formal model & game theory/\u5f62\u5f0f\u5316\u6a21\u578b\u4e0e\u535a\u5f08\u8bba]\n    C --\x3e C2[Empirical study on Uniswap/\u57fa\u4e8eUniswap\u7684\u5b9e\u8bc1\u7814\u7a76]\n    D --\x3e D1[Privacy enables insider attacks/\u9690\u79c1\u6027\u5bfc\u81f4\u5185\u90e8\u653b\u51fb]\n    D --\x3e D2[Transparency enables arbitrage/\u900f\u660e\u6027\u5bfc\u81f4\u5957\u5229]\n    D --\x3e D3[Empirical validation of the bind/\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u8be5\u56f0\u5883]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Bayesian Inverse Games with High-Dimensional Multi-Modal Observations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [inverse reinforcement learning], [Bayesian inference, variational autoencoder, Nash equilibrium, inverse games, multimodal observations]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yash Jain, Xinjie Liu, Lasse Peters, David Fridovich-Keil, Ufuk Topcu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The University of Texas at Austin, Delft University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00696",children:"https://arxiv.org/pdf/2601.00696"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Bayesian inference framework for inverse games to quantify uncertainty in estimating agent objectives, addressing the overconfidence of point-estimate methods. 2. Introduces a structured variational autoencoder with an embedded differentiable Nash game solver, enabling posterior sampling without requiring labeled objective data. 3. Demonstrates that multimodal inference reduces uncertainty when trajectory data is insufficient, leading to safer downstream planning decisions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9263c0ad6078bf92eb8f7a7ca21579f0a55a6e710fa80a06f40a66a735ce24a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9263c0ad6078bf92eb8f7a7ca21579f0a55a6e710fa80a06f40a66a735ce24a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of inferring agents' hidden objectives in multi-agent interactions, where existing maximum likelihood methods produce overconfident point estimates. The authors propose a Bayesian inverse game framework using a structured variational autoencoder with a differentiable Nash solver to generate posterior samples from multimodal observations. Experiments show the method improves inference quality, quantifies uncertainty, and enables safer autonomous decision-making compared to prior approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Bayesian Inverse Games with High-Dimensional Multi-Modal Observations") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("MLE\u65b9\u6cd5\u53ea\u63d0\u4f9b\u70b9\u4f30\u8ba1\uff0c\u5bfc\u81f4\u4e0d\u786e\u5b9a\u6027\u88ab\u5ffd\u7565/MLE methods provide only point estimates, ignoring uncertainty")\n    Problem --\x3e P2("\u4e0b\u6e38\u89c4\u5212\u53ef\u80fd\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u52a8\u4f5c/Downstream planning can be overconfident, leading to unsafe actions")\n    Method --\x3e M1("\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6/Approximate Bayesian inference framework")\n    Method --\x3e M2("\u7ed3\u6784\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5d4c\u5165\u53ef\u5fae\u7eb3\u4ec0\u6c42\u89e3\u5668/Structured VAE with embedded differentiable Nash solver")\n    Method --\x3e M3("\u5229\u7528\u591a\u6a21\u6001\u89c2\u6d4b\u6570\u636e/Utilizes multi-modal observation data")\n    Results --\x3e R1("\u6210\u529f\u5b66\u4e60\u5148\u9a8c\u548c\u540e\u9a8c\u5206\u5e03/Successfully learns prior and posterior distributions")\n    Results --\x3e R2("\u63a8\u7406\u8d28\u91cf\u4f18\u4e8eMLE\u65b9\u6cd5/Improves inference quality over MLE")\n    Results --\x3e R3("\u591a\u6a21\u6001\u63a8\u7406\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027/Multimodal inference further reduces uncertainty")'}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);