"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8346],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}},73309:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"daily/cs_AR/20260105-20260111","title":"20260105-20260111 (cs.AR)","description":"2026-01-05","source":"@site/docs/daily/cs_AR/20260105-20260111.md","sourceDirName":"daily/cs_AR","slug":"/daily/csar/20260105-20260111","permalink":"/ai_toutiao/daily/csar/20260105-20260111","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{"slug":"/daily/csar/20260105-20260111"},"sidebar":"tutorialSidebar","previous":{"title":"20251229-20260104 (cs.AR)","permalink":"/ai_toutiao/daily/csar/20251229-20260104"},"next":{"title":"cs.CC","permalink":"/ai_toutiao/daily/cscc"}}');var r=i(74848),a=i(28453);const t={slug:"/daily/csar/20260105-20260111"},o="20260105-20260111 (cs.AR)",c={},l=[{value:"2026-01-05",id:"2026-01-05",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20260105-20260111-csar",children:"20260105-20260111 (cs.AR)"})}),"\n",(0,r.jsx)(n.h2,{id:"2026-01-05",children:"2026-01-05"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Enhancing Reliability of STT-MRAM Caches by Eliminating Read Disturbance Accumulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [memory & caching], [STT-MRAM, read disturbance, cache reliability, ECC, REAP-cache]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Elham Cheshmikhani, Hamed Farbeh, Hossein Asadi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sharif University of Technology, Amirkabir University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00450",children:"https://arxiv.org/pdf/2601.00450"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces and formulates the phenomenon of read disturbance accumulation in STT-MRAM caches caused by speculative parallel reads during tag comparison. 2. Proposes the REAP-cache (Read Error Accumulation Preventer) scheme to eliminate this accumulation without compromising cache performance. 3. Demonstrates that REAP-cache significantly improves reliability (extending MTTF by 171x) with minimal overhead (less than 1% area and 2.7% energy increase)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e7f78ea49ca100ac89e593165b5879dec1063a4cf12be706bf9dd1db3c8f455_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e7f78ea49ca100ac89e593165b5879dec1063a4cf12be706bf9dd1db3c8f455_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies that the conventional parallel read of all blocks in a cache set for tag comparison leads to the accumulation of uncorrected read disturbance errors in STT-MRAM caches, degrading reliability. To solve this, the authors propose the REAP-cache scheme, which prevents this error accumulation. Their evaluation shows REAP-cache dramatically improves cache reliability (171x longer MTTF) with very low area and energy overheads."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Enhancing Reliability of STT-MRAM Caches<br>\u63d0\u5347STT-MRAM\u7f13\u5b58\u53ef\u9760\u6027] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u95ee\u9898: \u8bfb\u53d6\u5e72\u6270\u7d2f\u79ef\u964d\u4f4e\u53ef\u9760\u6027<br>Problem: Read Disturbance Accumulation Degrades Reliability]\n    C[\u65b9\u6cd5: \u63d0\u51faREAP-cache\u65b9\u6848<br>Method: Propose REAP-cache Scheme]\n    D[\u7ed3\u679c: MTTF\u63d0\u5347171\u500d\uff0c\u5f00\u9500\u6781\u5c0f<br>Results: 171x MTTF Improvement, Minimal Overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] ROBIN: Incremental Oblique Interleaved ECC for Reliability Improvement in STT-MRAM Caches"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [memory & caching], [STT-MRAM, Error-Correcting Codes (ECC), cache reliability, write failure, interleaving]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Elham Cheshmikhani, Hamed Farbeh, Hossein Asadi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sharif University of Technology, Amirkabir University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00456",children:"https://arxiv.org/pdf/2601.00456"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a comprehensive analysis revealing the inefficiency of conventional ECC configurations (per-word and interleaved) in STT-MRAM caches due to non-uniform distribution of bit transitions across codewords. 2. Proposed a novel ECC configuration called ROBIN (Incremental Oblique Interleaved ECC) designed to uniformly distribute bit transitions among codewords to maximize error correction capability. 3. Demonstrated significant reliability improvement, showing that ROBIN reduces the increased cache error rate caused by conventional ECC inefficiency by more than 28.6 times."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/220a026abe75f2e65296ee9d7d5c4aebb0b4aac8cebaceddd46efd3084ecae49_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/220a026abe75f2e65296ee9d7d5c4aebb0b4aac8cebaceddd46efd3084ecae49_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high error rate problem in STT-MRAM caches by identifying that conventional Error-Correcting Codes (ECCs) are inefficient due to data-dependent error patterns. The authors propose a new ECC configuration called ROBIN, which uses an incremental oblique interleaving technique to uniformly distribute bit transitions and improve correction capability. Evaluations show ROBIN reduces the cache error rate increase by over 28.6x compared to conventional ECCs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ROBIN: Incremental Oblique Interleaved ECC for Reliability Improvement in STT-MRAM Caches] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[STT-MRAM\u7f13\u5b58\u9519\u8bef\u7387\u9ad8 / High error rate in STT-MRAM caches]\n    B --\x3e B2[\u4f20\u7edfECC\u56e0\u6570\u636e\u4f9d\u8d56\u9519\u8bef\u6a21\u5f0f\u6548\u7387\u4f4e / Conventional ECC inefficient due to data-dependent error patterns]\n    C --\x3e C1[\u63d0\u51faROBIN ECC\u914d\u7f6e / Propose ROBIN ECC configuration]\n    C --\x3e C2[\u589e\u91cf\u659c\u4ea4\u9519\u5206\u5e03\u6bd4\u7279\u7ffb\u8f6c / Incremental oblique interleaving to distribute bit transitions uniformly]\n    D --\x3e D1[\u964d\u4f4e\u7f13\u5b58\u9519\u8bef\u7387\u63d0\u5347\u8d85\u8fc728.6\u500d / Reduces cache error rate increase by >28.6x]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Democratizing Electronic-Photonic AI Systems: An Open-Source AI-Infused Cross-Layer Co-Design and Design Automation Toolflow"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [electronic-photonic design automation, cross-layer co-design, inverse photonic design, AI-accelerated Maxwell solvers, photonic AI system]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Hongjian Zhou, Ziang Yin, Jiaqi Gu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arizona State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00130",children:"https://arxiv.org/pdf/2601.00130"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a cross-layer co-design framework for scalable photonic edge AI and Transformer inference architectures. 2. Introduced SimPhony, an open-source modeling tool for rapid EPIC AI system evaluation and design-space exploration. 3. Developed AI-enabled photonic design automation techniques, including physical AI-based Maxwell solvers and a fabrication-aware inverse design framework."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76312a14ab1d9b01be6967c891d86f1c36fb6eebdf382d27578721d3ff3e1c24_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76312a14ab1d9b01be6967c891d86f1c36fb6eebdf382d27578721d3ff3e1c24_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of designing electronic-photonic AI systems by proposing an open-source, AI-infused cross-layer co-design and automation framework. The method includes architecture designs for photonic AI, a modeling tool called SimPhony, and AI-powered design automation tools. The work aims to democratize and accelerate the development of next-generation photonic AI systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Democratizing Electronic-Photonic AI Systems<br>\u7535\u5b50-\u5149\u5b50AI\u7cfb\u7edf\u6c11\u4e3b\u5316] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Challenging EPIC AI System Design<br>EPIC AI\u7cfb\u7edf\u8bbe\u8ba1\u6311\u6218]\n    B --\x3e B2[Lack of Mature EPDA Toolchain<br>\u7f3a\u4e4f\u6210\u719f\u7684EPDA\u5de5\u5177\u94fe]\n    C --\x3e C1[Cross-Layer Co-Design Framework<br>\u8de8\u5c42\u534f\u540c\u8bbe\u8ba1\u6846\u67b6]\n    C --\x3e C2[SimPhony Modeling Tool<br>SimPhony\u5efa\u6a21\u5de5\u5177]\n    C --\x3e C3[AI-Enabled EPDA Stack<br>AI\u8d4b\u80fd\u7684EPDA\u5806\u6808]\n    D --\x3e D1[Democratizes Development<br>\u6c11\u4e3b\u5316\u5f00\u53d1]\n    D --\x3e D2[Enables Scalable EPDA<br>\u5b9e\u73b0\u53ef\u6269\u5c55EPDA]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Toward Large-Scale Photonics-Empowered AI Systems: From Physical Design Automation to System-Algorithm Co-Exploration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [photonic AI, electronic-photonic design automation (EPDA), system-algorithm co-exploration, cross-layer toolchain, physical design automation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ziang Yin, Hongjian Zhou, Nicholas Gangi, Meng Zhang, Jeff Zhang, Zhaoran Rena Huang, Jiaqi Gu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arizona State University, Rensselaer Polytechnic Institute"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00129",children:"https://arxiv.org/pdf/2601.00129"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identified three essential considerations for scaling practical photonic AI systems: dynamic tensor operation support, systematic management of overheads, and robustness under hardware non-idealities. 2. Built a cross-layer toolchain (SimPhony, ADEPT, ADEPT-Z, Apollo, LiDAR) for quantitative, physically-grounded co-design from system exploration to physical layout. 3. Established a co-design loop that bridges architectural intent and deployable photonic hardware by translating physical costs into system-level metrics."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd0ce87d1ffb64d07fd82b197f024f167052c6fb76c061ecf0885e18f056796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd0ce87d1ffb64d07fd82b197f024f167052c6fb76c061ecf0885e18f056796_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of scaling photonic AI systems by identifying key design considerations and developing a cross-layer toolchain for system-algorithm co-exploration. The proposed method uses tools like SimPhony and Apollo to model physical costs and automate design, enabling quantitative trade-off analysis under real implementation constraints. The main conclusion is that this approach creates a physically-grounded co-design loop essential for realizing large-scale, deployable photonic AI hardware."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Toward Large-Scale Photonics-Empowered AI Systems<br/>\u5927\u89c4\u6a21\u5149\u5b50\u8d4b\u80fdAI\u7cfb\u7edf] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>Scaling AI constrained by data movement & efficiency<br/>AI\u6269\u5c55\u53d7\u9650\u4e8e\u6570\u636e\u79fb\u52a8\u4e0e\u80fd\u6548] --\x3e B1[\u6311\u62181: \u52a8\u6001\u5f20\u91cf\u64cd\u4f5c\u652f\u6301<br/>Dynamic tensor operation support]\n    B --\x3e B2[\u6311\u62182: \u5f00\u9500\u7cfb\u7edf\u7ba1\u7406<br/>Systematic overhead management]\n    B --\x3e B3[\u6311\u62183: \u786c\u4ef6\u975e\u7406\u60f3\u6027\u9c81\u68d2\u6027<br/>Robustness under hardware non-idealities]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Cross-layer toolchain for co-design<br/>\u8de8\u5c42\u5de5\u5177\u94fe\u534f\u540c\u8bbe\u8ba1] --\x3e C1[SimPhony: \u5b9e\u73b0\u611f\u77e5\u5efa\u6a21<br/>Implementation-aware modeling]\n    C --\x3e C2[ADEPT/ADEPT-Z: \u7535\u8def\u4e0e\u62d3\u6251\u63a2\u7d22<br/>Circuit & topology exploration]\n    C --\x3e C3[Apollo/LiDAR: \u7269\u7406\u8bbe\u8ba1\u81ea\u52a8\u5316<br/>Physical design automation]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>Quantitative & physically-grounded co-design loop<br/>\u5b9a\u91cf\u4e14\u7269\u7406\u57fa\u7840\u7684\u534f\u540c\u8bbe\u8ba1\u5faa\u73af] --\x3e D1[\u8fde\u63a5\u7cfb\u7edf\u76ee\u6807\u4e0e\u53ef\u884c\u786c\u4ef6<br/>Connects system objectives to feasible hardware]\n    D --\x3e D2[\u4ea7\u751f\u53ef\u5236\u9020\u5e03\u5c40<br/>Produces manufacturable layouts]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [wireless communication systems], [splitting precoding, subspace selection, quantized refinement, massive MIMO, fronthaul capacity]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yasaman Khorsandmanesh, Emil Bjornson, Joakim Jalden"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," KTH Royal Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00616",children:"https://arxiv.org/pdf/2601.00616"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel splitting precoding architecture that separates precoding computation between the Advanced Antenna System (AAS) and Baseband Unit (BBU) to address fronthaul bottlenecks. 2. Introduces a local subspace selection method at the AAS to reduce channel dimensionality before fronthaul transmission. 3. Develops a quantization-aware refinement precoding algorithm at the BBU that operates on the reduced effective channel to optimize performance under limited fronthaul capacity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f66e91bfdb08909724d80ba8bae4b67df9824da0d5fae8eb15678f2e7897b484_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f66e91bfdb08909724d80ba8bae4b67df9824da0d5fae8eb15678f2e7897b484_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limited fronthaul capacity problem in massive MIMO 5G systems by proposing a splitting precoding architecture. The method separates processing between the antenna system (which performs subspace selection) and the baseband unit (which computes quantized refinement precoding), achieving higher spectral efficiency than conventional one-stage precoding approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\nRoot["Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Limited fronthaul capacity in massive MIMO 5G architectures"]\nRoot --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Splitting architecture with AAS subspace selection and BBU quantized refinement precoding"]\nRoot --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Achieves higher sum spectral efficiency than conventional one-stage precoding"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);