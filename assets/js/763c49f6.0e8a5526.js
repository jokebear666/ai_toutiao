"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7879],{4132:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/20251229-20260104","title":"20251229-20260104","description":"2025-12-29","source":"@site/docs/daily/20251229-20260104.md","sourceDirName":"daily","slug":"/daily/20251229-20260104","permalink":"/ai_toutiao/daily/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228","permalink":"/ai_toutiao/daily/20251222-20251228"},"next":{"title":"20260105-20260111","permalink":"/ai_toutiao/daily/20260105-20260111"}}');var r=i(74848),a=i(28453);const t={},o="20251229-20260104",l={},d=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2},{value:"2026-01-01",id:"2026-01-01",level:2}];function c(e){const n={a:"a",annotation:"annotation",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mn:"mn",mo:"mo",mover:"mover",mrow:"mrow",msup:"msup",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251229-20260104",children:"20251229-20260104"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"cs.DC total: 16"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Spark Works Ltd., IONOS SE, Iquadrat Inform\xe1tica S.L."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21340",children:"https://arxiv.org/pdf/2512.21340"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Harnessing Data Spaces for Smart City Infrastructures] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Luki\u0107, Franck Cappello"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21433",children:"https://arxiv.org/pdf/2512.21433"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[DeepCQ: \u901a\u7528\u6df1\u5ea6\u4ee3\u7406\u6846\u67b6\u7528\u4e8e\u6709\u635f\u538b\u7f29\u8d28\u91cf\u9884\u6d4b] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bc4\u4f30\u538b\u7f29\u540e\u6570\u636e\u8d28\u91cf\u7684\u8ba1\u7b97\u6210\u672c\u9ad8/Expensive to assess post-compression data quality]\n    C --\x3e C1[\u4e24\u9636\u6bb5\u8bbe\u8ba1: \u7279\u5f81\u63d0\u53d6 + \u8f7b\u91cf\u9884\u6d4b/Two-stage design: feature extraction + lightweight prediction]\n    C --\x3e C2[\u4e13\u5bb6\u6df7\u5408\u8bbe\u8ba1\u5904\u7406\u65f6\u53d8\u6570\u636e/Mixture-of-experts for time-evolving data]\n    D --\x3e D1[\u9884\u6d4b\u8bef\u5dee\u666e\u904d\u4f4e\u4e8e10%/Prediction errors generally under 10%]\n    D --\x3e D2[\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5/Significantly outperforms existing methods]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Demystifying ARM SME to Optimize General Matrix Multiplications"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [ARM SME, GEMM, cache-aware partitioning, micro-kernels, on-the-fly transposition]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," College of Computer Science and Technology, National University of Defense Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21473",children:"https://arxiv.org/pdf/2512.21473"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A systematic characterization of the ARM SME architecture that derives optimization guidelines for GEMM. 2. The design and implementation of MpGEMM, an open-source library featuring cache-aware partitioning and efficient data packing with on-the-fly transposition. 3. Specialized micro-kernels that fully utilize SME's multi-vector loads and all available tile registers to maximize performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the underutilization of ARM's Scalable Matrix Extension (SME) hardware for large-scale General Matrix Multiplication (GEMM). It proposes MpGEMM, an open-source library that optimizes GEMM through cache-aware partitioning, efficient data packing, and specialized micro-kernels tailored for SME. Evaluations on an Apple M4 Pro show MpGEMM achieves a 1.23x speedup over the vendor-optimized Apple Accelerate library."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Demystifying ARM SME to Optimize General Matrix Multiplications") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u73b0\u6709\u5e93\u672a\u80fd\u5145\u5206\u5229\u7528ARM SME\u786c\u4ef6/Existing libraries fail to exploit ARM SME")\n    Problem --\x3e P2("\u5927\u89c4\u6a21GEMM\u6027\u80fd\u74f6\u9888/Large-scale GEMM performance bottlenecks")\n    Method --\x3e M1("\u7cfb\u7edf\u5316\u67b6\u6784\u5206\u6790/Systematic SME characterization")\n    Method --\x3e M2("\u8bbe\u8ba1MpGEMM\u5e93/Design MpGEMM library")\n    M2 --\x3e M2a("\u7f13\u5b58\u611f\u77e5\u5206\u533a/Cache-aware partitioning")\n    M2 --\x3e M2b("\u9ad8\u6548\u6570\u636e\u6253\u5305/Efficient data packing")\n    M2 --\x3e M2c("\u4e13\u7528\u5fae\u5185\u6838/Specialized micro-kernels")\n    Results --\x3e R1("\u6027\u80fd\u8d85\u8d8aApple Accelerate\u5e93/Outperforms Apple Accelerate")\n    Results --\x3e R2("\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u5f00\u6e90\u65b9\u6848/Significantly beats other open-source alternatives")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21487",children:"https://arxiv.org/pdf/2512.21487"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[MoE\u63a8\u7406\u5185\u5b58\u5bc6\u96c6\uff0c\u73b0\u6709DEP\u8c03\u5ea6\u6548\u7387\u4f4e/MoE inference is memory-intensive, existing DEP scheduling is inefficient]\n    C --\x3e C1[\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5212\u5206\u4e0e\u8c03\u5ea6\u4f18\u5316/Fine-grained task partitioning and scheduling optimization]\n    D --\x3e D1[\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.61\u500d/Throughput improved by up to 1.61x]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Canaan Inc."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21571",children:"https://arxiv.org/pdf/2512.21571"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/kendryte/nncase",children:"https://github.com/kendryte/nncase"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a "compile once, adapt everywhere" capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u90e8\u7f72\u53d7\u9650\u4e8e\u5185\u5b58\u67b6\u6784\u5f02\u6784\u6027\uff0c\u4f20\u7edf\u7f16\u8bd1\u5668\u6d41\u7a0b\u788e\u7247\u5316/Memory architecture heterogeneity hinders efficient LLM deployment, traditional compilers have fragmented workflows.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8ee-graph\u7684\u9879\u91cd\u5199\u5f15\u64ce\uff0c\u7edf\u4e00NUMA\u62bd\u8c61\uff0c\u96c6\u6210\u81ea\u52a8\u5411\u91cf\u5316\u3001\u5206\u5e03\u3001\u8c03\u5ea6\u6a21\u5757/E-graph-based term rewriting engine, unified NUMA abstraction, integrates Auto Vectorize, Distribution, Schedule modules.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u6027\u80fd\u8d85\u8d8aMLC LLM\u548cIntel IPEX\uff0c\u63a5\u8fd1\u624b\u5de5\u4f18\u5316\u7684llama.cpp/Outperforms MLC LLM & Intel IPEX, achieves performance comparable to hand-optimized llama.cpp.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China (USTC), Hefei University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21615",children:"https://arxiv.org/pdf/2512.21615"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Embedding Samples Dispatching for Recommendation Model Training in Edge Environments<br>\u8fb9\u7f18\u73af\u5883\u4e2d\u63a8\u8350\u6a21\u578b\u8bad\u7ec3\u7684\u5d4c\u5165\u6837\u672c\u8c03\u5ea6"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>DLRM\u8fb9\u7f18\u8bad\u7ec3\u4e2d\u5d4c\u5165\u4f20\u8f93\u6210\u672c\u9ad8"] --\x3e P1["\u6311\u6218/Challenges<br>\u5f02\u6784\u7f51\u7edc\uff0c\u8d44\u6e90\u53d7\u9650"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>ESD\u673a\u5236\u4e0eHybridDis\u8c03\u5ea6"] --\x3e M1["\u65b9\u6cd5\u6838\u5fc3/Core<br>\u57fa\u4e8e\u9884\u671f\u4f20\u8f93\u6210\u672c\u7684\u6837\u672c\u8c03\u5ea6"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u51cf\u5c11\u4f20\u8f93\u6210\u672c\uff0c\u52a0\u901f\u8bad\u7ec3"] --\x3e R1["\u6027\u80fd\u63d0\u5347/Improvement<br>\u6210\u672c\u964d\u4f4e36.76%\uff0c\u901f\u5ea6\u63d0\u53471.74\u500d"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [real-time systems], [lock-free, fault-tolerance, resource sharing, multicore, worst-case response time analysis]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of York, Sun Yat-sen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21701",children:"https://arxiv.org/pdf/2512.21701"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Faults in critical sections cause error propagation; locking protocols lack fault tolerance, increasing blocking.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: LEFT-RS protocol enables concurrent read access and parallel critical section entry for fault resilience.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Up to 84.5% average schedulability improvement over existing approaches.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision transformer, cloud-device collaboration, dynamic scheduling, patch-level importance, weighted ensembling]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Tsinghua University, Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21730",children:"https://arxiv.org/pdf/2512.21730"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A collaboration-aware importance scorer that identifies critical regions at the patch level for selective processing. 2. A dynamic scheduler that adaptively adjusts patch transmission quality to balance latency and accuracy under changing network conditions. 3. A weighted ensembler that fuses edge and cloud inference results to improve overall accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents Hyperion, a cloud-device collaborative framework designed to enable low-latency inference on Ultra-HD video using off-the-shelf vision transformers. It tackles computational and transmission bottlenecks by selectively processing critical patches, dynamically adjusting transmission quality, and fusing results. Experiments show Hyperion improves frame processing rate by up to 1.61x and accuracy by up to 20.2% compared to baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Hyperion: Low-Latency Ultra-HD Video Analytics<br>Hyperion: \u4f4e\u5ef6\u8fdf\u8d85\u9ad8\u6e05\u89c6\u9891\u5206\u6790] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Ultra-HD\u89c6\u9891\u5904\u7406\u7684\u8ba1\u7b97\u4e0e\u4f20\u8f93\u74f6\u9888<br>Computational & Transmission Bottleneck for Ultra-HD Video]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u4e91-\u7aef\u534f\u4f5c\u7684Vision Transformer\u63a8\u7406\u6846\u67b6<br>Cloud-Device Collaborative ViT Inference Framework]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u5904\u7406\u7387\u63d0\u53471.61\u500d\uff0c\u51c6\u786e\u7387\u63d0\u534720.2%<br>1.61x Faster Frame Rate, 20.2% Higher Accuracy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Krishna Chaitanya Sunkara, Rambabu Konakanchi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Oracle, Charles Schwab"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21801",children:"https://arxiv.org/pdf/2512.21801"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Probabilistic LSTM forecasting validated within \xb130-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Smart IoT-Based Leak Forecasting and Detection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Coolant leaks cause energy loss in AI data centers]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: LSTM for forecasting + Random Forest for detection with IoT sensors]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 96.5% detection accuracy, 87% forecasting accuracy, 1,500 kWh energy saved]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["[arXiv251229] LIME",":Accelerating"," Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices"]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [collaborative inference, pipeline parallelism, model offloading, memory adaptation, edge computing]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shandong University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21835",children:"https://arxiv.org/pdf/2512.21835"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LIME, a collaborative system for lossless LLM inference across multiple memory-constrained edge devices under limited bandwidth. 2. Employs an interleaved pipeline parallelism with model offloading to dynamically balance computation and communication. 3. Introduces a fine-grained offline allocation scheduler and an online memory adaptation strategy to optimize resource usage and minimize inference latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes LIME, a system that enables lossless, collaborative LLM inference on multiple memory-constrained edge devices by using interleaved pipeline parallelism and model offloading, along with offline scheduling and online memory adaptation. Experiments on four Nvidia Jetson devices with LLaMA3.3-70B show that LIME achieves significant speedups over baselines without accuracy loss."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[LIME: \u534f\u4f5c\u5f0f\u65e0\u635fLLM\u63a8\u7406 / Collaborative Lossless LLM Inference] --\x3e Problem[\u8fb9\u7f18\u8bbe\u5907\u5185\u5b58\u53d7\u9650 / Memory-Constrained Edge Devices]\n    Root --\x3e Method[\u4ea4\u7ec7\u6d41\u6c34\u7ebf\u5e76\u884c\u4e0e\u6a21\u578b\u5378\u8f7d / Interleaved Pipeline Parallelism & Offloading]\n    Root --\x3e Results[\u5b9e\u73b0\u65e0\u635f\u52a0\u901f / Achieves Lossless Speedup]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tingyang Sun, Ting He, Bo Ji, Parimal Parag"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Pennsylvania State University, Virginia Tech, Indian Institute of Science"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21884",children:"https://arxiv.org/pdf/2512.21884"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u5206\u5e03\u5f0fLLM\u63a8\u7406\u7684\u8d44\u6e90\u5206\u914d\u4f18\u5316/Optimizing resource allocation for distributed LLM inference]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u6027\u80fd\u5efa\u6a21\u4e0e\u4f18\u5316\u7b97\u6cd5/Performance modeling and optimization algorithms]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u663e\u8457\u964d\u4f4e\u63a8\u7406\u65f6\u95f4/Substantially reduces inference time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] BLEST: Blazingly Efficient BFS using Tensor Cores"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [BFS, Tensor Cores, SpMSpV, Graph Reordering, Kernel Fusion]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Deniz Elbek, Kamer Kaya"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sabanci University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21967",children:"https://arxiv.org/pdf/2512.21967"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[BLEST: Blazingly Efficient BFS using Tensor Cores] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5982\u4f55\u5c06\u4e0d\u89c4\u5219\u56feBFS\u6620\u5c04\u5230\u5bc6\u96c6\u5f20\u91cf\u6838\u5fc3/Map irregular BFS to dense Tensor Cores]\n    C --\x3e C1[\u4e8c\u503c\u5316\u865a\u62df\u5207\u7247\u96c6/Binarised Virtual Slice Sets (BVSS)]\n    C --\x3e C2[\u56fe\u91cd\u6392\u5e8f\u7b56\u7565/Graph Reordering Strategies]\n    C --\x3e C3[\u6279\u5904\u7406SpMSpV\u4e0e\u6838\u878d\u5408/Batched SpMSpV & Kernel Fusion]\n    D --\x3e D1[\u5e73\u57473.58-4.9\u500d\u52a0\u901f/Average 3.58-4.9x Speedup]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Giuseppe De Palma, Saverio Giallorenzo"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22054",children:"https://arxiv.org/pdf/2512.22054"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [Mixture-of-Experts, expert parallelism, data shuffling, transformation-communication fusion, collective communication]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Infinigence AI, University of Southern California, Zhongguancun Academy, Shanghai Jiao Tong University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22036",children:"https://arxiv.org/pdf/2512.22036"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies the root cause of inefficiency in MoE data shuffling as the misalignment between expert-major and device-major data layouts, requiring disaggregated transformation and communication. 2. Proposes FUSCO, a communication library that fuses data transformation and communication operations into a single, efficient pipeline to eliminate redundant data movement. 3. Introduces lightweight planning and load-balancing mechanisms to eliminate redundant communication and disperse traffic, further optimizing the shuffling process."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the performance bottleneck of distributed data shuffling in Mixture-of-Experts (MoE) model training and inference. It proposes FUSCO, a communication library that fuses data transformation and communication to align expert-major and device-major data layouts efficiently. Evaluations show FUSCO achieves significant speedups over existing libraries like NCCL and DeepEP, reducing both training and inference latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[FUSCO: High-Performance Distributed Data Shuffling] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: MoE\u4e13\u5bb6\u5e76\u884c\u4e2d\u7684\u6570\u636e\u6df7\u6d17\u5f00\u9500\u5927/High overhead of data shuffling in MoE expert parallelism]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u901a\u8fc7\u878d\u5408\u6570\u636e\u8f6c\u6362\u4e0e\u901a\u4fe1\u5b9e\u73b0\u9ad8\u6548\u6df7\u6d17/Efficient shuffling via transformation-communication fusion]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u76f8\u6bd4NCCL\u548cDeepEP\u5b9e\u73b0\u663e\u8457\u52a0\u901f/Significant speedups over NCCL and DeepEP]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [federated fine-tuning, connection failures, adaptive aggregation, data heterogeneity, convergence guarantee]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The affiliations include IEEE members, suggesting multiple institutions. Based on common patterns, likely institutions include The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen) and/or other Chinese universities/tech institutes, given authors like Tsung-Hui Chang and Tony Q. S. Quek are affiliated with such institutions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22035",children:"https://arxiv.org/pdf/2512.22035"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes FedAuto, a novel Federated Fine-Tuning framework that mitigates the combined effects of unreliable connections and data heterogeneity via adaptive aggregation, requiring no prior knowledge of network conditions. 2. Establishes a rigorous, per-round convergence guarantee for FedAuto that holds for each individual realization, removing common assumptions on failure probabilities or client selection. 3. Demonstrates through extensive experiments that FedAuto outperforms state-of-the-art baselines under diverse failure scenarios for both full and partial-parameter fine-tuning (e.g., LoRA)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the performance degradation of Federated Fine-Tuning (FFT) in real-world networks with unreliable connections and heterogeneous data. It proposes FedAuto, a framework that uses adaptive aggregation to handle these issues without prior network knowledge or infrastructure changes. Experiments show FedAuto consistently outperforms existing methods and provides stronger theoretical convergence guarantees."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[FFT\u6027\u80fd\u53d7\u4e0d\u53ef\u9760\u8fde\u63a5\u548c\u6570\u636e\u5f02\u6784\u6027\u5f71\u54cd/FFT performance degraded by unreliable connections & data heterogeneity]\n    C --\x3e C1[FedAuto: \u901a\u8fc7\u81ea\u9002\u5e94\u805a\u5408\u7684FFT\u6846\u67b6/FedAuto: FFT framework with adaptive aggregation]\n    C --\x3e C2[\u65e0\u9700\u5148\u9a8c\u7f51\u7edc\u77e5\u8bc6/No prior network knowledge needed]\n    D --\x3e D1[\u5b9e\u9a8c\u8868\u73b0\u8d85\u8d8aSOTA/Outperforms SOTA baselines]\n    D --\x3e D2[\u63d0\u4f9b\u4e25\u683c\u6536\u655b\u4fdd\u8bc1/Provides rigorous convergence guarantee]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Illinois at Urbana-Champaign, IBM Research"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22113",children:"https://arxiv.org/pdf/2512.22113"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>\u57fa\u4e8e\u667a\u80fd\u4f53\u7ed3\u6784\u5316\u56fe\u904d\u5386\u7684\u4e91\u5e94\u7528\u6839\u56e0\u5206\u6790] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 17'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Santhosh Kumar Ravindran"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Microsoft Corporation"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21351",children:"https://arxiv.org/pdf/2512.21351"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u4ee3\u7801\u751f\u6210\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9API\u53d8\u5316/LLM code generation lacks adaptability to API changes]\n    C --\x3e C1[\u5c06RL\u8f68\u8ff9\u89c6\u4e3a\u57fa\u56e0\u7ec4\u8fdb\u884c\u8fdb\u5316\u64cd\u4f5c/Treat RL trajectories as genomes for evolutionary operations]\n    C --\x3e C2[\u5728\u591c\u95f4\u56de\u653e\u9636\u6bb5\u8fdb\u884c\u7a81\u53d8\u4e0e\u9009\u62e9/Mutation and selection during nocturnal replay]\n    D --\x3e D1[\u89e3\u51b3\u65b9\u6848\u65b0\u9896\u6027\u63d0\u534735%/35% higher novelty in solutions]\n    D --\x3e D2[\u9002\u5e94\u901f\u5ea6\u52a0\u5feb25%/25% faster adaptation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21395",children:"https://arxiv.org/pdf/2512.21395"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[A Reinforcement Learning Approach to Synthetic Data Generation] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: State-of-the-art generative models need large datasets and complex training, limiting use in small-sample settings.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Reframe SDG as RL; introduce RLSyn (stochastic policy optimized via PPO with discriminator rewards).]\n    D[\u5173\u952e\u7ed3\u679c/Results: RLSyn performs comparably to/better than GANs & diffusion models, especially on smaller datasets.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Illinois Institute of Technology, California State University, San Bernardino"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21412",children:"https://arxiv.org/pdf/2512.21412"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u7efc\u8ff0\u7684\u4e0d\u8db3: \u7ecf\u5178AoI\u4e0e\u6cdb\u5316RL\u7814\u7a76\u5206\u79bb / Gap: Classical AoI vs. Broad RL]\n    C --\x3e C1[\u63d0\u51fa\u4ee5AoI\u4e3a\u4e2d\u5fc3\u7684RL\u7efc\u8ff0\u6846\u67b6 / Propose AoI-centric RL Survey Framework]\n    C --\x3e C2[\u6784\u5efaAoI\u53d8\u4f53\u5206\u7c7b\u4e0e\u7b56\u7565\u4e2d\u5fc3\u5206\u7c7b\u6cd5 / Build AoI Variant & Policy-Centric Taxonomies]\n    D --\x3e D1[\u4e3aB5G/6G\u5efa\u7acb\u5b66\u4e60\u5f0f\u65b0\u9c9c\u5ea6\u4f18\u5316\u7684\u7edf\u4e00\u57fa\u7840 / Establish Unified Foundation for Learning-based Freshness Optimization]\n    D --\x3e D2[\u8bc6\u522b\u5f00\u653e\u6311\u6218: \u5ef6\u8fdf\u51b3\u7b56\u3001\u968f\u673a\u6027\u3001\u8de8\u5c42\u8bbe\u8ba1 / Identify Open Challenges: Delayed Decisions, Stochasticity, Cross-layer]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Washington, University of California, Berkeley"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21446",children:"https://arxiv.org/pdf/2512.21446"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[MDLMs\u89e3\u7801\u6162\uff0c\u901f\u5ea6\u4f18\u52bf\u6709\u9650/MDLMs decode slowly, limiting speed advantage]\n    C --\x3e C1[\u57fa\u4e8eGRPO\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6/On-policy RL framework based on GRPO]\n    C --\x3e C2[\u8054\u5408\u4f18\u5316\u6269\u6563\u6a21\u578b\u4e0e\u89e3\u63a9\u7801\u89c4\u5212\u5668/Jointly optimize diffusion model & unmasking planner]\n    D --\x3e D1[\u63d0\u5347\u7cbe\u5ea6-\u6548\u7387\u6743\u8861/Improves accuracy-efficiency trade-off]\n    D --\x3e D2[\u8fc8\u5411"\u6269\u6563\u9738\u6743"/Moving towards "diffusion supremacy"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21514",children:"https://arxiv.org/pdf/2512.21514"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[DiverseGRPO: Mitigating Mode Collapse] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[GRPO\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83/GRPO causes mode collapse]\n    B1 --\x3e B2[\u7f3a\u4e4f\u89c6\u89c9\u591a\u6837\u6027/Lacks visual diversity]\n    C --\x3e C1[\u5956\u52b1\u5c42\u9762: \u5206\u5e03\u521b\u9020\u529b\u5956\u52b1/Reward Level: Distributional Creativity Bonus]\n    C --\x3e C2[\u751f\u6210\u5c42\u9762: \u7ed3\u6784\u611f\u77e5\u6b63\u5219\u5316/Generation Level: Structure-Aware Regularization]\n    C1 --\x3e C3[\u57fa\u4e8e\u8bed\u4e49\u5206\u7ec4\u7684\u8c31\u805a\u7c7b/Spectral Clustering for Semantic Grouping]\n    D --\x3e D1[\u8bed\u4e49\u591a\u6837\u6027\u63d0\u534713%-18%/13%-18% Semantic Diversity Improvement]\n    D --\x3e D2[\u5efa\u7acb\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf/Establishes New Pareto Frontier]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Generative Actor Critic"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21527",children:"https://arxiv.org/pdf/2512.21527"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," github.com/qayqaq/Generative-Actor-Critic"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Generative Actor Critic] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edfRL\u5728\u7ebf\u6539\u8fdb\u79bb\u7ebf\u9884\u8bad\u7ec3\u6a21\u578b\u5b58\u5728\u6311\u6218/Challenges in refining offline models online]\n    C --\x3e C1[\u5c06\u7b56\u7565\u8bc4\u4f30\u91cd\u6784\u4e3a\u5b66\u4e60\u8f68\u8ff9\u4e0e\u56de\u62a5\u7684\u8054\u5408\u751f\u6210\u6a21\u578b/Reframe policy evaluation as learning p(\u03c4, y)]\n    C --\x3e C2[\u5c06\u7b56\u7565\u6539\u8fdb\u91cd\u6784\u4e3a\u5728\u6a21\u578b\u4e0a\u8fdb\u884c\u591a\u6837\u5316\u63a8\u7406/Reframe policy improvement as versatile inference]\n    C --\x3e C3[\u57fa\u4e8e\u6f5c\u53d8\u91cf\u6a21\u578b\u7684\u5b9e\u4f8b\u5316\u4e0e\u65b0\u9896\u63a8\u7406\u7b56\u7565/Instantiation with latent plans & novel inference]\n    D --\x3e D1[\u79bb\u7ebf\u6027\u80fd\u5f3a\u5927/Strong offline performance]\n    D --\x3e D2[\u79bb\u7ebf\u5230\u5728\u7ebf\u6539\u8fdb\u663e\u8457/Enhanced offline-to-online improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Peking University, Harbin Institute of Technology, Shenzhen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21540",children:"https://arxiv.org/pdf/2512.21540"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[LEASH: Adaptive Length Penalty and Reward Shaping] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs\u751f\u6210\u8fc7\u957f\u63a8\u7406\u94fe\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u65b9\u6cd5\u52a8\u6001\u8c03\u6574\u60e9\u7f5a\u7cfb\u6570/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c1160%\uff0c\u6027\u80fd\u4fdd\u6301\u7ade\u4e89\u529b/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Towards Learning-Based Formula 1 Race Strategies"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [mixed-integer nonlinear programming, reinforcement learning, energy allocation, tire wear, pit stop]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Giona Fieni, Joschua W\xfcthrich, Marc-Philippe Neumann, Mohammad M. Moradi, Christopher H. Onder"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute for Dynamic Systems and Control, ETH Z\xfcrich"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21570",children:"https://arxiv.org/pdf/2512.21570"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a comprehensive race scenario model for Formula 1 that jointly accounts for energy allocation, tire wear, and pit stop timing using lap time maps and a dynamic tire wear model. 2. Develops and solves the strategy optimization problem using a Mixed-Integer Nonlinear Program (MINLP) to handle the integer decisions of pit stops. 3. Implements a complementary Reinforcement Learning (RL) framework trained on the same scenario, providing a fast-inference solution suitable for real-time human decision support during races."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes two complementary frameworks to optimize Formula 1 race strategies by jointly managing energy, tire wear, and pit stops. It uses a Mixed-Integer Nonlinear Program for optimal offline planning and a Reinforcement Learning agent for fast, real-time inference. The RL agent achieves suboptimality of only about 5 seconds in a 1.5-hour race, demonstrating its potential for real-time strategic assistance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Towards Learning-Based Formula 1 Race Strategies<br/>\u57fa\u4e8e\u5b66\u4e60\u7684F1\u6bd4\u8d5b\u7b56\u7565"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Optimize F1 race strategy (energy, tires, pit stops)<br/>\u4f18\u5316F1\u6bd4\u8d5b\u7b56\u7565(\u80fd\u91cf\u3001\u8f6e\u80ce\u3001\u8fdb\u7ad9)"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Two complementary frameworks<br/>\u4e24\u4e2a\u4e92\u8865\u6846\u67b6"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br/>RL agent ~5s suboptimal in 1.5h race<br/>RL\u667a\u80fd\u4f53\u57281.5\u5c0f\u65f6\u6bd4\u8d5b\u4e2d\u8868\u73b0\u63a5\u8fd1\u6700\u4f18(\u7ea65\u79d2\u5dee\u8ddd)"]\n    Method --\x3e M1["MINLP for optimal solution<br/>\u6df7\u5408\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u6c42\u6700\u4f18\u89e3"]\n    Method --\x3e M2["Reinforcement Learning for fast inference<br/>\u5f3a\u5316\u5b66\u4e60\u7528\u4e8e\u5feb\u901f\u63a8\u7406"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xin Liu, Haoran Li, Dongbin Zhao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21586",children:"https://arxiv.org/pdf/2512.21586"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A[Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1["\u4ece\u89c6\u9891\u6a21\u4eff\u5b66\u4e60\u7684\u6311\u6218 / Challenges of Imitation Learning from Videos"]\n    C --\x3e C1["BCV-LR\u6846\u67b6 / BCV-LR Framework"]\n    C1 --\x3e C2["\u81ea\u76d1\u7763\u63d0\u53d6\u6f5c\u5728\u7279\u5f81 / Self-supervised Latent Feature Extraction"]\n    C1 --\x3e C3["\u57fa\u4e8e\u52a8\u6001\u7684\u6f5c\u5728\u52a8\u4f5c\u9884\u6d4b / Dynamics-based Latent Action Prediction"]\n    C1 --\x3e C4["\u5728\u7ebf\u5bf9\u9f50\u4e0e\u8fed\u4ee3\u7b56\u7565\u6539\u8fdb / Online Alignment & Iterative Policy Improvement"]\n    D --\x3e D1["\u9ad8\u6837\u672c\u6548\u7387 / High Sample Efficiency"]\n    D --\x3e D2["\u8d85\u8d8aSOTA\u65b9\u6cd5 / Outperforms SOTA Baselines"]\n    D --\x3e D3["\u9996\u6b21\u8bc1\u660e\u89c6\u9891\u53ef\u4f5c\u4e3a\u9ad8\u6548\u76d1\u7763 / First to Show Videos as Efficient Supervision"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Renmin University of China, The Chinese University of Hong Kong, Ant Group"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21625",children:"https://arxiv.org/pdf/2512.21625"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Rethinking Sample Polarity in RLVR] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[RLVR\u4e2d\u6b63\u8d1f\u6837\u672c\u7684\u89d2\u8272?/Roles of +/- samples in RLVR?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u5206\u6790\u6837\u672c\u6781\u6027/Analyze Sample Polarity]\n    Method --\x3e M2[\u63d0\u51faA3PO\u65b9\u6cd5/Propose A3PO Method]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6b63\u6837\u672c\u9510\u5316\u6a21\u5f0f/Positive samples sharpen patterns]\n    Results --\x3e R2[\u8d1f\u6837\u672c\u9f13\u52b1\u63a2\u7d22/Negative samples encourage exploration]\n    Results --\x3e R3[A3PO\u6709\u6548/A3PO is effective]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Maximilian Weichart"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Regensburg"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21648",children:"https://arxiv.org/pdf/2512.21648"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Max-We/inverse-rpo",children:"https://github.com/Max-We/inverse-rpo"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Variance-Aware Prior-Based Tree Policies for MCTS] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Extending prior-based UCTs from other UCBs is challenging]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]\n    D[\u5173\u952e\u7ed3\u679c/Results: New policies outperform PUCT without extra cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Kyung Hee University, Ghent University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21717",children:"https://arxiv.org/pdf/2512.21717"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National Taiwan Normal University, Wells Fargo Bank"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21819",children:"https://arxiv.org/pdf/2512.21819"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark's 7.09%, demonstrating its effectiveness in dynamic financial environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u65b9\u6cd5\u95ee\u9898/Traditional Methods' Issues]\n    B1 --\x3e B11[\u9ad8\u7ef4\u7279\u5f81\u4e0e\u8fc7\u62df\u5408/High-dimensional Features & Overfitting]\n    B1 --\x3e B12[\u9759\u6001\u805a\u7c7b\u65e0\u6cd5\u9002\u5e94\u5e02\u573a\u53d8\u5316/Static Clustering Fails to Adapt]\n    C --\x3e C1[\u91cf\u5b50\u589e\u5f3aA3C/Quantum-enhanced A3C]\n    C1 --\x3e C11[\u7b56\u7565\u7f51\u7edc\u5d4c\u5165VQC/Embed VQC in Policy Network]\n    C --\x3e C2[\u96c6\u6210\u65f6\u5e8f\u52a8\u6001\u805a\u7c7b/Integrate Time-series Dynamic Clustering]\n    D --\x3e D1[\u7d2f\u8ba1\u6536\u76ca17.09%/Cumulative Return 17.09%]\n    D --\x3e D2[\u8d85\u8d8a\u57fa\u51c67.09%/Outperforms Benchmark 7.09%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Mila \u2013 Quebec AI Institute, Universit\xe9 de Montr\xe9al, McGill University, LLNL, University of Edinburgh, CIFAR"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21852",children:"https://arxiv.org/pdf/2512.21852"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>\u8bba\u6587\u6807\u9898"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>KL\u6b63\u5219\u5316\u4f30\u8ba1\u5668\u914d\u7f6e\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u68af\u5ea6\u5b58\u5728\u504f\u5dee"] --\x3e P1["\u5b9e\u8df5\u95ee\u9898/Practical Issue<br>\u5e7f\u6cdb\u4f7f\u7528\u4f46\u5b9e\u73b0\u4e0e\u76ee\u6807\u4e0d\u4e00\u81f4"]\n    Problem --\x3e P2["\u7406\u8bba\u95ee\u9898/Theoretical Issue<br>\u68af\u5ea6\u504f\u5dee\u5f71\u54cd\u8bad\u7ec3\u7a33\u5b9a\u6027"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5206\u6790\u68af\u5ea6\u504f\u5dee\u5e76\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1"] --\x3e M1["\u5206\u6790/Analysis<br>\u7814\u7a76\u591a\u79cd\u4f30\u8ba1\u5668\u914d\u7f6e\u7684\u68af\u5ea6"]\n    Method --\x3e M2["\u5b9e\u9a8c/Experiments<br>RL\u5fae\u8c03\u591a\u4e2aLLM\u5e76\u8bc4\u4f30\u6027\u80fd"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u65e0\u504f\u68af\u5ea6\u914d\u7f6e\u5e26\u6765\u66f4\u597d\u6027\u80fd"] --\x3e R1["\u5728\u7ebf\u7b56\u7565/On-Policy<br>\u65e0\u504f\u68af\u5ea6\u914d\u7f6e\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u6027\u80fd"]\n    Results --\x3e R2["\u79bb\u7ebf\u7b56\u7565/Off-Policy<br>KL\u6b63\u5219\u5316\u6709\u52a9\u4e8e\u7a33\u5b9a\u5f02\u6b65\u8bad\u7ec3"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21919",children:"https://arxiv.org/pdf/2512.21919"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["SWE-RM: Execution-free Feedback For Software Engineering Agents"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u6267\u884c\u53cd\u9988\u7684\u5c40\u9650\u6027/Limitations of Execution-based Feedback"]\n    Problem --\x3e P2["\u65e0\u6267\u884c\u53cd\u9988\u672a\u88ab\u5145\u5206\u63a2\u7d22/Execution-free Feedback Underexplored"]\n    Method --\x3e M1["\u8bc6\u522bRL\u5173\u952e\u6307\u6807/Identify Key RL Metrics (Accuracy, Calibration)"]\n    Method --\x3e M2["\u53ef\u63a7\u5b9e\u9a8c\u5206\u6790/Controlled Experiments on Training Factors"]\n    Method --\x3e M3["\u63d0\u51faSWE-RM\u6a21\u578b/Propose SWE-RM (MoE Reward Model)"]\n    Results --\x3e R1["\u63d0\u5347TTS\u6027\u80fd/Improves TTS Performance (e.g., Qwen3-Coder-Max to 74.6%)"]\n    Results --\x3e R2["\u63d0\u5347RL\u6027\u80fd/Improves RL Performance (+3 points)"]\n    Results --\x3e R3["\u5f00\u6e90\u6a21\u578bSOTA/New SOTA Among Open-Source Models"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [forward-backward MDP, multi-objective reinforcement learning, orthogonal multipoint multicast, wireless caching, latency optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mohsen Amidzadeh"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Aalto University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21954",children:"https://arxiv.org/pdf/2512.21954"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel forward-backward Markov decision process (FB-MDP) model that captures both the forward dynamics of user preferences and the backward dynamics of latency in a cache-aided multicast network. 2. Proposes a forward-backward multi-objective reinforcement learning (FB-MORL) algorithm to optimize for expected latency, outage probability, and resource consumption simultaneously. 3. Demonstrates through simulation that the proposed FB-MORL algorithm can find a promising dynamic cache policy for latency-optimal streaming."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of optimizing streaming latency in a cellular network with cache-enabled base stations using multicast. The authors propose a novel forward-backward reinforcement learning framework that models the network's temporal dynamics as a multi-objective Markov decision process. Simulation results show their method is effective in finding a dynamic cache policy that reduces latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Optimizing latency in cache-aided cellular multicast networks"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Forward-Backward MDP modeling and FB-MORL algorithm"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Proposed algorithm finds promising dynamic cache policy"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Michail Kalntis, George Iosifidis, Jos\xe9 Su\xe1rez-Varela, Andra Lutu, Fernando A. Kuipers"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Delft University of Technology, Telef\xf3nica Research"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22022",children:"https://arxiv.org/pdf/2512.22022"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Meta-Learning-Based Handover Management in NextG O-RAN] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u5207\u6362\u5ef6\u8fdf\u4e0e\u5931\u8d25/Traditional HO delays & failures]\n    B --\x3e B2[\u5207\u6362\u7c7b\u578b\u95f4\u7684\u6743\u8861/Trade-offs between HO types]\n    C --\x3e C1[CONTRA\u6846\u67b6: \u8054\u5408\u4f18\u5316THO\u4e0eCHO/CONTRA: Jointly optimizes THOs & CHOs]\n    C --\x3e C2[\u5143\u5b66\u4e60\u7b97\u6cd5\u52a8\u6001\u9009\u62e9/Meta-learning for dynamic selection]\n    C --\x3e C3[O-RAN xApp\u90e8\u7f72/O-RAN xApp deployment]\n    D --\x3e D1[\u63d0\u5347\u7528\u6237\u541e\u5410\u91cf/Improves user throughput]\n    D --\x3e D2[\u964d\u4f4e\u5207\u6362\u6210\u672c/Reduces HO switching costs]\n    D --\x3e D3[\u4f18\u4e8e3GPP\u4e0eRL\u57fa\u7ebf/Outperforms 3GPP & RL baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 19'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&C), encryption weaknesses, radio-frequency (RF) links]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mark Ballard, Guanqun Song, Ting Zhu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Ohio State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21367",children:"https://arxiv.org/pdf/2512.21367"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Satellite Cybersecurity Across Orbital Altitudes] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[\u8f68\u9053\u9ad8\u5ea6\u5982\u4f55\u5f71\u54cd\u536b\u661f\u7f51\u7edc\u5b89\u5168/How orbital altitude dictates satellite cybersecurity]\nC --\x3e C1[\u5206\u679060\u8d77\u5b89\u5168\u4e8b\u4ef6\u4e0e\u6f0f\u6d1e\u4ee3\u7406/Analyze 60 security incidents & vulnerability proxies]\nD --\x3e D1[\u4e0d\u540c\u8f68\u9053\u6709\u72ec\u7279\u7684\u5a01\u80c1\u7279\u5f81/Distinct threat profiles per orbit]\nD --\x3e D2[\u5f31\u52a0\u5bc6\u548c\u6307\u4ee4\u5f02\u5e38\u662f\u4e3b\u8981\u9884\u6d4b\u56e0\u5b50/Weak encryption & command irregularities are key predictors]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Washington, University of California, Berkeley"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21446",children:"https://arxiv.org/pdf/2512.21446"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[MDLMs\u89e3\u7801\u6162\uff0c\u901f\u5ea6\u4f18\u52bf\u6709\u9650/MDLMs decode slowly, limiting speed advantage]\n    C --\x3e C1[\u57fa\u4e8eGRPO\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6/On-policy RL framework based on GRPO]\n    C --\x3e C2[\u8054\u5408\u4f18\u5316\u6269\u6563\u6a21\u578b\u4e0e\u89e3\u63a9\u7801\u89c4\u5212\u5668/Jointly optimize diffusion model & unmasking planner]\n    D --\x3e D1[\u63d0\u5347\u7cbe\u5ea6-\u6548\u7387\u6743\u8861/Improves accuracy-efficiency trade-off]\n    D --\x3e D2[\u8fc8\u5411"\u6269\u6563\u9738\u6743"/Moving towards "diffusion supremacy"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Harbin Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21452",children:"https://arxiv.org/pdf/2512.21452"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Intelligent recognition of GPR road hidden defect images <br/> GPR\u9053\u8def\u9690\u853d\u75c5\u5bb3\u56fe\u50cf\u667a\u80fd\u8bc6\u522b") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n\n    Problem --\x3e P1("Subjective & inefficient GPR interpretation <br/> GPR\u56fe\u50cf\u89e3\u91ca\u4e3b\u89c2\u4e14\u4f4e\u6548")\n    Problem --\x3e P2("Data scarcity <br/> \u6570\u636e\u7a00\u7f3a")\n\n    Method --\x3e M1("DCGAN-based Data Augmentation <br/> \u57fa\u4e8eDCGAN\u7684\u6570\u636e\u589e\u5f3a")\n    Method --\x3e M2("MCGA-Net (MCFF + GAM) <br/> MCGA-Net\u7f51\u7edc")\n    Method --\x3e M3("MS COCO Transfer Learning <br/> MS COCO\u8fc1\u79fb\u5b66\u4e60")\n\n    Results --\x3e R1("High Performance (Precision 92.8%, mAP@50 95.9%) <br/> \u9ad8\u6027\u80fd")\n    Results --\x3e R2("Robust to noise & weak signals <br/> \u5bf9\u566a\u58f0\u548c\u5f31\u4fe1\u53f7\u9c81\u68d2")\n    Results --\x3e R3("New paradigm for automated detection <br/> \u81ea\u52a8\u5316\u68c0\u6d4b\u65b0\u8303\u5f0f")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Technical University of Darmstadt"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21524",children:"https://arxiv.org/pdf/2512.21524"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a "digital twin". 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[GoldenFuzz: Generative Golden Reference Hardware Fuzzing] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u786c\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u5b58\u5728\u8bed\u4e49\u611f\u77e5\u6709\u9650\u3001\u6d4b\u8bd5\u4f4e\u6548\u3001\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u95ee\u9898/Hardware fuzzing suffers from limited semantic awareness, inefficiency, and high overhead]\n    C --\x3e C1[\u4f7f\u7528\u5feb\u901f\u9ec4\u91d1\u53c2\u8003\u6a21\u578b(GRM)\u4f5c\u4e3a\u6570\u5b57\u5b6a\u751f\u8fdb\u884c\u4e24\u9636\u6bb5\u6a21\u7cca\u6d4b\u8bd5/Two-stage fuzzing using a fast Golden Reference Model (GRM) as a digital twin]\n    C --\x3e C2[\u901a\u8fc7\u8fde\u63a5\u6307\u4ee4\u5757\u548c\u53cd\u9988\u673a\u5236\u6784\u5efa\u6d4b\u8bd5\u7528\u4f8b/Constructing test cases via instruction block concatenation and feedback]\n    D --\x3e D1[\u5728RISC-V\u5904\u7406\u5668\u4e0a\u5b9e\u73b0\u6700\u9ad8\u8986\u76d6\u7387\u548c\u6700\u5c0f\u5f00\u9500/Achieves highest coverage with minimal overhead on RISC-V processors]\n    D --\x3e D2[\u53d1\u73b0\u65b0\u7684\u9ad8\u5371\u6f0f\u6d1e/Uncovers new high-severity vulnerabilities]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinru Wen, Weizhong Lin, Xuan Xiao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," JCI (inferred from email domain ",(0,r.jsx)(n.code,{children:"jci.edu.cn"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21544",children:"https://arxiv.org/pdf/2512.21544"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[AVP-Fusion: \u6297\u75c5\u6bd2\u80bd\u8bc6\u522b / Antiviral Peptide Identification] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898 / Problem] --\x3e P1[\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u590d\u6742\u5e8f\u5217\u4f9d\u8d56 / Current methods struggle with sequence dependencies]\n    Problem --\x3e P2[\u96be\u4ee5\u5904\u7406\u6a21\u7cca\u6837\u672c / Hard to handle ambiguous samples]\n    Method[\u4e3b\u8981\u65b9\u6cd5 / Method] --\x3e M1[\u6784\u5efa\u5168\u666f\u7279\u5f81\u7a7a\u95f4 / Construct panoramic feature space]\n    Method --\x3e M2[\u81ea\u9002\u5e94\u95e8\u63a7\u673a\u5236\u878d\u5408\u7279\u5f81 / Adaptive Gating Mechanism for feature fusion]\n    Method --\x3e M3[\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u6570\u636e\u589e\u5f3a / Contrastive learning & data augmentation]\n    Results[\u5173\u952e\u7ed3\u679c / Results] --\x3e R1[\u51c6\u786e\u73870.9531, MCC 0.9064 / Accuracy 0.9531, MCC 0.9064]\n    Results --\x3e R2[\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5 / Outperforms SOTA]\n    Results --\x3e R3[\u5b9e\u73b0\u75c5\u6bd2\u5bb6\u65cf\u4e9a\u7c7b\u9884\u6d4b / Enables viral family subclass prediction]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," New York University, University of California, Riverside"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21563",children:"https://arxiv.org/pdf/2512.21563"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework's capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework's applicability to various data distributions and algorithms beyond ISTA/FISTA."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Discovering Sparse Recovery Algorithms Using Neural Architecture Search] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Automated discovery of sparse optimization algorithms is difficult and heuristic-driven]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Meta-learning framework using Neural Architecture Search (NAS) for algorithm rediscovery]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Rediscovered ISTA/FISTA elements; framework applies to various data and algorithms]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Maximilian Weichart"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Regensburg"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21648",children:"https://arxiv.org/pdf/2512.21648"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Max-We/inverse-rpo",children:"https://github.com/Max-We/inverse-rpo"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Variance-Aware Prior-Based Tree Policies for MCTS] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Extending prior-based UCTs from other UCBs is challenging]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]\n    D[\u5173\u952e\u7ed3\u679c/Results: New policies outperform PUCT without extra cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Huiyun Peng, Antonio Zhong, Ricardo Andr\xe9s Calvo M\xe9ndez, Kelechi G. Kalu, James C. Davis"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Purdue University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21757",children:"https://arxiv.org/pdf/2512.21757"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[How Do Agents Perform Code Optimization? An Empirical Study] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&R model]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21766",children:"https://arxiv.org/pdf/2512.21766"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&Resource (A/R/A&R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[UniLabOS: An AI-Native Operating System for Autonomous Laboratories] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8f6f\u4ef6\u788e\u7247\u5316\u963b\u788d\u81ea\u4e3b\u5b9e\u9a8c\u5ba4\u91c7\u7528/Fragmented software hinders adoption of autonomous labs]\n    C --\x3e C1[AI\u539f\u751f\u64cd\u4f5c\u7cfb\u7edf/AI-native operating system]\n    C1 --\x3e C2[\u7edf\u4e00\u6a21\u578b: A/R/A&R/Unified A/R/A&R model]\n    C1 --\x3e C3[\u53cc\u91cd\u62d3\u6251\u7ed3\u6784/Dual-topology representation]\n    C1 --\x3e C4[\u4e8b\u52a1\u6027CRUTD\u534f\u8bae/Transactional CRUTD protocol]\n    C1 --\x3e C5[\u5206\u5e03\u5f0f\u8fb9\u4e91\u67b6\u6784/Distributed edge-cloud architecture]\n    D --\x3e D1[\u56db\u4e2a\u771f\u5b9e\u573a\u666f\u9a8c\u8bc1/Four real-world demonstrations]\n    D --\x3e D2[\u5f02\u6784\u4eea\u5668\u7a33\u5065\u7f16\u6392/Robust orchestration across heterogeneous instruments]\n    D --\x3e D3[\u4e3a\u53ef\u590d\u73b0\u3001\u53ef\u6eaf\u6e90\u7684\u5b9e\u9a8c\u5960\u5b9a\u57fa\u7840/Foundation for reproducible, provenance-aware experimentation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Evgeny Alves Limarenko, Anastasiia Studenikina"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Moscow Institute of Physics and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21769",children:"https://arxiv.org/pdf/2512.21769"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("BertsWin: 3D MAE\u4f18\u5316") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("3D MAE\u62d3\u6251\u7a00\u758f\u6027/Topological Sparsity in 3D MAE")\n    Problem --\x3e P2("\u7834\u574f\u7a7a\u95f4\u5173\u7cfb/Destroys Spatial Context")\n    Method --\x3e M1("BertsWin\u6df7\u5408\u67b6\u6784/BertsWin Hybrid Architecture")\n    Method --\x3e M2("\u5b8c\u65743D\u4ee4\u724c\u7f51\u683c/Full 3D Token Grid")\n    Method --\x3e M3("Swin\u7a97\u53e3 & \u7ed3\u6784\u635f\u5931/Swin Windows & Structural Loss")\n    Results --\x3e R1("5.8x\u8bed\u4e49\u6536\u655b\u52a0\u901f/5.8x Faster Convergence")\n    Results --\x3e R2("15\u500d\u8bad\u7ec3\u8f6e\u6b21\u51cf\u5c11/15x Fewer Epochs")\n    Results --\x3e R3("FLOPs\u6301\u5e73\uff0c\u603b\u8d44\u6e90\u51cf\u5c11/FLOP Parity, Net Resource Reduction")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [speculative decoding, draft tree, inference acceleration, autoregressive image generation, dynamic tree structure]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Southeast University, Institute of Automation Chinese Academy of Sciences, Singapore Management University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21857",children:"https://arxiv.org/pdf/2512.21857"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Haodong-Lei-Ray/ADT-Tree",children:"https://github.com/Haodong-Lei-Ray/ADT-Tree"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identified the key obstacle of applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to spatially varying token prediction difficulty. 2. Proposed ADT-Tree, an adjacency-adaptive dynamic draft tree that dynamically adjusts tree depth and width based on adjacent token states and prior acceptance rates. 3. Demonstrated significant speedups (over 3x) on benchmarks and seamless integration with relaxed sampling methods for further acceleration."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the slow inference of visual autoregressive models by proposing ADT-Tree, a dynamic draft tree method that adapts its structure to image region complexity. It achieves over 3x speedup on standard benchmarks and can be combined with other sampling techniques for additional gains."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Fast Inference of Visual AR Model with ADT-Tree<br>\u89c6\u89c9\u81ea\u56de\u5f52\u6a21\u578b\u5feb\u901f\u63a8\u7406\u4e0eADT-Tree"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Visual AR models have slow sequential inference.<br>\u89c6\u89c9AR\u6a21\u578b\u63a8\u7406\u6162"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Propose Adjacency-Adaptive Dynamical Draft Trees (ADT-Tree).<br>\u63d0\u51fa\u90bb\u63a5\u81ea\u9002\u5e94\u52a8\u6001\u8349\u7a3f\u6811"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Achieves 3.13x/3.05x speedup on benchmarks.<br>\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b03.13x/3.05x\u52a0\u901f"]\n    Problem --\x3e P1["Spatially varying token prediction difficulty.<br>\u7a7a\u95f4\u53d8\u5316\u7684token\u9884\u6d4b\u96be\u5ea6"]\n    Method --\x3e M1["Dynamically adjusts tree depth & width.<br>\u52a8\u6001\u8c03\u6574\u6811\u6df1\u5ea6\u4e0e\u5bbd\u5ea6"]\n    Method --\x3e M2["Leverages adjacency & prior acceptance rates.<br>\u5229\u7528\u90bb\u63a5\u5173\u7cfb\u548c\u5148\u9a8c\u63a5\u53d7\u7387"]\n    Results --\x3e R1["Integrates with relaxed sampling.<br>\u53ef\u4e0e\u677e\u5f1b\u91c7\u6837\u65b9\u6cd5\u7ed3\u5408"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Soochow University, Meituan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21911",children:"https://arxiv.org/pdf/2512.21911"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Accelerate Speculative Decoding with Sparse Computation in Verification] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u9a8c\u8bc1\u9636\u6bb5\u6210\u4e3a\u74f6\u9888/Verification stage is bottleneck]\n    B1 --\x3e B2[\u957f\u4e0a\u4e0b\u6587\u4e0eMoE\u6a21\u578b/Long-context & MoE models]\n    C --\x3e C1[\u7a00\u758f\u9a8c\u8bc1\u6846\u67b6/Sparse Verification Framework]\n    C1 --\x3e C2[\u8054\u5408\u7a00\u758f\u5316\u6ce8\u610f\u529b\u3001FFN\u3001MoE/Jointly sparsifies Attention, FFN, MoE]\n    C1 --\x3e C3[\u68c0\u7d22\u91cd\u7528\u7b56\u7565/Retrieval Reuse Strategy]\n    D --\x3e D1[\u6709\u5229\u7684\u6548\u7387-\u7cbe\u5ea6\u6743\u8861/Favorable efficiency-accuracy trade-off]\n    D --\x3e D2[\u7a33\u5b9a\u7684\u63a5\u53d7\u957f\u5ea6/Stable acceptance length]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Southern University of Science and Technology, Microsoft Research"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21925",children:"https://arxiv.org/pdf/2512.21925"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm's consistent advantage over purely online or offline baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Hybrid CMAB-T<br>\u6df7\u5408\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u5728\u7ebf\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u9002\u5e94\u6162<br>Online: High Cost, Slow")\n    Problem --\x3e P2("\u79bb\u7ebf\u65b9\u6cd5\u53d7\u6570\u636e\u8d28\u91cf\u9650\u5236<br>Offline: Data Quality Limits")\n    Method --\x3e M1("\u63d0\u51fa\u6df7\u5408CMAB-T\u6846\u67b6<br>Propose Hybrid CMAB-T Framework")\n    Method --\x3e M2("\u8bbe\u8ba1\u6df7\u5408CUCB\u7b97\u6cd5<br>Design Hybrid CUCB Algorithm")\n    M2 --\x3e M2a("\u5229\u7528\u79bb\u7ebf\u6570\u636e\u5f15\u5bfc\u63a2\u7d22<br>Use Offline Data to Guide")\n    M2 --\x3e M2b("\u7ed3\u5408\u5728\u7ebf\u4ea4\u4e92\u7ea0\u6b63\u504f\u5dee<br>Use Online to Correct Bias")\n    Results --\x3e R1("\u7406\u8bba\u6094\u6068\u754c\u4fdd\u8bc1<br>Theoretical Regret Guarantee")\n    Results --\x3e R2("\u5b9e\u9a8c\u663e\u793a\u4e00\u81f4\u4f18\u52bf<br>Empirical Consistent Advantage")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21970",children:"https://arxiv.org/pdf/2512.21970"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://shengliangd.github.io/StereoVLA-Webpage",children:"https://shengliangd.github.io/StereoVLA-Webpage"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1(\u5355\u76eeVLA\u6a21\u578b\u7f3a\u4e4f\u7cbe\u786e\u7684\u51e0\u4f55\u611f\u77e5/Single-view VLAs lack accurate geometry perception)\n    C --\x3e C1(\u63d0\u51faStereoVLA\u6a21\u578b/Propose StereoVLA model)\n    C1 --\x3e C2(\u51e0\u4f55-\u8bed\u4e49\u7279\u5f81\u63d0\u53d6\u6a21\u5757/Geometric-Semantic Feature Extraction)\n    C2 --\x3e C3(\u4ece\u7acb\u4f53\u89c6\u56fe\u63d0\u53d6\u51e0\u4f55\u7279\u5f81/Extract geometric features from stereo views)\n    C2 --\x3e C4(\u4ece\u5355\u76ee\u89c6\u56fe\u63d0\u53d6\u8bed\u4e49\u7279\u5f81/Extract semantic features from monocular view)\n    C1 --\x3e C5(\u8f85\u52a9\u4ea4\u4e92\u533a\u57df\u6df1\u5ea6\u4f30\u8ba1\u4efb\u52a1/Auxiliary Interaction-Region Depth Estimation task)\n    D --\x3e D1(\u5728\u7acb\u4f53\u8bbe\u7f6e\u4e0b\u5927\u5e45\u8d85\u8d8a\u57fa\u7ebf/Large margin outperforms baselines under stereo setting)\n    D --\x3e D2(\u5bf9\u76f8\u673a\u4f4d\u59ff\u53d8\u5316\u5177\u6709\u5f3a\u9c81\u68d2\u6027/Strong robustness to camera pose variations)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National School of Artificial Intelligence (ENSIA)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22007",children:"https://arxiv.org/pdf/2512.22007"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[DuaDeep-SeqAffinity: \u5e8f\u5217\u6297\u539f-\u6297\u4f53\u4eb2\u548c\u529b\u9884\u6d4b / Sequence-Only Antigen-Antibody Affinity Prediction] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7a00\u7f3a\u76843D\u7ed3\u6784 / Traditional methods rely on scarce 3D structures]\n    C --\x3e C1[\u53cc\u6d41\u6df7\u5408\u67b6\u6784 / Dual-Stream Hybrid Architecture]\n    C1 --\x3e C2[\u4f7f\u7528ESM-2\u5d4c\u5165 / Uses ESM-2 Embeddings]\n    C1 --\x3e C3[1D CNN\u68c0\u6d4b\u5c40\u90e8\u6a21\u5f0f / 1D CNN for Local Motifs]\n    C1 --\x3e C4[Transformer\u7f16\u7801\u5168\u5c40\u4e0a\u4e0b\u6587 / Transformer for Global Context]\n    C1 --\x3e C5[\u878d\u5408\u6a21\u5757\u6574\u5408\u7279\u5f81 / Fusion Module Integrates Features]\n    D --\x3e D1[\u6027\u80fd\u8d85\u8d8aSOTA / Outperforms SOTA]\n    D --\x3e D2[\u76ae\u5c14\u900a\u76f8\u5173: 0.688 / Pearson: 0.688]\n    D --\x3e D3[AUC: 0.890]\n    D --\x3e D4[\u8bc1\u660e\u5e8f\u5217\u5d4c\u5165\u7684\u6709\u6548\u6027 / Proves Efficacy of Sequence Embeddings]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22065",children:"https://arxiv.org/pdf/2512.22065"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://streamavatar.github.io",children:"https://streamavatar.github.io"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Uppsala University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22066",children:"https://arxiv.org/pdf/2512.22066"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>LLM\u63a8\u7406\u80fd\u8017\u9ad8\uff0cPrefill\u4e0eDecode\u9636\u6bb5\u74f6\u9888\u4e0d\u540c"] --\x3e Problem_Sub1["SRAM\u5927\u5c0f\u4e0e\u9891\u7387\u5982\u4f55\u5f71\u54cd\u80fd\u6548\uff1f"]\n    Problem --\x3e Problem_Sub2["\u5185\u5b58\u5e26\u5bbd\u5982\u4f55\u9650\u5236\u6027\u80fd\uff1f"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u7ed3\u5408OpenRAM, LLMCompass, ScaleSIM\u7684\u6a21\u62df\u65b9\u6cd5"] --\x3e Method_Sub1["\u80fd\u8017\u5efa\u6a21/Energy Modeling"]\n    Method --\x3e Method_Sub2["\u5ef6\u8fdf\u6a21\u62df/Latency Simulation"]\n    Method --\x3e Method_Sub3["\u64cd\u4f5c\u5f3a\u5ea6\u5206\u6790/Operational Intensity"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e Results_Sub1["\u603b\u80fd\u8017\u4e3b\u8981\u7531SRAM\u5927\u5c0f\u51b3\u5b9a<br>\u5927\u7f13\u5b58\u589e\u52a0\u9759\u6001\u80fd\u8017"]\n    Results --\x3e Results_Sub2["\u9ad8\u9891\u53ef\u964d\u4f4e\u603b\u80fd\u8017<br>\uff08\u51cf\u5c11\u9759\u6001\u80fd\u8017\uff09"]\n    Results --\x3e Results_Sub3["\u6700\u4f18\u914d\u7f6e\uff1a\u9ad8\u9891(1200-1400MHz) + \u5c0f\u7f13\u5b58(32-64KB)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Yume-1.5: A Text-Controlled Interactive World Generation Model"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [interactive world generation, long-video generation, attention distillation, context compression, text-controlled generation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai AI Laboratory, Fudan University, Shanghai Innovation Institute"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22096",children:"https://arxiv.org/pdf/2512.22096"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/stdstu12/YUME",children:"https://github.com/stdstu12/YUME"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A long-video generation framework integrating unified context compression with linear attention. 2. A real-time streaming acceleration strategy using bidirectional attention distillation and an enhanced text embedding scheme. 3. A text-controlled method for generating world events."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Yume-1.5, a framework to address challenges in generating interactive, explorable worlds using diffusion models, such as large model size and slow inference. The method introduces a novel architecture combining context compression, attention distillation, and text-based event control to enable real-time, keyboard-controlled world generation from text or images. The work concludes with a public codebase demonstrating the feasibility of text-controlled interactive world creation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Yume-1.5: A Text-Controlled Interactive World Generation Model] --\x3e Problem(\u6838\u5fc3\u95ee\u9898/Problem)\n    Root --\x3e Method(\u4e3b\u8981\u65b9\u6cd5/Method)\n    Root --\x3e Results(\u5173\u952e\u7ed3\u679c/Results)\n    Problem --\x3e P1[\u5927\u6a21\u578b\u53c2\u6570\u4e0e\u6162\u63a8\u7406/Large Model & Slow Inference]\n    Problem --\x3e P2[\u7f3a\u4e4f\u6587\u672c\u63a7\u5236/Lack of Text Control]\n    Method --\x3e M1[\u957f\u89c6\u9891\u751f\u6210\u6846\u67b6/Long-Video Gen Framework]\n    Method --\x3e M2[\u5b9e\u65f6\u6d41\u52a0\u901f\u7b56\u7565/Real-time Streaming]\n    Method --\x3e M3[\u6587\u672c\u63a7\u5236\u4e8b\u4ef6\u751f\u6210/Text-Controlled Events]\n    M1 --\x3e M1_Sub[\u7edf\u4e00\u4e0a\u4e0b\u6587\u538b\u7f29\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b/Unified Context Compression & Linear Attention]\n    M2 --\x3e M2_Sub[\u53cc\u5411\u6ce8\u610f\u529b\u84b8\u998f\u4e0e\u6587\u672c\u5d4c\u5165/Bidirectional Attention Distillation & Text Embedding]\n    Results --\x3e R1[\u751f\u6210\u4ea4\u4e92\u5f0f\u4e16\u754c/Generates Interactive Worlds]\n    Results --\x3e R2[\u652f\u6301\u952e\u76d8\u63a2\u7d22/Supports Keyboard Exploration]\n    Results --\x3e R3[\u516c\u5f00\u4ee3\u7801\u5e93/Public Codebase]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Imperial College London, Fudan University, Xiamen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21652",children:"https://arxiv.org/pdf/2512.21652"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Enabling Ultra-Fast Cardiovascular Imaging...] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[CMR\u626b\u63cf\u65f6\u95f4\u957f/CMR Scan Time Long]\nB --\x3e B2[\u4e34\u5e8a\u73af\u5883\u5f02\u8d28\u6027\u9ad8/High Clinical Heterogeneity]\nC --\x3e C1[\u6784\u5efa\u591a\u6a21\u6001\u6570\u636e\u5e93MMCMR-427K/Build Multimodal DB MMCMR-427K]\nC --\x3e C2[\u63d0\u51fa\u901a\u7528\u57fa\u7840\u6a21\u578bCardioMM/Propose Generalist Foundation Model CardioMM]\nD --\x3e D1[\u5b9e\u73b024\u500d\u52a0\u901f\u6210\u50cf/Achieve 24x Accelerated Imaging]\nD --\x3e D2[\u96f6\u6837\u672c\u6cdb\u5316\u81f3\u65b0\u73af\u5883/Zero-shot Generalization to New Settings]\nD --\x3e D3[\u4fdd\u6301\u8bca\u65ad\u8d28\u91cf/Preserve Diagnostic Quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"cs.DC total: 42"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [GPU Virtualization, Benchmarking, Multi-tenancy, CUDA, Performance Isolation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jithin VG, Ditto PS"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Bud Ecosystem Inc"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22125",children:"https://arxiv.org/pdf/2512.22125"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/BudEcosystem/GPU-Virt-Bench",children:"https://github.com/BudEcosystem/GPU-Virt-Bench"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed GPU-Virt-Bench, a comprehensive benchmarking framework with 56 metrics across 10 categories for evaluating software-based GPU virtualization systems. 2. Enabled systematic comparison between software virtualization approaches (e.g., HAMi-core, BUD-FCSP) and ideal hardware-based MIG behavior. 3. Demonstrated the framework's utility by revealing critical performance characteristics for production deployment decisions in multi-tenant environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of standardized evaluation for software-based GPU virtualization systems, which are needed for efficient GPU sharing in AI/LLM workloads. The authors propose GPU-Virt-Bench, a comprehensive benchmarking framework that measures performance across multiple critical dimensions. The framework provides actionable insights for practitioners by comparing software solutions against hardware-based baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[GPU-Virt-Bench: A Comprehensive Benchmarking Framework] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[GPU\u8d44\u6e90\u5171\u4eab\u9700\u6c42\u9ad8\uff0c\u4f46\u8f6f\u4ef6\u865a\u62df\u5316\u65b9\u6848\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30/High demand for GPU sharing, but software virtualization lacks standardized evaluation]\n    C --\x3e C1[\u63d0\u51fa\u5305\u542b56\u4e2a\u6307\u6807\u300110\u4e2a\u7c7b\u522b\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6/Propose a comprehensive benchmarking framework with 56 metrics across 10 categories]\n    D --\x3e D1[\u7cfb\u7edf\u6bd4\u8f83\u8f6f\u4ef6\u65b9\u6848\u4e0eMIG\uff0c\u4e3a\u751f\u4ea7\u90e8\u7f72\u63d0\u4f9b\u5173\u952e\u6027\u80fd\u6d1e\u5bdf/Systematic comparison between software approaches and MIG provides key performance insights for deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Shanghai Innovation Institute"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22135",children:"https://arxiv.org/pdf/2512.22135"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u9501\u5b9a/Data Lock-in]\n    B --\x3e B2[\u8ba4\u77e5\u8fc7\u8f7d/Cognitive Overload]\n    C --\x3e C1[\u4e3b\u6743\u6570\u5b57\u5316\u8eab/Sovereign Digital Avatar (SoDA)]\n    C --\x3e C2[\u6b63\u4ea4\u89e3\u8026\u8bbe\u8ba1/Orthogonal Decoupling Design]\n    C --\x3e C3[\u610f\u56fe-\u6743\u9650\u63e1\u624b\u673a\u5236/Intent-Permission Handshake Mechanism]\n    D --\x3e D1[\u964d\u4f4e\u4ee4\u724c\u6d88\u8017/Reduces Token Consumption by 27-35%]\n    D --\x3e D2[\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8f7d/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SlimEdge: Lightweight Distributed DNN Deployment on Constrained Hardware"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [Structured Pruning, Multi-Objective Optimization, Edge Inference, MVCNN, View-Adaptive Compression]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mahadev Sunil Kumar, Arnab Raha, Debayan Das, Gopakumar G, Amitava Mukherjee"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Accenture PLC, Intel Corporation, Indian Institute of Science, Amrita Vishwa Vidyapeetham, Birla Institute of Technology and Science"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22136",children:"https://arxiv.org/pdf/2512.22136"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a framework for lightweight DNN deployment that integrates structured pruning with multi-objective optimization to meet heterogeneous hardware constraints. 2. Demonstrates the framework on MVCNN by quantifying the contribution of individual views to accuracy for view-adaptive pruning budget allocation. 3. Shows experimentally that the compressed models meet user-specified accuracy and memory bounds while achieving 1.2x to 5.0x inference speedup across diverse hardware."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7687c3e58bfa2b22573745dffb608fb7c36a0c339dd9216829f78a284f51e662_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7687c3e58bfa2b22573745dffb608fb7c36a0c339dd9216829f78a284f51e662_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of deploying large DNNs on resource-constrained edge devices. It proposes SlimEdge, a method that combines structured pruning and multi-objective optimization to compress models like MVCNN while preserving task performance. The results show that this approach successfully meets specified accuracy and memory constraints while significantly reducing inference latency on various edge hardware platforms."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SlimEdge: Lightweight Distributed DNN Deployment] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: DNN\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a/DNN deployment on resource-constrained edge devices)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u7ed3\u6784\u5316\u526a\u679d\u4e0e\u591a\u76ee\u6807\u4f18\u5316/Structured Pruning & Multi-Objective Optimization)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u6ee1\u8db3\u7cbe\u5ea6\u4e0e\u5185\u5b58\u7ea6\u675f\uff0c\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e1.2x-5.0x/Meets accuracy & memory bounds, 1.2x-5.0x latency reduction)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [edge-cloud collaboration, task decomposition, adaptive routing, parallel execution, token-efficient inference]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jiangwen Dong, Jiayu Li, Wanyu Lin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22137",children:"https://arxiv.org/pdf/2512.22137"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HybridFlow, a resource-adaptive inference framework for collaborative reasoning between edge and cloud LLMs. 2. Introduces a two-stage method involving dynamic task decomposition for parallel execution and a learned router for resource-aware subtask assignment. 3. Demonstrates effectiveness in reducing end-to-end inference time and token usage while maintaining accuracy on multiple reasoning benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a14e12f757065eef8f857ead7c55331977412b8a4d1ba64499c5c1457d797284_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a14e12f757065eef8f857ead7c55331977412b8a4d1ba64499c5c1457d797284_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of high latency and token cost for LLM inference on edge devices by proposing HybridFlow, a framework that dynamically decomposes queries into parallel subtasks and adaptively routes them between edge and cloud models. The method reduces inference time and token consumption while preserving competitive accuracy, as validated on several reasoning benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("LLM\u63a8\u7406\u5ef6\u8fdf\u9ad8\uff0cToken\u6d88\u8017\u5927/High LLM inference latency & token cost")\n    Problem --\x3e P2("\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u53d7\u9650/Resource-limited edge devices")\n    Problem --\x3e P3("\u73b0\u6709\u534f\u4f5c\u65b9\u6cd5\u7c97\u7c92\u5ea6\uff0c\u6548\u7387\u4f4e/Existing coarse-grained collaboration is inefficient")\n    Method --\x3e M1("\u4efb\u52a1\u5206\u89e3\u4e0e\u5e76\u884c\u6267\u884c/Task Decomposition & Parallel Execution")\n    Method --\x3e M2("\u8d44\u6e90\u611f\u77e5\u5b50\u4efb\u52a1\u8def\u7531/Resource-Aware Subtask Routing")\n    Results --\x3e R1("\u51cf\u5c11\u7aef\u5230\u7aef\u63a8\u7406\u65f6\u95f4/Reduces end-to-end inference time")\n    Results --\x3e R2("\u964d\u4f4e\u603b\u4f53Token\u4f7f\u7528/Lowers overall token usage")\n    Results --\x3e R3("\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387/Maintains competitive accuracy")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [FPGA, HLS, Point Cloud, Model Compression, Fixed-Point]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National University of Sciences and Technology (Pakistan), RPTU Kaiserslautern-Landau (Germany)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22139",children:"https://arxiv.org/pdf/2512.22139"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/dll-ncai/HLS4PC",children:"https://github.com/dll-ncai/HLS4PC"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed HLS4PC, a parameterizable HLS framework for accelerating point-based 3D point cloud models on FPGA. 2. Introduced PointMLP-Lite, a 4x less complex model variant created via hardware-aware compression techniques (URS, quantization, pruning, fusion). 3. Demonstrated FPGA acceleration achieving 3.56x higher throughput than prior work and outperforming GPU/CPU implementations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of real-time 3D point cloud processing by proposing HLS4PC, a parameterizable FPGA acceleration framework. The method combines algorithmic optimizations and hardware-aware model compression to create an efficient fixed-point implementation, which significantly outperforms previous accelerators and GPU/CPU baselines in throughput."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[GPU under-utilization due to sparse, unstructured point cloud data]\n    P1 --\x3e P2[High memory/computation demand hinders real-time performance]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Parameterizable HLS framework for FPGA]\n    M1 --\x3e M2[Hardware-aware compression: URS, quantization, pruning, fusion]\n    M2 --\x3e M3[Creates PointMLP-Lite model]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[PointMLP-Lite: 4x less complex, ~2% accuracy drop]\n    R1 --\x3e R2[3.56x higher throughput vs. prior work]\n    R2 --\x3e R3[2.3x (GPU) and 22x (CPU) higher throughput]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] On Harnessing Idle Compute at the Edge for Foundation Model Training"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [edge computing, tensor parallelism, parameter server, device heterogeneity, fault-tolerance]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Leyang Xue, Meghana Madhyastha, Myungjin Lee, Amos Storkey, Randal Burns, Mahesh K. Marina"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The University of Edinburgh, Johns Hopkins University, Cisco Research"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22142",children:"https://arxiv.org/pdf/2512.22142"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel selective hybrid tensor parallelism method to finely partition training operations for edge devices. 2. A parameter server-centric training framework to cope with device memory limits and avoid communication bottlenecks. 3. A cost optimization model to guide device selection and workload distribution, effectively handling device heterogeneity and churn."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of decentralized foundation model training on edge devices, which is hindered by memory limits, communication overhead, and device heterogeneity. It proposes Cleave, a new paradigm that uses selective hybrid tensor parallelism and a parameter server framework to partition training efficiently. The evaluation shows Cleave matches cloud-based training performance, scales to thousands of devices, and handles failures with much faster recovery than prior methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[On Harnessing Idle Compute at the Edge for Foundation Model Training] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[\u73b0\u6709\u8fb9\u7f18\u8bad\u7ec3\u65b9\u6cd5\u6027\u80fd\u4e0d\u8db3/Existing edge training falls short]\nB --\x3e B2[\u8bbe\u5907\u5185\u5b58\u4e0e\u901a\u4fe1\u74f6\u9888/Device memory & communication bottlenecks]\nB --\x3e B3[\u8bbe\u5907\u5f02\u6784\u6027\u4e0e\u52a8\u6001\u6027/Device heterogeneity & dynamism]\nC --\x3e C1[\u9009\u62e9\u6027\u6df7\u5408\u5f20\u91cf\u5e76\u884c/Selective hybrid tensor parallelism]\nC --\x3e C2[\u53c2\u6570\u670d\u52a1\u5668\u6846\u67b6/Parameter server framework]\nC --\x3e C3[\u6210\u672c\u4f18\u5316\u6a21\u578b/Cost optimization model]\nD --\x3e D1[\u5339\u914d\u4e91\u7aef\u8bad\u7ec3\u6027\u80fd/Matches cloud-based training]\nD --\x3e D2[\u6269\u5c55\u81f3\u6570\u5343\u8bbe\u5907/Scales to thousands of devices]\nD --\x3e D3[\u5feb\u901f\u6545\u969c\u6062\u590d/Fast failure recovery]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [gpu kernels], [Minimal Executable Program (MEP), Automatic Error Repair, Performance Pattern Inheritance, iterative optimization, cross-platform]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ruifan Chu, Anbang Wang, Xiuxiu Bai, Shuai Liu, Xiaoshe Dong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," School of Software Engineering, Xi\u2019an Jiaotong University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22147",children:"https://arxiv.org/pdf/2512.22147"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an end-to-end LLM framework that optimizes GPU kernels by constructing Minimal Executable Programs (MEPs) to avoid expensive full application builds and executions. 2. Introduces Automatic Error Repair and Performance Pattern Inheritance to automatically fix faults and reuse effective optimization strategies, reducing search cost. 3. Demonstrates cross-platform portability and effectiveness on NVIDIA GPUs and the Haiguang DCU platform, achieving significant speedups over direct LLM optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high cost of full builds for GPU kernel optimization in large HPC applications by proposing an LLM framework that uses Minimal Executable Programs (MEPs) for iterative optimization. The method integrates automatic error repair and performance pattern inheritance to maintain correctness and reuse strategies. It achieves substantial speedups across different hardware platforms without requiring full-source dependencies."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Full builds & runs are expensive in large applications/\u5927\u578b\u5e94\u7528\u4e2d\u5b8c\u6574\u6784\u5efa\u4e0e\u8fd0\u884c\u6210\u672c\u9ad8]\n    C --\x3e C1[Construct Minimal Executable Program (MEP) for kernel/\u4e3a\u5185\u6838\u6784\u5efa\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f]\n    C --\x3e C2[Multi-round iterative optimization with LLM feedback/\u57fa\u4e8eLLM\u53cd\u9988\u7684\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316]\n    C --\x3e C3[Integrate Automatic Error Repair & Performance Pattern Inheritance/\u96c6\u6210\u81ea\u52a8\u9519\u8bef\u4fee\u590d\u4e0e\u6027\u80fd\u6a21\u5f0f\u7ee7\u627f]\n    D --\x3e D1[Achieves significant speedups (e.g., 5.05x, 7.77x)/\u83b7\u5f97\u663e\u8457\u52a0\u901f\u6bd4]\n    D --\x3e D2[Cross-platform portability (NVIDIA, DCU)/\u8de8\u5e73\u53f0\u53ef\u79fb\u690d\u6027]\n    D --\x3e D3[Surpasses direct LLM optimization/\u8d85\u8d8a\u76f4\u63a5LLM\u4f18\u5316]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [serverless computing, GPU resource allocation, workload scheduling, multi-agent systems, collaborative reasoning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Guilin Zhang, Wulan Guo, Ziqi Tan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," George Washington University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22149",children:"https://arxiv.org/pdf/2512.22149"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An adaptive GPU resource allocation framework for multi-agent systems in serverless environments that dynamically adjusts resources based on workload characteristics, agent priorities, and minimum requirements. 2. An O(N) complexity algorithm for real-time adaptation, enabling millisecond-scale reallocation to handle dynamic workload fluctuations. 3. A comprehensive evaluation demonstrating the framework's superiority over static and round-robin strategies, achieving 85% latency reduction while maintaining throughput and improving GPU utilization and cost-efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an adaptive GPU resource allocation framework to address the challenge of efficiently deploying heterogeneous multi-agent AI systems on serverless platforms. The method dynamically allocates resources using a real-time algorithm to handle varying computational demands and workload fluctuations. The results show it significantly reduces latency compared to baseline schedulers while maintaining throughput, offering a cost-effective solution for serverless multi-agent deployment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments<br/>\u9762\u5411\u65e0\u670d\u52a1\u5668\u73af\u5883\u7684\u591a\u667a\u80fd\u4f53\u534f\u540c\u63a8\u7406\u7684\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Heterogeneous agent workloads & dynamic demands on serverless GPU platforms<br/>\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u5f02\u6784\u4e0e\u65e0\u670d\u52a1\u5668GPU\u5e73\u53f0\u52a8\u6001\u9700\u6c42"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Adaptive GPU resource allocation framework with O(N) real-time algorithm<br/>\u57fa\u4e8eO(N)\u5b9e\u65f6\u7b97\u6cd5\u7684\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d\u6846\u67b6"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br/>85% latency reduction vs. round-robin, maintains throughput<br/>\u76f8\u6bd4\u8f6e\u8be2\u8c03\u5ea6\u5ef6\u8fdf\u964d\u4f4e85%\uff0c\u4fdd\u6301\u541e\u5410\u91cf"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [spatial dataflow, tile-based compilation, MLIR, on-chip network, hardware representation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wei Li, Zhenyu Bai, Heru Wang, Pranav Dangi, Zhiqiang Zhang, Cheng Tan, Huiying Lan, Weng-Fai Wong, Tulika Mitra"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National University of Singapore, Arizona State University, Google, Lumai Ltd."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22168",children:"https://arxiv.org/pdf/2512.22168"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An end-to-end compiler framework (TL) that compiles tile-based programs (e.g., Triton kernels) onto spatial dataflow architectures, focusing on distributing tile instances across cores. 2. A novel hardware representation that captures interconnect topology, memory hierarchy, and compute capabilities to enable architecture-specific optimizations and support diverse targets. 3. A practical implementation built on the MLIR ecosystem, providing a generic entry point for different front-ends and an end point for different back-ends, demonstrated with performance gains over vendor libraries."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents TL, an end-to-end compiler framework that tackles the limited programmability of spatial dataflow accelerators by automatically mapping tile-based workloads across distributed cores to optimize data reuse and reduce communications. TL introduces a hardware-aware representation and is built on MLIR to support diverse targets. Experiments show it can match or exceed the performance of hand-tuned vendor libraries on kernels like GEMM and FlashAttention."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[TL: Automatic End-to-End Compiler] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Limited Programmability of Spatial Accelerators<br/>\u7a7a\u95f4\u52a0\u901f\u5668\u7684\u6709\u9650\u53ef\u7f16\u7a0b\u6027]\n    Problem --\x3e P2[Poor Performance of Naive Mappings<br/>\u6734\u7d20\u6620\u5c04\u6027\u80fd\u5dee]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[End-to-End Tile-Based Compiler Framework<br/>\u7aef\u5230\u7aef\u57fa\u4e8e\u5206\u5757\u7684\u7f16\u8bd1\u5668\u6846\u67b6]\n    Method --\x3e M2[Hardware Representation for Topology & Memory<br/>\u7528\u4e8e\u62d3\u6251\u548c\u5185\u5b58\u7684\u786c\u4ef6\u8868\u793a]\n    Method --\x3e M3[Built on MLIR Ecosystem<br/>\u57fa\u4e8eMLIR\u751f\u6001\u7cfb\u7edf\u6784\u5efa]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Performance on par with/vs Vendor Library (GEMM)<br/>\u6027\u80fd\u4e0e\u5382\u5546\u5e93\u76f8\u5f53/\u8d85\u8d8a(GEMM)]\n    Results --\x3e R2[Significant Speedup for FlashAttention<br/>FlashAttention\u663e\u8457\u52a0\u901f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [bit-flip faults, fault localization, transformer reliability, residual-path perturbation, loss-sensitivity profiling]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Muhammad Zeeshan Karamat, Sadman Saif, Christiana Chamon Garcia"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Virginia Tech"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22174",children:"https://arxiv.org/pdf/2512.22174"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces BitFlipScope, a scalable software framework for localizing bit-flip corruptions in transformer-based LLMs under two deployment scenarios (with and without a clean reference model). 2. Proposes differential analysis for fault localization when a reference model is available and residual-path perturbation/loss-sensitivity profiling for localization when no reference exists. 3. Enables lightweight performance recovery for corrupted models without requiring costly fine-tuning or full retraining."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces BitFlipScope, a framework for localizing and recovering from bit-flip corruptions in LLMs. It uses differential analysis with a reference model or perturbation-based profiling without one to identify fault-affected regions, enabling targeted recovery without full retraining. The work aims to improve fault resilience for LLMs in hardware-prone and adversarial environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Bit-flip faults corrupt LLM parameters, causing unpredictable behavior]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Differential analysis with reference model; Residual-path perturbation & loss-sensitivity profiling without reference]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Enables fault localization and lightweight recovery, improving fault-resilient LLM deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AiiDAlab: on the route to accelerate science"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [scientific workflow management], [AiiDAlab, AiiDA, provenance tracking, FAIR principles, web-based interface]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aliaksandr V.Yakutovich, Jusong Yu, Daniel Hollas, Edan Bainglass, Corsin Battaglia, Miki Bonacci, Lucas Fernandez Vilanova, Stephan Henne, Anders Kaestner, Michel Kenzelmann, Graham Kimbell, Jakob Lass, Fabio Lopes, Daniel G. Mazzone, Andres Ortega-Guerrero, Xing Wang, Nicola Marzari, Carlo A. Pignedoli, Giovanni Pizzi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Empa, Paul Scherrer Institute, \xc9cole Polytechnique F\xe9d\xe9rale de Lausanne, University of Bristol"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22173",children:"https://arxiv.org/pdf/2512.22173"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Development of the AiiDAlab platform, a web-based interface that simplifies access to and execution of complex computational workflows on supercomputers, lowering the barrier to entry for non-experts. 2. Maturation and expansion of the platform from its origins in computational materials science to support diverse scientific disciplines including quantum chemistry, atmospheric modeling, and experimental data analysis. 3. Integration with electronic laboratory notebooks (ELNs) and emphasis on automatic provenance tracking via AiiDA to enforce reproducibility and adherence to FAIR principles for generating Open Research Data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffb3ec2c93f3c0a0b3a1f69f46586695b4825664dea8e67ccbdf005064367c46_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffb3ec2c93f3c0a0b3a1f69f46586695b4825664dea8e67ccbdf005064367c46_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents AiiDAlab, a web-based platform designed to simplify the execution of complex computational workflows on supercomputers. It abstracts away technical details, provides an intuitive interface, and automatically tracks simulation provenance to ensure reproducibility. The platform has evolved to accelerate scientific discovery across multiple disciplines by allowing researchers to focus on their science rather than computational challenges."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[AiiDAlab: on the route to accelerate science]\n    Root --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u590d\u6742\u5de5\u4f5c\u6d41\u6267\u884c\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6/Complex workflow execution requires technical expertise]\n    Method --\x3e M1[\u63d0\u4f9b\u57fa\u4e8e\u6d4f\u89c8\u5668\u7684\u7528\u6237\u754c\u9762/Provide web-browser-based user interface]\n    Method --\x3e M2[\u5e95\u5c42AiiDA\u5f15\u64ce\u81ea\u52a8\u8ffd\u8e2a\u6eaf\u6e90/Underlying AiiDA engine automatically tracks provenance]\n    Results --\x3e R1[\u8de8\u591a\u5b66\u79d1\u52a0\u901f\u79d1\u5b66\u53d1\u73b0/Accelerates scientific discovery across multiple disciplines]\n    Results --\x3e R2[\u786e\u4fdd\u53ef\u91cd\u590d\u6027\u4e0eFAIR\u539f\u5219/Ensures reproducibility and FAIR principles]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] iOS as Acceleration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [distributed pipeline parallelism, mobile acceleration, iOS, memory constraints, thermal throttling]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Alexander K. Chen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Independent High School Researcher (No institutional affiliation inferred)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22180",children:"https://arxiv.org/pdf/2512.22180"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel proof-of-concept system using distributed pipeline parallelism to harness iOS devices as computational accelerators for local ML tasks. 2. Demonstrates the system's effectiveness in accelerating modest model training (e.g., ResNet-34) and agentic LRM tool-usage, achieving a 44% decrease in training time in a specific setup. 3. Explores the unique potential of ubiquitous mobile devices with powerful processors and sensors (e.g., LiDAR, GPS) as cost-effective resources for embodied agentic AI and local compute, discussing practical use-cases and limitations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the barrier of expensive compute for local machine learning by proposing a system that uses distributed pipeline parallelism to leverage underutilized iOS phones as accelerators. The method partitions model weights to circumvent mobile memory limits, successfully accelerating tasks like training ResNet-34. The work concludes that commonplace mobile devices have significant potential to contribute to ML, especially for local, cost-sensitive, or sensor-driven applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[iOS as Acceleration] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Powerful compute is a barrier for local ML; Cloud is not always viable]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Use distributed pipeline parallelism to harness iOS devices as accelerators]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieved faster training for modest models; Highlights mobile potential for ML]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] MatKV: Trading Compute for Flash Storage in LLM Inference"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [retrieval-augmented generation, key-value cache, flash storage, prefill optimization, power efficiency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kun-Woo Shin, Jay H. Park, Moonwook Oh, Yohan Jo, Jaeyoung Do, Sang-Won Lee"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Seoul National University, Samsung Electronics"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22195",children:"https://arxiv.org/pdf/2512.22195"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/kunwooshin/MatKV",children:"https://github.com/kunwooshin/MatKV"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MatKV, a scheme to precompute and materialize KV vectors of RAG documents in flash storage to avoid recomputation during inference. 2. Demonstrates that MatKV reduces inference time and power consumption by half for RAG workloads with minimal accuracy impact. 3. Shows MatKV enables additional optimizations like overlapping KV loading with decoding and enabling the use of low-end GPUs for decoding."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high compute and energy cost of the prefill phase in RAG-based LLM inference. It proposes MatKV, which precomputes and stores key-value vectors of documents in flash storage for reuse, trading compute for storage. Experiments show this approach halves inference time and power consumption while maintaining accuracy and enabling further hardware optimizations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["MatKV: Trading Compute for Flash Storage in LLM Inference"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>RAG\u63a8\u7406\u4e2dprefill\u9636\u6bb5\u8ba1\u7b97\u5f00\u9500\u5927<br>High compute cost of prefill in RAG inference"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u9884\u8ba1\u7b97\u5e76\u7269\u5316KV\u5411\u91cf\u5230\u95ea\u5b58<br>Precompute & materialize KVs to flash storage"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u63a8\u7406\u65f6\u95f4\u4e0e\u80fd\u8017\u51cf\u534a<br>Halves inference time & power consumption"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [computational fluid dynamics], [GPU porting, unified memory, memory pool manager, OpenFOAM, scalability]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Simone Bn\xe0, Giuseppe Giaquinto, Ettore Fadiga, Tommaso Zanelli, Francesco Bottau"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Cineca Supercomputing Centre, Universit\xe0 degli Studi di Napoli Federico II"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22215",children:"https://arxiv.org/pdf/2512.22215"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Presents SPUMA, a full GPU porting of OpenFOAM targeting both NVIDIA and AMD GPUs. 2. Implements a portable programming model with a memory pool manager leveraging unified memory for efficient GPU utilization. 3. Demonstrates significant performance and energy efficiency gains through extensive testing on pre-exascale clusters, showing up to 82% energy reduction compared to CPU simulations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of GPU programmability for open-source CFD by introducing SPUMA, a portable GPU port of OpenFOAM that uses a memory pool manager with unified memory. The method was tested on LUMI and Leonardo clusters, showing strong scalability up to 65% efficiency and weak scalability up to 85%, while reducing energy consumption by up to 82% compared to CPU-based simulations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: GPU programmability challenge in open-source CFD] --\x3e P1[GPU\u53ef\u7f16\u7a0b\u6027\u6311\u6218/GPU Programmability Challenge]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Portable GPU porting with memory pool] --\x3e M1[\u4fbf\u643a\u5f0f\u7f16\u7a0b\u6a21\u578b/Portable Programming Model]\n    Method --\x3e M2[\u5185\u5b58\u6c60\u7ba1\u7406\u5668/Memory Pool Manager]\n    Method --\x3e M3[\u5229\u7528\u7edf\u4e00\u5185\u5b58/Leverages Unified Memory]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Performance and energy efficiency on pre-exascale clusters] --\x3e R1[\u5f3a\u53ef\u6269\u5c55\u6027\u8fbe65%/Strong Scalability 65%]\n    Results --\x3e R2[\u5f31\u53ef\u6269\u5c55\u6027\u8fbe85%/Weak Scalability 85%]\n    Results --\x3e R3[\u80fd\u8017\u964d\u4f4e82%/Energy Reduction 82%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [megakernel, kernel fusion, SM-level graph, software pipelining, CUDA]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, Tsinghua University, NVIDIA, University of Michigan, Purdue University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22219",children:"https://arxiv.org/pdf/2512.22219"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/mirage-project/mirage",children:"https://github.com/mirage-project/mirage"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces an SM-level graph representation for capturing fine-grained data dependencies across GPU streaming multiprocessors. 2. Develops a compiler and an in-kernel parallel runtime that automatically transforms multi-operator inference into a single, high-performance mega-kernel. 3. Enables previously infeasible GPU optimizations like cross-operator software pipelining and fine-grained kernel overlap, significantly reducing inference latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Mirage Persistent Kernel (MPK), a compiler and runtime system that automatically fuses multiple GPU kernels for model inference into a single, optimized mega-kernel. It achieves this by using a novel SM-level graph representation and decentralized scheduling to enable fine-grained optimizations like software pipelining. Evaluation shows MPK reduces LLM inference latency by up to 1.7x, pushing performance close to hardware limits."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Mirage Persistent Kernel<br>\u5e7b\u5f71\u6301\u4e45\u5185\u6838] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Kernel-per-operator execution<br>limits GPU optimization<br>\u9010\u7b97\u5b50\u5185\u6838\u6267\u884c\u9650\u5236GPU\u4f18\u5316]\n    C --\x3e C1[SM-level graph &<br>mega-kernel runtime<br>SM\u7ea7\u56fe\u4e0e\u5de8\u578b\u5185\u6838\u8fd0\u884c\u65f6]\n    D --\x3e D1[Reduces inference latency<br>by up to 1.7x<br>\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe1.7\u500d]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Scalable Cloud-Native Architectures for Intelligent PMU Data Processing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [cloud-native, distributed stream processing, containerized microservices, elastic resource orchestration, edge-cloud hybrid]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Nachiappan Chockalingam, Akshay Deshpande, Lokesh Butra, Ram Sekhar Bodala, Nitin Saksena, Adithya Parthasarathy, Balakrishna Pothineni, Akash Kumar Agarwal"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE, NTT Data, Amtrak, Albertsons Companies"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22231",children:"https://arxiv.org/pdf/2512.22231"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive theoretical framework for AI-enhanced cloud-based PMU analytics. 2. Mathematical formulations for distributed machine learning optimized for PMU time-series data. 3. Analysis of edge-cloud hybrid architectures with integrated security and privacy considerations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a scalable cloud-native architecture to address the latency and scalability challenges of processing high-frequency data from Phasor Measurement Units (PMUs) in smart grids. The method integrates AI with edge and cloud computing, using distributed stream processing and containerized microservices for real-time analytics. The analysis shows the architecture can achieve sub-second response times while scaling to large deployments, providing a robust foundation for next-generation grid analytics."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Scalable Cloud-Native Architectures for Intelligent PMU Data Processing"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>PMU\u6570\u636e\u89c4\u6a21\u5927\uff0c\u4f20\u7edf\u67b6\u6784\u5ef6\u8fdf\u9ad8\uff0c\u53ef\u6269\u5c55\u6027\u5dee"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u4e91\u539f\u751f\u67b6\u6784\uff0c\u96c6\u6210AI\u3001\u8fb9\u7f18\u4e0e\u4e91\u8ba1\u7b97\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u548c\u5fae\u670d\u52a1"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u54cd\u5e94\uff0c\u53ef\u6269\u5c55\u81f3\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u63d0\u4f9b\u5b89\u5168\u53ef\u9760\u7684\u57fa\u7840"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Varshith Gudur"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Independent Researcher (Valori Kernel Project)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22280",children:"https://arxiv.org/pdf/2512.22280"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/varshith-Git/Valori-Kernel",children:"https://github.com/varshith-Git/Valori-Kernel"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Valori: A Deterministic Memory Substrate for AI Systems] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: AI\u5185\u5b58\u975e\u786e\u5b9a\u6027/AI Memory Non-Determinism]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u56fa\u5b9a\u70b9\u7b97\u672f\u4e0e\u72b6\u6001\u673a/Fixed-Point Arithmetic & State Machine]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u8de8\u5e73\u53f0\u6bd4\u7279\u4e00\u81f4\u6027/Cross-Platform Bit-Identical Results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Text-to-SQL, Cloud Cost Optimization, Query Efficiency, Large Language Models, Google BigQuery]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Saurabh Deochake, Debajyoti Mukhopadhyay"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," SentinelOne, WIDiCoReL Research Lab"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22364",children:"https://arxiv.org/pdf/2512.22364"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Existing efficiency metrics (e.g., VES) measure time, not cloud compute costs.] --\x3e B1[\u95ee\u9898\u80cc\u666f/Context<br>LLMs achieve high Text-to-SQL accuracy, but cost efficiency in cloud deployments is unknown.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Systematic evaluation of 6 LLMs on Google BigQuery (StackOverflow dataset).] --\x3e C1[\u8bc4\u4f30\u6307\u6807/Metrics<br>Measure bytes processed, slot utilization, estimated cost, and correctness.]\n    D[\u5173\u952e\u7ed3\u679c/Results] --\x3e D1[\u53d1\u73b01/Finding 1<br>Reasoning models process 44.5% fewer bytes with equivalent correctness.]\n    D --\x3e D2[\u53d1\u73b02/Finding 2<br>Weak correlation (r=0.16) between execution time and query cost.]\n    D --\x3e D3[\u53d1\u73b03/Finding 3<br>Up to 3.4x cost variance; standard models produce high-cost outliers.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Efficient Multi-Model Orchestration for Self-Hosted Large Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Kubernetes, Helm, DistilBERT, scale-to-zero, hybrid routing]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Tanu Malik"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Missouri"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22402",children:"https://arxiv.org/pdf/2512.22402"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A unified Helm-based deployment system for self-hosted LLMs on Kubernetes, 2. An adaptive scale-to-zero automation mechanism for efficient GPU resource utilization, 3. A hybrid routing module combining keyword heuristics and a lightweight DistilBERT classifier to balance cost, latency, and accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper introduces "Pick and Spin," a framework for efficient orchestration of self-hosted large language models. It addresses challenges in GPU utilization and workload routing by integrating Kubernetes-based deployment, adaptive scaling, and a hybrid routing strategy. The system demonstrates significant improvements in success rate, latency, and cost compared to static deployments.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Efficient Multi-Model Orchestration for Self-Hosted LLMs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Self-hosted LLM deployment challenges: GPU utilization, workload routing, reliability/\u81ea\u6258\u7ba1LLM\u90e8\u7f72\u6311\u6218\uff1aGPU\u5229\u7528\u7387\u3001\u5de5\u4f5c\u8d1f\u8f7d\u8def\u7531\u3001\u53ef\u9760\u6027]\n    C --\x3e C1[Pick and Spin Framework: Kubernetes, Helm, scale-to-zero, hybrid routing/Pick and Spin\u6846\u67b6\uff1aKubernetes, Helm, \u7f29\u5bb9\u81f3\u96f6, \u6df7\u5408\u8def\u7531]\n    D --\x3e D1[21.6% higher success rate, 30% lower latency, 33% lower cost/\u6210\u529f\u7387\u63d0\u534721.6%\uff0c\u5ef6\u8fdf\u964d\u4f4e30%\uff0c\u6210\u672c\u964d\u4f4e33%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, dynamic adaptation, multi-armed bandit, throughput optimization, latency reduction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National University of Defense Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22420",children:"https://arxiv.org/pdf/2512.22420"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies the critical trade-off in speculative decoding: beneficial in memory-bound (low-load) scenarios but detrimental in compute-bound (high-load) scenarios due to verification overhead. 2. Proposes Nightjar, a novel learning-based algorithm that dynamically adapts the speculative length (or disables SD) based on real-time request load and batch size. 3. Demonstrates significant performance gains, achieving up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the inefficiency of fixed-length speculative decoding in LLM serving, which fails to adapt to dynamic request loads. It proposes Nightjar, a learning-based algorithm that dynamically selects the optimal speculative length. Experiments show Nightjar significantly improves throughput and reduces latency compared to standard speculative decoding."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Nightjar: Dynamic Adaptive Speculative Decoding] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Fixed speculative length fails under dynamic loads]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Learning-based algorithm adapts speculative length]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Higher throughput, lower latency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Role-Based Fault Tolerance System for LLM RL Post-Training"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [role-based fault tolerance, RL post-training, UCX communication, warm standby, Effective Training Time Ratio (ETTR)]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University, State Key Laboratory of Mathematical Engineering and Advanced Computing"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22492",children:"https://arxiv.org/pdf/2512.22492"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a role-based fault isolation and recovery system (RobustRL) for RL post-training, enabling recovery of only the failed component (trainer, rollout) instead of restarting the entire task. 2. Introduces a role-aware monitoring mechanism to accurately detect failures and avoid false positives/delays specific to different RL roles. 3. Implements dynamic, UCX-based point-to-point communication to reconnect recovered roles and synchronize weights immediately, replacing static collective communication."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of fault tolerance for RL post-training of LLMs, which interleaves training and inference workloads. It proposes RobustRL, a system that isolates and recovers failed roles (e.g., trainer, rollout) individually using a Detect-Restart-Reconnect paradigm, instead of restarting the entire job. This approach significantly improves the Effective Training Time Ratio and reduces end-to-end training time compared to baseline methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Role-Based Fault Tolerance System for LLM RL Post-Training] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[RL\u540e\u8bad\u7ec3\u6df7\u5408\u8bad\u7ec3\u4e0e\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6613\u53d7\u53cc\u65b9\u6545\u969c\u5f71\u54cd/RL post-training mixes training & inference, vulnerable to faults from both]\n    B --\x3e B2[\u73b0\u6709\u5bb9\u9519\u6846\u67b6\u672a\u9488\u5bf9RL\u7684\u5f02\u6b65\u6267\u884c\u4f18\u5316/Existing FT frameworks not optimized for RL's async execution]\n    C --\x3e C1[\u57fa\u4e8e\u89d2\u8272\u7684\u6545\u969c\u9694\u79bb\u4e0e\u6062\u590d/Role-based fault isolation & recovery]\n    C --\x3e C2[\u68c0\u6d4b-\u91cd\u542f-\u91cd\u8fde\u8303\u5f0f/Detect-Restart-Reconnect paradigm]\n    C2 --\x3e C21[\u89d2\u8272\u611f\u77e5\u76d1\u63a7/Role-aware monitoring]\n    C2 --\x3e C22[\u975e\u4e2d\u65ad\u5f0f\u91cd\u542f/Non-disruptive restart with warm standbys]\n    C2 --\x3e C23[\u52a8\u6001UCX\u70b9\u5bf9\u70b9\u901a\u4fe1\u91cd\u8fde/Dynamic UCX P2P reconnection]\n    D --\x3e D1[ETTR\u8d85\u8fc780%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u768460%/ETTR >80%, better than baseline 60%]\n    D --\x3e D2[\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u52a0\u5feb8.4%-17.4%/End-to-end training time 8.4%-17.4% faster]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Object Abstraction To Streamline Edge-Cloud-Native Application Development"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [serverless computing, edge computing], [Object-as-a-Service (OaaS), edge-cloud continuum, serverless, FaaS, declarative SLA]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Pawissanutt Lertpongrujikorn"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of North Texas"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22534",children:"https://arxiv.org/pdf/2512.22534"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed the Object-as-a-Service (OaaS) paradigm, unifying resource, state, and workflow management with the Oparaca prototype. 2. Extended OaaS to the edge-cloud continuum with OaaS-IoT/EdgeWeaver, improving performance and reducing code complexity. 3. Established an empirical methodology and commercialization pathway for cloud-native research grounded in practitioner needs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fcd35442b8b6cfbc12c61e295e970899c2bfb10184fe06c88745b8fbf0137055_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fcd35442b8b6cfbc12c61e295e970899c2bfb10184fe06c88745b8fbf0137055_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This dissertation addresses the complexity and fragmentation in serverless and cloud-native development by proposing the Object-as-a-Service (OaaS) paradigm. It introduces a unified abstraction for resources, state, and workflows, and extends it to the edge-cloud continuum, demonstrating improved developer productivity and system performance. The work concludes that OaaS effectively hides infrastructure complexity, allowing developers to focus on application logic."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Object Abstraction for Edge-Cloud-Native Apps<br>\u9762\u5411\u8fb9\u7f18\u4e91\u539f\u751f\u5e94\u7528\u7684\u5bf9\u8c61\u62bd\u8c61") --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem("\u6838\u5fc3\u95ee\u9898/Problem") --\x3e P1("Serverless \u627f\u8bfa\u4e0e\u5b9e\u8df5\u5b58\u5728\u5dee\u8ddd<br>Gap in serverless promise vs. practice")\n    Problem --\x3e P2("\u57fa\u7840\u8bbe\u65bd\u788e\u7247\u5316\u4e0e\u590d\u6742\u5316<br>Infrastructure fragmentation & complexity")\n    Method("\u4e3b\u8981\u65b9\u6cd5/Method") --\x3e M1("\u63d0\u51fa OaaS \u8303\u5f0f<br>Propose OaaS paradigm")\n    Method --\x3e M2("\u5f00\u53d1 Oparaca \u539f\u578b<br>Develop Oparaca prototype")\n    Method --\x3e M3("\u6269\u5c55\u81f3\u8fb9\u7f18\u4e91\u8fde\u7eed\u4f53<br>Extend to edge-cloud continuum (OaaS-IoT)")\n    Results("\u5173\u952e\u7ed3\u679c/Results") --\x3e R1("\u7edf\u4e00\u8d44\u6e90\u3001\u72b6\u6001\u3001\u5de5\u4f5c\u6d41\u7ba1\u7406<br>Unified resource, state, workflow management")\n    Results --\x3e R2("\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\uff0c\u53ef\u6269\u5c55\u6027\u9886\u5148<br>Negligible overhead, state-of-the-art scalability")\n    Results --\x3e R3("\u4efb\u52a1\u5b8c\u6210\u66f4\u5feb\uff0c\u4ee3\u7801\u884c\u6570\u51cf\u5c11<br>Faster task completion, reduced lines of code")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [disaggregated infrastructure, hardware-affinity mapping, fine-grained asynchrony]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," HKUST, Alibaba Group"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22560",children:"https://arxiv.org/pdf/2512.22560"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/alibaba/ROLL",children:"https://github.com/alibaba/ROLL"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A hardware-affinity workload mapping strategy that routes compute-bound and bandwidth-bound tasks to best-fit GPU devices. 2. A fine-grained asynchrony mechanism that manages execution at the trajectory level to mitigate resource bubbles and improve utilization. 3. A statefulness-aware computation design that offloads stateless components to serverless infrastructure for elastic scaling."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents RollArt, a distributed system designed to scale agentic reinforcement learning training on disaggregated infrastructure. It addresses the heterogeneity of agentic RL workloads by proposing three core techniques: hardware-affinity workload mapping, fine-grained asynchrony, and statefulness-aware computation. The system demonstrates significant improvements in training throughput, achieving 1.35-2.05x speedup over baselines, and scales to thousands of GPUs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Agentic RL workloads are heterogeneous, causing inefficiency in monolithic infrastructure."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Disaggregated system with hardware-affinity mapping, fine-grained asynchrony, and statefulness-aware computation."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Achieves 1.35-2.05x training speedup and scales to >3000 GPUs."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [energy efficiency, dynamic voltage and frequency scaling (DVFS), GPU underutilization, visual token sequences, stage-level analysis]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mona Moghadampanah, Adib Rezaei Shahmirzadi, Farhana Amin, Dimitrios S. Nikolopoulos"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Virginia Tech"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22695",children:"https://arxiv.org/pdf/2512.22695"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides the first detailed, stage-level energy characterization of MLLM inference, identifying modality inflation as a key inefficiency. 2. Quantifies the significant energy overhead (17%-94%) of multimodal inference and reveals diverse bottlenecks (vision encoder vs. prefill) and GPU underutilization. 3. Demonstrates stage-wise DVFS as an effective optimization to reduce energy consumption with minimal performance impact."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f6dd42f6aa45e4d0992cdd9fa407ab5c4268e31f45ecafdc9b44861ceb445e1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f6dd42f6aa45e4d0992cdd9fa407ab5c4268e31f45ecafdc9b44861ceb445e1_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper investigates the energy inefficiency of multimodal large language model (MLLM) inference, termed "modality inflation," where extra encoding stages and longer token sequences increase energy consumption. It provides a stage-level energy analysis on GPUs, quantifying overheads and identifying bottlenecks, and proposes stage-wise dynamic voltage and frequency scaling (DVFS) as an effective optimization to save energy with modest performance loss.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Multimodal inference introduces unexplored energy trade-offs and inefficiencies (modality inflation)]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Stage-level energy analysis (vision encoding, prefill, decode) on GPU, and proposes stage-wise DVFS optimization]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Quantifies 17%-94% energy overhead, identifies bottlenecks and GPU underutilization, demonstrates DVFS saves energy with minor impact]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] OptiNIC: A Resilient and Tail-Optimal RDMA NIC for Distributed ML Workloads"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [RDMA, tail latency, collective communication, reliability, domain-specific transport]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ertza Warraich, Ali Imran, Annus Zulfiqar, Shay Vargaftik, Sonia Fahmy, Muhammad Shahbaz"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Purdue University, Broadcom, University of Michigan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22743",children:"https://arxiv.org/pdf/2512.22743"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes OptiNIC, a domain-specific RDMA transport that eliminates retransmissions and in-order delivery from the NIC, shifting to a best-effort, out-of-order model. 2. Introduces adaptive timeouts to trigger forward progress in case of data loss or delay, decoupling completion signaling from complete data delivery. 3. Shifts loss recovery to the ML pipeline (e.g., via Hadamard Transform and Erasure Coding) while retaining standard congestion control, improving performance and resilience for distributed ML workloads."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3143921b3b275baf220b75c6f927e8a49b4fa31653bbd117324490a1b8f8da93_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3143921b3b275baf220b75c6f927e8a49b4fa31653bbd117324490a1b8f8da93_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies tail latency in collective communication as a major bottleneck for distributed ML. It proposes OptiNIC, a new RDMA transport that relaxes strict reliability guarantees based on ML's tolerance for data loss, using adaptive timeouts and moving recovery to the application layer. Evaluation shows OptiNIC significantly improves time-to-accuracy, throughput, and tail latency while reducing hardware resource usage."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[OptiNIC: A Resilient and Tail-Optimal RDMA NIC] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Tail latency in collective communication bottlenecks distributed ML scaling]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Domain-specific RDMA transport with best-effort delivery, adaptive timeouts, and loss recovery in ML pipeline]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improves TTA 2x, throughput 1.6x, lowers 99th% latency 3.5x, cuts BRAM usage 2.7x]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Two-Robot Computational Landscape: A Complete Characterization of Model Power in Minimal Mobile Robot Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [distributed computing], [autonomous mobile robots, Look-Compute-Move (LCM), computational power hierarchy, finite-state robots, robots with lights]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Naoki Kitamura, Yuichi Sudo, Koichi Wada"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The University of Osaka, Hosei University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22770",children:"https://arxiv.org/pdf/2512.22770"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proves that under full synchrony, the FSTA (finite-state) and LUMI (robots with lights) models coincide for two robots, showing perfect synchrony can substitute for memory and communication at this minimal scale. 2. Shows that the FSTA and FCOM (finite-communication) models are orthogonal (bidirectionally incomparable), completing the landscape of incomparability. 3. Provides the first complete and exact characterization of the computational power hierarchy for two robots across all major models and schedulers using a novel simulation-free method."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddce34ada1bbaebc271a0c17bbc6cf8413606d2887ebd22bfe77cc4c0e90d34a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddce34ada1bbaebc271a0c17bbc6cf8413606d2887ebd22bfe77cc4c0e90d34a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper provides the first complete characterization of the computational power of two autonomous mobile robots across major models (OBLOT, FSTA, FCOM, LUMI) and schedulers. Using a novel simulation-free method, it reveals a landscape distinct from the general n-robot case, showing that perfect synchrony can substitute for memory and communication for two robots, and that FSTA and FCOM are orthogonal. This yields the first exact computational hierarchy for minimal robot systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Two-Robot Computational Landscape] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Two-robot computational hierarchy unresolved]\n    C --\x3e C1[Simulation-free analysis method]\n    D --\x3e D1[FSTA^F = LUMI^F under full sync]\n    D --\x3e D2[FSTA and FCOM are orthogonal]\n    D --\x3e D3[Complete landscape for two robots]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Argus: Token Aware Distributed LLM Inference Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [token-aware offloading, Lyapunov optimization, length prediction, edge-cloud systems, distributed inference]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Panlong Wu, Yifei Zhong, Danyang Chen, Ting Wang, Fangxin Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, Shenzhen (CUHK-SZ)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22925",children:"https://arxiv.org/pdf/2512.22925"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A Length-Aware Semantics (LAS) module that predicts output token lengths for prompts using a fine-tuned language model with token-length-sensitive feature modulation. 2. A Lyapunov-guided Offloading Optimization (LOO) module that formulates long-term Quality-of-Experience optimization considering both LLM prefilling and decoding costs. 3. A novel Iterative Offloading Algorithm with Damping and Congestion Control (IODCC) to solve the resulting integer nonlinear programming problem under time-varying constraints."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e6bf58921ba8401e4cc5e40322f2ce1b65861ebe0ac5f35cfead3e0339c7f09_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e6bf58921ba8401e4cc5e40322f2ce1b65861ebe0ac5f35cfead3e0339c7f09_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents Argus, a token-aware distributed LLM inference framework for edge-cloud systems. It addresses inference time variability by predicting output token lengths and using Lyapunov optimization for efficient task offloading. Evaluations show Argus achieves robust and efficient performance in dynamic, heterogeneous environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Argus: Token Aware Distributed LLM Inference Optimization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u63a8\u7406\u65f6\u95f4\u53ef\u53d8\u6027\u9ad8 / High LLM Inference Time Variability]\n    B --\x3e B2[\u52a8\u6001\u5f02\u6784\u8fb9\u7f18\u4e91\u73af\u5883 / Dynamic Heterogeneous Edge-Cloud Environment]\n    C --\x3e C1[LAS: \u8f93\u51fa\u957f\u5ea6\u9884\u6d4b / LAS: Output Length Prediction]\n    C --\x3e C2[LOO: \u674e\u96c5\u666e\u8bfa\u592b\u4f18\u5316\u5378\u8f7d / LOO: Lyapunov Optimization Offloading]\n    C --\x3e C3[IODCC: \u8fed\u4ee3\u5378\u8f7d\u7b97\u6cd5 / IODCC: Iterative Offloading Algorithm]\n    D --\x3e D1[\u9c81\u68d2\u6027\u80fd / Robust Performance]\n    D --\x3e D2[\u9ad8\u6548\u63a8\u7406 / Efficient Inference]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [uncertainty quantification], [stochastic Galerkin method, polynomial chaos expansion, domain decomposition, Neumann-Neumann preconditioner]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sudhi Sharma Padillath Vasudevan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Carleton University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23027",children:"https://arxiv.org/pdf/2512.23027"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Applies an intrusive stochastic Galerkin method with Polynomial Chaos Expansion to solve acoustic wave propagation in random media, transforming the stochastic PDE into a deterministic system. 2. Employs Domain Decomposition-based solvers to address the high computational cost associated with large-scale, high-dimensional stochastic systems. 3. Utilizes a conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner, demonstrating efficient scalability for the problem."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the high computational cost of simulating acoustic wave propagation in two-dimensional random media. It proposes a method combining an intrusive stochastic Galerkin approach with Polynomial Chaos Expansion and a Domain Decomposition-based linear solver preconditioned with a two-level Neumann-Neumann method. The results show that this approach provides an efficiently scalable solution for the problem."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[\u57fa\u4e8e\u57df\u5206\u89e3\u7684\u4e8c\u7ef4\u968f\u673a\u4ecb\u8d28\u58f0\u6ce2\u4f20\u64ad\u6c42\u89e3\u5668<br>A Domain Decomposition-based Solver for Acoustic Wave Propagation in 2D Random Media]\n    Root --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u8ba1\u7b97\u6210\u672c\u9ad8<br>High Computational Cost]\n    P1 --\x3e P2[\u7f51\u683c\u3001\u65f6\u95f4\u6b65\u3001\u968f\u673a\u53c2\u6570\u589e\u52a0<br>Increasing Mesh, Time Step, Random Parameters]\n    Method --\x3e M1[\u4fb5\u5165\u5f0f\u968f\u673a\u4f3d\u8fbd\u91d1\u6cd5<br>Intrusive Stochastic Galerkin]\n    M1 --\x3e M2[\u591a\u9879\u5f0f\u6df7\u6c8c\u5c55\u5f00<br>Polynomial Chaos Expansion (PCE)]\n    Method --\x3e M3[\u57df\u5206\u89e3\u6c42\u89e3\u5668<br>Domain Decomposition Solver]\n    M3 --\x3e M4[\u5171\u8f6d\u68af\u5ea6\u6cd5+\u4e24\u5c42Neumann-Neumann\u9884\u5904\u7406\u5668<br>Conjugate Gradient with Two-level Neumann-Neumann Preconditioner]\n    Results --\x3e R1[\u9ad8\u6548\u53ef\u6269\u5c55\u6027<br>Efficient Scalability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Viability and Performance of a Private LLM Server for SMBs: A Benchmark Analysis of Qwen3-30B on Consumer-Grade Hardware"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [quantization, mixture-of-experts, on-premise deployment, consumer-grade hardware, benchmark analysis]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Alex Khalil, Guillaume Heilles, Maria Parraga, Simon Heilles"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," UCLouvain, Universidad Esp\xedritu Santo, DENEM Labs"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23029",children:"https://arxiv.org/pdf/2512.23029"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive benchmarking framework for evaluating both the intrinsic model capabilities and the server-side performance (latency, throughput, scalability) of a private LLM deployment. 2. A practical demonstration and performance analysis of deploying a quantized, large-scale (30B parameter) Mixture-of-Experts model (Qwen3) on next-generation consumer-grade hardware (NVIDIA RTX 5090). 3. Evidence that a carefully configured on-premises LLM server can achieve performance comparable to cloud services, offering SMBs a viable, cost-effective, and privacy-preserving alternative."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the feasibility of deploying a private, high-performance LLM server for Small and Medium Businesses using consumer-grade hardware. It benchmarks a quantized Qwen3-30B model on an NVIDIA RTX 5090, evaluating both model capability and server performance under load. The results show that such an on-premises setup can achieve performance close to cloud services at a lower cost and with full data privacy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Viability and Performance of a Private LLM Server for SMBs<br>SMB\u79c1\u6709LLM\u670d\u52a1\u5668\u7684\u53ef\u884c\u6027\u4e0e\u6027\u80fd] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Cloud reliance: cost, privacy, sovereignty for SMBs<br>\u4e91\u4f9d\u8d56\uff1a\u6210\u672c\u3001\u9690\u79c1\u3001SMB\u4e3b\u6743]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Benchmark quantized Qwen3-30B on consumer hardware (RTX 5090)<br>\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u5bf9\u91cf\u5316Qwen3-30B\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>On-premises performance rivals cloud, viable for SMBs<br>\u672c\u5730\u6027\u80fd\u5ab2\u7f8e\u4e91\u7aef\uff0c\u5bf9SMB\u53ef\u884c]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [self-supervised learning, representation learning, distributed learning, decentralized clustering, contextual data]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mario Colosi, Reza Farahani, Maria Fazio, Radu Prodan, Massimo Villari"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Messina, University of Klagenfurt, University of Innsbruck"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23096",children:"https://arxiv.org/pdf/2512.23096"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces Osmotic Learning (OSM-L), a novel self-supervised paradigm for learning from distributed data without raw data exchange. 2. Proposes an "osmosis" process that aligns local representations to converge to a dynamic equilibrium, capturing contextual patterns. 3. Demonstrates that OSM-L functions as a decentralized clustering mechanism, identifying correlated data groups during training.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper proposes Osmotic Learning (OSM-L), a self-supervised distributed learning paradigm that extracts higher-level latent knowledge from decentralized data sources without sharing raw data. It achieves this through an iterative "osmosis" process that aligns local representations to converge to a contextual equilibrium, also enabling decentralized clustering. Experimental results show OSM-L achieves high accuracy in local information alignment while preserving contextual integrity.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A[Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Extracting meaningful knowledge from distributed, heterogeneous data without raw data exchange]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Osmotic Learning (OSM-L) - self-supervised paradigm using iterative alignment and "osmosis" for representation convergence]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves >0.99 alignment accuracy and preserves contextual integrity; enables decentralized clustering]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [graph federated learning, fairness, overlapping subgraphs, privacy-preserving, weighted aggregation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zihao Zhou, Shusen Yang, Fangyuan Zhao, Xuebin Ren"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Xi'an Jiaotong University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23235",children:"https://arxiv.org/pdf/2512.23235"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Uncover and theoretically analyze the unfairness issue in graph federated learning caused by imbalanced overlapping subgraphs across clients. 2. Propose FairGFL, a novel algorithm that uses a privacy-preserving estimation of overlapping ratios and an interpretable weighted aggregation approach to enhance cross-client fairness. 3. Improve the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies a fairness problem in graph federated learning when client subgraphs overlap in an imbalanced way. To solve this, it proposes FairGFL, a method that uses privacy-preserving overlap estimation and a fairness-aware regularizer to balance utility and fairness. Experiments show FairGFL outperforms baselines in both utility and fairness on benchmark datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA(FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs) --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Imbalanced overlapping subgraphs cause unfairness in GFL)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: FairGFL with privacy-preserving overlap estimation, weighted aggregation, and fairness regularizer)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Outperforms baselines in model utility and fairness)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Lyapunov Optimization, Deep Reinforcement Learning, Edge-Cloud Partitioning, Transformer Decomposition, Queue Stability]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Innsbruck, Sharif University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23310",children:"https://arxiv.org/pdf/2512.23310"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a fine-grained, adaptive partitioning framework (Splitwise) that decomposes transformer layers into attention heads and feed-forward sub-blocks, enabling exponentially more partition choices than layer-wise schemes. 2. Introduces a hierarchical DRL policy guided by Lyapunov optimization to jointly optimize latency, energy, and accuracy while guaranteeing queue stability under stochastic workloads and variable bandwidth. 3. Ensures robustness through partition checkpoints with exponential backoff recovery for communication failures, validated on real edge devices with large models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Splitwise, a Lyapunov-assisted DRL framework for dynamically partitioning LLM inference between edge and cloud at a fine-grained sub-layer level. It aims to minimize latency and energy while maintaining accuracy under fluctuating network conditions. Experiments show Splitwise significantly reduces latency and energy consumption compared to existing methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs are hard to deploy on edge devices; cloud-only is slow; static partitions fail with bandwidth changes.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Fine-grained partition of transformer layers; Lyapunov-assisted DRL for adaptive optimization; checkpointing for robustness.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Reduces latency 1.4x-2.8x; cuts energy up to 41%; lowers 95th-percentile latency by 53-61%.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [Kubernetes, Autoscaling, AIOps, Service Level Objectives, Cost Optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE, East West Bank, NTT Data, Albertsons"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23415",children:"https://arxiv.org/pdf/2512.23415"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("SLO\u8fdd\u53cd\u4e0e\u6210\u672c\u4f4e\u6548/SLO Violations & Cost Inefficiency")\n    Problem --\x3e P2("\u53cd\u5e94\u5f0f\u6269\u5c55\u4e0e\u4e0d\u900f\u660e\u903b\u8f91/Reactive Scaling & Opaque Logic")\n    Method --\x3e M1("AIOps\u9a71\u52a8\u7684\u591a\u4fe1\u53f7\u6846\u67b6/AIOps-Driven Multi-Signal Framework")\n    Method --\x3e M2("SLO\u4e0e\u6210\u672c\u611f\u77e5\u63a7\u5236/SLO & Cost-Aware Control")\n    Method --\x3e M3("\u8f7b\u91cf\u7ea7\u9700\u6c42\u9884\u6d4b/Lightweight Demand Forecasting")\n    Results --\x3e R1("SLO\u8fdd\u53cd\u65f6\u957f\u51cf\u5c1131%/SLO Violation Duration Reduced by 31%")\n    Results --\x3e R2("\u6269\u5c55\u54cd\u5e94\u65f6\u95f4\u63d0\u534724%/Scaling Response Time Improved by 24%")\n    Results --\x3e R3("\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u964d\u4f4e18%/Infrastructure Cost Lowered by 18%")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Local Rendezvous Hashing: Bounded Loads and Minimal Churn via Cache-Local Candidates"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [distributed systems], [consistent hashing, rendezvous hashing, load balancing, cache locality, minimal churn]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yongjie Guan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23434",children:"https://arxiv.org/pdf/2512.23434"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Local Rendezvous Hashing (LRH), which restricts HRW selection to a cache-local window of C distinct neighboring physical nodes on a ring. 2. Proposes next-distinct offsets to enforce bounded distinct candidate enumeration in exactly C ring steps. 3. Demonstrates that under fixed-candidate liveness failover, LRH achieves 0% excess churn while maintaining high throughput and good load balance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40c222a782553ce278b2cbc43564ea8beed18effebd850b7b92ac28f04bda05_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40c222a782553ce278b2cbc43564ea8beed18effebd850b7b92ac28f04bda05_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the trade-off between load balance and performance in consistent hashing for distributed systems. It proposes Local Rendezvous Hashing (LRH), a method that performs a Highest Random Weight selection within a small, cache-local window of nodes on a ring. LRH achieves near-optimal load balance with minimal key churn and significantly higher lookup throughput compared to multi-probe consistent hashing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Local Rendezvous Hashing] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Ring-based consistent hashing has high load imbalance or scattered memory accesses.]\n    C --\x3e C1[Restrict HRW selection to a cache-local window of C distinct nodes.]\n    D --\x3e D1[Reduces Max/Avg load to 1.0947 and achieves 60.05 Mkeys/s throughput.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [blockchain scalability], [Bitcoin, Layer-2, Proof-of-Stake, interoperability, SegWit]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Marko Vukoli\u0107, Orestis Alpos, Jakov Mitrovski, Themis Papameletiou, Nikola Risti\u0107, Dionysis Zindros"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Bitcoin Scaling Labs, Common Prefix"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23439",children:"https://arxiv.org/pdf/2512.23439"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Bitcoin-IPC, a protocol enabling permissionless creation of Proof-of-Stake Layer-2 subnets with stake denominated in Bitcoin (BTC). 2. Proposes a novel design embedded within Bitcoin's SegWit mechanism, inspired by SWIFT messaging, for seamless cross-subnet value transfer routed through Bitcoin L1. 3. Achieves significant scalability improvements, reducing transaction cost by up to 23x and increasing throughput from 7 to over 160 tps without modifying Bitcoin L1."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses Bitcoin's limited transaction throughput for use as a Medium of Exchange. It proposes Bitcoin-IPC, a protocol that creates a network of programmable Proof-of-Stake Layer-2 chains (subnets) that use Bitcoin for security and settlement. The design significantly increases transaction throughput and reduces cost without requiring changes to the Bitcoin base layer."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6bd4\u7279\u5e01\u4f5c\u4e3a\u4ea4\u6362\u5a92\u4ecb\u7684\u53ef\u6269\u5c55\u6027\u4e0d\u8db3/Bitcoin's limited scalability as Medium of Exchange]\n    C --\x3e C1[\u57fa\u4e8eSegWit\u548cSWIFT\u542f\u53d1\u7684L2 PoS\u5b50\u7f51\u534f\u8bae/L2 PoS Subnet protocol inspired by SegWit & SWIFT]\n    D --\x3e D1[\u541e\u5410\u91cf\u4ece7 tps\u63d0\u5347\u81f3160+ tps/Throughput increased from 7 to 160+ tps]\n    D --\x3e D2[\u6bcf\u7b14\u4ea4\u6613\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe23\u500d/Tx cost reduced up to 23x]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Decoupling Adaptive Control in TeaStore"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [self-adaptive systems], [self-adaptation, microservices, control loop, operator pattern, software architecture]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Eddy Truyen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," DistriNet, KU Leuven"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23495",children:"https://arxiv.org/pdf/2512.23495"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Decoupling Adaptive Control in TeaStore] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5b9e\u73b0\u5fae\u670d\u52a1\u4e2d\u7684\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94/Implementing fine-grained self-adaptation in microservices]\n    C --\x3e C1[\u8f6f\u4ef6\u67b6\u6784\u65b9\u6cd5/Software architectural methods]\n    C --\x3e C2[Operator\u6a21\u5f0f/Operator pattern]\n    C --\x3e C3[\u4f20\u7edf\u7f16\u7a0b\u6280\u672f/Legacy programming techniques]\n    D --\x3e D1[\u6743\u8861\u7ec6\u7c92\u5ea6\u4e0e\u7cfb\u7edf\u8303\u56f4\u63a7\u5236/Trade-offs between fine-grained and system-wide control]\n    D --\x3e D2[\u53ef\u7ec4\u5408\u7684\u591a\u5c42\u67b6\u6784/Composable multi-tiered architecture]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Fancy Some Chips for Your TeaStore? Modeling the Control of an Adaptable Discrete System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [modeling languages, control theory, distributed systems], [Chips, control theory, component-based modeling, Adaptable TeaStore, BIP]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Anna Gallone, Simon Bliudze, Sophie Cerf, Olga Kouchnarenko"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Universit\xe9 Marie et Louis Pasteur (FEMTO-ST), Univ. Lille (Inria, CNRS, CRIStAL)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23496",children:"https://arxiv.org/pdf/2512.23496"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/NwaitDev/Chips_Public",children:"https://github.com/NwaitDev/Chips_Public"}),", ",(0,r.jsx)(n.a,{href:"https://github.com/NwaitDev/TeaStore-Variation",children:"https://github.com/NwaitDev/TeaStore-Variation"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Chips, a novel language for designing models of complex, intertwined systems by mixing control theory with general-purpose programming concepts. 2. Enables systematic design, modeling, and analysis of adaptable systems through functional block descriptions. 3. Demonstrates the language's application and utility using a variation of the Adaptable TeaStore as a concrete running example."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Chips, a modeling language that combines control theory with programming concepts to facilitate the design and analysis of robust, component-based systems. The method is demonstrated on an Adaptable TeaStore application, showing how Chips can be used to systematically model complex, interacting entities like software, hardware, and services. The main conclusion is that Chips aids in ensuring system robustness and quality of service for web applications and cyber-physical systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Fancy Some Chips for Your TeaStore?<br/>Modeling the Control of an Adaptable Discrete System] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br/>Web\u5e94\u7528\u9700\u7ba1\u7406\u590d\u6742\u3001\u76f8\u4e92\u4f9d\u8d56\u7684\u8d44\u6e90\u4ee5\u786e\u4fdd\u9c81\u68d2\u6027] --\x3e Problem_Detail[\u7cfb\u7edf\u590d\u6742/Complex System<br/>\u8f6f\u4ef6\u3001\u786c\u4ef6\u3001\u7f51\u7edc\u3001\u5fae\u670d\u52a1\u4ea4\u7ec7]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u63d0\u51faChips\u5efa\u6a21\u8bed\u8a00] --\x3e Method_Detail1[\u6df7\u5408\u6982\u5ff5/Mixed Concepts<br/>\u63a7\u5236\u7406\u8bba + \u901a\u7528\u7f16\u7a0b\u8bed\u8a00]\n    Method --\x3e Method_Detail2[\u529f\u80fd\u5757\u63cf\u8ff0/Functional Blocks<br/>\u751f\u6210\u9c81\u68d2\u7684\u7ec4\u4ef6\u6a21\u578b]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br/>\u7cfb\u7edf\u5316\u8bbe\u8ba1\u3001\u5efa\u6a21\u4e0e\u5206\u6790] --\x3e Results_Detail[\u6848\u4f8b\u6f14\u793a/Case Study<br/>\u4f7f\u7528Adaptable TeaStore\u53d8\u4f53\u9a8c\u8bc1]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Optimal Configuration of API Resources in Cloud Native Computing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [cloud computing], [Kubernetes, resource optimization, microservices, DevOps, Bayesian optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Eddy Truyen, Wouter Joosen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," DistriNet, KU Leuven"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23494",children:"https://arxiv.org/pdf/2512.23494"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Applies an existing black-box optimization framework to the largely unexplored problem of fine-tuning CPU and memory allocation during the DevOps Release phase, before deployment. 2. Empirically evaluates the framework using the TeaStore microservice application and provides a statistical comparison of different optimization algorithms, analyzing their trade-offs. 3. Provides practical guidance on when to use factor screening (for optimal configuration or algorithm comparison with a budget) versus pure Bayesian optimization (for finding a near-optimal configuration)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd4cec4e268968c920e0f358d7cea15fb1e4dc177e4b11b53180a3f5172ef65_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd4cec4e268968c920e0f358d7cea15fb1e4dc177e4b11b53180a3f5172ef65_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper applies a black-box optimization framework to tune Kubernetes CPU and memory resource configurations for microservices during the DevOps Release phase, a problem often overlooked in favor of runtime autoscaling. The evaluation on the TeaStore application shows that factor screening is useful for finding the optimal configuration within a budget, but Bayesian optimization without screening is better for finding a near-optimal solution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Optimal Configuration of API Resources in Cloud Native Computing<br/>\u4e91\u539f\u751f\u8ba1\u7b97\u4e2dAPI\u8d44\u6e90\u7684\u6700\u4f18\u914d\u7f6e"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Untuned resource allocation before deployment<br/>\u90e8\u7f72\u524d\u672a\u8c03\u4f18\u7684\u8d44\u6e90\u5206\u914d"] --\x3e P1["\u5b50\u95ee\u9898/Sub-Problem<br/>Focus on Release phase, not Ops<br/>\u5173\u6ce8\u53d1\u5e03\u9636\u6bb5\uff0c\u800c\u975e\u8fd0\u7ef4\u9636\u6bb5"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Apply black-box optimization framework<br/>\u5e94\u7528\u9ed1\u76d2\u4f18\u5316\u6846\u67b6"] --\x3e M1["\u6280\u672f/Technique<br/>Factor screening & Bayesian optimization<br/>\u56e0\u5b50\u7b5b\u9009\u4e0e\u8d1d\u53f6\u65af\u4f18\u5316"]\n    Method --\x3e M2["\u8bc4\u4f30/Evaluation<br/>Use TeaStore microservice app<br/>\u4f7f\u7528TeaStore\u5fae\u670d\u52a1\u5e94\u7528"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Guidance on screening vs. no screening<br/>\u5173\u4e8e\u662f\u5426\u4f7f\u7528\u7b5b\u9009\u7684\u6307\u5bfc"] --\x3e R1["\u7ed3\u679c1/Result 1<br/>Screening helps find optimal config with budget<br/>\u7b5b\u9009\u6709\u52a9\u4e8e\u5728\u9884\u7b97\u5185\u627e\u5230\u6700\u4f18\u914d\u7f6e"]\n    Results --\x3e R2["\u7ed3\u679c2/Result 2<br/>Pure BO better for near-optimal config<br/>\u7eaf\u8d1d\u53f6\u65af\u4f18\u5316\u5bf9\u5bfb\u627e\u8fd1\u4f3c\u6700\u4f18\u914d\u7f6e\u66f4\u597d"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [autonomic computing], [MAPE-K loop, decentralized adaptation, event-driven, rule-based, microservices]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Brice Arl\xe9on Zemtsop Ndadji, Simon Bliudze, Cl\xe9ment Quinton"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23499",children:"https://arxiv.org/pdf/2512.23499"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u65b9\u6848\u96c6\u4e2d\u5f0f\u63a7\u5236\u4e0d\u9002\u7528\u4e8e\u5fae\u670d\u52a1/Existing centralized control ill-suited for microservices]\n    C --\x3e C1[\u57fa\u4e8eMAPE-K\u7684\u62bd\u8c61\u5c42\u4e0e\u4e8b\u4ef6\u9a71\u52a8\u89c4\u5219/MAPE-K abstraction layers & event-driven rules]\n    C --\x3e C2[\u89e3\u8026\u76d1\u63a7\u3001\u6267\u884c\u4e0e\u903b\u8f91/Decouple Monitor/Execute from adaptation logic]\n    D --\x3e D1[\u5b9e\u73b0\u4e09\u79cd\u81ea\u6cbb\u573a\u666f/Implemented three autonomy scenarios]\n    D --\x3e D2[\u53bb\u4e2d\u5fc3\u5316\u9002\u5e94\u65e0\u9700\u5168\u5c40\u534f\u8c03/Decentralized adaptation without global coordination]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [digital signal processing, computer arithmetic, high-performance computing], [energy-efficient computing, integer-friendly approximation, conflict-free memory access, fast Fourier transform, fast Schur algorithm]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sergey Salishev"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Saint Petersburg State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22676",children:"https://arxiv.org/pdf/2512.22676"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A power/energy consumption model for clocked CMOS logic to select optimal parallelism. 2. Integer-friendly approximation methods for elementary functions using constrained piecewise-polynomials to reduce lookup-table size. 3. Provably conflict-free data placement and execution order schemes for mixed-radix streaming FFT on multi-bank/single-port memories."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This thesis develops signal-processing algorithms and implementation schemes under constraints of minimal parallelism and memory space to improve energy efficiency. It proposes a power model, approximation methods, and conflict-free memory access schemes for FFT and fast Schur algorithms. The results provide constructive theorems and design trade-offs for building efficient specialized accelerators."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space<br>\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u5728\u6700\u5c0f\u5e76\u884c\u5ea6\u548c\u5185\u5b58\u7a7a\u95f4\u7ea6\u675f\u4e0b\u7684\u7efc\u5408"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Improving energy efficiency of low-power computing hardware<br>\u63d0\u9ad8\u4f4e\u529f\u8017\u8ba1\u7b97\u786c\u4ef6\u7684\u80fd\u6548"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>1. Power/energy model for CMOS logic<br>CMOS\u903b\u8f91\u529f\u8017/\u80fd\u8017\u6a21\u578b<br>2. Integer-friendly function approximation<br>\u6574\u6570\u53cb\u597d\u51fd\u6570\u8fd1\u4f3c<br>3. Conflict-free FFT schedules<br>\u65e0\u51b2\u7a81FFT\u8c03\u5ea6<br>4. Parallelism/memory analysis for fast Schur algorithm<br>\u5feb\u901fSchur\u7b97\u6cd5\u7684\u5e76\u884c\u5ea6/\u5185\u5b58\u5206\u6790"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Constructive theorems, schedules, and design trade-offs for efficient specialized accelerators<br>\u4e3a\u9ad8\u6548\u4e13\u7528\u52a0\u901f\u5668\u63d0\u4f9b\u6784\u9020\u6027\u5b9a\u7406\u3001\u8c03\u5ea6\u65b9\u6848\u548c\u8bbe\u8ba1\u6743\u8861"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [quantum computing], [hidden subgroup problem, exact quantum algorithm, distributed quantum algorithm, amplitude amplification, Chinese Remainder Theorem]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ziyuan Dong, Xiang Fan, Tengxun Zhong, Daowen Qiu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sun Yat-sen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22959",children:"https://arxiv.org/pdf/2512.22959"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new, more concise exact quantum algorithm for the finite Abelian hidden subgroup problem using amplitude amplification. 2. Introduces a distributed exact quantum algorithm for the same problem that reduces resource requirements and avoids quantum communication by leveraging the Chinese Remainder Theorem. 3. Develops a parallel exact classical algorithm with reduced query complexity, where the total queries across nodes do not exceed the centralized version under mild conditions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7feb61cf81eb163415a6709dd5e0b72019ffd85d693a4f2bc910ebd710ff58b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7feb61cf81eb163415a6709dd5e0b72019ffd85d693a4f2bc910ebd710ff58b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper revisits the finite Abelian hidden subgroup problem (AHSP). It proposes a new exact quantum algorithm, a distributed quantum algorithm that requires fewer resources and no quantum communication, and a parallel classical algorithm. The main conclusion is that these methods offer more concise, resource-efficient, and scalable solutions for solving the AHSP."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6709\u9650\u963f\u8d1d\u5c14\u9690\u85cf\u5b50\u7fa4\u95ee\u9898 / Finite Abelian Hidden Subgroup Problem]\n    C --\x3e C1[\u632f\u5e45\u653e\u5927 / Amplitude Amplification]\n    C --\x3e C2[\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406 / Chinese Remainder Theorem]\n    D --\x3e D1[\u7cbe\u786e\u91cf\u5b50\u7b97\u6cd5 / Exact Quantum Algorithm]\n    D --\x3e D2[\u5206\u5e03\u5f0f\u91cf\u5b50\u7b97\u6cd5 / Distributed Quantum Algorithm]\n    D --\x3e D3[\u5e76\u884c\u7ecf\u5178\u7b97\u6cd5 / Parallel Classical Algorithm]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," \xc5bo Akademi University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23071",children:"https://arxiv.org/pdf/2512.23071"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to \u03c1=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u6570\u636e\u4e0e\u6a21\u578b\u56fa\u6709\u7684\u7a00\u758f\u6027\u672a\u88ab\u89e3\u51b3\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5bc6\u3001\u6cdb\u5316\u6027\u5dee\uff0c\u4e14\u5b58\u5728\u6570\u636e\u548c\u5ba2\u6237\u7aef\u53c2\u4e0e\u5f02\u8d28\u6027\u3002]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u901a\u8fc7\u6982\u7387\u95e8\u53ca\u5176\u8fde\u7eed\u677e\u5f1b\u5bf9\u975e\u96f6\u53c2\u6570\u5bc6\u5ea6\u65bd\u52a0L0\u7ea6\u675f\uff0c\u76ee\u6807\u6e90\u81ea\u968f\u673a\u95e8\u7684\u71b5\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u8054\u90a6\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u3002]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u5728\u6570\u636e\u548c\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u4e0b\uff0c\u80fd\u8fbe\u5230\u76ee\u6807\u5bc6\u5ea6(\u03c1)\uff0c\u7edf\u8ba1\u6027\u80fd\u635f\u5931\u6700\u5c0f\uff0c\u4e14\u6bd4\u57fa\u4e8e\u5e45\u5ea6\u7684\u526a\u679d\u65b9\u6cd5\u66f4\u4f18\u3001\u901a\u4fe1\u9ad8\u6548\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 50'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Unbiased Visual Reasoning with Controlled Visual Inputs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [vision-language models, spurious correlations, information bottleneck, reinforcement learning, modular reasoning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22183",children:"https://arxiv.org/pdf/2512.22183"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Unbiased Visual Reasoning with Controlled Visual Inputs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[VLMs exploit spurious correlations/VLMs\u5229\u7528\u865a\u5047\u5173\u8054]\n    C --\x3e C1[VISTA: Modular framework decoupling perception & reasoning/VISTA: \u89e3\u8026\u611f\u77e5\u4e0e\u63a8\u7406\u7684\u6a21\u5757\u5316\u6846\u67b6]\n    C1 --\x3e C2[Frozen VLM sensor + LLM reasoner/\u51bb\u7ed3VLM\u611f\u77e5\u5668 + LLM\u63a8\u7406\u5668]\n    C2 --\x3e C3[Train with RL (GRPO)/\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60(GRPO)\u8bad\u7ec3]\n    D --\x3e D1[Improved robustness on SpuriVerse/\u5728SpuriVerse\u4e0a\u9c81\u68d2\u6027\u63d0\u5347]\n    D --\x3e D2[Competitive on MMVP & SeedBench/\u5728MMVP & SeedBench\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b]\n    D --\x3e D3[Transferable & interpretable/\u53ef\u8fc1\u79fb\u4e14\u53ef\u89e3\u91ca]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Dueling Double Deep Q-Network, curriculum learning, tennis simulation, sequential decision-making, sports analytics]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vishnu Mohan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22186",children:"https://arxiv.org/pdf/2512.22186"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed a custom tennis simulation environment that models hierarchical scoring, tactical decisions, fatigue, and opponent skill. 2. Integrated a Dueling Double Deep Q-Network (DDQN) with curriculum learning to enable stable and effective strategy learning in a long-horizon, stochastic domain. 3. Identified a key limitation of win-rate optimization, revealing a learned defensive bias and highlighting challenges in reward design for sports RL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a reinforcement learning framework using a Dueling Double Deep Q-Network trained with curriculum learning to optimize tennis strategy in a custom simulation. The method achieves high win rates and demonstrates stable convergence, but analysis reveals the learned policy is overly defensive, pointing to a fundamental issue with reward design in sports simulations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Tennis strategy optimization as a sequential decision-making challenge with hierarchical scoring, stochasticity, and opponent adaptation)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Dueling Double Deep Q-Network (DDQN) trained with curriculum learning in a custom tennis simulation environment)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: High win rates (98-100%) and stable convergence, but reveals a defensive policy bias, highlighting reward design limitations)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part I: Basic Concepts, Neural Networks, and Variants"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [prognostics & health management (phm)], [Neural Networks, Convolutional Neural Networks, Reinforcement Learning, Uncertainty Quantification, Physics-Informed Machine Learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jose I. Aizpurua"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of the Basque Country (UPV/EHU)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22190",children:"https://arxiv.org/pdf/2512.22190"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the application of Neural Networks (NNs) and their variants, specifically Convolutional Neural Networks (CNNs), for transformer condition monitoring using diverse data modalities. 2. Discusses the integration of NN concepts within the Reinforcement Learning (RL) paradigm for decision-making and control in transformer health management. 3. Provides perspectives on emerging research directions at the intersection of physics-informed machine learning and transformer Prognostics & Health Management (PHM)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of traditional, rule-based transformer condition monitoring by proposing the use of machine learning, particularly Neural Networks and their variants. It explores Convolutional Neural Networks for processing diverse sensor data and discusses Reinforcement Learning for control, concluding that physics-informed ML provides a powerful framework for more accurate diagnostics, prognostics, and decision-making in power transformer health management."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Physics-Informed ML for Transformer Condition Monitoring \u2013 Part I"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Traditional monitoring struggles with uncertainty & complexity"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Use Neural Networks, CNNs, and Reinforcement Learning"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Enables accurate diagnostics, prognostics, and control"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [intrinsic motivation, homeostatic control, adaptive optimization, non-stationary learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dhruv Tiwari"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Lovely Professional University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22200",children:"https://arxiv.org/pdf/2512.22200"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework, Emotion-Inspired Learning Signals (EILS), that models emotions as continuous, homeostatic appraisal signals (e.g., Curiosity, Stress, Confidence) for adaptive control. 2. Formalizes these signals as vector-valued internal states derived from interaction history to dynamically modulate the agent's optimization landscape in real-time. 3. Hypothesizes that this closed-loop homeostatic regulation enables superior sample efficiency and adaptation to non-stationary environments compared to standard baselines like PPO."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies the fragility of standard AI agents that rely on static, external rewards in open-ended environments. It proposes the Emotion-Inspired Learning Signals (EILS) framework, which uses bio-inspired internal signals like curiosity and stress to dynamically control learning. The authors hypothesize this approach will lead to more robust, adaptive, and sample-efficient autonomous agents."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[EILS: A Homeostatic Framework] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u9759\u6001\u5916\u90e8\u5956\u52b1/Static Extrinsic Reward]\n    Problem --\x3e P2[\u8106\u5f31\u6027\uff0c\u65e0\u6cd5\u9002\u5e94/Fragile, Non-Adaptive]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u60c5\u7eea\u542f\u53d1\u4fe1\u53f7/Emotion-Inspired Signals]\n    Method --\x3e M2[\u52a8\u6001\u7a33\u6001\u8c03\u8282/Dynamic Homeostatic Control]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u5047\u8bbe: \u66f4\u9ad8\u6837\u672c\u6548\u7387/Hypothesis: Higher Sample Efficiency]\n    Results --\x3e R2[\u5047\u8bbe: \u66f4\u597d\u975e\u5e73\u7a33\u9002\u5e94/Hypothesis: Better Non-Stationary Adaptation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Innovation Institute, OpenMoss Team"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22234",children:"https://arxiv.org/pdf/2512.22234"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/OpenMOSS/DiRL",children:"https://github.com/OpenMOSS/DiRL"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[dLLMs\u540e\u8bad\u7ec3\u4f4e\u6548/Post-training for dLLMs is inefficient]\n    B --\x3e B2[\u8bad\u7ec3\u4e0e\u63a8\u7406\u76ee\u6807\u4e0d\u5339\u914d/Training-Inference objective mismatch]\n    C --\x3e C1[DiRL\u6846\u67b6/DiRL Framework]\n    C1 --\x3e C1_1[\u6574\u5408FlexAttention\u4e0eLMDeploy/Integrates FlexAttention & LMDeploy]\n    C1 --\x3e C1_2[\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3/Two-stage post-training (SFT+RL)]\n    C --\x3e C2[DiPO\u7b97\u6cd5/DiPO Algorithm]\n    C2 --\x3e C2_1[\u65e0\u504fGRPO\u5b9e\u73b0/Unbiased GRPO for dLLMs]\n    D --\x3e D1[\u9ad8\u6548\u8bad\u7ec3\u4e0e\u63a8\u7406/Efficient Training & Inference]\n    D --\x3e D2[\u6570\u5b66SOTA\u6027\u80fd/Math SOTA Performance]\n    D --\x3e D3[\u8d85\u8d8aQwen2.5\u7cfb\u5217/Surpasses Qwen2.5 series]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [knowledge distillation, reinforcement learning, vision-language models, progressive masking, offline RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," NVIDIA"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22238",children:"https://arxiv.org/pdf/2512.22238"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Masters, a mask-progressive RL distillation framework that first masks non-dominant teacher weights to reduce complexity and then progressively restores them for stable student learning. 2. Introduces an offline RL stage with complementary accuracy and distillation rewards, leveraging pre-generated responses from masked teachers for efficient guidance. 3. Demonstrates that progressive teacher scaling (e.g., from 14B to 38B) yields smoother convergence and stronger generalization than one-shot distillation, providing a scalable path to efficient VLMs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of distilling large vision-language models (VLMs) into compact ones by proposing Masters, a framework that uses progressive masking of the teacher model and offline reinforcement learning. This method enables stable knowledge transfer and efficient training, resulting in small VLMs that achieve strong performance, sometimes surpassing larger models, while being far more efficient for deployment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Masking Teacher and Reinforcing Student for Distilling Vision-Language Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5927\u578bVLM\u96be\u4ee5\u90e8\u7f72\u5230\u79fb\u52a8/\u8fb9\u7f18\u8bbe\u5907/Large VLMs are impractical for mobile/edge deployment]\n    B --\x3e B2[\u5e08\u751f\u6a21\u578b\u5c3a\u5bf8\u5dee\u8ddd\u5bfc\u81f4\u77e5\u8bc6\u84b8\u998f\u4e0d\u7a33\u5b9a/Large size gap causes unstable distillation]\n    C --\x3e C1[\u63a9\u7801\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u84b8\u998f\u6846\u67b6/Mask-progressive RL distillation framework]\n    C --\x3e C2[\u5148\u63a9\u7801\u6559\u5e08\u975e\u4e3b\u5bfc\u6743\u91cd\uff0c\u518d\u6e10\u8fdb\u6062\u590d/First mask non-dominant teacher weights, then progressively restore]\n    C --\x3e C3[\u79bb\u7ebfRL\u9636\u6bb5\u4f7f\u7528\u51c6\u786e\u6027\u548c\u84b8\u998f\u5956\u52b1/Offline RL stage with accuracy and distillation rewards]\n    D --\x3e D1[\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u7d27\u51d1\u578bVLM/Outperforms existing compact VLMs on diverse benchmarks]\n    D --\x3e D2[\u6e10\u8fdb\u589e\u52a0\u6559\u5e08\u5c3a\u5bf8\u5e26\u6765\u66f4\u5e73\u6ed1\u6536\u655b\u548c\u66f4\u5f3a\u6cdb\u5316/Gradually increasing teacher size yields smoother convergence & stronger generalization]\n    D --\x3e D3[\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u90e8\u7f72VLM\u7684\u53ef\u6269\u5c55\u8def\u5f84/Provides a scalable path toward efficient, deployable VLMs]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhonghao Jiang, David Lo, Zhongxin Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Singapore Management University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22256",children:"https://arxiv.org/pdf/2512.22256"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/ZhonghaoJiang/Awesome-Issue-Solving",children:"https://github.com/ZhonghaoJiang/Awesome-Issue-Solving"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Agentic Software Issue Resolution with LLMs: A Survey] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\uff0c\u6548\u7387\u4f4e/Traditional methods rely on human expertise, inefficient]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf/LLM-based Agentic Systems]\n    Method --\x3e M2[\u7cfb\u7edf\u7efc\u8ff0126\u9879\u7814\u7a76/Systematic survey of 126 studies]\n    Method --\x3e M3[\u5efa\u7acb\u4e09\u7ef4\u5206\u7c7b\u6cd5/Establishes a 3D taxonomy]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u589e\u5f3a\u8f6f\u4ef6\u7ef4\u62a4\u6548\u7387/Enhances software maintenance efficiency]\n    Results --\x3e R2[\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u9a8c\u8bc1\u73af\u5883/Provides a validation environment for agentic systems]\n    Results --\x3e R3[\u603b\u7ed3\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411/Summarizes challenges & future directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [video understanding], [agentic framework, temporal zoom, reinforcement learning, long video reasoning, multimodal large language models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yang Ding, Yizhen Zhang, Xin Lai, Ruihang Chu, Yujiu Yang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, The Chinese University of Hong Kong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22315",children:"https://arxiv.org/pdf/2512.22315"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/zsgvivo/VideoZoomer",children:"https://github.com/zsgvivo/VideoZoomer"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VideoZoomer, a novel agentic framework that enables MLLMs to dynamically control visual focus during reasoning for long videos. 2. Introduces a two-stage training strategy combining supervised fine-tuning on distilled trajectories with reinforcement learning to refine the agentic policy. 3. Demonstrates strong performance across long video benchmarks, surpassing open-source models and rivaling proprietary systems with superior efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of Multimodal LLMs in understanding long videos due to context window constraints. It proposes VideoZoomer, an agentic framework that dynamically selects and zooms into key temporal moments for fine-grained evidence gathering, trained with a two-stage strategy. The resulting 7B model achieves state-of-the-art performance on long video reasoning benchmarks with high efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u957f\u89c6\u9891\u7406\u89e3\u53d7\u9650/Limited Long Video Understanding]\n    B1 --\x3e B2[\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236/Context Window Limitation]\n    B1 --\x3e B3[\u5747\u5300\u91c7\u6837\u5ffd\u7565\u5173\u952e\u8bc1\u636e/Uniform Sampling Overlooks Evidence]\n    C --\x3e C1[\u4ee3\u7406\u6846\u67b6/Agentic Framework]\n    C1 --\x3e C2[\u52a8\u6001\u65f6\u95f4\u805a\u7126/Dynamic Temporal Focusing]\n    C2 --\x3e C3[\u4ece\u7c97\u5230\u7ec6\u63a8\u7406/Coarse-to-Fine Reasoning]\n    C --\x3e C4[\u4e24\u9636\u6bb5\u8bad\u7ec3/Two-Stage Training]\n    C4 --\x3e C5[\u76d1\u7763\u5fae\u8c03/Supervised Fine-Tuning]\n    C4 --\x3e C6[\u5f3a\u5316\u5b66\u4e60/Reinforcement Learning]\n    D --\x3e D1[\u6027\u80fd\u5f3a\u52b2/Strong Performance]\n    D1 --\x3e D2[\u8d85\u8d8a\u5f00\u6e90\u6a21\u578b/Surpasses Open-Source Models]\n    D1 --\x3e D3[\u5ab2\u7f8e\u4e13\u6709\u7cfb\u7edf/Rivals Proprietary Systems]\n    D --\x3e D4[\u9ad8\u6548\u63a8\u7406/Efficient Reasoning]\n    D4 --\x3e D5[\u4f4e\u5e27\u9884\u7b97/Reduced Frame Budget]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Peking University, Tencent"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22322",children:"https://arxiv.org/pdf/2512.22322"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://huggingface.co/collections/yolay/smartsnap",children:"https://huggingface.co/collections/yolay/smartsnap"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]\n    D[\u5173\u952e\u7ed3\u679c/Results: Performance gains up to 26.08%; competitive with larger models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [Cyber-Physical Systems Security], [False Data Injection (FDI), Physics-Informed Neural Network (PINN), Multi-Agent Reinforcement Learning (MARL)]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mohammad Zakaria Haider, Amit Kumar Podder, Prabin Mali, Aranya Chakrabortty, Sumit Paudyal, Mohammad Ashiqur Rahman"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Florida International University, North Carolina State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22381",children:"https://arxiv.org/pdf/2512.22381"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes PHANTOM, a physics-aware adversarial attack framework that integrates a federated learning-enabled PINN as a digital twin for accurate modeling of EV charging systems. 2. Develops a multi-agent RL environment using DQN and SAC to generate stealthy FDI attack strategies that bypass conventional detection. 3. Constructs a T&D co-simulation platform to demonstrate the cascading, cross-boundary grid impacts (e.g., load imbalance, voltage instability) of the learned attacks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes PHANTOM, a physics-aware adversarial attack framework against federated learning-coordinated EV charging management. It uses a PINN-based digital twin and multi-agent RL to generate stealthy false data injection attacks, which are shown through co-simulation to cause significant grid instability, highlighting the need for physics-aware cybersecurity in vehicle-grid integration."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[PHANTOM: Physics-Aware Adversarial Attacks] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: EV Charging Grid Security)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: PINN Digital Twin + Multi-Agent RL)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Stealthy Attacks Cause Grid Instability)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [LoRA, Parameter-Efficient Fine-Tuning, Activation Function Annealing, Non-linear Adaptation, Model Merging]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Meituan, Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22455",children:"https://arxiv.org/pdf/2512.22455"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method's effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>LoRA\u7ebf\u6027\u9002\u914d\u7684\u8868\u8fbe\u80fd\u529b\u6709\u9650<br>LoRA's linear adaptation limits expressive power]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5f15\u5165\u9000\u706b\u6fc0\u6d3b\u51fd\u6570<br>Introduce annealed activation function]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u7f29\u5c0fLoRA\u4e0e\u5168\u53c2\u6570\u8bad\u7ec3\u7684\u5dee\u8ddd<br>Reduces gap between LoRA and full-parameter training]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] FinPercep-RM: A Fine-grained Reward Model and Co-evolutionary Curriculum for RL-based Real-world Super-Resolution"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [image super-resolution], [reinforcement learning from human feedback (RLHF), reward hacking, perceptual quality, curriculum learning, fine-grained assessment]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yidi Liu, Zihao Fan, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Xueyang Fu, Zheng-Jun Zha"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, Shanghai AI Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22647",children:"https://arxiv.org/pdf/2512.22647"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Fine-grained Perceptual Reward Model (FinPercep-RM) with an encoder-decoder architecture that outputs both a global quality score and a Perceptual Degradation Map to localize defects. 2. Introduces the FGR-30k dataset containing diverse and subtle distortions from real-world super-resolution models for training the reward model. 3. Designs a Co-evolutionary Curriculum Learning (CCL) mechanism that synchronizes the progressive training of the reward model and the ISR model to ensure stable training and suppress reward hacking."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1738fd28b1410f3f5c393bd5d70851ae8df2e1196df6379de62b5d7d48c736b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1738fd28b1410f3f5c393bd5d70851ae8df2e1196df6379de62b5d7d48c736b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of reward hacking in RLHF-based Image Super-Resolution, where traditional Image Quality Assessment models are insensitive to local distortions. The authors propose a fine-grained reward model (FinPercep-RM) and a co-evolutionary curriculum learning strategy to provide localized feedback and stabilize training. Experiments show the method improves both global quality and local realism in generated images."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[FinPercep-RM: A Fine-grained Reward Model and Co-evolutionary Curriculum for RL-based Real-world Super-Resolution] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>\u4f20\u7edfIQA\u6a21\u578b\u5bf9\u5c40\u90e8\u5931\u771f\u4e0d\u654f\u611f\uff0c\u5bfc\u81f4\u5956\u52b1\u6b3a\u9a97/Reward Hacking]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>1. \u7ec6\u7c92\u5ea6\u611f\u77e5\u5956\u52b1\u6a21\u578b (FinPercep-RM)<br>2. \u534f\u540c\u8fdb\u5316\u8bfe\u7a0b\u5b66\u4e60 (CCL)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u63d0\u5347\u5168\u5c40\u8d28\u91cf\u4e0e\u5c40\u90e8\u771f\u5b9e\u611f\uff0c\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3/Improves global quality & local realism, enables stable training]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [State-Dependent Riccati Equation (SDRE), Integral Reinforcement Learning (IRL), Algebraic Riccati Equation (ARE), Nonlinear Input-Affine Systems, Optimal Regulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Arya Rashidinejad Meibodi, Mahbod Gholamali Sinaki, Khalil Alipour"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Tehran, K. N. Toosi University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22668",children:"https://arxiv.org/pdf/2512.22668"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a partially model-free method for solving the State-Dependent Riccati Equation (SDRE) for nonlinear system control, eliminating the need for explicit drift dynamics knowledge. 2. Integrates Integral Reinforcement Learning (IRL) to learn the optimal control policy at each system state by solving the Algebraic Riccati Equation (ARE) online. 3. Demonstrates through simulation on a second-order nonlinear system that the IRL-based approach achieves performance comparable to the classical, model-dependent SDRE method."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4e534b9bbeb92e0817df99e432bb5925d48ed82bbc2dcc8e61dbc7faff88ee3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4e534b9bbeb92e0817df99e432bb5925d48ed82bbc2dcc8e61dbc7faff88ee3_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the optimal regulation of nonlinear input-affine systems. It proposes a novel method that combines the State-Dependent Riccati Equation (SDRE) framework with Integral Reinforcement Learning (IRL) to learn optimal control without requiring a complete system model. Simulation results show that this IRL-based approach can achieve performance similar to the traditional model-dependent SDRE technique."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Optimal Regulation of Nonlinear Input-Affine Systems via an IRL-Based SDRE Approach] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edfSDRE\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u7cfb\u7edf\u6a21\u578b/Traditional SDRE requires full model]\n    C --\x3e C1[\u4f7f\u7528\u79ef\u5206\u5f3a\u5316\u5b66\u4e60(IRL)\u5728\u7ebf\u6c42\u89e3ARE/Uses IRL to solve ARE online]\n    C --\x3e C2[\u90e8\u5206\u514d\u6a21\u578b\uff0c\u65e0\u9700\u6f02\u79fb\u52a8\u529b\u5b66\u77e5\u8bc6/Partially model-free, no drift dynamics]\n    D --\x3e D1[\u6027\u80fd\u63a5\u8fd1\u4f20\u7edfSDRE\u65b9\u6cd5/Performance matches traditional SDRE]\n    D --\x3e D2[\u4e3a\u975e\u7ebf\u6027\u63a7\u5236\u63d0\u4f9b\u53ef\u9760\u66ff\u4ee3\u65b9\u6848/Provides reliable alternative for nonlinear control]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Memento-II: Learning by Stateful Reflective Memory"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [stateful reflective decision process, episodic memory, policy iteration, continual learning, retrieval-augmented generation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jun Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University College London (UCL)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22716",children:"https://arxiv.org/pdf/2512.22716"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Stateful Reflective Decision Process (SRDP), a formal theoretical framework that models continual learning in LLM agents as a two-stage read-write interaction with episodic memory, linking it to policy evaluation and improvement. 2. Provides a theoretical analysis showing that the reflective learning process induces an equivalent Markov Decision Process, enabling the use of classical dynamic programming and RL tools, and establishes convergence guarantees when instantiated with entropy-regularised policy iteration. 3. Unifies heuristic approaches like case-based reasoning and retrieval-augmented generation with principled reinforcement learning, offering a rigorous mathematical foundation for building memory-augmented agents capable of online adaptation without parameter updates."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a theoretical framework for continual learning in LLM agents that uses episodic memory and reflection instead of back-propagation. The core method formalizes learning as a Stateful Reflective Decision Process, where writing to memory is policy evaluation and reading from it is policy improvement. The main conclusion is that this framework provides a principled, convergent foundation for agents to self-improve through interaction without fine-tuning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Memento-II: Learning by Stateful Reflective Memory] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca/Lack of theoretical explanation for memory-based continual learning in LLM agents]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u72b6\u6001\u5316\u53cd\u601d\u51b3\u7b56\u8fc7\u7a0b/Stateful Reflective Decision Process (SRDP) with read-write episodic memory]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u4e0e\u6536\u655b\u4fdd\u8bc1/Provides theoretical framework and convergence guarantees for optimal policy]\n    C --\x3e E[\u5199\u5165\u5bf9\u5e94\u7b56\u7565\u8bc4\u4f30/Writing corresponds to policy evaluation]\n    C --\x3e F[\u8bfb\u53d6\u5bf9\u5e94\u7b56\u7565\u6539\u8fdb/Reading corresponds to policy improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Cyber Resilience in Next-Generation Networks: Threat Landscape, Theoretical Foundations, and Design Paradigms"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [network security], [software-defined networking, network function virtualization, zero trust architecture, reinforcement learning, large language models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Junaid Farooq, Quanyan Zhu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Michigan-Dearborn, New York University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22721",children:"https://arxiv.org/pdf/2512.22721"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides an interdisciplinary survey and analysis of the evolving threat landscape for next-generation networks, including AI-driven threats. 2. Establishes rigorous definitions and evaluation frameworks for cyber resilience that extend beyond traditional robustness and fault-tolerance. 3. Delves into advanced design paradigms and practical strategies, such as zero trust architectures and AI-enabled autonomous network control, for building resilient systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45ce5f50020bb828e3588c3731b7d026aa73f3b8a029ede8f411eb0dc5e35dad_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45ce5f50020bb828e3588c3731b7d026aa73f3b8a029ede8f411eb0dc5e35dad_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This book examines the challenge of achieving cyber resilience in next-generation networks, which are characterized by technologies like SDN and NFV. It proposes a re-conceptualized framework for resilience and explores advanced design paradigms, including AI-driven methods, to enable adaptive and autonomous threat response. The main conclusion is that a fundamental redesign of resilience mechanisms is required to secure the evolving, heterogeneous network infrastructure."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Cyber Resilience in Next-Generation Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4e0b\u4e00\u4ee3\u7f51\u7edc\u5a01\u80c1\u683c\u5c40\u6f14\u53d8 / Evolving Threat Landscape in Next-Gen Networks]\n    C --\x3e C1[\u5efa\u7acb\u5f39\u6027\u5b9a\u4e49\u4e0e\u8bc4\u4f30\u6846\u67b6 / Establishing Resilience Definitions & Evaluation Frameworks]\n    C --\x3e C2[\u63a2\u7d22\u5148\u8fdb\u5f39\u6027\u8bbe\u8ba1\u8303\u5f0f / Exploring Advanced Resilience Design Paradigms]\n    C1 --\x3e C1a[\u8d85\u8d8a\u9c81\u68d2\u6027\u4e0e\u5bb9\u9519 / Beyond Robustness & Fault-Tolerance]\n    C2 --\x3e C2a[\u96f6\u4fe1\u4efb\u67b6\u6784 / Zero Trust Architecture]\n    C2 --\x3e C2b[AI\u4e0eLLM\u9a71\u52a8\u54cd\u5e94 / AI & LLM-Driven Response]\n    D --\x3e D1[\u9700\u8981\u91cd\u65b0\u6982\u5ff5\u5316\u7f51\u7edc\u5f39\u6027 / Need to Re-conceptualize Network Resilience]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [context folding, long-horizon RL, non-stationary observation, gradient dilution, selective segment training]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jiaqi Shao, Yufeng Miao, Wei Zhang, Bing Luo"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Hong Kong University of Science and Technology, Duke Kunshan University, Microsoft AI"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22733",children:"https://arxiv.org/pdf/2512.22733"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/SHAO-Jiaqi757/FoldAct",children:"https://github.com/SHAO-Jiaqi757/FoldAct"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Separated loss computation for independent gradient signals on summary and action tokens to address gradient dilution. 2. Full context consistency loss to reduce distribution shift caused by policy-dependent observation changes. 3. Selective segment training to reduce computational cost by processing unique contexts efficiently."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that treating context folding (history summarization) as a standard action in long-horizon RL for LLMs creates a non-stationary observation distribution, leading to training instability and inefficiency. It proposes FoldAct, a framework with three innovations\u2014separated loss, consistency loss, and selective training\u2014to stabilize training and improve efficiency. The method achieves stable training and a 5.19\xd7 speedup."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u975e\u5e73\u7a33\u89c2\u6d4b\u5206\u5e03 / Non-stationary Observation Distribution]\n    B --\x3e B2[\u68af\u5ea6\u7a00\u91ca / Gradient Dilution]\n    B --\x3e B3[\u8ba1\u7b97\u6210\u672c\u9ad8 / High Computational Cost]\n    C --\x3e C1[\u5206\u79bb\u635f\u5931\u8ba1\u7b97 / Separated Loss Computation]\n    C --\x3e C2[\u5168\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u635f\u5931 / Full Context Consistency Loss]\n    C --\x3e C3[\u9009\u62e9\u6027\u7247\u6bb5\u8bad\u7ec3 / Selective Segment Training]\n    D --\x3e D1[\u7a33\u5b9a\u8bad\u7ec3 / Stable Training]\n    D --\x3e D2[5.19\u500d\u52a0\u901f / 5.19\xd7 Speedup]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] ReDiF: Reinforced Distillation for Few Step Diffusion"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [reinforcement learning, knowledge distillation, policy optimization, denoising paths, model agnostic]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Amirhossein Tighkhorshid, Zahra Dehghanian, Gholamali Aminian, Chengchun Shi, Hamid R. Rabiee"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sharif University of Technology, Alan Turing Institute, London School of Economics"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22802",children:"https://arxiv.org/pdf/2512.22802"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel reinforcement learning framework for distilling diffusion models, treating distillation as a policy optimization problem. 2. Introduces a reward signal based on alignment with teacher outputs, allowing the student model to explore multiple denoising paths and take longer, optimized steps. 3. Demonstrates a model-agnostic framework that achieves superior performance with fewer inference steps and computational resources compared to existing distillation techniques."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the slow sampling problem in diffusion models by proposing ReDiF, a reinforcement learning-based distillation framework. Instead of using fixed losses, it treats distillation as policy optimization, using a reward signal to guide the student to take longer, optimized steps. The method achieves better performance with fewer steps and is applicable to various diffusion models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ReDiF: Reinforced Distillation for Few Step Diffusion] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Diffusion\u6a21\u578b\u91c7\u6837\u6162/Slow sampling in diffusion models)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u84b8\u998f\u6846\u67b6/Reinforcement learning based distillation framework)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u66f4\u5c11\u6b65\u9aa4\uff0c\u6027\u80fd\u66f4\u4f18/Fewer steps, superior performance)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22796",children:"https://arxiv.org/pdf/2512.22796"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method's flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Parallel Diffusion Solver via Residual Dirichlet Policy Optimization] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6269\u6563\u6a21\u578b\u91c7\u6837\u5ef6\u8fdf\u9ad8 / High sampling latency of DMs]\n    B --\x3e B2[\u73b0\u6709\u6c42\u89e3\u5668\u5728\u4f4e\u6b65\u6570\u4e0b\u8d28\u91cf\u4e0b\u964d / Existing solvers degrade quality at low NFEs]\n    C --\x3e C1[EPD-Solver: \u96c6\u6210\u5e76\u884c\u65b9\u5411\u6c42\u89e3\u5668 / Ensemble Parallel Direction solver]\n    C --\x3e C2[\u4e24\u9636\u6bb5\u4f18\u5316: \u84b8\u998f + RL\u5fae\u8c03 / Two-stage optimization: Distillation + RL fine-tuning]\n    C --\x3e C3[\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u5347\u73b0\u6709\u6c42\u89e3\u5668 / Plugin (EPD-Plugin) for existing samplers]\n    D --\x3e D1[\u4f4e\u5ef6\u8fdf\u4e0bSOTA FID\u5206\u6570 / SOTA FID scores at low latency]\n    D --\x3e D2[\u5728T2I\u4efb\u52a1\u4e2d\u63d0\u5347\u4eba\u7c7b\u504f\u597d\u5206\u6570 / Improved human preference scores in T2I]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Gaurav Chaudhary, Laxmidhar Behera"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IIT Kanpur"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22824",children:"https://arxiv.org/pdf/2512.22824"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Uniform goal selection is sample inefficient in multi-goal RL/\u591a\u76ee\u6807RL\u4e2d\u5747\u5300\u76ee\u6807\u9009\u62e9\u6837\u672c\u6548\u7387\u4f4e]\n    C --\x3e C1[Student-Teacher paradigm with Temporal Variance-Driven Curriculum/\u57fa\u4e8e\u65f6\u5e8f\u65b9\u5dee\u7684\u5e08\u751f\u8bfe\u7a0b\u5b66\u4e60\u8303\u5f0f]\n    C --\x3e C2[Teacher prioritizes goals with highest Q-value temporal variance/\u6559\u5e08\u6a21\u5757\u4f18\u5148\u9009\u62e9Q\u503c\u65f6\u5e8f\u65b9\u5dee\u6700\u9ad8\u7684\u76ee\u6807]\n    D --\x3e D1[Consistent improvements over SOTA methods/\u76f8\u6bd4SOTA\u65b9\u6cd5\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb]\n    D --\x3e D2[Evaluated on 11 robotic manipulation and navigation tasks/\u572811\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4e0e\u5bfc\u822a\u4efb\u52a1\u4e0a\u9a8c\u8bc1]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [reflective policy optimization, asymmetric clipping, sample efficiency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Cuiling Wu, Yaozhong Gan, Junliang Xing, Ying Fu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing Institute of Technology, QiYuan Lab"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22832",children:"https://arxiv.org/pdf/2512.22832"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency. 2. Introduces an asymmetric clipping mechanism derived from KL divergence to dynamically adjust the clipping range for improved training stability. 3. Validates the proposed MARPO framework on complex multi-agent benchmarks, demonstrating superior performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes MARPO, a new multi-agent reinforcement learning method to address sample inefficiency. It introduces a reflection mechanism to use trajectory information and an asymmetric clipping mechanism for stable training. The method is shown to outperform existing approaches in standard multi-agent environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[MARPO: A Reflective Policy Optimization for Multi-Agent Reinforcement Learning] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Sample inefficiency in MARL] --\x3e P1[\u6311\u6218/Challenge: High interaction cost]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: MARPO Framework] --\x3e M1[\u53cd\u5c04\u673a\u5236/Reflection Mechanism: Leverages subsequent trajectories]\n    Method --\x3e M2[\u975e\u5bf9\u79f0\u88c1\u526a/Asymmetric Clipping: KL-based dynamic adjustment]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Outperforms other methods] --\x3e R1[\u8bc4\u4f30/Evaluation: Classic multi-agent environments]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [automated environment synthesis, environment-level RL, agentic reinforcement learning, simulated user, policy optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tongyi Lab, Alibaba Group"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22857",children:"https://arxiv.org/pdf/2512.22857"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AutoForge] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73af\u5883\u5408\u6210\u534a\u81ea\u52a8/Semi-automated Environment Synthesis]\n    B --\x3e B2[\u4efb\u52a1\u96be\u5ea6\u4e0d\u8db3/Insufficient Task Difficulty]\n    B --\x3e B3[\u6a21\u62df\u7528\u6237\u4e0d\u7a33\u5b9a/Simulated User Instability]\n    C --\x3e C1[\u81ea\u52a8\u5316\u73af\u5883\u5408\u6210\u7ba1\u9053/Automated Environment Synthesis Pipeline]\n    C --\x3e C2[\u73af\u5883\u7ea7RL\u7b97\u6cd5/Environment-level RL Algorithm (ERPO)]\n    D --\x3e D1[\u57fa\u51c6\u6d4b\u8bd5\u6709\u6548/Effective on Benchmarks (\u03c4-bench, etc.)]\n    D --\x3e D2[\u57df\u5916\u6cdb\u5316\u5f3a/Strong Out-of-domain Generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Northeastern University, Dwarkadas J. Sanghvi College of Engineering"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22860",children:"https://arxiv.org/pdf/2512.22860"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Adaptive Trust Consensus for Blockchain IoT<br/>\u533a\u5757\u94fe\u7269\u8054\u7f51\u81ea\u9002\u5e94\u4fe1\u4efb\u5171\u8bc6"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["Securing Blockchain IoT Against Attacks<br/>\u4fdd\u62a4\u533a\u5757\u94fe\u7269\u8054\u7f51\u514d\u53d7\u653b\u51fb"] --\x3e A1["Naive Malicious Attack (NMA)<br/>\u7b80\u5355\u6076\u610f\u653b\u51fb"]\n    Problem --\x3e A2["Collusive Rumor Attack (CRA)<br/>\u5408\u8c0b\u8c23\u8a00\u653b\u51fb"]\n    Problem --\x3e A3["Adaptive Adversarial Attack (AAA)<br/>\u81ea\u9002\u5e94\u5bf9\u6297\u653b\u51fb"]\n    Problem --\x3e A4["Byzantine Fault Injection (BFI)<br/>\u62dc\u5360\u5ead\u6545\u969c\u6ce8\u5165"]\n    Problem --\x3e A5["Time-Delayed Poisoning (TDP)<br/>\u65f6\u95f4\u5ef6\u8fdf\u6295\u6bd2"]\n\n    Method["Trust Framework with FHE & ABAC + Learning Defenses<br/>\u57fa\u4e8eFHE\u548cABAC\u7684\u4fe1\u4efb\u6846\u67b6\u4e0e\u5b66\u4e60\u9632\u5fa1"] --\x3e M1["Reinforcement Learning (RL)<br/>\u5f3a\u5316\u5b66\u4e60"]\n    Method --\x3e M2["Deep RL (DRL)<br/>\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60"]\n    Method --\x3e M3["Multi-Agent RL (MARL)<br/>\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60"]\n\n    Results["Key Experimental Findings<br/>\u5173\u952e\u5b9e\u9a8c\u7ed3\u679c"] --\x3e R1["MARL best vs. Collusive Attacks<br/>MARL\u5bf9\u5408\u8c0b\u653b\u51fb\u6700\u4f73"]\n    Results --\x3e R2["DRL & MARL perfect vs. Adaptive Attacks<br/>DRL\u548cMARL\u5b8c\u7f8e\u9632\u5fa1\u81ea\u9002\u5e94\u653b\u51fb"]\n    Results --\x3e R3["All agents fail vs. Time-Delayed Poisoning<br/>\u6240\u6709\u667a\u80fd\u4f53\u5728\u5ef6\u8fdf\u6295\u6bd2\u653b\u51fb\u4e0b\u5931\u6548"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22876",children:"https://arxiv.org/pdf/2512.22876"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Reinforcement Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: End-to-end training of multi-component AI systems]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: MARL agents organized in a DAG (Reinforcement Networks)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improved performance, unified framework for structured MARL]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [hierarchical deep reinforcement learning, portfolio management, dynamic asset grouping, utility-based capital allocation, SHAP interpretability]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xiaotian Ren, Nuerxiati Abudurexiti, Zhengyong Jiang, Angelos Stefanidis, Hongbin Liu, Jionglong Su"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided content."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22895",children:"https://arxiv.org/pdf/2512.22895"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a hierarchical DRL framework (SAMP-HDRL) that integrates dynamic asset grouping, upper-lower agent coordination, and a utility-based capital allocation mechanism for robust portfolio management. 2. Demonstrates superior performance through extensive backtests across multiple market regimes, showing consistent improvements in return and risk-adjusted metrics over traditional and DRL baselines. 3. Provides interpretability via SHAP analysis, revealing a complementary "diversified + concentrated" decision pattern across agent layers.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles portfolio optimization in non-stationary markets by proposing SAMP-HDRL, a hierarchical deep reinforcement learning framework that segments assets, coordinates global and local agents, and uses a utility-based capital allocator. The method outperforms numerous baselines in backtests, achieving higher returns and risk-adjusted ratios, and its decisions are made interpretable through SHAP analysis, revealing a combined diversified and concentrated investment strategy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root[SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Portfolio optimization in non-stationary markets with regime shifts and limited DRL interpretability] --\x3e P1[\u6311\u6218/Challenges: Dynamic correlations, regime shifts]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Hierarchical DRL with segmented allocation] --\x3e M1[\u4e0a\u5c42\u4ee3\u7406/Upper-level Agent: Extracts global market signals]\n    Method --\x3e M2[\u52a8\u6001\u8d44\u4ea7\u5206\u7ec4/Dynamic Asset Grouping: Partitions market into subsets]\n    Method --\x3e M3[\u4e0b\u5c42\u4ee3\u7406/Lower-level Agents: Perform intra-group allocation]\n    Method --\x3e M4[\u6548\u7528\u8d44\u672c\u5206\u914d/Utility-based Capital Allocation: Integrates risky & risk-free assets]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Outperforms baselines, provides interpretability] --\x3e R1[\u6027\u80fd/Performance: Higher Return, Sharpe, Sortino, Omega ratios]\n    Results --\x3e R2[\u53ef\u89e3\u91ca\u6027/Interpretability: SHAP reveals "diversified + concentrated" mechanism]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Q-learning, ensemble learning, satisficing, distillation, bounded rationality]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," \xdcnver \xc7ift\xe7i"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tekirda\u011f Nam\u0131k Kemal University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22910",children:"https://arxiv.org/pdf/2512.22910"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a two-phase framework (Sat-EnQ) that first trains an ensemble of lightweight Q-networks using a satisficing objective to limit early value growth and reduce variance. 2. Provides theoretical proof that the satisficing objective induces bounded updates and cannot increase target variance, with a corollary for substantial reduction. 3. Demonstrates empirical results including significant variance reduction, elimination of catastrophic failures, robustness to noise, and improved compute efficiency compared to baseline methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the instability of deep Q-learning, especially early in training, by introducing Sat-EnQ. This framework first trains a satisficing ensemble of weak Q-learners to produce stable, low-variance estimates, then distills and fine-tunes the ensemble. The method significantly improves training reliability, robustness, and computational efficiency compared to standard approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Sat-EnQ] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Deep Q-Learning Instability]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Two-Phase Satisficing Ensemble]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Variance Reduction & Robustness]\n    B --\x3e B1[\u65e9\u671f\u8bad\u7ec3\u4e0d\u7a33\u5b9a/Early Training Instability]\n    B --\x3e B2[\u9ad8\u65b9\u5dee\u4e0e\u707e\u96be\u6027\u5931\u8d25/High Variance & Catastrophic Failure]\n    C --\x3e C1[\u9636\u6bb51: \u6ee1\u8db3\u5316\u96c6\u6210\u8bad\u7ec3/Phase 1: Satisficing Ensemble Training]\n    C --\x3e C2[\u9636\u6bb52: \u84b8\u998f\u4e0e\u5fae\u8c03/Phase 2: Distillation & Fine-tuning]\n    D --\x3e D1[3.8\u500d\u65b9\u5dee\u964d\u4f4e/3.8x Variance Reduction]\n    D --\x3e D2[0%\u707e\u96be\u6027\u5931\u8d25/0% Catastrophic Failure]\n    D --\x3e D3[2.5\u500d\u8ba1\u7b97\u6548\u7387\u63d0\u5347/2.5x Compute Efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Heterogeneity in Multi-Agent Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [heterogeneity, multi-agent reinforcement learning, parameter sharing, heterogeneity distance, dynamic algorithm]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tianyi Hu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu, Min Chen, Xin Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22941",children:"https://arxiv.org/pdf/2512.22941"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Harry67Hu/HetDPS",children:"https://github.com/Harry67Hu/HetDPS"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a systematic categorization of heterogeneity in MARL into five types with mathematical definitions. 2. Defines a heterogeneity distance and introduces a practical method to quantify agent heterogeneity. 3. Designs a heterogeneity-based dynamic parameter sharing algorithm that demonstrates better interpretability and adaptability compared to baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL). It proposes a methodology to define, quantify, and utilize heterogeneity, culminating in a dynamic parameter sharing algorithm. Experiments show this algorithm offers improved interpretability and adaptability over other parameter-sharing methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Heterogeneity in Multi-Agent Reinforcement Learning<br/>\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5f02\u8d28\u6027"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u7f3a\u4e4f\u5bf9\u5f02\u8d28\u6027\u7684\u4e25\u683c\u5b9a\u4e49<br/>Lacks rigorous definition of heterogeneity"]\n    Method --\x3e M1["\u5b9a\u4e49\u4e0e\u5206\u7c7b<br/>Definition & Categorization"]\n    Method --\x3e M2["\u91cf\u5316\u65b9\u6cd5<br/>Quantification Method"]\n    Method --\x3e M3["\u5e94\u7528\u7b97\u6cd5<br/>Application Algorithm"]\n    M1 --\x3e M1_1["\u4e94\u7c7b\u5f02\u8d28\u6027<br/>Five types of heterogeneity"]\n    M2 --\x3e M2_1["\u5f02\u8d28\u6027\u8ddd\u79bb<br/>Heterogeneity distance"]\n    M3 --\x3e M3_1["\u52a8\u6001\u53c2\u6570\u5171\u4eab<br/>Dynamic Parameter Sharing"]\n    Results --\x3e R1["\u6709\u6548\u8bc6\u522b\u4e0e\u91cf\u5316<br/>Effective identification & quantification"]\n    Results --\x3e R2["\u7b97\u6cd5\u6027\u80fd\u4f18\u8d8a<br/>Algorithm outperforms baselines"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] APO: Alpha-Divergence Preference Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (rlhf)], [alpha-divergence, preference optimization, mode collapse, anchored coordinates, gradient variance]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wang Zixian"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," China Mobile Communications Group Shandong Co., Ltd. Tai\u2019an Branch"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22953",children:"https://arxiv.org/pdf/2512.22953"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces APO, an anchored framework using Csisz\xe1r alpha-divergence to continuously interpolate between forward and reverse KL behavior for RLHF. 2. Derives unified gradient dynamics parameterized by alpha and analyzes gradient variance properties. 3. Proposes a practical reward-and-confidence-guarded alpha schedule to transition from mode-covering to mode-seeking behavior safely."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the trade-off between stable but under-exploitative mode-covering updates and high-reward but unstable mode-seeking updates in LLM alignment. It proposes APO, an anchored preference optimization framework that uses alpha-divergence to smoothly interpolate between these regimes via a guarded schedule. Experiments show APO achieves competitive performance while maintaining training stability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[APO: Alpha-Divergence Preference Optimization] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4e24\u79cd\u5206\u6b67\u6743\u8861 / Two Divergence Trade-off]\n    P1 --\x3e P2[\u524d\u5411KL\u8986\u76d6\u4f46\u4fdd\u5b88 / Forward KL: Mode-Covering but Conservative]\n    P1 --\x3e P3[\u53cd\u5411KL\u5bfb\u6c42\u4f46\u6613\u5d29\u6e83 / Reverse KL: Mode-Seeking but Collapses]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u951a\u5b9a\u6846\u67b6 / Anchored Framework]\n    M1 --\x3e M2[\u4f7f\u7528\u03b1-\u6563\u5ea6\u63d2\u503c / Use \u03b1-Divergence to Interpolate]\n    M2 --\x3e M3[\u8c03\u5ea6\u03b1\u503c / Schedule \u03b1 Value]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7ade\u4e89\u6027\u6027\u80fd / Competitive Performance]\n    Results --\x3e R2[\u4fdd\u6301\u7a33\u5b9a\u6027 / Maintains Training Stability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Diversity or Precision? A Deep Dive into Next Token Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [policy gradient, reward shaping, next-token prediction, exploration space, cross-entropy loss]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haoyuan Wu, Hai Wang, Jiajia Wu, Jinxiang Ou, Keyao Wang, Weile Chen, Zihao Zheng, Bei Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tencent, The Chinese University of Hong Kong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22955",children:"https://arxiv.org/pdf/2512.22955"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Reinterprets standard cross-entropy loss as a specific instance of policy gradient optimization in a single-step episode, bridging supervised learning and RL. 2. Proposes a generalized pre-training objective using on-policy RL principles and a novel reward-shaping strategy to balance diversity and precision in the token-output distribution. 3. Empirically finds that a precision-oriented prior, rather than a high-entropy one, creates a more favorable exploration space for subsequent RL, enhancing reasoning performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how the token-output distribution from pre-training shapes the exploration space for subsequent reinforcement learning (RL) in language models. It proposes a new pre-training method that frames next-token prediction as an RL problem, using a reward-shaping strategy to control distribution precision. The key finding is that a precision-focused prior, contrary to intuition, provides a better exploration foundation for RL than a high-entropy one."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Diversity or Precision? A Deep Dive into Next Token Prediction] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u9884\u8bad\u7ec3\u5206\u5e03\u5982\u4f55\u5f71\u54cd\u540e\u7eedRL\u7684\u63a2\u7d22\u7a7a\u95f4\uff1f/How does the pre-trained distribution affect the RL exploration space?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u5c06\u4ea4\u53c9\u71b5\u635f\u5931\u91cd\u65b0\u89e3\u91ca\u4e3a\u7b56\u7565\u68af\u5ea6/Reinterpret cross-entropy as policy gradient]\n    Method --\x3e M2[\u63d0\u51fa\u57fa\u4e8e\u5956\u52b1\u5851\u5f62\u7684\u5e7f\u4e49\u9884\u8bad\u7ec3\u76ee\u6807/Propose a generalized pre-training objective with reward shaping]\n    M2 --\x3e M2_1[\u6b63\u5956\u52b1\u7f29\u653e\u56e0\u5b50/Positive reward scaling factor]\n    M2 --\x3e M2_2[\u6392\u540d\u611f\u77e5\u7684\u8d1f\u4ee4\u724c\u5904\u7406/Rank-aware negative token treatment]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7cbe\u5ea6\u5bfc\u5411\u7684\u5148\u9a8c\u4f18\u4e8e\u9ad8\u71b5\u5148\u9a8c/Precision-oriented prior yields superior exploration space]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [reinforcement learning, training-inference mismatch, vocabulary pruning, gradient estimation, numerical stability]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," (Institutions not explicitly listed in provided content. Affiliation inference requires author list with affiliations or email domains, which are not present in the given text. Therefore, cannot be determined from the provided snippet.)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23087",children:"https://arxiv.org/pdf/2512.23087"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proves that the training-inference mismatch in LLM RL has an asymmetric effect, where the bound on log-probability mismatch scales with (1-p), making low-probability "tail" tokens the primary source of instability. 2. Proposes a novel method to stabilize RL training by dynamically pruning the vocabulary to exclude the extreme tail tokens, trading large, biased mismatches for a small, bounded optimization bias. 3. Provides both empirical demonstration of stable training and a theoretical bound on the optimization bias introduced by the proposed vocabulary pruning.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper identifies a fundamental training-inference mismatch in LLM reinforcement learning caused by differing numerical precision between high-throughput inference and stable training systems. To address this, the authors propose dynamically pruning low-probability "tail" tokens from the vocabulary during RL optimization, which stabilizes training by replacing large, biased errors with a small, bounded bias. Both theoretical analysis and empirical results support the effectiveness of this method.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d / Training-Inference Mismatch]\n    B1 --\x3e B2[\u5c3e\u90e8token\u5bfc\u81f4\u68af\u5ea6\u4e0d\u7a33\u5b9a / Tail tokens destabilize gradient estimation]\n    C --\x3e C1[\u52a8\u6001\u526a\u679d\u8bcd\u6c47\u8868 / Dynamic Vocabulary Pruning]\n    C1 --\x3e C2[\u6392\u9664\u6781\u7aef\u5c3e\u90e8token / Exclude extreme tail tokens]\n    D --\x3e D1[\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3 / Achieves stable training]\n    D --\x3e D2[\u7406\u8bba\u754c\u5b9a\u4f18\u5316\u504f\u5dee / Theoretically bounds optimization bias]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yingru Li, Ziniu Li, Jiacai Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided content."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23097",children:"https://arxiv.org/pdf/2512.23097"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Hybrid Online RL and IL for LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Train-inference distribution mismatch in LLM fine-tuning]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Unified framework combining Imitation Learning and Reinforcement Learning]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Gradient decomposes into Dense Gradient (analytic) and Sparse Gradient (sampled)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [reinforcement learning, vision-language model, supervised fine-tuning, generalization paradox, cross-dataset transferability]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fraunhofer IAIS, University of Bonn, Lamarr Institute, Department of Health Queensland, Griffith University, University Hospital Bonn"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23090",children:"https://arxiv.org/pdf/2512.23090"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced ChexReason, a resource-efficient vision-language model for medical imaging trained with an R1-style (SFT+GRPO) method using minimal data and compute. 2. Identified a fundamental tension where RL optimization (GRPO) improves in-distribution benchmark performance but significantly degrades cross-dataset generalization, a pattern also observed in high-resource models. 3. Discovered a generalization paradox where the SFT checkpoint uniquely improves cross-dataset performance, suggesting teacher-guided reasoning captures more institution-agnostic features than RL optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper investigates applying reinforcement learning (RL) to vision-language models for medical imaging, finding that while RL improves performance on the training benchmark, it harms the model's ability to generalize to new datasets. The authors conclude that for clinical robustness, curated supervised fine-tuning may be more effective than aggressive RL optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Benchmark Success, Clinical Failure<br>\u57fa\u51c6\u6210\u529f\uff0c\u4e34\u5e8a\u5931\u8d25] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[RL\u4f18\u5316\u63d0\u5347\u57fa\u51c6\u6027\u80fd\u4f46\u635f\u5bb3\u6cdb\u5316<br>RL improves benchmarks but harms generalization]\n    C --\x3e C1[\u4f7f\u7528SFT+GRPO\u8bad\u7ec3ChexReason VLM<br>Train ChexReason VLM with SFT+GRPO]\n    D --\x3e D1[GRPO\u63d0\u5347CheXpert\u6027\u80fd23%<br>GRPO improves CheXpert by 23%]\n    D --\x3e D2[GRPO\u5bfc\u81f4NIH\u6027\u80fd\u4e0b\u964d19%<br>GRPO degrades NIH by 19%]\n    D --\x3e D3[SFT\u68c0\u67e5\u70b9\u63d0\u5347\u8de8\u6570\u636e\u96c6\u6cdb\u5316<br>SFT checkpoint improves cross-dataset generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Evaluating Parameter Efficient Methods for RLVR"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Parameter-Efficient Fine-Tuning, Reinforcement Learning with Verifiable Rewards, LoRA, Spectral Collapse, Mathematical Reasoning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Qingyu Yin, Yulun Wu, Zhennan Shen, Sunbowen Li, Zhilin Wang, Yanshu Li, Chak Tou Leong, Jiale Kang, Jinjin Gu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University, HKUST, WUST, USTC, Brown University, Hong Kong Polytechnic University, INSAIT"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23165",children:"https://arxiv.org/pdf/2512.23165"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Conducted the first comprehensive evaluation of over 12 PEFT methods for RLVR, challenging the default use of standard LoRA. 2. Identified that structural PEFT variants (DoRA, AdaLoRA, MiSS) consistently outperform LoRA in this setting. 3. Discovered and explained the failure of SVD-informed initialization methods (e.g., PiSSA) due to a "spectral collapse" phenomenon and misalignment with RL optimization.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper systematically evaluates Parameter-Efficient Fine-Tuning (PEFT) methods for Reinforcement Learning with Verifiable Rewards (RLVR) on mathematical reasoning tasks. It finds that structural variants like DoRA outperform standard LoRA, while SVD-based methods fail due to spectral collapse, and extreme parameter reduction bottlenecks performance. The work provides a guide for selecting PEFT methods in RLVR."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Evaluating Parameter Efficient Methods for RLVR] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[RLVR\u4e2d\u6700\u4f73PEFT\u67b6\u6784\u672a\u77e5 / Optimal PEFT architecture for RLVR is unknown]\n    C --\x3e C1[\u7cfb\u7edf\u8bc4\u4f3012+\u79cdPEFT\u65b9\u6cd5 / Systematically evaluate 12+ PEFT methods]\n    C --\x3e C2[\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u6d4b\u8bd5 / Test on mathematical reasoning benchmarks]\n    D --\x3e D1[\u7ed3\u6784\u53d8\u4f53\u4f18\u4e8e\u6807\u51c6LoRA / Structural variants outperform standard LoRA]\n    D --\x3e D2[SVD\u521d\u59cb\u5316\u5bfc\u81f4\u8c31\u5d29\u6e83 / SVD initialization causes spectral collapse]\n    D --\x3e D3[\u6781\u7aef\u53c2\u6570\u51cf\u5c11\u635f\u5bb3\u63a8\u7406\u80fd\u529b / Extreme parameter reduction harms reasoning]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [cooperative driving, human-machine conflict, intention-aware planning, authority allocation, shared control]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Qin Wang, Shanmin Pang, Jianwu Fang, Shengye Dong, Fuhao Liu, Jianru Xue, Chen Lv"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Xi'an Jiaotong University, Nanyang Technological University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23220",children:"https://arxiv.org/pdf/2512.23220"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/i-Qin/HOCD",children:"https://github.com/i-Qin/HOCD"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Human-Oriented Cooperative Driving (HOCD) approach that minimizes human-machine conflict by prioritizing driver intention and state. 2. Designs an intention-aware trajectory planning method at the tactical level, using an intention consistency cost to align the trajectory with driver intention. 3. Develops a reinforcement learning-based control authority allocation strategy at the operational level to achieve consistency between driver state and authority allocation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d5e5ef9e0e93b645fd2997c604be86cc36eb4f1a7f88af7219f0cc6a908523b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d5e5ef9e0e93b645fd2997c604be86cc36eb4f1a7f88af7219f0cc6a908523b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a Human-Oriented Cooperative Driving (HOCD) approach to improve human-vehicle interaction by minimizing conflict. The method integrates intention-aware trajectory planning and a reinforcement learning-based authority allocation strategy. Simulation and human-in-the-loop experiments show the approach aligns with driver intention, ensures reasonable authority allocation, and enhances driving performance compared to other methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Human-Oriented Cooperative Driving Approach<br>\u4eba\u673a\u534f\u540c\u9a7e\u9a76\u65b9\u6cd5"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Human-machine conflict in cooperative driving<br>\u4eba\u673a\u534f\u540c\u9a7e\u9a76\u4e2d\u7684\u4eba\u673a\u51b2\u7a81"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>HOCD: Integrates intention & state<br>HOCD: \u96c6\u6210\u9a7e\u9a76\u610f\u56fe\u4e0e\u72b6\u6001"]\n    Method --\x3e SubMethod1["\u6218\u672f\u5c42\u9762/Tactical Level<br>Intention-aware trajectory planning<br>\u610f\u56fe\u611f\u77e5\u8f68\u8ff9\u89c4\u5212"]\n    Method --\x3e SubMethod2["\u64cd\u4f5c\u5c42\u9762/Operational Level<br>RL-based authority allocation<br>\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6743\u9650\u5206\u914d"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Aligns intention, reasonable allocation, enhances performance<br>\u5bf9\u9f50\u610f\u56fe\u3001\u5408\u7406\u5206\u914d\u3001\u63d0\u5347\u6027\u80fd"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [change detection], [vision-language model, remote sensing, semantic change detection, supervised fine-tuning, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xingwei Ma, Shiyang Feng, Bo Zhang, Bin Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Artificial Intelligence Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23244",children:"https://arxiv.org/pdf/2512.23244"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ViLaCD-R1, a novel two-stage vision-language framework for semantic change detection in remote sensing, comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). 2. Introduces a training strategy for the VLM using supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks to generate a coarse change mask. 3. Demonstrates that the framework significantly improves semantic change recognition and localization while suppressing non-semantic variations, achieving state-of-the-art performance on multiple benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of existing remote sensing change detection methods, such as poor semantic understanding and inaccurate localization, by proposing ViLaCD-R1. This two-stage vision-language framework first uses a fine-tuned VLM to generate a coarse change mask from dual-temporal images, then refines it with a decoder to produce a precise change map. The method shows superior performance in recognizing true semantic changes and suppressing irrelevant variations across several benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ViLaCD-R1: \u9065\u611f\u8bed\u4e49\u53d8\u5316\u68c0\u6d4b\u7684\u89c6\u89c9\u8bed\u8a00\u6846\u67b6] --\x3e B1(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e B2(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e B3(\u5173\u952e\u7ed3\u679c/Results)\n    B1 --\x3e C1[\u4f20\u7edf\u65b9\u6cd5\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3/Traditional methods lack semantic understanding]\n    B1 --\x3e C2[\u73b0\u6709VLM\u65b9\u6cd5\u5b9a\u4f4d\u4e0d\u51c6\u786e/Existing VLM methods have inaccurate localization]\n    B2 --\x3e D1[\u4e24\u9636\u6bb5\u6846\u67b6/Two-stage framework]\n    D1 --\x3e E1[\u591a\u56fe\u50cf\u63a8\u7406\u5668/Multi-Image Reasoner]\n    E1 --\x3e F1[SFT\u4e0eRL\u8bad\u7ec3/SFT and RL training]\n    E1 --\x3e F2[\u751f\u6210\u7c97\u53d8\u5316\u63a9\u7801/Generate coarse change mask]\n    D1 --\x3e E2[\u63a9\u7801\u5f15\u5bfc\u89e3\u7801\u5668/Mask-Guided Decoder]\n    E2 --\x3e F3[\u878d\u5408\u7279\u5f81\u4e0e\u63a9\u7801/Fuse features and mask]\n    E2 --\x3e F4[\u9884\u6d4b\u7cbe\u7ec6\u53d8\u5316\u56fe/Predict precise change map]\n    B3 --\x3e G1[\u63d0\u5347\u8bed\u4e49\u53d8\u5316\u8bc6\u522b/Improves semantic change recognition]\n    B3 --\x3e G2[\u6291\u5236\u975e\u8bed\u4e49\u53d8\u5316/Suppresses non-semantic variations]\n    B3 --\x3e G3[\u8fbe\u5230SOTA\u6027\u80fd/Achieves SOTA performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [semantic communications, agentic AI, joint source-channel coding, knowledge base, LLM/LVM agents]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haixiao Gao, Mengying Sun, Ruichen Zhang, Yanhan Wang, Xiaodong Xu, Nan Ma, Dusit Niyato, Ping Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing University of Posts and Telecommunications, Nanyang Technological University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23294",children:"https://arxiv.org/pdf/2512.23294"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides a comprehensive review of agentic AI-enhanced semantic communications, categorizing studies by agent types (embedded, LLM/LVM, RL). 2. Proposes a unified agentic AI-enhanced SemCom framework with a closed-loop architecture spanning application, semantic, and cloud-edge collaboration layers. 3. Introduces and validates a case study (AKB-JSCC) using agentic knowledge bases for joint source-channel coding, demonstrating improved reconstruction quality."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c6cd44bc1697f7504257d222eee725293b69d3eb38f48ca78c0d8e06f828cc7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c6cd44bc1697f7504257d222eee725293b69d3eb38f48ca78c0d8e06f828cc7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores how agentic AI can enhance semantic communications for 6G networks. It proposes a unified framework and a specific method (AKB-JSCC) that uses LLM/LVM and RL agents to build knowledge bases for improved coding. Experimental results show the proposed method achieves higher information reconstruction quality under various channel conditions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: How to empower semantic communications with intelligent agent capabilities for 6G"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Propose a unified agentic AI-enhanced SemCom framework and an AKB-JSCC case study using agentic knowledge bases"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: AKB-JSCC achieves higher information reconstruction quality under different channel conditions"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [CAD code generation, multi-expert reinforcement learning, Chain-of-Thought, CADExpert benchmark, CADQuery]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ke Niu, Haiyang Yu, Zhuofan Chen, Zhengtao Yao, Weitao Jia, Xiaodong Ge, Jingqun Tang, Benlei Cui, Bin Li, Xiangyang Xue"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University, ByteDance Inc."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23333",children:"https://arxiv.org/pdf/2512.23333"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Heterogeneous Collaborative Multi-Expert Reinforcement Learning (CME-CAD) paradigm for generating precise and editable CAD models., 2. Introduces a two-stage training process: Multi-Expert Fine-Tuning (MEFT) and Multi-Expert Reinforcement Learning (MERL)., 3. Presents CADExpert, an open-source benchmark with 17,299 instances including orthographic projections, CoT processes, CADQuery code, and 3D models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/854c145ea4394c54526f3cfa5f5b5e6528680bb17418bfc2756a03817bea2de5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/854c145ea4394c54526f3cfa5f5b5e6528680bb17418bfc2756a03817bea2de5_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of automating the generation of high-precision, editable CAD models from sketches, which existing methods struggle with. It proposes a new training paradigm called CME-CAD, which uses a two-stage process of Multi-Expert Fine-Tuning and Reinforcement Learning to collaboratively improve model performance. The approach aims to generate accurate, constraint-compatible CAD code and is supported by a new open-source benchmark called CADExpert."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[CME-CAD: CAD\u4ee3\u7801\u751f\u6210] --\x3e B1\n    A --\x3e B2\n    A --\x3e B3\n    B1[\u6838\u5fc3\u95ee\u9898/Problem<br>\u73b0\u6709\u65b9\u6cd5\u751f\u6210\u6a21\u578b\u4e0d\u53ef\u7f16\u8f91\u3001\u4e0d\u7cbe\u786e<br>\u4f9d\u8d56\u6587\u672c/\u56fe\u50cf\u8f93\u5165\uff0c\u6807\u6ce8\u6210\u672c\u9ad8]\n    B2[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5f02\u6784\u534f\u4f5c\u591a\u4e13\u5bb6\u5f3a\u5316\u5b66\u4e60<br>\u4e24\u9636\u6bb5\u8bad\u7ec3: MEFT + MERL]\n    B3[\u5173\u952e\u7ed3\u679c/Results<br>\u751f\u6210\u7cbe\u786e\u3001\u53ef\u7f16\u8f91\u7684CAD\u6a21\u578b<br>\u53d1\u5e03CADExpert\u57fa\u51c6\u6570\u636e\u96c6]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [text-to-sql], [Reinforcement Learning, Data Synthesis, Policy Optimization, Semantic-Logic Alignment, Group Relative Policy Optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sichuan University, IQuest Research, Beihang University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23366",children:"https://arxiv.org/pdf/2512.23366"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AGRO-SQL] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u7a00\u7f3a\u4e0e\u8d28\u91cf/Data Scarcity & Quality]\n    B --\x3e B2[\u6a21\u578b\u63a8\u7406\u9650\u5236/Model Reasoning Limitations]\n    C --\x3e C1[\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5/Data-Centric Approach]\n    C --\x3e C2[\u6a21\u578b\u4e2d\u5fc3\u65b9\u6cd5/Model-Centric Approach]\n    C1 --\x3e C1a[\u8fed\u4ee3\u6570\u636e\u5de5\u5382/Iterative Data Factory]\n    C1 --\x3e C1b[\u8bed\u4e49\u903b\u8f91\u5bf9\u9f50/Semantic-Logic Alignment]\n    C2 --\x3e C2a[\u591a\u6837\u6027\u611f\u77e5\u51b7\u542f\u52a8/Diversity-Aware Cold Start]\n    C2 --\x3e C2b[\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316/Group Relative Policy Optimization]\n    D --\x3e D1[\u5728BIRD\u548cSpider\u4e0aSOTA/SOTA on BIRD & Spider]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [continual learning], [big world hypothesis, computationally-embedded agent, interactivity, partially observable Markov decision process, model-based reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Alex Lewandowski, Adtiya A. Ramesh, Edan Meyer, Dale Schuurmans, Marlos C. Machado"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Alberta, Amii, The Swiss AI Lab IDSIA, USI & SUPSI, Canada CIFAR AI Chair, Google DeepMind"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23419",children:"https://arxiv.org/pdf/2512.23419"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a computationally-embedded perspective, representing an agent as an automaton simulated within a universal computer, proving it's equivalent to interacting with a POMDP over an infinite state-space. 2. Proposed a new objective called \"interactivity\" to measure an agent's ability to continually adapt its behavior by learning new predictions. 3. Developed a model-based RL algorithm for interactivity-seeking and constructed a synthetic problem to evaluate continual learning, finding deep linear networks outperform nonlinear ones in sustaining interactivity as capacity scales."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper proposes a computationally-embedded perspective to formalize the "big world hypothesis" in continual learning, where an agent is modeled as an automaton within the environment. It introduces "interactivity" as a new objective and a corresponding model-based RL algorithm to seek it. The main finding is that, in their synthetic evaluation, deep linear networks sustain higher interactivity as capacity increases, whereas deep nonlinear networks struggle.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis<br>\u8bba\u6587\u6807\u9898"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>\u5982\u4f55\u5f62\u5f0f\u5316\u667a\u80fd\u4f53\u5728\'\u5927\u4e16\u754c\'\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u7ea6\u675f"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u63d0\u51fa\u8ba1\u7b97\u5d4c\u5165\u89c6\u89d2\u4e0e\'\u4ea4\u4e92\u6027\'\u76ee\u6807\uff0c\u5f00\u53d1\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u6bd4\u975e\u7ebf\u6027\u7f51\u7edc\u66f4\u80fd\u7ef4\u6301\u4ea4\u4e92\u6027"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23457",children:"https://arxiv.org/pdf/2512.23457"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/zhangkc97/HiR",children:"https://github.com/zhangkc97/HiR"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Replay Failures as Successes: Sample-Efficient RL for Instruction Following] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u7a00\u758f/\u4e0d\u53ef\u533a\u5206\u7684\u5956\u52b1\u963b\u788d\u5b66\u4e60<br>Sparse/Indistinguishable Rewards Impede Learning]\n    Method[\u540e\u89c1\u6307\u4ee4\u91cd\u653e (HiR)<br>Hindsight instruction Replay (HiR)]\n    Results[\u8de8\u4efb\u52a1\u6709\u6548\u4e14\u8ba1\u7b97\u9ad8\u6548<br>Effective Across Tasks & Computationally Efficient]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tencent Hunyuan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23464",children:"https://arxiv.org/pdf/2512.23464"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0",children:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Generating high-quality, text-aligned 3D human motions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: SOTA performance, Extensive motion coverage, Open-source release"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (RLHF)], [reward model, inductive bias, information bottleneck, mutual information, reward hacking]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Alibaba, The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23461",children:"https://arxiv.org/pdf/2512.23461"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Qwen-Applications/DIR",children:"https://github.com/Qwen-Applications/DIR"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DIR, a novel information-theoretic debiasing method for reward models that maximizes mutual information with human preference while minimizing it with biased attributes. 2. Theoretically justifies the method's ability to handle complex, non-linear inductive biases, extending beyond simple linear correlation models. 3. Empirically demonstrates DIR's effectiveness in mitigating three types of biases (length, sycophancy, format) and shows it enhances RLHF performance and generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of inductive biases in reward models (RMs) for RLHF, which can lead to overfitting and reward hacking. It proposes DIR, an information-theoretic debiasing method inspired by the information bottleneck that optimizes mutual information to reduce bias. Experiments show DIR effectively mitigates multiple biases and improves RLHF performance and generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Eliminating Inductive Bias in Reward Models<br>\u6d88\u9664\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u5f52\u7eb3\u504f\u5dee] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Low-quality RM data with inductive biases<br>\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u5956\u52b1\u653b\u51fb] --\x3e B1[\u4e3e\u4f8b/Example<br>Response length bias<br>\u54cd\u5e94\u957f\u5ea6\u504f\u5dee]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>DIR: Information-theoretic debiasing<br>\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u4f18\u5316\u4e92\u4fe1\u606f] --\x3e C1[\u76ee\u6807/Objective<br>Max MI with preference, Min MI with bias<br>\u6700\u5927\u5316\u504f\u597d\u4e92\u4fe1\u606f\uff0c\u6700\u5c0f\u5316\u504f\u5dee\u4e92\u4fe1\u606f]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Mitigates multiple biases & enhances RLHF<br>\u51cf\u8f7b\u591a\u79cd\u504f\u5dee\u5e76\u63d0\u5347RLHF\u6027\u80fd] --\x3e D1[\u9a8c\u8bc1\u7684\u504f\u5dee/Verified Biases<br>Length, Sycophancy, Format<br>\u957f\u5ea6\u3001\u8fce\u5408\u6027\u3001\u683c\u5f0f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [software supply chain security], [agentic AI, reinforcement learning, large language model, blockchain security ledger, CI/CD]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Islamic University of Madinah, Arab Open University-Bahrain"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23480",children:"https://arxiv.org/pdf/2512.23480"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Agentic AI for Autonomous Defense in Software Supply Chain Security] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u6eaf\u6e90\u6846\u67b6\u65e0\u6cd5\u4e3b\u52a8\u7f13\u89e3\u6f0f\u6d1e/Traditional provenance frameworks lack active vulnerability mitigation]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u534f\u8c03/Multi-Agent Coordination]\n    C --\x3e C2[LLM\u63a8\u7406\u4e0eRL\u7b56\u7565/LLM Reasoning & RL]\n    C --\x3e C3[\u96c6\u6210CI/CD\u4e0e\u533a\u5757\u94fe\u65e5\u5fd7/CI/CD Integration & Blockchain Ledger]\n    D --\x3e D1[\u66f4\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u7387/Higher Detection Accuracy]\n    D --\x3e D2[\u66f4\u77ed\u7684\u7f13\u89e3\u5ef6\u8fdf/Lower Mitigation Latency]\n    D --\x3e D3[\u5408\u7406\u7684\u6784\u5efa\u5f00\u9500/Reasonable Build Overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Hierarchical Decision Mamba, Agentic AI, RAN Slicing, LLM, Self-healing]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Md Arafat Habib, Medhat Elsayed, Majid Bavand, Pedro Enrique Iturria Rivera, Yigit Ozcan, Melike Erol-Kantarci"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Ottawa, Ericsson Inc."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23502",children:"https://arxiv.org/pdf/2512.23502"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the first Hierarchical Decision Mamba (HDM) architecture for Agentic AI-based network management, enabling low-latency control via state-space sequence modeling. 2. Introduces a self-corrective control mechanism for continuous adjustment of slice weights and priorities to ensure SLA compliance. 3. Presents a coordinated Agentic AI framework that jointly orchestrates inter-slice provisioning, intra-slice scheduling, and self-healing for adaptive RAN management, integrating a Hybrid RAG-based LLM for context-aware decision-making."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05a50b9e8619f08f976fca766d72a9c64a17b17a2ce198f899fb8e68a2fb9f94_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05a50b9e8619f08f976fca766d72a9c64a17b17a2ce198f899fb8e68a2fb9f94_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a novel Agentic AI framework for 6G RAN slicing, which uses a Large Language Model (LLM) to interpret operator intents and a Hierarchical Decision Mamba (HDM) controller to coordinate specialized agents for resource scheduling and self-healing. The method addresses the lack of natural language understanding and coordinated decision-making in existing approaches. The framework demonstrates improved performance over baselines in terms of throughput, cell-edge performance, and latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Existing RAN slicing methods lack natural language understanding and coordinated decision-making.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic AI framework with LLM for intent interpretation and HDM for coordinating inter/intra-slice & self-healing agents.]\n    D[\u5173\u952e\u7ed3\u679c/Results: Shows higher throughput, improved cell-edge performance, and reduced latency vs. baselines.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [computational pathology], [agentic multimodal model, evidence-seeking inference, reinforcement learning, whole-slide images, vision-language model]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shengyi Hua, Jianfeng Wu, Tianle Shen, Kangzhe Hu, Zhongzhen Huang, Shujuan Ni, Zhihong Zhang, Yuan Li, Zhe Wang, Xiaofan Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Fourth Military Medical University, University of Science and Technology of China, Fudan University, Nanjing Medical University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23545",children:"https://arxiv.org/pdf/2512.23545"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed PathFound, an agentic multimodal model that introduces an evidence-seeking inference paradigm for pathological diagnosis, moving beyond static, single-pass analysis. 2. Integrated pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to enable proactive information acquisition and multi-stage diagnosis refinement. 3. Demonstrated that the evidence-seeking strategy consistently improves diagnostic accuracy across models and that PathFound achieves state-of-the-art performance, showing strong potential for discovering subtle pathological details."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes PathFound, an agentic multimodal model that mimics clinical workflows by actively seeking evidence for ambiguous pathological diagnoses through multi-turn interactions. It integrates visual foundation models, vision-language models, and reinforcement learning-based reasoning to refine its initial diagnosis. The method achieves state-of-the-art diagnostic accuracy and demonstrates the effectiveness of evidence-seeking workflows in computational pathology."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[PathFound: Agentic Multimodal Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Static inference vs. clinical workflow]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic model with VFM, VLM, RL]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: SOTA accuracy, discovers subtle details]\n    B --\x3e B1[\u9759\u6001\u63a8\u7406\u8303\u5f0f/Static inference paradigm]\n    B --\x3e B2[\u7f3a\u4e4f\u8bc1\u636e\u518d\u83b7\u53d6/Lacks reassessment & evidence acquisition]\n    C --\x3e C1[\u591a\u9636\u6bb5\u8bca\u65ad/Multi-stage diagnosis]\n    C --\x3e C2[\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6/Proactive information acquisition]\n    D --\x3e D1[\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u5347/Improved diagnostic accuracy]\n    D --\x3e D2[\u53d1\u73b0\u7ec6\u5fae\u7279\u5f81/Discover subtle pathological features]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] ThinkGen: Generalized Thinking for Visual Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [text-to-image generation], [Chain-of-Thought (CoT), Multimodal Large Language Model (MLLM), Diffusion Transformer (DiT), reinforcement learning, SepGRPO]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Siyu Jiao, Yiheng Lin, Yujie Zhong, Qi She, Wei Zhou, Xiaohan Lan, Zilong Huang, Fei Yu, Yingchen Yu, Yunqing Zhao, Yao Zhao, Yunchao Wei"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing Jiaotong University, Bytedance"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23568",children:"https://arxiv.org/pdf/2512.23568"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/jiaosiyuu/ThinkGen",children:"https://github.com/jiaosiyuu/ThinkGen"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM's CoT reasoning for various generation tasks. 2. Introduces a decoupled architecture using a pretrained MLLM to generate instructions and a DiT for image synthesis. 3. Proposes a separable GRPO-based training paradigm (SepGRPO) for alternating reinforcement learning between modules, enabling joint training across diverse datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8377ac1537eac2a0f36b9ae8883a51e957cbbeb6e49b280cc20b5c5080e11f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8377ac1537eac2a0f36b9ae8883a51e957cbbeb6e49b280cc20b5c5080e11f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ThinkGen, a framework that integrates Chain-of-Thought reasoning from Multimodal LLMs with a Diffusion Transformer for visual generation. It uses a decoupled architecture and a novel separable reinforcement learning training method to generalize across diverse generation scenarios. Experiments show it achieves state-of-the-art performance on multiple benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ThinkGen: Generalized Thinking for Visual Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[CoT\u63a8\u7406\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u5e94\u7528\u6709\u9650/CoT for generation is nascent and scenario-specific]\n    C --\x3e C1[\u89e3\u8026\u67b6\u6784: MLLM + DiT/Decoupled architecture: MLLM + DiT]\n    C --\x3e C2[\u53ef\u5206\u79bbGRPO\u8bad\u7ec3\u8303\u5f0f/SepGRPO training paradigm]\n    D --\x3e D1[\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5b9e\u73b0SOTA/Achieves SOTA across multiple benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] ProGuard: Towards Proactive Multimodal Safeguard"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal safety], [proactive guard, out-of-distribution (OOD) detection, reinforcement learning (RL), multimodal safety taxonomy, synonym-bank reward]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shaohan Yu, Lijun Li, Chenyang Si, Lu Sheng, Jing Shao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Artificial Intelligence Laboratory, Nanjing University, Beihang University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23573",children:"https://arxiv.org/pdf/2512.23573"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://yushaohan.github.io/ProGuard",children:"https://yushaohan.github.io/ProGuard"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ProGuard, a vision-language proactive guard model that identifies and describes out-of-distribution safety risks without requiring model adjustments. 2. Constructs a modality-balanced dataset of 87K samples with binary safety labels and hierarchical risk categories to mitigate modality bias. 3. Trains the model purely via reinforcement learning augmented with a synonym-bank-based similarity reward to enhance OOD risk inference and description."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ffca72668094b2c8095387a83d8b49cc465da7d2f333cac7db429f76193be61_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ffca72668094b2c8095387a83d8b49cc465da7d2f333cac7db429f76193be61_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes ProGuard, a proactive multimodal safeguard that uses reinforcement learning on a balanced dataset to detect and describe unseen safety risks. It achieves performance comparable to closed-source models on safety classification and significantly improves OOD risk detection and description by over 50%."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ProGuard: Towards Proactive Multimodal Safeguard] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u751f\u6210\u6a21\u578b\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u6301\u7eed\u7684\u591a\u6a21\u6001\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u3002]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faProGuard\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u57fa\u7840\u6a21\u578b\uff0c\u5f15\u5165OOD\u7c7b\u522b\u63a8\u65ad\u4efb\u52a1\u548c\u540c\u4e49\u8bcd\u5e93\u5956\u52b1\u3002]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u4e8c\u5143\u5b89\u5168\u5206\u7c7b\u4e0a\u5ab2\u7f8e\u95ed\u6e90\u5927\u6a21\u578b\uff0cOOD\u98ce\u9669\u68c0\u6d4b\u63d0\u534752.6%\uff0c\u63cf\u8ff0\u63d0\u534764.8%\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [transfer learning], [Le Cam Distortion, Deficiency Distance, Directional Simulability, Unsupervised Domain Adaptation, Negative Transfer]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Deniz Akdemir"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," None (Institution not specified in provided content)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23617",children:"https://arxiv.org/pdf/2512.23617"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a decision-theoretic framework for robust transfer learning based on Le Cam's theory, replacing symmetric invariance with directional simulability. 2. Introduces Le Cam Distortion, quantified by the Deficiency Distance, as a rigorous upper bound for transfer risk. 3. Demonstrates the framework's effectiveness across diverse experiments (genomics, vision, RL), showing it prevents source degradation and catastrophic negative transfer where traditional methods fail."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper identifies a flaw in standard Unsupervised Domain Adaptation, which can cause harmful "negative transfer" by forcing invariance between unequally informative domains. It proposes a new framework based on Le Cam\'s theory, using directional simulability and a metric called Le Cam Distortion to enable safe transfer without degrading the source domain. Experiments show this method successfully prevents information loss and catastrophic failure in safety-critical applications.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u6807\u51c6UDA\u7684\u7f3a\u9677/Flaw of Standard UDA]\n    Problem --\x3e P2[\u8d1f\u8fc1\u79fb\u4e0e\u4fe1\u606f\u7834\u574f/Negative Transfer & Information Destruction]\n    Method --\x3e M1[Le Cam\u7406\u8bba/Le Cam's Theory]\n    Method --\x3e M2[\u65b9\u5411\u53ef\u6a21\u62df\u6027/Directional Simulability]\n    Method --\x3e M3[Le Cam Distortion\u5ea6\u91cf/Le Cam Distortion Metric]\n    Results --\x3e R1[\u57fa\u56e0\u7ec4\u5b66\u5b8c\u7f8e\u4f30\u8ba1/Perfect Genomics Estimation]\n    Results --\x3e R2[\u96f6\u6e90\u57df\u635f\u5931/Zero Source Utility Loss]\n    Results --\x3e R3[\u5b89\u5168RL\u7b56\u7565\u8f6c\u79fb/Safe RL Policy Transfer]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Process Reward Model, Policy-Invariant Reward Shaping, Multi-Perspective Reward Fusion]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Huajie Tan, Sixiang Chen, Yijie Xu, Zixiao Wang, Yuheng Ji, Cheng Chi, Yaoxu Lyu, Zhongxia Zhao, Xiansheng Chen, Peterson Co, Shaoxuan Xie, Guocai Yao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Peking University, Beijing Academy of Artificial Intelligence"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23703",children:"https://arxiv.org/pdf/2512.23703"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://robo-dopamine.github.io",children:"https://robo-dopamine.github.io"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Dopamine-Reward, a method for learning a step-aware, general-purpose process reward model (GRM) from multi-view inputs to overcome perceptual limitations. 2. Proposes a theoretically-sound Policy-Invariant Reward Shaping method within the Dopamine-RL framework to enable efficient policy learning without altering the optimal policy. 3. Demonstrates high efficiency and generalization, where a one-shot adapted GRM enables policy learning to achieve 95% success with only 150 online rollouts."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbdde8d7dea23f224b530580752926db8c72c9f5768172278573c890a3c6b0c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbdde8d7dea23f224b530580752926db8c72c9f5768172278573c890a3c6b0c6_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of designing effective reward functions for real-world robotic RL by introducing Robo-Dopamine. It proposes a general, step-aware reward model trained on a large dataset and a robust policy learning framework with theoretically-sound reward shaping. Experiments show the approach achieves state-of-the-art reward accuracy and significantly improves policy learning efficiency with strong generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: RL reward design is hard; existing PRMs lack step-awareness & use single-view, reward shaping is unsound]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Dopamine-Reward (GRM with Step-wise Discretization & Multi-Perspective Fusion) & Dopamine-RL (Policy-Invariant Reward Shaping)]\n    D[\u5173\u952e\u7ed3\u679c/Results: SOTA reward accuracy; High policy learning efficiency (95% success with 150 rollouts); Strong generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Training AI Co-Scientists Using Rubric Rewards"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Meta Superintelligence Labs, ELLIS Institute T\xfcbingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23707",children:"https://arxiv.org/pdf/2512.23707"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Training AI Co-Scientists Using Rubric Rewards"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: LMs struggle to generate research plans that follow all constraints."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: RL with self-grading using automatically extracted rubrics."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Human experts prefer finetuned model\'s plans; method generalizes across domains."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, StepFun, FinStep"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23515",children:"https://arxiv.org/pdf/2512.23515"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/FinStep-AI/Alpha-R1",children:"https://github.com/FinStep-AI/Alpha-R1"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 30'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [RFET, stochastic computing, SCNN, stochastic number generator, accelerator]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sheng Lu, Qianhou Qu, Sungyong Jung, Qilian Liang, Chenyun Pan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"}),' University of Texas at Arlington (inferred from IEEE affiliation and author "Qilian Liang, Fellow, IEEE" known association)']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22131",children:"https://arxiv.org/pdf/2512.22131"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel SCNN architecture leveraging Reconfigurable Field-Effect Transistors (RFETs) for device-level reconfigurability. 2. Designs highly efficient and compact core modules (e.g., SNGs, APCs) enabled by RFET technology. 3. Develops and evaluates a dedicated RFET-based SCNN accelerator, showing significant improvements in area, latency, and energy over a FinFET baseline."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high resource consumption of Stochastic Computing Neural Networks (SCNNs) by proposing a novel accelerator architecture based on Reconfigurable Field-Effect Transistors (RFETs). The inherent reconfigurability of RFETs enables the design of compact and efficient core components like stochastic number generators. Experimental results demonstrate that the proposed RFET-based accelerator achieves substantial reductions in area, latency, and energy consumption compared to a FinFET-based design at the same technology node."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: SCNN\u8d44\u6e90\u6d88\u8017\u9ad8/High SCNN Resource Usage]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8eRFET\u7684\u67b6\u6784/RFET-Based Architecture]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u9762\u79ef\u3001\u5ef6\u8fdf\u3001\u80fd\u8017\u964d\u4f4e/Reduced Area, Latency, Energy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HookMIL: Revisiting Context Modeling in Multiple Instance Learning for Computational Pathology"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [computational pathology], [Multiple Instance Learning, Hook Tokens, Linear Complexity, Multimodal Initialization, Hook Diversity Loss]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xitong Ling, Minxi Ouyang, Xiaoxiao Li, Jiawen Li, Ying Chen, Yuxuan Sun, Xinrui Chen, Tian Guan, Xiaoping Liu, Yonghong He"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Xiamen University, Westlake University, Wuhan University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22188",children:"https://arxiv.org/pdf/2512.22188"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/lingxitong/HookMIL",children:"https://github.com/lingxitong/HookMIL"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HookMIL, a context-aware MIL framework using learnable hook tokens for structured contextual aggregation with linear computational complexity. 2. Introduces a multimodal initialization strategy for hook tokens using visual, textual, and spatial priors to accelerate convergence and improve representation. 3. Presents a Hook Diversity Loss and a hook-to-hook communication mechanism to encourage token specialization and refine interactions while minimizing redundancy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the loss of context in traditional MIL and the high computational cost of transformer-based MIL for whole-slide image analysis. It proposes HookMIL, a framework that uses learnable hook tokens for efficient, linear-complexity context modeling, enhanced by multimodal initialization and specialized loss functions. Experiments on four public datasets show that HookMIL achieves state-of-the-art performance with improved efficiency and interpretability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[HookMIL: Revisiting Context Modeling in MIL for Computational Pathology] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: MIL loses context; Transformers are inefficient] --\x3e P1[\u4f20\u7edfMIL\u4e22\u5931\u4e0a\u4e0b\u6587/Traditional MIL loses context]\n    Problem --\x3e P2[\u57fa\u4e8eTransformer\u7684MIL\u8ba1\u7b97\u590d\u6742/Transformer-based MIL has quadratic complexity]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: HookMIL Framework] --\x3e M1[\u4f7f\u7528\u53ef\u5b66\u4e60\u7684Hook Tokens/Use learnable Hook Tokens]\n    Method --\x3e M2[\u591a\u6a21\u6001\u521d\u59cb\u5316/Multimodal Initialization]\n    Method --\x3e M3[Hook\u591a\u6837\u6027\u635f\u5931\u4e0e\u901a\u4fe1\u673a\u5236/Hook Diversity Loss & Communication]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[SOTA\u6027\u80fd/State-of-the-art Performance]\n    Results --\x3e R2[\u8ba1\u7b97\u9ad8\u6548/Computationally Efficient]\n    Results --\x3e R3[\u53ef\u89e3\u91ca\u6027/Interpretability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Innovation Institute, OpenMoss Team"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22234",children:"https://arxiv.org/pdf/2512.22234"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/OpenMOSS/DiRL",children:"https://github.com/OpenMOSS/DiRL"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[dLLMs\u540e\u8bad\u7ec3\u4f4e\u6548/Post-training for dLLMs is inefficient]\n    B --\x3e B2[\u8bad\u7ec3\u4e0e\u63a8\u7406\u76ee\u6807\u4e0d\u5339\u914d/Training-Inference objective mismatch]\n    C --\x3e C1[DiRL\u6846\u67b6/DiRL Framework]\n    C1 --\x3e C1_1[\u6574\u5408FlexAttention\u4e0eLMDeploy/Integrates FlexAttention & LMDeploy]\n    C1 --\x3e C1_2[\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3/Two-stage post-training (SFT+RL)]\n    C --\x3e C2[DiPO\u7b97\u6cd5/DiPO Algorithm]\n    C2 --\x3e C2_1[\u65e0\u504fGRPO\u5b9e\u73b0/Unbiased GRPO for dLLMs]\n    D --\x3e D1[\u9ad8\u6548\u8bad\u7ec3\u4e0e\u63a8\u7406/Efficient Training & Inference]\n    D --\x3e D2[\u6570\u5b66SOTA\u6027\u80fd/Math SOTA Performance]\n    D --\x3e D3[\u8d85\u8d8aQwen2.5\u7cfb\u5217/Surpasses Qwen2.5 series]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Graph Attention-based Adaptive Transfer Learning for Link Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [graph neural networks], [graph attention network, link prediction, transfer learning, graph transformer, contrastive loss]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Jinan University, Great Bay University, JD Technology, University of Illinois Chicago"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22252",children:"https://arxiv.org/pdf/2512.22252"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/DSI-Lab1/GAATNet",children:"https://github.com/DSI-Lab1/GAATNet"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes GAATNet, a novel graph attention adaptive transfer network combining pre-training and fine-tuning for cross-dataset knowledge transfer in link prediction. 2. Incorporates distant neighbor embeddings as biases in self-attention to capture global node features. 3. Introduces a lightweight self-adapter module during fine-tuning to improve training efficiency and generalization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses challenges in link prediction on large-scale sparse graphs and cross-dataset transfer learning by proposing GAATNet, which integrates graph attention with adaptive transfer strategies. The method uses distant neighbor embeddings and a self-adapter module to enhance global feature capture and training efficiency. Experiments on seven datasets show state-of-the-art performance, offering a scalable solution for integrating GNNs with transfer learning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Graph Attention-based Adaptive Transfer Learning for Link Prediction] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Challenges in large-scale sparse graphs and cross-dataset transfer learning for link prediction]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes GAATNet with distant neighbor embeddings and lightweight self-adapter for adaptive transfer]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves SOTA performance on seven datasets, provides scalable GNN-transfer learning solution]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [photonic neural networks, transfer matrix, Slicing method, back-propagation, simulation framework]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tzamn Melendez Carmona, Federico Marchesin, Marco P. Abrate, Peter Bienstman, Stefano Di Carlo, Alessandro Savino Senior"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Politecnico di Torino, Ghent University - imec, University College London"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22264",children:"https://arxiv.org/pdf/2512.22264"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Slicing method, an efficient transfer matrix computation approach compatible with back-propagation for training Photonic Neural Networks (PNNs). 2. Introduces LuxIA, a unified simulation and training framework that integrates the Slicing method to enable scalable PNN training. 3. Demonstrates through experiments that LuxIA surpasses existing tools in speed and scalability for training large-scale PNNs on standard datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the scalability challenges in simulating and training large-scale Photonic Neural Networks (PNNs) by introducing the Slicing method for efficient transfer matrix computation. The method is integrated into the LuxIA framework, which significantly reduces memory usage and training time. Experimental results show LuxIA outperforms existing tools, enabling the exploration of larger and more complex photonic architectures."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[LuxIA: A Lightweight Unitary matriX-based Framework] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5f53\u524dPNN\u4eff\u771f\u5de5\u5177\u53ef\u6269\u5c55\u6027\u5dee<br>Current PNN simulation tools lack scalability]\n    C --\x3e C1[\u63d0\u51faSlicing\u65b9\u6cd5<br>Propose the Slicing method]\n    C --\x3e C2[\u6784\u5efaLuxIA\u7edf\u4e00\u6846\u67b6<br>Build the unified LuxIA framework]\n    D --\x3e D1[\u663e\u8457\u964d\u4f4e\u5185\u5b58\u4e0e\u65f6\u95f4\u6d88\u8017<br>Significantly reduces memory and time consumption]\n    D --\x3e D2[\u5728\u901f\u5ea6\u4e0e\u53ef\u6269\u5c55\u6027\u4e0a\u8d85\u8d8a\u73b0\u6709\u5de5\u5177<br>Outperforms existing tools in speed and scalability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [scientific machine learning], [Physics-informed neural networks, Kolmogorov-Arnold networks, Adaptive weighting, B-splines, Partial differential equations]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Guokan Chen, Yao Xiao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fujian University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22283",children:"https://arxiv.org/pdf/2512.22283"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DBAW-PIKAN, a novel architecture combining a Kolmogorov-Arnold Network (KAN) with learnable B-splines for enhanced function representation in solving PDEs., 2. Introduces an adaptive weighting strategy with a dynamic decay upper bound to mitigate gradient flow stiffness and spectral bias, addressing key failure modes of PINNs., 3. Demonstrates significant improvements in convergence speed and solution accuracy (at least an order of magnitude) on benchmarks like Klein-Gordon, Burgers, and Helmholtz equations without added computational cost."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DBAW-PIKAN, a novel neural network that integrates a Kolmogorov-Arnold architecture with an adaptive weighting strategy to overcome the stiffness and spectral bias challenges faced by Physics-Informed Neural Networks (PINNs) when solving multi-scale PDEs. The method accelerates convergence and improves solution accuracy by at least an order of magnitude on standard benchmarks without increasing computational complexity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[PINNs struggle with multi-scale/high-frequency PDEs / PINNs\u5728\u5904\u7406\u591a\u5c3a\u5ea6/\u9ad8\u9891PDE\u65f6\u9047\u5230\u56f0\u96be]\n    P1 --\x3e P2[Issues: Gradient flow stiffness & spectral bias / \u95ee\u9898: \u68af\u5ea6\u6d41\u521a\u5ea6\u548c\u8c31\u504f\u5dee]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Architecture: Kolmogorov-Arnold Network (KAN) with learnable B-splines / \u67b6\u6784: \u57fa\u4e8e\u53ef\u5b66\u4e60B\u6837\u6761\u7684KAN]\n    Method --\x3e M2[Strategy: Adaptive weighting with dynamic decay upper bound / \u7b56\u7565: \u5e26\u52a8\u6001\u8870\u51cf\u4e0a\u754c\u7684\u81ea\u9002\u5e94\u52a0\u6743]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Faster convergence & higher accuracy / \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u9ad8\u7684\u7cbe\u5ea6]\n    R1 --\x3e R2[Improvement: At least one order of magnitude / \u63d0\u5347: \u81f3\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7]\n    Results --\x3e R3[Benchmarks: Klein-Gordon, Burgers, Helmholtz equations / \u57fa\u51c6: Klein-Gordon, Burgers, Helmholtz\u65b9\u7a0b]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Northwestern University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22307",children:"https://arxiv.org/pdf/2512.22307"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (<0.1% for 7,168 key bits)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators] --\x3e Problem(\u6838\u5fc3\u95ee\u9898/Problem: Model IP Protection & Supply Chain Threats)\n    Root --\x3e Method(\u4e3b\u8981\u65b9\u6cd5/Method: Hardware-Software Co-design with Logic Locking)\n    Root --\x3e Results(\u5173\u952e\u7ed3\u679c/Results: Resists Attacks, <0.1% Overhead)\n    Problem --\x3e P1(\u6a21\u578b\u76d7\u7a83/Model Theft)\n    Problem --\x3e P2(\u6a21\u578b\u7834\u574f/Model Corruption)\n    Problem --\x3e P3(\u4fe1\u606f\u6cc4\u9732/Information Leakage)\n    Method --\x3e M1(\u8f6f\u4ef6\u4fa7: \u795e\u7ecf\u5143\u5d4c\u5165\u5bc6\u94a5/Software: Key Embedding in Neurons)\n    Method --\x3e M2(\u786c\u4ef6\u4fa7: \u8f7b\u91cf\u7ea7\u9501\u5b9a\u6a21\u5757/Hardware: Lightweight Locking Module)\n    Results --\x3e R1(\u62b5\u5fa1\u4f18\u5316\u653b\u51fb/Withstands Oracle-Guided Attacks)\n    Results --\x3e R2(\u4f4e\u8ba1\u7b97\u5f00\u9500/Low Computational Overhead)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Missouri, SRI International"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22387",children:"https://arxiv.org/pdf/2512.22387"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Is AI-generated code reproducible?"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion)."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Quantum Generative Models for Computational Fluid Dynamics: A First Exploration of Latent Space Learning in Lattice Boltzmann Simulations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Quantum Generative Models, Computational Fluid Dynamics, Lattice Boltzmann Method, Vector Quantized Variational Autoencoder, Quantum Circuit Born Machine]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Achraf Hsain, Fouad Mohammed Abbou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Al Akhawayn University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22672",children:"https://arxiv.org/pdf/2512.22672"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A complete open-source pipeline bridging CFD simulation and quantum machine learning. 2. The first empirical study of quantum generative modeling on compressed latent representations of physics simulations. 3. A comparative analysis of quantum (QCBM, QGAN) and classical (LSTM) generative models for a physics-derived latent distribution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores the application of quantum generative models to Computational Fluid Dynamics (CFD) data. The authors compress fluid simulation data into a discrete latent space using a VQ-VAE and then compare quantum (QCBM, QGAN) and classical (LSTM) models for generating samples from this distribution. Under their experimental conditions, the quantum models, particularly the QCBM, outperformed the classical baseline in generating samples closer to the true distribution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Quantum Generative Models for CFD: Latent Space Learning in LBM Simulations"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Modeling compressed CFD latent distributions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: VQ-VAE compression + QCBM/QGAN vs LSTM"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Quantum models (QCBM best) outperformed classical LSTM"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [differential games], [Hamilton-Jacobi reachability, reach-avoid games, dimensionality decomposition, UAVs, tracking control]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Minh Bui, Simon Monckton, Mo Chen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Simon Fraser University, Defense Research & Development Canada (DRDC)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22793",children:"https://arxiv.org/pdf/2512.22793"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel dimensionality reduction framework for 3D reach-avoid games by decomposing the problem into horizontal and vertical sub-games., 2. A Hamilton-Jacobi-based tracking control algorithm to reconstruct the solution from sub-games, guaranteeing capture and subsequent tracking of the attacker., 3. Theoretical proof of the conditions for maintaining capture guarantees and empirical validation in both numerical simulations and a physics simulator (Gazebo)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the high-dimensional challenge of 3D reach-avoid differential games for UAVs by proposing a decomposition approach that splits the problem into horizontal and vertical sub-games, solves them using Hamilton-Jacobi reachability analysis, and uses a novel tracking control to reconstruct the solution. The method is proven to maintain optimality and capture guarantees, and its effectiveness is successfully demonstrated through simulations and a physics simulator for quadrotor capture."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898: Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[3D\u8ffd\u9003\u535a\u5f08\u9ad8\u7ef4\u6311\u6218/High Dimensionality of 3D Reach-Avoid Games]\n    B --\x3e B2[\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u6027/Limitations of Existing Approaches]\n    C --\x3e C1[\u7ef4\u5ea6\u5206\u89e3/Dimensionality Decomposition]\n    C1 --\x3e C1_1[\u6c34\u5e73\u5b50\u535a\u5f08/Horizontal Sub-game]\n    C1 --\x3e C1_2[\u5782\u76f4\u5b50\u535a\u5f08/Vertical Sub-game]\n    C --\x3e C2[HJ\u53ef\u8fbe\u6027\u5206\u6790/HJ Reachability Analysis]\n    C --\x3e C3[HJ\u8ddf\u8e2a\u63a7\u5236/HJ-based Tracking Control]\n    D --\x3e D1[\u4fdd\u6301\u6700\u4f18\u6027\u4e0e\u4fdd\u8bc1/Maintains Optimality & Guarantees]\n    D --\x3e D2[\u4eff\u771f\u9a8c\u8bc1/Simulation Validation]\n    D --\x3e D3[\u7269\u7406\u6a21\u62df\u5668\u6210\u529f\u6355\u83b7/Successful Capture in Physics Simulator]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22796",children:"https://arxiv.org/pdf/2512.22796"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method's flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Parallel Diffusion Solver via Residual Dirichlet Policy Optimization] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6269\u6563\u6a21\u578b\u91c7\u6837\u5ef6\u8fdf\u9ad8 / High sampling latency of DMs]\n    B --\x3e B2[\u73b0\u6709\u6c42\u89e3\u5668\u5728\u4f4e\u6b65\u6570\u4e0b\u8d28\u91cf\u4e0b\u964d / Existing solvers degrade quality at low NFEs]\n    C --\x3e C1[EPD-Solver: \u96c6\u6210\u5e76\u884c\u65b9\u5411\u6c42\u89e3\u5668 / Ensemble Parallel Direction solver]\n    C --\x3e C2[\u4e24\u9636\u6bb5\u4f18\u5316: \u84b8\u998f + RL\u5fae\u8c03 / Two-stage optimization: Distillation + RL fine-tuning]\n    C --\x3e C3[\u4f5c\u4e3a\u63d2\u4ef6\u63d0\u5347\u73b0\u6709\u6c42\u89e3\u5668 / Plugin (EPD-Plugin) for existing samplers]\n    D --\x3e D1[\u4f4e\u5ef6\u8fdf\u4e0bSOTA FID\u5206\u6570 / SOTA FID scores at low latency]\n    D --\x3e D2[\u5728T2I\u4efb\u52a1\u4e2d\u63d0\u5347\u4eba\u7c7b\u504f\u597d\u5206\u6570 / Improved human preference scores in T2I]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Gaurav Chaudhary, Laxmidhar Behera"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IIT Kanpur"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22824",children:"https://arxiv.org/pdf/2512.22824"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Uniform goal selection is sample inefficient in multi-goal RL/\u591a\u76ee\u6807RL\u4e2d\u5747\u5300\u76ee\u6807\u9009\u62e9\u6837\u672c\u6548\u7387\u4f4e]\n    C --\x3e C1[Student-Teacher paradigm with Temporal Variance-Driven Curriculum/\u57fa\u4e8e\u65f6\u5e8f\u65b9\u5dee\u7684\u5e08\u751f\u8bfe\u7a0b\u5b66\u4e60\u8303\u5f0f]\n    C --\x3e C2[Teacher prioritizes goals with highest Q-value temporal variance/\u6559\u5e08\u6a21\u5757\u4f18\u5148\u9009\u62e9Q\u503c\u65f6\u5e8f\u65b9\u5dee\u6700\u9ad8\u7684\u76ee\u6807]\n    D --\x3e D1[Consistent improvements over SOTA methods/\u76f8\u6bd4SOTA\u65b9\u6cd5\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb]\n    D --\x3e D2[Evaluated on 11 robotic manipulation and navigation tasks/\u572811\u4e2a\u673a\u5668\u4eba\u64cd\u4f5c\u4e0e\u5bfc\u822a\u4efb\u52a1\u4e0a\u9a8c\u8bc1]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [robotics control], [aerial manipulator, prescribed performance control, variable-gain extended state observer, dynamic coupling, motion control]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mengyu Ji, Shiliang Guo, Zhengzhen Li, Jiahao Shen, Huazi Cao, Shiyu Zhao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Westlake University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22957",children:"https://arxiv.org/pdf/2512.22957"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel prescribed performance motion control framework (PreGME) for aerial manipulators. 2. The use of variable-gain extended state observers (ESOs) for accurate real-time estimation of rapidly varying dynamic coupling. 3. A control strategy that generates a preset error trajectory to ensure tracking errors remain within a prescribed performance envelope for high-precision control."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f2803479d85cfb232ae59d1133082b1c37608a63bed7f68577a5675d15b2598_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f2803479d85cfb232ae59d1133082b1c37608a63bed7f68577a5675d15b2598_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes PreGME, a new control framework for aerial manipulators that combines variable-gain extended state observers to estimate dynamic coupling with prescribed performance control to constrain error trajectories. The method enables high-precision control even during aggressive arm motions. Experiments, including aerial mixology and cart-pulling, validate its effectiveness under significant dynamic disturbances."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["PreGME: Prescribed Performance Control of Aerial Manipulators"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Aerial manipulator dynamic coupling affects control precision"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Variable-gain ESO + Prescribed performance control"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: High tracking performance validated by real-world experiments"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [robotic manipulation], [robotic foundation models, high-level planning, low-level control, imitation learning, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shuanghao Bai, Wenxuan Song, Jiayi Chen, Yuheng Ji, Zhide Zhong, Jin Yang, Han Zhao, Wanqi Zhou, Zhe Li, Pengxiang Ding, Cheng Chi, Chang Xu, Xiaolong Zheng, Donglin Wang, Haoang Li, Shanghang Zhang, Badong Chen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Xi'an Jiaotong University, Hong Kong University of Science and Technology (Guangzhou), Chinese Academy of Sciences, Westlake University, Zhejiang University, University of Sydney, BAAI, Peking University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22983",children:"https://arxiv.org/pdf/2512.22983"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," Awesome-Robotics-Manipulation"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a unified algorithmic abstraction for robot manipulation, organizing approaches into high-level planning and low-level control. 2. Extends classical task planning to include reasoning over language, code, motion, affordances, and 3D representations. 3. Introduces a training-paradigm-oriented taxonomy for learning-based control, categorizing methods by input modeling, latent representation learning, and policy learning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22135ed5ae9ef66789b2dbe7f9c4c6e6a9de91ca6dd4b2025e75cfd5d4a89d02_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22135ed5ae9ef66789b2dbe7f9c4c6e6a9de91ca6dd4b2025e75cfd5d4a89d02_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey paper organizes recent learning-based approaches to robot manipulation within a unified framework of high-level planning and low-level control. It extends task planning to include multimodal reasoning and proposes a new taxonomy for learning-based control. The analysis aims to clarify the design space and identifies key challenges like scalability and safety for future robotic foundation models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Embodied Robot Manipulation in the Era of Foundation Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Robot manipulation remains a central and challenging problem / \u673a\u5668\u4eba\u64cd\u4f5c\u4ecd\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218]\n    C --\x3e C1[Unified abstraction: High-level planning & Low-level control / \u7edf\u4e00\u62bd\u8c61\uff1a\u9ad8\u5c42\u89c4\u5212\u4e0e\u5e95\u5c42\u63a7\u5236]\n    C1 --\x3e C2[High-level: Reasoning over language, code, motion, etc. / \u9ad8\u5c42\uff1a\u57fa\u4e8e\u8bed\u8a00\u3001\u4ee3\u7801\u3001\u8fd0\u52a8\u7b49\u7684\u63a8\u7406]\n    C1 --\x3e C3[Low-level: Taxonomy for learning-based control / \u5e95\u5c42\uff1a\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u5206\u7c7b\u6cd5]\n    D --\x3e D1[Clarifies design space of foundation models / \u9610\u660e\u57fa\u7840\u6a21\u578b\u7684\u8bbe\u8ba1\u7a7a\u95f4]\n    D --\x3e D2[Identifies open challenges: scalability, safety, etc. / \u6307\u51fa\u5f00\u653e\u6311\u6218\uff1a\u53ef\u6269\u5c55\u6027\u3001\u5b89\u5168\u6027\u7b49]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [activation function, hardware accelerator, taylor series, energy efficiency, edge inference]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Soham Pramanik, Vimal William, Arnab Raha, Debayan Das, Amitava Mukherjee, Janet L. Paluh"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Jadavpur University, SandLogic Technologies, Intel Corporation, Indian Institute of Science, Amrita University, SUNY Polytechnic Institute"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23062",children:"https://arxiv.org/pdf/2512.23062"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TYTAN, a Taylor-series based Generalized Non-linear Approximation Engine (G-NAE) for accelerating non-linear activation functions in deep learning. 2. Integrates a re-configurable hardware design with a specialized algorithm to dynamically estimate approximations, aiming for minimal accuracy deviation. 3. Demonstrates significant performance gains and efficiency improvements, including ~2x performance, ~56% power reduction, and ~35x lower area compared to a baseline NVDLA implementation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TYTAN, a hardware-software co-designed engine that uses Taylor series approximations to accelerate non-linear activation functions for energy-efficient AI inference at the edge. The system dynamically configures the approximation to maintain accuracy. Evaluations show it achieves high frequency operation (>950 MHz) with substantial improvements in performance, power, and area compared to a standard accelerator."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[TYTAN: Taylor-series based Non-Linear Activation Engine] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Edge AI inference requires acceleration and energy efficiency, limited by high-power operations like activation functions.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes a Generalized Non-linear Approximation Engine (G-NAE) using Taylor series and re-configurable hardware with a dynamic approximation algorithm.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: >950 MHz operation, ~2x performance, ~56% power reduction, ~35x lower area vs. NVDLA baseline.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [Zero Trust Architecture], [Zero Trust, Micro-Segmentation, Adaptive Identity, Security Automation, Financial Risk Modeling]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Paulo Fernandes Biao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Biaotech.dev"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23124",children:"https://arxiv.org/pdf/2512.23124"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SecureBank, a financially-aware and context-adaptive Zero Trust architecture specifically for high-assurance banking systems. 2. Integrates novel components like Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro-Segmentation, and Impact-Driven Security Automation. 3. Provides experimental validation through Monte Carlo simulation using new metrics (TII, ITAL, SAE), showing improved attack handling and trust adaptation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces SecureBank, a Zero Trust architecture designed for banking systems that incorporates financial risk and context. It integrates components like adaptive identity scoring and impact-driven automation. Simulation results show it improves automated attack handling and identity trust adaptation while maintaining transactional integrity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[SecureBank: A Financially-Aware Zero Trust Architecture] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4f20\u7edf\u5b89\u5168\u6a21\u578b\u4e0d\u8db3/Limitations of Traditional Security]\n    Problem --\x3e P2[\u73b0\u6709\u96f6\u4fe1\u4efb\u7f3a\u4e4f\u91d1\u878d\u8bed\u4e49/Existing ZT Lacks Financial Awareness]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u91d1\u878d\u96f6\u4fe1\u4efb/Financial Zero Trust]\n    Method --\x3e M2[\u81ea\u9002\u5e94\u8eab\u4efd\u8bc4\u5206/Adaptive Identity Scoring]\n    Method --\x3e M3[\u4e0a\u4e0b\u6587\u5fae\u9694\u79bb/Contextual Micro-Segmentation]\n    Method --\x3e M4[\u5f71\u54cd\u9a71\u52a8\u81ea\u52a8\u5316/Impact-Driven Automation]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u63d0\u5347\u653b\u51fb\u81ea\u52a8\u5316\u5904\u7406/Improved Automated Attack Handling]\n    Results --\x3e R2[\u52a0\u901f\u8eab\u4efd\u4fe1\u4efb\u9002\u5e94/Accelerated Identity Trust Adaptation]\n    Results --\x3e R3[\u4fdd\u6301\u4ea4\u6613\u5b8c\u6574\u6027/Preserved Transactional Integrity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [regression], [squeeze and excitation, channel attention, residual connections, multi-layer perceptron, penetration acceleration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yankang Li, Changsheng Li"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Nanjing University of Science and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23131",children:"https://arxiv.org/pdf/2512.23131"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed SE-MLP, a novel MLP architecture integrating a channel attention mechanism for feature prediction. 2. Incorporated residual connections into the MLP framework to enhance model stability and performance. 3. Demonstrated the model's superior accuracy, generalization, and engineering applicability for rapidly predicting penetration acceleration features."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes SE-MLP, a multi-layer perceptron model enhanced with squeeze-and-excitation channel attention and residual connections, to rapidly predict prior acceleration features for penetration signals. The model establishes a nonlinear mapping from physical parameters to acceleration features, outperforming baseline models like MLP, XGBoost, and Transformer in accuracy and stability. The results validate its feasibility and provide a practical basis for engineering applications in penetration fuse design."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u4fb5\u5f7b\u52a0\u901f\u5ea6\u5148\u9a8c\u7279\u5f81\u83b7\u53d6\u8017\u65f6\u8017\u529b/Prior acceleration features are expensive and time-consuming to obtain]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faSE-MLP\u6a21\u578b\uff0c\u96c6\u6210\u901a\u9053\u6ce8\u610f\u529b\u4e0e\u6b8b\u5dee\u8fde\u63a5/Proposed SE-MLP integrating channel attention and residual connections]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff0c\u6cdb\u5316\u6027\u597d\uff0c\u5de5\u7a0b\u8bef\u5dee\u53ef\u63a5\u53d7/High prediction accuracy, good generalization, acceptable engineering error]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [molecular language modeling], [HELM notation, DeBERTa, cyclic peptide, membrane permeability, peptide-protein interaction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Seungeon Lee, Takuto Koyama, Itsuki Maeda, Shigeyuki Matsumoto, Yasushi Okuno"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Kyoto University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23175",children:"https://arxiv.org/pdf/2512.23175"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HELM-BERT, the first encoder-based peptide language model trained on HELM notation, designed to capture hierarchical dependencies. 2. Pre-trains the model on a curated corpus of 39,079 chemically diverse linear and cyclic peptides. 3. Demonstrates superior performance over SMILES-based models in downstream tasks like cyclic peptide membrane permeability and peptide-protein interaction prediction."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HELM-BERT, a transformer model based on DeBERTa and trained on HELM notation to better represent therapeutic peptides. It shows that this approach significantly outperforms existing SMILES-based models in predicting key peptide properties, demonstrating the data-efficiency advantages of topology-aware representations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u5206\u5b50\u8868\u793a(\u5982SMILES)\u65e0\u6cd5\u6709\u6548\u6355\u6349\u80bd\u7684\u5316\u5b66\u4e0e\u62d3\u6251\u590d\u6742\u6027/Existing molecular representations fail to capture peptide complexity]\n    C --\x3e C1[\u57fa\u4e8eDeBERTa, \u4f7f\u7528HELM\u7b26\u53f7\u8bad\u7ec3\u9996\u4e2a\u7f16\u7801\u5668\u80bd\u8bed\u8a00\u6a21\u578b/Based on DeBERTa, first encoder peptide LM trained on HELM notation]\n    C --\x3e C2[\u572839,079\u4e2a\u591a\u6837\u5316\u80bd\u7684\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3/Pre-trained on a corpus of 39,079 diverse peptides]\n    D --\x3e D1[\u5728\u819c\u6e17\u900f\u6027\u548c\u80bd-\u86cb\u767d\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e0a\u663e\u8457\u4f18\u4e8eSMILES\u6a21\u578b/Significantly outperforms SMILES models on permeability & interaction prediction]\n    D --\x3e D2[HELM\u8868\u793a\u63d0\u4f9b\u6570\u636e\u6548\u7387\u4f18\u52bf/HELM representations offer data-efficiency advantages]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Meta Platforms"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23236",children:"https://arxiv.org/pdf/2512.23236"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[KernelEvolve: Scaling Agentic Kernel Coding] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[DLRM\u8bad\u7ec3/\u63a8\u7406\u6548\u7387<br/>DLRM Training/Inference Efficiency]\n    B --\x3e B2[\u6a21\u578b\u3001\u5185\u6838\u3001\u786c\u4ef6\u5f02\u6784\u6027<br/>Model, Kernel, Hardware Heterogeneity]\n    C --\x3e C1[\u667a\u80fd\u5185\u6838\u7f16\u7801\u6846\u67b6<br/>Agentic Kernel Coding Framework]\n    C --\x3e C2[\u591a\u62bd\u8c61\u5c42: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]\n    C --\x3e C3[\u56fe\u641c\u7d22\u4e0e\u68c0\u7d22\u589e\u5f3a\u63d0\u793a<br/>Graph Search & Retrieval-Augmented Prompt]\n    D --\x3e D1[100%\u6b63\u786e\u7387, 17\u500d\u52a0\u901f<br/>100% Correctness, 17x Speedup]\n    D --\x3e D2[\u5f00\u53d1\u65f6\u95f4: \u6570\u5468->\u6570\u5c0f\u65f6<br/>Dev Time: Weeks->Hours]\n    D --\x3e D3[\u964d\u4f4e\u65b0\u786c\u4ef6\u7f16\u7a0b\u58c1\u5792<br/>Reduces New Hardware Programmability Barrier]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [diffusion transformer, inference acceleration, caching, error minimization, dynamic programming]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tong Shao, Yusen Fu, Guoying Sun, Jingde Kong, Zhuotao Tian, Jingyong Su"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Harbin Institute of Technology, Shenzhen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23258",children:"https://arxiv.org/pdf/2512.23258"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CEM, a novel plugin for optimizing caching strategies in DiT acceleration via cumulative error minimization. 2. Introduces a dynamic programming algorithm guided by a predefined error prior to adaptively minimize caching error. 3. Demonstrates the method's model-agnostic nature, seamless integration into existing frameworks, and significant fidelity improvements across multiple models and tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2f0b193709fc539d32a8fa74b0405ea99491982cb3f280e0dd10ff89b6b0a3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2f0b193709fc539d32a8fa74b0405ea99491982cb3f280e0dd10ff89b6b0a3_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the slow inference of Diffusion Transformers (DiTs) by proposing CEM, a plug-and-play fidelity optimization plugin. CEM minimizes cumulative caching error via a dynamic programming algorithm, adapting to error variations during denoising. The method is training-free, model-agnostic, and significantly improves generation fidelity when integrated with existing acceleration techniques."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: DiT\u63a8\u7406\u6162\uff0c\u73b0\u6709\u7f13\u5b58\u52a0\u901f\u65b9\u6cd5\u5b58\u5728\u56fa\u5b9a\u7b56\u7565\u5bfc\u81f4\u7684\u7d2f\u79ef\u8bef\u5dee/DiT inference is slow; existing caching-based acceleration suffers from fixed-strategy cumulative error"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faCEM\u63d2\u4ef6\uff0c\u901a\u8fc7\u7d2f\u79ef\u8bef\u5dee\u6700\u5c0f\u5316\u7684\u52a8\u6001\u89c4\u5212\u4f18\u5316\u7f13\u5b58\u7b56\u7565/Propose CEM plugin, optimizing caching strategy via cumulative error minimization with dynamic programming"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: \u663e\u8457\u63d0\u5347\u751f\u6210\u4fdd\u771f\u5ea6\uff0c\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210/Significantly improves generation fidelity, model-agnostic, seamlessly integrable"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [visual SLAM], [ORB-SLAM3, YOLOv8, dynamic object filtering, point cloud refinement, CUDA acceleration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sheng-Kai Chen, Jie-Yu Chao, Jr-Yu Chang, Po-Lien Wu, Po-Chiang Lin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Yuan Ze University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23318",children:"https://arxiv.org/pdf/2512.23318"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes PCR-ORB, an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to filter dynamic objects. 2. Implements a multi-stage filtering strategy combining semantic segmentation (YOLOv8), ground plane estimation, sky removal, edge filtering, and temporal consistency for robust dynamic object removal. 3. Achieves real-time performance through CUDA-accelerated processing and demonstrates significant accuracy improvements in specific dynamic sequences on the KITTI dataset."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e72d53f96b383c73428b67d24fbf2d4163ac5820be1bfed6f370c529922f919_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e72d53f96b383c73428b67d24fbf2d4163ac5820be1bfed6f370c529922f919_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces PCR-ORB, an enhanced visual SLAM system that improves ORB-SLAM3's robustness in dynamic environments by integrating YOLOv8 for semantic segmentation and a multi-stage point cloud refinement process to filter moving objects. The method achieves real-time performance with CUDA acceleration. Evaluation on KITTI shows scenario-dependent effectiveness, with notable accuracy improvements in some sequences but mixed results overall."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: vSLAM accuracy compromised by dynamic objects]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: ORB-SLAM3 + YOLOv8 segmentation + multi-stage point cloud filtering]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Mixed performance, notable improvement in specific sequences (e.g., Seq04)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [explainable ai (xai)], [inverse kinematics, shapley additive explanations (SHAP), InterpretML, obstacle avoidance, neural network]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sheng-Kai Chen, Yi-Ling Tsai, Chun-Chih Chang, Yan-Chen Chen, Po-Chiang Lin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Yuan Ze University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23312",children:"https://arxiv.org/pdf/2512.23312"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an explainability-centered workflow integrating SHapley Additive exPlanations (SHAP) with physics-based obstacle avoidance evaluation for neural inverse kinematics. 2. Introduces and trains two lightweight variants of IKNet (Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling) on a synthetic dataset. 3. Demonstrates through simulation that neural IK architectures with more balanced feature importance attribution tend to maintain wider safety margins without sacrificing accuracy, linking XAI insights to robotic safety."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study addresses the lack of transparency in neural network-based inverse kinematics (IK) solvers by proposing an explainable AI workflow. It integrates SHAP analysis with physics-based simulation to evaluate two new IKNet variants on obstacle avoidance tasks. The key finding is that architectures with more evenly distributed feature importance achieve better safety performance, showing how XAI can guide the development of trustworthy robotic manipulation systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A["Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation<br>\u53ef\u89e3\u91ca\u795e\u7ecf\u9006\u8fd0\u52a8\u5b66\u7528\u4e8e\u969c\u788d\u7269\u611f\u77e5\u673a\u5668\u4eba\u64cd\u4f5c"] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B["\u6838\u5fc3\u95ee\u9898/Problem<br>Opaque neural IK models lack transparency and safety for responsible AI.<br>\u9ed1\u76d2\u795e\u7ecfIK\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\u4e0e\u5b89\u5168\u6027"] --\x3e B1["\u6311\u6218/Challenges<br>Debugging failures, safety certification"]\n    C["\u4e3b\u8981\u65b9\u6cd5/Method<br>XAI workflow integrating SHAP and physics simulation.<br>\u96c6\u6210SHAP\u4e0e\u7269\u7406\u4eff\u771f\u7684XAI\u5de5\u4f5c\u6d41"] --\x3e C1["\u6a21\u578b/Variants<br>Improved IKNet, Focused IKNet"]\n    C --\x3e C2["\u5de5\u5177/Tools<br>SHAP, InterpretML, Simulator"]\n    D["\u5173\u952e\u7ed3\u679c/Results<br>Balanced feature attribution correlates with wider safety margins.<br>\u5747\u8861\u7684\u7279\u5f81\u5f52\u56e0\u4e0e\u66f4\u5bbd\u7684\u5b89\u5168\u88d5\u5ea6\u76f8\u5173"] --\x3e D1["\u7ed3\u8bba/Conclusion<br>XAI guides architectural refinement for trustworthy IK.<br>XAI\u6307\u5bfc\u53ef\u4fe1IK\u7684\u67b6\u6784\u6539\u8fdb"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HL-index: Fast Reachability Query in Hypergraphs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [db], [graph databases], [hypergraph, reachability query, s-reachability, HL-index, index construction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Peiting Xie, Xiangjun Zai, Yanping Wu, Xiaoyang Wang, Wenjie Zhang, Lu Qin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The University of New South Wales, University of Technology Sydney"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23345",children:"https://arxiv.org/pdf/2512.23345"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the novel concept of s-reachability and the max-reachability query for hypergraphs, generalizing traditional reachability to model groupwise interactions. 2. Proposes the HL-index, a compact vertex-to-hyperedge index specifically designed to answer max-reachability queries efficiently. 3. Develops a fast covering relationship detection method and a lightweight neighbor-index to accelerate the construction of a minimal HL-index."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of efficiently answering reachability queries in hypergraphs, which model complex group interactions. It proposes a new index structure called HL-index, along with optimization techniques for its construction, to solve the max-reachability query problem. Experiments on 20 datasets show the approach is efficient and scalable."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[HL-index: Fast Reachability Query in Hypergraphs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8d85\u56fe\u53ef\u8fbe\u6027\u67e5\u8be2<br>Hypergraph Reachability Query]\n    B --\x3e B2[\u5efa\u6a21\u9ad8\u9636\u7fa4\u4f53\u4ea4\u4e92<br>Modeling Higher-order Group Interactions]\n    C --\x3e C1[\u63d0\u51fas-\u53ef\u8fbe\u6027\u4e0e\u6700\u5927\u53ef\u8fbe\u6027\u67e5\u8be2<br>Propose s-reachability & Max-reachability Query]\n    C --\x3e C2[\u8bbe\u8ba1HL-index\u7d22\u5f15\u7ed3\u6784<br>Design HL-index Structure]\n    C --\x3e C3[\u5feb\u901f\u8986\u76d6\u5173\u7cfb\u68c0\u6d4b\u4e0e\u90bb\u5c45\u7d22\u5f15<br>Fast Covering Detection & Neighbor-index]\n    D --\x3e D1[\u572820\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1<br>Validated on 20 Datasets]\n    D --\x3e D2[\u9ad8\u6548\u4e14\u53ef\u6269\u5c55<br>Efficient and Scalable]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] SoulX-LiveTalk Technical Report"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [Self-correcting Bidirectional Distillation, Multi-step Retrospective Self-Correction, hybrid sequence parallelism, Parallel VAE, kernel-level optimizations]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Le Shen, Qiao Qian, Tan Yu, Ke Zhou, Tianhang Yu, Yu Zhan, Zhenjie Wang, Ming Tao, Shunshun Yin, Siyuan Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Soul AI Lab, Donghua University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23379",children:"https://arxiv.org/pdf/2512.23379"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://soul-ailab.github.io/soulx-livetalk/",children:"https://soul-ailab.github.io/soulx-livetalk/"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a Self-correcting Bidirectional Distillation strategy that retains bidirectional attention within video chunks to preserve spatiotemporal correlations and enhance visual fidelity. 2. Proposed a Multi-step Retrospective Self-Correction Mechanism to ensure stability during infinite generation by enabling autonomous recovery from accumulated errors. 3. Engineered a full-stack inference acceleration suite with hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations to achieve real-time performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of deploying large diffusion models for real-time, audio-driven avatar generation by introducing SoulX-LiveTalk, a 14B-parameter framework. It employs a bidirectional distillation strategy and a self-correction mechanism to maintain high visual quality and stability, while a suite of inference optimizations enables sub-second latency and 32 FPS throughput, setting a new standard for interactive digital humans."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SoulX-LiveTalk] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5b9e\u65f6\u65e0\u9650\u65f6\u957f\u97f3\u9891\u9a71\u52a8\u5316\u8eab\u751f\u6210\u4e2d\u8ba1\u7b97\u8d1f\u8f7d\u4e0e\u4f4e\u5ef6\u8fdf\u7684\u51b2\u7a81]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u81ea\u6821\u6b63\u53cc\u5411\u84b8\u998f\u4e0e\u591a\u6b65\u56de\u987e\u81ea\u6821\u6b63\u673a\u5236]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 0.87\u79d2\u542f\u52a8\u5ef6\u8fdf\uff0c32 FPS\u5b9e\u65f6\u541e\u5410]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [kernel generation, multi-agent system, domain-specific languages (DSLs), performance tuning, Triton]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Huawei Technologies Co., Ltd., Hunan University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23424",children:"https://arxiv.org/pdf/2512.23424"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed AKG kernel agent, a multi-agent framework that automates the generation, migration, and performance tuning of computational kernels for diverse hardware platforms. 2. Designed the system to support multiple Domain-Specific Languages (DSLs) like Triton, TileLang, CPP, and CUDA-C, enabling cross-platform portability and correctness. 3. Demonstrated the system's effectiveness through evaluation on KernelBench, achieving an average 1.46x speedup over PyTorch Eager baselines on GPU and NPU backends."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AKG kernel agent, a multi-agent framework that automates the development and optimization of high-performance computational kernels for modern AI workloads across diverse hardware. The system supports multiple DSLs for portability and uses LLMs for code generation and tuning. Evaluation shows it achieves a 1.46x average speedup over baseline implementations, effectively accelerating kernel development."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AKG Kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[AI\u6a21\u578b\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u5185\u6838\u7684\u9700\u6c42 / AI Models Demand High-Performance Kernels]\n    B --\x3e B2[\u786c\u4ef6\u591a\u6837\u6027\u4e0e\u624b\u52a8\u4f18\u5316\u7684\u74f6\u9888 / Hardware Diversity & Manual Optimization Bottleneck]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u5316\u5185\u6838\u751f\u6210\u4e0e\u8c03\u4f18 / Multi-Agent System Automates Kernel Generation & Tuning]\n    C --\x3e C2[\u652f\u6301\u591a\u79cdDSL\u4ee5\u9762\u5411\u4e0d\u540c\u786c\u4ef6\u540e\u7aef / Supports Multiple DSLs for Different Hardware Backends]\n    D --\x3e D1[\u5728KernelBench\u4e0a\u8bc4\u4f30 / Evaluated on KernelBench]\n    D --\x3e D2[\u5e73\u5747\u52a0\u901f1.46\u500d / Average 1.46x Speedup Achieved]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [image classification], [convolutional neural networks, fuzzy logic, road surface classification, intelligent transport systems, data fusion]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mustafa Demetgul, Sanja Lazarova Molnar"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Karlsruhe Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23436",children:"https://arxiv.org/pdf/2512.23436"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a real-time system for road surface classification by fusing weather-conditional data and road condition data. 2. Compares the performance of multiple deep learning CNNs (AlexNet, LeNet, VGG, ResNet) on both image-based and acceleration-data-as-image classification tasks. 3. Introduces the use of fuzzy logic to classify road surfaces according to environmental factors like weather and time of day, using sensor data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a real-time system for road surface condition monitoring. It employs deep learning CNNs to classify road types from images and acceleration data, achieving over 95% accuracy, and suggests using fuzzy logic to incorporate weather and time-of-day factors. The work aims to enhance vehicle safety and autonomous driving systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Classical road monitoring is expensive and unsystematic.]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Use deep learning (CNN) on images/acceleration data and fuzzy logic for environmental context.]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Over 95% classification accuracy achieved.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tencent Hunyuan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23464",children:"https://arxiv.org/pdf/2512.23464"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0",children:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Generating high-quality, text-aligned 3D human motions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: SOTA performance, Extensive motion coverage, Open-source release"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [scientific computing], [kinetic-diffusion Monte Carlo, asymptotic-preserving, Boltzmann-BGK, error analysis, plasma simulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhirui Tang, Julian Koellermeier, Emil L\xf8vbak, Giovanni Samaey"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," KU Leuven, University of Groningen, Ghent University, Karlsruhe Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23580",children:"https://arxiv.org/pdf/2512.23580"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides a comprehensive theoretical and numerical convergence analysis for the combined Kinetic-Diffusion Monte Carlo (KDMC) method and its associated fluid estimation scheme. 2. Proves theoretical upper bounds for the error of both the KDMC simulation and the fluid estimation technique. 3. Demonstrates through numerical experiments that the analyzed algorithm achieves lower error than a purely fluid-based method and significant speedup compared to a fully kinetic Monte Carlo reference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6302c36c316815b29f4097f7a2975625261d744e473d4e2098cfa440ddbd03df_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6302c36c316815b29f4097f7a2975625261d744e473d4e2098cfa440ddbd03df_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes a combined Kinetic-Diffusion Monte Carlo (KDMC) method and fluid estimation scheme for simulating neutral particles in plasma edge physics, a computationally expensive problem for large fusion reactors. The work provides theoretical error bounds and numerical verification, showing the method is more accurate than fluid-based approaches and faster than fully kinetic Monte Carlo. The analysis confirms the effectiveness of this asymptotic-preserving approach for nuclear fusion applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u9ad8\u78b0\u649e\u7387\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u5de8\u5927/High collision rates lead to substantial computational cost in large reactors (ITER, DEMO)]\n    C --\x3e C1[\u5206\u6790\u6e10\u8fd1\u4fdd\u6301\u7684\u52a8\u529b\u5b66-\u6269\u6563\u8499\u7279\u5361\u6d1b(KDMC)\u4e0e\u6d41\u4f53\u4f30\u8ba1\u65b9\u6848/Analyze Asymptotic-Preserving Kinetic-Diffusion Monte Carlo (KDMC) & fluid estimation]\n    C --\x3e C2[\u7406\u8bba\u8bef\u5dee\u4e0a\u754c\u8bc1\u660e\u4e0e\u6570\u503c\u9a8c\u8bc1/Prove theoretical upper bounds & numerical verification]\n    D --\x3e D1[\u6bd4\u7eaf\u6d41\u4f53\u65b9\u6cd5\u8bef\u5dee\u66f4\u4f4e/Lower error than purely fluid-based method]\n    D --\x3e D2[\u76f8\u6bd4\u5168\u52a8\u529b\u5b66MC\u663e\u8457\u52a0\u901f/Significant speedup vs. fully kinetic MC]\n    D --\x3e D3[\u8bc1\u5b9e\u4e86\u5728\u6838\u805a\u53d8\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027/Confirms effectiveness in nuclear fusion applications]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Space AI: Leveraging Artificial Intelligence for Space to Improve Life on Earth"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [autonomous systems], [autonomous operations, mission planning, in-situ resource utilisation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ziyang Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22399",children:"https://arxiv.org/pdf/2512.22399"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes and defines "Space AI" as a unified interdisciplinary field at the intersection of AI and space science. 2. Consolidates historical and contemporary progress into a systematic four-context framework (AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life). 3. Identifies key application areas where AI advances can translate to societal benefits on Earth, such as in sensing, robotics, and trustworthy AI.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper introduces "Space AI" as a new interdisciplinary field and proposes a systematic framework to organize its applications across four mission contexts, from Earth-based planning to multi-planetary life support. It argues that AI is critical for enabling autonomous and resilient space operations under extreme conditions, and that advances in this domain will also yield significant benefits for life on Earth.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Space AI: Leveraging AI for Space to Improve Life on Earth] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>\u5982\u4f55\u5728\u6781\u7aef\u4e0d\u786e\u5b9a\u548c\u6709\u9650\u76d1\u7763\u4e0b<br>\u5b9e\u73b0\u592a\u7a7a\u81ea\u4e3b\u5f39\u6027\u64cd\u4f5c<br>How to enable autonomous, resilient space operations under extreme uncertainty and limited oversight]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u63d0\u51fa\u7cfb\u7edf\u5316\u56db\u7ef4\u6846\u67b6<br>Propose a systematic four-context framework<br>(AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u7edf\u4e00\u4e86\u8de8\u5b66\u79d1\u9886\u57df\u5e76\u8bc6\u522b\u5173\u952e\u5e94\u7528<br>\u52a0\u901f\u592a\u7a7a\u63a2\u7d22\u80fd\u529b\u5e76\u4ea7\u751f\u5e7f\u6cdb\u5730\u7403\u5f71\u54cd<br>Unifies interdisciplinary field and identifies key applications<br>Accelerates space exploration capability and yields broad Earth impact]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [scheduling], [constraint programming, biased random-key genetic algorithm, makespan, exact delays, local search]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," V\xedtor A. Barbosa, Rafael A. Melo"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute of Computing, Universidade Federal da Bahia"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23150",children:"https://arxiv.org/pdf/2512.23150"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A Constraint Programming (CP) model for the single-machine coupled task scheduling problem with exact delays, utilizing well-established global constraints. 2. A novel Biased Random-Key Genetic Algorithm (BRKGA) that incorporates an efficient decoder, periodical restarts, shakes, and a local search algorithm for enhanced exploration. 3. An empirical evaluation demonstrating that the BRKGA provides high-quality solutions quickly, while the CP model with extended resources can find best-known solutions for a majority of benchmark instances."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the NP-hard single-machine coupled task scheduling problem with exact delays to minimize makespan. It proposes both a Constraint Programming model and a Biased Random-Key Genetic Algorithm (BRKGA) enhanced with local search and shake components. Computational results show the BRKGA finds good solutions quickly, while the CP model with more resources achieves state-of-the-art results on most benchmark instances."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[\u8bba\u6587\u6807\u9898/Paper Title: Constraint Programming and BRKGA for Coupled Task Scheduling] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u5355\u673a\u7cbe\u786e\u5ef6\u8fdf\u8026\u5408\u4efb\u52a1\u8c03\u5ea6\uff0c\u6700\u5c0f\u5316\u5b8c\u5de5\u65f6\u95f4/Single-machine coupled task scheduling with exact delays to minimize makespan]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u7ea6\u675f\u89c4\u5212\u6a21\u578b\u4e0e\u5e26\u504f\u7f6e\u968f\u673a\u5bc6\u94a5\u9057\u4f20\u7b97\u6cd5/Constraint Programming model and Biased Random-Key Genetic Algorithm (BRKGA)]\n    Results[\u5173\u952e\u7ed3\u679c/Results: BRKGA\u5feb\u901f\u63d0\u4f9b\u9ad8\u8d28\u91cf\u89e3\uff0cCP\u6a21\u578b\u5728\u5145\u5206\u8d44\u6e90\u4e0b\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u89e3/BRKGA provides high-quality solutions quickly; CP model reaches best-known solutions with sufficient resources]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2026-01-01",children:"2026-01-01"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"cs.DC total: 17"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Governing Cloud Data Pipelines with Agentic AI"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [policy-aware control, bounded AI agents, adaptive resource reconfiguration, schema reconciliation, automated failure recovery]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aswathnarayan Muthukrishnan Kirubakaran, Adithya Parthasarathy, Nitin Saksena, Ram Sekhar Bodala, Akshay Deshpande, Suhas Malempati, Shiva Carimireddy, Abhirup Mazumder"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE, Independent Researcher, Albertsons, Amtrak, Cato"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23737",children:"https://arxiv.org/pdf/2512.23737"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A production-oriented control plane architecture for policy-aware agentic management of cloud data pipelines. 2. Detailed agent workflows for monitoring, optimization, and schema management. 3. An evaluation demonstrating significant improvements in recovery time, operational cost, and reduction of manual intervention."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5297c02d67a11ab83e576eb218227051a192108c8ce2adf60d62e9fbdb7e355_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5297c02d67a11ab83e576eb218227051a192108c8ce2adf60d62e9fbdb7e355_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Agentic Cloud Data Engineering, a control architecture that integrates bounded AI agents to autonomously govern cloud data pipelines by analyzing telemetry and enforcing declarative policies. The method enables adaptive actions like resource reconfiguration and automated recovery. Experimental results show it reduces recovery time by up to 45%, lowers costs by ~25%, and cuts manual intervention by over 70% compared to static orchestration."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Governing Cloud Data Pipelines with Agentic AI"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u9759\u6001\u914d\u7f6e\u4e0e\u88ab\u52a8\u8fd0\u7ef4/Static Config & Reactive Ops"]\n    Problem --\x3e P2["\u6062\u590d\u6162\u3001\u6210\u672c\u9ad8\u3001\u624b\u52a8\u591a/Slow Recovery, High Cost, Manual Overhead"]\n    Method --\x3e M1["\u7b56\u7565\u611f\u77e5\u63a7\u5236\u67b6\u6784/Policy-aware Control Architecture"]\n    Method --\x3e M2["\u96c6\u6210\u6709\u754cAI\u4ee3\u7406/Integrate Bounded AI Agents"]\n    Method --\x3e M3["\u81ea\u9002\u5e94\u64cd\u4f5c/Adaptive Actions"]\n    Results --\x3e R1["\u6062\u590d\u65f6\u95f4\u964d\u4f4e45%/Recovery Time \u219345%"]\n    Results --\x3e R2["\u8fd0\u8425\u6210\u672c\u964d\u4f4e25%/Operational Cost \u219325%"]\n    Results --\x3e R3["\u624b\u52a8\u5e72\u9884\u51cf\u5c1170%/Manual Intervention \u219370%"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [subspace clustering], [Schubert Variety, Grassmann Manifold, Linde-Buzo-Grey (LBG), Subspace Clustering, Geometric Learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Karim Salta, Michael Kirby, Chris Peterson"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Colorado State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23766",children:"https://arxiv.org/pdf/2512.23766"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the concept of a trainable prototype called a Schubert Variety of Best Fit (SVBF) for representing clusters of subspaces. 2. Integrates the SVBF prototype into the Linde-Buzo-Grey (LBG) clustering pipeline to create the SVBF-LBG algorithm. 3. Demonstrates improved cluster purity on synthetic, image, spectral, and video action data compared to methods using subspace means."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a73e8fbe969f250567092a96ad55fca5bd7133b8ca34f30feedb918976b1faf5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a73e8fbe969f250567092a96ad55fca5bd7133b8ca34f30feedb918976b1faf5_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new subspace clustering method that uses a geometric prototype called a Schubert Variety of Best Fit (SVBF) instead of a simple subspace mean. The SVBF is integrated into the Linde-Buzo-Grey algorithm, resulting in an SVBF-LBG framework that shows improved clustering performance on various data types while preserving mathematical structure for analysis."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Need for geometric representatives in subspace clustering"] --\x3e Problem_Sub["\u5b50\u95ee\u9898/Sub-Problem<br>Subspace means on Grassmann manifold may not be optimal"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Propose SVBF-LBG algorithm"] --\x3e Method_Sub1["\u65b9\u6cd5\u7ec4\u4ef6/Component 1<br>Schubert Variety of Best Fit (SVBF) prototype"]\n    Method --\x3e Method_Sub2["\u65b9\u6cd5\u7ec4\u4ef6/Component 2<br>Integration into Linde-Buzo-Grey (LBG) pipeline"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Improved cluster purity"] --\x3e Results_Sub1["\u7ed3\u679c\u7ec6\u8282/Detail 1<br>Tested on synthetic, image, spectral, video data"]\n    Results --\x3e Results_Sub2["\u7ed3\u679c\u7ec6\u8282/Detail 2<br>Retains mathematical structure for downstream analysis"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python with Partitioning and Parallel Execution"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [memory management], [garbage collection, concurrent mark-and-sweep, memory fragmentation, parallel execution, zone-based architecture]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abdulla M"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Could not be determined from the provided content."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23768",children:"https://arxiv.org/pdf/2512.23768"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Abdullahlab-n/VGC-for-arxiv",children:"https://github.com/Abdullahlab-n/VGC-for-arxiv"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a dual-layer (Active and Passive) garbage collector architecture to separate compile-time and runtime memory management responsibilities., 2. Proposes a concurrent mark-and-sweep strategy for the Active VGC to reduce pause times in parallel workloads., 3. Employs predictive memory mapping and cache-aligned allocation in the Passive VGC to minimize fragmentation and reduce total memory usage."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0edb6409b92db2ec79f95ff72421bf0148b259c4251b261594c32563a128cb85_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0edb6409b92db2ec79f95ff72421bf0148b259c4251b261594c32563a128cb85_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes VGC, a novel garbage collector for Python designed to overcome performance bottlenecks like the GIL and fragmentation. It uses a dual-layer architecture with a runtime concurrent collector and a compile-time allocator to reduce pause times and memory usage. The results show significant improvements in performance and scalability for parallel applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Python GC Bottlenecks: GIL, Pauses, Fragmentation]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Dual-Layer Architecture / \u53cc\u5c42\u67b6\u6784]\n    M1 --\x3e M1_1[Active VGC: Runtime Concurrent Mark-and-Sweep / \u8fd0\u884c\u65f6\u5e76\u53d1\u6807\u8bb0\u6e05\u9664]\n    M1 --\x3e M1_2[Passive VGC: Compile-Time Predictive Allocation / \u7f16\u8bd1\u65f6\u9884\u6d4b\u6027\u5206\u914d]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Reduced Pause Times (up to 30%) / \u964d\u4f4e\u6682\u505c\u65f6\u95f4]\n    Results --\x3e R2[Reduced Memory Usage (up to 25%) / \u964d\u4f4e\u5185\u5b58\u4f7f\u7528]\n    Results --\x3e R3[Improved Scalability for Parallel Apps / \u63d0\u5347\u5e76\u884c\u5e94\u7528\u53ef\u6269\u5c55\u6027]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [Zero-Trust Architecture, SHAP-weighted aggregation, TPM-based attestation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Samaresh Kumar Singh, Joyjit Roy, Martin So"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23809",children:"https://arxiv.org/pdf/2512.23809"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: IIoT\u5b89\u5168\u6f0f\u6d1e\u4e0e\u8054\u90a6\u5b66\u4e60\u653b\u51fb / IIoT Security Gaps & FL Attacks]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u96f6\u4fe1\u4efb\u8ba4\u8bc1\u4e0e\u53ef\u89e3\u91ca\u805a\u5408 / Zero-Trust Attestation & Explainable Aggregation]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u4e0e\u6297\u653b\u51fb\u9c81\u68d2\u6027 / High Detection Accuracy & Attack Robustness]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [IoT Security], [Economic Denial Security, Stackelberg Game, Cost Asymmetry, Computational Puzzles]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Samaresh Kumar Singh, Joyjit Roy"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE (Inferred from author affiliations as IEEE members; specific institutional affiliation not provided in the excerpt)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23849",children:"https://arxiv.org/pdf/2512.23849"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed the Economic Denial Security (EDS) framework, a detection-independent defense that exploits the defender's environmental control to impose economic infeasibility on attackers., 2. Formally modeled EDS as a Stackelberg game, deriving optimal parameters and proving that the composition of its four mechanisms yields superlinear (2.1x) cost amplification., 3. Demonstrated practical efficacy with a lightweight (<12KB) implementation, validated on a 20-device IoT testbed and against IoT-23 malware, showing significant attack slowdown, cost asymmetry, and improved mitigation rates."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the failure of detection-based security in resource-constrained IoT/edge environments. It proposes Economic Denial Security (EDS), a framework that uses mechanisms like computational puzzles and bandwidth taxation to make attacks economically infeasible by amplifying attacker costs. The method is proven to be lightweight, effective in significantly slowing attacks and reducing success rates, and provides a detection-independent layer of defense."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u68c0\u6d4b\u5b89\u5168\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT/\u8fb9\u7f18\u73af\u5883\u4e2d\u5931\u6548/Detection-based security fails in resource-constrained IoT/edge]\n    C --\x3e C1[\u7ecf\u6d4e\u62d2\u7edd\u5b89\u5168\u6846\u67b6 / Economic Denial Security (EDS) Framework]\n    C1 --\x3e C2[\u56db\u79cd\u673a\u5236\u7ec4\u5408 / Four Mechanism Composition]\n    C2 --\x3e C3[\u8ba1\u7b97\u8c1c\u9898 / Computational Puzzles]\n    C2 --\x3e C4[\u4ea4\u4e92\u71b5 / Interaction Entropy]\n    C2 --\x3e C5[\u65f6\u95f4\u62c9\u4f38 / Temporal Stretching]\n    C2 --\x3e C6[\u5e26\u5bbd\u5f81\u7a0e / Bandwidth Taxation]\n    C --\x3e C7[\u65af\u5854\u514b\u5c14\u4f2f\u683c\u535a\u5f08\u5efa\u6a21 / Stackelberg Game Modeling]\n    D --\x3e D1[32-560\u500d\u653b\u51fb\u51cf\u901f / 32-560x Attack Slowdown]\n    D --\x3e D2[85-520:1 \u6210\u672c\u4e0d\u5bf9\u79f0 / 85-520:1 Cost Asymmetry]\n    D --\x3e D3[\u5185\u5b58\u5360\u7528<12KB / <12KB Memory Footprint]\n    D --\x3e D4[94% \u6076\u610f\u8f6f\u4ef6\u7f13\u89e3 / 94% Malware Mitigation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [container-based resource management, mixed-integer nonlinear programming (MINLP), convex optimization, queueing-based delay, heterogeneous tasks]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yongmin Zhang, Pengyu Huang, Mingyi Dong, Jing Yao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," School of Computer Science and Engineering, Central South University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23952",children:"https://arxiv.org/pdf/2512.23952"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a measurement-driven, nonlinear fitting model to characterize the relationship between CPU/memory allocations and processing latency for heterogeneous edge workloads. 2. Formulated the joint latency and power minimization as an NP-hard MINLP problem and decomposed it into tractable convex subproblems. 3. Designed a two-stage container-based resource management scheme (CRMS) with polynomial-time complexity for quasi-dynamic execution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b13e70a9fc316e5473ea643ee1dee12e7843bf02004c4bc9cb1c91fc4f547efb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b13e70a9fc316e5473ea643ee1dee12e7843bf02004c4bc9cb1c91fc4f547efb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a sensitivity-aware container management framework (CRMS) for optimizing performance on a single edge server hosting heterogeneous tasks. It uses a profiling-derived model and convex optimization to minimize latency and power consumption. Simulation results show CRMS reduces latency by over 14% and improves energy efficiency compared to baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks<br>\u8bba\u6587\u6807\u9898"]\n    Root --\x3e Problem["\u4efb\u52a1\u5f02\u6784\u6027\u4e0e\u8d44\u6e90\u53d7\u9650<br>Task Heterogeneity & Limited Resources"]\n    Root --\x3e Method["\u4e24\u9636\u6bb5\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u65b9\u6848 (CRMS)<br>Two-stage Container-based Resource Management Scheme (CRMS)"]\n    Root --\x3e Results["\u5ef6\u8fdf\u964d\u4f4e\u8d8514%\uff0c\u80fd\u6548\u63d0\u5347<br>Latency Reduced >14%, Energy Efficiency Improved"]\n    Problem --\x3e P1["\u8fb9\u7f18\u670d\u52a1\u5668\u8d44\u6e90\u4f18\u5316\u6311\u6218<br>Edge Server Resource Optimization Challenge"]\n    Method --\x3e M1["\u975e\u7ebf\u6027\u62df\u5408\u4e0e\u6392\u961f\u5ef6\u8fdf\u5efa\u6a21<br>Nonlinear Fitting & Queueing Delay Modeling"]\n    Method --\x3e M2["MINLP\u95ee\u9898\u5206\u89e3\u4e0e\u51f8\u4f18\u5316\u6c42\u89e3<br>MINLP Decomposition & Convex Optimization"]\n    Results --\x3e R1["\u76f8\u6bd4\u542f\u53d1\u5f0f\u548c\u641c\u7d22\u57fa\u7ebf\u66f4\u4f18<br>Outperforms Heuristic & Search-based Baselines"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [decentralized federated learning, mixing matrix, energy consumption, time-varying topology, wireless networks]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xusheng Zhang, Tuan Nguyen, Ting He"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Oxford, Pennsylvania State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24069",children:"https://arxiv.org/pdf/2512.24069"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel convergence theorem for DFL that allows for arbitrarily time-varying mixing matrices, providing theoretical justification for dynamic communication topologies. 2. A multi-phase design framework for mixing matrices that activates time-varying communication topologies to trade off per-iteration energy consumption and convergence rate. 3. An optimization approach that minimizes the maximum per-node energy consumption until convergence, explicitly considering the broadcast nature of wireless communications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/090a96d0adae430f081f3c2325be19fc983de3cc1e88b07fcc83e4ab4e983d30_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/090a96d0adae430f081f3c2325be19fc983de3cc1e88b07fcc83e4ab4e983d30_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of high energy consumption in Decentralized Federated Learning (DFL) for wireless networks by designing time-varying mixing matrices. The proposed method introduces a multi-phase framework that dynamically adjusts communication topologies to balance energy use across nodes and trade off per-iteration cost with convergence speed. The evaluation shows the solution effectively combines the low energy of sparse topologies with the fast convergence of dense ones."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning<br>\u65f6\u53d8\u6df7\u5408\u77e9\u9635\u8bbe\u8ba1\u7528\u4e8e\u80fd\u6548\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60"]\n    Root --\x3e Problem["Minimize max per-node energy consumption in DFL<br>\u6700\u5c0f\u5316DFL\u4e2d\u6700\u5927\u5355\u8282\u70b9\u80fd\u8017"]\n    Root --\x3e Method["Multi-phase framework with time-varying topologies<br>\u57fa\u4e8e\u65f6\u53d8\u62d3\u6251\u7684\u591a\u9636\u6bb5\u6846\u67b6"]\n    Root --\x3e Results["Validated efficacy: low energy + fast convergence<br>\u9a8c\u8bc1\u6709\u6548\u6027\uff1a\u4f4e\u80fd\u8017+\u5feb\u901f\u6536\u655b"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [client selection, resource allocation, generalization error, convex optimization, data heterogeneity]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yanbing Yang, Huiling Zhu, Wenchi Cheng, Jingqing Wang, Changrun Chen, Jiangzhou Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Xidian University (Inferred from authors' affiliations: Yanbing Yang, Huiling Zhu, Wenchi Cheng, Jingqing Wang, Changrun Chen, and Jiangzhou Wang are typically affiliated with Xidian University, China, as per IEEE publications)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24286",children:"https://arxiv.org/pdf/2512.24286"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Presents a theoretical analysis linking client data heterogeneity to global model generalization error in Federated Learning. 2. Formulates an optimization problem to jointly minimize learning latency and energy consumption under a generalization error constraint. 3. Proposes a joint Client Selection and Resource Allocation (CSRA) scheme using convex optimization and relaxation techniques."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d00d21e4555bde2acb5f1a697568b443b6eb9860e36434dcc6d960ed7390c050_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d00d21e4555bde2acb5f1a697568b443b6eb9860e36434dcc6d960ed7390c050_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the inefficiency of Federated Learning in wireless networks caused by data heterogeneity and resource constraints. It proposes a joint client selection and resource allocation (CSRA) optimization scheme to minimize latency and energy while controlling model error. Simulation results show the proposed CSRA achieves higher accuracy, lower latency, and reduced energy consumption compared to heterogeneity-agnostic baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Data Heterogeneity-Aware Client Selection for Federated Learning in Wireless Networks") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("FL\u6548\u7387\u53d7\u9650/FL Efficiency Limited")\n    P1 --\x3e P1_1("\u901a\u4fe1\u4e0e\u8ba1\u7b97\u8d44\u6e90\u7ea6\u675f/Communication & Computation Constraints")\n    P1 --\x3e P1_2("\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u6784\u6027/Client Data Heterogeneity")\n    Method --\x3e M1("\u7406\u8bba\u5206\u6790/Theoretical Analysis")\n    M1 --\x3e M1_1("\u5f02\u6784\u6027\u5bf9\u6cdb\u5316\u8bef\u5dee\u7684\u5f71\u54cd/Impact of Heterogeneity on Generalization Error")\n    Method --\x3e M2("\u4f18\u5316\u95ee\u9898\u5efa\u6a21/Optimization Problem Formulation")\n    M2 --\x3e M2_1("\u8054\u5408\u6700\u5c0f\u5316\u5ef6\u8fdf\u4e0e\u80fd\u8017/Jointly Minimize Latency & Energy")\n    M2 --\x3e M2_2("\u7ea6\u675f\u6cdb\u5316\u8bef\u5dee/Constraining Generalization Error")\n    Method --\x3e M3("\u63d0\u51faCSRA\u65b9\u6848/Proposed CSRA Scheme")\n    M3 --\x3e M3_1("\u8054\u5408\u5ba2\u6237\u7aef\u9009\u62e9\u4e0e\u8d44\u6e90\u5206\u914d/Joint Client Selection & Resource Allocation")\n    M3 --\x3e M3_2("\u51f8\u4f18\u5316\u4e0e\u677e\u5f1b\u6280\u672f/Convex Optimization & Relaxation")\n    Results --\x3e R1("\u66f4\u9ad8\u6d4b\u8bd5\u51c6\u786e\u7387/Higher Test Accuracy")\n    Results --\x3e R2("\u964d\u4f4e\u5b66\u4e60\u5ef6\u8fdf/Reduced Learning Latency")\n    Results --\x3e R3("\u66f4\u4f4e\u80fd\u8017/Lower Energy Consumption")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] RedunCut: Measurement-Driven Sampling and Accuracy Performance Modeling for Low-Cost Live Video Analytics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [dynamic model size selection, live video analytics, measurement-driven sampling, accuracy performance modeling, cost-accuracy tradeoff]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Gur-Eyal Sela, Kumar Krishna Agrawal, Bharathan Balaji, Joseph Gonzalez, Ion Stoica"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," UC Berkeley, Amazon"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24386",children:"https://arxiv.org/pdf/2512.24386"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A measurement-driven planner that estimates the cost-benefit tradeoff of sampling to avoid inefficient sampling. 2. A lightweight, data-driven performance model to improve per-segment accuracy prediction. 3. A new DMSS system (RedunCut) that reduces compute cost by 14-62% at fixed accuracy across diverse video workloads and remains robust to limited data and drift."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b99d771bb4464484bc20a905a41cf7ba47990b34219a4a1e3c0b5dc5c0c242bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b99d771bb4464484bc20a905a41cf7ba47990b34219a4a1e3c0b5dc5c0c242bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high inference cost in live video analytics by proposing RedunCut, a dynamic model size selection system. It introduces a measurement-driven planner to optimize sampling and a data-driven model to predict accuracy, reducing compute costs by 14-62% while maintaining target accuracy across diverse video types. The system demonstrates robustness to limited historical data and concept drift."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[RedunCut: Low-Cost Live Video Analytics] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u9ad8\u63a8\u7406\u6210\u672c/High Inference Cost]\n    Problem --\x3e P2[\u73b0\u6709\u65b9\u6cd5\u6cdb\u5316\u6027\u5dee/Prior Methods Fail to Generalize]\n    P2 --\x3e P2_1[\u91c7\u6837\u6548\u7387\u4f4e/Inefficient Sampling]\n    P2 --\x3e P2_2[\u7cbe\u5ea6\u9884\u6d4b\u4e0d\u51c6/Inaccurate Accuracy Prediction]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u6d4b\u91cf\u9a71\u52a8\u7684\u89c4\u5212\u5668/Measurement-Driven Planner]\n    Method --\x3e M2[\u8f7b\u91cf\u7ea7\u6027\u80fd\u6a21\u578b/Lightweight Performance Model]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6210\u672c\u964d\u4f4e 14-62%/Cost Reduction 14-62%]\n    Results --\x3e R2[\u4fdd\u6301\u76ee\u6807\u7cbe\u5ea6/Maintains Target Accuracy]\n    Results --\x3e R3[\u5bf9\u6570\u636e\u6f02\u79fb\u9c81\u68d2/Robust to Drift]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] PackKV: Reducing KV Cache Memory Footprint through LLM-Aware Lossy Compression"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [KV cache, lossy compression, memory footprint, GPU kernels, attention mechanism]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bo Jiang, Taolue Yang, Youyuan Liu, Xubin He, Sheng Di, Sian Jin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Temple University, Argonne National Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24449",children:"https://arxiv.org/pdf/2512.24449"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/BoJiang03/PackKV",children:"https://github.com/BoJiang03/PackKV"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes PackKV, a generic KV cache management framework featuring novel lossy compression techniques specifically tailored to KV cache data characteristics. 2. Presents a careful co-design of compression algorithms and system architecture that is compatible with the dynamically growing KV cache while preserving high computational efficiency. 3. Achieves significantly higher memory reduction rates and execution throughput compared to state-of-the-art methods, effectively eliminating decompression overhead and accelerating matrix-vector multiplication."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42e07bd3aaf7626174ef50b03ee71ac8de443f8fb5560e374d8293b4df52b84f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42e07bd3aaf7626174ef50b03ee71ac8de443f8fb5560e374d8293b4df52b84f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high memory footprint of the KV cache during long-context LLM inference by proposing PackKV, a framework that uses LLM-aware lossy compression. PackKV co-designs compression algorithms and system architecture to reduce memory usage while maintaining computational efficiency. The results show that PackKV achieves superior memory reduction and higher throughput compared to existing quantization methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[PackKV: Reducing KV Cache Memory Footprint] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\u5927/Large KV Cache Memory Footprint]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: LLM\u611f\u77e5\u7684\u6709\u635f\u538b\u7f29/LLM-Aware Lossy Compression]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u66f4\u9ad8\u5185\u5b58\u51cf\u5c11\u4e0e\u541e\u5410\u91cf/Higher Memory Reduction & Throughput]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Document Data Matching for Blockchain-Supported Real Estate"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [decentralized systems], [Verifiable Credentials, Optical Character Recognition, Natural Language Processing, Blockchain, Data Matching]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Henrique Lin, Tiago Dias, Miguel Correia"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," INESC-ID, Instituto Superior T\xe9cnico, Universidade de Lisboa, Unlockit"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24457",children:"https://arxiv.org/pdf/2512.24457"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Development of a prototype system that automates the extraction of key information from heterogeneous real estate documents using an OCR and NLP pipeline trained on synthetic data. 2. A framework for converting extracted document data into standardized Verifiable Credentials and performing automated data matching to detect inconsistencies. 3. Integration of blockchain as a decentralized trust layer to reinforce transparency and integrity in document verification and management."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77d42eaf9ccd48f40b91694b8109e5b2c7abc796e86c6fd2151ac05f73c2f492_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77d42eaf9ccd48f40b91694b8109e5b2c7abc796e86c6fd2151ac05f73c2f492_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the inefficiency and fraud risk in manual real estate document handling by proposing a system that integrates OCR, NLP, and Verifiable Credentials to automate document extraction and verification, backed by a blockchain trust layer. The developed prototype demonstrates competitive accuracy in information extraction and reduces verification time while maintaining reliability. The framework shows potential to streamline transactions and enhance trust in the real estate sector."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Document Data Matching for Blockchain-Supported Real Estate] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Manual document handling in real estate is inefficient and prone to fraud.)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Integrates OCR, NLP, and Verifiable Credentials for automated extraction and verification, using blockchain for trust.)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Prototype achieves competitive accuracy and reduces verification time, demonstrating potential to streamline transactions.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Understanding LLM Checkpoint/Restore I/O Strategies and Patterns"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [checkpoint/restore, I/O characterization, liburing, I/O coalescing, parallel file systems]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mikaila J. Gossman, Avinash Maurya, Bogdan Nicolae, Jon C. Calhoun"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Clemson University, Argonne National Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24511",children:"https://arxiv.org/pdf/2512.24511"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed microbenchmarks to quantify trade-offs of using the kernel-accelerated I/O library ",(0,r.jsx)(n.code,{children:"liburing"})," for LLM checkpointing, evaluating interactions between aggregation, alignment, and I/O coalescing. 2. Demonstrated that file system-aware aggregation and I/O coalescing strategies are critical for restoring bandwidth and reducing metadata overhead, significantly outperforming uncoalesced operations. 3. Achieved substantial performance improvements over state-of-the-art engines, with up to 3.9x higher write throughput than DataStates-LLM and 7.6x higher than TorchSnapshot."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a135466d9791e7bf6694d7dbe73c7c7a28f3f0c0d670bddbb0b4be458fd22e58_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a135466d9791e7bf6694d7dbe73c7c7a28f3f0c0d670bddbb0b4be458fd22e58_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the I/O bottleneck in checkpointing large language models (LLMs) by investigating the use of the ",(0,r.jsx)(n.code,{children:"liburing"})," library for optimized I/O operations. The authors propose and evaluate strategies like aggregation and I/O coalescing to improve performance. Their approach significantly outperforms existing checkpointing engines, highlighting the need for file system-aware I/O strategies in modern LLM training systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A["Understanding LLM Checkpoint/Restore I/O Strategies and Patterns<br/>\u8bba\u6587\u6807\u9898"] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B["\u6838\u5fc3\u95ee\u9898/Problem<br/>LLM checkpoint/restore is a big-data I/O bottleneck<br/>LLM\u68c0\u67e5\u70b9/\u6062\u590d\u662f\u5927\u6570\u636eI/O\u74f6\u9888"]\n    C["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Microbenchmark liburing, evaluate aggregation & coalescing<br/>\u5bf9liburing\u8fdb\u884c\u5fae\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u805a\u5408\u4e0e\u5408\u5e76"]\n    D["\u5173\u952e\u7ed3\u679c/Results<br/>3.9x-7.6x higher throughput vs. SOTA<br/>\u76f8\u6bd4SOTA\u541e\u5410\u91cf\u63d0\u53473.9-7.6\u500d"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [distributed bilevel optimization, resource-adaptive, hypergradient estimator, convergence analysis, dual pruning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mingyi Li, Xiao Zhang, Ruisheng Zheng, Hongjian Shi, Yuan Yuan, Xiuzhen Cheng, Dongxiao Yu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shandong University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24667",children:"https://arxiv.org/pdf/2512.24667"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the first resource-adaptive distributed bilevel optimization framework that allows clients to optimize submodels based on their available computational resources. 2. Introduces a second-order free hypergradient estimator to reduce computational overhead on resource-limited clients. 3. Provides theoretical convergence analysis for the proposed methods (RABO and RAFBO), showing they achieve an asymptotically optimal convergence rate dominated by the minimum coverage of outer parameters."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1a37c13f80adceef30f4612f5b9f03192647fcb35238d17be6ae91567195d2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1a37c13f80adceef30f4612f5b9f03192647fcb35238d17be6ae91567195d2_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of applying distributed bilevel optimization to large-scale models on resource-limited clients by proposing a resource-adaptive framework. The method uses a second-order free hypergradient estimator and allows clients to optimize submodels adapted to their available resources. Theoretical analysis shows the proposed methods achieve optimal convergence rates, and experiments demonstrate their effectiveness and computational efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Traditional distributed bilevel optimization is computationally excessive for low-resource clients with large-scale models.]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose a resource-adaptive framework with a second-order free hypergradient estimator, enabling clients to optimize submodels based on available resources.]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: The proposed methods (RABO, RAFBO) achieve an asymptotically optimal convergence rate of O(1/\u221aC*xQ), proven by theory and validated by experiments.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] AI-Driven Cloud Resource Optimization for Multi-Cluster Environments"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [multi-cluster systems, resource optimization, predictive learning, policy-aware decision-making, cross-cluster telemetry]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vinoth Punniyamoorthy, Akash Kumar Agarwal, Bikesh Kumar, Abhirup Mazumder, Kabilan Kannan, Sumit Saha"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," IEEE (affiliations indicate authors are IEEE Senior Members, with industry affiliations from Albertsons and East West Bank, USA)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24914",children:"https://arxiv.org/pdf/2512.24914"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An AI-driven framework for adaptive resource optimization across multi-cluster cloud systems, moving beyond reactive, cluster-centric approaches. 2. Integration of predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management. 3. A prototype demonstrating improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02143e20715d24c6ab11a29c3710ca28e3f39c48ce36f9862a254d3564252726_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02143e20715d24c6ab11a29c3710ca28e3f39c48ce36f9862a254d3564252726_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an AI-driven framework to address the problem of inefficient and reactive resource management in multi-cluster cloud environments. The method uses predictive learning and policy-aware decision-making on cross-cluster telemetry to proactively optimize resource allocation for performance, cost, and reliability. The results show the framework improves resource efficiency and system stability compared to traditional approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AI-Driven Cloud Resource Optimization for Multi-Cluster Environments] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u53cd\u5e94\u5f0f\u4e14\u96c6\u7fa4\u4e2d\u5fc3\u5316 / Existing approaches are reactive and cluster-centric]\n    B --\x3e B2[\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u4f4e\u6548\u548c\u5ef6\u8fdf\u9002\u5e94 / Causes inefficient resource utilization and delayed adaptation]\n    C --\x3e C1[AI\u9a71\u52a8\u6846\u67b6\u96c6\u6210\u9884\u6d4b\u5b66\u4e60 / AI-driven framework integrates predictive learning]\n    C --\x3e C2[\u7b56\u7565\u611f\u77e5\u51b3\u7b56\u4e0e\u6301\u7eed\u53cd\u9988 / Policy-aware decision-making and continuous feedback]\n    C --\x3e C3[\u5206\u6790\u8de8\u96c6\u7fa4\u9065\u6d4b\u6570\u636e / Analyzes cross-cluster telemetry]\n    D --\x3e D1[\u63d0\u9ad8\u8d44\u6e90\u6548\u7387 / Improved resource efficiency]\n    D --\x3e D2[\u66f4\u5feb\u7a33\u5b9a\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8 / Faster stabilization during workload fluctuations]\n    D --\x3e D3[\u51cf\u5c11\u6027\u80fd\u53d8\u5f02 / Reduced performance variability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Reliable and Resilient Collective Communication Library for LLM Training and Serving"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [fault-tolerant collective communication, multi-NIC failover, connection migration, bandwidth-aware load redistribution, resilient collective algorithms]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wei Wang, Nengneng Yu, Sixian Xiong, Zaoxing Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Maryland, College Park"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25059",children:"https://arxiv.org/pdf/2512.25059"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/r2cc-project/R-2CCL",children:"https://github.com/r2cc-project/R-2CCL"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A fault-tolerant communication library (R\xb2CCL) that provides lossless, low-overhead failover by exploiting multi-NIC hardware. 2. Techniques including rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under network failures. 3. Demonstrated high robustness to NIC failures with minimal overhead (<1% for training, <3% for inference) and significant performance improvements over baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd037366831b8135233f491feff11095f79c30662f36cb517794f6588542c452_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd037366831b8135233f491feff11095f79c30662f36cb517794f6588542c452_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents R\xb2CCL, a fault-tolerant collective communication library designed to handle network faults in large-scale LLM training and serving. It achieves low-overhead recovery through techniques like rapid connection migration and bandwidth-aware load redistribution. Evaluation shows it incurs minimal performance overhead and significantly outperforms existing solutions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Reliable and Resilient Collective Communication Library for LLM Training and Serving] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Network faults waste GPU hours and cause job failures in large-scale ML clusters]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: R\xb2CCL library with rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms]\n    Results[\u5173\u952e\u7ed3\u679c/Results: <1% training overhead, <3% inference overhead, 12.18x-47x faster than baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [heuristic synthesis, evolutionary search, instance-optimal, LLM code generation, cache eviction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The University of Texas at Austin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25065",children:"https://arxiv.org/pdf/2512.25065"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Vulcan, a framework that recasts heuristic design as an automated search problem using LLMs to synthesize instance-optimal heuristics tailored to specific deployment contexts. 2. Introduces LLM-friendly, task-agnostic interfaces that separate policy and mechanism, making the synthesis tractable and enabling even small LLMs to generate correct code. 3. Demonstrates the framework's effectiveness by synthesizing heuristics for cache eviction and memory tiering that outperform state-of-the-art human-designed algorithms."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Vulcan, a framework that uses LLM-driven evolutionary search to automatically synthesize instance-optimal system heuristics, tailored to specific workloads and hardware. It introduces task-agnostic interfaces to separate policy from mechanism, enabling efficient code generation. The synthesized heuristics for cache eviction and memory tiering were shown to outperform existing state-of-the-art algorithms."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Manual heuristic design is slow and cannot adapt to changing hardware and workloads.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Use LLM-driven evolutionary search over task-agnostic interfaces to synthesize instance-optimal heuristics.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Synthesized heuristics outperform state-of-the-art algorithms in cache eviction and memory tiering.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Adaptive Resource Orchestration for Distributed Quantum Computing Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [Distributed Quantum Computing], [Modular Entanglement Hub, Quantum Network Orchestrator, Teleportation Success Rate, Ebit Cache, Monte Carlo Simulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kuan-Cheng Chen, Felix Burt, Nitish K. Panigrahy, Kin K. Leung"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Imperial College London, Binghamton University SUNY"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24902",children:"https://arxiv.org/pdf/2512.24902"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed the Modular Entanglement Hub (ModEn-Hub) architecture, a hub-and-spoke photonic interconnect with a central orchestrator for managing entanglement resources. 2. Introduced an adaptive orchestration policy featuring logarithmically scaled parallelism and opportunistic caching of entanglement bits (ebits). 3. Demonstrated through Monte Carlo simulation that the orchestrated system sustains high teleportation success rates (~90%) across many QPUs, significantly outperforming a naive sequential baseline."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cdc243a82e638196fde6023c44f1f4a5ab3b6055535ac757574242b690b212_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cdc243a82e638196fde6023c44f1f4a5ab3b6055535ac757574242b690b212_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," To scale quantum computing, the paper proposes the Modular Entanglement Hub (ModEn-Hub) architecture, which centralizes entanglement generation and uses an adaptive orchestrator to manage resources. Simulation results show this approach maintains a high teleportation success rate of about 90% across 1-128 quantum processors, vastly outperforming a simple baseline, thus enabling scalable distributed quantum-HPC systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Adaptive Resource Orchestration for Distributed Quantum Computing Systems"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Scaling quantum computing requires networking multiple QPUs, but managing entanglement is challenging."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Propose Modular Entanglement Hub (ModEn-Hub) with an adaptive orchestrator for parallel entanglement attempts and caching."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Orchestration sustains ~90% teleportation success vs. ~30% for baseline, enabling scalable quantum-HPC."]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "reinforcement learning" total: 46'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23719",children:"https://arxiv.org/pdf/2512.23719"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[CAD-to-mesh\u6d41\u7a0b\u74f6\u9888 / CAD-to-mesh Pipeline Bottlenecks]\n    C --\x3e C1[AI\u8f85\u52a9\u51e0\u4f55\u4e0e\u7f51\u683c\u751f\u6210 / AI-aided Geometry & Meshing]\n    C --\x3e C2[\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 / Machine Learning Methods]\n    C --\x3e C3[\u65b0\u5174\u81ea\u52a8\u5316\u5de5\u5177 / Emerging Automation Tools]\n    C1 --\x3e C1a[\u90e8\u4ef6\u5206\u7c7b / Part Classification]\n    C1 --\x3e C1b[\u7f51\u683c\u8d28\u91cf\u9884\u6d4b / Mesh Quality Prediction]\n    C1 --\x3e C1c[\u53bb\u7279\u5f81\u5316 / Defeaturing]\n    C2 --\x3e C2a[\u975e\u7ed3\u6784\u5316/\u5757\u7ed3\u6784\u5316\u7f51\u683c / Unstructured/Block-structured Meshing]\n    C2 --\x3e C2b[\u4f53\u79ef\u53c2\u6570\u5316 / Volumetric Parameterizations]\n    C2 --\x3e C2c[\u5e76\u884c\u7f51\u683c\u751f\u6210 / Parallel Mesh Generation]\n    C3 --\x3e C3a[\u5f3a\u5316\u5b66\u4e60 / Reinforcement Learning]\n    C3 --\x3e C3b[\u5927\u8bed\u8a00\u6a21\u578b / Large Language Models]\n    D --\x3e D1[AI\u4f5c\u4e3a\u8f85\u52a9\u6280\u672f / AI as Assistive Technology]\n    D --\x3e D2[\u4ee3\u8868\u6027\u65b9\u6cd5\u4e0e\u90e8\u7f72 / Representative Methods & Deployments]\n    D --\x3e D3[\u5173\u952e\u7814\u7a76\u6311\u6218 / Key Research Challenges]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [skill graph, verifiable rewards, continual memory, experience synthesis, audit logging]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ken Huang, Jerry Huang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," DistributedApps.ai, OWASP, Kleiner Perkins"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23760",children:"https://arxiv.org/pdf/2512.23760"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Audited Skill-Graph Self-Improvement (ASG-SI) framework, which treats agent self-improvement as the iterative compilation of an auditable, growing skill graph. 2. Introduces a verifier-auditor mechanism that uses replayable evidence and decomposed rewards to gate skill promotion, enabling independent audit and governance. 3. Integrates experience synthesis for scalable testing and continual memory control to manage context growth and preserve long-horizon performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses security and governance challenges in self-improving AI agents, such as reward hacking and opaque behavioral drift. It proposes the ASG-SI framework, which compiles agent improvements into an auditable skill graph verified by replayable evidence. The approach reframes self-improvement as the accumulation of verifiable, reusable capabilities for reproducible evaluation and operational governance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Audited Skill-Graph Self-Improvement (ASG-SI) / \u5ba1\u8ba1\u6280\u80fd\u56fe\u81ea\u6211\u6539\u8fdb"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem"] --\x3e P1["\u90e8\u7f72\u7684\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u4e0e\u6cbb\u7406\u6311\u6218 / Deployed self-improving agents pose security & governance challenges"]\n    P1 --\x3e P2["\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u3001\u884c\u4e3a\u6f02\u79fb\u3001\u4e0d\u900f\u660e\u7684\u66f4\u65b0 / Reward hacking, behavioral drift, opaque updates"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method"] --\x3e M1["ASG-SI \u6846\u67b6 / ASG-SI Framework"]\n    M1 --\x3e M2["\u5c06\u6539\u8fdb\u7f16\u8bd1\u4e3a\u53ef\u5ba1\u8ba1\u6280\u80fd\u56fe / Compile improvements into auditable skill graph"]\n    M2 --\x3e M3["\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7684\u8bc1\u636e\u548c\u53ef\u5206\u89e3\u5956\u52b1\u8fdb\u884c\u6280\u80fd\u63d0\u5347 / Verifier-backed evidence & decomposed rewards gate skill promotion"]\n    M3 --\x3e M4["\u96c6\u6210\u7ecf\u9a8c\u5408\u6210\u548c\u6301\u7eed\u8bb0\u5fc6\u63a7\u5236 / Integrate experience synthesis & continual memory control"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e R1["\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u3001\u53ef\u91cd\u7528\u7684\u80fd\u529b\u79ef\u7d2f / Provides accumulation of verifiable, reusable capabilities"]\n    R1 --\x3e R2["\u4e3a\u81ea\u6211\u6539\u8fdbAI\u63d0\u4f9b\u53ef\u590d\u73b0\u8bc4\u4f30\u548c\u64cd\u4f5c\u6cbb\u7406\u7684\u8def\u5f84 / Offers path for reproducible evaluation & operational governance of self-improving AI"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [safe reinforcement learning], [constrained MDP, trust region policy optimization, natural policy gradient, safety gymnasium, hard constraints]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ankit Kanwar, Dominik Wagner, Luke Ong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sony Corporation, Nanyang Technological University (NTU Singapore)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23770",children:"https://arxiv.org/pdf/2512.23770"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new algorithm for hard-constrained RL that adaptively biases policy updates towards safety while seeking reward improvement. 2. Introduces a trust-region update using a convex combination of the natural policy gradients of cost and reward to ensure a fixed fraction of optimal cost reduction per step. 3. Provides a theoretical guarantee of local progress towards safety and demonstrates superior balance of safety and task performance on Safety Gymnasium benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of reinforcement learning under hard safety constraints, where existing methods struggle to avoid violations without sacrificing reward. It proposes SB-TRPO, an algorithm that performs trust-region updates by combining reward and cost gradients to bias updates towards safety. Experiments show that SB-TRPO achieves a better balance of safety and task completion than state-of-the-art methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Safety-Biased Policy Optimisation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: RL in safety-critical domains requires strict constraint adherence without sacrificing reward performance.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: SB-TRPO uses convex combination of natural policy gradients for cost and reward in trust-region updates.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Achieves best balance of safety and task completion on Safety Gymnasium benchmarks.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks on llms], [denial-of-service, over-generation, black-box attack, evolutionary search, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Manu, Yi Guo, Jo Plested, Tim Lynar, Kanchana Thilakarathna, Nirhoshan Sivaroopan, Jack Yang, Wangli Yang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Western Sydney University, University of New South Wales Canberra, The University of Sydney, University of Wollongong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23779",children:"https://arxiv.org/pdf/2512.23779"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a black-box, query-only benchmark for evaluating prompt-induced denial-of-service attacks on LLMs. 2. Proposes two novel prompt-only attackers: an evolutionary search method (EOGen) and a goal-conditioned reinforcement learning method (RL-GOAL). 3. Defines the Over-Generation Factor (OGF) as a key metric to quantify attack success and characterize model vulnerability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of denial-of-service attacks on large language models via prompt-induced over-generation. It proposes a standardized black-box benchmark and two automated attack methods, EOGen and RL-GOAL, to find adversarial prefixes that delay model termination. The results show that the RL-GOAL attacker is particularly effective at forcing models to generate excessively long outputs, highlighting a significant vulnerability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Prompt-Induced Over-Generation as Denial-of-Service<br/>\u63d0\u793a\u8bf1\u5bfc\u8fc7\u5ea6\u751f\u6210\u4f5c\u4e3a\u62d2\u7edd\u670d\u52a1\u653b\u51fb] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>LLM\u8fc7\u5ea6\u751f\u6210\u5bfc\u81f4\u670d\u52a1\u62d2\u7edd\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u589e\u52a0]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u9ed1\u76d2\u57fa\u51c6\u4e0e\u4e24\u79cd\u653b\u51fb\u8005: EOGen(\u8fdb\u5316\u641c\u7d22)\u548cRL-GOAL(\u5f3a\u5316\u5b66\u4e60)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>RL-GOAL\u653b\u51fb\u8005\u5b9e\u73b0\u66f4\u9ad8\u7684\u5e73\u5747\u8fc7\u5ea6\u751f\u6210\u56e0\u5b50(OGF)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [ensemble reinforcement learning, selective update, variational autoencoder, high-frequency trading, risk management]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Molei Qin, Xinyu Cai, Yewen Li, Haochong Xia, Chuqiao Zong, Shuo Sun, Xinrun Wang, Bo An"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Nanyang Technological University, Singapore Management University, Hong Kong University of Science and Technology (Guangzhou)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23773",children:"https://arxiv.org/pdf/2512.23773"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A selective update mechanism for ensemble Q-learners using ensemble TD errors to stabilize training and improve convergence in high-leverage environments. 2. A risk-aware filtering and routing mechanism that uses VAEs to model market state dynamics and identify agent capability boundaries, enabling dynamic policy selection to mitigate risk. 3. A novel three-stage ensemble RL framework (FineFT) that integrates stable training and risk management, demonstrating superior profitability and over 40% risk reduction in crypto futures trading."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes FineFT, a three-stage ensemble reinforcement learning framework designed to address the challenges of high leverage and unseen market states in futures trading. The method uses selective updates for stable training and VAEs for risk-aware policy routing, achieving higher profitability and significantly lower risk compared to state-of-the-art baselines in high-frequency crypto futures experiments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[FineFT: Efficient and Risk-Aware Ensemble RL for Futures Trading] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u9ad8\u6760\u6746\u653e\u5927\u6ce2\u52a8/High leverage amplifies reward fluctuations]\n    B --\x3e B2[\u7f3a\u4e4f\u80fd\u529b\u8fb9\u754c\u610f\u8bc6/Lack of self-awareness of capability boundaries]\n    C --\x3e C1[\u9636\u6bb5I: \u9009\u62e9\u6027\u66f4\u65b0/Stage I: Selective Update]\n    C --\x3e C2[\u9636\u6bb5II: \u8fc7\u6ee4\u4e0eVAE\u8bad\u7ec3/Stage II: Filtering & VAE Training]\n    C --\x3e C3[\u9636\u6bb5III: \u52a8\u6001\u8def\u7531/Stage III: Dynamic Routing]\n    D --\x3e D1[\u8d85\u8d8a12\u4e2aSOTA\u57fa\u7ebf/Outperforms 12 SOTA baselines]\n    D --\x3e D2[\u98ce\u9669\u964d\u4f4e\u8d8540%/Risk reduced by >40%]\n    D --\x3e D3[\u5b9e\u73b0\u66f4\u9ad8\u76c8\u5229/Achieves superior profitability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [max-entropy reinforcement learning, flow-based policy, flow matching, soft actor-critic, linear quadratic regulator]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuyang Zhang, Yang Hu, Bo Dai, Na Li"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Harvard University, Georgia Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23870",children:"https://arxiv.org/pdf/2512.23870"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a variant of the Soft Actor-Critic (SAC) algorithm that uses flow-based models to parameterize the policy, enhancing expressiveness. 2. Introduces an online variant of flow matching called Importance Sampling Flow Matching (ISFM) for policy updates using samples from a user-specified distribution instead of the unknown target. 3. Provides a theoretical analysis of ISFM, characterizing how the choice of sampling distribution impacts learning efficiency, and validates the method with a case study on max-entropy Linear Quadratic Regulator (LQR) problems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d43d8f718c30e1679c2274346eea229b95864ab6207cedce0e09dc784832028_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d43d8f718c30e1679c2274346eea229b95864ab6207cedce0e09dc784832028_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of simple policy approximations in max-entropy reinforcement learning by proposing a new SAC variant that uses expressive flow-based policies. The method employs a novel online flow matching technique (ISFM) for efficient policy updates and demonstrates its effectiveness by learning the optimal action distribution in max-entropy LQR problems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Max-Entropy RL with Flow Matching and LQR Case Study] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[SAC\u4f7f\u7528\u7b80\u5355\u7b56\u7565\u7c7b\u727a\u7272\u4e86\u8868\u8fbe\u6027\u548c\u9c81\u68d2\u6027/SAC's simple policy classes sacrifice expressiveness & robustness]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u63d0\u51fa\u4f7f\u7528\u6d41\u6a21\u578b\u53c2\u6570\u5316\u7b56\u7565\u7684SAC\u53d8\u4f53/Propose SAC variant with flow-based policy]\n    Method --\x3e M2[\u5f00\u53d1\u5728\u7ebf\u6d41\u5339\u914d\u53d8\u4f53ISFM\u8fdb\u884c\u7b56\u7565\u66f4\u65b0/Develop online flow matching variant ISFM for policy update]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7406\u8bba\u5206\u6790ISFM\u91c7\u6837\u5206\u5e03\u7684\u5f71\u54cd/Theoretical analysis of ISFM sampling distribution impact]\n    Results --\x3e R2[\u5728\u6700\u5927\u71b5LQR\u95ee\u9898\u4e0a\u9a8c\u8bc1\u7b97\u6cd5\u6709\u6548\u6027/Validate algorithm on max-entropy LQR problems]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Distributed Beamforming in Massive MIMO Communication for a Constellation of Airborne Platform Stations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [distributed beamforming, multi-agent deep reinforcement learning, massive MIMO, aerial platform stations, channel state information]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Hesam Khoshkbari, Georges Kaddoum, Bassant Selim, Omid Abbasi, Halim Yanikomeroglu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," \xc9cole de technologie sup\xe9rieure, Carleton University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23900",children:"https://arxiv.org/pdf/2512.23900"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a distributed beamforming framework for massive MIMO networks using a constellation of aerial platform stations (APSs) without requiring CSI sharing among agents, reducing overhead. 2. Introduces an entropy-based multi-agent deep reinforcement learning (DRL) model where each APS acts as an independent agent, capable of operating with imperfect channel state information (CSI). 3. Demonstrates through simulations that the proposed method outperforms conventional techniques like ZF and MRT in high-interference scenarios and shows robustness to CSI errors and scalability with increasing users."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d49692981b3fd19b522f0e296bc9eed43c81e4a2c2f5a5b23a0691d21b1d5a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d49692981b3fd19b522f0e296bc9eed43c81e4a2c2f5a5b23a0691d21b1d5a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a distributed beamforming framework for massive MIMO networks using a constellation of aerial platforms. It employs an entropy-based multi-agent deep reinforcement learning model where each platform acts independently without sharing channel state information, reducing overhead. Simulation results show the method outperforms traditional beamforming techniques in high-interference environments and remains robust and scalable."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Distributed Beamforming for Airborne Platform Stations<br/>\u5206\u5e03\u5f0f\u6ce2\u675f\u8d4b\u5f62\u7528\u4e8e\u7a7a\u4e2d\u5e73\u53f0\u7ad9"] --\x3e Problem["Beamforming & Interference in NTBS Networks<br/>NTBS\u7f51\u7edc\u4e2d\u7684\u6ce2\u675f\u8d4b\u5f62\u4e0e\u5e72\u6270"]\n    Root --\x3e Method["Entropy-based Multi-agent DRL without CSI Sharing<br/>\u65e0\u9700CSI\u5171\u4eab\u7684\u57fa\u4e8e\u71b5\u7684\u591a\u667a\u80fd\u4f53DRL"]\n    Root --\x3e Results["Outperforms ZF/MRT, Robust, Scalable<br/>\u4f18\u4e8eZF/MRT\uff0c\u9c81\u68d2\uff0c\u53ef\u6269\u5c55"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [neuromorphic computing], [temporal inductive bias, dissipative dynamics, spiking neural networks, generalization, phase-space analysis]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xia Chen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Technische Universit\xe4t M\xfcnchen (Georg Nemetschek Institute, Munich Data Science Institute)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23916",children:"https://arxiv.org/pdf/2512.23916"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes that physical constraints (like metabolic budgets) act not as limitations but as a temporal inductive bias that promotes generalization in neural systems. 2. Reveals through phase-space analysis that proper dissipative dynamics compress the solution space and align with spectral bias to abstract invariant features, unlike expansive dynamics. 3. Empirically demonstrates across multiple tasks (classification, reconstruction, RL) that a critical "transition" regime of dynamical constraints maximizes generalization capability.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b28592acb015fa66de83fc46eda200fa0018a58a31fbfacdf9dd0fced988bac9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b28592acb015fa66de83fc46eda200fa0018a58a31fbfacdf9dd0fced988bac9_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper argues that physical constraints, often seen as limitations, can serve as a beneficial temporal inductive bias for generalization in neural networks. It analyzes signal propagation to show that dissipative dynamics compress phase space and abstract features, a principle implemented using Spiking Neural Networks. Experiments across various tasks confirm that properly constrained temporal dynamics maximize generalization, suggesting a new direction for robust AI development."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A["Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: Conventional deep learning uses unconstrained optimization, unlike biologically constrained systems."]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: Propose temporal constraints as inductive bias; analyze phase-space dynamics; use Spiking Neural Networks (SNNs) for temporal integration."]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results: Dissipative dynamics maximize generalization; a critical \'transition\' regime is identified across tasks."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [spelling correction], [reinforcement learning, zero-supervision, Chinese spelling correction, PPO, cluster-consensus reward]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhiming Lin, Kai Zhao, Sophie Zhang, Peilai Yu, Canran Xiao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Nankai University, Western Sydney University, Sun Yat-sen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23971",children:"https://arxiv.org/pdf/2512.23971"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CEC-Zero, a zero-supervision RL framework for Chinese spelling correction that enables LLMs to self-correct without labeled data. 2. Introduces a cluster-consensus reward mechanism based on semantic similarity and candidate agreement to guide policy optimization. 3. Demonstrates superior performance over supervised and fine-tuned LLM baselines across multiple benchmarks, establishing a label-free paradigm."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f497dc978d283e6c34450b390462e1f0ee33c507d41a14f70226f631c7d28168_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f497dc978d283e6c34450b390462e1f0ee33c507d41a14f70226f631c7d28168_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of Chinese spelling correction (CSC) by introducing CEC-Zero, a zero-supervision reinforcement learning framework. The method synthesizes errors from clean text and uses a novel cluster-consensus reward to optimize an LLM policy with PPO, eliminating the need for costly annotations. It significantly outperforms existing supervised and fine-tuned methods on multiple benchmarks, offering a robust and scalable solution for real-world noisy text processing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5927\u89c4\u6a21\u4e2d\u6587\u62fc\u5199\u7ea0\u9519\u4f9d\u8d56\u6602\u8d35\u6807\u6ce8\uff0c\u73b0\u6709\u65b9\u6cd5\u5bf9\u65b0\u578b\u9519\u8bef\u4e0d\u9c81\u68d2/Large-scale Chinese spelling correction relies on costly annotations; existing methods lack robustness to novel errors.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u96f6\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5408\u6210\u9519\u8bef\u8f93\u5165\uff0c\u4f7f\u7528\u805a\u7c7b\u5171\u8bc6\u5956\u52b1\u548cPPO\u4f18\u5316/Proposes a zero-supervision RL framework, synthesizes errorful inputs, uses cluster-consensus rewards and PPO for optimization.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u57289\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8d85\u8d8a\u76d1\u7763\u57fa\u7ebf10-13 F1\u70b9\uff0c\u8d85\u8d8aLLM\u5fae\u8c035-8\u70b9/Outperforms supervised baselines by 10-13 F1 points and strong LLM fine-tunes by 5-8 points across 9 benchmarks.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] RSAgent: Learning to Reason and Act for Text-Guided Segmentation via Multi-Turn Tool Invocations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [text-guided segmentation], [agentic MLLM, multi-turn tool invocation, iterative mask refinement]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xingqi He, Yujie Zhang, Shuyong Gao, Wenjie Li, Lingyi Hong, Mingxi Chen, Kaixun Jiang, Jiyuan Fu, Wenqiang Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Jiao Tong University School of Medicine"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24023",children:"https://arxiv.org/pdf/2512.24023"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RSAgent, an agentic MLLM that interleaves reasoning and action for segmentation via multi-turn tool invocations, enabling iterative refinement. 2. Builds a data pipeline to synthesize multi-turn reasoning segmentation trajectories for training. 3. Introduces a two-stage training framework combining cold-start supervised fine-tuning with agentic reinforcement learning using fine-grained, task-specific rewards."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492283683a8b1ec7673cb4aa97997d0e1ab70ed4a074c17cfa6a9a5e87c60998_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492283683a8b1ec7673cb4aa97997d0e1ab70ed4a074c17cfa6a9a5e87c60998_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of one-shot methods in text-guided segmentation, where initial errors cannot be corrected. It proposes RSAgent, an agentic multimodal LLM that iteratively uses a segmentation toolbox, observes feedback, and refines its spatial hypotheses over multiple turns. Experiments show RSAgent achieves state-of-the-art performance on benchmarks like ReasonSeg and RefCOCOg."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[RSAgent: Learning to Reason and Act for Text-Guided Segmentation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: One-shot grounding methods lack verification and refinement capabilities]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic MLLM with multi-turn tool invocation for iterative reasoning and mask refinement]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves SOTA on benchmarks (66.5% gIoU on ReasonSeg, 81.5% cIoU on RefCOCOg)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Reinforced Diffusion: Learning to Push the Limits of Anisotropic Diffusion for Image Denoising"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [image denoising], [anisotropic diffusion, reinforcement learning, deep Q-learning, stochastic diffusion]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinran Qin, Yuhui Quan, Ruotao Xu, Hui Ji"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," South China University of Technology, National University of Singapore"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24035",children:"https://arxiv.org/pdf/2512.24035"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A trainable anisotropic diffusion framework for image denoising based on reinforcement learning. 2. Modeling the denoising process as a series of diffusion actions with order learned by deep Q-learning, forming a stochastic anisotropic diffusion process. 3. Demonstrating that the proposed method outperforms existing diffusion-based methods and competes with deep CNN-based methods on multiple noise types."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be25ff96e1d5d489676fdfbae564029c066808ffe1f445710f3d58c023ed964_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be25ff96e1d5d489676fdfbae564029c066808ffe1f445710f3d58c023ed964_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a novel image denoising method called Reinforced Diffusion, which uses deep reinforcement learning (deep Q-learning) to learn the optimal sequence of naive diffusion actions, forming an adaptive stochastic anisotropic diffusion process. This approach overcomes the limitations of traditional fixed diffusion operators. Experimental results show it outperforms other diffusion-based methods and is competitive with state-of-the-art deep CNN-based denoisers."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Reinforced Diffusion: Image Denoising] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Traditional anisotropic diffusion has limited performance due to non-adaptive operators.)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Trainable diffusion framework using Deep Q-Learning to learn action sequences.)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Outperforms diffusion-based methods, competes with deep CNN methods.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [prompt optimization, multi-agent architecture, decision tree protocols, zero-shot alignment, automated debugging]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Natchaya Temyingyong, Daman Jain, Neeraj Kumarsahu, Prabhat Kumar, Rachata Phondi, Wachiravit Modecrua, Krittanon Kaewtawee, Krittin Pachtrachai, Touchapon Kraisingkorn"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Amity AI Research and Application Center"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24040",children:"https://arxiv.org/pdf/2512.24040"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ROAD, a novel framework that treats prompt optimization as a dynamic debugging investigation, eliminating the need for curated gold-standard datasets. 2. Proposes a specialized multi-agent architecture (Analyzer, Optimizer, Coach) to convert unstructured failure logs into structured Decision Tree Protocols. 3. Demonstrates high sample efficiency and performance improvements on both academic benchmarks and a live production system, offering a data-efficient alternative to RL-based methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2d710802d4ef2f4627a2a20e4c9834618953664f1165bf78a33477b890319f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2d710802d4ef2f4627a2a20e4c9834618953664f1165bf78a33477b890319f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of optimizing LLM agents without requiring large, labeled datasets, which are often unavailable in real-world software engineering. It proposes ROAD, a framework that uses a multi-agent architecture to perform automated debugging on failure logs, converting them into structured protocols for improvement. The results show that ROAD is highly sample-efficient and significantly improves agent performance, providing a practical alternative to resource-intensive training methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ROAD: Reflective Optimization via Automated Debugging] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: APO methods need large labeled datasets, but real-world has messy logs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-agent debugging (Analyzer, Optimizer, Coach) to create Decision Tree Protocols]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Sample-efficient, +5.6% success rate, +19% performance on complex tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] HY-MT1.5 Technical Report"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [machine translation], [holistic training framework, on-policy distillation, parameter efficiency]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mao Zheng, Zheng Li, Tao Chen, Mingyang Song, Di Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tencent Hunyuan Team"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24092",children:"https://arxiv.org/pdf/2512.24092"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Tencent-Hunyuan/HY-MT",children:"https://github.com/Tencent-Hunyuan/HY-MT"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of high-performance machine translation models. 2. Proposes a holistic multi-stage training framework integrating general/MT pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. 3. Demonstrates state-of-the-art performance, with the 1.8B model achieving remarkable parameter efficiency and the 7B model surpassing ultra-large proprietary models on challenging benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ef782a5a818ae655e93a8b8755b15f73eb04f3d46c041e15eb5c4a26d7b05b1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ef782a5a818ae655e93a8b8755b15f73eb04f3d46c041e15eb5c4a26d7b05b1_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This report introduces the HY-MT1.5 series of machine translation models, developed using a holistic multi-stage training pipeline. The models, particularly the 1.8B parameter version, show exceptional parameter efficiency, outperforming much larger models and commercial APIs, while the 7B model sets a new state-of-the-art for its size class."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[HY-MT1.5 Technical Report] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u9ad8\u6027\u80fd\u673a\u5668\u7ffb\u8bd1/High-performance Machine Translation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u6574\u4f53\u8bad\u7ec3\u6846\u67b6/Holistic Training Framework]\n    C --\x3e C1[\u591a\u9636\u6bb5\u7ba1\u9053/Multi-stage Pipeline]\n    C1 --\x3e C1a[\u9884\u8bad\u7ec3/Pre-training]\n    C1 --\x3e C1b[\u76d1\u7763\u5fae\u8c03/Supervised Fine-tuning]\n    C1 --\x3e C1c[\u7b56\u7565\u84b8\u998f/On-policy Distillation]\n    C1 --\x3e C1d[\u5f3a\u5316\u5b66\u4e60/Reinforcement Learning]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5353\u8d8a\u6027\u80fd\u4e0e\u6548\u7387/Outstanding Performance & Efficiency]\n    D --\x3e D1[HY-MT1.5-1.8B: \u53c2\u6570\u9ad8\u6548/Parameter Efficient]\n    D --\x3e D2[HY-MT1.5-7B: \u65b0SOTA/New SOTA]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] GARDO: Reinforcing Diffusion Models without Reward Hacking"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [reward hacking, diffusion models, regularization, mode collapse, online RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haoran He, Yuxiao Ye, Jie Liu, Jiajun Liang, Zhiyong Wang, Ziyang Yuan, Xintao Wang, Hangyu Mao, Pengfei Wan, Ling Pan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Hong Kong University of Science and Technology, Kuaishou Technology, CUHK MMLab, The University of Edinburgh"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24138",children:"https://arxiv.org/pdf/2512.24138"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://tinnerhrhe.github.io/gardo_project",children:"https://tinnerhrhe.github.io/gardo_project"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed GARDO, a framework with gated regularization that selectively penalizes high-uncertainty samples to mitigate reward hacking efficiently., 2. Introduced an adaptive regularization mechanism that periodically updates the reference model to align with the online policy, enabling effective exploration., 3. Designed a diversity-aware reward amplification strategy to encourage mode coverage and prevent diversity collapse during RL fine-tuning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of reward hacking in RL-fine-tuned diffusion models, where optimizing imperfect proxy rewards degrades real image quality and diversity. The authors propose GARDO, a framework featuring gated, adaptive regularization and diversity-aware optimization to prevent overfitting, maintain exploration, and enhance diversity. Experiments show GARDO effectively mitigates reward hacking and improves generation diversity without sacrificing sample efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[GARDO: Reinforcing Diffusion Models without Reward Hacking] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Reward Hacking in RL for Diffusion Models/\u6269\u6563\u6a21\u578bRL\u4e2d\u7684\u5956\u52b1\u7834\u89e3]\n    B --\x3e B2[Proxy Reward Mismatch & Mode Collapse/\u4ee3\u7406\u5956\u52b1\u4e0d\u5339\u914d\u4e0e\u6a21\u5f0f\u5d29\u6e83]\n    C --\x3e C1[Gated & Adaptive Regularization/\u95e8\u63a7\u81ea\u9002\u5e94\u6b63\u5219\u5316]\n    C --\x3e C2[Diversity-aware Reward Optimization/\u591a\u6837\u6027\u611f\u77e5\u5956\u52b1\u4f18\u5316]\n    D --\x3e D1[Mitigates Reward Hacking/\u7f13\u89e3\u5956\u52b1\u7834\u89e3]\n    D --\x3e D2[Enhances Diversity & Maintains Efficiency/\u63d0\u5347\u591a\u6837\u6027\u5e76\u4fdd\u6301\u6548\u7387]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [diffusion models], [Preference Mode Collapse, Reinforcement Learning from Human Feedback, reward hacking, generative diversity, directional correction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Chubin Chen, Sujie Hu, Jiashu Zhu, Meiqi Wu, Jintao Chen, Yanxun Li, Nisha Huang, Chengyu Fang, Jiahong Wu, Xiangxiang Chu, Xiu Li"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tsinghua University, AMAP, Alibaba Group"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24146",children:"https://arxiv.org/pdf/2512.24146"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces and quantifies the phenomenon of Preference Mode Collapse (PMC) in diffusion model alignment. 2. Proposes DivGenBench, a novel benchmark to measure the extent of PMC. 3. Proposes the Directional Decoupling Alignment (D\xb2-Align) framework to mitigate PMC by directionally correcting the reward signal."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f62594e4cc99762132258ccba4873b41aea26a85dbeb402b03da55458d0e32bf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f62594e4cc99762132258ccba4873b41aea26a85dbeb402b03da55458d0e32bf_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies Preference Mode Collapse (PMC), where diffusion models over-optimize for reward scores and lose generative diversity. To address this, the authors propose D\xb2-Align, a framework that learns a directional correction to the reward signal to prevent collapse. The method achieves better alignment with human preference while preserving output diversity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898/Paper Title: Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Preference Mode Collapse (PMC)\u5bfc\u81f4\u751f\u6210\u591a\u6837\u6027\u4e0b\u964d/PMC degrades generative diversity]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faD\xb2-Align\u6846\u67b6\uff0c\u65b9\u5411\u6027\u6821\u6b63\u5956\u52b1\u4fe1\u53f7/Proposes D\xb2-Align framework to directionally correct reward signal]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u4fdd\u6301\u591a\u6837\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u597d\u7684\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50/Achieves better human preference alignment while preserving diversity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Fleet Size and Mix Vehicle Routing Problem (FSMVRP), deep reinforcement learning (DRL), Markov Decision Process (MDP), fleet-and-route integrated policy network (FRIPN), remaining graph embedding]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Pengfu Wan, Jiawei Chen, Gangyan Xu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24251",children:"https://arxiv.org/pdf/2512.24251"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Formulates the Fleet Size and Mix Vehicle Routing Problem (FSMVRP) as a Markov Decision Process (MDP) for a deep reinforcement learning approach. 2. Proposes a novel policy network (FRIPN) that integrates fleet composition and routing decisions into a single model. 3. Introduces specialized input embeddings, including a remaining graph embedding, to enhance decision-making for vehicle employment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a deep reinforcement learning method to solve the complex Fleet Size and Mix Vehicle Routing Problem (FSMVRP). The core innovation is a policy network called FRIPN that jointly decides on fleet composition and routing. Experiments show the method is computationally efficient and scalable, producing near-optimal solutions quickly, especially for large-scale problems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: FSMVRP - simultaneous fleet composition & routing)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: DRL-based MDP formulation with FRIPN policy network & remaining graph embedding)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Near-optimal solutions in seconds, high computational efficiency & scalability)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] DRL-TH: Jointly Utilizing Temporal Graph Attention and Hierarchical Fusion for UGV Navigation in Crowded Environments"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [temporal graph attention, hierarchical graph pooling, multi-modal fusion, UGV navigation, deep reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ruitong Li, Lin Zhang, Yuenan Zhao, Chengxin Liu, Ran Song, Wei Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The affiliations are not explicitly provided in the given content. Based on the author names, it is not possible to reliably infer the main research institution(s)."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24284",children:"https://arxiv.org/pdf/2512.24284"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a DRL-based navigation framework (DRL-TH) that integrates historical observations and adaptively fuses multi-modal information. 2. Introduced a Temporal-Guided Graph Attention Network (TG-GAT) to capture temporal context and scene evolution between consecutive frames. 3. Designed a Graph Hierarchical Abstraction Module (GHAM) to dynamically and balance multi-scale representations from RGB and LiDAR features."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83abe1de24f9a7e490d93db45dec754f2a2ff7f3de84d6e6983a358e1d9dff40_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83abe1de24f9a7e490d93db45dec754f2a2ff7f3de84d6e6983a358e1d9dff40_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DRL-TH, a deep reinforcement learning framework for UGV navigation in crowded environments. It addresses limitations of single-frame observation and simple fusion by introducing a temporal graph attention network and a hierarchical graph pooling module for adaptive multi-modal feature integration. Experiments and real-world deployment show that DRL-TH outperforms existing methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[DRL-TH: UGV\u5bfc\u822a\u6846\u67b6] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u5355\u5e27\u89c2\u6d4b/Single-frame observation]\n    Problem --\x3e P2[\u7b80\u5355\u591a\u6a21\u6001\u878d\u5408/Simple multi-modal fusion]\n    P1 --\x3e P1_Sub[\u9650\u5236\u52a8\u6001\u9002\u5e94\u6027/Limits dynamic adaptability]\n    P2 --\x3e P2_Sub[\u96be\u4ee5\u6355\u6349\u65f6\u5e8f\u4e0a\u4e0b\u6587/Hard to capture temporal context]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u65f6\u5e8f\u5f15\u5bfc\u56fe\u6ce8\u610f\u529b\u7f51\u7edc/Temporal-Guided GAT (TG-GAT)]\n    Method --\x3e M2[\u56fe\u5c42\u6b21\u62bd\u8c61\u6a21\u5757/Graph Hierarchical Abstraction Module (GHAM)]\n    M1 --\x3e M1_Sub[\u6355\u6349\u8fde\u7eed\u5e27\u5173\u8054/Captures correlations between consecutive frames]\n    M2 --\x3e M2_Sub[\u52a8\u6001\u878d\u5408RGB\u4e0eLiDAR\u7279\u5f81/Dynamically fuses RGB & LiDAR features]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5/Outperforms existing methods]\n    Results --\x3e R2[\u771f\u5b9eUGV\u4e0a\u8868\u73b0\u826f\u597d/Performs well on real UGV]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Real-world Reinforcement Learning from Suboptimal Interventions"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [human-in-the-loop RL, constrained RL, state-wise Lagrangian, suboptimal interventions, robotic manipulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yinuo Zhao, Huiqian Jin, Lechun Jiang, Xinyi Zhang, Kun Wu, Pei Ren, Zhiyuan Xu, Zhengping Che, Lei Sun, Dapeng Wu, Chi Harold Liu, Jian Tang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing Innovation Center of Humanoid Robotics, City University of Hong Kong, Nankai University, Beijing Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24288",children:"https://arxiv.org/pdf/2512.24288"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SiLRI, a state-wise Lagrangian RL algorithm that formulates the online manipulation problem as a constrained RL optimization where constraint bounds are determined by the uncertainty of human interventions. 2. Introduces a state-wise Lagrange multiplier and solves the problem via a min-max optimization to jointly optimize the policy and the multiplier, enabling exploitation of suboptimal interventions without being constrained by them. 3. Demonstrates through real-world experiments that SiLRI significantly accelerates learning, reducing time to 90% success rate by at least 50% compared to prior methods and achieving 100% success on long-horizon tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of leveraging suboptimal human interventions to accelerate real-world robotic RL without being limited by them. It proposes SiLRI, a state-wise Lagrangian RL algorithm that treats interventions as state-dependent constraints and solves a min-max optimization. Real-world experiments show SiLRI cuts learning time by over 50% and achieves perfect success on complex tasks where other methods fail."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Real-world Reinforcement Learning from Suboptimal Interventions] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u5982\u4f55\u5229\u7528\u53ef\u80fd\u6b21\u4f18\u7684\u4eba\u7c7b\u5e72\u9884\u52a0\u901f\u5b66\u4e60\u800c\u4e0d\u53d7\u5176\u9650\u5236/How to leverage potentially suboptimal human interventions to accelerate learning without being constrained by them]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faSiLRI\uff0c\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u62c9\u683c\u6717\u65e5\u7684RL\u7b97\u6cd5\uff0c\u5c06\u5e72\u9884\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u7ea6\u675f/Propose SiLRI, a state-wise Lagrangian RL algorithm treating intervention uncertainty as constraints]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u5b66\u4e60\u901f\u5ea6\u63d0\u5347>50%\uff0c\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e0a\u8fbe\u5230100%\u6210\u529f\u7387/Learning speed improved >50%, achieved 100% success rate on long-horizon tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [visual thinking, reinforcement learning, chain-of-thought, geometric reasoning, multimodal integration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Meiqi Chen, Fandong Meng, Jie Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Tencent Inc (WeChat AI)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24297",children:"https://arxiv.org/pdf/2512.24297"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces FIGR, a novel method that integrates active visual thinking into multi-step reasoning via end-to-end reinforcement learning. 2. Proposes a mechanism to adaptively regulate when and how to invoke visual reasoning, externalizing structural hypotheses by constructing visual representations. 3. Demonstrates significant performance improvements on challenging mathematical reasoning benchmarks, enhancing the stability and reliability of complex reasoning."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87f7f4c5ac39e44125cddcd070468c932e7b1c2ea80095ffe3322857f26d40ed_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87f7f4c5ac39e44125cddcd070468c932e7b1c2ea80095ffe3322857f26d40ed_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces FIGR, a method that enhances complex reasoning by integrating active visual thinking through reinforcement learning, allowing models to construct visual diagrams during problem-solving. It adaptively decides when to use visual reasoning to better capture spatial and structural relationships. Experiments show FIGR outperforms text-only baselines on mathematical reasoning benchmarks, improving stability and reliability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Text-based reasoning struggles with implicit spatial and structural relationships.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: FIGR integrates active visual thinking via RL to construct visual representations adaptively.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Outperforms text-only baselines, improves stability and reliability on math benchmarks.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Multi-Agent Reinforcement Learning, Centralized Training with Decentralized Execution (CTDE), Model Predictive Control (MPC), Dynamic Computation Allocation, Recommender Systems]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," JD.com, Tsinghua University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24325",children:"https://arxiv.org/pdf/2512.24325"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MaRCA, a multi-agent reinforcement learning framework that models recommender system stages as cooperative agents for end-to-end computation resource allocation. 2. Introduces an AutoBucket TestBench for accurate computation cost estimation in large-scale systems. 3. Designs a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of dynamic computation allocation in large-scale, multi-stage recommender systems under resource constraints. It proposes MaRCA, a multi-agent reinforcement learning framework that uses Centralized Training with Decentralized Execution (CTDE) and integrates a Model Predictive Control-based balancer to optimize revenue. The system was deployed on a major e-commerce platform, handling hundreds of billions of daily requests and achieving a 16.67% revenue uplift using existing resources."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[MaRCA: Multi-Agent RL for Dynamic Computation Allocation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6d41\u91cf\u89c4\u6a21\u589e\u957f\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u9636\u6bb5\u95f4\u4f9d\u8d56\uff0c\u9650\u5236\u5168\u5c40\u6700\u4f18\u6027\u3002]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faMaRCA\u6846\u67b6\uff0c\u5c06\u63a8\u8350\u7cfb\u7edf\u9636\u6bb5\u5efa\u6a21\u4e3a\u5408\u4f5c\u667a\u80fd\u4f53\uff0c\u4f7f\u7528CTDE\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165AutoBucket TestBench\u548c\u57fa\u4e8eMPC\u7684\u6536\u76ca-\u6210\u672c\u5e73\u8861\u5668\u3002]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u9886\u5148\u7684\u5168\u7403\u7535\u5546\u5e73\u53f0\u5e7f\u544a\u7ba1\u7ebf\u4e2d\u7aef\u5230\u7aef\u90e8\u7f72\uff0c\u6bcf\u65e5\u5904\u7406\u6570\u5343\u4ebf\u5e7f\u544a\u8bf7\u6c42\uff0c\u4f7f\u7528\u73b0\u6709\u8ba1\u7b97\u8d44\u6e90\u5b9e\u73b016.67%\u7684\u6536\u76ca\u63d0\u5347\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multimodal agent, reinforcement learning, tool-use, policy optimization, benchmark]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yong Xien Chng, Tao Hu, Wenwen Tong, Xueheng Li, Jiandong Chen, Haojia Yu, Jiefan Lu, Hewei Guo, Hanming Deng, Chengjun Xie, Gao Huang, Dahua Lin, Lewei Lu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," SenseTime Research, Tsinghua University, University of Science and Technology of China"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24330",children:"https://arxiv.org/pdf/2512.24330"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/OpenSenseNova/SenseNova-MARS",children:"https://github.com/OpenSenseNova/SenseNova-MARS"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SenseNova-MARS, a novel framework that empowers Vision-Language Models (VLMs) with interleaved visual reasoning and tool-use capabilities via Reinforcement Learning (RL). 2. Proposes the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve RL training stability and enhance the model's ability to invoke tools and reason effectively. 3. Introduces the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions, for evaluating agentic VLMs on complex visual tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a82c0f2ba917fb46c8e884b39cb5c9d4a0a7e1d4671707b44bf5a18d77fa8e73_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a82c0f2ba917fb46c8e884b39cb5c9d4a0a7e1d4671707b44bf5a18d77fa8e73_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces SenseNova-MARS, a framework that uses reinforcement learning to enable Vision-Language Models to dynamically interleave reasoning with external tools like search and image cropping. The proposed BN-GSPO algorithm improves training stability and tool-use capability. Experiments show the model achieves state-of-the-art performance on search and fine-grained image understanding benchmarks, even surpassing some proprietary models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[SenseNova-MARS] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[VLMs\u7f3a\u4e4f\u52a8\u6001\u5de5\u5177\u8c03\u7528\u4e0e\u63a8\u7406\u4ea4\u7ec7\u7684\u80fd\u529b/VLMs lack dynamic interleaving of tool-use and reasoning]\n    C --\x3e C1[\u63d0\u51faBN-GSPO\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5/Propose BN-GSPO RL algorithm]\n    C --\x3e C2[\u96c6\u6210\u56fe\u50cf\u641c\u7d22\u3001\u6587\u672c\u641c\u7d22\u3001\u56fe\u50cf\u88c1\u526a\u5de5\u5177/Integrate image search, text search, image crop tools]\n    D --\x3e D1[\u5728MMSearch\u548cHR-MMSearch\u4e0aSOTA/Achieves SOTA on MMSearch and HR-MMSearch]\n    D --\x3e D2[\u8d85\u8d8aGemini-3-Flash\u548cGPT-5/Surpasses proprietary models like Gemini-3-Flash and GPT-5]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [inverse reinforcement learning, dynamic discrete choice, semiparametric inference, debiased machine learning, efficient influence function]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lars van der Laan, Aurelien Bibaut, Nathan Kallus"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Washington, Netflix Research, Cornell University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24407",children:"https://arxiv.org/pdf/2512.24407"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a semiparametric framework for debiased inverse reinforcement learning that enables statistically efficient inference for reward-dependent functionals. 2. Showed that the log-behavior policy acts as a pseudo-reward that identifies policy value differences and, with normalization, the reward itself, formalizing these as smooth functionals. 3. Constructed automatic debiased machine-learning estimators that allow flexible nonparametric nuisance estimation while achieving \u221an-consistency, asymptotic normality, and semiparametric efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f071bfe838a84ec68caefb3e8f32ddce9a94446707278cc78a1f8f23d2b1cdcf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f071bfe838a84ec68caefb3e8f32ddce9a94446707278cc78a1f8f23d2b1cdcf_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper develops a unified semiparametric framework for inference in inverse reinforcement learning and dynamic discrete choice models. The method leverages the log-behavior policy as a pseudo-reward and constructs debiased machine learning estimators, enabling flexible nonparametric estimation while providing statistical guarantees like asymptotic normality and efficiency. The framework bridges classical econometric inference with modern machine learning tools for sequential decision-making problems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Efficient Inference for IRL and DDC Models] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Flexible IRL lacks inference guarantees;<br>Classical DDC is restrictive & computationally heavy]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Semiparametric debiased IRL framework;<br>Log-behavior policy as pseudo-reward;<br>Automatic debiased ML estimators]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u221an-consistent, asymptotically normal,<br>semiparametrically efficient inference;<br>Unified, tractable approach]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [adaptive learning], [bias-noise-alignment, diagnostic-driven adaptation, temporal-difference error, stabilized optimizer, actor-critic]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Akash Samanta, Sheldon Williamson"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Ontario Tech University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24445",children:"https://arxiv.org/pdf/2512.24445"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel diagnostic-driven adaptive learning framework that decomposes error evolution into bias, noise, and alignment components. 2. Derives and instantiates the framework across multiple learning paradigms, including supervised optimization, actor-critic RL, and learned optimizers. 3. Establishes theoretical stability guarantees and bounded updates for the proposed diagnostic-driven methods under standard assumptions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fffef5a11b6873e7029659f1544c8ea507323fdf48462b3c7caeee1ffd63e30_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fffef5a11b6873e7029659f1544c8ea507323fdf48462b3c7caeee1ffd63e30_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of unstable and slow learning in nonstationary environments by proposing a new framework that models error evolution through bias, noise, and alignment diagnostics. The method uses these online-computed diagnostics to guide and stabilize learning in optimization, reinforcement learning, and meta-learning. The work provides a unifying, interpretable foundation for reliable adaptation in dynamic settings."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Learning instability in nonstationary environments)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Diagnostic-driven framework decomposing error into bias, noise, alignment)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Unifying control backbone for optimization/RL/learned optimizers with stability guarantees)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [federated graph neural network, cross-bank Personalized PageRank, hierarchical reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lecheng Zheng, Jian Ni, Chris Zobel, John R Birge"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Virginia Tech, University of Chicago"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24487",children:"https://arxiv.org/pdf/2512.24487"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A federated graph neural network framework for collaborative customer behavior modeling across competing financial institutions without sharing raw data. 2. Introduction of cross-bank Personalized PageRank for identifying coordinated behavioral clusters and providing interpretable network segmentation. 3. A hierarchical reinforcement learning mechanism for optimizing dynamic intervention targeting policies to balance risk prevention, customer friction, and operational costs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c47cc80a0132ed420b5c61d870561d1aa347aadfb05091a6bcecd09c9007954d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c47cc80a0132ed420b5c61d870561d1aa347aadfb05091a6bcecd09c9007954d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes an integrated framework combining federated graph learning and reinforcement learning to address customer risk analytics in fragmented financial markets. The method enables collaborative modeling across institutions and optimizes intervention policies, significantly improving fraud detection rates and loss prevention compared to isolated or rule-based approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u6570\u636e\u5b64\u5c9b/Data Silos"]\n    Problem --\x3e P2["\u7c7b\u522b\u4e0d\u5e73\u8861/Class Imbalance"]\n    Problem --\x3e P3["\u6b21\u4f18\u7b56\u7565/Suboptimal Policies"]\n    Method --\x3e M1["\u8054\u90a6\u56fe\u795e\u7ecf\u7f51\u7edc/Federated GNN"]\n    Method --\x3e M2["\u8de8\u94f6\u884c\u4e2a\u6027\u5316PageRank/Cross-bank PPR"]\n    Method --\x3e M3["\u5206\u5c42\u5f3a\u5316\u5b66\u4e60/Hierarchical RL"]\n    Results --\x3e R1["\u964d\u4f4e\u9519\u8bef\u7387/Reduced Error Rates"]\n    Results --\x3e R2["\u63d0\u5347\u635f\u5931\u9884\u9632/Improved Loss Prevention"]\n    Results --\x3e R3["\u5e02\u573a\u7279\u5b9a\u9608\u503c/Market-specific Thresholds"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [spatial reasoning, LoRA, GRPO, supervised fine-tuning, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Purdue University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24532",children:"https://arxiv.org/pdf/2512.24532"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A two-stage approach for multi-step spatial reasoning that first fine-tunes an LLM on atomic spatial transformations and then trains lightweight LoRA adapters via RL to compose these blocks for planning. 2. The creation of a synthetic ASCII-art dataset and a corresponding ASCII-based RL environment to support training and evaluation. 3. Demonstration that the proposed method outperforms baselines in both dynamic and static environments, with faster convergence and more stable training than end-to-end RL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of multi-step spatial reasoning in LLMs by proposing a two-stage method: first, supervised fine-tuning on basic spatial transformations to build physics awareness, and then training LoRA adapters with reinforcement learning (GRPO) to learn planning policies. The approach is evaluated using a custom ASCII-art environment and is shown to outperform various baselines, converging faster and more stably than training from scratch with RL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>LLMs struggle with spatial transformations and multi-step planning]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Two-stage: SFT on spatial blocks, then RL (GRPO) with LoRA for planning]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Outperforms baselines, faster convergence, stable training]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal generation], [vision-language models, chain-of-thought, reinforcement learning from human feedback]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xueyan Li, Yingyi Xue, Mengjie Jiang, Qingzi Zhu, Yazhe Niu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Artificial Intelligence Laboratory, Xi'an Jiaotong University, Columbia University, The Chinese University of Hong Kong MMLab"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24555",children:"https://arxiv.org/pdf/2512.24555"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a hierarchical, multi-path Chain-of-Thought (CoT) method to enhance reasoning diversity for meme generation. 2. Introduces a group-wise pairwise reward model trained on memes sharing the same template to robustly capture subjective human humor preferences. 3. Develops a group-wise reinforcement learning optimization framework with a theoretical guarantee for monotonic improvement, enabling better alignment with human preferences."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51d7b92e3cbe88fcb46458e3ce7a303a30ccee8230eb6865946f2c654b707c34_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51d7b92e3cbe88fcb46458e3ce7a303a30ccee8230eb6865946f2c654b707c34_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HUMOR, a framework for generating humorous memes. It uses a hierarchical multi-path Chain-of-Thought to guide reasoning and a group-wise reward model with RL for preference alignment. Experiments show it improves reasoning diversity, alignment, and overall meme quality in VLMs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u8d85\u8d8a\u76d1\u7763\u7684\u5e7d\u9ed8\u6897\u56fe\u751f\u6210/Humorous meme generation beyond direct supervision]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: HUMOR\u6846\u67b6/HUMOR Framework]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u63d0\u5347\u591a\u6837\u6027\u3001\u5bf9\u9f50\u6027\u548c\u8d28\u91cf/Improved diversity, alignment, and quality]\n    C --\x3e C1[\u5206\u5c42\u591a\u8def\u5f84\u601d\u7ef4\u94fe/Hierarchical Multi-path CoT]\n    C --\x3e C2[\u57fa\u4e8e\u5206\u7ec4\u7684\u5956\u52b1\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60/Group-wise Reward Model & RL]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Dec-POMDP, CTDE, GRPO]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dong Qiu, Duo Xu, Limengxi Yue"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," New England College, Northeastern University, University of Massachusetts Amherst"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24609",children:"https://arxiv.org/pdf/2512.24609"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A reinforcement learning-augmented LLM agent framework that formulates multi-agent collaboration as a Dec-POMDP and uses CTDE. 2. The introduction of Group Relative Policy Optimization (GRPO) for jointly optimizing agent policies with global training signals. 3. A simplified joint reward function that balances task quality, speed, and coordination cost."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/251d4cfbf0941a0b6ad2b2a8b7158ec06789c4a7a60653f447034ce562d8c91d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/251d4cfbf0941a0b6ad2b2a8b7158ec06789c4a7a60653f447034ce562d8c91d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of collaborative awareness in LLMs for multi-agent settings by proposing a framework that combines reinforcement learning with LLMs, using a Dec-POMDP formulation and CTDE. It introduces GRPO for policy optimization and a balanced reward function. The method significantly outperforms baselines in collaborative writing and coding tasks, demonstrating improved speed, consistency, and success rates."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Reinforcement Learning-Augmented LLM Agents<br/>\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u7684LLM\u667a\u80fd\u4f53] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem<br/>LLMs lack collaborative awareness in multi-agent settings<br/>LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7f3a\u4e4f\u534f\u4f5c\u610f\u8bc6]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Dec-POMDP & CTDE framework with GRPO and a simplified joint reward<br/>\u57fa\u4e8eDec-POMDP\u548cCTDE\u7684\u6846\u67b6\uff0c\u4f7f\u7528GRPO\u548c\u7b80\u5316\u8054\u5408\u5956\u52b1]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results<br/>3x speedup, 98.7% writing consistency, 74.6% coding pass rate<br/>3\u500d\u901f\u5ea6\u63d0\u5347\uff0c98.7%\u5199\u4f5c\u4e00\u81f4\u6027\uff0c74.6%\u7f16\u7801\u901a\u8fc7\u7387]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [LLM agent framework, automated agent generation, hybrid policy optimization, in-context optimization, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"}),' Tencent (inferred from "TencentCloudADP" in GitHub URL)']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24615",children:"https://arxiv.org/pdf/2512.24615"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/TencentCloudADP/youtu-agent",children:"https://github.com/TencentCloudADP/youtu-agent"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. A modular LLM agent framework (Youtu-Agent) with a structured configuration system for decoupling components and enabling automated synthesis. 2. Two agent generation paradigms: Workflow mode for standard tasks and Meta-Agent mode for complex tasks, capable of auto-generating tools and prompts. 3. A hybrid policy optimization system combining an in-context learning "Agent Practice" module and a scalable reinforcement learning "Agent RL" module for continuous agent evolution.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0414a5769d966ffb5a9f4428d4a182e5095ba0b107862d50c8224788df0caa46_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0414a5769d966ffb5a9f4428d4a182e5095ba0b107862d50c8224788df0caa46_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Youtu-Agent, a framework to automate the generation and continuous optimization of LLM agents, addressing high configuration costs and static capabilities. It introduces structured configuration, automated generation paradigms, and a hybrid optimization system combining in-context learning and reinforcement learning. Experiments show state-of-the-art performance on several benchmarks and significant improvements in agent capabilities through automated synthesis and optimization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Youtu-Agent] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u9ad8\u914d\u7f6e\u6210\u672c / High Configuration Cost]\n    B --\x3e B2[\u9759\u6001\u80fd\u529b / Static Capabilities]\n    C --\x3e C1[\u7ed3\u6784\u5316\u914d\u7f6e\u7cfb\u7edf / Structured Configuration System]\n    C --\x3e C2[\u81ea\u52a8\u5316\u751f\u6210 / Automated Generation]\n    C --\x3e C21[\u5de5\u4f5c\u6d41\u6a21\u5f0f / Workflow Mode]\n    C --\x3e C22[\u5143\u667a\u80fd\u4f53\u6a21\u5f0f / Meta-Agent Mode]\n    C --\x3e C3[\u6df7\u5408\u7b56\u7565\u4f18\u5316 / Hybrid Policy Optimization]\n    C --\x3e C31[\u667a\u80fd\u4f53\u5b9e\u8df5 / Agent Practice]\n    C --\x3e C32[\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60 / Agent RL]\n    D --\x3e D1[SOTA\u6027\u80fd / SOTA Performance]\n    D --\x3e D2[\u9ad8\u5de5\u5177\u5408\u6210\u7387 / High Tool Synthesis Rate]\n    D --\x3e D3[\u80fd\u529b\u663e\u8457\u63d0\u5347 / Significant Capability Improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [robot navigation], [hybrid motion planning, deep reinforcement learning, entity-aware reward, graph-based global planner, collision avoidance]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yury Kolomeytsev, Dmitry Golembiovsky"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Lomonosov Moscow State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24651",children:"https://arxiv.org/pdf/2512.24651"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HMP-DRL, a hybrid framework integrating a graph-based global planner with a local DRL policy via checkpoints. 2. Introduces an entity-aware reward structure for the local planner to ensure social compliance by adjusting safety based on agent type. 3. Validates the method in a realistic simulation, showing superior performance in success rate, collision rate, and time to goal."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes HMP-DRL, a hybrid motion planning framework that combines a graph-based global planner for long-range pathfinding with a local Deep Reinforcement Learning policy for reactive, socially-compliant navigation. The method uses checkpoints to integrate the global path and an entity-aware reward function to dynamically adjust to different moving agents. Experiments in realistic simulation show it outperforms other methods in key navigation metrics, enhancing safety and reliability in complex environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u56fe\u89c4\u5212\u5668\u7f3a\u4e4f\u53cd\u5e94\u6027/Traditional graph planners lack reactivity]\n    B --\x3e B2[\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587/DRL methods lack global context]\n    C --\x3e C1[\u6df7\u5408\u6846\u67b6HMP-DRL/Hybrid framework HMP-DRL]\n    C1 --\x3e C2[\u56fe\u89c4\u5212\u5668\u751f\u6210\u8def\u5f84/Graph planner generates path]\n    C1 --\x3e C3[\u5c40\u90e8DRL\u7b56\u7565\u4f7f\u7528\u68c0\u67e5\u70b9\u548c\u5b9e\u4f53\u611f\u77e5\u5956\u52b1/Local DRL policy uses checkpoints & entity-aware reward]\n    D --\x3e D1[\u66f4\u9ad8\u7684\u6210\u529f\u7387/Higher success rate]\n    D --\x3e D2[\u66f4\u4f4e\u7684\u78b0\u649e\u7387/Lower collision rate]\n    D --\x3e D3[\u66f4\u77ed\u7684\u5230\u8fbe\u65f6\u95f4/Shorter time to goal]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [embodied ai / robotic manipulation], [imitation learning, offline reinforcement learning, multimodal dataset, bimanual manipulation, sim-to-real transfer]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Chengkai Hou, Kun Wu, Jiaming Liu, Zhengping Che, Di Wu, Fei Liao, Guangrun Li, Jingyang He, Qiuxuan Feng, Zhao Jin, Chenyang Gu, Zhuoyang Liu, Nuowei Han, Xiangju Mi, Yaoxu Lv, Yankai Fu, Gaole Dai, Langzhe Gu, Tao Li, Yuheng Zhang, Yixue Zhang, Xinhua Wang, Shichao Fan, Meng Li, Zhen Zhao, Ning Liu, Zhiyuan Xu, Pei Ren, Junjie Ji, Haonan Liu, Kuan Cheng, Shanghang Zhang, Jian Tang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing Innovation Center of Humanoid Robotics, Peking University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24653",children:"https://arxiv.org/pdf/2512.24653"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces RoboMIND 2.0, a large-scale, multimodal real-world dataset with over 310K dual-arm manipulation trajectories across diverse robots and tasks, including tactile and mobile manipulation data. 2. Provides high-fidelity digital twins and a complementary 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer research. 3. Proposes the MIND-2 system, a hierarchical framework optimized via offline RL that integrates a high-level semantic planner and a low-level vision-language-action executor for complex task decomposition and execution."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1a0e9601e4aa64a92e289971771ed61ad7545ed91ce3194cf342f87d6636d96_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1a0e9601e4aa64a92e289971771ed61ad7545ed91ce3194cf342f87d6636d96_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the scarcity of diverse, large-scale real-world robotic manipulation data by introducing the RoboMIND 2.0 dataset, which includes hundreds of thousands of bimanual and mobile manipulation trajectories. To leverage this data, the authors propose the MIND-2 system, a hierarchical framework that uses offline reinforcement learning to integrate high-level planning with low-level control. The work aims to significantly advance the generalization capabilities of embodied AI agents in long-horizon, contact-rich, and unstructured environments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[RoboMIND 2.0 \u8bba\u6587 / RoboMIND 2.0 Paper] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem] --\x3e B1[\u6570\u636e\u7a00\u7f3a / Scarcity of large-scale, diverse real-world robotic demonstrations]\n    B --\x3e B2[\u6cdb\u5316\u80fd\u529b\u6709\u9650 / Limited generalization in long-horizon bimanual and mobile manipulation]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method] --\x3e C1[\u53d1\u5e03RoboMIND 2.0\u6570\u636e\u96c6 / Release RoboMIND 2.0 Dataset]\n    C1 --\x3e C1_1[31\u4e07+\u771f\u5b9e\u8f68\u8ff9 / 310K+ real trajectories]\n    C1 --\x3e C1_2[\u89e6\u89c9\u4e0e\u79fb\u52a8\u6570\u636e / Tactile & mobile data]\n    C1 --\x3e C1_3[\u6570\u5b57\u5b6a\u751f\u4e0e\u4eff\u771f\u6570\u636e / Digital twins & simulated data]\n    C --\x3e C2[\u63d0\u51faMIND-2\u7cfb\u7edf / Propose MIND-2 System]\n    C2 --\x3e C2_1[\u9ad8\u5c42\u8bed\u4e49\u89c4\u5212\u5668 / High-level semantic planner (MIND-2-VLM)]\n    C2 --\x3e C2_2[\u4f4e\u5c42VLA\u6267\u884c\u5668 / Low-level VLA executor (MIND-2-VLA)]\n    C2 --\x3e C2_3[\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4f18\u5316 / Optimized via offline RL]\n    D[\u5173\u952e\u7ed3\u679c / Results] --\x3e D1[\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6 / Large-scale multimodal dataset]\n    D --\x3e D2[\u4fc3\u8fdb\u6cdb\u5316\u7814\u7a76 / Facilitates research on generalization]\n    D --\x3e D3[\u5c42\u6b21\u5316\u7cfb\u7edf\u6846\u67b6 / Hierarchical system framework]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [wireless networks and mobile computing], [intelligent reflecting surface (IRS), multi-access edge computing (MEC), deep reinforcement learning (DRL), Stackelberg game, UAV trajectory optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yixian Wang, Geng Sun, Zemin Sun, Jiacheng Wang, Changyuan Zhao, Daxin Tian, Dusit Niyato, Shiwen Mao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Jilin University, Nanyang Technological University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24659",children:"https://arxiv.org/pdf/2512.24659"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel IRS-enabled low-altitude MEC architecture with hybrid IRSs (building-installed and UAV-carried) to enhance air-ground connectivity in vehicular networks. 2. Formulates the joint optimization problem as a multi-objective NP-hard problem and solves it via a hierarchical online optimization approach (HOOA) based on a Stackelberg game. 3. Introduces a novel GDMTD3 (generative diffusion model-enhanced twin delayed deep deterministic policy gradient) algorithm integrated with a KKT-based method at the leader level for continuous decision-making."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a70ac61590f84cefea0f7f78edf4eaf7e0546f7c7759345e2ce5ad8ec8d0b049_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a70ac61590f84cefea0f7f78edf4eaf7e0546f7c7759345e2ce5ad8ec8d0b049_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a hierarchical online optimization approach (HOOA) for an IRS-enabled low-altitude MEC system in vehicular networks to minimize task delay and energy consumption. The method reformulates the problem as a Stackelberg game, using a matching mechanism for vehicles and a novel deep reinforcement learning algorithm (GDMTD3) for server-side decisions. Simulation results show the proposed HOOA reduces average delay by 2.5% and energy consumption by 3.1% compared to benchmarks, demonstrating improved performance and stability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898 / Paper Title: Hierarchical Online Optimization Approach for IRS-enabled Low-altitude MEC in Vehicular Networks] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem: \u52a8\u6001\u8f66\u8f86\u7f51\u7edc\u4e2d\u9ad8\u79fb\u52a8\u6027\u548c\u906e\u6321\u5bfc\u81f4\u65f6\u53d8\u4fe1\u9053\uff0c\u9650\u5236\u53ef\u9760\u8fde\u63a5\u548c\u8ba1\u7b97\u670d\u52a1 / Dynamic vehicular networks with high mobility and blockage lead to time-varying channels, limiting reliable connectivity and computing services.]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method: \u5206\u5c42\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5(HOOA)\uff0c\u5c06\u95ee\u9898\u91cd\u6784\u4e3aStackelberg\u535a\u5f08\uff0c\u7ed3\u5408\u5339\u914d\u673a\u5236\u548cGDMTD3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5 / Hierarchical Online Optimization Approach (HOOA) reformulates problem as Stackelberg game, combining matching mechanism and GDMTD3 DRL algorithm.]\n    D[\u5173\u952e\u7ed3\u679c / Results: \u5e73\u5747\u4efb\u52a1\u5b8c\u6210\u5ef6\u8fdf\u964d\u4f4e2.5%\uff0c\u5e73\u5747\u80fd\u8017\u964d\u4f4e3.1%\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u6536\u655b\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027 / Reduces average task completion delay by 2.5% and energy consumption by 3.1%, with superior convergence stability and robustness.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [model homotopy, continuation learning, single rigid body model, policy transfer, legged locomotion]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dongyun Kang, Min-Gyu Kim, Tae-Gyu Song, Hajun Kim, Sehoon Ha, Hae-Won Park"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), Georgia Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24698",children:"https://arxiv.org/pdf/2512.24698"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a continuation-based learning framework combining simplified model pretraining and model homotopy transfer for efficient policy learning. 2. Introduces a model homotopy path defined by gradually redistributing mass and inertia from a Single Rigid Body (SRB) model to a full-body model. 3. Demonstrates faster convergence and superior transfer stability for complex dynamic tasks (e.g., flips, wall maneuvers) and successful real-robot deployment."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f290446d6dbc75a7566abaf855c8d703414e58780e4d737ff33bd9bcd9c33512_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f290446d6dbc75a7566abaf855c8d703414e58780e4d737ff33bd9bcd9c33512_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of transferring policies from simplified to full-body dynamics for legged robots. It proposes a framework that first pretrains a policy using a Single Rigid Body model and then uses a model homotopy to gradually transfer it to the full-body environment. The method achieves faster convergence, stable transfer, and is validated on dynamic tasks with a real quadruped robot."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Dynamic Policy Learning for Legged Robot] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u6a21\u578b\u5dee\u5f02/Model discrepancy]\n    P1 --\x3e P2[\u7b80\u5316\u6a21\u578b\u5230\u5168\u8eab\u6a21\u578b\u7b56\u7565\u8fc1\u79fb\u56f0\u96be/Difficult policy transfer from simplified to full-body model]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u7b80\u5316\u6a21\u578b\u9884\u8bad\u7ec3/Simplified model pretraining]\n    M1 --\x3e M2[\u4f7f\u7528\u5355\u521a\u4f53\u6a21\u578b/Using Single Rigid Body model]\n    Method --\x3e M3[\u6a21\u578b\u540c\u4f26\u8fc1\u79fb/Model homotopy transfer]\n    M3 --\x3e M4[\u6e10\u8fdb\u8d28\u91cf\u4e0e\u60ef\u91cf\u91cd\u5206\u914d/Gradual mass & inertia redistribution]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u66f4\u5feb\u6536\u655b/Faster convergence]\n    Results --\x3e R2[\u8fc1\u79fb\u7a33\u5b9a/Superior transfer stability]\n    Results --\x3e R3[\u771f\u5b9e\u673a\u5668\u4eba\u90e8\u7f72\u6210\u529f/Successful real-robot deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [reasoning segmentation], [evolutionary prompting, zero-shot learning, visual arena, semantic mutation, heterogeneous arena]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kai Ye, Xiaotong You, Jianghang Lin, Jiayi Ji, Pingyang Dai, Liujuan Cao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Xiamen University, National University of Singapore"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24702",children:"https://arxiv.org/pdf/2512.24702"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/AHideoKuzeA/Evol-SAM3",children:"https://github.com/AHideoKuzeA/Evol-SAM3"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. 2. Introduces a "Generate-Evaluate-Evolve" loop with a Visual Arena for reference-free fitness assessment and a Semantic Mutation operator for diversity and error correction. 3. Designs a Heterogeneous Arena module that integrates geometric priors with semantic reasoning for robust final selection.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b60e24e2f5e5668a6d7d977acfb32177365388575df74e72ccb5a8b3d4e7f7e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b60e24e2f5e5668a6d7d977acfb32177365388575df74e72ccb5a8b3d4e7f7e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of static, training-free methods for reasoning segmentation by proposing EVOL-SAM3, a zero-shot framework that uses an evolutionary prompting strategy to iteratively refine prompt hypotheses at inference time. The method outperforms both static baselines and fully supervised state-of-the-art methods on the ReasonSeg benchmark without any training."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[EVOL-SAM3: \u96f6\u6837\u672c\u63a8\u7406\u5206\u5272\u7684\u8fdb\u5316\u63d0\u793a / EVOL-SAM3: Zero-Shot Reasoning Segmentation via Evolutionary Prompting] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem] --\x3e B1[\u9759\u6001\u63a8\u7406\u8303\u5f0f / Static Inference Paradigm]\n    B1 --\x3e B2[\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3 / Insufficient Reasoning Depth]\n    B1 --\x3e B3[\u65e0\u6cd5\u81ea\u6211\u7ea0\u6b63 / Lack of Self-Correction]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method] --\x3e C1[\u8fdb\u5316\u641c\u7d22 / Evolutionary Search]\n    C1 --\x3e C2[\u751f\u6210-\u8bc4\u4f30-\u8fdb\u5316\u5faa\u73af / Generate-Evaluate-Evolve Loop]\n    C2 --\x3e C3[\u89c6\u89c9\u7ade\u6280\u573a / Visual Arena]\n    C2 --\x3e C4[\u8bed\u4e49\u7a81\u53d8 / Semantic Mutation]\n    C2 --\x3e C5[\u5f02\u6784\u7ade\u6280\u573a / Heterogeneous Arena]\n    D[\u5173\u952e\u7ed3\u679c / Results] --\x3e D1[\u8d85\u8d8a\u9759\u6001\u57fa\u7ebf / Outperforms Static Baselines]\n    D --\x3e D2[\u8d85\u8d8a\u5168\u76d1\u7763SOTA / Surpasses Fully Supervised SOTA]\n    D --\x3e D3[\u96f6\u6837\u672c\u8bbe\u7f6e / Zero-Shot Setting]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Control of Microrobots with Reinforcement Learning under On-Device Compute Constraints"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [reinforcement learning, quantization, domain randomization, gait scheduling, edge ML]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yichen Liu, Kesava Viswanadha, Zhongyu Li, Nelson Lojo, Kristofer S. J. Pister"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of California, Berkeley"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24740",children:"https://arxiv.org/pdf/2512.24740"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes and implements an edge ML pipeline for microrobot locomotion, training a compact RL policy in simulation and deploying it on an ultra-low-power ARM Cortex-M0 SoC. 2. Introduces a resource-aware gait scheduling framework that selects the optimal gait mode (e.g., trot, gallop) based on the hardware's power budget and achievable inference frequency to maximize expected reward. 3. Demonstrates the use of domain randomization and integer quantization (Int8) to enhance policy robustness and enable higher update rates on severely resource-constrained hardware."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b59e857eb5b5c4d1e8a552ef8542246a2d1db88ba891759753679922c30b963c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b59e857eb5b5c4d1e8a552ef8542246a2d1db88ba891759753679922c30b963c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of on-device, low-latency control for microrobots under strict compute and power constraints. The method involves training a compact reinforcement learning policy with domain randomization in simulation, quantizing it to Int8 for efficient inference on a 5 MHz microcontroller, and proposing a power-budget-aware gait scheduler. The main conclusion is that this edge ML approach enables autonomous locomotion control on ultra-small hardware, with domain randomization improving out-of-distribution stability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Control of Microrobots with RL under On-Device Compute Constraints<br>\u5fae\u673a\u5668\u4eba\u5728\u8bbe\u5907\u8ba1\u7b97\u7ea6\u675f\u4e0b\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[On-device autonomy for microrobots<br>\u5fae\u673a\u5668\u4eba\u7684\u8bbe\u5907\u7aef\u81ea\u4e3b\u6027]\n    B --\x3e B2[Severe compute/power constraints<br>\u4e25\u82db\u7684\u8ba1\u7b97/\u529f\u8017\u7ea6\u675f]\n    C --\x3e C1[Train compact RL policy with domain randomization<br>\u4f7f\u7528\u57df\u968f\u673a\u5316\u8bad\u7ec3\u7d27\u51d1RL\u7b56\u7565]\n    C --\x3e C2[Quantize policy (Int8) for efficient inference<br>\u91cf\u5316\u7b56\u7565(Int8)\u4ee5\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406]\n    C --\x3e C3[Resource-aware gait scheduling<br>\u8d44\u6e90\u611f\u77e5\u7684\u6b65\u6001\u8c03\u5ea6]\n    D --\x3e D1[Deployment on ultra-small SoC (Cortex-M0)<br>\u5728\u8d85\u5c0f\u578bSoC\u4e0a\u90e8\u7f72]\n    D --\x3e D2[Connects power budget to feasible update rate<br>\u8fde\u63a5\u529f\u8017\u9884\u7b97\u4e0e\u53ef\u884c\u66f4\u65b0\u9891\u7387]\n    D --\x3e D3[Improved OOD stability via domain randomization<br>\u901a\u8fc7\u57df\u968f\u673a\u5316\u63d0\u5347OOD\u7a33\u5b9a\u6027]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [robotic manipulation], [3D object flow, video generation, zero-shot manipulation, trajectory optimization, reinforcement learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Karthik Dharmarajan, Wenlong Huang, Jiajun Wu, Li Fei-Fei, Ruohan Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Stanford University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24766",children:"https://arxiv.org/pdf/2512.24766"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Dream2Flow, a framework that bridges video generation and robotic control using 3D object flow as an intermediate representation. 2. Demonstrates the ability to reconstruct 3D object motions from generated videos and formulate manipulation as object trajectory tracking, overcoming the embodiment gap. 3. Shows that the method enables zero-shot guidance from pre-trained video models to manipulate diverse object categories (rigid, articulated, deformable, granular) without task-specific demonstrations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c22839be4198942eb08182abe0606d486a3126572afb757ce865cb1b3a787721_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c22839be4198942eb08182abe0606d486a3126572afb757ce865cb1b3a787721_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Dream2Flow, a framework that uses 3D object flow extracted from videos generated by off-the-shelf models as an interface for robotic manipulation. It translates these generated motions into executable robot actions via trajectory optimization or reinforcement learning, enabling zero-shot manipulation of diverse objects in open-world settings. The results demonstrate 3D object flow as a general and scalable bridge between video generation models and robotic control."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Translating human-like motions from video models into low-level robot actions)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Use 3D object flow as intermediate representation, reconstruct motions from videos, track trajectories)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Enables zero-shot manipulation of diverse objects, bridges video generation to robot control)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [UAV-mounted RIS, deep reinforcement learning, imperfect CSI, jitter, throughput optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Anas K. Saeed, Mahmoud M. Salim, Ali Arshad Nasir, Ali H. Muqaibel"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," King Fahd University of Petroleum and Minerals"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24773",children:"https://arxiv.org/pdf/2512.24773"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Formulated a stochastic nonconvex optimization problem for throughput maximization in a UAV-mounted RIS system under practical impairments of 3D UAV jitter and imperfect cascaded CSI. 2. Proposed a model-free DRL framework with a contextual bandit formulation, utilizing a differentiable feasibility layer to handle strict unit-modulus constraints and Monte Carlo estimation for the reward. 3. Instantiated the framework with constrained variants of DDPG and TD3 algorithms (without target networks) that achieve higher throughput than AO-WMMSE baselines under severe impairments and offer significantly faster online inference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21b151210402631df4e03eef8b93269c08979932c1031e607f39d4ebdad4ff7f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21b151210402631df4e03eef8b93269c08979932c1031e607f39d4ebdad4ff7f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the problem of maximizing throughput in a UAV-mounted RIS communication system under practical impairments like UAV jitter and imperfect channel knowledge. It proposes a deep reinforcement learning framework with constrained policy gradient algorithms to jointly optimize the base station's beamforming and the RIS's phase shifts. The results show the DRL approach outperforms conventional optimization methods under severe impairments and offers much faster online decision-making."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Throughput Optimization in UAV-Mounted RIS under Jittering and Imperfect CSI via DRL] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[UAV\u6296\u52a8\u4e0e\u4e0d\u5b8c\u7f8eCSI\u964d\u4f4e\u7cfb\u7edf\u6027\u80fd/UAV Jitter & Imperfect CSI Degrade Performance]\n    C --\x3e C1[\u57fa\u4e8e\u60c5\u5883\u8d4c\u535a\u673a\u7684\u65e0\u6a21\u578bDRL\u6846\u67b6/Model-free DRL with Contextual Bandit]\n    C --\x3e C2[\u4f7f\u7528\u53ef\u5fae\u53ef\u884c\u6027\u5c42\u4e0e\u8499\u7279\u5361\u6d1b\u5956\u52b1/Using Differentiable Feasibility Layer & Monte Carlo Reward]\n    C --\x3e C3[\u5b9e\u4f8b\u5316\u7ea6\u675f\u578bDDPG\u4e0eTD3\u7b97\u6cd5/Instantiating Constrained DDPG & TD3]\n    D --\x3e D1[\u5728\u4e25\u91cd\u635f\u4f24\u4e0b\u6027\u80fd\u4f18\u4e8eAO-WMMSE/Outperforms AO-WMMSE under Severe Impairments]\n    D --\x3e D2[\u5728\u7ebf\u63a8\u7406\u901f\u5ea6\u5feb(~0.6ms)/Fast Online Inference (~0.6ms)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Iterative Deployment Improves Planning Skills in LLMs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [iterative deployment, implicit reward, data curation, planning, fine-tuning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Augusto B. Corr\xeaa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, Andr\xe9 G. Pereira, Yarin Gal"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Oxford, AI Sequrity Company, UFRGS"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24940",children:"https://arxiv.org/pdf/2512.24940"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that iterative deployment and fine-tuning on curated user data significantly improves LLM planning skills, including emergent generalization to longer plans. 2. Provides a theoretical analysis showing iterative deployment effectively implements an outer-loop reinforcement learning process with an implicit reward function. 3. Highlights the AI safety implications of this implicit training regime and positions it as an alternative to explicit RL training."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper shows that repeatedly deploying LLMs and fine-tuning them on curated data from previous deployments significantly improves their planning capabilities. This process is analyzed as an implicit form of reinforcement learning, which raises safety concerns due to the undefined reward function and offers an alternative training paradigm based on data curation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Iterative Deployment Improves Planning Skills in LLMs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u89c4\u5212\u80fd\u529b/LLM Planning Skills]\n    C --\x3e C1[\u8fed\u4ee3\u90e8\u7f72\u4e0e\u5fae\u8c03/Iterative Deployment & Fine-tuning]\n    C1 --\x3e C2[\u7528\u6237\u6570\u636e\u7b5b\u9009/User Data Curation]\n    D --\x3e D1[\u89c4\u5212\u80fd\u529b\u63d0\u5347/Improved Planning Skills]\n    D --\x3e D2[\u53d1\u73b0\u9690\u5f0fRL/Discovering Implicit RL]\n    D2 --\x3e D3[AI\u5b89\u5168\u5f71\u54cd/AI Safety Implications]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Lyapunov certificates, exponential stability, multi-step learning, actor-critic, maximum entropy RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yongwei Zhang, Yuanzhe Xing, Quan Quan, Zhikun She"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beihang University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24955",children:"https://arxiv.org/pdf/2512.24955"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework (MSACL) that integrates exponential stability theory with maximum entropy RL via multi-step Lyapunov certificate learning, using off-policy data to learn certificates that satisfy theoretical stability conditions. 2. Introduces Exponential Stability Labels (ESL) and a \u03bb-weighted aggregation mechanism to effectively balance the bias-variance trade-off in multi-step learning. 3. Guides policy optimization with a stability-aware advantage function to ensure the learned policy promotes rapid Lyapunov descent, achieving provable stability and robustness under simple rewards."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes MSACL, a model-free reinforcement learning framework that ensures provable exponential stability by learning Lyapunov certificates from multi-step data and guiding policy optimization with a stability-aware advantage. It demonstrates superior performance over baseline and state-of-the-art Lyapunov-based RL methods across six benchmarks, achieving rapid convergence and robustness with simple rewards. The work establishes a link between Lyapunov theory and actor-critic frameworks for verifiably safe control."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Provable Stability in Model-Free RL / \u6a21\u578b\u65e0\u5173RL\u7684\u53ef\u8bc1\u660e\u7a33\u5b9a\u6027]\n    C --\x3e C1[Multi-Step Lyapunov Certificate Learning / \u591a\u6b65\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\u5b66\u4e60]\n    C --\x3e C2[Stability-Aware Advantage Function / \u7a33\u5b9a\u6027\u611f\u77e5\u4f18\u52bf\u51fd\u6570]\n    D --\x3e D1[Superiority over SOTA / \u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5]\n    D --\x3e D2[Exponential Stability & Robustness / \u6307\u6570\u7a33\u5b9a\u6027\u4e0e\u9c81\u68d2\u6027]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (RLHF)], [preference strength, reward modeling, sample efficiency, utility difference, Pearson Distance Correlation (PDC)]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Timo Kaufmann, Yannick Metz, Daniel Keim, Eyke H\xfcllermeier"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," LMU Munich, University of Konstanz"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25023",children:"https://arxiv.org/pdf/2512.25023"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals. 2. Empirical evidence of improved sample efficiency and robustness across diverse tasks. 3. The Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/89532a897b8fa7db270c20a989bfbc8848f6809665ba966305a08daa55266fce_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/89532a897b8fa7db270c20a989bfbc8848f6809665ba966305a08daa55266fce_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of standard RLHF, which only captures the direction of a preference but not its strength. It proposes ResponseRank, a method that learns preference strength by ranking responses using relative differences in noisy proxy signals (like response times) within local strata. The method demonstrates improved sample efficiency and robustness across synthetic, language modeling, and RL control tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6807\u51c6RLHF\u4ec5\u63d0\u4f9b\u504f\u597d\u65b9\u5411/Standard RLHF only provides preference direction]\n    B --\x3e B2[\u504f\u597d\u5f3a\u5ea6\u96be\u4ee5\u53ef\u9760\u6d4b\u91cf/Preference strength is hard to measure reliably]\n    C --\x3e C1[\u5229\u7528\u4ee3\u7406\u4fe1\u53f7(\u5982\u54cd\u5e94\u65f6\u95f4)/Leverage proxy signals (e.g., response time)]\n    C --\x3e C2[\u5c40\u90e8\u5c42\u5185\u76f8\u5bf9\u6bd4\u8f83/Local within-strata relative comparison]\n    C --\x3e C3[\u6392\u5e8f\u63a8\u65ad\u5f3a\u5ea6/Rank to infer strength]\n    D --\x3e D1[\u63d0\u5347\u6837\u672c\u6548\u7387\u4e0e\u9c81\u68d2\u6027/Improved sample efficiency & robustness]\n    D --\x3e D2[\u63d0\u51fa\u65b0\u8bc4\u4f30\u6307\u6807PDC/Proposed new metric PDC]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Many Minds from One Model: Bayesian Transformers for Population Intelligence"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Bayesian Transformers, Variational Inference, Population Diversity, Normalization Layers, Wisdom of Crowds]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Diji Yang, Yi Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of California Santa Cruz"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25063",children:"https://arxiv.org/pdf/2512.25063"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Population Bayesian Transformers (B-Trans), a method to convert a standard LLM into a Bayesian model by treating normalization layer biases as stochastic variables with a Gaussian variational approximation, enabling diverse model sampling from a single weight set. 2. Introduces sequence-level noise freezing to maintain temporal coherence within each sampled model instance's generation, ensuring consistent behavior across tokens. 3. Demonstrates that aggregating predictions from a population of sampled B-Trans instances enhances exploration and decision-making, leading to superior semantic diversity and task performance in zero-shot generation, RLVR, and RL without labels."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0113a2c263c7e9a33e3b5ce49ac7afb88b3a3baeb7fd88c121fac5ef4b745b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0113a2c263c7e9a33e3b5ce49ac7afb88b3a3baeb7fd88c121fac5ef4b745b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the lack of diversity and exploration in deterministic LLMs by proposing B-Trans, which transforms a standard LLM into a Bayesian model by making normalization biases stochastic. This allows sampling diverse "minds" from one model, and aggregating their predictions improves performance and semantic variety in reasoning tasks.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Many Minds from One Model: Bayesian Transformers for Population Intelligence] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u4ee3Transformer\u662f\u5355\u4e00\u601d\u7ef4\u7684/Modern Transformers are single-minded]\n    B --\x3e B2[\u7f3a\u4e4f\u591a\u6837\u6027\u963b\u788d\u63a2\u7d22/Lack of diversity hinders exploration]\n    C --\x3e C1[\u63d0\u51faB-Trans: \u8d1d\u53f6\u65afTransformer/Propose B-Trans: Bayesian Transformer]\n    C --\x3e C2[\u5f52\u4e00\u5316\u5c42\u504f\u7f6e\u4f5c\u4e3a\u968f\u673a\u53d8\u91cf/Normalization biases as stochastic variables]\n    C --\x3e C3[\u5e8f\u5217\u7ea7\u566a\u58f0\u51bb\u7ed3/Sequence-level noise freezing]\n    D --\x3e D1[\u589e\u5f3a\u8bed\u4e49\u591a\u6837\u6027/Improved semantic diversity]\n    D --\x3e D2[\u63d0\u5347\u4efb\u52a1\u6027\u80fd/Better task performance]\n    D --\x3e D3[\u5b9e\u73b0\u7fa4\u4f53\u667a\u6167/Achieves wisdom of crowds]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Scaling Open-Ended Reasoning to Predict the Future"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [language model forecasting], [open-ended forecasting, reinforcement learning, retrieval-augmented generation, calibration, Qwen3]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Max Planck Institute for Intelligent Systems, ELLIS Institute T\xfcbingen, T\xfcbingen AI Center, University of T\xfcbingen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25070",children:"https://arxiv.org/pdf/2512.25070"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," /github (URL implied from first page content)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A fully automated pipeline to synthesize a large-scale dataset (OpenForesight) for training language models on open-ended forecasting questions from news events. 2. A specialized forecasting system integrating retrieval and an improved RL reward function, trained on Qwen3, which prevents future information leakage. 3. The OpenForecaster 8B model, which demonstrates that specialized training improves accuracy, calibration, and consistency, matching larger proprietary models, with calibration benefits generalizing to other benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7433331ffccb9fb0f52db33a75b12ae808ae87c5410037274fcfdc5f22b3505_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7433331ffccb9fb0f52db33a75b12ae808ae87c5410037274fcfdc5f22b3505_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of training language models for open-ended future prediction. The authors propose an automated method to generate a large forecasting dataset from news and train a specialized model (OpenForecaster 8B) using retrieval and an improved RL reward. Their final model matches the performance of much larger proprietary models, showing improved prediction accuracy, calibration, and consistency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Scaling Open-Ended Reasoning to Predict the Future<br>\u9884\u6d4b\u672a\u6765\u7684\u5f00\u653e\u5f0f\u63a8\u7406\u6269\u5c55] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5f00\u653e\u5f0f\u672a\u6765\u9884\u6d4b<br>Train LLMs for open-ended future forecasting]\n    C --\x3e C1[\u81ea\u52a8\u4ece\u65b0\u95fb\u751f\u6210\u6570\u636e\u96c6<br>Automated dataset generation from news]\n    C --\x3e C2[\u4f7f\u7528\u68c0\u7d22\u548c\u6539\u8fdb\u7684RL\u8fdb\u884c\u8bad\u7ec3<br>Training with retrieval & improved RL]\n    C --\x3e C3[\u9632\u6b62\u672a\u6765\u4fe1\u606f\u6cc4\u9732<br>Prevent future info leakage]\n    D --\x3e D1[OpenForecaster 8B \u5339\u914d\u66f4\u5927\u6a21\u578b<br>Matches larger proprietary models]\n    D --\x3e D2[\u63d0\u5347\u51c6\u786e\u6027\u3001\u6821\u51c6\u548c\u4e00\u81f4\u6027<br>Improves accuracy, calibration, consistency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [off-policy evaluation, fitted Q-evaluation, Bellman completeness, stationary distribution, density ratio]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lars van der Laan, Nathan Kallus"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Washington, Netflix, Cornell University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23805",children:"https://arxiv.org/pdf/2512.23805"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identified the fundamental norm mismatch causing FQE's reliance on Bellman completeness, 2. Proposed a simple fix by reweighting regression steps with an estimated stationary density ratio, 3. Provided strong evaluation guarantees without requiring realizability or Bellman completeness, avoiding geometric error blow-up."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0334a3bea1166b5e2cbda1d446e2561bf91e6e45af4da23da7bb2759aa9a5043_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0334a3bea1166b5e2cbda1d446e2561bf91e6e45af4da23da7bb2759aa9a5043_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the fragility of Fitted Q-evaluation (FQE) in off-policy reinforcement learning, which traditionally requires the strong assumption of Bellman completeness. The authors propose a simple modification to FQE by reweighting each regression step using an estimate of the stationary density ratio, aligning the optimization with the contractive norm of the Bellman operator. This enables robust policy evaluation guarantees even when the function class is not Bellman complete, maintaining the practicality of regression-based methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6807\u51c6FQE\u9700\u8981\u8d1d\u5c14\u66fc\u5b8c\u5907\u6027\u5047\u8bbe / Standard FQE requires Bellman completeness]\n    B --\x3e B2[\u5047\u8bbe\u8fc7\u5f3a\u4e14\u96be\u4ee5\u6ee1\u8db3 / Assumption is strong and hard to satisfy]\n    C --\x3e C1[\u8bc6\u522b\u6839\u672c\u7684\u8303\u6570\u4e0d\u5339\u914d / Identify fundamental norm mismatch]\n    C --\x3e C2[\u4f7f\u7528\u5e73\u7a33\u5bc6\u5ea6\u6bd4\u91cd\u65b0\u52a0\u6743\u56de\u5f52\u6b65\u9aa4 / Reweight regression steps using stationary density ratio]\n    D --\x3e D1[\u65e0\u9700\u8d1d\u5c14\u66fc\u5b8c\u5907\u6027\u7684\u5f3a\u4fdd\u8bc1 / Strong guarantees without Bellman completeness]\n    D --\x3e D2[\u907f\u514d\u51e0\u4f55\u8bef\u5dee\u7206\u70b8 / Avoid geometric error blow-up]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [fitted Q-iteration, entropy regularization, stationary distribution, Bellman operator, offline RL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lars van der Laan, Nathan Kallus"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Washington, Netflix, Cornell University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23927",children:"https://arxiv.org/pdf/2512.23927"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identified a geometric mismatch causing instability in soft FQI, showing the soft Bellman operator is contractive in the stationary norm of the soft-optimal policy, not the behavior norm. 2. Proposed stationary-reweighted soft FQI, a method that reweights regression updates using the current policy's stationary distribution to restore contraction. 3. Provided a theoretical analysis proving local linear convergence under function approximation with damped weight-estimation errors and suggested a continuation approach for global convergence via temperature annealing."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a133d7f0a68e796e5601b9dd17517ab3deea2ceb5f9dce008c265e4c615a1b43_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a133d7f0a68e796e5601b9dd17517ab3deea2ceb5f9dce008c265e4c615a1b43_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the instability of entropy-regularized fitted Q-iteration (soft FQI) under function approximation and distribution shift in offline reinforcement learning. The authors propose a new method, stationary-reweighted soft FQI, which reweights updates using the policy's stationary distribution to restore local contraction. They prove local linear convergence and suggest that global convergence can be achieved by gradually reducing the softmax temperature."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Soft FQI instability under function approximation & distribution shift]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Stationary-reweighted soft FQI (reweights updates using policy's stationary distribution)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Local linear convergence proven; global convergence via temperature annealing suggested]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [policy mirror descent, temporal difference learning, sample complexity, Markov decision process, policy optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wenye Li, Hongxu Chen, Jiacai Liu, Ke Wei"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Fudan University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24056",children:"https://arxiv.org/pdf/2512.24056"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes two novel algorithms (Expected TD-PMD and Approximate TD-PMD) that combine policy mirror descent with TD learning under online Markovian sampling. 2. Establishes an ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsxs)(n.mover,{accent:"true",children:[(0,r.jsx)(n.mo,{stretchy:"false",children:"{"}),(0,r.jsx)(n.mo,{children:"~"})]}),(0,r.jsx)(n.mi,{children:"O"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(n.msup,{children:[(0,r.jsx)(n.mi,{children:"\u03b5"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"{"})]}),(0,r.jsx)(n.mo,{children:"\u2212"}),(0,r.jsx)(n.mn,{children:"2"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\tilde\\{O\\}(\\varepsilon^\\{-2\\})"})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1.2369em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord accent",children:(0,r.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,r.jsxs)(n.span,{className:"vlist-r",children:[(0,r.jsxs)(n.span,{className:"vlist",style:{height:"0.9869em"},children:[(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"mopen",children:"{"})]}),(0,r.jsxs)(n.span,{style:{top:"-3.669em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"accent-body",style:{left:"-0.25em"},children:(0,r.jsx)(n.span,{className:"mord",children:"~"})})]})]}),(0,r.jsx)(n.span,{className:"vlist-s",children:"\u200b"})]}),(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.25em"},children:(0,r.jsx)(n.span,{})})})]})}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,r.jsx)(n.span,{className:"mclose",children:"}"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsxs)(n.span,{className:"mord",children:[(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"}),(0,r.jsx)(n.span,{className:"msupsub",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.888em"},children:(0,r.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(n.span,{className:"mopen mtight",children:"{"})})]})})})})})]}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2212"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"2"}),(0,r.jsx)(n.span,{className:"mclose",children:"})"})]})]})]})," sample complexity for achieving average-time ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsx)(n.mrow,{children:(0,r.jsx)(n.mi,{children:"\u03b5"})}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\varepsilon"})]})})}),(0,r.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"})]})})]}),"-optimality with a constant step size. 3. Improves sample complexity to ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsx)(n.mi,{children:"O"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(n.msup,{children:[(0,r.jsx)(n.mi,{children:"\u03b5"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"{"})]}),(0,r.jsx)(n.mo,{children:"\u2212"}),(0,r.jsx)(n.mn,{children:"2"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"O(\\varepsilon^\\{-2\\})"})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1.138em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsxs)(n.span,{className:"mord",children:[(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"}),(0,r.jsx)(n.span,{className:"msupsub",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.888em"},children:(0,r.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(n.span,{className:"mopen mtight",children:"{"})})]})})})})})]}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2212"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"2"}),(0,r.jsx)(n.span,{className:"mclose",children:"})"})]})]})]})," for last-iterate ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsx)(n.mrow,{children:(0,r.jsx)(n.mi,{children:"\u03b5"})}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\varepsilon"})]})})}),(0,r.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"})]})})]}),"-optimality using adaptive policy update step sizes."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e127c9df69a866d0fceeb04827980cde5bc823d8ff492633bf924e6720d9ce1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e127c9df69a866d0fceeb04827980cde5bc823d8ff492633bf924e6720d9ce1_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the sample complexity of policy mirror descent combined with temporal difference learning under online Markovian data. It introduces two algorithms, Expected TD-PMD and Approximate TD-PMD, and proves they achieve ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsxs)(n.mover,{accent:"true",children:[(0,r.jsx)(n.mo,{stretchy:"false",children:"{"}),(0,r.jsx)(n.mo,{children:"~"})]}),(0,r.jsx)(n.mi,{children:"O"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(n.msup,{children:[(0,r.jsx)(n.mi,{children:"\u03b5"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"{"})]}),(0,r.jsx)(n.mo,{children:"\u2212"}),(0,r.jsx)(n.mn,{children:"2"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\tilde\\{O\\}(\\varepsilon^\\{-2\\})"})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1.2369em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord accent",children:(0,r.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,r.jsxs)(n.span,{className:"vlist-r",children:[(0,r.jsxs)(n.span,{className:"vlist",style:{height:"0.9869em"},children:[(0,r.jsxs)(n.span,{style:{top:"-3em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"mopen",children:"{"})]}),(0,r.jsxs)(n.span,{style:{top:"-3.669em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,r.jsx)(n.span,{className:"accent-body",style:{left:"-0.25em"},children:(0,r.jsx)(n.span,{className:"mord",children:"~"})})]})]}),(0,r.jsx)(n.span,{className:"vlist-s",children:"\u200b"})]}),(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.25em"},children:(0,r.jsx)(n.span,{})})})]})}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,r.jsx)(n.span,{className:"mclose",children:"}"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsxs)(n.span,{className:"mord",children:[(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"}),(0,r.jsx)(n.span,{className:"msupsub",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.888em"},children:(0,r.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(n.span,{className:"mopen mtight",children:"{"})})]})})})})})]}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2212"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"2"}),(0,r.jsx)(n.span,{className:"mclose",children:"})"})]})]})]})," sample complexity for average-time optimality, which is further refined to ",(0,r.jsxs)(n.span,{className:"katex",children:[(0,r.jsx)(n.span,{className:"katex-mathml",children:(0,r.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(n.semantics,{children:[(0,r.jsxs)(n.mrow,{children:[(0,r.jsx)(n.mi,{children:"O"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(n.msup,{children:[(0,r.jsx)(n.mi,{children:"\u03b5"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"{"})]}),(0,r.jsx)(n.mo,{children:"\u2212"}),(0,r.jsx)(n.mn,{children:"2"}),(0,r.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,r.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,r.jsx)(n.annotation,{encoding:"application/x-tex",children:"O(\\varepsilon^\\{-2\\})"})]})})}),(0,r.jsxs)(n.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1.138em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,r.jsx)(n.span,{className:"mopen",children:"("}),(0,r.jsxs)(n.span,{className:"mord",children:[(0,r.jsx)(n.span,{className:"mord mathnormal",children:"\u03b5"}),(0,r.jsx)(n.span,{className:"msupsub",children:(0,r.jsx)(n.span,{className:"vlist-t",children:(0,r.jsx)(n.span,{className:"vlist-r",children:(0,r.jsx)(n.span,{className:"vlist",style:{height:"0.888em"},children:(0,r.jsxs)(n.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,r.jsx)(n.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(n.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(n.span,{className:"mopen mtight",children:"{"})})]})})})})})]}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(n.span,{className:"mbin",children:"\u2212"}),(0,r.jsx)(n.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(n.span,{className:"base",children:[(0,r.jsx)(n.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(n.span,{className:"mord",children:"2"}),(0,r.jsx)(n.span,{className:"mclose",children:"})"})]})]})]})," for last-iterate optimality with adaptive step sizes."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Existing PMD analysis limited to generative or Markovian sampling with pre-approximated action values]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose Expected TD-PMD (off-policy) and Approximate TD-PMD (mixed policy) algorithms]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieve \u02dcO(\u03b5\u207b\xb2) sample complexity for average-time \u03b5-optimality; improved to O(\u03b5\u207b\xb2) for last-iterate \u03b5-optimality with adaptive steps]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [risk-sensitive reinforcement learning, Bayesian dynamic programming, coherent risk measures, robust Markov decision process, convex optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shanyu Han, Yangbo He, Yang Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Peking University, The Chinese University of Hong Kong, Shenzhen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24580",children:"https://arxiv.org/pdf/2512.24580"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel unified framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty by defining inner and outer coherent risk measures. 2. Develops a Bayesian Dynamic Programming algorithm that alternates posterior updates with value iteration, using a Monte Carlo and convex optimization estimator with strong consistency guarantees. 3. Provides theoretical analysis including convergence, sample complexity, and computational complexity under Dirichlet posterior and CVaR, validated through numerical experiments and an option hedging application."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b966fa69f9b8aafe26700ce5afe83099b3257d5b90314e5d3f668e4079ecdda_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b966fa69f9b8aafe26700ce5afe83099b3257d5b90314e5d3f668e4079ecdda_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces a robust Bayesian framework for on-policy risk-sensitive reinforcement learning that addresses transition uncertainty through coupled inner and outer risk measures. It develops a Bayesian Dynamic Programming algorithm with theoretical guarantees and demonstrates its effectiveness in convergence and robustness via numerical experiments and an option hedging application."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Need for risk-sensitive RL robust to transition uncertainty"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Unified framework with inner/outer risk measures, Bayesian DP algorithm with posterior updates and value iteration"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Theoretical guarantees, convergence, validated via experiments and option hedging application"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Sparse Offline Reinforcement Learning with Corruption Robustness"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [offline reinforcement learning, sparsity, corruption robustness, single-policy concentrability, actor-critic]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Nam Phuong Tran, Andi Nika, Goran Radanovic, Long Tran-Thanh, Debmalya Mandal"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Warwick, Max Planck Institute for Software Systems (MPI-SWS)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24768",children:"https://arxiv.org/pdf/2512.24768"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies limitations of integrating sparsity into standard robust offline RL methods like LSVI, showing they can fail due to overly pessimistic bonuses. 2. Proposes novel actor-critic methods with sparse robust estimator oracles that avoid pointwise pessimistic bonuses. 3. Provides the first non-vacuous theoretical guarantees for learning in high-dimensional sparse MDPs under weak (single-policy concentrability) coverage and strong data corruption."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ce133c71cdf619bf6a1597c047c8adc5b10b7d0584bd6af1944718635e12340_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ce133c71cdf619bf6a1597c047c8adc5b10b7d0584bd6af1944718635e12340_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of robust offline reinforcement learning in high-dimensional, sparse Markov Decision Processes where data may be corrupted. The authors propose new actor-critic methods that use sparse robust estimator oracles, avoiding the pitfalls of traditional approaches. Their work provides the first theoretical guarantees showing that learning a near-optimal policy is possible under weak data coverage and strong corruption, where previous methods fail."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Sparse Offline RL with Corruption Robustness<br>\u7a00\u758f\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e0e\u6297\u6c61\u67d3\u9c81\u68d2\u6027"] --\x3e Problem["Problem: High-dim sparse MDPs with corrupted data & weak coverage<br>\u95ee\u9898: \u5177\u6709\u6c61\u67d3\u6570\u636e\u548c\u5f31\u8986\u76d6\u7684\u9ad8\u7ef4\u7a00\u758fMDP"]\n    Root --\x3e Method["Method: Actor-critic with sparse robust estimator oracles<br>\u65b9\u6cd5: \u4f7f\u7528\u7a00\u758f\u9c81\u68d2\u4f30\u8ba1\u5668oracle\u7684Actor-critic"]\n    Root --\x3e Results["Results: First non-vacuous guarantees under single-policy concentrability & corruption<br>\u7ed3\u679c: \u5728\u5355\u7b56\u7565\u96c6\u4e2d\u6027\u548c\u6c61\u67d3\u4e0b\u7684\u9996\u4e2a\u975e\u5e73\u51e1\u4fdd\u8bc1"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:'cs.AI/cs.LG contains "accelerate" total: 28'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23719",children:"https://arxiv.org/pdf/2512.23719"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[CAD-to-mesh\u6d41\u7a0b\u74f6\u9888 / CAD-to-mesh Pipeline Bottlenecks]\n    C --\x3e C1[AI\u8f85\u52a9\u51e0\u4f55\u4e0e\u7f51\u683c\u751f\u6210 / AI-aided Geometry & Meshing]\n    C --\x3e C2[\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 / Machine Learning Methods]\n    C --\x3e C3[\u65b0\u5174\u81ea\u52a8\u5316\u5de5\u5177 / Emerging Automation Tools]\n    C1 --\x3e C1a[\u90e8\u4ef6\u5206\u7c7b / Part Classification]\n    C1 --\x3e C1b[\u7f51\u683c\u8d28\u91cf\u9884\u6d4b / Mesh Quality Prediction]\n    C1 --\x3e C1c[\u53bb\u7279\u5f81\u5316 / Defeaturing]\n    C2 --\x3e C2a[\u975e\u7ed3\u6784\u5316/\u5757\u7ed3\u6784\u5316\u7f51\u683c / Unstructured/Block-structured Meshing]\n    C2 --\x3e C2b[\u4f53\u79ef\u53c2\u6570\u5316 / Volumetric Parameterizations]\n    C2 --\x3e C2c[\u5e76\u884c\u7f51\u683c\u751f\u6210 / Parallel Mesh Generation]\n    C3 --\x3e C3a[\u5f3a\u5316\u5b66\u4e60 / Reinforcement Learning]\n    C3 --\x3e C3b[\u5927\u8bed\u8a00\u6a21\u578b / Large Language Models]\n    D --\x3e D1[AI\u4f5c\u4e3a\u8f85\u52a9\u6280\u672f / AI as Assistive Technology]\n    D --\x3e D2[\u4ee3\u8868\u6027\u65b9\u6cd5\u4e0e\u90e8\u7f72 / Representative Methods & Deployments]\n    D --\x3e D3[\u5173\u952e\u7814\u7a76\u6311\u6218 / Key Research Challenges]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] An Electronic Ising Machine"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Ising machine, analog computing, coupled oscillators, NP-Hard problems, energy-based learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Matt Bowring, Ben Anderdson, Ben Tiffany"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Purdue University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23720",children:"https://arxiv.org/pdf/2512.23720"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed a custom printed circuit board (PCB) as a low-power, high-speed accelerator for NP-Hard graph problems. 2. Implemented an analog computing architecture using coupled nonlinear electronic oscillators based on the annealing principle. 3. Provided a detailed hardware design, simulations, and experiments, offering insight into novel physics-based computing devices."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d9bd94424dd9d472b237fd13390bb509481b9b3c0f6c3249e5f405a2b4cec7c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d9bd94424dd9d472b237fd13390bb509481b9b3c0f6c3249e5f405a2b4cec7c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents an electronic Ising machine, a custom PCB accelerator that uses coupled analog oscillators to solve NP-Hard graph problems. The system leverages an energy-based representation and annealing to naturally find stable phase alignments that encode solutions. The work contributes a practical hardware implementation and insights into physics-based computing as an alternative paradigm."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[An Electronic Ising Machine] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem: Solving NP-Hard graph problems efficiently]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method: Custom PCB with analog coupled oscillators & annealing]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results: Low-power, high-speed physics-based accelerator]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [physics-informed machine learning], [coupled systems, sparsity regularization, multitask learning, partial differential equations, mesh-free sampling]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Esha Saha, Hao Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Alberta"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23761",children:"https://arxiv.org/pdf/2512.23761"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MUSIC, a novel sparsity-induced multitask neural network framework for learning coupled system dynamics when physics constraints and data are incomplete and mutually exclusive. 2. Introduces a method that integrates partial physical constraints with data-driven learning using mesh-free sampling and sparsity regularization for model compression and efficiency. 3. Demonstrates the framework's effectiveness on complex solutions (e.g., shock waves) under data-scarce and noisy conditions, outperforming non-sparse baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0e3d79b9b98f61c6847aeaba2b3e63b7fa984963e6f3f20b8ab17794c98a542_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0e3d79b9b98f61c6847aeaba2b3e63b7fa984963e6f3f20b8ab17794c98a542_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of modeling coupled dynamical systems where the governing equation is known for only one variable and data is available for another. It proposes MUSIC, a sparsity-regularized multitask neural network that integrates these partial constraints with data to recover full system solutions. The method shows improved accuracy and efficiency in learning complex solutions under scarce and noisy data conditions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Mismatch between known physics (for one variable) and observed data (for another) in coupled systems."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>MUSIC: Sparsity-induced multitask neural network with partial physics constraints and data-driven learning."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Accurately learns complex solutions (shock waves, patterns) under data-scarce, noisy conditions; outperforms non-sparse methods."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, entropy penalty, training-free, reasoning acceleration, draft-model verification]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tiancheng Su, Meicong Zhang, Guoxiu He"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," East China Normal University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23765",children:"https://arxiv.org/pdf/2512.23765"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Entropy-Aware Speculative Decoding (EASD), a training-free method that introduces a dynamic entropy-based penalty to reject low-confidence draft tokens, 2. Enables speculative decoding to potentially surpass the target model's performance by incorporating draft-model verification and preventing error propagation, 3. Demonstrates that EASD maintains efficiency comparable to standard speculative decoding while improving reasoning accuracy across multiple benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of speculative decoding being constrained by the target model's performance. It proposes Entropy-Aware Speculative Decoding (EASD), which uses entropy to quantify uncertainty and reject low-confidence draft tokens. Experiments show EASD outperforms existing methods and can surpass the target LLM's performance while maintaining comparable efficiency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Entropy-Aware Speculative Decoding] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[SD\u6027\u80fd\u53d7\u9650\u4e8e\u76ee\u6807\u6a21\u578b/SD performance capped by target model]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u5f15\u5165\u52a8\u6001\u71b5\u60e9\u7f5a/Introduce dynamic entropy penalty]\n    Method --\x3e M2[\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u62d2\u7edd\u4f4e\u7f6e\u4fe1\u5ea6\u4ee4\u724c/Reject low-confidence tokens based on uncertainty]\n    Method --\x3e M3[\u76ee\u6807\u6a21\u578b\u91cd\u91c7\u6837/Target model re-sampling]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u8d85\u8d8a\u73b0\u6709SD\u65b9\u6cd5/Outperforms existing SD methods]\n    Results --\x3e R2[\u5e38\u8d85\u8d8a\u76ee\u6807LLM\u672c\u8eab/Often surpasses target LLM]\n    Results --\x3e R3[\u6548\u7387\u4e0eSD\u76f8\u5f53/Efficiency comparable to SD]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [FPGA acceleration, model recovery, hardware-software co-design, GRU, Neural ODE]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bin Xu, Ayan Banerjee, Sandeep Gupta"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arizona State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23767",children:"https://arxiv.org/pdf/2512.23767"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed MERINDA, a hardware-friendly FPGA-accelerated framework for model recovery that replaces Neural ODEs with a formulation combining GRU-based discretized dynamics, dense inverse-ODE layers, sparsity-driven dropout, and lightweight solvers. 2. Designed the framework for streaming parallelism, enabling critical computational kernels to be fully parallelized on FPGA hardware. 3. Demonstrated transformative efficiency gains over GPU implementations, including 114x lower energy, 28x smaller memory footprint, and 1.68x faster training while maintaining state-of-the-art accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of deploying physical AI for model recovery on resource-constrained edge devices, where state-of-the-art methods using Neural ODEs are inefficient. The authors propose MERINDA, an FPGA-accelerated framework that uses a hardware-friendly architecture to replace expensive Neural ODE components. The results show that MERINDA achieves substantial improvements in energy, memory, and speed over GPU implementations while matching model recovery accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Enabling Physical AI at the Edge<br>\u5728\u8fb9\u7f18\u5b9e\u73b0\u7269\u7406\u4eba\u5de5\u667a\u80fd] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Model recovery methods (Neural ODEs) are inefficient for edge hardware<br>\u6a21\u578b\u6062\u590d\u65b9\u6cd5\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u6548\u7387\u4f4e\u4e0b]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>MERINDA: FPGA-accelerated, hardware-friendly framework<br>MERINDA: FPGA\u52a0\u901f\u7684\u786c\u4ef6\u53cb\u597d\u6846\u67b6]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>114x lower energy, 28x smaller memory, 1.68x faster training<br>\u80fd\u8017\u964d\u4f4e114\u500d, \u5185\u5b58\u5360\u7528\u51cf\u5c1128\u500d, \u8bad\u7ec3\u901f\u5ea6\u63d0\u53471.68\u500d]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Hardware Acceleration for Neural Networks: A Comprehensive Survey"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [hardware acceleration, systolic arrays, quantization, operator fusion, KV-cache]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bin Xu, Ayan Banerjee, Sandeep Gupta"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arizona State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23914",children:"https://arxiv.org/pdf/2512.23914"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Provides a unified taxonomy for hardware acceleration of neural networks across workloads, execution settings, and optimization levers. 2. Synthesizes key architectural ideas and discusses the role of software stacks and compilers in bridging models to hardware. 3. Highlights open challenges and future directions, such as efficient long-context LLM inference and robust support for dynamic workloads."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc95cc34eab31cf02c422baf1703e4640782447f887e0a949c6377cc40e8dc57_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc95cc34eab31cf02c422baf1703e4640782447f887e0a949c6377cc40e8dc57_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey comprehensively reviews the landscape of hardware acceleration for neural networks, organizing it by workloads, execution settings, and optimization techniques. It synthesizes key architectural approaches and the software-hardware co-design needed for efficient execution. The paper concludes by identifying open challenges like KV-cache management for LLMs and points to future research directions for next-generation accelerators."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Hardware Acceleration for Neural Networks: A Comprehensive Survey"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Hardware bottlenecks (memory, communication) limit neural network efficiency."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Survey & taxonomy of accelerators (GPU, TPU, FPGA), workloads, and optimizations."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Synthesis of architectural ideas and identification of open challenges (e.g., LLM inference)."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] HERO-Sign: Hierarchical Tuning and Efficient Compiler-Time GPU Optimizations for SPHINCS+ Signature Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [gpu kernels], [SPHINCS+, GPU Optimization, Tree Fusion, Adaptive Compilation, Kernel Overlapping]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yaoyun Zhou, Qian Wang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of California, Merced"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23969",children:"https://arxiv.org/pdf/2512.23969"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a Tree Fusion strategy for the FORS component, guided by an automated Tree Tuning search algorithm to adapt to different GPU architectures. 2. Employs an adaptive compilation strategy that automatically selects between PTX and native code paths for different SPHINCS+ kernels to maximize efficiency. 3. Optimizes batched signature generation using a task graph-based construction to reduce multi-stream idle time and kernel launch overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/29ca58021f9583efba2be9c3f10082df113be98d3f93c0f5ef9cc70c6fa8e481_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/29ca58021f9583efba2be9c3f10082df113be98d3f93c0f5ef9cc70c6fa8e481_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes HERO-Sign, a GPU-accelerated implementation for the post-quantum signature scheme SPHINCS+. It uses hierarchical tuning, including a Tree Fusion strategy and adaptive compilation, to better exploit GPU parallelism and reduce overhead. The method achieves significant throughput improvements and latency reduction compared to state-of-the-art GPU implementations across multiple architectures."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["HERO-Sign: SPHINCS+\u7b7e\u540d\u751f\u6210\u4f18\u5316 / HERO-Sign: SPHINCS+ Signature Generation Optimization"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["SPHINCS+\u7b7e\u540d\u751f\u6210\u6162 / Slow SPHINCS+ Signature Generation"]\n    Problem --\x3e P2["\u73b0\u6709GPU\u4f18\u5316\u672a\u5145\u5206\u5229\u7528\u5e76\u884c\u6027 / Existing GPU Optimizations Underutilize Parallelism"]\n    Method --\x3e M1["\u6811\u878d\u5408\u7b56\u7565 / Tree Fusion Strategy"]\n    Method --\x3e M2["\u81ea\u9002\u5e94\u7f16\u8bd1 / Adaptive Compilation"]\n    Method --\x3e M3["\u4efb\u52a1\u56fe\u6784\u5efa / Task Graph Construction"]\n    Results --\x3e R1["\u541e\u5410\u91cf\u63d0\u53471.24-3.13\u500d / Throughput Improvement 1.24-3.13x"]\n    Results --\x3e R2["\u5185\u6838\u542f\u52a8\u5ef6\u8fdf\u964d\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7 / Kernel Launch Latency Reduced by Two Orders of Magnitude"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [sparse attention, hardware-efficient, block-wise mean, spatiotemporal-aware permutation, first-frame sink]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aiyue Chen, Yaofu Liu, Junjian Huang, Guang Lian, Yiwu Yao, Wangli Lan, Jing Lin, Zhixin Ma, Tingting Zhou, Harry Yang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Huawei Technologies Co., Ltd, The Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24086",children:"https://arxiv.org/pdf/2512.24086"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes using block-wise mean values as representative tokens for low-overhead sparse mask prediction. 2. Implements spatiotemporal-aware token permutation to enhance the effectiveness of the sparse attention pattern. 3. Introduces a first-frame sink mechanism specifically optimized for video generation scenarios."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41a00bea8b8b0ba5148f027ed70530ca8414368fe966ff2da38fd4f95487de2b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41a00bea8b8b0ba5148f027ed70530ca8414368fe966ff2da38fd4f95487de2b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes RainFusion2.0, a hardware-efficient and adaptive sparse attention mechanism to reduce the high computational cost of Diffusion Transformers in video and image generation. The method uses block-wise mean tokens for mask prediction and introduces spatiotemporal-aware permutation and a first-frame sink mechanism. Experiments show it achieves 80% sparsity with 1.5-1.8x speedup without quality loss, and generalizes across models and hardware."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[RainFusion2.0] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: DiT\u6a21\u578b\u6ce8\u610f\u529b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u5f00\u9500\u5927\u4e14\u786c\u4ef6\u901a\u7528\u6027\u5dee]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5757\u5747\u503c\u4ee3\u8868\u4ee4\u724c\u9884\u6d4b\uff0c\u65f6\u7a7a\u611f\u77e5\u4ee4\u724c\u91cd\u6392\uff0c\u9996\u5e27\u4e0b\u6c89\u673a\u5236]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 80%\u7a00\u758f\u5ea6\uff0c1.5~1.8\u500d\u7aef\u5230\u7aef\u52a0\u901f\uff0c\u8de8\u6a21\u578b\u548c\u786c\u4ef6\u6709\u6548]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] CorGi: Contribution-Guided Block-Wise Interval Caching for Training-Free Acceleration of Diffusion Transformers"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [diffusion transformer, inference acceleration, interval caching, cross-attention, training-free]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yonglak Son, Suhyeok Kim, Seungryong Kim, Young Geun Kim"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Korea University, KAIST AI"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24195",children:"https://arxiv.org/pdf/2512.24195"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://casl-ku.github.io/CorGi",children:"https://casl-ku.github.io/CorGi"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CorGi, a training-free framework that accelerates DiT inference by selectively caching and reusing outputs of low-contribution transformer blocks across denoising steps. 2. Introduces CorGi+, an extension for text-to-image tasks that uses cross-attention maps to identify salient tokens and applies partial attention updates to protect important details. 3. Demonstrates significant speedup (up to 2.0x on average) on state-of-the-art DiT models while preserving high generation quality."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92c567dd9feea285991c6dbbdd5d85a85129420ce1925c585625dca252b806c4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92c567dd9feea285991c6dbbdd5d85a85129420ce1925c585625dca252b806c4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high inference cost of Diffusion Transformers (DiT) by proposing CorGi, a training-free acceleration framework that reduces redundant computation through contribution-guided, block-wise interval caching. For text-to-image tasks, CorGi+ further refines the approach using cross-attention maps for partial updates. Evaluations show the methods achieve up to 2.0x speedup while maintaining image quality."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[CorGi: Contribution-Guided Block-Wise Interval Caching<br>CorGi: \u8d21\u732e\u5f15\u5bfc\u7684\u5757\u7ea7\u95f4\u9694\u7f13\u5b58] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[DiT\u63a8\u7406\u6210\u672c\u9ad8<br>High DiT Inference Cost]\n    B1 --\x3e B2[\u53bb\u566a\u6b65\u9aa4\u95f4\u5b58\u5728\u5197\u4f59\u8ba1\u7b97<br>Redundant Computation Across Steps]\n    C --\x3e C1[CorGi: \u7f13\u5b58\u4f4e\u8d21\u732e\u5757<br>Cache Low-Contribution Blocks]\n    C1 --\x3e C2[CorGi+: \u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u56fe<br>Use Cross-Attention Maps]\n    C2 --\x3e C3[\u90e8\u5206\u6ce8\u610f\u529b\u66f4\u65b0<br>Partial Attention Updates]\n    D --\x3e D1[\u52a0\u901f\u9ad8\u8fbe2.0\u500d<br>Up to 2.0x Speedup]\n    D --\x3e D2[\u4fdd\u6301\u751f\u6210\u8d28\u91cf<br>Preserve Generation Quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Science Context Protocol, autonomous scientific agents, unified resource integration, experiment lifecycle management, federated servers]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yankai Jiang, Wenjie Lou, Lilong Wang, Zhenyu Tang, Shiyang Feng, Jiaxuan Lu, Haoran Sun, Yaning Pan, Shuang Gu, Haoyang Su, Feng Liu, Wangxu Wei, Pan Tan, Dongzhan Zhou, Fenghua Ling, Cheng Tan, Bo Zhang, Xiaosong Wang, Lei Bai, Bowen Zhou"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Artificial Intelligence Laboratory"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24189",children:"https://arxiv.org/pdf/2512.24189"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/InternScience/scp",children:"https://github.com/InternScience/scp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SCP, an open-source protocol-level standard for universally describing and invoking heterogeneous scientific resources (tools, models, datasets, instruments)., 2. Introduces a secure service architecture (centralized Hub & federated Servers) for managing the complete, traceable experiment lifecycle and enforcing fine-grained access control., 3. Demonstrates a functional platform built on SCP, integrating over 1,600 tool resources to facilitate secure, large-scale, multi-institution collaboration between AI agents and human researchers, reducing integration overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces the Science Context Protocol (SCP), an open-source standard designed to address the fragmentation and bespoke nature of current autonomous scientific agent systems. SCP provides a universal specification for resource integration and a secure service architecture for experiment orchestration, enabling seamless, large-scale collaboration across platforms. The authors conclude that SCP establishes essential infrastructure for scalable, reproducible, and agent-driven science by standardizing context and tool orchestration at the protocol level."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root[SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Bespoke, isolated agent systems; Lack of shared protocol for heterogeneous resources"] --\x3e Problem_Detail["\u5177\u4f53\u6311\u6218/Specific Challenges<br>Difficult to deploy beyond single lab; Hard to reuse components & reproduce workflows"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Science Context Protocol (SCP)"] --\x3e Method_Pillar1["\u652f\u67f11: \u7edf\u4e00\u8d44\u6e90\u96c6\u6210/Unified Resource Integration<br>Universal spec for describing/invoking tools, models, data, instruments"]\n    Method --\x3e Method_Pillar2["\u652f\u67f12: \u5b9e\u9a8c\u751f\u547d\u5468\u671f\u7ba1\u7406/Experiment Lifecycle Management<br>Secure architecture (Hub & Servers) for registration, execution, monitoring"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Enables global web of autonomous agents"] --\x3e Results_Outcome1["\u6210\u679c1: \u5927\u89c4\u6a21\u751f\u6001\u7cfb\u7edf/Large-scale Ecosystem<br>1,600+ integrated tool resources"]\n    Results --\x3e Results_Outcome2["\u6210\u679c2: \u4fc3\u8fdb\u534f\u4f5c/Facilitates Collaboration<br>Reduces integration overhead; Enhances reproducibility"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning for Accurate and Robust UAV Trajectory Tracking"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [control theory & optimization], [Heteroscedastic Bayesian Optimization, PID Tuning, UAV Trajectory Tracking]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Fuqiang Gu, Jiangshan Ai, Xu Lu, Xianlei Long, Yan Li, Tao Jiang, Chao Chen, Huidong Liu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Chongqing University, Macquarie University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24249",children:"https://arxiv.org/pdf/2512.24249"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HBO-PID, a novel control algorithm integrating Heteroscedastic Bayesian Optimization with classical PID for UAV control. 2. Introduces explicit modeling of input-dependent noise variance to improve adaptation to dynamic environments. 3. Adopts a two-stage optimization strategy to accelerate the convergence of finding optimal controller parameters."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f2d1516402e9370a6abddfcf55734a6f894512a452d5f59baa27df4f4b8fcdd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f2d1516402e9370a6abddfcf55734a6f894512a452d5f59baa27df4f4b8fcdd_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes HBO-PID, a novel control algorithm that combines Heteroscedastic Bayesian Optimization with PID control to improve UAV trajectory tracking. The method explicitly models noise variance and uses a two-stage optimization for efficiency. Experiments show it significantly outperforms state-of-the-art methods in both position and angular accuracy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898/Paper Title: Heteroscedastic Bayesian Optimization-Based Dynamic PID Tuning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u65e0\u4eba\u673a\u8f68\u8ff9\u8ddf\u8e2a\u7cbe\u5ea6\u4e0e\u9c81\u68d2\u6027\u4e0d\u8db3/UAV Trajectory Tracking Accuracy & Robustness Limited]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5f02\u65b9\u5dee\u8d1d\u53f6\u65af\u4f18\u5316PID/Heteroscedastic Bayesian Optimization PID (HBO-PID)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u4f4d\u7f6e\u7cbe\u5ea6\u63d0\u534724.7%-42.9%, \u89d2\u5ea6\u7cbe\u5ea6\u63d0\u534740.9%-78.4%/Position Accuracy \u219124.7%-42.9%, Angular Accuracy \u219140.9%-78.4%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [data selection, policy gradient, mask learning, quality-diversity trade-off, FineWeb]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," ByteDance Seed, Shanghai Jiao Tong University, University of Sydney, Sun Yat-sen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24265",children:"https://arxiv.org/pdf/2512.24265"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/ByteDance-Seed/DATAMASK",children:"https://github.com/ByteDance-Seed/DATAMASK"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DATAMASK, a novel joint learning framework for large-scale pre-training data selection that simultaneously optimizes quality and diversity metrics. 2. Formulates data selection as a mask learning problem and solves it efficiently using policy gradient-based optimization with acceleration enhancements, reducing selection time by 98.9% compared to greedy algorithms. 3. Creates and releases FineWeb-Mask, a high-quality and diverse 10% subset of the 15-trillion-token FineWeb dataset, which significantly improves model performance (e.g., +3.2% on a 1.5B model) across diverse tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fd504349b8c0bb1934304d821a648ed4ca490b2f41e136f9b7a6220f39d5d2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fd504349b8c0bb1934304d821a648ed4ca490b2f41e136f9b7a6220f39d5d2_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of efficiently selecting high-quality and diverse data for large-scale LLM pre-training, where traditional methods are costly and suboptimal. It proposes DATAMASK, a policy gradient-based framework that learns optimal data masks to jointly optimize quality and diversity, drastically speeding up selection. The resulting curated dataset, FineWeb-Mask, leads to significant performance gains in pre-trained models, demonstrating the framework's effectiveness."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\uff0c\u8054\u5408\u8003\u8651\u8d28\u91cf\u4e0e\u591a\u6837\u6027\u6307\u6807\u8fdb\u884c\u6837\u672c\u9009\u62e9\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faDATAMASK\u6846\u67b6\uff0c\u5c06\u9009\u62e9\u8fc7\u7a0b\u89c6\u4e3a\u63a9\u7801\u5b66\u4e60\u95ee\u9898\uff0c\u4f7f\u7528\u7b56\u7565\u68af\u5ea6\u8fdb\u884c\u4f18\u5316]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u9009\u62e9\u65f6\u95f4\u51cf\u5c1198.9%\uff0c\u4eceFineWeb\u4e2d\u9009\u51fa\u7684\u5b50\u96c6\u663e\u8457\u63d0\u5347\u591a\u79cd\u6a21\u578b\u6027\u80fd]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Real-world Reinforcement Learning from Suboptimal Interventions"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [human-in-the-loop RL, constrained RL, state-wise Lagrangian, suboptimal interventions, robotic manipulation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yinuo Zhao, Huiqian Jin, Lechun Jiang, Xinyi Zhang, Kun Wu, Pei Ren, Zhiyuan Xu, Zhengping Che, Lei Sun, Dapeng Wu, Chi Harold Liu, Jian Tang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing Innovation Center of Humanoid Robotics, City University of Hong Kong, Nankai University, Beijing Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24288",children:"https://arxiv.org/pdf/2512.24288"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SiLRI, a state-wise Lagrangian RL algorithm that formulates the online manipulation problem as a constrained RL optimization where constraint bounds are determined by the uncertainty of human interventions. 2. Introduces a state-wise Lagrange multiplier and solves the problem via a min-max optimization to jointly optimize the policy and the multiplier, enabling exploitation of suboptimal interventions without being constrained by them. 3. Demonstrates through real-world experiments that SiLRI significantly accelerates learning, reducing time to 90% success rate by at least 50% compared to prior methods and achieving 100% success on long-horizon tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f15ba64d7b2d7760e2411270a47d97305fe1e21ad798c2423cb89a0e5cb5750_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of leveraging suboptimal human interventions to accelerate real-world robotic RL without being limited by them. It proposes SiLRI, a state-wise Lagrangian RL algorithm that treats interventions as state-dependent constraints and solves a min-max optimization. Real-world experiments show SiLRI cuts learning time by over 50% and achieves perfect success on complex tasks where other methods fail."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Real-world Reinforcement Learning from Suboptimal Interventions] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u5982\u4f55\u5229\u7528\u53ef\u80fd\u6b21\u4f18\u7684\u4eba\u7c7b\u5e72\u9884\u52a0\u901f\u5b66\u4e60\u800c\u4e0d\u53d7\u5176\u9650\u5236/How to leverage potentially suboptimal human interventions to accelerate learning without being constrained by them]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faSiLRI\uff0c\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u62c9\u683c\u6717\u65e5\u7684RL\u7b97\u6cd5\uff0c\u5c06\u5e72\u9884\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u7ea6\u675f/Propose SiLRI, a state-wise Lagrangian RL algorithm treating intervention uncertainty as constraints]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u5b66\u4e60\u901f\u5ea6\u63d0\u5347>50%\uff0c\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e0a\u8fbe\u5230100%\u6210\u529f\u7387/Learning speed improved >50%, achieved 100% success rate on long-horizon tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [visual question answering, lesion segmentation, multimodal models]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen, Noel Codella, Roberto Andres Novoa, Josep Malvehy"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Microsoft, University of Washington, Stanford University, Hospital Clinic of Barcelona"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24340",children:"https://arxiv.org/pdf/2512.24340"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://osf.io/72rp3",children:"https://osf.io/72rp3"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduction of the Dermatology Assessment Schema (DAS), a novel expert-developed framework for structured dermatological feature assessment. 2. Release of DermaVQA-DAS, an extended dataset supporting closed-ended question answering and lesion segmentation on patient-generated images. 3. Comprehensive benchmarking of state-of-the-art multimodal models on the new tasks, analyzing the impact of prompt design on segmentation performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of patient-centered benchmarks in dermatology by introducing DermaVQA-DAS, a dataset extension built upon a novel expert-developed assessment schema (DAS) for structured feature annotation. It supports two tasks\u2014closed-ended visual question answering and lesion segmentation\u2014on patient-generated images and queries. The study benchmarks modern multimodal models, finding strong QA performance and demonstrating that prompt design significantly impacts segmentation results."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[DermaVQA-DAS] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u60a3\u8005\u89c6\u89d2/Existing datasets lack patient perspective]\n    P1 --\x3e P2[\u9650\u5236\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u62a4\u7406\u5e94\u7528/Limits patient-centered care applications]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u63d0\u51fa\u76ae\u80a4\u75c5\u8bc4\u4f30\u6846\u67b6(DAS)/Propose Dermatology Assessment Schema (DAS)]\n    M1 --\x3e M2[\u6269\u5c55DermaVQA\u6570\u636e\u96c6/Extend DermaVQA dataset]\n    M2 --\x3e M3[\u652f\u6301\u4e24\u9879\u4efb\u52a1:\u5c01\u95ed\u5f0f\u95ee\u7b54\u4e0e\u5206\u5272/Support two tasks: closed QA & segmentation]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u63d0\u793a\u8bbe\u8ba1\u5f71\u54cd\u5206\u5272\u6027\u80fd/Prompt design impacts segmentation performance]\n    R1 --\x3e R2[\u6a21\u578b\u5728QA\u4e0a\u8868\u73b0\u5f3a\u52b2/Models perform strongly on QA]\n    R2 --\x3e R3[\u516c\u5f00\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u534f\u8bae/Publicly release dataset & evaluation protocols]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Subsecond 3D Mesh Generation for Robot Manipulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [3D reconstruction], [3D mesh generation, open-vocabulary segmentation, point cloud registration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Qian Wang, Omar Abdellall, Tony Gao, Xiatao Sun, Daniel Rakita"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Yale University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24428",children:"https://arxiv.org/pdf/2512.24428"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An end-to-end system for generating a contextually grounded 3D mesh from a single RGB-D image in under one second. 2. Integration of open-vocabulary segmentation, accelerated diffusion-based mesh generation, and robust point cloud registration into a single optimized pipeline. 3. Demonstration of the system's effectiveness in enabling real-world robot manipulation tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c21c85b85a842e2b91805631063ff03077c9e225bd56663524ef2ce7b37de98b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c21c85b85a842e2b91805631063ff03077c9e225bd56663524ef2ce7b37de98b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a fast, end-to-end system that generates a high-quality, contextually grounded 3D mesh from a single RGB-D image in under one second. The method integrates open-vocabulary segmentation, accelerated diffusion-based mesh generation, and point cloud registration. The system enables the practical use of meshes for real-time robotic perception and planning, as demonstrated in a manipulation task."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Subsecond 3D Mesh Generation for Robot Manipulation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u751f\u6210\u6162\u4e14\u7f3a\u4e4f\u573a\u666f\u5173\u8054/Slow generation & lack of contextual grounding]\n    C --\x3e C1[\u5f00\u653e\u8bcd\u6c47\u5206\u5272/Open-vocabulary segmentation]\n    C --\x3e C2[\u52a0\u901f\u6269\u6563\u7f51\u683c\u751f\u6210/Accelerated diffusion mesh generation]\n    C --\x3e C3[\u70b9\u4e91\u914d\u51c6/Point cloud registration]\n    D --\x3e D1[<1\u79d2\u751f\u6210/<1 second generation]\n    D --\x3e D2[\u652f\u6301\u673a\u5668\u4eba\u64cd\u4f5c/Enables robot manipulation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [computational physics, numerical methods], [genetic programming, sequence acceleration, neutron transport, slab geometry, discrete ordinates]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Japan K. Patel, Barry D. Ganapol, Anthony Magliari, Matthew C. Schmidt, Todd A. Wareing"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Gateway Scripts, University of Arizona, Varian Medical Systems, Washington University in St. Louis"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24559",children:"https://arxiv.org/pdf/2512.24559"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Applied genetic programming to automatically discover novel convergence acceleration methods for neutron transport problems, moving beyond classical methods with fixed assumptions. 2. Evolved a specific mathematical formula accelerator tailored to the convergence characteristics of discrete ordinates (SN) solutions in slab geometry. 3. Demonstrated the discovered accelerator's superior performance, achieving over 75% success rate in improving convergence, nearly double that of classical techniques on the tested problem set."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d34d82f8c1e37e97ac83244d31b5fb8965de8b3a0c8f93a666dd8bc4b3585880_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d34d82f8c1e37e97ac83244d31b5fb8965de8b3a0c8f93a666dd8bc4b3585880_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper uses genetic programming to automatically discover new mathematical formulas for accelerating the convergence of numerical solutions to neutron transport problems in slab geometry. The evolved accelerator, which uses second differences and cross-product terms, significantly outperformed classical methods like Aitken's and Wynn's, showing the potential of AI to generate novel numerical methods in computational physics."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Evolutionary Discovery of Sequence Acceleration Methods for Slab Geometry Neutron Transport] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u7ecf\u5178\u52a0\u901f\u65b9\u6cd5\u6cdb\u5316\u6027\u5dee<br>Classical acceleration methods lack generalization]\n    C --\x3e C1[\u4f7f\u7528\u9057\u4f20\u7f16\u7a0b\u8fdb\u5316\u516c\u5f0f<br>Use Genetic Programming to evolve formulas]\n    D --\x3e D1[\u53d1\u73b0\u65b0\u578b\u52a0\u901f\u5668<br>Discovered novel accelerator]\n    D --\x3e D2[\u6210\u529f\u7387 >75%, \u6027\u80fd\u7ffb\u500d<br>>75% success rate, nearly double performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [autoregressive visual generation, radial parallel prediction, nested attention mechanism]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Siyang Wang, Hanting Li, Wei Li, Jie Hu, Xinghao Chen, Feng Zhao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, Huawei Noah's Ark Lab"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24639",children:"https://arxiv.org/pdf/2512.24639"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a radial parallel prediction framework (RadAR) that reorders the autoregressive generation process from sequential to spatial, grouping tokens into concentric rings for parallel prediction. 2. Introduced a nested attention mechanism to dynamically refine inconsistent predictions during the forward pass, mitigating error accumulation from parallel generation. 3. Designed a method that preserves the structural locality and spatial coherence of visual scenes while significantly improving inference efficiency and parallelizability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bffd5ae0463dd26d6d9beddadbbf4c0de1249205c2c3865172fb5172c4b22d2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bffd5ae0463dd26d6d9beddadbbf4c0de1249205c2c3865172fb5172c4b22d2_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the low inference efficiency of traditional autoregressive models in visual generation due to their sequential token-by-token decoding. It proposes RadAR, a framework that organizes generation around a radial topology, enabling parallel prediction of tokens within the same spatial ring and using a nested attention mechanism to correct errors. The method significantly accelerates generation while maintaining representational capacity."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u987a\u5e8f\u89e3\u7801\u5bfc\u81f4\u63a8\u7406\u6548\u7387\u4f4e/Traditional autoregressive sequential decoding leads to low inference efficiency]\n    C --\x3e C1[\u63d0\u51faRadAR\u6846\u67b6\uff1a\u5f84\u5411\u5e76\u884c\u9884\u6d4b/Propose RadAR framework: Radial Parallel Prediction]\n    C1 --\x3e C2[\u5c06token\u6309\u7a7a\u95f4\u8ddd\u79bb\u5206\u7ec4\u4e3a\u540c\u5fc3\u73af/Group tokens into concentric rings by spatial distance]\n    C1 --\x3e C3[\u5f15\u5165\u5d4c\u5957\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u52a8\u6001\u4fee\u6b63/Introduce nested attention for dynamic correction]\n    D --\x3e D1[\u4fdd\u6301\u89c6\u89c9\u7ed3\u6784\u5c40\u90e8\u6027\u548c\u7a7a\u95f4\u8fde\u8d2f\u6027/Preserves structural locality and spatial coherence]\n    D --\x3e D2[\u663e\u8457\u63d0\u9ad8\u5e76\u884c\u5316\u548c\u751f\u6210\u6548\u7387/Significantly improves parallelization and generation efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [VLA models, action chunking, trajectory smoothing, asynchronous inference, robot motion control]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yongsheng Zhao, Lei Zhao, Baoping Cheng, Gongxin Yao, Xuanzhang Wen, Han Gao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," China Mobile (Hangzhou) Information Technology Co., Ltd."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24673",children:"https://arxiv.org/pdf/2512.24673"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VLA-RAIL, a framework for asynchronous inference and motion control to enable smooth, continuous robot action execution. 2. Introduces a Trajectory Smoother using polynomial fitting to filter noise and jitter within an action chunk. 3. Designs a Chunk Fuser to ensure position, velocity, and acceleration continuity between successive action chunks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/886e2a128c843b55a605e8cbe2a7b174fc4b0e84225f1908b0b180891d09bdad_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/886e2a128c843b55a605e8cbe2a7b174fc4b0e84225f1908b0b180891d09bdad_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of motion jitter, stalling, and pauses when deploying Vision-Language-Action (VLA) models on robots due to sequential inference and execution. It proposes VLA-RAIL, a framework that decouples model inference from robot control via a Trajectory Smoother and Chunk Fuser. Experiments show it reduces jitter, increases speed, and improves task success rates for robotic manipulation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[VLA-RAIL: A Real-Time Asynchronous Inference Linker] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u673a\u5668\u4eba\u52a8\u4f5c\u6296\u52a8\u3001\u5361\u987f/Existing methods cause jitter, stalling in robot actions]\n    C --\x3e C1[\u5f02\u6b65\u63a8\u7406\u4e0e\u8fd0\u52a8\u63a7\u5236/Asynchronous inference & motion control]\n    C1 --\x3e C2[\u8f68\u8ff9\u5e73\u6ed1\u5668/Trajectory Smoother]\n    C1 --\x3e C3[\u5757\u878d\u5408\u5668/Chunk Fuser]\n    D --\x3e D1[\u51cf\u5c11\u8fd0\u52a8\u6296\u52a8/Reduces motion jitter]\n    D --\x3e D2[\u63d0\u5347\u6267\u884c\u901f\u5ea6/Enhances execution speed]\n    D --\x3e D3[\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387/Improves task success rates]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["[arXiv260101] FPGA Co-Design for Efficient N",":M"," Sparse and Quantized Model Inference"]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [N",":M"," structured pruning, 4-bit quantization, systolic array, FPGA accelerator, hardware-software co-design]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Fen-Yu Hsieh, Yun-Chang Teng, Ding-Yong Hong, Jan-Jan Wu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute of Information Science, Academia Sinica"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24713",children:"https://arxiv.org/pdf/2512.24713"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an automation framework and unified pipeline for applying N",":M"," structured pruning and 4-bit integer quantization to compress LLMs. 2. Presents a hardware-software co-design method that generates a custom systolic-array-based FPGA accelerator for efficient inference. 3. Demonstrates the synergy of fine-grained sparsity and quantization, achieving significant reductions in storage and latency while offering flexibility beyond fixed hardware sparsity patterns."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a594f5eb4f19e15f5f182ee786cc270613c6a3d07553a78731a54b9a3ae90ea_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a594f5eb4f19e15f5f182ee786cc270613c6a3d07553a78731a54b9a3ae90ea_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high computational and memory demands of LLMs by proposing a hardware-software co-design framework. The method combines N",":M"," structured pruning and 4-bit quantization to compress models, and implements a custom FPGA accelerator for efficient inference. The results show significant reductions in storage and latency, demonstrating the effectiveness of the approach for deployable LLM inference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("LLM\u90e8\u7f72\u56f0\u96be/LLM Deployment Challenge")\n    P1 --\x3e P2("\u9ad8\u8ba1\u7b97\u4e0e\u5185\u5b58\u9700\u6c42/High Computation & Memory Requirements")\n    Method --\x3e M1("\u6a21\u578b\u538b\u7f29/Model Compression")\n    M1 --\x3e M2("N:M\u7ed3\u6784\u5316\u526a\u679d\u4e0e4-bit\u91cf\u5316/N:M Structured Pruning & 4-bit Quantization")\n    Method --\x3e M3("\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1/Hardware-Software Co-Design")\n    M3 --\x3e M4("\u751f\u6210\u57fa\u4e8e\u8109\u52a8\u9635\u5217\u7684FPGA\u52a0\u901f\u5668/Generating Systolic-Array-based FPGA Accelerator")\n    Results --\x3e R1("\u5b58\u50a8\u51cf\u5c114\u500d/4x Weight Storage Reduction")\n    Results --\x3e R2("\u77e9\u9635\u4e58\u6cd5\u52a0\u901f1.71\u500d/1.71x Matrix Multiplication Speedup")\n    Results --\x3e R3("\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e1.29\u500d/1.29x End-to-End Latency Reduction")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [video generation, diffusion sampling, model capacity, velocity divergence, inference acceleration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jibin Song, Mingi Kwon, Jaeseok Jeong, Youngjung Uh"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Yonsei University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24724",children:"https://arxiv.org/pdf/2512.24724"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://jibin86.github.io/flowblending_project_page",children:"https://jibin86.github.io/flowblending_project_page"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. The observation that model capacity impact varies across denoising timesteps, being crucial in early/late stages but negligible in intermediate stages., 2. The proposal of FlowBlending, a stage-aware multi-model sampling strategy that dynamically allocates large and small models to different stages., 3. The introduction of simple criteria and a velocity-divergence analysis to identify capacity-sensitive regions and choose stage boundaries."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ac4128c7bf14ee06860b55c2869f6a243b40a94d93faf3a63e6549b8c5d06f8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ac4128c7bf14ee06860b55c2869f6a243b40a94d93faf3a63e6549b8c5d06f8_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high computational cost of video diffusion models by proposing FlowBlending, a stage-aware sampling strategy that uses a large model for critical early/late denoising stages and a small model for the intermediate stage. This method achieves up to 1.65x faster inference with significantly fewer FLOPs while preserving the output quality of the large model, and is compatible with other acceleration techniques."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: High computational cost of video diffusion models")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Stage-aware multi-model sampling (large model for early/late stages, small model for intermediate stage)")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Faster inference, fewer FLOPs, maintained visual fidelity")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Big AI is accelerating the metacrisis: What can we do?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [ethics & society], [metacrisis, language engineers, human flourishing, planetary boundaries, technofeudalism]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Steven Bird"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Charles Darwin University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24863",children:"https://arxiv.org/pdf/2512.24863"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),' 1. Identifies and critiques the role of "Big AI" and language engineers in accelerating converging global crises (ecological, meaning, language). 2. Highlights the ethical conflict between professional obligations (e.g., ACL Code of Ethics) and the harms caused by current NLP/AI development practices. 3. Proposes a paradigm shift for NLP, advocating for a future centered on human flourishing and amplifying social networks rather than scaling through large, polluting models.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper argues that the current trajectory of "Big AI," particularly in NLP, is accelerating a global metacrisis. It critiques the field\'s focus on scalability and value-neutral technology development, which benefits powerful interests at the expense of the public good and the planet. The paper concludes by urgently calling for an alternative, life-affirming future for NLP centered on human flourishing.']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Big AI is accelerating the metacrisis: What can we do?] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Big AI\u52a0\u901f\u751f\u6001\u3001\u610f\u4e49\u548c\u8bed\u8a00\u5371\u673a/Big AI accelerates ecological, meaning, and language crises]\n    B --\x3e B2[\u8bed\u8a00\u5de5\u7a0b\u5e08\u7684\u4f26\u7406\u56f0\u5883/Ethical dilemma of language engineers]\n    C --\x3e C1[\u6279\u5224\u5f53\u524d\u53ef\u6269\u5c55\u6027\u53d9\u4e8b/Critique current scalability narrative]\n    C --\x3e C2[\u547c\u5401\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848/Call to explore alternatives]\n    D --\x3e D1[\u9700\u8981\u4ee5\u4eba\u7c7b\u7e41\u8363\u4e3a\u4e2d\u5fc3\u7684\u672a\u6765/NLP future must center human flourishing]\n    D --\x3e D2[\u5229\u7528\u96c6\u4f53\u667a\u6167\u8bbe\u8ba1\u751f\u547d\u80af\u5b9a\u7684NLP/Design life-affirming NLP with collective intelligence]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [3D object detection], [semi-automated annotation, human-in-the-loop, 3D object detection, data anonymization, domain adaptation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Andrii Gamalii, Daniel G\xf3rniak, Robert Nowak, Bart\u0142omiej Olber, Krystian Radlak, Jakub Winter"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Warsaw University of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24896",children:"https://arxiv.org/pdf/2512.24896"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A semi-automated annotation pipeline that combines AI-generated initial annotations with human verification to reduce cost and time. 2. A system architecture supporting iterative model retraining and incorporating data anonymization and domain adaptation techniques. 3. A methodology and toolset that accelerates the creation of a large-scale, multimodal autonomous driving dataset tailored to Polish road conditions."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/575844a7a43a73f8b8d00aa31dfa90a80dbb02b7129fa4cb48b23a397afe6e78_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/575844a7a43a73f8b8d00aa31dfa90a80dbb02b7129fa4cb48b23a397afe6e78_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the costly and time-consuming problem of manually annotating large-scale, multimodal datasets for autonomous vehicles. It proposes a semi-automated, human-in-the-loop annotation pipeline that uses 3D object detection to generate initial labels, enabling iterative retraining and incorporating anonymization and adaptation techniques. The developed solution significantly reduces annotation time while ensuring high-quality, consistent labels, directly supporting the creation of a Polish-specific autonomous driving dataset."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Manual annotation of multimodal AV datasets is costly and time-consuming."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: A semi-automated, human-in-the-loop pipeline using 3D object detection for initial annotations."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Substantial time savings and consistent, high-quality annotations."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] FineTec: Fine-Grained Action Recognition Under Temporal Corruption via Skeleton Decomposition and Sequence Completion"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dian Shao, Mingfei Shi, Like Liu"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.strong,{children:"institution:"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25067",children:"https://arxiv.org/pdf/2512.25067"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5283ff5d47b7344e785800154886fe627c149576029db00dc6b0fd29ebf4b9fb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5283ff5d47b7344e785800154886fe627c149576029db00dc6b0fd29ebf4b9fb_w640_q70.webp"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI using Physics-Informed Diffusion Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [medical imaging], [diffusion models, quantitative MRI, data consistency, physics-informed, multi-parametric mapping]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shishuai Wang, Florian Wiesinger, Noemi Sgambelluri, Carolin Pirkl, Stefan Klein, Juan A. Hernandez-Tamames, Dirk H.J. Poot"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Erasmus MC (Erasmus University Medical Center)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23726",children:"https://arxiv.org/pdf/2512.23726"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a diffusion model-based method (q3-MuPa) for quantitative MRI mapping that combines a deep generative model with a physics-based data consistency constraint., 2. Enables high-quality mapping from a fourfold-accelerated, nearly silent MRI scan (MuPa-ZTE), reducing acquisition time to ~1 minute., 3. Demonstrates successful training on synthetic data from digital phantoms alone, with strong generalization to real patient and phantom scans."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e081389f251cbbacaf7c704cd1a34c3a032b2173e63192833db976abd6541d5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e081389f251cbbacaf7c704cd1a34c3a032b2173e63192833db976abd6541d5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes q3-MuPa, a method that uses a physics-informed diffusion model to generate high-quality quantitative MRI maps (T1, T2, proton density) from accelerated, silent scans. The method integrates a denoising diffusion model with the MRI signal physics as a constraint during inference. It achieves accurate mapping from 1-minute scans and generalizes well to real data despite being trained only on synthetic phantoms."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Need for fast, quiet, and accurate quantitative MRI mapping)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Physics-informed diffusion model with data consistency)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: High-accuracy maps from 1-min scans, trained on synthetic data)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [hpc], [numerical linear algebra], [hierarchical preconditioning, stochastic Galerkin method, PDE-constrained optimization, generalized polynomial chaos, uncertainty quantification]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zhendong Li, Akwum Onwunta, Bed\u0159ich Soused\xedk"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Lehigh University, University of Maryland, Baltimore County"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23804",children:"https://arxiv.org/pdf/2512.23804"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Development of efficient hierarchical preconditioners for large-scale, ill-conditioned linear systems in stochastic PDE-constrained optimization. 2. A discretize-then-optimize framework integrating finite elements, stochastic Galerkin approximation, and time discretization for problems with uncertain coefficients. 3. Exploitation of sparsity in generalized polynomial chaos expansions to balance computational cost and preconditioning quality."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05293316aad14f8b4a2329613d52a860965c42ee1108d515f0cd4dc855e7ddac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05293316aad14f8b4a2329613d52a860965c42ee1108d515f0cd4dc855e7ddac_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes hierarchical preconditioners to accelerate the solution of optimal control problems governed by PDEs with uncertain coefficients. The method combines a discretize-then-optimize framework with stochastic Galerkin approximation and exploits sparsity in polynomial chaos expansions. Numerical experiments show the preconditioners significantly improve solver convergence for both steady-state and time-dependent problems under uncertainty."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Stochastic Galerkin Method and Hierarchical Preconditioning<br>\u968f\u673aGalerkin\u65b9\u6cd5\u4e0e\u5206\u5c42\u9884\u5904\u7406"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["PDE\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u542b\u4e0d\u786e\u5b9a\u7cfb\u6570<br>PDE-constrained Optimization with Uncertain Coefficients"] --\x3e P1["\u5927\u89c4\u6a21\u75c5\u6001\u7ebf\u6027\u7cfb\u7edf<br>Large-scale Ill-conditioned Linear Systems"]\n    Method["\u79bb\u6563-\u4f18\u5316\u6846\u67b6\u4e0e\u5206\u5c42\u9884\u5904\u7406<br>Discretize-then-Optimize & Hierarchical Preconditioning"] --\x3e M1["\u6709\u9650\u5143/\u968f\u673aGalerkin/\u65f6\u95f4\u79bb\u6563<br>FEM/Stochastic Galerkin/Time Discretization"]\n    Method --\x3e M2["\u5229\u7528gPC\u5c55\u5f00\u7684\u7a00\u758f\u6027<br>Exploit Sparsity of gPC Expansion"]\n    Results["\u6570\u503c\u5b9e\u9a8c<br>Numerical Experiments"] --\x3e R1["\u663e\u8457\u52a0\u901f\u8fed\u4ee3\u6c42\u89e3\u5668<br>Significantly Accelerates Iterative Solvers"]\n    Results --\x3e R2["\u4e3a\u7a33\u6001/\u77ac\u6001\u95ee\u9898\u63d0\u4f9b\u9c81\u68d2\u6c42\u89e3\u5668<br>Robust Solvers for Steady/Time-dependent Problems"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [remote sensing image analysis], [InSAR, Transformer, ground deformation forecasting, cross-site generalization, multimodal learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wendong Yao, Binhua Huang, Soumyabrata Dev"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," ADAPT SFI Research Centre, University College Dublin"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23906",children:"https://arxiv.org/pdf/2512.23906"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel multimodal patch-based Transformer architecture for InSAR-based ground deformation nowcasting, integrating displacement snapshots with static kinematic indicators and temporal encodings. 2. Demonstrated superior performance of the proposed model over baseline models (CNN-LSTM, STGCN) on a test tile in eastern Ireland, achieving high accuracy (RMSE=0.90mm, R\xb2=0.97). 3. Showcased strong cross-site generalization by training on one tile and applying the model without fine-tuning to five unseen European tiles, maintaining high performance (R\xb2\u22650.93) across diverse deformation patterns."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of forecasting ground deformation from InSAR time series data. It proposes a multimodal Transformer model that combines recent displacement maps with kinematic indicators and temporal features to predict the next displacement epoch. The model achieves high accuracy and demonstrates strong generalization across different geographic sites in Europe without requiring retraining."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[\u8bba\u6587\u6807\u9898: A multimodal Transformer for InSAR-based ground deformation forecasting] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u5982\u4f55\u5229\u7528\u5386\u53f2InSAR\u6570\u636e\u9884\u6d4b\u672a\u6765\u7684\u5730\u8868\u5f62\u53d8?] --\x3e P1[\u6311\u6218/Challenges: \u957f\u671f\u8d8b\u52bf\u3001\u5b63\u8282\u5468\u671f\u3001\u7a81\u53d8\u4e8b\u4ef6\u7684\u53e0\u52a0]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u591a\u6a21\u6001Transformer] --\x3e M1[\u8f93\u5165/Inputs: \u8fd1\u671f\u5f62\u53d8\u56fe\u3001\u9759\u6001\u8fd0\u52a8\u5b66\u6307\u6807\u3001\u65f6\u95f4\u7f16\u7801]\n    Method --\x3e M2[\u4efb\u52a1/Task: \u5355\u6b65\u3001\u56fa\u5b9a\u95f4\u9694\u7684\u4e0b\u4e00\u65f6\u671f\u4e34\u8fd1\u9884\u62a5]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6027\u80fd/Performance: RMSE=0.90mm, R\xb2=0.97 (\u7231\u5c14\u5170\u6d4b\u8bd5\u96c6)]\n    Results --\x3e R2[\u6cdb\u5316/Generalization: \u8de8\u6b27\u6d325\u4e2a\u672a\u89c1\u533a\u57df\uff0cR\xb2\u22650.93]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [medical image reconstruction], [disentangled representation, latent diffusion model, self-supervised learning, multidimensional MRI, zero-shot adaptation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ruiyang Zhao, Fan Lam"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24674",children:"https://arxiv.org/pdf/2512.24674"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel learned feature-based image representation that disentangles features like geometry and contrast into distinct latent spaces. 2. The integration of a latent diffusion model to impose stronger constraints on the disentangled feature spaces. 3. New reconstruction formulations and algorithms that combine the learned representation with zero-shot self-supervised learning adaptation and subspace modeling."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f858a20b731ce7ed66cd4e854bc6e6bdd5ae01548b1060d4814f643684ce73a0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f858a20b731ce7ed66cd4e854bc6e6bdd5ae01548b1060d4814f643684ce73a0_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new method for reconstructing multidimensional MRI data by learning a disentangled image representation that separates features like geometry and contrast into distinct latent spaces, enhanced by a latent diffusion model. The approach integrates this representation with zero-shot self-supervised learning, enabling improved reconstruction without task-specific training. It demonstrates superior performance on accelerated T1 and T2 parameter mapping compared to state-of-the-art methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Limited data for task-specific training in multidimensional MRI reconstruction"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Disentangled representation + Latent diffusion model + Zero-shot self-supervised adaptation"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Improved performance on T1/T2 mapping without task-specific training"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [diffusion model, training-free acceleration, first-order sampler, forward-value discretization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuchen Jiao, Na Li, Changxiao Cai, Gen Li"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, Zhejiang University, University of Michigan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24927",children:"https://arxiv.org/pdf/2512.24927"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Challenges the prevailing belief that higher-order ODE solvers are inherently faster for DPM sampling, proposing that the placement of DPM evaluations is a crucial, independent design factor. 2. Introduces a novel, training-free first-order sampler that approximates the forward-value evaluation using a cheap one-step lookahead predictor, resulting in a leading discretization error with the opposite sign to DDIM. 3. Provides theoretical guarantees for the sampler's approximation of the ideal forward-value trajectory while maintaining first-order convergence, and demonstrates empirical competitiveness with higher-order samplers on standard benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef8de5dcbba9edb9daa0ab1ba8e254668331d9851247da681521a06ad8b83b22_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef8de5dcbba9edb9daa0ab1ba8e254668331d9851247da681521a06ad8b83b22_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper challenges the view that first-order diffusion samplers are inherently slower than higher-order ones. It proposes a new first-order sampler that uses a forward-value approach with a lookahead predictor to better place model evaluations. The method is theoretically sound and empirically matches or outperforms state-of-the-art higher-order samplers on image generation tasks under the same computational budget."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    A["Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach<br>\u8bba\u6587\u6807\u9898"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br>Higher-order solvers are standard; first-order methods are seen as slower.<br>\u9ad8\u9636\u6c42\u89e3\u5668\u662f\u6807\u51c6\uff1b\u4e00\u9636\u65b9\u6cd5\u88ab\u8ba4\u4e3a\u66f4\u6162\u3002"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br>Proposes a training-free first-order sampler using forward-value evaluation via a one-step lookahead predictor.<br>\u63d0\u51fa\u4e00\u79cd\u514d\u8bad\u7ec3\u7684\u4e00\u9636\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u4e00\u6b65\u524d\u77bb\u9884\u6d4b\u5668\u8fdb\u884c\u524d\u5411\u503c\u8bc4\u4f30\u3002"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br>Sampler improves quality under same NFE budget, competitive with higher-order methods.<br>\u91c7\u6837\u5668\u5728\u76f8\u540cNFE\u9884\u7b97\u4e0b\u63d0\u5347\u8d28\u91cf\uff0c\u4e0e\u9ad8\u9636\u65b9\u6cd5\u7ade\u4e89\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);