"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9887],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},77769:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_GR/20251229-20260104","title":"20251229-20260104 (cs.GR)","description":"2025-12-29","source":"@site/docs/daily/cs_GR/20251229-20260104.md","sourceDirName":"daily/cs_GR","slug":"/daily/csgr/20251229-20260104","permalink":"/ai_toutiao/daily/csgr/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{"slug":"/daily/csgr/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.GR)","permalink":"/ai_toutiao/daily/csgr/20251222-20251228"},"next":{"title":"20260105-20260111 (cs.GR)","permalink":"/ai_toutiao/daily/csgr/20260105-20260111"}}');var a=i(74848),r=i(28453);const t={slug:"/daily/csgr/20251229-20260104"},o="20251229-20260104 (cs.GR)",l={},d=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2},{value:"2026-01-01",id:"2026-01-01",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"20251229-20260104-csgr",children:"20251229-20260104 (cs.GR)"})}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [neural rendering], [Neural Radiance Fields, anisotropic specular reflections, Anisotropic Spherical Gaussian, von Mises-Fisher distribution, material editing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Albert Barreiro, Roger Mar\xed, Rafael Redondo, Gloria Haro, Carles Bosch"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Eurecat, Centre Tecnol\xf2gic de Catalunya; Universitat Pompeu Fabra; Universitat de Vic - UCC"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21692",children:"https://arxiv.org/pdf/2512.21692"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ShinyNeRF, a novel NeRF framework capable of modeling both isotropic and anisotropic specular reflections. 2. Proposes a method to jointly estimate physical surface properties (normals, tangents, specular concentration, anisotropy) by approximating outgoing radiance with a mixture of isotropic von Mises-Fisher distributions. 3. Achieves state-of-the-art performance in digitizing anisotropic materials and enables interpretable material property editing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad12a4dd31b4ec9b89dafef4a6d4d851fe0aa09b5e3d8c6f918d085ee2acda50_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad12a4dd31b4ec9b89dafef4a6d4d851fe0aa09b5e3d8c6f918d085ee2acda50_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ShinyNeRF, a novel Neural Radiance Fields framework designed to accurately model anisotropic specular reflections, such as those on brushed metals, which previous methods struggled with. The method learns an approximation of outgoing radiance using a mixture of isotropic von Mises-Fisher distributions to jointly estimate physical surface properties. Experimental results show it achieves state-of-the-art performance and enables plausible material editing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u5404\u5411\u5f02\u6027\u9ad8\u5149/Existing methods struggle with anisotropic specular reflections]\n    C --\x3e C1[\u63d0\u51faShinyNeRF\u6846\u67b6/Propose ShinyNeRF framework]\n    C1 --\x3e C2[\u4f7f\u7528\u5404\u5411\u540c\u6027vMF\u6df7\u5408\u8fd1\u4f3c\u51fa\u5c04\u8f90\u5c04\u5ea6/Use isotropic vMF mixture to approximate outgoing radiance]\n    C2 --\x3e C3[\u8054\u5408\u4f30\u8ba1\u6cd5\u7ebf\u3001\u5207\u7ebf\u3001\u9ad8\u5149\u53c2\u6570/Jointly estimate normals, tangents, specular parameters]\n    D --\x3e D1[\u5b9e\u73b0SOTA\u6027\u80fd/Achieves SOTA performance]\n    D --\x3e D2[\u63d0\u4f9b\u7269\u7406\u89e3\u91ca\u548c\u6750\u8d28\u7f16\u8f91/Provides physical interpretation and material editing]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Graph Drawing Stress Model with Resistance Distances"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [graph drawing], [resistance distance, stress model, graph Laplacian, stochastic gradient descent, spectral embedding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yosuke Onoue"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nihon University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21901",children:"https://arxiv.org/pdf/2512.21901"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new stress-based graph drawing paradigm using resistance distance instead of graph-theoretic shortest distance, which better captures global graph structure and admits an isometric embedding in Euclidean space. 2. Introduces Omega, a linear-time graph drawing algorithm that combines fast resistance distance embedding with random node-pair sampling for SGD, achieving more effective and robust optimization than pivot-based methods. 3. Establishes a practical and scalable connection between spectral graph theory and stress-based layouts, demonstrating improved neighborhood preservation and cluster faithfulness in visualizations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90743acf53987a8cc4eeb2edd80f71bfd5deac0b98227953e258bc7a00aa5f41_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90743acf53987a8cc4eeb2edd80f71bfd5deac0b98227953e258bc7a00aa5f41_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper challenges the conventional use of shortest-path distances in stress-based graph drawing by proposing resistance distance as a superior alternative derived from the graph Laplacian. It introduces the Omega algorithm, which efficiently computes resistance distance embeddings and uses random sampling for SGD to produce more readable layouts with lower stress. The method effectively reveals global graph structures like clusters and maintains linear-time complexity for large networks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Graph Drawing Stress Model with Resistance Distances] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[\u4f20\u7edf\u5e94\u529b\u6a21\u578b\u4f7f\u7528\u6700\u77ed\u8def\u5f84\u8ddd\u79bb\uff0c\u5b58\u5728\u7406\u8bba\u548c\u8ba1\u7b97\u9650\u5236/Traditional stress models use shortest-path distances with theoretical and computational limitations]\nC --\x3e C1[\u63d0\u51fa\u57fa\u4e8e\u7535\u963b\u8ddd\u79bb\u7684\u65b0\u8303\u5f0f\uff0c\u6e90\u81ea\u62c9\u666e\u62c9\u65af\u8c31/Propose new paradigm based on resistance distance from graph Laplacian spectrum]\nC --\x3e C2[\u5f15\u5165Omega\u7b97\u6cd5\uff1a\u5feb\u901f\u7535\u963b\u8ddd\u79bb\u5d4c\u5165\u4e0e\u968f\u673a\u8282\u70b9\u5bf9\u91c7\u6837/Introduce Omega algorithm: fast resistance distance embedding with random node-pair sampling]\nD --\x3e D1[\u6539\u8fdb\u90bb\u57df\u4fdd\u6301\u548c\u805a\u7c7b\u5fe0\u5b9e\u6027/Improved neighborhood preservation and cluster faithfulness]\nD --\x3e D2[\u66f4\u4f4e\u3001\u66f4\u7a33\u5b9a\u7684\u5e94\u529b\u503c\uff0c\u7ebf\u6027\u590d\u6742\u5ea6/Lower and more stable stress values, linear-time complexity]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [computer-aided manufacturing (CAM)], [spiral toolpath planning, scalar field optimization, topology-preserving deformation, conformal slit mapping, boundary-conforming]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shen Changqing, Xu Bingzhou, Qi Bosong, Zhang Xiaojian, Yan Sijie, Ding Han"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huazhong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22502",children:"https://arxiv.org/pdf/2512.22502"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a strategy to enforce boundary conformity and eliminate zero-gradient singularities in scalar-field-based toolpath optimization for multiply connected surfaces. 2. Reformulates the optimization as a topology-preserving mesh deformation with boundary-synchronous updates to achieve globally optimized spacing and smooth transitions. 3. Demonstrates significant improvements in machining efficiency, scallop-height uniformity, and vibration reduction compared to a state-of-the-art method."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8db268a37d6b76e48aa2571b6519b562d7e55bfc3d4e8f7c07120bc4dbfc1315_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8db268a37d6b76e48aa2571b6519b562d7e55bfc3d4e8f7c07120bc4dbfc1315_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating continuous, boundary-conforming spiral toolpaths for ball-end milling on complex freeform surfaces. The proposed method uses conformal slit mapping to create an initial singularity-free scalar field and then optimizes it via a topology-preserving mesh deformation process. Experimental results show the approach increases machining efficiency by over 14%, improves surface finish uniformity, and reduces vibrations compared to existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6311\u6218: \u4fdd\u6301\u8fb9\u754c\u4e00\u81f4\u6027\u5e76\u6d88\u9664\u5947\u70b9/Challenge: Maintain boundary conformity & eliminate singularities]\n    C --\x3e C1[\u4f7f\u7528\u5171\u5f62\u72ed\u7f1d\u6620\u5c04\u521d\u59cb\u5316/Use conformal slit mapping for initialization]\n    C --\x3e C2[\u62d3\u6251\u4fdd\u6301\u7f51\u683c\u53d8\u5f62\u4f18\u5316/Topology-preserving mesh deformation optimization]\n    D --\x3e D1[\u6548\u7387\u63d0\u5347 14.24%/Efficiency improved by 14.24%]\n    D --\x3e D2[\u5747\u5300\u6027\u63d0\u5347 5.70%/Uniformity improved by 5.70%]\n    D --\x3e D3[\u632f\u52a8\u51cf\u5c11 >10%/Vibration reduced by >10%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video generation], [Human-Object Interaction, Diffusion Transformer, Relative Coordinate Maps, Progressive Curriculum Learning, Geometry Consistency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bangya Liu, Xinyu Gong, Zelin Zhao, Ziyang Song, Yulei Lu, Suhui Wu, Jun Zhang, Suman Banerjee, Hao Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Wisconsin-Madison, ByteDance, Georgia Institute of Technology, The Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22854",children:"https://arxiv.org/pdf/2512.22854"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://neutrinoliu.github.io/byteloom/",children:"https://neutrinoliu.github.io/byteloom/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ByteLoom, a Diffusion Transformer-based framework for generating realistic HOI videos with geometrically consistent objects. 2. Introduces the RCM-cache mechanism using Relative Coordinate Maps to maintain object geometry consistency and control 6-DoF transformations. 3. Designs a progressive training curriculum to compensate for HOI dataset scarcity and relax the need for fine-grained hand mesh annotations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9f5ff16308904b889be6695aafd24bfc28b798f080cc6c723a25066bcdc2bdf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9f5ff16308904b889be6695aafd24bfc28b798f080cc6c723a25066bcdc2bdf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of poor cross-view consistency and reliance on hand mesh annotations in Human-Object Interaction (HOI) video generation. It proposes ByteLoom, a framework that uses a novel RCM-cache mechanism for geometry consistency and a progressive curriculum learning strategy for training. The method effectively preserves human identity and object geometry while generating smooth motion."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u591a\u89c6\u56fe\u4fe1\u606f\u6ce8\u5165\u673a\u5236/Existing methods lack multi-view injection]\n    B --\x3e B2[\u4e25\u91cd\u4f9d\u8d56\u624b\u90e8\u7f51\u683c\u6807\u6ce8/Heavy reliance on hand mesh annotations]\n    C --\x3e C1[\u63d0\u51faRCM-cache\u673a\u5236/Propose RCM-cache mechanism]\n    C --\x3e C2[\u8bbe\u8ba1\u6e10\u8fdb\u5f0f\u8bfe\u7a0b\u5b66\u4e60/Design progressive curriculum learning]\n    D --\x3e D1[\u4fdd\u6301\u7269\u4f53\u51e0\u4f55\u4e00\u81f4\u6027/Preserves object geometry consistency]\n    D --\x3e D2[\u751f\u6210\u5e73\u6ed1\u8fd0\u52a8\u89c6\u9891/Generates smooth motion videos]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tencent Hunyuan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23464",children:"https://arxiv.org/pdf/2512.23464"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0",children:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Generating high-quality, text-aligned 3D human motions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: SOTA performance, Extensive motion coverage, Open-source release"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] OpenPBR: Novel Features and Implementation Details"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [computer graphics rendering], [physically based rendering, uber-shader, microfacet theory, subsurface scattering, thin-film interference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jamie Portsmouth, Peter Kutz, Stephen Hill"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Autodesk, Adobe, Lucasfilm"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23696",children:"https://arxiv.org/pdf/2512.23696"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes OpenPBR, a standardized, physically based uber-shader for interoperable material authoring across VFX, animation, and design visualization workflows. 2. Details novel model features including slab-based layering, statistical mixing, and specific physical components like metallic/dielectric substrates, subsurface scattering, and thin-film iridescence layers. 3. Provides in-depth implementation guidance and mathematical derivations for technical topics such as decoupling specular reflectivity from transmission and coat darkening physics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34de1d742b1a9090342372c28b227530e6e3c7bfbebef32f3a6f3cfd4dd32542_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34de1d742b1a9090342372c28b227530e6e3c7bfbebef32f3a6f3cfd4dd32542_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces OpenPBR, a standardized physically based rendering shader designed for material interoperability across different rendering systems. It details the model's theoretical foundations, layered components, and provides implementation guidance. The work serves as a companion to the official specification, aiming to standardize and improve material workflows in graphics production."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("OpenPBR: Novel Features and Implementation Details") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Need for interoperable, physically based material authoring across VFX/animation workflows")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Standardized uber-shader with slab-based layering, microfacet theory, and multi-layer substrates (metallic, dielectric, subsurface, coat, fuzz, thin-film)")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Detailed model specification, implementation guidance, and demonstration of interoperability across renderers")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Domain matters: Towards domain-informed evaluation for link prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph machine learning], [link prediction, algorithm evaluation, domain adaptation, complex networks, graph neural networks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yilin Bi, Junhao Bian, Shuyan Wan, Shuaijia Wang, Tao Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Electronic Science and Technology of China"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23371",children:"https://arxiv.org/pdf/2512.23371"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a large-scale, systematic evaluation of 12 link prediction algorithms across 740 networks from 7 domains, revealing low consistency in algorithm rankings across domains. 2. Proposed the Winner Score metric to identify domain-specific top-performing algorithms (e.g., NMF for social networks, NeoGNN for economics). 3. Introduced the Ranking Stability Coefficient (RSC) to quantify the number of networks needed for stable evaluation, showing significant variation across domains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/052f77d6e344a45d0c05f39094686bed2c2049bf461f2d4ea65caf1fbb66f68e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/052f77d6e344a45d0c05f39094686bed2c2049bf461f2d4ea65caf1fbb66f68e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper systematically evaluates link prediction algorithms across diverse network domains, finding that algorithm performance rankings are highly domain-specific rather than universal. It proposes metrics to identify the best algorithm for each domain and to determine the number of networks needed for stable evaluation, emphasizing the importance of aligning algorithmic mechanisms with network structure."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\nA["Domain matters: Towards domain-informed evaluation for link prediction<br>\u9886\u57df\u91cd\u8981\uff1a\u9762\u5411\u9886\u57df\u611f\u77e5\u7684\u94fe\u63a5\u9884\u6d4b\u8bc4\u4f30"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br>Existing evaluations assume consistent algorithm performance across domains.<br>\u73b0\u6709\u8bc4\u4f30\u5047\u8bbe\u7b97\u6cd5\u6027\u80fd\u5728\u4e0d\u540c\u9886\u57df\u4e00\u81f4\u3002"]\nA --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br>Large-scale evaluation of 12 algorithms on 740 networks across 7 domains.<br>\u57287\u4e2a\u9886\u57df\u7684740\u4e2a\u7f51\u7edc\u4e0a\u5bf912\u79cd\u7b97\u6cd5\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u4f30\u3002"]\nA --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br>Algorithm rankings are domain-specific; Proposed Winner Score & RSC metrics.<br>\u7b97\u6cd5\u6392\u540d\u662f\u9886\u57df\u7279\u5b9a\u7684\uff1b\u63d0\u51fa\u4e86Winner Score\u548cRSC\u6307\u6807\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2026-01-01",children:"2026-01-01"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PartMotionEdit: Fine-Grained Text-Driven 3D Human Motion Editing via Part-Level Modulation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [human motion generation and editing], [part-level modulation, bidirectional cross-modal attention, diffusion models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yujie Yang, Zhichao Zhang, Jiazhou Chen, Zichao Wu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University of Technology, Hangzhou Dianzi University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24200",children:"https://arxiv.org/pdf/2512.24200"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Part-aware Motion Modulation (PMM) module for fine-grained, part-specific motion editing via time-varying part weights. 2. Introduces a part-level similarity curve supervision mechanism with dual-layer normalization to guide PMM training. 3. Designs a Bidirectional Motion Interaction (BMI) module using bidirectional cross-modal attention for better text-motion semantic alignment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a35321bae3cf5142e02d89f04a13673ff8306173f82f32bd722d0923dbbcd1f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a35321bae3cf5142e02d89f04a13673ff8306173f82f32bd722d0923dbbcd1f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes PartMotionEdit, a framework for fine-grained text-driven 3D human motion editing. It introduces a part-level modulation module and a bidirectional interaction module to achieve precise, local motion control based on textual instructions, and demonstrates superior performance over existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["PartMotionEdit: Fine-Grained Text-Driven 3D Human Motion Editing"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Existing methods lack precise, part-specific motion control due to global modeling."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Proposes Part-aware Motion Modulation (PMM) and Bidirectional Motion Interaction (BMI) modules."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Outperforms state-of-the-art methods in quantitative and qualitative evaluations."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] BATISNet: Instance Segmentation of Tooth Point Clouds with Boundary Awareness"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [instance segmentation], [point cloud segmentation, boundary-aware loss, dental point clouds]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yating Cai, Yanghui Xu, Zehua Hu, Jiazhou Chen, Jing Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University of Technology, Zhejiang Gongshang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24201",children:"https://arxiv.org/pdf/2512.24201"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes BATISNet, a boundary-aware instance segmentation network for tooth point clouds that learns both semantic and instance features. 2. Designs a boundary-aware loss function to specifically supervise and improve the segmentation accuracy at tooth boundaries. 3. Demonstrates robust performance in complex clinical scenarios (e.g., missing teeth, malposed teeth) where existing semantic segmentation methods struggle."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/700103c92b00e30f54ce87dbe0220c75481c776fda9612b68afbf5ccb0030515_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/700103c92b00e30f54ce87dbe0220c75481c776fda9612b68afbf5ccb0030515_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes BATISNet, a boundary-aware instance segmentation network for tooth point clouds, to address the challenges of tightly packed teeth and unclear boundaries in complex dental cases. The method combines semantic and instance feature learning with a specialized boundary-aware loss to mitigate adhesion and ambiguity. Experimental results show it outperforms existing methods, providing more reliable data for clinical applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[BATISNet: Instance Segmentation of Tooth Point Clouds with Boundary Awareness] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Semantic segmentation struggles with tightly packed teeth, unclear boundaries, and complex cases like missing/malposed teeth.] --\x3e Problem_Detail[\u95ee\u9898\u7ec6\u8282/Problem Details: Tooth adhesion and boundary ambiguity]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: BATISNet, a boundary-aware instance network] --\x3e Method_Component1[\u7f51\u7edc\u7ec4\u4ef6/Network Components: Feature extraction backbone and instance segmentation module]\n    Method --\x3e Method_Component2[\u635f\u5931\u51fd\u6570/Loss Function: Boundary-aware loss for supervising instance boundaries]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Outperforms existing methods in tooth integrity segmentation, robust in complex clinical scenarios.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] The Uncanny Valley in medical simulation-based training: a visual summary"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [virtual reality], [Uncanny Valley, virtual reality, medical simulation, photorealism, anthropomorphism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Eleni Grigoriou, Manos Kamarianakis, George Papagiannakis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Crete, FORTH - Institute of Computer Science (ICS), ORamaVR"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24240",children:"https://arxiv.org/pdf/2512.24240"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a comprehensive, evidence-based visual guide on the impact of the Uncanny Valley in medical VR training. 2. Synthesizes multidisciplinary perspectives from computer graphics, VR, and medical education to analyze the phenomenon. 3. Reviews and illustrates the state of photorealism and physically based rendering in the context of interactive VR for training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0529156f8e982b0e22d29913cff03007a4f314a7a2cb96b137a263c9f28feae2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0529156f8e982b0e22d29913cff03007a4f314a7a2cb96b137a263c9f28feae2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This review article analyzes the "Uncanny Valley" phenomenon and its critical influence on medical virtual reality simulation-based training. It synthesizes evidence and provides a visual guide from a multidisciplinary perspective, concluding that understanding and addressing this discomfort is crucial for effective, immersive medical training where realism is key.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["The Uncanny Valley in medical simulation-based training: a visual summary<br/>\u533b\u7597\u6a21\u62df\u8bad\u7ec3\u4e2d\u7684\u6050\u6016\u8c37\uff1a\u89c6\u89c9\u603b\u7ed3"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Uncanny Valley causes discomfort in medical VR training<br/>\u6050\u6016\u8c37\u5728\u533b\u7597VR\u8bad\u7ec3\u4e2d\u5f15\u53d1\u4e0d\u9002"] --\x3e P1["\u5f71\u54cd/Impact<br/>Affects realism and immersion for learning<br/>\u5f71\u54cd\u5b66\u4e60\u6240\u9700\u7684\u771f\u5b9e\u611f\u4e0e\u6c89\u6d78\u611f"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Multidisciplinary review & visual guide<br/>\u591a\u5b66\u79d1\u7efc\u8ff0\u4e0e\u89c6\u89c9\u6307\u5357"] --\x3e M1["\u89c6\u89d2/Perspective<br/>Computer graphics, VR, medical education<br/>\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u3001VR\u3001\u533b\u5b66\u6559\u80b2"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Understanding UV is crucial for effective training<br/>\u7406\u89e3\u6050\u6016\u8c37\u5bf9\u6709\u6548\u8bad\u7ec3\u81f3\u5173\u91cd\u8981"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image denoising], [Noise2Noise, Monte Carlo denoising, high dynamic range, tone mapping, Jensen gap]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Andrew Tinits, Stephen Mann"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Waterloo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24794",children:"https://arxiv.org/pdf/2512.24794"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identified that certain nonlinear functions can be applied to noisy targets in Noise2Noise training without introducing significant bias. 2. Developed a theoretical framework to analyze the effects of nonlinearities and described a class of functions with minimal bias. 3. Demonstrated the method's effectiveness for training Monte Carlo denoisers on HDR images using only noisy data, achieving results comparable to models trained with clean references."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7ef23248abb9edf960ef0ea8dac0c52ee12d9db03ab8dd602dfd8c83c62645_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7ef23248abb9edf960ef0ea8dac0c52ee12d9db03ab8dd602dfd8c83c62645_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of Noise2Noise training where applying nonlinear functions to noisy targets introduces bias. The authors propose a theoretical framework to identify low-bias nonlinearities and apply this to denoise high dynamic range Monte Carlo renderings using tone mapping. Their method, trained only on noisy data, achieves performance close to models trained with clean reference images."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("Noise2Noise\u8bad\u7ec3\u4e2d\u975e\u7ebf\u6027\u51fd\u6570\u5bfc\u81f4\u504f\u5dee/Bias from nonlinearities in Noise2Noise")\n    Problem --\x3e P2("HDR\u56fe\u50cf\u8bad\u7ec3\u88ab\u5f02\u5e38\u503c\u5e72\u6270/HDR training overwhelmed by outliers")\n    Method --\x3e M1("\u7406\u8bba\u5206\u6790\u975e\u7ebf\u6027\u5f71\u54cd/Theoretical analysis of nonlinear effects")\n    Method --\x3e M2("\u8bc6\u522b\u4f4e\u504f\u5dee\u975e\u7ebf\u6027\u51fd\u6570\u7c7b/Identify low-bias nonlinear function class")\n    Method --\x3e M3("\u7279\u5b9a\u635f\u5931\u4e0e\u8272\u8c03\u6620\u5c04\u7ec4\u5408/Specific loss & tone mapping combination")\n    Results --\x3e R1("\u4ec5\u7528\u566a\u58f0\u6570\u636e\u8bad\u7ec3/Train with only noisy data")\n    Results --\x3e R2("\u6027\u80fd\u63a5\u8fd1\u5e72\u51c0\u6570\u636e\u8bad\u7ec3\u6a21\u578b/Performance approaches clean-data-trained model")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D scene understanding and animation], [3D Gaussian Splatting, physics simulation, large language model, real-time animation, open-vocabulary]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Luca Collorone, Mert Kiray, Indro Spinelli, Fabio Galasso, Benjamin Busam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sapienza University of Rome, Technical University of Munich, Munich Center for Machine Learning (MCML)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24986",children:"https://arxiv.org/pdf/2512.24986"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the first framework to directly couple 3D Gaussian Splatting with a physics simulator, bypassing slow mesh extraction. 2. Enables open-vocabulary, real-time, and interactive 4D animation through an LLM that generates executable code to modify scene parameters. 3. Presents a train-free and computationally lightweight pipeline, shifting animation workflows from offline rendering to interactive dialogue."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1113cf9009e210565f13d799d298867f98470a28066f31b961bce3b6577044fe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1113cf9009e210565f13d799d298867f98470a28066f31b961bce3b6577044fe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents PhysTalk, a system that generates real-time, physics-based 4D animations from text prompts and 3D Gaussian Splatting scenes. It uses a large language model to produce code that manipulates scene proxies for physics simulation, enabling interactive and realistic motion without requiring model training. This approach makes physically realistic animation more accessible and interactive."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7269\u7406\u771f\u5b9e\u6027\u548c\u5b9e\u65f6\u4ea4\u4e92\u6027/Current methods lack physical realism and real-time interaction]\n    C --\x3e C1[\u4f7f\u7528LLM\u5c06\u6587\u672c\u63d0\u793a\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801/Uses LLM to translate prompts into executable code]\n    C --\x3e C2[\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4ee3\u7406\u76f4\u63a5\u4fee\u65393DGS\u53c2\u6570/Modifies 3DGS parameters via lightweight proxies]\n    C --\x3e C3[\u96c6\u6210\u7269\u7406\u6a21\u62df\u5668\u8fdb\u884c\u78b0\u649e\u611f\u77e5\u52a8\u753b/Integrates physics simulator for collision-aware animation]\n    D --\x3e D1[\u5b9e\u73b0\u5b9e\u65f6\u3001\u5f00\u96c6\u8bcd\u6c47\u76844D\u52a8\u753b/Achieves real-time, open-vocabulary 4D animation]\n    D --\x3e D2[\u65e0\u9700\u8bad\u7ec3\uff0c\u8ba1\u7b97\u8f7b\u91cf/Train-free and computationally lightweight]\n    D --\x3e D3[\u5c06\u5de5\u4f5c\u6d41\u8f6c\u5411\u4ea4\u4e92\u5f0f\u5bf9\u8bdd/Shifts workflow to interactive dialogue]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Variational Quantum Brushes"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [quantum computing for art], [variational quantum algorithms, quantum geometric control, variational eigensolver, computational art, quantum brushes]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jui-Ting Lu, Henrique Ennes, Chih-Kang Huang, Ali Abbassi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universit\xe9 de Lorraine, CNRS, Inria, Universit\xe9 de Technologie de Troyes, Orange Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24173",children:"https://arxiv.org/pdf/2512.24173"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/moth-quantum/QuantumBrush",children:"https://github.com/moth-quantum/QuantumBrush"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces a mathematical framework for quantum brushes based on variational quantum algorithms. 2. Implements the "Steerable" brush, which uses quantum geometric control theory to merge two images. 3. Implements the "Chemical" brush, which mimics variational eigensolvers to evolve colors on a canvas.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8a1ae2b1cfdee3a098d127a86fa773993bb3eab697781cc52c1e25f3f449b7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8a1ae2b1cfdee3a098d127a86fa773993bb3eab697781cc52c1e25f3f449b7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper introduces two new quantum brushes for computational art, built on variational quantum algorithms. The "Steerable" brush merges artworks using quantum geometric control, while the "Chemical" brush evolves colors by mimicking molecular energy estimation. The implementations are open-source and compatible with existing quantum brush software.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Variational Quantum Brushes] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Leveraging quantum behavior for novel artistic effects]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Two variational quantum algorithm-based brushes: Steerable and Chemical]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Open-source implementation, compatible with original quantum brushes]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}}}]);