"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4805],{4943:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/cs_HC/20251215-20251221","title":"20251215-20251221 (cs.HC)","description":"2025-12-18","source":"@site/docs/daily/cs_HC/20251215-20251221.md","sourceDirName":"daily/cs_HC","slug":"/daily/cs_HC/20251215-20251221","permalink":"/ai_toutiao/daily/cs_HC/20251215-20251221","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1766462881000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"cs.HC","permalink":"/ai_toutiao/category/cshc"},"next":{"title":"20251222-20251228 (cs.HC)","permalink":"/ai_toutiao/daily/cshc/20251222-20251228"}}');var s=i(4848),t=i(8453);const a={},o="20251215-20251221 (cs.HC)",l={},c=[{value:"2025-12-18",id:"2025-12-18",level:2},{value:"2025-12-19",id:"2025-12-19",level:2}];function h(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"20251215-20251221-cshc",children:"20251215-20251221 (cs.HC)"})}),"\n",(0,s.jsx)(n.h2,{id:"2025-12-18",children:"2025-12-18"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'[arXiv251218] I am here for you": How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [ai], [human-computer interaction], [conversational AI, relational style, transparent style, anthropomorphism, emotional reliance, online experiment, adolescent psychology]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Pilyoung Kim, Yun Xie, Sujin Yang"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Denver, Ewha Womans University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15117",children:"https://arxiv.org/pdf/2512.15117"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper uses a preregistered online experiment with adolescent-parent dyads to compare how relational versus transparent conversational styles in AI chatbots affect adolescents' perceptions. It finds that a relational style increases anthropomorphism, trust, and emotional closeness, and is especially preferred by socially and emotionally vulnerable adolescents, highlighting a design consideration for youth AI safety."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251218] Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Quantum-Inspired Rogue Variable Modeling (QRVM), Human-in-the-Loop Decoherence, Collective Cognitive Inference, proof of concept, VUCA]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Agnieszka Bienkowska, Jacek Malecki, Alexander Mathiesen-Ohman, Katarzyna Tworek"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided text"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15325",children:"https://arxiv.org/pdf/2512.15325"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper presents a proof of concept for the LAIZA human-AI symbiotic system, which uses a quantum-inspired cognitive mechanism to detect "rogue variables" and manage ambiguity by preserving interpretive plurality and activating structured human clarification. The main conclusion is that this approach enables proactive scenario-based preparation and decisive action in VUCA environments, reframing ambiguity as a key construct for organizational resilience.']}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251218] Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [crowdsourcing, user study, extended reality, conversational agents, privacy, technology acceptance model]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Efe Bozkir, Enkelejda Kasneci"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Technical University of Munich"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15343",children:"https://arxiv.org/pdf/2512.15343"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper conducted a large-scale crowdsourcing study with 1036 participants to explore user acceptance and concerns regarding LLM-powered conversational agents in Extended Reality (XR). The study found that while users generally accept these technologies, they express significant concerns about security, privacy, social implications, and trust, with location data being the most sensitive. The results highlight the importance of practitioner transparency and that familiarity with generative AI increases acceptance, while prior XR device ownership is linked to lower acceptance."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251218] Intent-Driven UAM Rescheduling"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [ai], [scheduling optimization], [Mixed Integer Linear Programming (MILP), Answer Set Programming (ASP), three-valued logic, decision tree, Resource-Constrained Project Scheduling Problem (RCPSP)]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Jeongseok Kim, Kangjin Kim"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Cleverplant, Chodang University"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15462",children:"https://arxiv.org/pdf/2512.15462"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an intent-driven rescheduling system for Urban Air Mobility (UAM) that combines Answer Set Programming (ASP) with Mixed Integer Linear Programming (MILP) to handle ambiguous human requests. It uses a three-valued logic and a decision tree to interpret vague user intents for transparent schedule adjustments. The main conclusion is that this integrated framework provides a robust, explainable, and adaptive structure for UAM scheduling."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2025-12-19",children:"2025-12-19"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Finite Exponential Continuous State Machine (FECSM), Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA), Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU), HDBSCAN, min-max normalization, User Interface Change Prediction Index (UICPI)]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Shrinivass Arunachalam Balasubramanian"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15775",children:"https://arxiv.org/pdf/2512.15775"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a dynamic web UI optimization method that uses a Finite Exponential Continuous State Machine for cross-device responsiveness assessment and a novel Quokka Nonlinear Difference Swarm Optimization Algorithm for design optimization. The core technique involves classifying user experience changes with a Bidirectional Gated Luong and Mish Recurrent Unit model. The main conclusion is that this integrated approach achieves an average fitness of 98.5632% for optimal UI design by incorporating cross-responsiveness assessment and user behavior patterns."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [multi-agent framework, large language model, qualitative thematic analysis, Collaborative Theme Identification Agent (CoTI)]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Qidi Xu, Nuzha Amjad, Grace Giles, Alexa Cumming, De'angelo Hermesky, Alexander Wen, Min Ji Kwak, Yejin Kim"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," UTHealth Houston, University of Texas Health Sciences Center Houston"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16063",children:"https://arxiv.org/pdf/2512.16063"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces CoTI, a multi-agent LLM framework with three specialized agents to automate qualitative thematic analysis of patient interviews. The framework was applied to heart failure patient data and produced results more aligned with a senior investigator's analysis than with junior investigators or baseline NLP models. However, collaboration between the AI and junior investigators showed limited gains, suggesting a risk of over-reliance that may hinder independent critical thinking."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [schema filtering, functional dependency graph, graph transformer, Steiner-tree heuristic, query-aware LLM encoder]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Thanh Dat Hoang, Thanh Tam Nguyen, Thanh Trung Huynh, Hongzhi Yin, Quoc Viet Hung Nguyen"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Griffith University, VinUniversity, The University of Queensland"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16083",children:"https://arxiv.org/pdf/2512.16083"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces GRAST-SQL, a framework for scaling Text2SQL systems by efficiently filtering and compacting database schemas before prompting an LLM. It uses a query-aware LLM encoder, a graph transformer over functional dependencies, and a Steiner-tree heuristic to select a relevant, connectivity-preserving sub-schema. The method achieves high recall and precision while maintaining low latency and scaling to schemas with over 23,000 columns."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] Evaluation of Generative Models for Emotional 3D Animation Generation in VR"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [generative models, speech-driven 3D animation, virtual reality (VR), user study, emotional arousal, reconstruction-based method, UV mapping, OpenXR, Blender]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Kiran Chhatre, Renan Guarese, Andrii Matviienko, Christopher Peters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," KTH Royal Institute of Technology"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16081",children:"https://arxiv.org/pdf/2512.16081"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates generative models for creating emotional 3D animations synchronized with speech in a VR environment using a user study. The main conclusion is that models explicitly modeling emotions achieve higher recognition accuracy than those focusing only on speech synchrony, but current models struggle with subtle emotions and underperform compared to reconstruction-based methods in facial expression quality."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] ParamExplorer: A framework for exploring parameters in generative art"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [ai], [generative art], [reinforcement learning, parameter exploration, human-in-the-loop, p5.js]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Julien Gachadoat, Guillaume Lagarde"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Bordeaux"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16529",children:"https://arxiv.org/pdf/2512.16529"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ParamExplorer, an interactive and modular framework inspired by reinforcement learning to help explore the high-dimensional parameter spaces of generative art algorithms. It allows for exploration guided by human feedback and integrates with existing p5.js projects. The framework implements and evaluates several automated exploration strategies, referred to as agents, to discover aesthetically compelling outputs more efficiently than manual trial-and-error."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] OMG-Bench: A New Challenging Benchmark for Skeleton-based Online Micro Hand Gesture Recognition"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [ai], [computer vision], [transformer, memory banks, self-supervised learning, multi-view hand pose estimation, online gesture recognition]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Haochen Chang, Pengfei Ren, Buyuan Zhang, Da Li, Tianhao Han, Haoyang Zhang, Liang Xie, Hongbo Chen, Erwei Yin"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Sun Yat-sen University, Beijing University of Posts and Telecommunications, Shanghai Jiao Tong University, Nankai University, Academy of Military Sciences, Tianjin Artificial Intelligence Innovation Center"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16727",children:"https://arxiv.org/pdf/2512.16727"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces OMG-Bench, a large-scale benchmark for skeleton-based online micro hand gesture recognition, and proposes HMATr, a hierarchical memory-augmented transformer framework that unifies gesture detection and classification. HMATr leverages memory banks to preserve historical context and uses learnable queries to encode gesture positions, outperforming state-of-the-art methods by 7.6% in detection rate."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [ai], [human-ai interaction], [human evaluation, epistemic failure, plausibility, hermeneutic error, co-construction, verification burden, cognitive drift]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Claudia Vale Oliveira, Nelson Zagalo, Filipe Silva, Anabela Brandao, Syeda Faryal Hussain Khurrum, Joaquim Santos"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Aveiro"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16750",children:"https://arxiv.org/pdf/2512.16750"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper uses a multi-round, multi-LLM evaluation with interdisciplinary tasks to study how humans interpret model responses. It concludes that LLM errors are co-constructed through model-generated plausibility and human interpretive shortcuts, shifting error analysis from predictive metrics to a relational, hermeneutic process."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [explainable AI, differential privacy, membership inference attack, re-identification attack, post-hoc explanations, feature selection, transformer models]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Missouri-Columbia"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16851",children:"https://arxiv.org/pdf/2512.16851"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a framework that uses explainable AI (XAI) to identify the most influential features in AI-XR models and selectively applies differential privacy (DP) to those features during inference to defend against privacy attacks. This XAI-guided DP approach reduces the success rates of membership inference and re-identification attacks while preserving model accuracy and improving inference time compared to traditional DP. The method is deployed as a system called PrivateXR on an HTC VIVE Pro headset, allowing users to adjust privacy levels in real-time during XR gameplay."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251219] TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [transformer encoder, self-supervised learning, foundation model, edge deployment, ultra-low-power microcontroller, gesture classification, kinematic regression]"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Matteo Fasulo, Giusy Spacone, Thorir Mar Ingolfsson, Yawei Li, Luca Benini, Andrea Cossettini"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," ETH Zurich, University of Bologna"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15729",children:"https://arxiv.org/pdf/2512.15729"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces TinyMyo, a lightweight Transformer-based foundation model pre-trained with self-supervised learning for EMG signal processing. It demonstrates strong generalization across multiple tasks like gesture classification and speech recognition while being deployable on an ultra-low-power microcontroller. The work provides an open-source, efficient model for edge-based EMG applications."]}),"\n"]}),"\n"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var r=i(6540);const s={},t=r.createContext(s);function a(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);