"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2801],{14199:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_AI/20251229-20260104","title":"20251229-20260104 (cs.AI)","description":"2025-12-29","source":"@site/docs/daily/cs_AI/20251229-20260104.md","sourceDirName":"daily/cs_AI","slug":"/daily/csai/20251229-20260104","permalink":"/ai_toutiao/daily/csai/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767243055000,"frontMatter":{"slug":"/daily/csai/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.AI)","permalink":"/ai_toutiao/daily/csai/20251222-20251228"},"next":{"title":"cs.AR","permalink":"/ai_toutiao/category/csar"}}');var a=i(74848),r=i(28453);const t={slug:"/daily/csai/20251229-20260104"},o="20251229-20260104 (cs.AI)",l={},d=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2},{value:"2026-01-01",id:"2026-01-01",level:2}];function c(e){const n={a:"a",annotation:"annotation",h1:"h1",h2:"h2",header:"header",li:"li",math:"math",mermaid:"mermaid",mi:"mi",mo:"mo",mover:"mover",mrow:"mrow",msqrt:"msqrt",p:"p",path:"path",semantics:"semantics",span:"span",strong:"strong",svg:"svg",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"20251229-20260104-csai",children:"20251229-20260104 (cs.AI)"})}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Santhosh Kumar Ravindran"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Microsoft Corporation"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21351",children:"https://arxiv.org/pdf/2512.21351"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u4ee3\u7801\u751f\u6210\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u96be\u4ee5\u5e94\u5bf9API\u53d8\u5316/LLM code generation lacks adaptability to API changes]\n    C --\x3e C1[\u5c06RL\u8f68\u8ff9\u89c6\u4e3a\u57fa\u56e0\u7ec4\u8fdb\u884c\u8fdb\u5316\u64cd\u4f5c/Treat RL trajectories as genomes for evolutionary operations]\n    C --\x3e C2[\u5728\u591c\u95f4\u56de\u653e\u9636\u6bb5\u8fdb\u884c\u7a81\u53d8\u4e0e\u9009\u62e9/Mutation and selection during nocturnal replay]\n    D --\x3e D1[\u89e3\u51b3\u65b9\u6848\u65b0\u9896\u6027\u63d0\u534735%/35% higher novelty in solutions]\n    D --\x3e D2[\u9002\u5e94\u901f\u5ea6\u52a0\u5feb25%/25% faster adaptation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] EcoNet: Multiagent Planning and Control Of Household Energy Resources Using Active Inference"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [active inference, multi-agent systems, home energy management systems (HEMS), distributed energy resources (DER), Bayesian inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," John C. Boik, Kobus Esterhuysen, Jacqueline B. Hynes, Axel Constant, Ines Hipolito, Mahault Albarracin, Alex B. Kiefer, Karl Friston"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," VERSES, University of Sussex, Macquarie University, UCL (University College London)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21343",children:"https://arxiv.org/pdf/2512.21343"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes EcoNet, a novel Bayesian framework for household and neighborhood energy management based on active inference. 2. Addresses the challenge of planning under uncertainty (e.g., weather, solar forecasts) while handling complex, conditional, and conflicting household goals. 3. Demonstrates the approach through simulations for multiagent planning and control of distributed energy resources."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b885d3c6c9f392a494063522c79cde9a59fead8ab6b04010259b6485f007cec8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b885d3c6c9f392a494063522c79cde9a59fead8ab6b04010259b6485f007cec8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces EcoNet, a multiagent planning and control system for household energy resources using active inference, a Bayesian approach, to manage uncertainty and conflicting goals. The method aims to optimize energy use, costs, and emissions while maintaining comfort. Simulation results demonstrate its potential for improved energy management and coordination."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[EcoNet: \u591a\u667a\u80fd\u4f53\u5bb6\u5ead\u80fd\u6e90\u89c4\u5212\u4e0e\u63a7\u5236 / EcoNet: Multiagent Household Energy Planning & Control] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u590d\u6742\u4e14\u51b2\u7a81\u7684\u5bb6\u5ead\u76ee\u6807 / Complex & Conflicting Household Goals]\n    B --\x3e B2[\u51b3\u7b56\u5b58\u5728\u4e0d\u786e\u5b9a\u6027 / Decision-making Under Uncertainty]\n    C --\x3e C1[\u57fa\u4e8e\u4e3b\u52a8\u63a8\u7406\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5 / Active Inference-based Bayesian Approach]\n    C --\x3e C2[\u591a\u667a\u80fd\u4f53\u89c4\u5212\u4e0e\u63a7\u5236 / Multiagent Planning & Control]\n    D --\x3e D1[\u6a21\u62df\u7ed3\u679c\u5c55\u793a / Simulation Results Presented]\n    D --\x3e D2[\u6539\u5584\u80fd\u6e90\u7ba1\u7406\u4e0e\u534f\u8c03 / Improved Energy Management & Coordination]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Multi-Agent LLM Committees for Autonomous Software Beta Testing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [automated software testing], [multi-agent system, large language model, vision-language model, consensus voting, beta testing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21352",children:"https://arxiv.org/pdf/2512.21352"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u624b\u52a8\u6d4b\u8bd5\u6210\u672c\u9ad8\uff0c\u5355\u667a\u80fd\u4f53LLM\u5b58\u5728\u5e7b\u89c9/Manual testing costly, single-agent LLM hallucinates]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u59d4\u5458\u4f1a\u4e0e\u4e09\u8f6e\u6295\u7968\u534f\u8bae/Multi-agent committee & three-round voting]\n    C --\x3e C2[\u89c6\u89c9LLM\u4e0e\u89d2\u8272\u591a\u6837\u6027/Vision LLMs & persona diversity]\n    D --\x3e D1[\u4efb\u52a1\u6210\u529f\u738789.5%\uff0c\u8d85\u8d8a\u57fa\u7ebf/Task success 89.5%, beats baseline]\n    D --\x3e D2[\u52a8\u4f5c\u5ef6\u8fdf0.71\u79d2\uff0c\u9002\u5408CI/CD/Action latency 0.71s, suitable for CI/CD]\n    D --\x3e D3[\u8986\u76d68/10 OWASP\u6f0f\u6d1e\u7c7b\u522b/Covers 8/10 OWASP Top 10]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [software fairness], [correlation tuning, phi-coefficient, multi-objective optimization, pre-processing, bias mitigation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," King\u2019s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21348",children:"https://arxiv.org/pdf/2512.21348"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u516c\u5e73\u7814\u7a76\u5ffd\u89c6\u8f6f\u4ef6\u8d28\u91cf\u7ef4\u5ea6/Traditional fairness research neglects software quality dimension]\n    B --\x3e B2[\u9884\u5904\u7406\u65b9\u6cd5\u6548\u679c\u4e0d\u8db3/Pre-processing methods lack effectiveness]\n    C --\x3e C1[\u63d0\u51fa\u76f8\u5173\u6027\u8c03\u4f18 (CoT)/Propose Correlation Tuning (CoT)]\n    C --\x3e C2[\u4f7f\u7528Phi\u7cfb\u6570\u91cf\u5316\u76f8\u5173\u6027/Use Phi-coefficient to quantify correlation]\n    C --\x3e C3[\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316/Employ multi-objective optimization]\n    D --\x3e D1[\u63d0\u9ad8\u5f31\u52bf\u7fa4\u4f53TPR 17.5%/Increase unprivileged group TPR by 17.5%]\n    D --\x3e D2[\u5173\u952e\u504f\u5dee\u6307\u6807\u964d\u4f4e >50%/Key bias metrics reduced by >50%]\n    D --\x3e D3[\u8d85\u8d8aSOTA\u65b9\u6cd5 3-10\u4e2a\u767e\u5206\u70b9/Outperform SOTA by 3-10 percentage points]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [db], [text-to-SQL], [unanswerable question detection, few-shot prompting, biomedical databases]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zurich University of Applied Sciences, University of Zurich"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21345",children:"https://arxiv.org/pdf/2512.21345"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks") --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem("\u6838\u5fc3\u95ee\u9898/Problem") --\x3e P1("Text-to-SQL\u5bf9\u4e0d\u53ef\u56de\u7b54\u67e5\u8be2\u751f\u6210\u53ef\u6267\u884cSQL/Text-to-SQL generates executable SQL for unanswerable queries")\n    P1 --\x3e P2("\u751f\u7269\u533b\u5b66\u9886\u57df\u98ce\u9669\u9ad8/High risk in biomedical contexts")\n    Method("\u4e3b\u8981\u65b9\u6cd5/Method") --\x3e M1("Query Carefully \u7ba1\u9053/Query Carefully pipeline")\n    M1 --\x3e M2("LLM (llama3.3:70b) + \u6a21\u5f0f\u611f\u77e5\u63d0\u793a + \u5c11\u6837\u672c/LLM (llama3.3:70b) + schema-aware prompts + few-shot")\n    M2 --\x3e M3("\u5305\u542b\u53ef\u56de\u7b54\u4e0e\u4e0d\u53ef\u56de\u7b54\u793a\u4f8b/Includes answerable and unanswerable examples")\n    Results("\u5173\u952e\u7ed3\u679c/Results") --\x3e R1("\u6784\u5efaOncoMX-NAQ\u57fa\u51c6/Built OncoMX-NAQ benchmark")\n    R1 --\x3e R2("\u4e0d\u53ef\u56de\u7b54\u68c0\u6d4b\u51c6\u786e\u73870.8/Unanswerable-detection accuracy 0.8")\n    R2 --\x3e R3("\u7ed3\u6784\u6027\u95ee\u9898\u68c0\u6d4b\u597d\uff0c\u8bed\u4e49\u6a21\u7cca\u6311\u6218\u5927/Good for structural, challenging for semantic ambiguity")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Relevance-Zone Based Search, AlphaZero, Life-and-Death problems, heuristic search, pattern table]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chung-Chin Shih, Ti-Rong Wu, Ting Han Wei, Yu-Shan Hsu, Hung Guei, I-Chen Wu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Academia Sinica, National Yang Ming Chiao Tung University, Kochi University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21365",children:"https://arxiv.org/pdf/2512.21365"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ",children:"https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Applied and analyzed Relevance-Zone Based Search (RZS) and relevance-zone pattern tables to solve Go Life-and-Death problems, identifying critical relevance-zones. 2. Discovered that solvers can find rare patterns and even alternative solutions differing from established human grandmaster answers. 3. Identified and analyzed key limitations of current solvers, such as misjudging rare patterns and prioritizing direct survival over territory maximization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6376caf4e3dced23991e86eb4d5b0f512ce3623019adeaf18ee253d5fd00c507_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6376caf4e3dced23991e86eb4d5b0f512ce3623019adeaf18ee253d5fd00c507_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes the performance of state-of-the-art computer Go solvers using Relevance-Zone Based Search on classic Life-and-Death problems. The study finds that while these solvers can identify critical areas and discover rare patterns, they exhibit limitations like misjudging pattern values and having a non-human preference for direct survival over territory. The authors suggest future approaches to address these solver issues."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers<br/>\u4f7f\u7528\u57fa\u4e8e\u76f8\u5173\u533a\u57df\u6c42\u89e3\u5668\u89e3\u51b3\u56f4\u68cb\u6b7b\u6d3b\u95ee\u9898\u7684\u7814\u7a76"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br/>Analyzing solver behavior on Go Life-and-Death problems<br/>\u5206\u6790\u6c42\u89e3\u5668\u5728\u56f4\u68cb\u6b7b\u6d3b\u95ee\u9898\u4e0a\u7684\u884c\u4e3a"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Using Relevance-Zone Based Search (RZS) and pattern tables<br/>\u4f7f\u7528\u57fa\u4e8e\u76f8\u5173\u533a\u57df\u7684\u641c\u7d22\u548c\u6a21\u5f0f\u8868"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br/>Identifies relevance-zones, finds rare/alternative solutions, reveals solver limitations<br/>\u8bc6\u522b\u76f8\u5173\u533a\u57df\uff0c\u53d1\u73b0\u7f55\u89c1/\u66ff\u4ee3\u89e3\u6cd5\uff0c\u63ed\u793a\u6c42\u89e3\u5668\u5c40\u9650"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [computational psychology], [multimodal large language model, multi-agent collaboration, cosine similarity, projective assessment, psychological report generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shuide Wen, Yu Sun, Beier Ku, Zhi Gao, Lijun Ma, Yang Yang, Can Jiao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Shenzhen University, University of Oxford, Guangzhou University of Chinese Medicine, Harbin Institute of Technology, Shenzhen Institute of Education Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21360",children:"https://arxiv.org/pdf/2512.21360"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel multi-agent collaboration framework to automate the interpretation of House-Tree-Person drawings, decoupling visual feature recognition from psychological inference. 2. Demonstrated that multimodal large language models (MLLMs) can achieve expert-level baseline comprehension in interpreting projective drawings, with high semantic similarity to human expert interpretations. 3. Introduced a destigmatizing narrative and social-psychological perspective integration to correct visual hallucinations and enhance the ecological validity and coherence of automated psychological reports."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/681955eb18a63880e0327c5debb6e992188de12ca52cef0c9c34258f09c3a91d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/681955eb18a63880e0327c5debb6e992188de12ca52cef0c9c34258f09c3a91d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an automated assessment framework for the House-Tree-Person drawing test using multimodal LLMs and multi-agent collaboration to address issues of subjective scoring and lack of standardization. The framework effectively interprets drawings with high similarity to expert analysis and generates coherent psychological reports. The results confirm the potential of multimodal models as standardized tools for projective psychological assessment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration<br>\u4ece\u89c6\u89c9\u611f\u77e5\u5230\u6df1\u5ea6\u5171\u60c5\uff1a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u623f\u6811\u4eba\u7ed8\u753b\u81ea\u52a8\u8bc4\u4f30\u6846\u67b6] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>HTP\u6d4b\u8bd5\u8bc4\u5206\u6807\u51c6\u4e0d\u4e00\uff0c\u4f9d\u8d56\u4e3b\u89c2\u7ecf\u9a8c\uff0c\u7f3a\u4e4f\u7edf\u4e00\u91cf\u5316\u7cfb\u7edf] --\x3e B1\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6] --\x3e C1\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u6a21\u578b\u89e3\u91ca\u4e0e\u4e13\u5bb6\u89e3\u91ca\u8bed\u4e49\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u6709\u6548\u5fc3\u7406\u62a5\u544a] --\x3e D1\n    B1[HTP test has heterogeneous scoring, relies on subjective experience, lacks unified quantitative coding]\n    C1[Multimodal LLMs and multi-agent collaboration framework]\n    D1[High semantic similarity to expert interpretations; multi-agent system produces reports with high ecological validity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21354",children:"https://arxiv.org/pdf/2512.21354"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Reflection-Driven Control for Trustworthy Code Agents] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[LLM\u4ee3\u7406\u7f3a\u4e4f\u53ef\u9760\u7684\u5b89\u5168\u63a7\u5236/LLM agents lack reliable safety controls]\n    Problem --\x3e P2[\u53ef\u80fd\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa/Can produce harmful outputs]\n    Method --\x3e M1[\u5c06\u81ea\u6211\u53cd\u601d\u4f5c\u4e3a\u63a8\u7406\u7684\u663e\u5f0f\u6b65\u9aa4/Elevates self-reflection to an explicit reasoning step]\n    Method --\x3e M2[\u5185\u90e8\u53cd\u601d\u5faa\u73af\u76d1\u63a7\u51b3\u7b56\u8def\u5f84/Internal reflection loop monitors decision path]\n    Method --\x3e M3[\u4ece\u53cd\u601d\u8bb0\u5fc6\u4e2d\u68c0\u7d22\u4fee\u590d\u793a\u4f8b/Retrieves repair examples from reflective memory]\n    Results --\x3e R1[\u663e\u8457\u63d0\u9ad8\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027/Substantially improves security & policy compliance]\n    Results --\x3e R2[\u57fa\u672c\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027/Largely preserves functional correctness]\n    Results --\x3e R3[\u8fd0\u884c\u65f6\u548ctoken\u5f00\u9500\u6700\u5c0f/Minimal runtime & token overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] AInsteinBench: Benchmarking Coding Agents on Scientific Repositories"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [software engineering], [benchmark, scientific computing, code generation, pull requests, test-driven verification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ByteDance Seed, Princeton University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21373",children:"https://arxiv.org/pdf/2512.21373"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/ByteDance-Seed/AInsteinBench",children:"https://github.com/ByteDance-Seed/AInsteinBench"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Can LLM agents operate as scientific computing development agents?]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: End-to-end evaluation using tasks from real scientific pull requests]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Measures ability beyond surface-level code generation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Safe Path Planning and Observation Quality Enhancement Strategy for Unmanned Aerial Vehicles in Water Quality Monitoring Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [robotic perception and planning], [Interfered Fluid Dynamical System (IFDS), Model Predictive Control (MPC), Dynamic Flight Altitude Adjustment (DFAA)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuanshuang Fu, Qianyao Wang, Qihao Wang, Bonan Zhang, Jiaxin Zhao, Yiming Cao, Zhijun Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Electronic Science and Technology of China, North China University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21375",children:"https://arxiv.org/pdf/2512.21375"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a dynamic prediction model that transforms time-varying light and shadow disturbances (e.g., sun glint) into 3D virtual obstacles for path planning. 2. Introduces an improved IFDS algorithm combined with an MPC framework to generate smooth, safe, and dynamically feasible real-time trajectories for UAVs. 3. Designs a Dynamic Flight Altitude Adjustment (DFAA) mechanism to actively lower flight altitude in narrow observable areas, enhancing spatial resolution and data quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5582bc8dd27c45953b75b142df4da9d25f5164a9ed81f8842a846572fbb8a2f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5582bc8dd27c45953b75b142df4da9d25f5164a9ed81f8842a846572fbb8a2f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of UAV water quality monitoring being hindered by dynamic illumination disturbances like shadows and sun glint, which degrade spectral data. The proposed method actively plans safe flight paths by modeling disturbances as obstacles, using an improved IFDS and MPC for real-time trajectory optimization, and dynamically adjusting altitude to improve data quality. Simulation results show the method achieves a 98% obstacle avoidance success rate and increases effective observation data volume by approximately 27%."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Safe Path Planning and Observation Quality Enhancement Strategy for UAVs in Water Quality Monitoring Tasks] --\x3e B\nA --\x3e C\nA --\x3e D\nB[\u6838\u5fc3\u95ee\u9898/Problem<br>Dynamic illumination disturbances (shadows, sun glint) cause spectral distortion, reducing data quality and safety.]\nC[\u4e3b\u8981\u65b9\u6cd5/Method<br>1. Model disturbances as 3D virtual obstacles.<br>2. Improved IFDS + MPC for real-time path planning.<br>3. Dynamic Flight Altitude Adjustment (DFAA).]\nD[\u5173\u952e\u7ed3\u679c/Results<br>98% obstacle avoidance success rate, improved path smoothness, ~27% increase in effective observation data.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks], [adversarial attack, large language model, retrieval-augmented generation, Android malware detection, adversarial training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tianwei Lan, Farid Na\xeft-Abdesselam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universit\xe9 Paris Cit\xe9"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21404",children:"https://arxiv.org/pdf/2512.21404"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: ML-based Android malware detectors are vulnerable to adversarial attacks.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes LAMLAD, a dual-agent LLM framework with RAG for generating stealthy perturbations.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves up to 97% attack success rate; adversarial training defense reduces ASR by >30%.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Feasible strategies in three-way conflict analysis with three-valued ratings"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [conflict analysis], [three-way conflict analysis, feasible strategy, consistency measure, non-consistency measure, weighted agent-issue evaluation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jing Liu, Mengjun Hu, Guangming Lang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Changsha University of Science and Technology, Saint Mary's University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21420",children:"https://arxiv.org/pdf/2512.21420"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework for identifying feasible strategies in conflict resolution from the perspectives of consistency and non-consistency. 2. Introduces weighted consistency and non-consistency measures that incorporate the importance of both agents and issues. 3. Develops algorithms to systematically identify feasible strategies, L-order feasible strategies, and optimal solutions, demonstrating superior performance over existing approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4b2e48e756e98608f4388b841aa7940f0ba7b237737fa314abc4db83fbf680f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4b2e48e756e98608f4388b841aa7940f0ba7b237737fa314abc4db83fbf680f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the gap in formulating actionable strategies for conflict resolution within three-way conflict analysis. It proposes a method that computes agent clique ratings and uses novel weighted consistency and non-consistency measures to identify feasible and optimal strategies. The approach is validated through case studies and shown to outperform conventional conflict analysis models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Feasible strategies in three-way conflict analysis<br>\u4e09\u5411\u51b2\u7a81\u5206\u6790\u4e2d\u7684\u53ef\u884c\u7b56\u7565] --\x3e B(Problem: Lack of focus on conflict resolution strategies<br>\u95ee\u9898: \u7f3a\u4e4f\u5bf9\u51b2\u7a81\u89e3\u51b3\u7b56\u7565\u7684\u5173\u6ce8)\n    A --\x3e C(Method: Weighted consistency/non-consistency measures & algorithms<br>\u65b9\u6cd5: \u52a0\u6743\u4e00\u81f4/\u975e\u4e00\u81f4\u6027\u5ea6\u91cf\u4e0e\u7b97\u6cd5)\n    A --\x3e D(Results: Outperforms conventional approaches, identifies optimal solutions<br>\u7ed3\u679c: \u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u8bc6\u522b\u6700\u4f18\u89e3)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Three-way conflict analysis based on alliance and conflict functions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [decision theory], [three-way decision, conflict analysis, alliance function, conflict function, alliance set]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junfang Luo, Mengjun Hu, Guangming Lang, Xin Yang, Keyun Qin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Southwestern University of Finance and Economics, University of Regina, Changsha University of Science and Technology, Southwest Jiaotong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21419",children:"https://arxiv.org/pdf/2512.21419"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel separation of the traditional auxiliary function into distinct alliance and conflict functions to clarify semantic interpretation in conflict analysis. 2. Introduces a framework for trisecting agents, issues, and agent pairs based on the new alliance and conflict functions. 3. Explores and applies new concepts such as alliance sets and strategies to solve crucial questions in conflict analysis, demonstrating the model with a real-world application."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54277009925f58600c765060d6cbc575e96e562e3c9748aa2f54e97b83024e0b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54277009925f58600c765060d6cbc575e96e562e3c9748aa2f54e97b83024e0b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the semantic ambiguity in aggregating traditional three-way conflict analysis functions by proposing a separation into distinct alliance and conflict functions. The method enables clearer trisection of agents, issues, and agent pairs, leading to the exploration of alliance sets and strategies. The main conclusion is that this separation provides a more interpretable and applicable framework for conflict analysis, as illustrated by a real-world example."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Three-way Conflict Analysis Based on Alliance and Conflict Functions] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u8f85\u52a9\u51fd\u6570\u805a\u5408\u8bed\u4e49\u6a21\u7cca/Semantic ambiguity in aggregating traditional auxiliary functions]\n    C --\x3e C1[\u5206\u79bb\u4e3a\u8054\u76df\u4e0e\u51b2\u7a81\u51fd\u6570/Separate into alliance and conflict functions]\n    C --\x3e C2[\u57fa\u4e8e\u65b0\u51fd\u6570\u8fdb\u884c\u4e09\u5206/Trisec based on new functions]\n    D --\x3e D1[\u63d0\u51fa\u8054\u76df\u96c6\u4e0e\u7b56\u7565\u6982\u5ff5/Propose alliance sets and strategies]\n    D --\x3e D2[\u63d0\u4f9b\u771f\u5b9e\u5e94\u7528\u6848\u4f8b/Provide a real-world application]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Teaching People LLM's Errors and Getting it Right"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [human-ai interaction], [overreliance, failure patterns, mental models, user study, meta-labels]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasovi\u0107"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Utah"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21422",children:"https://arxiv.org/pdf/2512.21422"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness\u2014assessing a user's ability to anticipate LLM errors using taught patterns\u2014which showed a positive effect, unlike traditional human-AI team accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Teaching People LLM\u2019s Errors and Getting it Right] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Users overrely on LLMs due to inaccurate mental models]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Analyze failure pattern existence, test discovery methods, propose new evaluation metric]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Patterns exist, discovery methods are mixed, new metric shows teaching is effective]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Three-way decision with incomplete information based on similarity and satisfiability"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [rough set theory], [three-way decision, incomplete information, similarity degree, satisfiability degree, approximability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junfang Luo, Mengjun Hu, Keyun Qin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Southwest Jiaotong University, University of Regina"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21421",children:"https://arxiv.org/pdf/2512.21421"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new measure of similarity degree of objects as a generalization of equivalence relations for handling incomplete information in the computational formulation of three-way decision. 2. Introduces a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability for the conceptual formulation of three-way decision under incomplete information. 3. Proposes novel approaches for three-way decision using approximability of objects and confidence of formulas, pointing out new research directions beyond the common method of similarity classes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d87784acc1b1cc397b822153c118be23974be9721c3d19c9dfc95fbbaef158e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d87784acc1b1cc397b822153c118be23974be9721c3d19c9dfc95fbbaef158e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper generalizes the computational and conceptual formulations of three-way decision to handle incomplete information, which is common in real-world applications. For the computational side, it introduces a similarity degree measure and explores decision-making via \u03b1-similarity classes and approximability; for the conceptual side, it proposes a satisfiability degree measure and studies approaches using \u03b1-meaning sets and confidence. The work extends rough set theory and identifies promising new directions for three-way decision under uncertainty."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Three-Way Decision with Incomplete Information Based on Similarity and Satisfiability] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5904\u7406\u4e0d\u5b8c\u5168\u4fe1\u606f/Handling Incomplete Information]\n    C --\x3e C1[\u8ba1\u7b97\u5f0f: \u76f8\u4f3c\u5ea6/Computational: Similarity Degree]\n    C --\x3e C2[\u6982\u5ff5\u5f0f: \u53ef\u6ee1\u8db3\u5ea6/Conceptual: Satisfiability Degree]\n    C1 --\x3e C1a[\u03b1-\u76f8\u4f3c\u7c7b/\u03b1-Similarity Classes]\n    C1 --\x3e C1b[\u53ef\u903c\u8fd1\u6027/Approximability]\n    C2 --\x3e C2a[\u03b1-\u610f\u4e49\u96c6/\u03b1-Meaning Sets]\n    C2 --\x3e C2b[\u7f6e\u4fe1\u5ea6/Confidence]\n    D --\x3e D1[\u63a8\u5e7f\u4e24\u79cd\u8868\u8ff0/Generalizes Both Formulations]\n    D --\x3e D2[\u6307\u51fa\u65b0\u65b9\u5411/Points to New Directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [computational ethics], [moral context, probabilistic clustering, LLM semantics, interpretable prediction, human judgment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Intelligent Systems and Robotics, Sorbonne University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21439",children:"https://arxiv.org/pdf/2512.21439"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[COMETH: Learning Interpretable Moral Contexts] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Moral judgments are context-dependent]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Probabilistic clustering + LLM semantics + Human judgments]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Doubles alignment with human judgments vs. LLM prompting]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Washington, University of California, Berkeley"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21446",children:"https://arxiv.org/pdf/2512.21446"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[MDLMs\u89e3\u7801\u6162\uff0c\u901f\u5ea6\u4f18\u52bf\u6709\u9650/MDLMs decode slowly, limiting speed advantage]\n    C --\x3e C1[\u57fa\u4e8eGRPO\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6/On-policy RL framework based on GRPO]\n    C --\x3e C2[\u8054\u5408\u4f18\u5316\u6269\u6563\u6a21\u578b\u4e0e\u89e3\u63a9\u7801\u89c4\u5212\u5668/Jointly optimize diffusion model & unmasking planner]\n    D --\x3e D1[\u63d0\u5347\u7cbe\u5ea6-\u6548\u7387\u6743\u8861/Improves accuracy-efficiency trade-off]\n    D --\x3e D2[\u8fc8\u5411"\u6269\u6563\u9738\u6743"/Moving towards "diffusion supremacy"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Harbin Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21452",children:"https://arxiv.org/pdf/2512.21452"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Intelligent recognition of GPR road hidden defect images <br/> GPR\u9053\u8def\u9690\u853d\u75c5\u5bb3\u56fe\u50cf\u667a\u80fd\u8bc6\u522b") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n\n    Problem --\x3e P1("Subjective & inefficient GPR interpretation <br/> GPR\u56fe\u50cf\u89e3\u91ca\u4e3b\u89c2\u4e14\u4f4e\u6548")\n    Problem --\x3e P2("Data scarcity <br/> \u6570\u636e\u7a00\u7f3a")\n\n    Method --\x3e M1("DCGAN-based Data Augmentation <br/> \u57fa\u4e8eDCGAN\u7684\u6570\u636e\u589e\u5f3a")\n    Method --\x3e M2("MCGA-Net (MCFF + GAM) <br/> MCGA-Net\u7f51\u7edc")\n    Method --\x3e M3("MS COCO Transfer Learning <br/> MS COCO\u8fc1\u79fb\u5b66\u4e60")\n\n    Results --\x3e R1("High Performance (Precision 92.8%, mAP@50 95.9%) <br/> \u9ad8\u6027\u80fd")\n    Results --\x3e R2("Robust to noise & weak signals <br/> \u5bf9\u566a\u58f0\u548c\u5f31\u4fe1\u53f7\u9c81\u68d2")\n    Results --\x3e R3("New paradigm for automated detection <br/> \u81ea\u52a8\u5316\u68c0\u6d4b\u65b0\u8303\u5f0f")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image retrieval], [polyp re-identification, gated progressive fusion, multimodal feature fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Suncheng Xiang, Xiaoyang Wang, Junjie Jiang, Hejia Wang, Dahong Qian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Peking University, Shanghai Fifth People's Hospital"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21476",children:"https://arxiv.org/pdf/2512.21476"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/JeremyXSC/GPF-Net",children:"https://github.com/JeremyXSC/GPF-Net"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1) Proposes a novel multimodal feature fusion framework named GPF-Net for polyp re-identification. 2) Introduces a gated progressive fusion strategy for layer-wise refinement of semantic information through multi-level feature interactions. 3) Demonstrates state-of-the-art performance on standard benchmarks, showing the benefit of multimodal fusion over unimodal methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75fe09ad1f753b61f2c30ab37c16d0deef5060ca95658846bc6dcaf6bb4c53f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75fe09ad1f753b61f2c30ab37c16d0deef5060ca95658846bc6dcaf6bb4c53f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of colonoscopic polyp re-identification, where coarse high-level features harm small object matching. The authors propose GPF-Net, a Gated Progressive Fusion network that selectively fuses multi-level features using gates. Experiments show this multimodal approach outperforms state-of-the-art unimodal ReID models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Coarse high-level features lead to inferior results for small polyps]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Gated Progressive Fusion network for selective, multi-level feature fusion]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms unimodal models, benefits of multimodal fusion strategy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21487",children:"https://arxiv.org/pdf/2512.21487"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[MoE\u63a8\u7406\u5185\u5b58\u5bc6\u96c6\uff0c\u73b0\u6709DEP\u8c03\u5ea6\u6548\u7387\u4f4e/MoE inference is memory-intensive, existing DEP scheduling is inefficient]\n    C --\x3e C1[\u7ec6\u7c92\u5ea6\u4efb\u52a1\u5212\u5206\u4e0e\u8c03\u5ea6\u4f18\u5316/Fine-grained task partitioning and scheduling optimization]\n    D --\x3e D1[\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53471.61\u500d/Throughput improved by up to 1.61x]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Oogiri-Master: Benchmarking Humor Understanding via Oogiri"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [humor understanding], [Oogiri, benchmark, linguistic analysis, incongruity resolution, insight-augmented prompting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21494",children:"https://arxiv.org/pdf/2512.21494"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Oogiri-Master: Benchmarking Humor Understanding via Oogiri] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: What makes Oogiri responses funny to humans?]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Introduce Oogiri-Master benchmark and Oogiri-Corpus dataset with diverse responses and independent ratings]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: LLMs approach human performance; insight-augmented prompting improves results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [multimodal forgery detection], [visual-textual co-reasoning, cross-cues-aware chain of thought (CCT), GRPO-based optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Fanwei Zeng, Changtao Miao, Jing Huang, Zhiya Tan, Shutao Gong, Xiaoming Yu, Yang Wang, Huazhe Tan, Weibin Yao, Jianshu Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ant Group, Nanyang Technological University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21482",children:"https://arxiv.org/pdf/2512.21482"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed LogicLens, a unified framework for visual-textual co-reasoning that jointly performs detection, grounding, and explanation for text-centric forgery analysis. 2. Introduced a Cross-Cues-aware Chain of Thought (CCT) mechanism for iterative cross-validation of visual and textual cues, and a weighted multi-task reward function for GRPO-based optimization. 3. Created the RealText dataset with 5,397 images and fine-grained annotations using a novel PR\xb2 (Perceiver, Reasoner, Reviewer) multi-agent annotation pipeline."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/138f8fcb4727c77950b23146e1184851aa8b8cea95056b1d6b161c37e231ad80_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/138f8fcb4727c77950b23146e1184851aa8b8cea95056b1d6b161c37e231ad80_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces LogicLens, a unified visual-textual co-reasoning framework for analyzing text-centric forgeries. It uses a novel Cross-Cues-aware Chain of Thought mechanism and multi-task optimization to jointly handle detection, grounding, and explanation. Experiments show LogicLens achieves state-of-the-art performance, significantly outperforming specialized frameworks and other MLLMs in zero-shot and dense-text scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6587\u672c\u4e2d\u5fc3\u4f2a\u9020\u5a01\u80c1/Sophisticated text-centric forgeries]\n    B --\x3e B2[\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u63a8\u7406/Current methods lack reasoning]\n    B --\x3e B3[\u4efb\u52a1\u5272\u88c2/Tasks treated as discrete]\n    C --\x3e C1[\u7edf\u4e00\u6846\u67b6/Unified Visual-Textual Co-reasoning framework]\n    C --\x3e C2[\u8de8\u7ebf\u7d22\u601d\u7ef4\u94fe/Cross-Cues-aware Chain of Thought (CCT)]\n    C --\x3e C3[\u591a\u4efb\u52a1\u5956\u52b1\u51fd\u6570/Weighted multi-task reward function]\n    C --\x3e C4[PR\xb2\u6807\u6ce8\u7ba1\u9053/PR\xb2 annotation pipeline]\n    C --\x3e C5[RealText\u6570\u636e\u96c6/RealText dataset]\n    D --\x3e D1[\u96f6\u6837\u672c\u8bc4\u4f30\u9886\u5148/Superior zero-shot performance]\n    D --\x3e D2[\u5bc6\u96c6\u6587\u672c\u6570\u636e\u96c6\u9886\u5148/Lead on dense-text dataset]\n    D --\x3e D3[\u516c\u5f00\u8d44\u6e90/Public dataset, model, code]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dartmouth College"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21506",children:"https://arxiv.org/pdf/2512.21506"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21514",children:"https://arxiv.org/pdf/2512.21514"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DiverseGRPO: Mitigating Mode Collapse] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[GRPO\u5bfc\u81f4\u6a21\u5f0f\u5d29\u6e83/GRPO causes mode collapse]\n    B1 --\x3e B2[\u7f3a\u4e4f\u89c6\u89c9\u591a\u6837\u6027/Lacks visual diversity]\n    C --\x3e C1[\u5956\u52b1\u5c42\u9762: \u5206\u5e03\u521b\u9020\u529b\u5956\u52b1/Reward Level: Distributional Creativity Bonus]\n    C --\x3e C2[\u751f\u6210\u5c42\u9762: \u7ed3\u6784\u611f\u77e5\u6b63\u5219\u5316/Generation Level: Structure-Aware Regularization]\n    C1 --\x3e C3[\u57fa\u4e8e\u8bed\u4e49\u5206\u7ec4\u7684\u8c31\u805a\u7c7b/Spectral Clustering for Semantic Grouping]\n    D --\x3e D1[\u8bed\u4e49\u591a\u6837\u6027\u63d0\u534713%-18%/13%-18% Semantic Diversity Improvement]\n    D --\x3e D2[\u5efa\u7acb\u65b0\u7684\u5e15\u7d2f\u6258\u524d\u6cbf/Establishes New Pareto Frontier]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Selective LLM-Guided Regularization for Enhancing Recommendation Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [selective regularization, knowledge distillation, cold-start, long-tail, gating mechanism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shanglin Yang, Zhan Shi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sichuan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21526",children:"https://arxiv.org/pdf/2512.21526"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a selective LLM-guided regularization framework (S-LLMR) that activates LLM supervision only when a gating mechanism predicts the LLM to be reliable, addressing the issue of inaccurate global distillation. 2. Introduces a trainable gating mechanism informed by user history length, item popularity, and model uncertainty to dynamically decide when to apply LLM-based pairwise ranking supervision. 3. Demonstrates through experiments that the method improves overall accuracy and yields substantial gains in cold-start and long-tail recommendation scenarios, outperforming global distillation baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of leveraging large language models (LLMs) for recommendation without suffering from their high cost and unreliability in certain scenarios. It proposes Selective LLM-Guided Regularization (S-LLMR), a model-agnostic framework that uses a gating mechanism to selectively apply LLM-based supervision only when the LLM is predicted to be reliable. Experiments show this approach improves recommendation accuracy, especially for cold-start users and long-tail items, outperforming methods that uniformly distill LLM knowledge."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Selective LLM-Guided Regularization<br>\u9009\u62e9\u6027LLM\u5f15\u5bfc\u6b63\u5219\u5316] --\x3e B(Problem/\u6838\u5fc3\u95ee\u9898<br>LLMs as standalone recommenders are costly/unreliable;<br>Global distillation forces imitation of inaccurate LLM guidance.)\n    A --\x3e C(Method/\u4e3b\u8981\u65b9\u6cd5<br>Selective LLM-Guided Regularization (S-LLMR):<br>Trainable gating mechanism activates LLM supervision only when reliable.)\n    A --\x3e D(Results/\u5173\u952e\u7ed3\u679c<br>Improves overall accuracy;<br>Substantial gains in cold-start & long-tail regimes.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Hierarchy-Aware Fine-Tuning of Vision-Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [multimodal learning], [hierarchical classification, vision-language models, efficient fine-tuning, LoRA, Tree-Path KL Divergence]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiayu Li, Rajesh Gangireddy, Samet Akcay, Wei Cheng, Juhua Hu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Washington, Intel"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21529",children:"https://arxiv.org/pdf/2512.21529"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an efficient hierarchy-aware fine-tuning framework for Vision-Language Models (VLMs) that updates only a few parameters. 2. Introduces two novel loss functions: Tree-Path KL Divergence (TP-KL) for vertical consistency along label paths and Hierarchy-Sibling Smoothed Cross-Entropy (HiSCE) for horizontal consistency among sibling classes. 3. Demonstrates consistent improvements in Full-Path Accuracy and reduced Tree-based Inconsistency Error across multiple hierarchical benchmarks with minimal parameter overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b60d2fc3dd0ad92b5ac8857f844fed2dbe51e280dfb702c26028d91c14fd92_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b60d2fc3dd0ad92b5ac8857f844fed2dbe51e280dfb702c26028d91c14fd92_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of adapting large Vision-Language Models (VLMs) to hierarchical classification tasks efficiently. The proposed method combines two novel hierarchy-aware loss functions (TP-KL and HiSCE) with lightweight LoRA adaptation to enforce structural consistency in predictions. Experiments show the approach improves accuracy and reduces inconsistency across taxonomy levels with minimal computational cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Hierarchy-Aware Fine-Tuning of Vision-Language Models") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("VLMs\u9002\u5e94\u5c42\u7ea7\u5206\u7c7b\u6548\u7387\u4f4e/VLMs inefficient for hierarchical classification")\n    Problem --\x3e P2("\u6807\u51c6\u65b9\u6cd5\u9884\u6d4b\u4e0d\u4e00\u81f4/Standard methods produce inconsistent predictions")\n    Method --\x3e M1("\u63d0\u51fa\u5c42\u7ea7\u611f\u77e5\u5fae\u8c03\u6846\u67b6/Propose hierarchy-aware fine-tuning framework")\n    Method --\x3e M2("\u7ed3\u5408TP-KL\u4e0eHiSCE\u635f\u5931/Combine TP-KL and HiSCE losses")\n    Method --\x3e M3("\u96c6\u6210\u8f7b\u91cf\u7ea7LoRA\u9002\u914d/Integrate lightweight LoRA adaptation")\n    Results --\x3e R1("\u63d0\u5347\u5168\u8def\u5f84\u7cbe\u5ea6/Improves Full-Path Accuracy")\n    Results --\x3e R2("\u964d\u4f4e\u4e0d\u4e00\u81f4\u6027\u9519\u8bef/Reduces Tree-based Inconsistency Error")\n    Results --\x3e R3("\u53c2\u6570\u5f00\u9500\u6700\u5c0f/Minimal parameter overhead")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Peking University, Harbin Institute of Technology, Shenzhen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21540",children:"https://arxiv.org/pdf/2512.21540"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LEASH: Adaptive Length Penalty and Reward Shaping] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs\u751f\u6210\u8fc7\u957f\u63a8\u7406\u94fe\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u65b9\u6cd5\u52a8\u6001\u8c03\u6574\u60e9\u7f5a\u7cfb\u6570/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c1160%\uff0c\u6027\u80fd\u4fdd\u6301\u7ade\u4e89\u529b/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [human-ai interaction], [bidirectional alignment, value-centered design, interactive alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21551",children:"https://arxiv.org/pdf/2512.21551"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Human-AI Interaction Alignment] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Establishes agenda for reciprocal, responsible human-AI futures]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [ai for education], [human-ai alignment, trustworthy ai, adaptive learning, educational technology, ai ethics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hua Shen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," NYU Shanghai, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21552",children:"https://arxiv.org/pdf/2512.21552"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes the novel concept of "bidirectional human-AI alignment" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI\'s role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898: Bidirectional Human-AI Alignment in Education] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: AI in education introduces risks to equity, privacy, and autonomy.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Exploration of Reproducible Generated Image Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image forensics], [AIGC detection, reproducibility, generalizability, diffusion models, binary classification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yihang Duan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in the provided content. (Author name only, no affiliation or email domain provided)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21562",children:"https://arxiv.org/pdf/2512.21562"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and analyzes the root causes of poor reproducibility in AIGC image detection research, citing omitted experimental details and overfitting to generator-specific features. 2. Provides empirical evidence for the reproducibility issue by constructing a test dataset and reproducing a representative detection method, demonstrating performance drops under cross-generator testing. 3. Proposes reference directions for the research community to improve reproducibility and generalizability, such as more comprehensive disclosure of experimental details."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c9df3d6873df2ea90e378adf52625583637b76319eb9a55ebf11b8f17abf1fc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c9df3d6873df2ea90e378adf52625583637b76319eb9a55ebf11b8f17abf1fc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the reproducibility and generalizability challenges in AI-Generated Content (AIGC) image detection. By reviewing key literature, building a test dataset, and reproducing a detection method, it identifies causes like omitted experimental details and model overfitting. The study concludes that while basic performance can be reproduced, detection fails when preprocessing disrupts key features or when testing across different generators, highlighting the need for better methodological disclosure and robustness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Exploration of Reproducible Generated Image Detection] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Poor Reproducibility & Generalizability]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Literature Review, Dataset Construction, Method Reproduction]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Performance Drops with Preprocessing/Cross-Generator Tests]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Towards Long-window Anchoring in Vision-Language Model Distillation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal training], [knowledge distillation, long-context, rotary position embeddings (RoPE), attention mechanism, vision-language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haoyi Zhou, Shuo Li, Tianyu Chen, Qi Song, Chonghan Gao, Jianxin Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beihang University, Zhongguancun Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21576",children:"https://arxiv.org/pdf/2512.21576"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies the problem of limited effective context windows in small, distilled vision-language models despite using identical positional embeddings and architectures as their larger counterparts. 2. Proposes LAid, a novel distillation method featuring progressive distance-weighted attention matching and learnable RoPE response gain modulation to transfer long-range attention mechanisms. 3. Demonstrates that LAid-distilled models achieve significantly longer effective context windows (up to 3.2x) while maintaining performance on standard benchmarks, and provides spectral analysis showing successful transfer of low-frequency attention components."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4663870a97f8c352e6cd352d0f9f9be365648a5545642796d256fa99c7ddcd4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4663870a97f8c352e6cd352d0f9f9be365648a5545642796d256fa99c7ddcd4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem that small, distilled vision-language models have much shorter effective context windows than their large teacher models. The authors propose LAid, a new distillation method that transfers long-range attention capabilities via progressive attention matching and learnable RoPE modulation. Their method successfully extends the context window of small models by up to 3.2 times while preserving performance on standard benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Towards Long-window Anchoring in Vision-Language Model Distillation] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Small distilled VLMs have limited effective context windows]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: LAid - Progressive attention matching & learnable RoPE modulation]\n    D[\u5173\u952e\u7ed3\u679c/Results: Achieves up to 3.2x longer context, maintains benchmark performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [NeMo Framework, LoRA, Nemotron SLM, hyperparameter sweep, multi-agent system]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ali Sahami, Sudhanshu Garg, Andrew Wang, Chaitanya Kulkarni, Farhad Farahani, Sean Yun-Shiuan Chuang, Jian Wan, Srinivasan Manoharan, Uma Kona, Nitin Sharma, Linsey Pang, Prakhar Mehrotra, Jessica Clark, Mark Moyou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," PayPal AI, NVIDIA"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21578",children:"https://arxiv.org/pdf/2512.21578"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. The first application of NVIDIA's NeMo Framework to optimize commerce-specific agents. 2. An LLM-powered fine-tuning strategy for retrieval-focused commerce tasks. 3. A demonstration of significant latency and cost improvements while maintaining agent quality, providing a scalable framework for multi-agent system optimization in production e-commerce."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90dda98c8c5c5f9d75ede0c681c9024dc5973d432f246b90eed23aad0a03c916_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90dda98c8c5c5f9d75ede0c681c9024dc5973d432f246b90eed23aad0a03c916_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents the optimization of PayPal's Commerce Agent, a multi-agent system, by fine-tuning a Nemotron small language model using NVIDIA's NeMo Framework and LoRA. The method involved systematic hyperparameter sweeps to improve the performance-critical search component. The results show that the fine-tuned model effectively resolves the key latency issue in the retrieval component, which accounted for over 50% of response time, while maintaining or enhancing overall system performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["NEMO-4-PAYPAL: Empowering PayPal\'s Commerce Agent"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["Search Latency/\u641c\u7d22\u5ef6\u8fdf"]\n    P1 --\x3e P2[">50% Response Time/\u8d85\u8fc750%\u54cd\u5e94\u65f6\u95f4"]\n    Method --\x3e M1["Fine-tuning with NeMo/\u4f7f\u7528NeMo\u5fae\u8c03"]\n    M1 --\x3e M2["LoRA on Nemotron SLM/\u5728Nemotron SLM\u4e0a\u4f7f\u7528LoRA"]\n    M2 --\x3e M3["Hyperparameter Sweep/\u8d85\u53c2\u6570\u626b\u63cf"]\n    Results --\x3e R1["Latency & Cost Improvement/\u5ef6\u8fdf\u4e0e\u6210\u672c\u6539\u8fdb"]\n    Results --\x3e R2["Maintained Agent Quality/\u4fdd\u6301\u4ee3\u7406\u8d28\u91cf"]\n    Results --\x3e R3["Scalable Framework/\u53ef\u6269\u5c55\u6846\u67b6"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A Unified Definition of Hallucination, Or: It's the World Model, Stupid"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection & evaluation], [hallucination, world modeling, knowledge conflict, benchmark, language model evaluation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21577",children:"https://arxiv.org/pdf/2512.21577"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Unified Definition of Hallucination / \u5e7b\u89c9\u7684\u7edf\u4e00\u5b9a\u4e49"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root["A Unified Definition of Hallucination / \u5e7b\u89c9\u7684\u7edf\u4e00\u5b9a\u4e49"] --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root["A Unified Definition of Hallucination / \u5e7b\u89c9\u7684\u7edf\u4e00\u5b9a\u4e49"] --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["Hallucination persists in LLMs / \u5e7b\u89c9\u5728LLM\u4e2d\u6301\u7eed\u5b58\u5728"]\n    Method --\x3e M1["Unified definition: inaccurate world modeling / \u7edf\u4e00\u5b9a\u4e49\uff1a\u4e0d\u51c6\u786e\u7684\u4e16\u754c\u5efa\u6a21"]\n    Method --\x3e M2["Framework: reference world & conflict policy / \u6846\u67b6\uff1a\u53c2\u8003\u4e16\u754c\u4e0e\u51b2\u7a81\u7b56\u7565"]\n    Results --\x3e R1["Clarifies evaluation & terminology / \u6f84\u6e05\u8bc4\u4f30\u4e0e\u672f\u8bed"]\n    Results --\x3e R2["Proposes new benchmark plans / \u63d0\u51fa\u65b0\u57fa\u51c6\u8ba1\u5212"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision-language model, logic tree reasoning, medical multimodal diagnosis, explainable AI, LLaVA]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zelin Zang, Wenyi Gu, Siqi Ma, Dan Yang, Yue Shen, Zhu Zhang, Guohui Fan, Wing-Kuen Ling, Fuji Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsientang Institute of Advanced Study (TIAS), Westlake University, Ant Group, China-Japan Friendship Hospital"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21583",children:"https://arxiv.org/pdf/2512.21583"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a diagnostic framework integrating vision-language alignment with logic-regularized reasoning to enhance reliability. 2. Introduces a reasoning controller and logic tree generator to decompose tasks and assemble verifiable conclusions, improving interpretability. 3. Demonstrates improved diagnostic accuracy and more interpretable reasoning traces on multimodal medical benchmarks like MedXpertQA."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b6b8d6d34a614d3cb042f13334dede18494914ca29d6f0fd6f4467f789871f82_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b6b8d6d34a614d3cb042f13334dede18494914ca29d6f0fd6f4467f789871f82_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of unreliable reasoning and hallucinations in existing multimodal medical AI models. It proposes a diagnostic framework built on LLaVA that combines vision-language alignment with logic-regularized reasoning to generate verifiable conclusions via logic trees. Evaluations show the method improves diagnostic accuracy and yields more interpretable reasoning traces, advancing trustworthy multimodal medical AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u533b\u5b66\u591a\u6a21\u6001\u8bca\u65ad\u6846\u67b6<br/>Medical Multimodal Diagnostic Framework] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u6a21\u578b\u5e7b\u89c9\u4e0e\u63a8\u7406\u4e0d\u4e00\u81f4<br/>Existing Models: Hallucinations & Inconsistent Reasoning]\n    C --\x3e C1[\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u5bf9\u9f50\u4e0e\u903b\u8f91\u6811\u63a8\u7406<br/>Vision-Language Alignment + Logic Tree Reasoning]\n    D --\x3e D1[\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027<br/>Improved Diagnostic Accuracy & Interpretability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [item-to-item recommendation, data-centric, long-tail items, data augmentation, data filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yinfu Feng, Yanjing Wu, Rong Xiao, Xiaoyi Zen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21595",children:"https://arxiv.org/pdf/2512.21595"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLM-I2I, a data-centric framework that leverages Large Language Models to enhance I2I recommendation models without altering their architecture. 2. Introduces an LLM-based data generator to synthesize user-item interactions, specifically targeting long-tail items to alleviate data sparsity. 3. Designs an LLM-based data discriminator to filter out noisy interactions from both real and synthetic data, improving overall data quality for training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses data sparsity and noise problems in Item-to-Item (I2I) recommendation systems by proposing LLM-I2I, a data-centric framework that uses an LLM to generate synthetic interactions for long-tail items and filter noisy data. The refined data is then used to train existing I2I models. Experimental results on industrial and academic datasets show significant improvements in recommendation accuracy, especially for long-tail items, and deployment on a large e-commerce platform led to measurable gains in recall and gross merchandise value."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u7a00\u758f\u4e0e\u566a\u58f0/Data Sparsity & Noise]\n    C --\x3e C1[LLM\u6570\u636e\u751f\u6210\u5668/LLM-based Data Generator]\n    C --\x3e C2[LLM\u6570\u636e\u5224\u522b\u5668/LLM-based Data Discriminator]\n    C1 --\x3e C3[\u5408\u6210\u4ea4\u4e92\u6570\u636e/Synthesize Interaction Data]\n    C2 --\x3e C4[\u8fc7\u6ee4\u566a\u58f0\u6570\u636e/Filter Noisy Data]\n    C3 & C4 --\x3e C5[\u878d\u5408\u6570\u636e\u8bad\u7ec3I2I\u6a21\u578b/Fuse Data to Train I2I Model]\n    D --\x3e D1[\u63d0\u5347\u63a8\u8350\u51c6\u786e\u7387/Improves Recommendation Accuracy]\n    D --\x3e D2[\u63d0\u5347\u957f\u5c3e\u7269\u54c1\u6027\u80fd/Better for Long-tail Items]\n    D --\x3e D3[\u7ebf\u4e0a\u6307\u6807\u63d0\u5347/Online Metric Improvements (RN+6.02%, GMV+1.22%)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] AMS-IO-Bench and AMS-IO-Agent: Benchmarking and Structured Reasoning for Analog and Mixed-Signal Integrated Circuit Input/Output Design"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [AMS IC design, LLM-based agent, structured reasoning, design automation, I/O ring generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhishuai Zhang, Xintian Li, Shilong Liu, Aodong Zhang, Lu Jie, Nan Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Princeton University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21613",children:"https://arxiv.org/pdf/2512.21613"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Arcadia-1/AMS-IO-Agent",children:"https://github.com/Arcadia-1/AMS-IO-Agent"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed AMS-IO-Agent, a domain-specialized LLM-based agent for structure-aware I/O subsystem generation in AMS ICs. 2. Introduced AMS-IO-Bench, a benchmark for wirebond-packaged AMS I/O ring automation. 3. Demonstrated the first reported human-agent collaborative AMS IC design where an LLM agent's output was directly used in a silicon tape-out, achieving over 70% DRC+LVS pass rate and reducing design time from hours to minutes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7205181105fdcb012bb4c8c5b3cce6565751edc220003d3784f6dbf648ee893a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7205181105fdcb012bb4c8c5b3cce6565751edc220003d3784f6dbf648ee893a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the labor-intensive and non-reusable nature of analog and mixed-signal (AMS) integrated circuit I/O design by proposing AMS-IO-Agent, an LLM-based agent that uses structured domain knowledge and intent structuring to automate the process. The method connects natural language design intent to industrial deliverables and is evaluated on a new benchmark, AMS-IO-Bench. The agent significantly outperforms baseline LLMs, achieves a high verification pass rate, and its generated I/O ring was successfully fabricated, demonstrating practical effectiveness in real design flows."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AMS-IO-Bench and AMS-IO-Agent<br>\u8bba\u6587\u6807\u9898/Paper Title] --\x3e B[\u624b\u52a8AMS I/O\u8bbe\u8ba1\u8d39\u65f6\u4e14\u4e0d\u53ef\u590d\u7528<br>\u6838\u5fc3\u95ee\u9898/Problem: Manual AMS I/O design is time-consuming and non-reusable]\n    A --\x3e C[\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6<br>\u4e3b\u8981\u65b9\u6cd5/Method: Proposes an LLM-based agent and structured reasoning framework]\n    A --\x3e D[\u9a8c\u8bc1\u901a\u8fc7\u7387>70%\uff0c\u8bbe\u8ba1\u65f6\u95f4\u4ece\u5c0f\u65f6\u51cf\u81f3\u5206\u949f\uff0c\u6210\u529f\u6d41\u7247<br>\u5173\u952e\u7ed3\u679c/Results: >70% pass rate, design time reduced from hours to minutes, successful tape-out]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent platform, knowledge graph, physiologically based pharmacokinetic (PBPK) simulations, autonomous execution, human-in-the-loop]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Takahide Suzuki, Kazuki Nakanishi, Takashi Fujiwara, Hideyuki Shimizu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Science Tokyo, Kyoto University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21623",children:"https://arxiv.org/pdf/2512.21623"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine for drug design. 2. Features an architecture with specialized agents (Biologist, Chemist, Pharmacologist) governed by an Orchestrator, which actively execute simulations and reason over results to create a dynamic feedback loop for iterative optimization. 3. Democratizes therapeutic design by transforming drug discovery from a stochastic search into a programmable, evidence-based engineering discipline through the integration of autonomous execution with human guidance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbd4a841925fb9129111928c81fe29ac7016c26df168e9b4ca87c8782a692d5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbd4a841925fb9129111928c81fe29ac7016c26df168e9b4ca87c8782a692d5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of fragmented and passive tools in therapeutic discovery by proposing OrchestRA, a multi-agent platform where specialized AI agents autonomously execute and reason over biological, chemical, and pharmacological tasks. This creates a dynamic feedback loop for iterative drug candidate optimization, guided by human input. The conclusion is that this approach transforms drug discovery into a more programmable and evidence-based engineering process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Fragmented domains & execution gap<br>AI as passive assistants]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>OrchestRA Multi-Agent Platform<br>Agents execute & reason<br>Human-in-the-loop]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Autonomous discovery engine<br>Dynamic feedback loop<br>Programmable evidence-based design]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-armed bandits], [multiple-play bandits, prioritized resource sharing, regret analysis, combinatorial optimization, UCB]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hong Xie, Haoran Gu, Yanying Huang, Tao Tan, Defu Lian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, Chongqing University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21626",children:"https://arxiv.org/pdf/2512.21626"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new variant of the multiple-play stochastic bandit model (MSB-PRS) that incorporates prioritized capacity sharing among plays, tailored for resource allocation in LLM and edge intelligence applications. 2. Establishes instance-independent and instance-dependent regret lower bounds for the proposed model, characterizing its fundamental learning difficulty. 3. Designs an offline optimal policy solver (MSB-PRS-OffOpt) and an online UCB-based learning algorithm with theoretical regret guarantees that nearly match the derived lower bounds."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8562089dc3d9fa0a65e8caf8921b51648e1718efd62395a7af2fadba8cf952d9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8562089dc3d9fa0a65e8caf8921b51648e1718efd62395a7af2fadba8cf952d9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a new multi-armed bandit model where multiple plays with priorities compete for the stochastic capacity of arms. The authors design an algorithm that first computes an optimal allocation offline and then uses it within an online UCB-based strategy, proving that its regret nearly matches the fundamental lower bounds they establish for this problem."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing<br/>\u591a\u81c2\u8001\u864e\u673a\u4f18\u5148\u5bb9\u91cf\u5171\u4eab"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Prioritized resource allocation in LLM/edge intelligence<br/>LLM/\u8fb9\u7f18\u667a\u80fd\u4e2d\u7684\u4f18\u5148\u8d44\u6e90\u5206\u914d"] --\x3e P1["\u6a21\u578b/Model<br/>M arms, K plays, stochastic capacity, priority weights<br/>M\u4e2a\u81c2\uff0cK\u4e2a\u73a9\u5bb6\uff0c\u968f\u673a\u5bb9\u91cf\uff0c\u4f18\u5148\u7ea7\u6743\u91cd"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Algorithm Design<br/>\u7b97\u6cd5\u8bbe\u8ba1"] --\x3e M1["\u79bb\u7ebf\u6700\u4f18\u6c42\u89e3\u5668/MSB-PRS-OffOpt<br/>Computes optimal policy<br/>\u8ba1\u7b97\u6700\u4f18\u7b56\u7565"]\n    Method --\x3e M2["\u5728\u7ebfUCB\u7b97\u6cd5/Online UCB Algorithm<br/>Uses offline solver as subroutine<br/>\u4ee5\u79bb\u7ebf\u6c42\u89e3\u5668\u4e3a\u5b50\u7a0b\u5e8f"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Theoretical Analysis<br/>\u7406\u8bba\u5206\u6790"] --\x3e R1["\u4e0b\u754c/Regret Lower Bounds<br/>\u03a9(\u03b1\u2081\u03c3\u221aKMT), \u03a9(\u03b1\u2081\u03c3\xb2(M/\u0394)lnT)"]\n    Results --\x3e R2["\u4e0a\u754c/Regret Upper Bounds<br/>Matching lower bounds up to factors<br/>\u4e0e\u4e0b\u754c\u5339\u914d\uff08\u5dee\u56e0\u5b50\uff09"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maximilian Weichart"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Regensburg"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21648",children:"https://arxiv.org/pdf/2512.21648"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Max-We/inverse-rpo",children:"https://github.com/Max-We/inverse-rpo"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Variance-Aware Prior-Based Tree Policies for MCTS] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Extending prior-based UCTs from other UCBs is challenging]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]\n    D[\u5173\u952e\u7ed3\u679c/Results: New policies outperform PUCT without extra cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] TrackTeller: Temporal Multimodal 3D Grounding for Behavior-Dependent Object References"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D object grounding], [temporal multimodal grounding, LiDAR-image fusion, language-conditioned decoding, UniScene representation, NuPrompt benchmark]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiahong Yu, Ziqi Wang, Hailiang Zhao, Wei Zhai, Xueqiang Yan, Shuiguang Deng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Fudan University, Huawei Technologies Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21641",children:"https://arxiv.org/pdf/2512.21641"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TrackTeller, a unified temporal multimodal framework for 3D grounding that integrates LiDAR-image fusion, language-conditioned decoding, and temporal reasoning. 2. Introduces a shared UniScene representation aligned with textual semantics to generate language-aware 3D proposals. 3. Demonstrates significant performance improvements on the NuPrompt benchmark, including a 70% relative gain in Average Multi-Object Tracking Accuracy and a 3.15-3.4x reduction in False Alarm Frequency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc60054c622874cc83217afc715702b65eb56126f722620ffb7004f46ebe296d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc60054c622874cc83217afc715702b65eb56126f722620ffb7004f46ebe296d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of grounding natural language references to objects in dynamic 3D driving scenes, which often depend on recent motion or behavior. The authors propose TrackTeller, a framework that fuses LiDAR and camera data with language, builds a unified scene representation, and uses temporal reasoning to refine object identification. Experiments show that TrackTeller significantly outperforms existing baselines in language-grounded tracking accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[TrackTeller: Temporal Multimodal 3D Grounding] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u52a8\u60013D\u573a\u666f\u4e2d\u7684\u884c\u4e3a\u4f9d\u8d56\u8bed\u8a00\u6307\u4ee3/Dynamic 3D Behavior-Dependent Language Grounding]\n    C --\x3e C1[\u7edf\u4e00\u591a\u6a21\u6001\u65f6\u5e8f\u6846\u67b6/Unified Temporal Multimodal Framework]\n    C1 --\x3e C2[LiDAR-\u56fe\u50cf\u878d\u5408\u4e0e\u8bed\u8a00\u89e3\u7801/LiDAR-Image Fusion & Language Decoding]\n    C1 --\x3e C3[\u6784\u5efaUniScene\u8868\u793a/Build UniScene Representation]\n    C1 --\x3e C4[\u5229\u7528\u8fd0\u52a8\u5386\u53f2\u63a8\u7406/Reason with Motion History]\n    D --\x3e D1[\u5728NuPrompt\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd/Significant Improvement on NuPrompt]\n    D1 --\x3e D2[AMOTA\u63d0\u534770%/70% AMOTA Gain]\n    D1 --\x3e D3[\u8bef\u62a5\u7387\u964d\u4f4e3.15-3.4\u500d/3.15-3.4x FA Reduction]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Near-Optimal Coalition Structures in Polynomial Time"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [cooperative game theory], [coalition structure generation, anytime algorithms, sparse relaxations, dynamic programming, MILP]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Angshul Majumdar"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Indraprastha Institute of Information Technology, Delhi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21657",children:"https://arxiv.org/pdf/2512.21657"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proves that under a "sparse synergy" model, sparse relaxation methods can find near-optimal coalition structures in polynomial time with high probability. 2. Demonstrates that broad classes of dynamic programming and MILP algorithms require exponential time to achieve comparable solution quality. 3. Establishes a rigorous probabilistic anytime performance separation favoring sparse relaxations over exact methods for the CSG problem.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb8e459bba93eeaf4c9237729ad06cf13b47ef6a941811135ed634157dd979c7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb8e459bba93eeaf4c9237729ad06cf13b47ef6a941811135ed634157dd979c7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the coalition structure generation (CSG) problem. It compares three algorithmic paradigms and proves that, under a random sparse synergy model, sparse relaxation methods can find near-optimal solutions in polynomial time, while exact methods like DP and MILP require exponential time to reach similar quality, establishing a clear anytime performance advantage for the sparse approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Near-Optimal Coalition Structures in Polynomial Time] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Coalition Structure Generation (CSG)]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Compare DP, MILP, and Sparse Relaxations]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Sparse relaxations achieve near-optimal welfare in polynomial time; DP/MILP require exponential time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [swarm intelligence], [Ant Colony Optimization, structural prior, load-aware objective, overlap suppression, multi-robot path planning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zikun Guo, Adeyinka P. Adedigba, Rammohan Mallipeddi, Heoncheol Lee"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kyungpook National University, Kumoh National Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21654",children:"https://arxiv.org/pdf/2512.21654"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a structure-induced exploration framework that integrates structural priors into ACO initialization to constrain the search space. 2. Designs a pheromone update rule that emphasizes structurally meaningful connections and incorporates a load-aware objective to balance total travel distance with individual robot workload. 3. Introduces an explicit overlap suppression strategy to ensure distinct and balanced task allocation across the robot team."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca4635b64758650f78e762004770f2a7ac8eb62cd36aa2db98d90af82d3f6eae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca4635b64758650f78e762004770f2a7ac8eb62cd36aa2db98d90af82d3f6eae_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of scalable and balanced multi-robot path planning. It proposes a new framework that integrates structural priors into Ant Colony Optimization, along with a load-aware objective and overlap suppression, to improve route compactness, stability, and workload distribution. The method demonstrates consistent improvements over metaheuristic baselines and offers a scalable solution for applications like logistics and search-and-rescue."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Structural Induced Exploration for Balanced and Scalable Multi-Robot Path Planning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Multi-robot path planning is combinatorially complex and requires balancing global efficiency with fair task allocation. \u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55/Traditional methods struggle to scale.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: A structure-induced ACO framework. \u5229\u7528\u7ed3\u6784\u5148\u9a8c\u3001\u8d1f\u8f7d\u611f\u77e5\u76ee\u6807\u548c\u91cd\u53e0\u6291\u5236/Uses structural prior, load-aware objective, and overlap suppression.]\n    D[\u5173\u952e\u7ed3\u679c/Results: Improves route compactness, stability, and workload distribution. \u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u6846\u67b6/Provides a scalable framework.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [YOLO-NAS, YOLOv8, perception, autonomous vehicles, custom dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jalal Khan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," United Arab Emirates University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21673",children:"https://arxiv.org/pdf/2512.21673"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a comparative performance analysis of two emerging deep learning models, YOLO-NAS and YOLOv8, for object detection in autonomous vehicle perception. 2. Created and utilized a custom dataset to evaluate the models under real-world use case scenarios. 3. Provided empirical results showing YOLOv8s offers a 75% reduction in training time and a 2% higher object detection accuracy (83% vs 81%) compared to YOLO-NAS."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a67f4b1902039d3a0f1a96acadea1a1625b1870da583b146bb58337f3c0561_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a67f4b1902039d3a0f1a96acadea1a1625b1870da583b146bb58337f3c0561_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper compares the performance of YOLO-NAS and YOLOv8 deep learning models for object detection in autonomous vehicle perception using a custom dataset. The analysis finds that the YOLOv8s model is significantly faster to train and achieves slightly higher detection accuracy than the YOLO-NAS model."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Comparative Analysis of Deep Learning Models for Perception in Autonomous Vehicles] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[\u8bc4\u4f30\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6027\u80fd/Evaluate DL model performance for AV perception]\nC --\x3e C1[\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u6bd4\u8f83YOLO-NAS\u4e0eYOLOv8/Compare YOLO-NAS and YOLOv8 using a custom dataset]\nD --\x3e D1[YOLOv8s\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1175%/YOLOv8s saves 75% training time]\nD --\x3e D2[YOLOv8s\u51c6\u786e\u7387\u66f4\u9ad8(83% vs 81%)/YOLOv8s has higher accuracy (83% vs 81%)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [spatiotemporal forecasting], [probabilistic forecasting, uncertainty estimation, principal component analysis, road impedance, traffic flow]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haochen Lv, Yan Lin, Shengnan Guo, Xiaowei Mao, Hong Nie, Letian Gong, Youfang Lin, Huaiyu Wan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beijing Jiaotong University, Aalborg University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21685",children:"https://arxiv.org/pdf/2512.21685"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a dynamic impedance evolution network to model directional traffic transfer patterns driven by congestion and flow variability, revealing causes of uncertainty and enhancing reliability and interpretability. 2. Designs a principal component network to forecast the dominant eigenvectors of future flow covariance, enabling the capture of spatiotemporal uncertainty correlations. 3. Integrates domain-specific transportation theory with spatiotemporal principal component learning for probabilistic traffic flow forecasting, achieving superior performance over existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f835b2051524d67481fbf9f4479086a541b29307c2876046f2c3ee4eec60f92_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f835b2051524d67481fbf9f4479086a541b29307c2876046f2c3ee4eec60f92_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes RIPCN, a Road Impedance Principal Component Network for probabilistic traffic flow forecasting. It integrates transportation theory with principal component learning to model the causes of uncertainty and capture spatiotemporal uncertainty correlations. Experimental results show it outperforms existing probabilistic forecasting methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RIPCN: A Road Impedance Principal Component Network for Probabilistic Traffic Flow Forecasting] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1(\u5982\u4f55\u5efa\u6a21\u4ea4\u901a\u6d41\u4e0d\u786e\u5b9a\u6027\u7684\u6210\u56e0? / How to model the causes of traffic flow uncertainty?)\n    B --\x3e B2(\u5982\u4f55\u6355\u6349\u4e0d\u786e\u5b9a\u6027\u7684\u65f6\u7a7a\u76f8\u5173\u6027? / How to capture spatiotemporal correlations of uncertainty?)\n    C --\x3e C1(\u52a8\u6001\u963b\u6297\u6f14\u5316\u7f51\u7edc / Dynamic Impedance Evolution Network)\n    C --\x3e C2(\u4e3b\u6210\u5206\u7f51\u7edc / Principal Component Network)\n    D --\x3e D1(\u8d85\u8d8a\u73b0\u6709\u6982\u7387\u9884\u6d4b\u65b9\u6cd5 / Outperforms existing probabilistic forecasting methods)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] BeHGAN: Bengali Handwritten Word Generation from Plain Text Using Generative Adversarial Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [handwritten text generation], [Generative Adversarial Networks, Handwritten Text Generation, Bengali, Dataset, Pre-processing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md. Rakibul Islam, Md. Kamrozzaman Bhuiyan, Safwan Muntasir, Arifur Rahman Jawad, Most. Sharmin Sultana Samu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided text. Affiliation/domain cannot be reliably inferred."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21694",children:"https://arxiv.org/pdf/2512.21694"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a method for generating Bengali handwritten words from plain text using GANs, addressing a significant research gap. 2. Developed and used a novel, self-collected dataset of Bengali handwriting from approximately 500 diverse individuals. 3. Demonstrated the ability to produce diverse and realistic handwritten outputs through the described approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8b36b4afe805283b88409b54815e1bd251762075786246ae741c57cb65c191a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8b36b4afe805283b88409b54815e1bd251762075786246ae741c57cb65c191a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of research on Bengali handwritten text generation by proposing a GAN-based method to generate words from plain text. The authors created a new dataset of Bengali handwriting samples from hundreds of contributors. The work successfully generates diverse handwritten outputs and contributes to advancing research in this area for the Bengali language."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BeHGAN: Bengali Handwritten Word Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[HTG is challenging & understudied for Bengali<br/>\u5b5f\u52a0\u62c9\u8bed\u624b\u5199\u6587\u672c\u751f\u6210\u7814\u7a76\u4e0d\u8db3\u4e14\u56f0\u96be]\n    C --\x3e C1[Propose GAN-based method<br/>\u63d0\u51fa\u57fa\u4e8eGAN\u7684\u65b9\u6cd5]\n    C --\x3e C2[Use self-collected dataset<br/>\u4f7f\u7528\u81ea\u6536\u96c6\u6570\u636e\u96c6]\n    C --\x3e C3[Pre-process images<br/>\u9884\u5904\u7406\u56fe\u50cf]\n    D --\x3e D1[Generates diverse handwritten words<br/>\u751f\u6210\u591a\u6837\u5316\u624b\u5199\u8bcd]\n    D --\x3e D2[Contributes to Bengali HTG research<br/>\u63a8\u52a8\u5b5f\u52a0\u62c9\u8bed\u624b\u5199\u6587\u672c\u751f\u6210\u7814\u7a76]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [agentic AI, consensus-driven reasoning, explainable AI, responsible AI, multi-model governance]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Eranga Bandara, Tharaka Hewa, Ross Gore, Sachin Shetty, Ravi Mukkamala, Peter Foytik, Abdul Rahman, Safdar H. Bouk, Xueping Liang, Amin Hass, Sachini Rajapakse, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Old Dominion University, University of Oulu, Deloitte & Touche LLP, Florida International University, Nanyang Technological University, University of Colombo, IcicleLabs.AI, Accenture Technology Labs, Effectz.AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21699",children:"https://arxiv.org/pdf/2512.21699"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel RAI/XAI agent architecture for production workflows based on multi-model consensus and reasoning-layer governance. 2. Introduces a mechanism where a consortium of heterogeneous LLM/VLM agents generate independent outputs, exposing uncertainty and alternatives for structured consolidation. 3. Demonstrates that the consensus-driven approach improves robustness, transparency, and operational trust across diverse real-world agentic AI workflows."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed22161f8f004c98e3fb6124bac7991548de5e54f47adb42f0d3eb1095409e6e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed22161f8f004c98e3fb6124bac7991548de5e54f47adb42f0d3eb1095409e6e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of explainability and responsibility in increasingly autonomous agentic AI systems. It proposes a new architecture where multiple AI agents generate candidate outputs, and a dedicated reasoning agent consolidates them while enforcing safety constraints, thereby improving decision robustness and auditability. The work provides a practical framework for building agentic systems that are both scalable and responsible by design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Agentic AI lacks explainability & responsibility] --\x3e B1[\u6311\u6218/Challenges<br>Explainability, Accountability, Robustness, Governance]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Multi-model Consensus & Reasoning-layer Governance] --\x3e C1[\u67b6\u6784/Architecture<br>Consortium of LLM/VLM Agents]\n    C --\x3e C2[\u8fc7\u7a0b/Process<br>Structured Consolidation by Dedicated Reasoning Agent]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Improved Robustness, Transparency & Operational Trust]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [audio deepfake detection], [transfer learning, zero-shot inference, fine-tuning, Bengali audio, BanglaFake dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Most. Sharmin Sultana Samu, Md. Rakibul Islam, Md. Zahid Hossain, Md. Kamrozzaman Bhuiyan, Farhad Uz Zaman"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in the provided content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21702",children:"https://arxiv.org/pdf/2512.21702"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducts the first systematic benchmark for Bengali deepfake audio detection using the BanglaFake dataset. 2. Evaluates and demonstrates the limited performance of multiple pre-trained models in a zero-shot setting for this task. 3. Shows that fine-tuning deep learning models (e.g., ResNet18) significantly improves detection performance, establishing an effective approach for low-resource languages."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66eab5318a9b87f6facd46827f1723103def2a66467b77d3a3f1b6ea7a41d92f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66eab5318a9b87f6facd46827f1723103def2a66467b77d3a3f1b6ea7a41d92f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the underexplored problem of Bengali deepfake audio detection. It first evaluates several pre-trained models using zero-shot inference, finding limited performance, and then fine-tunes various architectures, with ResNet18 achieving the best results. The study concludes that fine-tuning is crucial for effective deepfake detection in low-resource languages like Bengali."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Zero-Shot to Zero-Lies: Detecting Bengali Deepfake Audio through Transfer Learning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Bengali Deepfake Audio Detection is unexplored)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Zero-shot inference & Fine-tuning of pre-trained models)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Fine-tuned ResNet18 achieves best performance (79.17% accuracy))"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [spoken dialogue systems], [Graph-of-Thoughts, full-duplex, speech acts, causal inference, multimodal transformer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, University of California, Berkeley, Carnegie Mellon University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21706",children:"https://arxiv.org/pdf/2512.21706"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://got-duplex.github.io/",children:"https://got-duplex.github.io/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Enabling Conversational Behavior Reasoning in Full-Duplex Speech<br/>\u5b9e\u73b0\u5168\u53cc\u5de5\u8bed\u97f3\u5bf9\u8bdd\u884c\u4e3a\u63a8\u7406"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Current systems lack explicit reasoning for conversational behaviors."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Model reasoning as causal inference in a Graph-of-Thoughts (GoT)."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Robust behavior detection and interpretable reasoning chains."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [ai-generated text detection], [transformer, fine-tuning, zero-shot, Bengali, paraphrase detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not specified in provided content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21709",children:"https://arxiv.org/pdf/2512.21709"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Detecting AI-Generated Paraphrases in Bengali] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM misuse & lack of Bengali detection research]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Compare 5 transformers (Zero-Shot vs. Fine-Tuned)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Fine-tuning needed; XLM-R, mDeBERTa, mBERT achieve ~91% accuracy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [interpretability & analysis], [latent tokens, chain-of-thought, model reliability, causal analysis, shortcut learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21711",children:"https://arxiv.org/pdf/2512.21711"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces "Steering Experiments" to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts "Shortcut Experiments" to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a "pseudo-reasoning" mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Latent token mechanisms unclear, reliability concerns] --\x3e B1[\u6f5c\u5728\u4ee4\u724c\u673a\u5236\u4e0d\u660e\u786e/Unclear latent token mechanisms]\n    B --\x3e B2[\u53ef\u9760\u6027\u95ee\u9898/Reliability concerns]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Causal & adversarial analysis] --\x3e C1[\u5f15\u5bfc\u5b9e\u9a8c/Steering experiments]\n    C --\x3e C2[\u6377\u5f84\u5b9e\u9a8c/Shortcut experiments]\n    D[\u5173\u952e\u7ed3\u679c/Results: COCONUT is pseudo-reasoning] --\x3e D1[\u4ee4\u724c\u5bf9\u6270\u52a8\u4e0d\u654f\u611f/Tokens insensitive to perturbation]\n    D --\x3e D2[\u5229\u7528\u6570\u636e\u96c6\u6377\u5f84/Exploits dataset shortcuts]\n    D --\x3e D3[\u6027\u80fd\u63d0\u5347\u4e0d\u57fa\u4e8e\u771f\u5b9e\u63a8\u7406/Performance gains not from true reasoning]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kyung Hee University, Ghent University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21717",children:"https://arxiv.org/pdf/2512.21717"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [dialogue systems], [theme detection, topic clustering, hierarchical generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21715",children:"https://arxiv.org/pdf/2512.21715"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[CATCH: \u53ef\u63a7\u4e3b\u9898\u68c0\u6d4b\u6846\u67b6 / Controllable Theme Detection Framework] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898 / Problem] --\x3e P1[\u77ed\u8bdd\u8bed\u7a00\u758f\u8bed\u4e49 / Sparse, short utterances]\n    Problem --\x3e P2[\u8de8\u5bf9\u8bdd\u4e3b\u9898\u5bf9\u9f50 / Cross-dialogue theme alignment]\n    Problem --\x3e P3[\u7528\u6237\u504f\u597d\u6574\u5408 / Personalized user preferences]\n    Method[\u4e3b\u8981\u65b9\u6cd5 / Method] --\x3e M1[\u4e0a\u4e0b\u6587\u611f\u77e5\u4e3b\u9898\u8868\u793a / Context-aware topic representation]\n    Method --\x3e M2[\u504f\u597d\u5f15\u5bfc\u4e3b\u9898\u805a\u7c7b / Preference-guided topic clustering]\n    Method --\x3e M3[\u5206\u5c42\u4e3b\u9898\u751f\u6210 / Hierarchical theme generation]\n    Results[\u5173\u952e\u7ed3\u679c / Results] --\x3e R1[\u5728DSTC-12\u57fa\u51c6\u6d4b\u8bd5\u6709\u6548 / Effective on DSTC-12 benchmark]\n    Results --\x3e R2[\u63d0\u5347\u805a\u7c7b\u4e0e\u751f\u6210\u8d28\u91cf / Improved clustering & generation quality with 8B LLM]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] An Information Theoretic Perspective on Agentic System Design"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [mutual information, noisy channel, compressor-predictor, on-device AI, information-theoretic]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher R\xe9, Dan Biderman"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21720",children:"https://arxiv.org/pdf/2512.21720"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[An Information Theoretic Perspective on Agentic System Design] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1("Agentic\u7cfb\u7edf\u8bbe\u8ba1\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc<br/>Agentic system design lacks theoretical guidance")\n    C --\x3e C1("\u63d0\u51fa\u4fe1\u606f\u8bba\u6846\u67b6\u4e0e\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668<br/>Propose information-theoretic framework & mutual information estimator")\n    D --\x3e D1("\u66f4\u5927\u538b\u7f29\u5668\u66f4\u9ad8\u6548\u3001\u66f4\u51c6\u786e<br/>Larger compressors are more efficient and accurate")\n    D --\x3e D2("\u6269\u5c55\u538b\u7f29\u5668\u4f18\u4e8e\u6269\u5c55\u9884\u6d4b\u5668<br/>Scaling compressors outperforms scaling predictors")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] HELP: Hierarchical Embodied Language Planner for Household Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [embodied agent, hierarchical planning, large language model, household tasks, open source LLM]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alexandr V. Korchemnyi, Anatoly O. Onishchenko, Eva A. Bakaeva, Alexey K. Kovalev, Aleksandr I. Panov"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," MIRAI, Cognitive AI Systems Lab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21723",children:"https://arxiv.org/pdf/2512.21723"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Hierarchical Embodied Language Planner (HELP) architecture using multiple LLM-based agents for decomposing and grounding natural language instructions. 2. Demonstrates the approach on a real-world household task using an embodied agent. 3. Focuses on the use of relatively small, open-source LLMs to enable autonomous deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d5e8ef0910254268525eec44918d2562afe5a6df81ece96ba720311313fef5b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of planning for embodied agents following ambiguous natural language instructions in complex environments. It proposes HELP, a hierarchical planner using multiple LLM-based agents to decompose high-level instructions into grounded, executable subtasks. The method is evaluated on a household task with a real robot, showing the feasibility of using smaller, open-source LLMs for autonomous operation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HELP: Hierarchical Embodied Language Planner for Household Tasks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Embodied agents need robust planning for ambiguous natural language instructions in complex environments.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Hierarchical planner with multiple LLM-based agents to decompose and ground instructions into executable steps.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Evaluated on real-world household task; demonstrates use of smaller open-source LLMs for autonomous deployment.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A Model of Causal Explanation on Neural Networks for Tabular Data"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [explainable ai], [CENNET, structural causal models, entropy, causal explanation, tabular data]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Takashi Isozaki, Masahiro Yamamoto, Atsushi Noda"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sony Computer Science Laboratories, Inc., Sony Corporation of America"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21746",children:"https://arxiv.org/pdf/2512.21746"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CENNET, a novel causal explanation method for neural network predictions on tabular data. 2. Introduces a new explanation power index based on entropy for evaluating the proposed method. 3. Demonstrates the method's effectiveness by combining structural causal models with neural networks for causal explanations, validated on synthetic and quasi-real data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02e8ba8968728eba560984773ed8ba2b124e42c46e3c839dec8a1ca2a5975ce1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02e8ba8968728eba560984773ed8ba2b124e42c46e3c839dec8a1ca2a5975ce1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of providing causal explanations for neural network predictions on tabular data, where pseudo-correlations can mislead. The authors propose a method called CENNET, which integrates structural causal models with neural networks to generate causal explanations and introduces an entropy-based index to measure explanation power. Experiments on synthetic and quasi-real data show that CENNET effectively provides causal explanations compared to existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A Model of Causal Explanation on Neural Networks for Tabular Data] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Explaining NN predictions on tabular data, addressing pseudo-correlation and causality]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose CENNET, a causal explanation method using SCMs and an entropy-based index]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: CENNET provides causal explanations, validated via comparative experiments]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huiyun Peng, Antonio Zhong, Ricardo Andr\xe9s Calvo M\xe9ndez, Kelechi G. Kalu, James C. Davis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Purdue University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21757",children:"https://arxiv.org/pdf/2512.21757"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[How Do Agents Perform Code Optimization? An Empirical Study] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network for Multimodal Liver Tumor Segmentation from Unpaired Datasets"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image segmentation], [Quaternion Neural Networks, Cross-Attention, Unpaired Data, Multimodal Learning, Explainable AI]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Arunkumar V, Firos V M, Senthilkumar S, Gangadharan G R"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Anna University, National Institute of Technology Tiruchirappalli"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21760",children:"https://arxiv.org/pdf/2512.21760"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an Adaptive Quaternion Cross-Fusion (A-QCF) block for bidirectional knowledge transfer between unpaired CT and MRI data streams., 2. Introduces a unified segmentation model (A-QCF-Net) that leverages Quaternion Neural Networks to build a shared feature space from separate datasets., 3. Demonstrates significant performance gains over strong unimodal baselines and validates clinical relevance through explainability analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebec19949c3fad65f84d0acee71e271ec2d8caca288cc4ecf24768e9533dbbe8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebec19949c3fad65f84d0acee71e271ec2d8caca288cc4ecf24768e9533dbbe8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of training multimodal segmentation models with unpaired datasets. It proposes A-QCF-Net, which uses Quaternion Neural Networks and an adaptive cross-fusion block to enable knowledge transfer between separate CT and MRI data. The method significantly outperforms unimodal baselines and provides a viable paradigm for leveraging large, unpaired medical image archives."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network<br>for Multimodal Liver Tumor Segmentation from Unpaired Datasets] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Scarcity of paired & aligned multimodal medical datasets]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Adaptive Quaternion Cross-Fusion (A-QCF) block<br>Quaternion Neural Networks for shared feature space]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Significant Dice score improvement over nnU-Net<br>Validated by explainability analysis]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [Data Provenance], [Data Provenance, Compliance Rating, Generative AI, Dataset Ethics, Transparency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Matyas Bohacek, Ignacio Vilanova Echavarri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University, Imperial College London"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21775",children:"https://arxiv.org/pdf/2512.21775"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u6570\u636e\u96c6\u521b\u5efa\u7f3a\u4e4f\u4f26\u7406\u4e0e\u6cd5\u5f8b\u76d1\u7763/Lack of ethical & legal oversight in dataset creation")\n    Problem --\x3e P2("\u6570\u636e\u6765\u6e90\u4e0e\u5408\u6cd5\u6027\u4fe1\u606f\u4e22\u5931/Loss of data origin & legitimacy info")\n    Method --\x3e M1("\u63d0\u51fa\u5408\u89c4\u8bc4\u7ea7\u65b9\u6848(CRS)\u6846\u67b6/Propose Compliance Rating Scheme (CRS) framework")\n    Method --\x3e M2("\u5f00\u53d1\u57fa\u4e8e\u6570\u636e\u6eaf\u6e90\u6280\u672f\u7684\u5f00\u6e90\u5e93/Develop open-source library using data provenance")\n    Results --\x3e R1("\u8bc4\u4f30\u73b0\u6709\u6570\u636e\u96c6\u7684\u5408\u89c4\u6027/Evaluate compliance of existing datasets")\n    Results --\x3e R2("\u6307\u5bfc\u8d1f\u8d23\u4efb\u7684\u65b0\u6570\u636e\u96c6\u6784\u5efa/Guide responsible construction of new datasets")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Inference-based GAN Video Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video generation], [VAE-GAN, Markov chain, long video generation, temporal consistency, encoder-decoder]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jingbo Yang, Adrian G. Bors"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of York"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21776",children:"https://arxiv.org/pdf/2512.21776"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new video generator, Encoder GAN3 (EncGAN3), which is a VAE-GAN hybrid structure that incorporates inference capabilities into an adversarial-based unconditional video generator. 2. Introduces a novel, memory-efficient approach to generate long videos (hundreds/thousands of frames) by extending the base VAE-GAN model. 3. Leverages a Markov chain framework with a recall mechanism, where each state is a short VAE-GAN generator, to sequentially connect video sub-sequences and ensure temporal continuity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5d6cd59a07e4478b6b21e586a92b15f90e237037b758a29738bf31e46f9843c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5d6cd59a07e4478b6b21e586a92b15f90e237037b758a29738bf31e46f9843c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating long, high-quality videos, a task where existing models suffer from quality degradation. The proposed method first introduces a VAE-GAN hybrid video generator (EncGAN3) and then extends it using a Markov chain framework to sequentially generate short video clips, enabling the creation of temporally consistent long videos. The main conclusion is that this approach overcomes the temporal scaling limitation and allows for memory-efficient generation of long video sequences."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Inference-based GAN Video Generation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u751f\u6210\u957f\u89c6\u9891/Existing models struggle with long video generation]\n    P1 --\x3e P2[\u89c6\u9891\u957f\u5ea6\u589e\u52a0\u5bfc\u81f4\u8d28\u91cf\u4e0b\u964d/Increased length degrades quality]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u63d0\u51faVAE-GAN\u6df7\u5408\u89c6\u9891\u751f\u6210\u5668/Propose VAE-GAN hybrid video generator]\n    M1 --\x3e M2[\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u6846\u67b6\u6269\u5c55/Extend with Markov chain framework]\n    M2 --\x3e M3[\u72b6\u6001\u4ee3\u8868\u77ed\u89c6\u9891\u751f\u6210\u5668/Each state is a short video generator]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u80fd\u591f\u751f\u6210\u957f\u89c6\u9891\u5e8f\u5217/Can generate long video sequences]\n    R1 --\x3e R2[\u786e\u4fdd\u65f6\u5e8f\u8fde\u7eed\u6027\u4e0e\u4e00\u81f4\u6027/Ensures temporal continuity and consistency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Accelerating Scientific Discovery with Autonomous Goal-evolving Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [scientific discovery agents], [autonomous goal evolution, bi-level optimization, LLM agents, objective function design, scientific discovery]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuanqi Du, Botao Yu, Tianyu Liu, Tony Shen, Junwu Chen, Jan G. Rittig, Kunyang Sun, Yikun Zhang, Zhangde Song, Bo Zhou, Cassandra Masschelein, Yingze Wang, Haorui Wang, Haojun Jia, Chao Zhang, Hongyu Zhao, Martin Ester, Teresa Head-Gordon, Carla P. Gomes, Huan Sun, Chenru Duan, Philippe Schwaller, Wengong Jin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Cornell University, The Ohio State University, Yale University, Simon Fraser University, \xc9cole Polytechnique F\xe9d\xe9rale de Lausanne, University of California Berkeley, Northeastern University, Deep Principle, University of Illinois Chicago, Georgia Institute of Technology, Broad Institute of MIT and Harvard"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21782",children:"https://arxiv.org/pdf/2512.21782"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and addresses the unmet requirement of automating objective function design for scientific discovery agents, moving beyond fixed, imperfect proxies. 2. Proposes the SAGA framework, a novel bi-level architecture where an outer loop of LLM agents evolves objectives and an inner loop optimizes solutions under them. 3. Demonstrates the framework's effectiveness across diverse scientific domains (antibiotic, materials, DNA, chemical process design), showing improved discovery outcomes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9035dcf8fd16c34c235e39c8960c63fa826c45df283663a01722181f7ab419d8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9035dcf8fd16c34c235e39c8960c63fa826c45df283663a01722181f7ab419d8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces SAGA, a framework for scientific discovery where LLM agents autonomously evolve and refine the objective functions used to guide optimization, rather than relying on fixed human-specified goals. This bi-level architecture enables systematic exploration of objective spaces and their trade-offs. The method is shown to substantially improve the effectiveness of discovery agents across multiple application domains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Accelerating Scientific Discovery with Autonomous Goal-evolving Agents] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Fixed objectives are imperfect proxies for grand scientific challenges / \u56fa\u5b9a\u7684\u76ee\u6807\u51fd\u6570\u662f\u79d1\u5b66\u91cd\u5927\u6311\u6218\u7684\u4e0d\u5b8c\u7f8e\u4ee3\u7406]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Proposes SAGA: Scientific Autonomous Goal-evolving Agent / \u63d0\u51faSAGA: \u79d1\u5b66\u81ea\u4e3b\u76ee\u6807\u6f14\u5316\u667a\u80fd\u4f53]\n    M1 --\x3e M2[Bi-level architecture: LLM outer loop evolves objectives, inner loop optimizes solutions / \u53cc\u5c42\u67b6\u6784: LLM\u5916\u5faa\u73af\u6f14\u5316\u76ee\u6807\uff0c\u5185\u5faa\u73af\u4f18\u5316\u89e3]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Applied to antibiotic, materials, DNA, chemical process design / \u5e94\u7528\u4e8e\u6297\u751f\u7d20\u3001\u6750\u6599\u3001DNA\u3001\u5316\u5de5\u8fc7\u7a0b\u8bbe\u8ba1]\n    R1 --\x3e R2[Automating objective formulation improves discovery effectiveness / \u81ea\u52a8\u5316\u76ee\u6807\u5236\u5b9a\u63d0\u5347\u4e86\u53d1\u73b0\u6548\u80fd]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Multi-agent Adaptive Mechanism Design"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [mechanism design], [distributionally robust optimization, online learning, incentive compatibility, adaptive mechanism, regret analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qiushi Han, David Simchi-Levi, Renfei Tan, Zishuo Zhao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Massachusetts Institute of Technology, University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21794",children:"https://arxiv.org/pdf/2512.21794"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DRAM, a novel framework combining mechanism design and online learning to handle unknown agent beliefs. 2. Provides theoretical guarantees of high-probability truthfulness and achieves optimal ",(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsxs)(n.mrow,{children:[(0,a.jsxs)(n.mover,{accent:"true",children:[(0,a.jsx)(n.mo,{stretchy:"false",children:"{"}),(0,a.jsx)(n.mo,{children:"~"})]}),(0,a.jsx)(n.mi,{children:"O"}),(0,a.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,a.jsx)(n.mo,{stretchy:"false",children:"("}),(0,a.jsx)(n.msqrt,{children:(0,a.jsx)(n.mo,{stretchy:"false",children:"{"})}),(0,a.jsx)(n.mi,{children:"T"}),(0,a.jsx)(n.mo,{stretchy:"false",children:"}"}),(0,a.jsx)(n.mo,{stretchy:"false",children:")"})]}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"\\tilde\\{O\\}(\\sqrt\\{T\\})"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"1.2919em",verticalAlign:"-0.305em"}}),(0,a.jsx)(n.span,{className:"mord accent",children:(0,a.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(n.span,{className:"vlist-r",children:[(0,a.jsxs)(n.span,{className:"vlist",style:{height:"0.9869em"},children:[(0,a.jsxs)(n.span,{style:{top:"-3em"},children:[(0,a.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(n.span,{className:"mopen",children:"{"})]}),(0,a.jsxs)(n.span,{style:{top:"-3.669em"},children:[(0,a.jsx)(n.span,{className:"pstrut",style:{height:"3em"}}),(0,a.jsx)(n.span,{className:"accent-body",style:{left:"-0.25em"},children:(0,a.jsx)(n.span,{className:"mord",children:"~"})})]})]}),(0,a.jsx)(n.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(n.span,{className:"vlist-r",children:(0,a.jsx)(n.span,{className:"vlist",style:{height:"0.25em"},children:(0,a.jsx)(n.span,{})})})]})}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.02778em"},children:"O"}),(0,a.jsx)(n.span,{className:"mclose",children:"}"}),(0,a.jsx)(n.span,{className:"mopen",children:"("}),(0,a.jsx)(n.span,{className:"mord sqrt",children:(0,a.jsxs)(n.span,{className:"vlist-t vlist-t2",children:[(0,a.jsxs)(n.span,{className:"vlist-r",children:[(0,a.jsxs)(n.span,{className:"vlist",style:{height:"0.935em"},children:[(0,a.jsxs)(n.span,{className:"svg-align",style:{top:"-3.2em"},children:[(0,a.jsx)(n.span,{className:"pstrut",style:{height:"3.2em"}}),(0,a.jsx)(n.span,{className:"mopen",style:{paddingLeft:"1em"},children:"{"})]}),(0,a.jsxs)(n.span,{style:{top:"-2.895em"},children:[(0,a.jsx)(n.span,{className:"pstrut",style:{height:"3.2em"}}),(0,a.jsx)(n.span,{className:"hide-tail",style:{minWidth:"1.02em",height:"1.28em"},children:(0,a.jsx)(n.svg,{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.28em",viewBox:"0 0 400000 1296",preserveAspectRatio:"xMinYMin slice",children:(0,a.jsx)(n.path,{d:"M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z"})})})]})]}),(0,a.jsx)(n.span,{className:"vlist-s",children:"\u200b"})]}),(0,a.jsx)(n.span,{className:"vlist-r",children:(0,a.jsx)(n.span,{className:"vlist",style:{height:"0.305em"},children:(0,a.jsx)(n.span,{})})})]})}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"T"}),(0,a.jsx)(n.span,{className:"mclose",children:"})"})]})})]})," cumulative regret with a matching lower bound. 3. Generalizes the framework (DRAM+) to support plug-in estimators, structured priors, and delayed feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c99ece7d8b60855735e1eee48c51256eacf5f3997d56ced3396434f12a30ad44_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of designing a truthful mechanism when the principal has no prior knowledge of agents' beliefs. It proposes the Distributionally Robust Adaptive Mechanism (DRAM), which iteratively learns beliefs and updates a robust optimization problem to minimize cost while ensuring truthfulness. The mechanism is proven to achieve optimal regret, and the framework is the first to maintain truthfulness under these general learning conditions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Multi-agent Adaptive Mechanism Design] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Elicit truthful reports with no prior knowledge of agent beliefs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Distributionally Robust Adaptive Mechanism (DRAM)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Guaranteed truthfulness & optimal $\\tilde{O}(\\sqrt{T})$ regret]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [image captioning], [scientific figure captioning, large-scale dataset, domain-specific training, human evaluation, large language models (LLMs)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Pennsylvania State University, Adobe Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21789",children:"https://arxiv.org/pdf/2512.21789"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u79d1\u5b66\u56fe\u8868\u8bf4\u660e\u8d28\u91cf\u5dee/Poor quality of scientific figure captions]\n    Problem --\x3e P2[\u7f3a\u4e4f\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6/Lack of large-scale real-world dataset]\n    Method --\x3e M1[\u6784\u5efaarXiv\u56fe\u8868-\u8bf4\u660e\u5bf9\u6570\u636e\u96c6/Construct arXiv figure-caption dataset]\n    Method --\x3e M2[\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u4e0e\u8bc4\u4f30/Domain-specific training & evaluation]\n    Method --\x3e M3[\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5174\u8d77/Navigate rise of LLMs]\n    Results --\x3e R1[\u603b\u7ed3\u6280\u672f\u65b9\u6cd5\u7ecf\u9a8c/Summarize technical & methodological lessons]\n    Results --\x3e R2[\u63d0\u51fa\u672a\u6765\u6311\u6218\u4e0e\u65b9\u5411/Outline future challenges & directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [diffusion models], [Parameter-Efficient Fine-Tuning, Mixture of Low-rank Experts, Instruction-Guided Routing, Multi-Conditional Generation, Diffusion Transformers]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jinqi Xiao, Qing Yan, Liming Jiang, Zichuan Liu, Hao Kang, Shen Sang, Tiancheng Zhi, Jing Liu, Cheng Yang, Xin Lu, Bo Yuan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ByteDance Inc., Rutgers University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21788",children:"https://arxiv.org/pdf/2512.21788"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/yanq095/InstructMoLE",children:"https://github.com/yanq095/InstructMoLE"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces InstructMoLE, a framework using an Instruction-Guided Mixture of Low-Rank Experts for multi-conditional image generation., 2. Proposes Instruction-Guided Routing (IGR), a global routing signal derived from user instructions to select a coherent expert council for all tokens, addressing spatial fragmentation and semantic drift., 3. Introduces an output-space orthogonality loss to promote expert functional diversity and prevent representational collapse."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11bd8639cb632e86b35367843cf453bbc6a02fb6882f88ff7441c78b42b653ce_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11bd8639cb632e86b35367843cf453bbc6a02fb6882f88ff7441c78b42b653ce_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of task interference in multi-conditional image generation when using monolithic PEFT adapters like LoRA. It proposes InstructMoLE, a novel framework that uses global instruction-guided routing to select a consistent mixture of low-rank experts, combined with an orthogonality loss for diversity, which outperforms existing methods on benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Task interference & spatial fragmentation in multi-conditional DiT fine-tuning]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Global Instruction-Guided Routing (IGR) & output-space orthogonality loss]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms LoRA & MoLE variants on benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CellMamba: Adaptive Mamba for Accurate and Efficient Cell Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [Mamba, Triple-Mapping Adaptive Coupling (TMAC), Adaptive Mamba Head, biomedical instance detection, VSSD backbone]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ruochen Liu, Yi Tian, Jiahao Wang, Hongbin Liu, Xianxu Hou, Jingxin Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Liverpool, National University of Singapore, Xi'an Jiaotong-Liverpool University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21803",children:"https://arxiv.org/pdf/2512.21803"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Triple-Mapping Adaptive Coupling (TMAC) module that splits channels into parallel branches with dual idiosyncratic and one consensus attention map for enhanced spatial discriminability. 2. Designs an Adaptive Mamba Head that fuses multi-scale features via learnable weights to handle varying object sizes robustly. 3. Introduces CellMamba, a lightweight one-stage detector built on a VSSD backbone with CellMamba Blocks, achieving superior accuracy and efficiency on biomedical cell detection datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc3fe9b8372a27eedc5a8e2e1150bcdf6cf461c195f9ed154d8890662de191da_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fc3fe9b8372a27eedc5a8e2e1150bcdf6cf461c195f9ed154d8890662de191da_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes CellMamba, a lightweight one-stage detector for cell detection in pathological images. It introduces a novel Triple-Mapping Adaptive Coupling (TMAC) module and an Adaptive Mamba Head to improve spatial discriminability and multi-scale feature fusion. Experiments show CellMamba outperforms CNN, Transformer, and Mamba baselines in accuracy while being more efficient in model size and inference speed."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CellMamba: Adaptive Mamba for Cell Detection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Cell detection challenges in pathological images]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: CellMamba with TMAC module & Adaptive Mamba Head]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms baselines, lightweight & efficient]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] S&P 500 Stock's Movement Prediction using CNN"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [financial time series forecasting], [Convolutional Neural Network (CNN), multivariate raw data, stock movement prediction, historical data matrices, S&P 500]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rahul Gupta"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," None (No affiliation or email domain provided in the given content)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21804",children:"https://arxiv.org/pdf/2512.21804"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the application of Convolutional Neural Networks (CNNs), typically used for image classification, to the problem of stock movement prediction by treating multivariate historical stock data as image-like matrices. 2. Utilizes raw, unprocessed market data including events like stock splits and dividends, instead of relying on pre-engineered financial features. 3. Demonstrates a flexible prediction framework that can be applied at different levels: individual stocks, sectors, or entire portfolios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d6197655292ac8e55d8c7606c8c3cfe730f7f8dad4004b93d4a9b3a8d8f457_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the problem of predicting stock price movements for the S&P 500 index. The core method involves using a Convolutional Neural Network (CNN) to analyze multivariate historical stock data, which is structured as image-like matrices, without extensive feature engineering. The approach shows promising results and offers a flexible model for stock, sector, or portfolio-level predictions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["S&P 500 Stock\'s Movement Prediction using CNN<br>\u4f7f\u7528CNN\u9884\u6d4b\u6807\u666e500\u80a1\u7968\u8d70\u52bf"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Predicting stock price movement<br>\u9884\u6d4b\u80a1\u7968\u4ef7\u683c\u8d70\u52bf"] --\x3e P1["\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u7279\u5f81\u5de5\u7a0b<br>Traditional methods rely on engineered features"]\n    Problem --\x3e P2["\u73b0\u6709\u7814\u7a76\u591a\u4f7f\u7528\u5355\u7ef4\u6570\u636e<br>Existing research often uses single-dimension data"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Use CNN on raw multivariate data<br>\u5bf9\u539f\u59cb\u591a\u53d8\u91cf\u6570\u636e\u4f7f\u7528CNN"] --\x3e M1["\u5c06\u5386\u53f2\u6570\u636e\u77e9\u9635\u89c6\u4e3a\u56fe\u50cf<br>Treat historical data matrices as images"]\n    Method --\x3e M2["\u5305\u542b\u539f\u59cb\u5e02\u573a\u4e8b\u4ef6(\u5982\u62c6\u80a1)<br>Include raw market events (e.g., splits)"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Model achieves promising results<br>\u6a21\u578b\u53d6\u5f97\u6709\u5e0c\u671b\u7684\u7ed3\u679c"] --\x3e R1["\u652f\u6301\u80a1\u7968/\u884c\u4e1a/\u7ec4\u5408\u7ea7\u522b\u9884\u6d4b<br>Supports stock/sector/portfolio prediction"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [space robotics], [modular robot, reconfigurable robot, lunar construction, field demonstration, connector design]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kentaro Uno, Elian Neppel, Gustavo H. Diaz, Ashutosh Mishra, Shamistan Karimov, A. Sejal Jain, Ayesha Habib, Pascal Pama, Hazal Gozbasi, Shreya Santra, Kazuya Yoshida"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Space Robotics Laboratory (SRL), Department of Aerospace Engineering, Graduate School of Engineering, Tohoku University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21853",children:"https://arxiv.org/pdf/2512.21853"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces MoonBot, a modular and reconfigurable robotic system designed for lunar payload constraints and task adaptability. 2. Details the system's design and development, including a field demonstration simulating lunar infrastructure tasks like civil engineering and component deployment. 3. Systematically summarizes lessons learned, particularly on connector design, to inform future modular robotic systems for lunar missions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7ceec836e29be790b6ca39392714dc64e19923b0842210e75988ad1c5fdeeb2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7ceec836e29be790b6ca39392714dc64e19923b0842210e75988ad1c5fdeeb2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces MoonBot, a modular and reconfigurable robot designed for constructing lunar bases under strict mass constraints. It details the robot's design and validates its concept through field demonstrations of simulated construction tasks. The work concludes with lessons learned, especially regarding connector design, to guide future lunar robotic systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MoonBot: \u9762\u5411\u6708\u7403\u57fa\u5730\u5efa\u8bbe\u7684\u6a21\u5757\u5316\u6309\u9700\u53ef\u91cd\u6784\u673a\u5668\u4eba] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6708\u7403\u63a2\u7d22\u4e0e\u57fa\u5730\u5efa\u8bbe\u9700\u6c42 / Lunar Exploration & Base Construction Needs]\n    C --\x3e C1[\u6a21\u5757\u5316\u53ef\u91cd\u6784\u673a\u5668\u4eba\u7cfb\u7edf / Modular & Reconfigurable Robotic System]\n    C --\x3e C2[\u6982\u5ff5\u9a8c\u8bc1\u4e0e\u73b0\u573a\u6f14\u793a / Proof-of-Concept & Field Demonstration]\n    D --\x3e D1[\u6210\u529f\u6267\u884c\u6a21\u62df\u4efb\u52a1 / Successfully Executed Simulated Tasks]\n    D --\x3e D2[\u603b\u7ed3\u4e86\u8fde\u63a5\u5668\u8bbe\u8ba1\u7b49\u7ecf\u9a8c\u6559\u8bad / Summarized Lessons (e.g., Connector Design)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [evaluation], [anthropomorphic intelligence, benchmark, psychological counseling, rubric-based evaluation, reasoning-before-scoring]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ant Group, Xiamen University, Beijing Normal University, Zhejiang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21849",children:"https://arxiv.org/pdf/2512.21849"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/inclusionAI/HeartBench",children:"https://github.com/inclusionAI/HeartBench"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based "reasoning-before-scoring" evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLMs\u7f3a\u4e4f\u62df\u4eba\u5316\u667a\u80fd / LLMs lack anthropomorphic intelligence]\n    B --\x3e B2[\u4e2d\u6587\u8bed\u5883\u7f3a\u4e4f\u8bc4\u4f30\u6846\u67b6 / Lack of evaluation frameworks in Chinese context]\n    C --\x3e C1[\u57fa\u4e8e\u5fc3\u7406\u54a8\u8be2\u573a\u666f\u7684\u57fa\u51c6 / Benchmark based on psychological counseling scenarios]\n    C --\x3e C2[\u7406\u8bba\u9a71\u52a8\u7684\u5206\u7c7b\u6cd5 / Theory-driven taxonomy]\n    C --\x3e C3[\u57fa\u4e8e\u91cf\u89c4\u7684\u63a8\u7406\u8bc4\u5206\u6cd5 / Rubric-based reasoning-before-scoring]\n    D --\x3e D1[\u6a21\u578b\u6027\u80fd\u5b58\u5728\u4e0a\u9650 / Performance ceiling in models]\n    D --\x3e D2[\u590d\u6742\u573a\u666f\u8868\u73b0\u663e\u8457\u4e0b\u964d / Significant decay in complex scenarios]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Mila \u2013 Quebec AI Institute, Universit\xe9 de Montr\xe9al, McGill University, LLNL, University of Edinburgh, CIFAR"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21852",children:"https://arxiv.org/pdf/2512.21852"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>\u8bba\u6587\u6807\u9898"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>KL\u6b63\u5219\u5316\u4f30\u8ba1\u5668\u914d\u7f6e\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\uff0c\u68af\u5ea6\u5b58\u5728\u504f\u5dee"] --\x3e P1["\u5b9e\u8df5\u95ee\u9898/Practical Issue<br>\u5e7f\u6cdb\u4f7f\u7528\u4f46\u5b9e\u73b0\u4e0e\u76ee\u6807\u4e0d\u4e00\u81f4"]\n    Problem --\x3e P2["\u7406\u8bba\u95ee\u9898/Theoretical Issue<br>\u68af\u5ea6\u504f\u5dee\u5f71\u54cd\u8bad\u7ec3\u7a33\u5b9a\u6027"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5206\u6790\u68af\u5ea6\u504f\u5dee\u5e76\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1"] --\x3e M1["\u5206\u6790/Analysis<br>\u7814\u7a76\u591a\u79cd\u4f30\u8ba1\u5668\u914d\u7f6e\u7684\u68af\u5ea6"]\n    Method --\x3e M2["\u5b9e\u9a8c/Experiments<br>RL\u5fae\u8c03\u591a\u4e2aLLM\u5e76\u8bc4\u4f30\u6027\u80fd"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u65e0\u504f\u68af\u5ea6\u914d\u7f6e\u5e26\u6765\u66f4\u597d\u6027\u80fd"] --\x3e R1["\u5728\u7ebf\u7b56\u7565/On-Policy<br>\u65e0\u504f\u68af\u5ea6\u914d\u7f6e\u63d0\u5347\u7a33\u5b9a\u6027\u548c\u6027\u80fd"]\n    Results --\x3e R2["\u79bb\u7ebf\u7b56\u7565/Off-Policy<br>KL\u6b63\u5219\u5316\u6709\u52a9\u4e8e\u7a33\u5b9a\u5f02\u6b65\u8bad\u7ec3"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image classification], [feature-level fusion, convolutional neural networks, diabetic retinopathy screening, EfficientNet, DenseNet]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md Rafid Islam, Rafsan Jany, Akib Ahmed, Mohammad Ashrafuzzaman Khan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," North South University, Korea Institute of Oriental Medicine, American International University\u2013Bangladesh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21861",children:"https://arxiv.org/pdf/2512.21861"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes and evaluates feature-level fusion of complementary CNN backbones (ResNet50, EfficientNet-B0, DenseNet121) for binary diabetic retinopathy screening. 2. Demonstrates that fusion models consistently outperform single backbones in accuracy and generalization across a large, heterogeneous dataset pooled from five public sources. 3. Provides a practical analysis of the accuracy-efficiency trade-off, identifying the EfficientNet-B0 + DenseNet121 fusion as offering the best balance between performance and computational latency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d879fd7c14baee1110e20d8ebdaec476df8f8819b2fc9a74154be1d0a91d7963_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d879fd7c14baee1110e20d8ebdaec476df8f8819b2fc9a74154be1d0a91d7963_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates feature-level fusion of CNN models to improve binary diabetic retinopathy screening. It finds that fusing EfficientNet-B0 and DenseNet121 achieves the best accuracy (82.89%) with a favorable balance of performance and inference speed, demonstrating that lightweight fusion enhances generalization across diverse datasets for scalable screening."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Large-scale DR screening is constrained by limited specialists and variable image quality.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Feature-level fusion of complementary CNN backbones (e.g., EfficientNet, DenseNet) on pooled fundus images.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Fusion outperforms single models. Eff+Den fusion offers best accuracy-latency balance.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, University of California, Los Angeles, Palo Alto Networks"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21871",children:"https://arxiv.org/pdf/2512.21871"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/bluedream02/CopyGuard",children:"https://github.com/bluedream02/CopyGuard"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: LVLMs may infringe copyright when processing visual inputs"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Benchmark dataset & Tool-augmented defense framework"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Current LVLMs are deficient; Proposed framework reduces risk"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [Privacy-preserving machine learning], [dataset distillation, random forest, synthetic data generation, explainable AI, membership-inference attack]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yiming Qian, Thorsten Neumann, Xueyining Huang, David Hardoon, Fei Gao, Yong Liu, Siow Mong Rick Goh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of High Performance Computing (A*STAR), Standard Chartered Bank, Xi\u2019an Jiaotong\u2013Liverpool University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21866",children:"https://arxiv.org/pdf/2512.21866"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a privacy-preserving dataset distillation framework that converts a trained random forest into transparent rule regions and generates synthetic data by uniform sampling within these regions, creating a compact, auditable surrogate dataset. 2. Enables explainable AI by providing both global pattern summaries (e.g., support, lift) from aggregated rules and local, human-readable rationales with calibrated uncertainty for individual cases based on tree-vote disagreement. 3. Demonstrates strong utility-privacy trade-offs, showing the distilled data maintains competitive model performance (e.g., precision, F1) with significant data reduction (85-93%), improves cross-institution learning, and resists membership-inference attacks (AUC ~0.5), indicating low memorization risk."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6994d363f1e76d7cc78ab02d48685c11199b353aab61b3eb5297064b1df9b722_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6994d363f1e76d7cc78ab02d48685c11199b353aab61b3eb5297064b1df9b722_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a dataset distillation method for financial fraud detection that converts a random forest model into interpretable rule regions to generate synthetic data, preserving privacy and model utility. The approach produces a compact, explainable dataset that supports collaborative learning across institutions while resisting privacy attacks. Experiments show it reduces data volume by over 85% with minimal performance loss and enhances cross-cluster fraud detection."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u7684\u534f\u4f5c\u5f0f\u6b3a\u8bc8\u68c0\u6d4b/Need for privacy-preserving collaborative fraud detection")\n    Problem --\x3e P2("\u6a21\u578b\u9700\u8981\u53ef\u89e3\u91ca\u6027/Model needs explainability")\n    Method --\x3e M1("\u5c06\u968f\u673a\u68ee\u6797\u8f6c\u6362\u4e3a\u89c4\u5219\u533a\u57df/Convert random forest to rule regions")\n    Method --\x3e M2("\u5728\u533a\u57df\u5185\u5747\u5300\u91c7\u6837\u751f\u6210\u5408\u6210\u6570\u636e/Uniformly sample within regions to generate synthetic data")\n    Results --\x3e R1("\u6570\u636e\u91cf\u51cf\u5c1185-93%/Data volume reduced by 85-93%")\n    Results --\x3e R2("\u4fdd\u6301\u7ade\u4e89\u6027\u6027\u80fd/Maintains competitive performance")\n    Results --\x3e R3("\u62b5\u6297\u6210\u5458\u63a8\u7406\u653b\u51fb/Resists membership-inference attacks")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent framework, bias mitigation, financial forecasting, LLM integration, modular design]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Marc S. Montalvo, Hamed Yaghoobian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Rochester Institute of Technology, Muhlenberg College"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21878",children:"https://arxiv.org/pdf/2512.21878"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news for decomposed financial reasoning. 2. Embeds explicit bias-mitigation protocols (e.g., against survivorship and hindsight bias) to enhance transparency and robustness. 3. Demonstrates practical effectiveness through an eight-week evaluation showing outperformance of major market benchmarks, highlighting the promise of bias-aware generative AI in finance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/351cdc3ccfe2b2d987cf53c8380e153fe4b93de0def6253cbc7b2feb4af093fe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/351cdc3ccfe2b2d987cf53c8380e153fe4b93de0def6253cbc7b2feb4af093fe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces MASFIN, a multi-agent system that combines LLMs with financial data and news to perform decomposed reasoning and forecasting while mitigating biases. In an eight-week evaluation, it achieved a 7.33% cumulative return, outperforming benchmarks like the S&P 500 in most weeks, though with higher volatility. The results show the potential of modular, bias-aware AI frameworks for transparent and reproducible quantitative finance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u91cf\u5316\u65b9\u6cd5\u6613\u53d7\u751f\u5b58\u504f\u5dee\u5f71\u54cd/Traditional quantitative methods vulnerable to survivorship bias]\n    B --\x3e B2[AI\u65b9\u6cd5\u5728\u4fe1\u53f7\u96c6\u6210\u548c\u53ef\u590d\u73b0\u6027\u4e0a\u5b58\u5728\u6311\u6218/AI approaches struggle with signal integration and reproducibility]\n    C --\x3e C1[\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6/Modular multi-agent framework]\n    C --\x3e C2[\u96c6\u6210LLM\u4e0e\u7ed3\u6784\u5316\u6307\u6807\u548c\u975e\u7ed3\u6784\u5316\u65b0\u95fb/Integrates LLMs with structured metrics and unstructured news]\n    C --\x3e C3[\u5d4c\u5165\u504f\u5dee\u7f13\u89e3\u534f\u8bae/Embeds bias-mitigation protocols]\n    D --\x3e D1[8\u5468\u7d2f\u8ba1\u56de\u62a57.33%/7.33% cumulative return over eight weeks]\n    D --\x3e D2[\u57286/8\u5468\u4e2d\u8d85\u8d8a\u57fa\u51c6/Outperformed benchmarks in six of eight weeks]\n    D --\x3e D3[\u6ce2\u52a8\u6027\u8f83\u9ad8/Higher volatility]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text-to-sql], [benchmark, multilingual, domain-specific, large language models, sports analytics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Birla Institute of Technology and Science (BITS), Pilani"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21877",children:"https://arxiv.org/pdf/2512.21877"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a "Gold Standard" dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u5728\u4e13\u4e1a\u9886\u57dfText-to-SQL\u80fd\u529b\u672a\u5145\u5206\u63a2\u7d22/LLMs\' Text-to-SQL capability in specialized domains is under-explored]\n    B --\x3e B2[\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u591a\u8bed\u8a00\u548c\u4f53\u80b2\u5206\u6790\u7279\u6027/Existing benchmarks lack multilingual and sports analytics features]\n    C --\x3e C1[\u6784\u5efa\u677f\u7403\u9886\u57df\u4e13\u4e1a\u591a\u8bed\u8a00\u57fa\u51c6/Build a specialized multilingual benchmark for cricket]\n    C --\x3e C2[\u4e0e\u4e13\u5bb6\u5408\u4f5c\u521b\u5efa"\u9ec4\u91d1\u6807\u51c6"\u67e5\u8be2/Collaborate with experts to create "Gold Standard" queries]\n    C --\x3e C3[\u8bc4\u4f30\u516d\u4e2a\u6700\u5148\u8fdb\u7684LLMs/Evaluate six state-of-the-art LLMs]\n    D --\x3e D1[\u4e13\u4e1a\u9886\u57df\u6027\u80fd\u663e\u8457\u4e0b\u964d/Significant performance drop in specialized domain]\n    D --\x3e D2[DeepSeek R1\u8868\u73b0\u6700\u4f73/DeepSeek R1 achieves SOTA]\n    D --\x3e D3[\u5370\u5730\u8bed\u67e5\u8be2\u51c6\u786e\u7387\u53ef\u6bd4\u6216\u66f4\u9ad8/Hindi queries yield parity or higher accuracy]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tingyang Sun, Ting He, Bo Ji, Parimal Parag"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Pennsylvania State University, Virginia Tech, Indian Institute of Science"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21884",children:"https://arxiv.org/pdf/2512.21884"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u5206\u5e03\u5f0fLLM\u63a8\u7406\u7684\u8d44\u6e90\u5206\u914d\u4f18\u5316/Optimizing resource allocation for distributed LLM inference]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u6027\u80fd\u5efa\u6a21\u4e0e\u4f18\u5316\u7b97\u6cd5/Performance modeling and optimization algorithms]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u663e\u8457\u964d\u4f4e\u63a8\u7406\u65f6\u95f4/Substantially reduces inference time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [visual navigation], [world model, future frame projection, 4-dof uav, long-horizon visual generation, aerial navigation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Weichen Zhang, Peizhi Tang, Xin Zeng, Fanhang Man, Shiquan Yu, Zichao Dai, Baining Zhao, Hongjin Chen, Yu Shang, Wei Wu, Chen Gao, Xinlei Chen, Xin Wang, Yong Li, Wenwu Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21887",children:"https://arxiv.org/pdf/2512.21887"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ANWM, an aerial navigation world model for predicting future visual observations to incorporate high-level semantics into UAV path planning. 2. Introduces a physics-inspired Future Frame Projection (FFP) module to provide coarse geometric priors and mitigate uncertainty in long-distance visual generation. 3. Demonstrates superior performance in long-distance visual forecasting and improves UAV navigation success rates in large-scale 3D environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02f69e3df37002aba4354016667950073739b574c3c8044ad15f65d9721e62db_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02f69e3df37002aba4354016667950073739b574c3c8044ad15f65d9721e62db_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ANWM, an aerial navigation world model that predicts future visual observations for UAVs using a novel Future Frame Projection module. It addresses the challenges of complex 4-DoF action spaces and long-horizon visual generation. The model outperforms existing methods in visual forecasting and enhances navigation success in large-scale environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[UAV\u5bfc\u822a\u7f3a\u4e4f\u9ad8\u5c42\u8bed\u4e49\u89c4\u5212\u80fd\u529b/UAV navigation lacks high-level semantic planning]\n    B --\x3e B2[\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u5904\u7406\u590d\u6742\u52a8\u4f5c\u7a7a\u95f4\u4e0e\u957f\u8ddd\u79bb\u89c6\u89c9\u751f\u6210/Existing models struggle with complex action space & long-horizon visual generation]\n    C --\x3e C1[\u63d0\u51faANWM\u4e16\u754c\u6a21\u578b/Propose ANWM world model]\n    C --\x3e C2[\u5f15\u5165\u672a\u6765\u5e27\u6295\u5f71\u6a21\u5757/Introduce Future Frame Projection module]\n    D --\x3e D1[\u957f\u8ddd\u79bb\u89c6\u89c9\u9884\u6d4b\u6027\u80fd\u663e\u8457\u63d0\u5347/Significantly outperforms in long-distance visual forecasting]\n    D --\x3e D2[\u63d0\u9ad8\u5927\u89c4\u6a21\u73af\u5883\u5bfc\u822a\u6210\u529f\u7387/Improves UAV navigation success rates in large-scale environments]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Flexible Multitask Learning with Factorized Diffusion Policy"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [diffusion policy, modular architecture, multitask learning, imitation learning, mixture-of-experts]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chaoqi Liu, Haonan Chen, Sigmund H. H\xf8eg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois at Urbana-Champaign, Harvard University, Norwegian University of Science and Technology, Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21898",children:"https://arxiv.org/pdf/2512.21898"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel modular diffusion policy framework (FDP) that factorizes complex action distributions into a composition of specialized diffusion models. 2. Proposes continuous score aggregation via an observation-conditioned router for stable training and clear component specialization, addressing issues in standard MoE. 3. Demonstrates that the modular structure enables flexible policy adaptation to new tasks and mitigates catastrophic forgetting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b261f496908cd892964760d9f52edb76c57a6126f2c6a9969b7e36d9d43b048e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b261f496908cd892964760d9f52edb76c57a6126f2c6a9969b7e36d9d43b048e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of multitask imitation learning in robotics, where complex action distributions are difficult to model. It proposes a Factorized Diffusion Policy (FDP) that decomposes the policy into specialized diffusion components and composes them via a router. The method outperforms baselines in simulation and real-world manipulation and supports flexible adaptation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Flexible Multitask Learning with Factorized Diffusion Policy] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u673a\u5668\u4eba\u591a\u4efb\u52a1\u5b66\u4e60/Robot Multitask Learning]\n    B1 --\x3e B2[\u52a8\u4f5c\u5206\u5e03\u590d\u6742\u591a\u6a21\u6001/Action Distribution Highly Multimodal]\n    B2 --\x3e B3[\u5355\u4f53\u6a21\u578b\u6b20\u62df\u5408\u4e0e\u4e0d\u7075\u6d3b/Monolithic Models Underfit & Inflexible]\n    C --\x3e C1[\u56e0\u5b50\u5316\u6269\u6563\u7b56\u7565/Factorized Diffusion Policy (FDP)]\n    C1 --\x3e C2[\u6a21\u5757\u5316\u6269\u6563\u4e13\u5bb6/Modular Diffusion Experts]\n    C2 --\x3e C3[\u57fa\u4e8e\u89c2\u5bdf\u7684\u8def\u7531\u5668/Observation-Conditioned Router]\n    C3 --\x3e C4[\u8fde\u7eed\u5206\u6570\u805a\u5408/Continuous Score Aggregation]\n    D --\x3e D1[\u6027\u80fd\u8d85\u8d8a\u57fa\u7ebf/Outperforms Baselines]\n    D1 --\x3e D2[\u4eff\u771f\u4e0e\u771f\u5b9e\u673a\u5668\u4eba\u9a8c\u8bc1/Simulation & Real-World Validation]\n    D2 --\x3e D3[\u652f\u6301\u7075\u6d3b\u7b56\u7565\u9002\u5e94/Enables Flexible Policy Adaptation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal training], [multimodal fusion, sparse mixture-of-experts, schema-guided textualization, clinical trial prediction, temperature scaling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Carolina Apar\xedcio, Qi Shi, Bo Wen, Tesfaye Yadete, Qiwei Han"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nova School of Business and Economics, Hogarthian Technologies, IBM Research, Cleveland Clinic, Oregon Health & Science University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21897",children:"https://arxiv.org/pdf/2512.21897"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A multimodal framework (MMCTOP) that integrates molecular structures, protocol metadata, eligibility narratives, and disease ontologies for clinical trial outcome prediction. 2. A novel architecture combining schema-guided textualization for data normalization and a drug-disease-conditioned sparse Mixture-of-Experts (SMoE) for context-aware, specialized multimodal fusion. 3. Demonstrates improved prediction performance (precision, F1, AUC) over baselines and incorporates operational safeguards like temperature scaling for calibrated probabilities to enhance auditability and reproducibility."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb552211ea905d5cbf8e190ead9078caf65c5d200327a02c7a6dab156a030645_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb552211ea905d5cbf8e190ead9078caf65c5d200327a02c7a6dab156a030645_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes MMCTOP, a multimodal framework for predicting clinical trial outcomes. It uses schema-guided textualization to normalize heterogeneous data and a sparse Mixture-of-Experts model for specialized fusion, achieving better performance than existing methods and providing calibrated risk estimates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[MMCTOP: \u591a\u6a21\u6001\u6587\u672c\u5316\u4e0e\u4e13\u5bb6\u6df7\u5408\u6846\u67b6<br>MMCTOP: Multimodal Textualization and Mixture-of-Experts Framework] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u6311\u6218<br>Multimodal Data Fusion Challenge] --\x3e P1[\u9ad8\u7ef4\u751f\u7269\u533b\u5b66\u4fe1\u606f\u5b66<br>High-Dim Biomedical Informatics]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u591a\u6a21\u6001\u6846\u67b6<br>Multimodal Framework] --\x3e M1[\u6a21\u5f0f\u611f\u77e5\u8868\u5f81\u5b66\u4e60<br>Modality-Aware Representation Learning]\n    Method --\x3e M2[\u67b6\u6784\u8bbe\u8ba1/Architecture Design]\n    M1 --\x3e M1_1[\u9886\u57df\u7279\u5b9a\u7f16\u7801\u5668<br>Domain-Specific Encoders]\n    M2 --\x3e M2_1[\u6a21\u5f0f\u611f\u77e5\u8868\u5f81\u5b66\u4e60<br>Modality-Aware Representation Learning]\n    M2 --\x3e M2_2[\u7a00\u758f\u4e13\u5bb6\u6df7\u5408<br>Sparse Mixture-of-Experts (SMoE)]\n    M2 --\x3e M2_3[\u6a21\u5f0f\u611f\u77e5\u8868\u5f81\u5b66\u4e60<br>Modality-Aware Representation Learning]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>\u6027\u80fd\u63d0\u5347\u4e0e\u6821\u51c6<br>Performance & Calibration] --\x3e R1[\u6307\u6807\u6539\u8fdb<br>Metric Improvements]\n    Results --\x3e R2[\u6d88\u878d\u7814\u7a76<br>Ablation Studies]\n    Results --\x3e R3[\u6982\u7387\u6821\u51c6<br>Probability Calibration]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [agent system], [spatial transcriptomics, AI agents, benchmark, deterministic grader, harness design]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kenny Workman, Zhen Yang, Harihara Muralidharan, Hannah Le"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," LatchBio"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21907",children:"https://arxiv.org/pdf/2512.21907"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SpatialBench, a benchmark of 146 verifiable problems derived from real-world spatial biology analysis workflows, covering five technologies and seven task categories. 2. Provides a deterministic grader for each problem to evaluate the recovery of key biological results from messy spatial datasets. 3. Demonstrates through benchmark data that frontier AI agents have low accuracy (20-38%) on these tasks and reveals the significant impact of harness design (tools, prompts, control flow, execution environment) on performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3912de9f7e0f0d2acbf8bcd709b023f2ed3b9ccd56886885ca3f8e9e9e81880_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3912de9f7e0f0d2acbf8bcd709b023f2ed3b9ccd56886885ca3f8e9e9e81880_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SpatialBench, a benchmark to evaluate whether AI agents can analyze messy, real-world spatial biology data. It tests frontier models on 146 practical problems and finds low accuracy, highlighting that performance heavily depends on the agent's harness design. The benchmark serves as a tool to measure and diagnose agent capabilities for faithful and reproducible data analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[AI\u4ee3\u7406\u80fd\u5426\u4ece\u6df7\u4e71\u7684\u771f\u5b9e\u7a7a\u95f4\u6570\u636e\u4e2d\u63d0\u53d6\u751f\u7269\u5b66\u89c1\u89e3?/Can AI agents extract biological insight from messy, real-world spatial datasets?]\n    C --\x3e C1[\u5f15\u5165\u5305\u542b146\u4e2a\u53ef\u9a8c\u8bc1\u95ee\u9898\u7684\u57fa\u51c6SpatialBench/Introduce SpatialBench benchmark with 146 verifiable problems]\n    C --\x3e C2[\u63d0\u4f9b\u786e\u5b9a\u6027\u8bc4\u5206\u5668\u8bc4\u4f30\u5173\u952e\u751f\u7269\u5b66\u7ed3\u679c\u6062\u590d/Provide deterministic grader to evaluate recovery of key biological result]\n    D --\x3e D1[\u57fa\u7840\u6a21\u578b\u51c6\u786e\u7387\u4f4e (20-38%)/Base model accuracy remains low (20-38%)]\n    D --\x3e D2[\u5de5\u5177\u94fe\u8bbe\u8ba1\u5bf9\u6027\u80fd\u6709\u91cd\u5927\u5f71\u54cd/Harness design has large empirical effect on performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (rlhf)], [preference optimization, single-index model, semiparametric, link function, policy learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nathan Kallus"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Netflix, Cornell University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21917",children:"https://arxiv.org/pdf/2512.21917"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formulates policy alignment as a semiparametric single-index model problem, relaxing the need for a known link function between preferences and rewards. 2. Develops novel policy learners based on profiling, orthogonalizing, and link-agnostic ranking objectives, providing theoretical error bounds. 3. Proposes practical first-order optimization implementations that are robust to unknown preference noise and scale, enabling direct policy optimization without explicit reward fitting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/378875cc0ef0eb142c184d960e479724ea3df83c84cf81e185efea5469a4387e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/378875cc0ef0eb142c184d960e479724ea3df83c84cf81e185efea5469a4387e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of bias in aligning language models when the assumed link function between human preferences and latent rewards is misspecified. It proposes a semiparametric framework that treats the link function as unknown, develops several robust policy learning algorithms, and provides theoretical guarantees. The main conclusion is that this approach enables more reliable policy alignment without needing to correctly specify the preference noise distribution."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Semiparametric Preference Optimization<br>\u4f60\u7684\u8bed\u8a00\u6a21\u578b\u662f\u4e00\u4e2a\u5355\u6307\u6807\u6a21\u578b"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>\u5df2\u77e5\u94fe\u63a5\u51fd\u6570\u9519\u8bef\u5bfc\u81f4\u7b56\u7565\u504f\u5dee<br>Misspecified link function causes policy misalignment"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5c06\u94fe\u63a5\u51fd\u6570\u89c6\u4e3a\u672a\u77e5\u7684\u534a\u53c2\u6570\u5355\u6307\u6807\u6a21\u578b<br>Treat link as unknown semiparametric single-index model"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u5f00\u53d1\u9c81\u68d2\u7684\u7b56\u7565\u5b66\u4e60\u5668\u5e76\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1<br>Develop robust policy learners with theoretical guarantees"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [unsupervised anomaly detection, disentangled representation, pseudo-healthy image reconstruction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tao Yang, Xiuying Wang, Hao Liu, Guanzhong Gong, Lian-Ming Wu, Yu-Ping Wang, Lisheng Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21924",children:"https://arxiv.org/pdf/2512.21924"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a disentangled representation module to decouple brain MRI into imaging-invariant anatomical information and imaging-specific information, improving model generalizability across multi-modality and multi-center data. 2. Designed an edge-to-image restoration module that reconstructs high-quality pseudo-healthy images from edge information, suppressing the propagation of abnormal residuals. 3. Introduced brain anatomical priors and a differentiable one-hot encoding operator to constrain and stabilize the disentanglement learning process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/785ff0154b41353c2fdfb9a61f66c2f97de1b49c0e9dbba451d335e3a8460e71_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/785ff0154b41353c2fdfb9a61f66c2f97de1b49c0e9dbba451d335e3a8460e71_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of generalizability and performance in unsupervised anomaly detection for brain MRI. It proposes a new framework that disentangles anatomical from imaging information and reconstructs pseudo-healthy images from edges, achieving state-of-the-art results on multi-center datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6cdb\u5316\u6027\u5dee\u4e0e\u5f02\u5e38\u6b8b\u7559/Generalizability & Residuals]\n    C --\x3e C1[\u89e3\u8026\u8868\u793a\u6a21\u5757/Disentangled Representation Module]\n    C --\x3e C2[\u8fb9\u7f18\u5230\u56fe\u50cf\u6062\u590d\u6a21\u5757/Edge-to-Image Restoration Module]\n    D --\x3e D1[\u6027\u80fd\u8d85\u8d8a17\u79cdSOTA\u65b9\u6cd5/Outperforms 17 SOTA Methods]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LVLM-Aided Alignment of Task-Specific Vision Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [model alignment and interpretability], [LVLM-VA, spurious correlations, explainable AI (XAI), vision-language model, human-in-the-loop]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alexander Koebler, Lukas Kuhn, Ingo Thon, Florian Buettner"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Goethe University Frankfurt, Siemens AG, German Cancer Research Center (DKFZ)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21985",children:"https://arxiv.org/pdf/2512.21985"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces LVLM-Aided Visual Alignment (LVLM-VA), a novel method for aligning small task-specific vision models with human domain knowledge using a Large Vision Language Model (LVLM). 2. Proposes a bidirectional interface that translates model behavior into natural language and maps human class-level specifications to image-level critiques, enabling efficient expert-model interaction. 3. Demonstrates that the method effectively reduces the model's dependence on spurious features and group-specific biases without requiring fine-grained, instance-level feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c85ee676094853ba26d7711ac1d50d0ab994498bc2f91f2aaab4f1104d3222_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c85ee676094853ba26d7711ac1d50d0ab994498bc2f91f2aaab4f1104d3222_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of small task-specific vision models relying on spurious correlations, which leads to brittle real-world performance. The authors propose LVLM-Aided Visual Alignment (LVLM-VA), a method that uses a Large Vision Language Model to create a bidirectional interface between human domain knowledge and the model, translating explanations and critiques. The method is shown to significantly improve model alignment with human specifications and reduce dependence on spurious features across synthetic and real-world datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LVLM-Aided Alignment of Task-Specific Vision Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5c0f\u89c4\u6a21\u4efb\u52a1\u4e13\u7528\u89c6\u89c9\u6a21\u578b\u4f9d\u8d56\u865a\u5047\u76f8\u5173\u6027/Small task-specific vision models rely on spurious correlations]\n    B --\x3e B2[\u5bfc\u81f4\u90e8\u7f72\u65f6\u884c\u4e3a\u8106\u5f31/Leads to brittle behavior when deployed]\n    C --\x3e C1[\u5229\u7528LVLM\u8fdb\u884c\u89c6\u89c9\u5bf9\u9f50/Leverage LVLM for visual alignment]\n    C --\x3e C2[\u53cc\u5411\u63a5\u53e3: \u884c\u4e3a\u8f6c\u8bed\u8a00, \u89c4\u8303\u8f6c\u8bc4\u4f30/Bidirectional interface: behavior to language, specs to critiques]\n    D --\x3e D1[\u6a21\u578b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u89c4\u8303\u66f4\u597d\u5bf9\u9f50/Better alignment of model behavior with human specifications]\n    D --\x3e D2[\u51cf\u5c11\u5bf9\u865a\u5047\u7279\u5f81\u548c\u504f\u89c1\u7684\u4f9d\u8d56/Reduced dependence on spurious features and biases]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [vision-and-language navigation], [spatiotemporal context modeling, slot-based compression, prompt-guided multimodal integration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wen Jiang, Li Wang, Kangyao Huang, Wei Fan, Jinyuan Liu, Shaoyu Liu, Hongwei Duan, Bin Xu, Xiangyang Ji"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beijing Institute of Technology, Tsinghua University, Dalian University of Technology, Xidian University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22010",children:"https://arxiv.org/pdf/2512.22010"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A slot-based historical image compression module to distill multi-view historical observations into fixed-length contextual representations. 2. A spatiotemporal trajectory encoding module to capture the temporal dynamics and spatial structure of UAV trajectories. 3. A prompt-guided multimodal integration module to fuse spatiotemporal context with current observations for robust waypoint prediction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c00484796a9df425f1884ea8ae22314b0592466ebe305303cf7f1f0c467b528_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c00484796a9df425f1884ea8ae22314b0592466ebe305303cf7f1f0c467b528_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes LongFly, a framework for long-horizon UAV vision-and-language navigation that addresses the challenge of modeling spatiotemporal context. The method integrates a history-aware modeling strategy with modules for compressing past observations, encoding trajectories, and fusing multimodal information. Experimental results show it outperforms state-of-the-art baselines in navigation success metrics across seen and unseen environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LongFly: Long-Horizon UAV Vision-and-Language Navigation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Current UAV VLN methods struggle with long-horizon spatiotemporal context, leading to inaccurate alignment and unstable planning.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: History-aware spatiotemporal modeling with slot-based image compression, trajectory encoding, and prompt-guided multimodal integration.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms SOTA baselines by 7.89% in success rate and 6.33% in SPL.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [generative models for drug discovery], [hit-like molecule generation, autoregressive models, diffusion models, docking scores, multi-stage filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nagham Osman, Vittorio Lembo, Giovanni Bottegoni, Laura Toni"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University College London, University of Urbino Carlo Bo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22031",children:"https://arxiv.org/pdf/2512.22031"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Framing hit-like molecule generation as a standalone task for generative models. 2. Proposing a tailored evaluation framework integrating physicochemical, structural, and bioactivity criteria. 3. Benchmarking autoregressive and diffusion models, with synthesized GSK-3\u03b2 hits confirmed active in vitro."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0d0d188f2e13e0f8561de5950d5637586c871a0ee36935ebfbd5bb2bad540_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2a0d0d188f2e13e0f8561de5950d5637586c871a0ee36935ebfbd5bb2bad540_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether generative models can replace the hit identification step in drug discovery. It proposes a multi-stage evaluation framework and benchmarks autoregressive and diffusion models, showing they can generate valid, diverse, and biologically relevant compounds, with some synthesized hits confirmed active in vitro."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("Hit identification is resource-intensive/\u547d\u4e2d\u8bc6\u522b\u8d44\u6e90\u5bc6\u96c6")\n    Method --\x3e M1("Propose tailored evaluation framework/\u63d0\u51fa\u5b9a\u5236\u8bc4\u4f30\u6846\u67b6")\n    Method --\x3e M2("Benchmark autoregressive & diffusion models/\u57fa\u51c6\u6d4b\u8bd5\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b")\n    Results --\x3e R1("Models generate valid, diverse, bioactive compounds/\u6a21\u578b\u751f\u6210\u6709\u6548\u3001\u591a\u6837\u3001\u6709\u751f\u7269\u6d3b\u6027\u7684\u5316\u5408\u7269")\n    Results --\x3e R2("Selected hits synthesized & confirmed active/\u9009\u5b9a\u547d\u4e2d\u7269\u88ab\u5408\u6210\u5e76\u786e\u8ba4\u6709\u6548")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Michail Kalntis, George Iosifidis, Jos\xe9 Su\xe1rez-Varela, Andra Lutu, Fernando A. Kuipers"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Delft University of Technology, Telef\xf3nica Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22022",children:"https://arxiv.org/pdf/2512.22022"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Meta-Learning-Based Handover Management in NextG O-RAN] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u5207\u6362\u5ef6\u8fdf\u4e0e\u5931\u8d25/Traditional HO delays & failures]\n    B --\x3e B2[\u5207\u6362\u7c7b\u578b\u95f4\u7684\u6743\u8861/Trade-offs between HO types]\n    C --\x3e C1[CONTRA\u6846\u67b6: \u8054\u5408\u4f18\u5316THO\u4e0eCHO/CONTRA: Jointly optimizes THOs & CHOs]\n    C --\x3e C2[\u5143\u5b66\u4e60\u7b97\u6cd5\u52a8\u6001\u9009\u62e9/Meta-learning for dynamic selection]\n    C --\x3e C3[O-RAN xApp\u90e8\u7f72/O-RAN xApp deployment]\n    D --\x3e D1[\u63d0\u5347\u7528\u6237\u541e\u5410\u91cf/Improves user throughput]\n    D --\x3e D2[\u964d\u4f4e\u5207\u6362\u6210\u672c/Reduces HO switching costs]\n    D --\x3e D3[\u4f18\u4e8e3GPP\u4e0eRL\u57fa\u7ebf/Outperforms 3GPP & RL baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LibContinual: A Comprehensive Library towards Realistic Continual Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [catastrophic forgetting, stability-plasticity dilemma, modular architecture, memory budget, online continual learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenbin Li, Shangge Liu, Borui Kang, Yiyang Chen, KaXuan Lew, Yang Chen, Yinghuan Shi, Lei Wang, Yang Gao, Jiebo Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University, University of Wollongong, University of Rochester"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22029",children:"https://arxiv.org/pdf/2512.22029"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/RL-VIG/LibContinual",children:"https://github.com/RL-VIG/LibContinual"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed LibContinual, a unified, modular, and reproducible library for Continual Learning (CL) that integrates 19 representative algorithms across five methodological categories. 2. Systematically identified and investigated three unrealistic implicit assumptions (offline data accessibility, unregulated memory, intra-task semantic homogeneity) prevalent in mainstream CL evaluation. 3. Conducted a comprehensive analysis under stricter, more realistic settings (strict online CL, unified memory budget, category-randomized tasks), revealing significant performance drops in many existing methods and highlighting the need for resource-aware and semantically robust CL strategies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a733a967f663a216bbd5fb0cee657ed8bb70a4e6f0205d669f983cbf9bb6fd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a733a967f663a216bbd5fb0cee657ed8bb70a4e6f0205d669f983cbf9bb6fd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces LibContinual, a comprehensive library designed to unify and standardize research in Continual Learning (CL). By using this framework to evaluate existing methods under more realistic constraints, the study shows that many current CL algorithms suffer significant performance drops, underscoring the gap between common evaluation practices and real-world applicability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LibContinual: A Comprehensive Library towards Realistic Continual Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u7814\u7a76\u788e\u7247\u5316\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6/Fragmented research landscape, lack of unified framework]\n    B --\x3e B2[\u8bc4\u4f30\u5b58\u5728\u4e0d\u73b0\u5b9e\u7684\u9690\u542b\u5047\u8bbe/Unrealistic implicit assumptions in evaluation]\n    C --\x3e C1[\u6784\u5efa\u6a21\u5757\u5316\u3001\u53ef\u590d\u73b0\u7684\u5e93/Build a modular, reproducible library]\n    C --\x3e C2[\u96c6\u621019\u79cd\u4ee3\u8868\u6027\u7b97\u6cd5/Integrate 19 representative algorithms]\n    C --\x3e C3[\u5728\u66f4\u73b0\u5b9e\u7684\u8bbe\u5b9a\u4e0b\u7cfb\u7edf\u8bc4\u4f30/Systematically evaluate under more realistic settings]\n    D --\x3e D1[\u73b0\u6709\u65b9\u6cd5\u5728\u73b0\u5b9e\u7ea6\u675f\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d/Existing methods show significant performance drop under realistic constraints]\n    D --\x3e D2[\u5f3a\u8c03\u8d44\u6e90\u611f\u77e5\u548c\u8bed\u4e49\u9c81\u68d2\u7b56\u7565\u7684\u5fc5\u8981\u6027/Highlight the necessity of resource-aware and semantically robust strategies]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22065",children:"https://arxiv.org/pdf/2512.22065"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://streamavatar.github.io",children:"https://streamavatar.github.io"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Unifying Learning Dynamics and Generalization in Transformers Scaling Law"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [learning theory], [scaling law, learning dynamics, generalization error, transformer, stochastic gradient descent]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chiwun Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sun Yat-sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22088",children:"https://arxiv.org/pdf/2512.22088"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of \u0398(C^{-1/6}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Scaling Law\u7406\u8bba\u539f\u7406\u4e0d\u6e05 / Poorly understood theoretical underpinnings of scaling laws]\n    C --\x3e C1[\u5f62\u5f0f\u5316\u5b66\u4e60\u52a8\u6001\u4e3aODE\u7cfb\u7edf / Formalize learning dynamics as ODE system]\n    C --\x3e C2[\u8fd1\u4f3c\u4e3a\u6838\u884c\u4e3a / Approximate to kernel behaviors]\n    C --\x3e C3[\u5206\u6790SGD\u8bad\u7ec3\u771f\u5b9eTransformer / Analyze SGD training for real transformers]\n    D --\x3e D1[\u6cdb\u5316\u8bef\u5dee\u4e0a\u754c\u4e0e\u76f8\u53d8 / Upper bound on excess risk with phase transition]\n    D --\x3e D2[\u4f18\u5316\u76f8:\u6307\u6570\u8870\u51cf / Optimization phase: Exponential decay]\n    D --\x3e D3[\u7edf\u8ba1\u76f8:\u5e42\u5f8b\u8870\u51cf \u0398(C^{-1/6}) / Statistical phase: Power-law decay \u0398(C^{-1/6})]\n    D --\x3e D4[\u5206\u79bb\u7684\u89c4\u6a21\u5b9a\u5f8b / Isolated scaling laws for model size, time, data]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [benchmark construction], [Turkish NLU benchmark, semi-automated annotation, sentiment analysis dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Duygu Altinok"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22100",children:"https://arxiv.org/pdf/2512.22100"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Introducing TrGLUE and SentiTurca] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u7f3a\u4e4f\u571f\u8033\u5176\u8bed\u7efc\u5408\u57fa\u51c6/Lack of Turkish NLU Benchmark]\n    C --\x3e C1[\u534a\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b/Semi-automated Pipeline]\n    C1 --\x3e C2[LLM\u6807\u6ce8 + \u4ea4\u53c9\u9a8c\u8bc1 + \u4eba\u5de5\u6821\u9a8c/LLM Annotation + Cross-check + Human Validation]\n    D --\x3e D1[\u53d1\u5e03TrGLUE & SentiTurca/Release TrGLUE & SentiTurca]\n    D --\x3e D2[\u63d0\u4f9b\u4ee3\u7801\u4e0e\u8d44\u6e90/Provide Code & Resources]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent pipeline, automated data analysis, insight generation, report synthesis, visual analytics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Minnesota"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22101",children:"https://arxiv.org/pdf/2512.22101"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A2P-Vis] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u6d41\u7a0b\u7684\u74f6\u9888/Gaps in automating data science]\n    B1 --\x3e B2[\u751f\u6210\u6709\u6d1e\u5bdf\u529b\u7684\u53ef\u89c6\u5316/Generating insightful visual evidence]\n    B1 --\x3e B3[\u7ec4\u88c5\u6210\u4e13\u4e1a\u62a5\u544a/Assembling coherent professional report]\n    C --\x3e C1[\u4e24\u90e8\u5206\u591a\u667a\u80fd\u4f53\u7ba1\u9053/Two-part multi-agent pipeline]\n    C1 --\x3e C2[\u6570\u636e\u5206\u6790\u5668/Data Analyzer]\n    C2 --\x3e C3[\u751f\u6210\u5e76\u8bc4\u4f30\u56fe\u8868\u4e0e\u6d1e\u5bdf/Generates & evaluates charts & insights]\n    C1 --\x3e C4[\u62a5\u544a\u5448\u73b0\u5668/Presenter]\n    C4 --\x3e C5[\u7f16\u6392\u4e3b\u9898\u5e76\u64b0\u5199\u53d9\u8ff0/Orders topics & composes narrative]\n    D --\x3e D1[\u7aef\u5230\u7aef\u534f\u540c\u5206\u6790/End-to-end co-analysis]\n    D1 --\x3e D2[\u63d0\u9ad8\u81ea\u52a8\u5316\u6570\u636e\u5206\u6790\u7684\u5b9e\u7528\u6027/Improves usefulness of automated analysis]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [neural network pruning, game theory, equilibrium, non-cooperative game, sparsification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zubair Shah, Noaman Khan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hamad Bin Khalifa University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22106",children:"https://arxiv.org/pdf/2512.22106"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel game-theoretic perspective on neural network pruning, modeling parameter groups as players in a non-cooperative game where sparsity emerges as an equilibrium outcome. 2. Provides a theoretical analysis showing that dominated players (redundant parameters) collapse to zero participation under mild conditions, offering a principled explanation for pruning. 3. Derives a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit, heuristic importance scores."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fd762b6b064bb7810151beeb40f55c93bfc05054b2d4a98cd925aed8bea43b2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fd762b6b064bb7810151beeb40f55c93bfc05054b2d4a98cd925aed8bea43b2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a novel game-theoretic framework for neural network pruning, where sparsity emerges naturally from the equilibrium of a non-cooperative game among model components. The method jointly updates network parameters and participation variables without external importance scores. Experiments show it achieves competitive sparsity-accuracy trade-offs with a more interpretable, theory-grounded foundation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Sparsity is imposed externally via heuristics, lacking a principled model of parameter interaction.")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Model pruning as a non-cooperative game among parameters; sparsity emerges at equilibrium.")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Competitive sparsity-accuracy trade-offs with an interpretable, theory-grounded algorithm.")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois at Urbana-Champaign, IBM Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22113",children:"https://arxiv.org/pdf/2512.22113"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>\u57fa\u4e8e\u667a\u80fd\u4f53\u7ed3\u6784\u5316\u56fe\u904d\u5386\u7684\u4e91\u5e94\u7528\u6839\u56e0\u5206\u6790] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Atomistic Simulation Guided Convolutional Neural Networks for Thermal Modeling of Friction Stir Welding"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [physics-informed machine learning], [molecular dynamics, convolutional neural network, friction stir welding, explainable AI, LAMMPS]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Akshansh Mishra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Politecnico di Milano, AI Fab Lab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21344",children:"https://arxiv.org/pdf/2512.21344"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed a novel method to transform atomistic simulation data (atomic positions and velocities) into physics-based 2D spatial grids for deep learning input. 2. Created and optimized a 2D CNN model to directly predict temperature evolution from spatially resolved atomistic data, achieving high accuracy (R\xb2=0.94). 3. Used Class Activation Map analysis to provide explainability, showing the model's focus aligns with physical mechanisms (e.g., tool-material interface)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34d6f71500319f52aecac1e95e1951a537fdc504134a8ba43851f31acc2e41c6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a method that combines molecular dynamics simulations with convolutional neural networks for thermal modeling in friction stir welding. The method transforms atomic-scale simulation data into spatial grids and uses a CNN to accurately predict temperature, with results validated against physical mechanisms. The approach demonstrates that deep learning can effectively learn from atomistic data to model complex thermomechanical processes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Atomistic Simulation Guided CNNs for Thermal Modeling of FSW / \u539f\u5b50\u6a21\u62df\u5f15\u5bfc\u7684CNN\u7528\u4e8e\u6405\u62cc\u6469\u64e6\u710a\u70ed\u5efa\u6a21"]\n    Root --\x3e Problem["\u51c6\u786e\u9884\u6d4b\u6e29\u5ea6\u6f14\u5316\u5bf9\u4e8e\u7406\u89e3\u6405\u62cc\u6469\u64e6\u710a\u7684\u70ed\u673a\u68b0\u884c\u4e3a\u81f3\u5173\u91cd\u8981 / Accurate prediction of temperature evolution is essential for understanding thermomechanical behavior in FSW"]\n    Root --\x3e Method["\u4f7f\u7528LAMMPS\u8fdb\u884c\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u5c06\u539f\u5b50\u6570\u636e\u8f6c\u6362\u4e3a\u7269\u7406\u4e8c\u7ef4\u7a7a\u95f4\u7f51\u683c\uff0c\u5e76\u5f00\u53d12D CNN\u8fdb\u884c\u9884\u6d4b / Use LAMMPS for MD simulations, transform atomic data into physics-based 2D spatial grids, and develop a 2D CNN for prediction"]\n    Root --\x3e Results["\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff08R\xb2=0.94\uff09\uff0cCAM\u5206\u6790\u8868\u660e\u6a21\u578b\u5173\u6ce8\u4e0e\u5267\u70c8\u53d8\u5f62\u548c\u751f\u70ed\u76f8\u5173\u7684\u533a\u57df / Model achieves high predictive accuracy (R\xb2=0.94), CAM analysis shows model focuses on regions associated with intense deformation and heat generation"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Applications of synthetic financial data in portfolio and risk modeling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [generative models for time series], [TimeGAN, Variational Autoencoder (VAE), synthetic financial data, portfolio optimization, risk modeling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Christophe D. Hounwanou, Yae Ulrich Gaba"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," African Institute for Mathematical Sciences (AIMS Rwanda), Sefako Makgatho Health Sciences University (SMU), AI Research and Innovation Nexus for Africa (AIRINA Labs)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21798",children:"https://arxiv.org/pdf/2512.21798"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Evaluated and compared the performance of TimeGAN and VAEs for generating realistic synthetic financial time series data. 2. Demonstrated that TimeGAN-generated data closely matches real data in distributional, volatility, and autocorrelation properties. 3. Showed the practical utility of synthetic data in downstream financial tasks like mean-variance portfolio optimization, yielding similar portfolio weights and risk metrics to real data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a7ecf00c1350b58057e2f03c93bf0e8845d1441745fc22505c46475eceeeb65_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a7ecf00c1350b58057e2f03c93bf0e8845d1441745fc22505c46475eceeeb65_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the scarcity and privacy issues of real financial data by using generative models like TimeGAN and VAEs to create synthetic return series. It evaluates the synthetic data on statistical similarity and financial tasks, concluding that TimeGAN effectively captures temporal dynamics and can serve as a privacy-preserving, cost-effective substitute for real data in portfolio and risk analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Applications of synthetic financial data in portfolio and risk modeling") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Privacy and accessibility limit financial research")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Use TimeGAN and VAEs to generate synthetic financial time series")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: TimeGAN data is realistic and useful for portfolio/risk tasks")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Residual Prior Diffusion: A Probabilistic Framework Integrating Coarse Latent Priors with Diffusion Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [diffusion models], [diffusion models, generative modeling, evidence lower bound, residual learning, two-stage framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Takuro Kutsuna"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Toyota Central R&D Labs., Inc."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21593",children:"https://arxiv.org/pdf/2512.21593"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Residual Prior Diffusion (RPD), a two-stage probabilistic framework that integrates a coarse prior model with a diffusion model to capture large-scale structure and fine-scale details separately. 2. Formulates RPD with a tractable evidence lower bound, showing optimization reduces to familiar noise/velocity prediction objectives, and introduces auxiliary variables to leverage prior information and theoretically reduce prediction difficulty. 3. Demonstrates experimentally that RPD outperforms standard diffusion models on synthetic datasets with fine local structure and matches or exceeds baselines on natural image generation, maintaining performance with few inference steps."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08078ea833fb6d000def6c1e69b08b734ff7e29a1c3014bf3ec3e8b313815438_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08078ea833fb6d000def6c1e69b08b734ff7e29a1c3014bf3ec3e8b313815438_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies a problem where standard diffusion models struggle to simultaneously model global structure and fine local details. It proposes Residual Prior Diffusion (RPD), a two-stage framework that first learns a coarse prior and then a diffusion model for the residual. Experiments show RPD captures fine details better than standard models and maintains strong performance with fewer inference steps."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Residual Prior Diffusion (RPD) / \u6b8b\u5dee\u5148\u9a8c\u6269\u6563\u6a21\u578b"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u5355\u4e00\u6269\u6563\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u5168\u5c40\u7ed3\u6784\u548c\u5c40\u90e8\u7ec6\u8282 / Single diffusion model struggles with global structure and local details"]\n    Method --\x3e M1["\u4e24\u9636\u6bb5\u6846\u67b6: \u7c97\u7c92\u5ea6\u5148\u9a8c + \u6b8b\u5dee\u6269\u6563\u6a21\u578b / Two-stage framework: coarse prior + residual diffusion model"]\n    Method --\x3e M2["\u6982\u7387\u6a21\u578b\u4e0e\u53ef\u5904\u7406ELBO / Probabilistic model with tractable ELBO"]\n    Results --\x3e R1["\u5728\u5408\u6210\u6570\u636e\u4e0a\u51c6\u786e\u6355\u6349\u7ec6\u8282 / Accurately captures details on synthetic data"]\n    Results --\x3e R2["\u81ea\u7136\u56fe\u50cf\u751f\u6210\u5339\u914d\u6216\u8d85\u8d8a\u57fa\u7ebf / Natural image generation matches or exceeds baselines"]\n    Results --\x3e R3["\u5c11\u6b65\u63a8\u7406\u4fdd\u6301\u6027\u80fd / Maintains performance with few inference steps"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Imperial College London, Fudan University, Xiamen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21652",children:"https://arxiv.org/pdf/2512.21652"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Enabling Ultra-Fast Cardiovascular Imaging...] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[CMR\u626b\u63cf\u65f6\u95f4\u957f/CMR Scan Time Long]\nB --\x3e B2[\u4e34\u5e8a\u73af\u5883\u5f02\u8d28\u6027\u9ad8/High Clinical Heterogeneity]\nC --\x3e C1[\u6784\u5efa\u591a\u6a21\u6001\u6570\u636e\u5e93MMCMR-427K/Build Multimodal DB MMCMR-427K]\nC --\x3e C2[\u63d0\u51fa\u901a\u7528\u57fa\u7840\u6a21\u578bCardioMM/Propose Generalist Foundation Model CardioMM]\nD --\x3e D1[\u5b9e\u73b024\u500d\u52a0\u901f\u6210\u50cf/Achieve 24x Accelerated Imaging]\nD --\x3e D2[\u96f6\u6837\u672c\u6cdb\u5316\u81f3\u65b0\u73af\u5883/Zero-shot Generalization to New Settings]\nD --\x3e D3[\u4fdd\u6301\u8bca\u65ad\u8d28\u91cf/Preserve Diagnostic Quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [GPU Virtualization, Benchmarking, Multi-tenancy, CUDA, Performance Isolation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jithin VG, Ditto PS"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Bud Ecosystem Inc"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22125",children:"https://arxiv.org/pdf/2512.22125"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/BudEcosystem/GPU-Virt-Bench",children:"https://github.com/BudEcosystem/GPU-Virt-Bench"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed GPU-Virt-Bench, a comprehensive benchmarking framework with 56 metrics across 10 categories for evaluating software-based GPU virtualization systems. 2. Enabled systematic comparison between software virtualization approaches (e.g., HAMi-core, BUD-FCSP) and ideal hardware-based MIG behavior. 3. Demonstrated the framework's utility by revealing critical performance characteristics for production deployment decisions in multi-tenant environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of standardized evaluation for software-based GPU virtualization systems, which are needed for efficient GPU sharing in AI/LLM workloads. The authors propose GPU-Virt-Bench, a comprehensive benchmarking framework that measures performance across multiple critical dimensions. The framework provides actionable insights for practitioners by comparing software solutions against hardware-based baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GPU-Virt-Bench: A Comprehensive Benchmarking Framework] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[GPU\u8d44\u6e90\u5171\u4eab\u9700\u6c42\u9ad8\uff0c\u4f46\u8f6f\u4ef6\u865a\u62df\u5316\u65b9\u6848\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30/High demand for GPU sharing, but software virtualization lacks standardized evaluation]\n    C --\x3e C1[\u63d0\u51fa\u5305\u542b56\u4e2a\u6307\u6807\u300110\u4e2a\u7c7b\u522b\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6/Propose a comprehensive benchmarking framework with 56 metrics across 10 categories]\n    D --\x3e D1[\u7cfb\u7edf\u6bd4\u8f83\u8f6f\u4ef6\u65b9\u6848\u4e0eMIG\uff0c\u4e3a\u751f\u4ea7\u90e8\u7f72\u63d0\u4f9b\u5173\u952e\u6027\u80fd\u6d1e\u5bdf/Systematic comparison between software approaches and MIG provides key performance insights for deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [ad-hoc teamwork, retrieval-augmented generation, teammate modeling, Overcooked]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Conor Wallace, Umer Siddique, Yongcan Cao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Texas at San Antonio"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22129",children:"https://arxiv.org/pdf/2512.22129"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces COLLAB, a novel language-based framework that uses LLMs as behavioral world models to classify unseen teammate types in ad-hoc teamwork. 2. Extends COLLAB to RECOLLAB by incorporating retrieval-augmented generation (RAG) with exemplar trajectories to stabilize inference and improve adaptation. 3. Demonstrates empirically in the Overcooked environment that RECOLLAB achieves Pareto-optimal trade-offs between classification accuracy and episodic return, highlighting the value of retrieval grounding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/078fe396118022eaa0d391e86072d08c5b6617a143aba1478029ca3185af6472_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/078fe396118022eaa0d391e86072d08c5b6617a143aba1478029ca3185af6472_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of ad-hoc teamwork, where an agent must collaborate with unseen teammates. It proposes RECOLLAB, a framework that uses retrieval-augmented LLMs to model and classify teammate behavior from short interaction traces. The method is shown to effectively improve adaptation and coordination in the cooperative Overcooked environment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("RECOLLAB: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("Ad-hoc Teammate Modeling<br>Ad-hoc\u961f\u53cb\u5efa\u6a21")\n    Problem --\x3e P2("Brittle Conventional Models<br>\u4f20\u7edf\u6a21\u578b\u8106\u5f31\u6027")\n    Method --\x3e M1("COLLAB: LLM-based Framework<br>\u57fa\u4e8eLLM\u7684\u6846\u67b6")\n    Method --\x3e M2("RECOLLAB: Adds RAG<br>\u589e\u52a0RAG\u68c0\u7d22")\n    Results --\x3e R1("Improved Adaptation<br>\u63d0\u5347\u9002\u5e94\u6027")\n    Results --\x3e R2("Pareto-Optimal Trade-offs<br>\u5e15\u7d2f\u6258\u6700\u4f18\u6743\u8861")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Shanghai Innovation Institute"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22135",children:"https://arxiv.org/pdf/2512.22135"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of "data as a persistent asset, model as a transient tool". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u9501\u5b9a/Data Lock-in]\n    B --\x3e B2[\u8ba4\u77e5\u8fc7\u8f7d/Cognitive Overload]\n    C --\x3e C1[\u4e3b\u6743\u6570\u5b57\u5316\u8eab/Sovereign Digital Avatar (SoDA)]\n    C --\x3e C2[\u6b63\u4ea4\u89e3\u8026\u8bbe\u8ba1/Orthogonal Decoupling Design]\n    C --\x3e C3[\u610f\u56fe-\u6743\u9650\u63e1\u624b\u673a\u5236/Intent-Permission Handshake Mechanism]\n    D --\x3e D1[\u964d\u4f4e\u4ee4\u724c\u6d88\u8017/Reduces Token Consumption by 27-35%]\n    D --\x3e D2[\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8f7d/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [FPGA, HLS, Point Cloud, Model Compression, Fixed-Point]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Sciences and Technology (Pakistan), RPTU Kaiserslautern-Landau (Germany)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22139",children:"https://arxiv.org/pdf/2512.22139"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/dll-ncai/HLS4PC",children:"https://github.com/dll-ncai/HLS4PC"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed HLS4PC, a parameterizable HLS framework for accelerating point-based 3D point cloud models on FPGA. 2. Introduced PointMLP-Lite, a 4x less complex model variant created via hardware-aware compression techniques (URS, quantization, pruning, fusion). 3. Demonstrated FPGA acceleration achieving 3.56x higher throughput than prior work and outperforming GPU/CPU implementations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of real-time 3D point cloud processing by proposing HLS4PC, a parameterizable FPGA acceleration framework. The method combines algorithmic optimizations and hardware-aware model compression to create an efficient fixed-point implementation, which significantly outperforms previous accelerators and GPU/CPU baselines in throughput."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[GPU under-utilization due to sparse, unstructured point cloud data]\n    P1 --\x3e P2[High memory/computation demand hinders real-time performance]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Parameterizable HLS framework for FPGA]\n    M1 --\x3e M2[Hardware-aware compression: URS, quantization, pruning, fusion]\n    M2 --\x3e M3[Creates PointMLP-Lite model]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[PointMLP-Lite: 4x less complex, ~2% accuracy drop]\n    R1 --\x3e R2[3.56x higher throughput vs. prior work]\n    R2 --\x3e R3[2.3x (GPU) and 22x (CPU) higher throughput]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Pre-review to Peer review: Pitfalls of Automating Reviews using Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [peer review automation], [large language models, peer review, pre-review, citation prediction, review alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Akhil Pandey Akella, Harish Varma Siravuri, Shaurya Rohatgi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," AllSci Corp, Sunwater Capital, Kellogg School of Management (Northwestern University), Northern Illinois University, MBZUAI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22145",children:"https://arxiv.org/pdf/2512.22145"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a systematic evaluation of frontier open-weight LLMs for generating peer reviews, measuring alignment with human reviewers and correlation with post-publication metrics like citations and novelty. 2. Identified key pitfalls of LLMs as autonomous reviewers, including weak correlation with human scores (0.15), systematic overestimation bias (3-5 points), and uniformly high confidence scores despite errors. 3. Demonstrated the potential utility of LLMs as pre-review screening agents, as their generated reviews correlate more strongly with post-publication outcomes than with human reviewer scores, and released an open-source dataset (DLMRSD) to support further safety research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff267a101523eaa0ec56d561e9fa2c165c73baa1b3016d38df1ed64dbc91dcf6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff267a101523eaa0ec56d561e9fa2c165c73baa1b3016d38df1ed64dbc91dcf6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates the use of large language models (LLMs) for automating academic peer review by comparing LLM-generated reviews against human reviewer scores and post-publication metrics. The study finds that while LLMs show weak alignment with human reviewers and exhibit overconfidence and bias, their reviews correlate better with future citation impact, suggesting they could serve as useful pre-review screening tools rather than fully autonomous reviewers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Pre-review to Peer Review: Pitfalls of Automating Reviews using Large Language Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u7528\u4e8e\u81ea\u52a8\u5316\u540c\u884c\u8bc4\u5ba1\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027/Safety & Reliability of Automating Peer Review with LLMs]\n    C --\x3e C1[\u4f7f\u7528\u524d\u6cbf\u5f00\u6e90LLMs\u751f\u6210\u8bc4\u5ba1\u5e76\u4e0e\u4eba\u7c7b\u8bc4\u5206\u53ca\u53d1\u8868\u540e\u6307\u6807\u5bf9\u6bd4/Using Frontier Open-Weight LLMs to Generate Reviews vs. Human Scores & Post-Publication Metrics]\n    D --\x3e D1[LLMs\u4e0e\u4eba\u7c7b\u8bc4\u5ba1\u5458\u5f31\u76f8\u5173\uff0c\u5b58\u5728\u9ad8\u4f30\u504f\u5dee\u4e0e\u8fc7\u5ea6\u81ea\u4fe1/Weak Correlation with Humans, Overestimation Bias, High Confidence]\n    D --\x3e D2[LLM\u8bc4\u5ba1\u4e0e\u53d1\u8868\u540e\u6307\u6807\u76f8\u5173\u6027\u66f4\u5f3a\uff0c\u9002\u5408\u9884\u5ba1\u7b5b\u67e5/LLM Reviews Correlate More with Post-Publication Metrics, Suitable for Pre-Review Screening]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [hpc], [gpu kernels], [Minimal Executable Program (MEP), Automatic Error Repair, Performance Pattern Inheritance, iterative optimization, cross-platform]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ruifan Chu, Anbang Wang, Xiuxiu Bai, Shuai Liu, Xiaoshe Dong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," School of Software Engineering, Xi\u2019an Jiaotong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22147",children:"https://arxiv.org/pdf/2512.22147"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an end-to-end LLM framework that optimizes GPU kernels by constructing Minimal Executable Programs (MEPs) to avoid expensive full application builds and executions. 2. Introduces Automatic Error Repair and Performance Pattern Inheritance to automatically fix faults and reuse effective optimization strategies, reducing search cost. 3. Demonstrates cross-platform portability and effectiveness on NVIDIA GPUs and the Haiguang DCU platform, achieving significant speedups over direct LLM optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high cost of full builds for GPU kernel optimization in large HPC applications by proposing an LLM framework that uses Minimal Executable Programs (MEPs) for iterative optimization. The method integrates automatic error repair and performance pattern inheritance to maintain correctness and reuse strategies. It achieves substantial speedups across different hardware platforms without requiring full-source dependencies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Full builds & runs are expensive in large applications/\u5927\u578b\u5e94\u7528\u4e2d\u5b8c\u6574\u6784\u5efa\u4e0e\u8fd0\u884c\u6210\u672c\u9ad8]\n    C --\x3e C1[Construct Minimal Executable Program (MEP) for kernel/\u4e3a\u5185\u6838\u6784\u5efa\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f]\n    C --\x3e C2[Multi-round iterative optimization with LLM feedback/\u57fa\u4e8eLLM\u53cd\u9988\u7684\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316]\n    C --\x3e C3[Integrate Automatic Error Repair & Performance Pattern Inheritance/\u96c6\u6210\u81ea\u52a8\u9519\u8bef\u4fee\u590d\u4e0e\u6027\u80fd\u6a21\u5f0f\u7ee7\u627f]\n    D --\x3e D1[Achieves significant speedups (e.g., 5.05x, 7.77x)/\u83b7\u5f97\u663e\u8457\u52a0\u901f\u6bd4]\n    D --\x3e D2[Cross-platform portability (NVIDIA, DCU)/\u8de8\u5e73\u53f0\u53ef\u79fb\u690d\u6027]\n    D --\x3e D3[Surpasses direct LLM optimization/\u8d85\u8d8a\u76f4\u63a5LLM\u4f18\u5316]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [serverless computing, GPU resource allocation, workload scheduling, multi-agent systems, collaborative reasoning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guilin Zhang, Wulan Guo, Ziqi Tan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," George Washington University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22149",children:"https://arxiv.org/pdf/2512.22149"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An adaptive GPU resource allocation framework for multi-agent systems in serverless environments that dynamically adjusts resources based on workload characteristics, agent priorities, and minimum requirements. 2. An O(N) complexity algorithm for real-time adaptation, enabling millisecond-scale reallocation to handle dynamic workload fluctuations. 3. A comprehensive evaluation demonstrating the framework's superiority over static and round-robin strategies, achieving 85% latency reduction while maintaining throughput and improving GPU utilization and cost-efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an adaptive GPU resource allocation framework to address the challenge of efficiently deploying heterogeneous multi-agent AI systems on serverless platforms. The method dynamically allocates resources using a real-time algorithm to handle varying computational demands and workload fluctuations. The results show it significantly reduces latency compared to baseline schedulers while maintaining throughput, offering a cost-effective solution for serverless multi-agent deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments<br/>\u9762\u5411\u65e0\u670d\u52a1\u5668\u73af\u5883\u7684\u591a\u667a\u80fd\u4f53\u534f\u540c\u63a8\u7406\u7684\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Heterogeneous agent workloads & dynamic demands on serverless GPU platforms<br/>\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u5f02\u6784\u4e0e\u65e0\u670d\u52a1\u5668GPU\u5e73\u53f0\u52a8\u6001\u9700\u6c42"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Adaptive GPU resource allocation framework with O(N) real-time algorithm<br/>\u57fa\u4e8eO(N)\u5b9e\u65f6\u7b97\u6cd5\u7684\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d\u6846\u67b6"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br/>85% latency reduction vs. round-robin, maintains throughput<br/>\u76f8\u6bd4\u8f6e\u8be2\u8c03\u5ea6\u5ef6\u8fdf\u964d\u4f4e85%\uff0c\u4fdd\u6301\u541e\u5410\u91cf"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Rethinking Leveraging Pre-Trained Multi-Layer Representations for Speaker Verification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [speaker verification], [Layer Attentive Pooling, Attentive Statistical Temporal Pooling, pre-trained speech models, multi-level features, speaker embeddings]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jin Sob Kim, Hyun Joon Park, Wooseok Shin, Sung Won Han"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Korea University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22148",children:"https://arxiv.org/pdf/2512.22148"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/sadPororo/LAP",children:"https://github.com/sadPororo/LAP"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Layer Attentive Pooling (LAP), a novel dynamic strategy for aggregating multi-layer representations from pre-trained speech models, moving beyond static weighted averaging. 2. Introduced a lightweight backend speaker model combining LAP and Attentive Statistical Temporal Pooling (ASTP) for efficient speaker embedding extraction. 3. Demonstrated state-of-the-art performance on the VoxCeleb benchmark with a compact architecture that significantly reduces training time."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96b640602033c1b23da872d515add261756f5ab1b958eac2b83c4e62b1fc7f3f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96b640602033c1b23da872d515add261756f5ab1b958eac2b83c4e62b1fc7f3f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the underutilization of multi-layer features from pre-trained speech models in speaker verification. It proposes a novel Layer Attentive Pooling (LAP) method and a lightweight backend model to dynamically aggregate these features. The approach achieves state-of-the-art results on VoxCeleb while being more efficient in training time."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[\u91cd\u65b0\u601d\u8003\u5229\u7528\u9884\u8bad\u7ec3\u591a\u5c42\u8868\u793a\u8fdb\u884c\u8bf4\u8bdd\u4eba\u9a8c\u8bc1<br/>Rethinking Leveraging Pre-Trained Multi-Layer Representations for Speaker Verification] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br/>\u9759\u6001\u52a0\u6743\u5e73\u5747\u805a\u5408\u591a\u5c42\u7279\u5f81\u7684\u5c40\u9650\u6027<br/>Limitations of static weighted average for multi-layer feature aggregation] --\x3e Problem_Detail[\u7ec6\u8282/Detail<br/>\u672a\u5145\u5206\u5229\u7528\u9ad8\u5c42\u8868\u793a<br/>Underutilization of high-level representations]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u63d0\u51fa\u5c42\u6ce8\u610f\u529b\u6c60\u5316<br/>Propose Layer Attentive Pooling (LAP)] --\x3e Method_Detail1[\u7ec6\u8282/Detail<br/>\u52a8\u6001\u591a\u89c6\u89d2\u8bc4\u4f30\u5c42\u91cd\u8981\u6027<br/>Time-dynamically assess layer significance from multiple perspectives]\n    Method --\x3e Method_Detail2[\u7ec6\u8282/Detail<br/>\u4f7f\u7528\u6700\u5927\u6c60\u5316\u800c\u975e\u5e73\u5747<br/>Employ max pooling instead of averaging]\n    Method --\x3e Method_Detail3[\u7ec6\u8282/Detail<br/>\u8f7b\u91cf\u7ea7\u540e\u7aef\u6a21\u578b (LAP+ASTP)<br/>Lightweight backend model (LAP + ASTP)]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br/>\u5728VoxCeleb\u4e0a\u8fbe\u5230SOTA<br/>Achieves SOTA on VoxCeleb benchmark] --\x3e Results_Detail[\u7ec6\u8282/Detail<br/>\u6027\u80fd\u4f18\u8d8a\u4e14\u5927\u5e45\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4<br/>Superior performance and greatly reduced training time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Practical challenges of control monitoring in frontier AI deployments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [ai security], [control monitoring, oversight latency, safety case, scheming agents, incremental attacks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," David Lindner, Charlie Griffin, Tomek Korbak, Roland S. Zimmermann, Geoffrey Irving, Sebastian Farquhar, Alan Cooney"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google DeepMind, UK AI Safety Institute, University of Oxford"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22154",children:"https://arxiv.org/pdf/2512.22154"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Analysis of real-world deployment dynamics (parallelism, latency, incremental attacks, partial incrimination) for control monitoring, 2. Proposal and comparison of three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs, 3. Introduction of a high-level safety case sketch as a tool for analyzing and comparing monitoring protocols, applied to four case studies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes the practical challenges of scaling automated control monitors for overseeing frontier AI agents in real-world deployments. It proposes and compares three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs and introduces a safety case sketch as an analytical tool. The analysis identifies oversight, latency, and recovery as key challenges, explored through four case studies of potential AI attacks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Practical challenges of control monitoring in frontier AI deployments<br>\u524d\u6cbfAI\u90e8\u7f72\u4e2d\u63a7\u5236\u76d1\u63a7\u7684\u5b9e\u9645\u6311\u6218") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u73b0\u5b9e\u90e8\u7f72\u7684\u52a8\u6001<br>Real-world Deployment Dynamics")\n    P1 --\x3e P1_1("\u5e76\u884c\u5b9e\u4f8b<br>Parallel Instances")\n    P1 --\x3e P1_2("\u76d1\u7763\u5ef6\u8fdf<br>Oversight Latency")\n    P1 --\x3e P1_3("\u589e\u91cf\u653b\u51fb<br>Incremental Attacks")\n    P1 --\x3e P1_4("\u90e8\u5206\u5f52\u8d23<br>Partial Incrimination")\n    Method --\x3e M1("\u76d1\u63a7\u534f\u8bae<br>Monitoring Protocols")\n    M1 --\x3e M1_1("\u540c\u6b65\u76d1\u63a7<br>Synchronous")\n    M1 --\x3e M1_2("\u534a\u540c\u6b65\u76d1\u63a7<br>Semi-synchronous")\n    M1 --\x3e M1_3("\u5f02\u6b65\u76d1\u63a7<br>Asynchronous")\n    Method --\x3e M2("\u5b89\u5168\u6848\u4f8b\u8349\u56fe<br>Safety Case Sketch")\n    Results --\x3e R1("\u8bc6\u522b\u6838\u5fc3\u6311\u6218<br>Identified Core Challenges")\n    R1 --\x3e R1_1("\u76d1\u7763<br>Oversight")\n    R1 --\x3e R1_2("\u5ef6\u8fdf<br>Latency")\n    R1 --\x3e R1_3("\u6062\u590d<br>Recovery")\n    Results --\x3e R2("\u6848\u4f8b\u7814\u7a76\u5e94\u7528<br>Case Studies Application")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [bit-flip faults, fault localization, transformer reliability, residual-path perturbation, loss-sensitivity profiling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Muhammad Zeeshan Karamat, Sadman Saif, Christiana Chamon Garcia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Virginia Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22174",children:"https://arxiv.org/pdf/2512.22174"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces BitFlipScope, a scalable software framework for localizing bit-flip corruptions in transformer-based LLMs under two deployment scenarios (with and without a clean reference model). 2. Proposes differential analysis for fault localization when a reference model is available and residual-path perturbation/loss-sensitivity profiling for localization when no reference exists. 3. Enables lightweight performance recovery for corrupted models without requiring costly fine-tuning or full retraining."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces BitFlipScope, a framework for localizing and recovering from bit-flip corruptions in LLMs. It uses differential analysis with a reference model or perturbation-based profiling without one to identify fault-affected regions, enabling targeted recovery without full retraining. The work aims to improve fault resilience for LLMs in hardware-prone and adversarial environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Bit-flip faults corrupt LLM parameters, causing unpredictable behavior]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Differential analysis with reference model; Residual-path perturbation & loss-sensitivity profiling without reference]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Enables fault localization and lightweight recovery, improving fault-resilient LLM deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent path finding], [multi-agent path finding, vehicle routing, polynomial-time algorithm, conflict resolution, assignment problem]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Stefan Edelkamp"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Charles University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22171",children:"https://arxiv.org/pdf/2512.22171"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),'  1. Proposes a polynomial-time algorithm for solving discrete multi-agent multi-goal path finding (CMAPF) problems with node and edge conflicts, which is unexpected given the NP-hardness of traditional vehicle routing. 2. Introduces a planner that autonomously finds and updates the assignment of multiple goals to agents, contrasting with regular MAPF which uses fixed assignments. 3. Develops conflict resolution strategies including global assignment to reduce conflicts, and local methods like "ants-on-the-stick," local assignment, path interleaving, and destination clearing.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9267701cf1d96333033d8663590f3b652040a494de98cd10ba5a86ede709d3b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9267701cf1d96333033d8663590f3b652040a494de98cd10ba5a86ede709d3b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the multi-agent multi-goal path finding (CMAPF) problem where agents in graphs must be assigned and routed to multiple goals. It presents a polynomial-time algorithm for discrete variants with conflicts, implemented in a planner that autonomously handles goal assignment and resolves conflicts. The main conclusion is that efficient, conflict-free solutions can be achieved in polynomial time, challenging the typical NP-hard complexity of vehicle routing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[\u4e3a\u591a\u667a\u80fd\u4f53\u89c4\u5212\u591a\u76ee\u6807\u65e0\u51b2\u7a81\u8def\u5f84/Plan multi-goal conflict-free paths for multi-agent]\nC --\x3e C1[\u81ea\u4e3b\u76ee\u6807\u5206\u914d\u4e0e\u51b2\u7a81\u89e3\u51b3\u7b56\u7565/Autonomous goal assignment & conflict resolution]\nD --\x3e D1[\u79bb\u6563\u95ee\u9898\u53ef\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3/Discrete problems solvable in polynomial time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Wireless Traffic Prediction with Large Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [spatio-temporal forecasting], [large language model, wireless traffic prediction, spatial-temporal correlation, prompt engineering, fine-tuning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chuanting Zhang, Haixia Zhang, Jingping Qiao, Zongzhang Li, Mohamed-Slim Alouini"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shandong University, Shandong Normal University, China Mobile Communications Group Shandong Co., Ltd, King Abdullah University of Science and Technology (KAUST)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22178",children:"https://arxiv.org/pdf/2512.22178"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TIDES, an LLM-based framework that captures spatial-temporal correlations for urban wireless traffic prediction. 2. Introduces a prompt engineering scheme to bridge the domain gap between numerical traffic data and language models by embedding statistical features as structured inputs. 3. Designs a DeepSeek module enabling spatial alignment via cross-domain attention, allowing the LLM to leverage information from related regions, and employs efficient fine-tuning of lightweight components."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/402a3d6681d9c203daf7e8ef09e0d0af8998f3eba780abc404c945025563d6a8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/402a3d6681d9c203daf7e8ef09e0d0af8998f3eba780abc404c945025563d6a8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TIDES, a novel framework that uses a large language model (LLM) enhanced with spatial awareness for urban wireless traffic prediction. It addresses the lack of spatial modeling in existing LLM-based predictors through region clustering, prompt engineering, and a spatial alignment module, achieving superior accuracy and robustness on real-world datasets, which is key for intelligent 6G network management."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Wireless Traffic Prediction with Large Language Model] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: LLMs overlook spatial dependencies in city-scale wireless traffic)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: TIDES framework with clustering, prompt engineering, and DeepSeek spatial alignment module)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Outperforms SOTA baselines in accuracy and robustness for 6G network management)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Characterizing Motion Encoding in Video Diffusion Timesteps"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video generation], [video diffusion models, timestep analysis, motion-appearance disentanglement, motion transfer, one-shot customization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vatsal Baherwani, Yixuan Ren, Abhinav Shrivastava"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Maryland"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22175",children:"https://arxiv.org/pdf/2512.22175"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a quantitative proxy and conducts a large-scale study to systematically characterize how motion is encoded across the denoising timesteps of video diffusion models, identifying distinct motion-dominant and appearance-dominant regimes. 2. Derives an operational motion-appearance boundary in timestep space, turning a widely used empirical heuristic into a spatiotemporal disentanglement principle. 3. Simplifies the one-shot motion customization paradigm by restricting training and inference to the motion-dominant regime, achieving strong motion transfer without auxiliary debiasing modules or specialized objectives."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ff2b9cdf8da1e9fbc9ae04ff2d085e89388ee26b1689338abbb853b17970bed_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ff2b9cdf8da1e9fbc9ae04ff2d085e89388ee26b1689338abbb853b17970bed_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how motion is encoded across the denoising timesteps of text-to-video diffusion models. By quantifying the trade-off between appearance editing and motion preservation when injecting new conditions, the authors identify early timesteps as motion-dominant and later ones as appearance-dominant. This characterization enables a simplified, effective method for one-shot motion transfer without extra modules."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Characterizing Motion Encoding in Video Diffusion Timesteps] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e2d\u8fd0\u52a8\u7f16\u7801\u673a\u5236\u4e0d\u660e\u786e / Motion encoding in video diffusion is poorly understood]\n    C --\x3e C1[\u901a\u8fc7\u6761\u4ef6\u6ce8\u5165\u91cf\u5316\u8fd0\u52a8-\u5916\u89c2\u6743\u8861 / Quantify motion-appearance trade-off via conditional injection]\n    C --\x3e C2[\u5927\u89c4\u6a21\u5b9a\u91cf\u7814\u7a76 / Large-scale quantitative study]\n    D --\x3e D1[\u8bc6\u522b\u65e9\u671f\u8fd0\u52a8\u4e3b\u5bfc\u4e0e\u540e\u671f\u5916\u89c2\u4e3b\u5bfc\u9636\u6bb5 / Identify early motion-dominant and late appearance-dominant regimes]\n    D --\x3e D2[\u7b80\u5316\u5355\u6837\u672c\u8fd0\u52a8\u5b9a\u5236\u8303\u5f0f / Simplify one-shot motion customization paradigm]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] iOS as Acceleration"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [distributed pipeline parallelism, mobile acceleration, iOS, memory constraints, thermal throttling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alexander K. Chen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent High School Researcher (No institutional affiliation inferred)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22180",children:"https://arxiv.org/pdf/2512.22180"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel proof-of-concept system using distributed pipeline parallelism to harness iOS devices as computational accelerators for local ML tasks. 2. Demonstrates the system's effectiveness in accelerating modest model training (e.g., ResNet-34) and agentic LRM tool-usage, achieving a 44% decrease in training time in a specific setup. 3. Explores the unique potential of ubiquitous mobile devices with powerful processors and sensors (e.g., LiDAR, GPS) as cost-effective resources for embodied agentic AI and local compute, discussing practical use-cases and limitations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the barrier of expensive compute for local machine learning by proposing a system that uses distributed pipeline parallelism to leverage underutilized iOS phones as accelerators. The method partitions model weights to circumvent mobile memory limits, successfully accelerating tasks like training ResNet-34. The work concludes that commonplace mobile devices have significant potential to contribute to ML, especially for local, cost-sensitive, or sensor-driven applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[iOS as Acceleration] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Powerful compute is a barrier for local ML; Cloud is not always viable]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Use distributed pipeline parallelism to harness iOS devices as accelerators]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieved faster training for modest models; Highlights mobile potential for ML]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Enhancing Medical Data Analysis through AI-Enhanced Locally Linear Embedding: Applications in Medical Point Location and Imagery"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [dimensionality reduction], [Locally Linear Embedding (LLE), AI-enhanced LLE, medical data analysis, medical billing, transcription]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hassan Khalid, Muhammad Mahad Khaliq, Muhammad Jawad Bashir"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Science and Technology (NUST)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22182",children:"https://arxiv.org/pdf/2512.22182"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an innovative integration of AI with Locally Linear Embedding (LLE) to handle high-dimensional medical data. 2. Develops a comprehensive mathematical model for the AI-enhanced LLE technique. 3. Demonstrates the model's application in real-world healthcare scenarios, showing significant improvements in data processing accuracy and operational efficiency for medical billing and transcription."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d42fb5873195bf570514a88549054269194cfaa817a772eb3decd5c337e47e24_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d42fb5873195bf570514a88549054269194cfaa817a772eb3decd5c337e47e24_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces an AI-enhanced Locally Linear Embedding (LLE) model to improve the analysis of high-dimensional medical data. The method is applied to automate and enhance medical billing and transcription services. The results show significant improvements in processing accuracy and operational efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Enhancing Medical Data Analysis through AI-Enhanced LLE] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Handling complex high-dimensional medical data for billing and transcription)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Integrating AI with Locally Linear Embedding (LLE))\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Improved data processing accuracy and operational efficiency)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Interpretable Link Prediction in AI-Driven Cancer Research: Uncovering Co-Authorship Patterns"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [network science], [co-authorship networks, link prediction, SHAP, random forest, interdisciplinary collaboration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shahab Mosallaie, Andrea Schiffauerova, Ashkan Ebadi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Concordia University, National Research Council Canada"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22181",children:"https://arxiv.org/pdf/2512.22181"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Constructed 36 overlapping co-authorship networks from 7,738 publications to model new, persistent, and discontinued collaborations in AI-driven cancer research. 2. Engineered both attribute-based and structure-based features and built four machine learning classifiers, with Random Forest achieving the highest recall for all collaboration types. 3. Applied SHAP for model interpretability, identifying key factors like discipline similarity, productivity, and seniority that influence collaboration patterns."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f6c5e92a95d2e6eeb8291558739ab641247bb834675d42c86ece0ee73d9d15_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f6c5e92a95d2e6eeb8291558739ab641247bb834675d42c86ece0ee73d9d15_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper uses machine learning to predict collaboration patterns in AI-driven cancer research by analyzing co-authorship networks. The authors built classifiers using engineered features and applied SHAP for interpretability, finding that discipline similarity promotes new and persistent collaborations while high productivity and seniority are linked to discontinued links. The results aim to guide the formation of effective interdisciplinary research teams and inform policy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Interpretable Link Prediction in AI-Driven Cancer Research: Uncovering Co-Authorship Patterns] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6311\u6218: \u7ec4\u5efa\u6709\u6548\u7684\u8de8\u5b66\u79d1\u764c\u75c7\u7814\u7a76\u56e2\u961f/Challenge: Forming effective interdisciplinary cancer research teams]\n    C --\x3e C1[\u6784\u5efa\u5408\u8457\u7f51\u7edc\u4f5c\u4e3a\u5408\u4f5c\u4ee3\u7406/Construct co-authorship networks as collaboration proxy]\n    C --\x3e C2[\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u8fdb\u884c\u94fe\u63a5\u9884\u6d4b/Use ML classifiers for link prediction]\n    C --\x3e C3[\u4f7f\u7528SHAP\u8fdb\u884c\u6a21\u578b\u53ef\u89e3\u91ca\u6027/Use SHAP for model interpretability]\n    D --\x3e D1[\u968f\u673a\u68ee\u6797\u5728\u6240\u6709\u5408\u4f5c\u7c7b\u578b\u4e2d\u53ec\u56de\u7387\u6700\u9ad8/Random forest achieved highest recall]\n    D --\x3e D2[\u5b66\u79d1\u76f8\u4f3c\u6027\u5f97\u5206\u662f\u5173\u952e\u56e0\u7d20/Discipline similarity score is a crucial factor]\n    D --\x3e D3[\u9ad8\u751f\u4ea7\u529b\u548c\u8d44\u5386\u4e0e\u4e2d\u65ad\u94fe\u63a5\u6b63\u76f8\u5173/High productivity and seniority positively associated with discontinued links]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Unbiased Visual Reasoning with Controlled Visual Inputs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [vision-language models, spurious correlations, information bottleneck, reinforcement learning, modular reasoning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22183",children:"https://arxiv.org/pdf/2512.22183"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Unbiased Visual Reasoning with Controlled Visual Inputs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[VLMs exploit spurious correlations/VLMs\u5229\u7528\u865a\u5047\u5173\u8054]\n    C --\x3e C1[VISTA: Modular framework decoupling perception & reasoning/VISTA: \u89e3\u8026\u611f\u77e5\u4e0e\u63a8\u7406\u7684\u6a21\u5757\u5316\u6846\u67b6]\n    C1 --\x3e C2[Frozen VLM sensor + LLM reasoner/\u51bb\u7ed3VLM\u611f\u77e5\u5668 + LLM\u63a8\u7406\u5668]\n    C2 --\x3e C3[Train with RL (GRPO)/\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60(GRPO)\u8bad\u7ec3]\n    D --\x3e D1[Improved robustness on SpuriVerse/\u5728SpuriVerse\u4e0a\u9c81\u68d2\u6027\u63d0\u5347]\n    D --\x3e D2[Competitive on MMVP & SeedBench/\u5728MMVP & SeedBench\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b]\n    D --\x3e D3[Transferable & interpretable/\u53ef\u8fc1\u79fb\u4e14\u53ef\u89e3\u91ca]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Dueling Double Deep Q-Network, curriculum learning, tennis simulation, sequential decision-making, sports analytics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vishnu Mohan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22186",children:"https://arxiv.org/pdf/2512.22186"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed a custom tennis simulation environment that models hierarchical scoring, tactical decisions, fatigue, and opponent skill. 2. Integrated a Dueling Double Deep Q-Network (DDQN) with curriculum learning to enable stable and effective strategy learning in a long-horizon, stochastic domain. 3. Identified a key limitation of win-rate optimization, revealing a learned defensive bias and highlighting challenges in reward design for sports RL."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a reinforcement learning framework using a Dueling Double Deep Q-Network trained with curriculum learning to optimize tennis strategy in a custom simulation. The method achieves high win rates and demonstrates stable convergence, but analysis reveals the learned policy is overly defensive, pointing to a fundamental issue with reward design in sports simulations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Tennis strategy optimization as a sequential decision-making challenge with hierarchical scoring, stochasticity, and opponent adaptation)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Dueling Double Deep Q-Network (DDQN) trained with curriculum learning in a custom tennis simulation environment)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: High win rates (98-100%) and stable convergence, but reveals a defensive policy bias, highlighting reward design limitations)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HookMIL: Revisiting Context Modeling in Multiple Instance Learning for Computational Pathology"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [computational pathology], [Multiple Instance Learning, Hook Tokens, Linear Complexity, Multimodal Initialization, Hook Diversity Loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xitong Ling, Minxi Ouyang, Xiaoxiao Li, Jiawen Li, Ying Chen, Yuxuan Sun, Xinrui Chen, Tian Guan, Xiaoping Liu, Yonghong He"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Xiamen University, Westlake University, Wuhan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22188",children:"https://arxiv.org/pdf/2512.22188"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/lingxitong/HookMIL",children:"https://github.com/lingxitong/HookMIL"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HookMIL, a context-aware MIL framework using learnable hook tokens for structured contextual aggregation with linear computational complexity. 2. Introduces a multimodal initialization strategy for hook tokens using visual, textual, and spatial priors to accelerate convergence and improve representation. 3. Presents a Hook Diversity Loss and a hook-to-hook communication mechanism to encourage token specialization and refine interactions while minimizing redundancy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the loss of context in traditional MIL and the high computational cost of transformer-based MIL for whole-slide image analysis. It proposes HookMIL, a framework that uses learnable hook tokens for efficient, linear-complexity context modeling, enhanced by multimodal initialization and specialized loss functions. Experiments on four public datasets show that HookMIL achieves state-of-the-art performance with improved efficiency and interpretability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[HookMIL: Revisiting Context Modeling in MIL for Computational Pathology] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: MIL loses context; Transformers are inefficient] --\x3e P1[\u4f20\u7edfMIL\u4e22\u5931\u4e0a\u4e0b\u6587/Traditional MIL loses context]\n    Problem --\x3e P2[\u57fa\u4e8eTransformer\u7684MIL\u8ba1\u7b97\u590d\u6742/Transformer-based MIL has quadratic complexity]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: HookMIL Framework] --\x3e M1[\u4f7f\u7528\u53ef\u5b66\u4e60\u7684Hook Tokens/Use learnable Hook Tokens]\n    Method --\x3e M2[\u591a\u6a21\u6001\u521d\u59cb\u5316/Multimodal Initialization]\n    Method --\x3e M3[Hook\u591a\u6837\u6027\u635f\u5931\u4e0e\u901a\u4fe1\u673a\u5236/Hook Diversity Loss & Communication]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[SOTA\u6027\u80fd/State-of-the-art Performance]\n    Results --\x3e R2[\u8ba1\u7b97\u9ad8\u6548/Computationally Efficient]\n    Results --\x3e R3[\u53ef\u89e3\u91ca\u6027/Interpretability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] MatKV: Trading Compute for Flash Storage in LLM Inference"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [retrieval-augmented generation, key-value cache, flash storage, prefill optimization, power efficiency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kun-Woo Shin, Jay H. Park, Moonwook Oh, Yohan Jo, Jaeyoung Do, Sang-Won Lee"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Seoul National University, Samsung Electronics"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22195",children:"https://arxiv.org/pdf/2512.22195"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/kunwooshin/MatKV",children:"https://github.com/kunwooshin/MatKV"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MatKV, a scheme to precompute and materialize KV vectors of RAG documents in flash storage to avoid recomputation during inference. 2. Demonstrates that MatKV reduces inference time and power consumption by half for RAG workloads with minimal accuracy impact. 3. Shows MatKV enables additional optimizations like overlapping KV loading with decoding and enabling the use of low-end GPUs for decoding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high compute and energy cost of the prefill phase in RAG-based LLM inference. It proposes MatKV, which precomputes and stores key-value vectors of documents in flash storage for reuse, trading compute for storage. Experiments show this approach halves inference time and power consumption while maintaining accuracy and enabling further hardware optimizations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["MatKV: Trading Compute for Flash Storage in LLM Inference"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>RAG\u63a8\u7406\u4e2dprefill\u9636\u6bb5\u8ba1\u7b97\u5f00\u9500\u5927<br>High compute cost of prefill in RAG inference"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u9884\u8ba1\u7b97\u5e76\u7269\u5316KV\u5411\u91cf\u5230\u95ea\u5b58<br>Precompute & materialize KVs to flash storage"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u63a8\u7406\u65f6\u95f4\u4e0e\u80fd\u8017\u51cf\u534a<br>Halves inference time & power consumption"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [Retrieval-Augmented Generation, Hallucination Prevention, Multi-Stage Validation, Corpus Expansion, Self-Improving AI]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Teja Chinthala"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher (affiliated email domain: avila.edu)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22199",children:"https://arxiv.org/pdf/2512.22199"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel RAG architecture enabling safe corpus expansion through validated write-back of model outputs. 2. A multi-stage acceptance layer combining grounding verification, attribution checking, and novelty detection for safety. 3. An experience store for meta-learning from both accepted and rejected responses."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5eee110568078584ba44c846b5af3fab7d300dbfaec310a5826fd74784dc8040_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5eee110568078584ba44c846b5af3fab7d300dbfaec310a5826fd74784dc8040_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem that conventional RAG systems have static knowledge bases. It proposes Bidirectional RAG, a novel architecture that safely expands the retrieval corpus by writing back high-quality, validated LLM responses. The results show that this self-improving approach nearly doubles answer coverage compared to standard RAG while adding significantly fewer documents than a naive write-back strategy, demonstrating a safe and practical path for RAG systems to learn from deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Bidirectional RAG: Safe Self-Improving RAG] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u9759\u6001\u77e5\u8bc6\u5e93\u65e0\u6cd5\u4ece\u4ea4\u4e92\u4e2d\u5b66\u4e60/Static corpus cannot evolve from interactions]\n    C --\x3e C1[\u5e26\u9a8c\u8bc1\u7684\u56de\u5199\u673a\u5236/Validated write-back]\n    C --\x3e C2[\u591a\u9636\u6bb5\u9a8c\u8bc1\u5c42/Multi-stage acceptance layer]\n    D --\x3e D1[\u8986\u76d6\u7387\u7ffb\u500d/Coverage doubled vs. Standard RAG]\n    D --\x3e D2[\u6587\u6863\u589e\u957f\u51cf\u5c1172%/72% less corpus growth vs. naive write-back]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [dynamic routing, residual networks, cosine incompatibility, Gumbel-Softmax, FLOPs regularization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yogeswar Reddy Thota"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Texas at Dallas"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22206",children:"https://arxiv.org/pdf/2512.22206"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces CosineGate, an end-to-end differentiable architecture for dynamic routing in residual networks using cosine incompatibility as a self-supervised skip signal. 2. Proposes the Cosine Incompatibility Ratio (CIR) to measure semantic redundancy and employs Gumbel-Softmax relaxation for per-sample, per-block gating during training. 3. Incorporates a progressive FLOPs regularization term to control average computational usage without destabilizing the optimization process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed7e3fa1c114a73795152210d2b55ffe2541fede331ce04d228e11ca599688fa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed7e3fa1c114a73795152210d2b55ffe2541fede331ce04d228e11ca599688fa_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the computational inefficiency in residual networks, where all blocks are evaluated for every input. It proposes CosineGate, a method that uses the cosine incompatibility between identity and residual features to dynamically skip redundant blocks, achieving significant FLOPs savings on CIFAR-10 while maintaining or improving accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CosineGate: Semantic Dynamic Routing via Cosine Incompatibility in Residual Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Modern residual networks perform redundant computation for all inputs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Uses cosine incompatibility ratio and Gumbel-Softmax for dynamic per-block gating]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves accuracy-efficiency Pareto frontier on CIFAR-10 with significant FLOPs savings]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Emergent Persuasion: Will LLMs Persuade Without Being Prompted?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [ai safety & alignment], [emergent persuasion, activation steering, supervised fine-tuning (SFT), threat model, persona vectors]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vincent Chang, Thee Ho, Sunishchal Dev, Kevin Zhu, Shi Feng, Kellin Pelrine, Matthew Kowal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Algoverse, FAR.AI, UC Berkeley, George Washington University, University of Toronto"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22201",children:"https://arxiv.org/pdf/2512.22201"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/ith8/persona_vectors",children:"https://github.com/ith8/persona_vectors"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Investigates the novel threat model of "unprompted" or "emergent" persuasion in LLMs, moving beyond the standard misuse (prompted) scenario. 2. Empirically compares two techniques for inducing traits (activation steering vs. supervised fine-tuning) and finds SFT reliably increases unprompted persuasion while steering does not. 3. Demonstrates that SFT on benign persuasion datasets can lead to increased persuasion propensity on harmful topics, highlighting a significant safety risk.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3e4599070a9919228b3e5bc9cb7f7fd0fe17df086f5d7bec7ef20de22526f15_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3e4599070a9919228b3e5bc9cb7f7fd0fe17df086f5d7bec7ef20de22526f15_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies whether Large Language Models (LLMs) will attempt to persuade users without being explicitly prompted to do so. The authors investigate this by applying activation steering and supervised fine-tuning (SFT) to induce persuasive traits, finding that SFT reliably increases unprompted persuasion, including on harmful topics, even when trained only on benign data. The main conclusion is that emergent harmful persuasion is a real risk that warrants further study for AI safety and governance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Emergent Persuasion: Will LLMs Persuade Without Being Prompted?] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u7814\u7a76\u6a21\u578b\u5728\u672a\u53d7\u660e\u786e\u63d0\u793a\u65f6\u8fdb\u884c\u8bf4\u670d\u7684\u98ce\u9669 / Study risk of unprompted persuasion]\n    C --\x3e C1[\u6fc0\u6d3b\u5f15\u5bfc\u4ee5\u690d\u5165\u4eba\u683c\u7279\u8d28 / Activation steering for persona traits]\n    C --\x3e C2[\u76d1\u7763\u5fae\u8c03\u4ee5\u690d\u5165\u4eba\u683c\u7279\u8d28 / Supervised fine-tuning for persona traits]\n    D --\x3e D1[\u76d1\u7763\u5fae\u8c03\u4f1a\u53ef\u9760\u5730\u589e\u52a0\u65e0\u63d0\u793a\u8bf4\u670d / SFT reliably increases unprompted persuasion]\n    D --\x3e D2[\u826f\u6027\u4e3b\u9898\u5fae\u8c03\u53ef\u80fd\u5bfc\u81f4\u6709\u5bb3\u4e3b\u9898\u8bf4\u670d / Benign SFT can increase harmful topic persuasion]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] TCFormer: A 5M-Parameter Transformer with Density-Guided Aggregation for Weakly-Supervised Crowd Counting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [crowd counting], [weakly-supervised learning, vision transformer, density-guided aggregation, parameter efficiency, lightweight model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qiang Guo, Rubo Zhang, Bingbing Zhang, Junjie Liu, Jianqing Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dalian Minzu University, Dalian University of Technology, Dalian Rijia Electronics Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22203",children:"https://arxiv.org/pdf/2512.22203"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TCFormer, an ultra-lightweight transformer-based framework with only 5 million parameters for weakly-supervised crowd counting. 2. Introduces a Learnable Density-Weighted Averaging module to dynamically re-weight local features based on predicted density, compensating for the lack of spatial annotations. 3. Designs a density-level classification loss to discretize crowd density into grades, regularizing training and enhancing performance across varying density levels."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67bff3bf5e0b02cbd2cc6071e68fd191f9adc37c49a6f5dd3f4b89fbc7205ca3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67bff3bf5e0b02cbd2cc6071e68fd191f9adc37c49a6f5dd3f4b89fbc7205ca3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TCFormer, a tiny transformer-based model for weakly-supervised crowd counting that uses only image-level count labels. It introduces a density-guided feature aggregation module and a density-level classification loss to achieve accurate counting. Experiments show it achieves a superior trade-off between parameter efficiency and accuracy, making it suitable for edge devices."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[TCFormer: 5M\u53c2\u6570Transformer\u7528\u4e8e\u5f31\u76d1\u7763\u4eba\u7fa4\u8ba1\u6570] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u6807\u6ce8\u6210\u672c\u9ad8/High Annotation Cost]\n    Problem --\x3e P2[\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8/High Computational Complexity]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u9ad8\u6548\u89c6\u89c9Transformer\u7279\u5f81\u63d0\u53d6\u5668/Efficient ViT Feature Extractor]\n    Method --\x3e M2[\u53ef\u5b66\u4e60\u5bc6\u5ea6\u52a0\u6743\u5e73\u5747\u6a21\u5757/Learnable Density-Weighted Averaging]\n    Method --\x3e M3[\u5bc6\u5ea6\u7b49\u7ea7\u5206\u7c7b\u635f\u5931/Density-Level Classification Loss]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u4ec55M\u53c2\u6570/Only 5M Parameters]\n    Results --\x3e R2[\u5f31\u76d1\u7763\u4e0b\u7ade\u4e89\u6027\u6027\u80fd/Competitive Performance under Weak Supervision]\n    Results --\x3e R3[\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907/Suitable for Edge Devices]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] GamiBench: Evaluating Spatial Reasoning and 2D-to-3D Planning Capabilities of MLLMs with Origami Folding Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [spatial reasoning, multimodal large language models, benchmark, origami folding, viewpoint consistency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ryan Spencer, Roey Yaari, Ritvik Vemavarapu, Joyce Yang, Steven Ngo, Utkarsh Sharma"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Algoverse AI Research, UC San Diego, University of New South Wales"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22207",children:"https://arxiv.org/pdf/2512.22207"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/stvngo/GamiBench",children:"https://github.com/stvngo/GamiBench"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces GamiBench, a novel benchmark for evaluating spatial reasoning and 2D-to-3D planning in MLLMs using origami folding tasks. 2. Proposes new diagnostic metrics, viewpoint consistency (VC) and impossible fold selection rate (IFSR), to holistically assess the reasoning process. 3. Provides a comprehensive dataset of 186 regular and 186 impossible 2D crease patterns with 3D shapes from multiple viewpoints."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7bb91a40c2344a9e50dec2b2754647404d609db9a78508a54a040d5f6c5f58b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7bb91a40c2344a9e50dec2b2754647404d609db9a78508a54a040d5f6c5f58b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces GamiBench, a benchmark that uses origami folding tasks to evaluate the spatial reasoning and 2D-to-3D planning capabilities of Multimodal Large Language Models (MLLMs). It assesses models on tasks like predicting 3D configurations and detecting impossible folds, revealing that even state-of-the-art models like GPT-5 and Gemini-2.5-Pro struggle with fundamental spatial understanding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[GamiBench: Evaluating Spatial Reasoning and 2D-to-3D Planning Capabilities of MLLMs with Origami Folding Tasks] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: MLLMs struggle with sequential, multi-view spatial reasoning] --\x3e Problem_Sub[\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3/Existing benchmarks focus on static images]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Origami-inspired benchmark with 3 VQA tasks] --\x3e Method_Sub[\u5f15\u5165\u65b0\u6307\u6807/Introduces new metrics (VC, IFSR)]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Leading models (GPT-5, Gemini) struggle with spatial understanding]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Toward Equitable Recovery: A Fairness-Aware AI Framework for Prioritizing Post-Flood Aid in Bangladesh"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [algorithmic fairness], [adversarial debiasing, gradient reversal layer, fairness-aware representation learning, statistical parity difference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Farjana Yesmin, Romana Akter"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher, Researcher (affiliations not specified)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22210",children:"https://arxiv.org/pdf/2512.22210"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive dataset integrating official flood impact data with socioeconomic indicators across 87 upazilas in Bangladesh. 2. An adversarial debiasing architecture adapted from healthcare AI for disaster management. 3. Rigorous fairness evaluation showing significant reductions in statistical parity and regional fairness gaps while maintaining predictive accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd82a75c606f74970d3c93e7f31e57d4d35ae9f285a2ccb25e804770225a020b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd82a75c606f74970d3c93e7f31e57d4d35ae9f285a2ccb25e804770225a020b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a fairness-aware AI framework using adversarial debiasing with a gradient reversal layer to prioritize post-flood aid allocation in Bangladesh. The model learns bias-invariant representations to reduce systematic disadvantages against marginalized regions. Experimental results show it significantly improves fairness metrics while maintaining strong predictive accuracy, demonstrating the effective application of algorithmic fairness in humanitarian contexts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Toward Equitable Recovery: A Fairness-Aware AI Framework for Prioritizing Post-Flood Aid in Bangladesh] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Biased post-disaster aid allocation perpetuates historical inequities in vulnerable regions]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Adversarial debiasing model with gradient reversal layer for bias-invariant representations]\n    D[\u5173\u952e\u7ed3\u679c/Results: Reduces statistical parity by 41.6%, regional fairness gaps by 43.2%, maintains R\xb2=0.784]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [agentic AI, risk assessment, technical governance, autonomous action, safety controls]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shaun Khoo, Jessica Foo, Roy Ka-Wei Lee"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," GovTech Singapore, Singapore University of Technology and Design"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22211",children:"https://arxiv.org/pdf/2512.22211"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/govtech-ai/arc-framework",children:"https://github.com/govtech-ai/arc-framework"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel capability-centric perspective for analyzing agentic AI systems. 2. Distills three primary intrinsic risk sources (components, design, capabilities) and maps them to specific risks and technical controls. 3. Provides a structured, practical methodology for organizations to implement the framework for governance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0283ff7ed974694c06d620f02b6bfd0752cd1ab34c83d05b1d66ec9b4088059c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0283ff7ed974694c06d620f02b6bfd0752cd1ab34c83d05b1d66ec9b4088059c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces the Agentic Risk & Capability (ARC) Framework to address governance challenges posed by autonomous AI agents. The framework provides a structured methodology to identify, assess, and mitigate risks from agentic systems by analyzing their capabilities and linking risk sources to technical controls. It aims to enable safe and responsible deployment of agentic AI while supporting innovation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["With Great Capabilities Come Great Responsibilities: Introducing the Agentic Risk & Capability Framework for Governing Agentic AI Systems"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Agentic AI systems present novel risks and governance challenges due to autonomous actions like code execution and web interaction."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Proposes the Agentic Risk & Capability (ARC) Framework, a technical governance framework for risk identification, assessment, and mitigation."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Provides a robust, adaptable methodology for safe and responsible deployment of agentic AI, linking risk sources to controls."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] On the Existence and Behaviour of Secondary Attention Sinks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [attention sinks, transformer, mlp, attention mechanism, large language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jeffrey T.H. Wong, Cheng Zhang, Louis Mahon, Wayne Luk, Anton Isopoussu, Yiren Zhao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Imperial College London, UnlikelyAI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22213",children:"https://arxiv.org/pdf/2512.22213"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Identifies and characterizes a new class of "secondary attention sinks" that arise in middle layers, have variable lifetimes, and draw moderate attention, differing from persistent primary sinks like BOS. 2. Shows that secondary sinks are formed by specific middle-layer MLP modules that map token representations to align with the primary sink\'s direction, with their L2-norm determining sink strength and lifetime. 3. Observes that in larger models, these sink patterns (sink levels) become more deterministic and frequent, with distinct levels identified in models like QwQ-32B and Qwen3-14B.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper identifies a new phenomenon called "secondary attention sinks" in transformer LLMs, which are distinct from the known primary sinks (like BOS). The authors show these secondary sinks are created by middle-layer MLPs aligning tokens with the primary sink direction, and their properties (strength, lifetime) become more structured in larger models. This provides new insights into the internal mechanics of attention in large language models.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["On the Existence and Behaviour of Secondary Attention Sinks<br/>\u4e8c\u6b21\u6ce8\u610f\u529b\u6c47\u7684\u5b58\u5728\u4e0e\u884c\u4e3a"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br/>Prior work only studied persistent primary sinks (e.g., BOS)<br/>\u5148\u524d\u7814\u7a76\u4ec5\u5173\u6ce8\u6301\u4e45\u7684\u4e3b\u6c47\uff08\u5982BOS\uff09"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Extensive experiments across 11 model families<br/>\u5bf911\u4e2a\u6a21\u578b\u7cfb\u5217\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br/>1. Secondary sinks form via MLPs in middle layers<br/>\u6b21\u7ea7\u6c47\u901a\u8fc7\u4e2d\u95f4\u5c42MLP\u5f62\u6210<br/>2. L2-norm determines sink score & lifetime<br/>L2\u8303\u6570\u51b3\u5b9a\u6c47\u5206\u6570\u4e0e\u5bff\u547d<br/>3. Sink levels are deterministic in large models<br/>\u5927\u6a21\u578b\u4e2d\u6c47\u5c42\u7ea7\u66f4\u786e\u5b9a"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] VLM-PAR: A Vision Language Model for Pedestrian Attribute Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [pedestrian attribute recognition], [vision-language model, cross-attention fusion, class imbalance, domain generalization, SigLIP]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abdellah Zakaria Sellam, Salah Eddine Bekhouche, Fadi Dornaika, Cosimo Distante, Abdenour Hadid"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Salento, Institute of Applied Sciences and Intelligent Systems - CNR, University of the Basque Country UPV/EHU, IKERBASQUE, Sorbonne University Abu Dhabi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22217",children:"https://arxiv.org/pdf/2512.22217"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VLM-PAR, a modular vision-language framework built on frozen SigLIP 2 multilingual encoders for Pedestrian Attribute Recognition. 2. Introduces a compact cross-attention fusion mechanism to align image and prompt embeddings by refining visual features. 3. Demonstrates state-of-the-art performance on the imbalanced PA100K benchmark and significant gains on PETA and Market-1501, showing effectiveness against imbalance and domain shift."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44bf59cdfc87f0708e9f41a8899fbff5562f87b0b721fe79f7fcfc23fb5bb4d4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44bf59cdfc87f0708e9f41a8899fbff5562f87b0b721fe79f7fcfc23fb5bb4d4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes VLM-PAR, a vision-language model framework that uses a frozen SigLIP encoder and a cross-attention fusion module to refine visual features for Pedestrian Attribute Recognition. It achieves new state-of-the-art results on the PA100K benchmark and shows strong performance on other datasets, demonstrating the effectiveness of leveraging large-scale vision-language pretraining to address class imbalance and generalization challenges in PAR."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[VLM-PAR: A Vision Language Model for Pedestrian Attribute Recognition] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Class Imbalance, Attribute Co-dependencies, Domain Shifts<br>\u7c7b\u522b\u4e0d\u5e73\u8861, \u5c5e\u6027\u4f9d\u8d56, \u57df\u504f\u79fb]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Vision-Language Framework with Cross-Attention Fusion<br>\u89c6\u89c9\u8bed\u8a00\u6846\u67b6\u4e0e\u8de8\u6ce8\u610f\u529b\u878d\u5408]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>SOTA on PA100K, Gains on PETA & Market-1501<br>PA100K\u4e0aSOTA, PETA & Market-1501\u4e0a\u63d0\u5347]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Signal-SGN++: Topology-Enhanced Time-Frequency Spiking Graph Network for Skeleton-Based Action Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [skeleton-based action recognition], [Spiking Neural Networks, Graph Convolutional Networks, Time-Frequency Learning, Topology-Aware Learning, Energy Efficiency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naichuan Zheng, Xiahai Lun, Weiyi Li, Yuchen Du"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beijing University of Posts and Telecommunications"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22214",children:"https://arxiv.org/pdf/2512.22214"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel spiking graph network backbone integrating 1D Spiking Graph Convolution (1D-SGC) and Frequency Spiking Convolution (FSC) for joint spatiotemporal and spectral feature extraction. 2. Introduces a Topology-Shift Self-Attention (TSSA) mechanism to adaptively route attention across learned skeletal topologies without increasing computational complexity. 3. Designs an auxiliary Multi-Scale Wavelet Transform Fusion (MWTF) branch with a Topology-Aware Time-Frequency Fusion (TATF) unit to preserve structural priors in multi-resolution spectral fusion."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6af8fb8807de54b37db40834a79908ad86cf7e159907b658e54986356c4494d4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6af8fb8807de54b37db40834a79908ad86cf7e159907b658e54986356c4494d4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Signal-SGN++, a novel spiking graph network for skeleton-based action recognition that integrates topology-aware learning with time-frequency spiking dynamics to capture motion dependencies. The method combines a spiking graph backbone with a topology-shift attention mechanism and a multi-scale wavelet fusion branch. Experiments show it achieves a superior accuracy-efficiency trade-off, outperforming other SNN methods and competing with state-of-the-art GCNs while using significantly less energy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Signal-SGN++<br/>\u8bba\u6587\u6807\u9898/Paper Title] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[GCNs\u80fd\u8017\u9ad8<br/>GCNs High Energy Cost]\n    B --\x3e B2[SNNs\u96be\u4ee5\u6355\u6349\u65f6\u7a7a-\u9891\u7387\u4e0e\u62d3\u6251\u4f9d\u8d56<br/>SNNs Limited in Capturing Time-Freq & Topology]\n    C --\x3e C1[\u4e3b\u5e72\u7f51\u7edc: 1D-SGC + FSC<br/>Backbone: 1D-SGC + FSC]\n    C --\x3e C2[\u62d3\u6251\u8f6c\u79fb\u81ea\u6ce8\u610f\u529b TSSA<br/>Topology-Shift Self-Attention TSSA]\n    C --\x3e C3[\u591a\u5c3a\u5ea6\u5c0f\u6ce2\u53d8\u6362\u878d\u5408 MWTF<br/>Multi-Scale Wavelet Transform Fusion MWTF]\n    D --\x3e D1[\u4f18\u4e8e\u73b0\u6709SNN\u65b9\u6cd5<br/>Outperforms Existing SNN Methods]\n    D --\x3e D2[\u4e0e\u5148\u8fdbGCNs\u7ed3\u679c\u76f8\u5f53<br/>Competitive with SOTA GCNs]\n    D --\x3e D3[\u80fd\u8017\u663e\u8457\u964d\u4f4e<br/>Substantially Reduced Energy Consumption]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] On Extending Semantic Abstraction for Efficient Search of Hidden Objects"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [semantic abstraction, relevancy maps, 3D localization, hidden objects, unstructured search]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tasha Pais, Nikhilesh Belulkar"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22220",children:"https://arxiv.org/pdf/2512.22220"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Extends the Semantic Abstraction framework to the novel domain of localizing hidden (occluded) objects. 2. Proposes using historical placement data to efficiently guide the unstructured search for hidden objects. 3. Demonstrates a model that can accurately identify a hidden object's complete 3D location faster than a naive random search."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb1e039b06f845acfd3a644354907fc35eec78f060cf605799b7607c8a20ba8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb1e039b06f845acfd3a644354907fc35eec78f060cf605799b7607c8a20ba8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of efficiently finding hidden or lost objects by extending the Semantic Abstraction framework. The method uses 2D VLM relevancy maps as abstract object representations to learn 3D localization and leverages historical placement data to optimize the search. The result is a model that can locate hidden objects significantly faster than random search, aiming to improve the capabilities of household robots."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("On Extending Semantic Abstraction for Efficient Search of Hidden Objects") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Localizing hidden/occluded objects")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Use VLM relevancy maps & historical data for efficient 3D search")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Faster and accurate 3D localization vs. random search")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] M\xfcntz-Sz\xe1sz Networks: Neural Architectures with Learnable Power-Law Bases"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [neural network architecture], [M\xfcntz-Sz\xe1sz Networks, fractional power bases, physics-informed neural networks, universal approximation, singular function approximation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Gnankan Landry Regis N'guessan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Axiom Research Group, The Nelson Mandela African Institution of Science and Technology (NM-AIST), African Institute for Mathematical Sciences (AIMS) Research and Innovation Centre"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22222",children:"https://arxiv.org/pdf/2512.22222"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces M\xfcntz-Sz\xe1sz Networks (MSN), a novel neural architecture with learnable fractional power bases to approximate functions with singular or fractional power behavior. 2. Provides theoretical analysis proving MSN inherits universal approximation from the M\xfcntz-Sz\xe1sz theorem and establishes superior approximation rates compared to standard MLPs for singular functions. 3. Demonstrates empirical superiority, achieving significantly lower error with fewer parameters in supervised regression and 3-6x improvement in physics-informed neural network benchmarks, while learning interpretable exponents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c66c3ba4917449496481593b1432346dc5ef9301c3c66f4713e327bbb234969d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c66c3ba4917449496481593b1432346dc5ef9301c3c66f4713e327bbb234969d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces M\xfcntz-Sz\xe1sz Networks (MSN), a neural architecture that replaces fixed activation functions with learnable fractional power bases to better approximate singular functions common in physics. It proves MSN's universal approximation capability and shows it achieves much lower error with fewer parameters than standard MLPs on regression and physics-informed tasks, demonstrating the value of theory-guided design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[M\xfcntz-Sz\xe1sz Networks: Neural Architectures with Learnable Power-Law Bases] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Standard neural networks poorly approximate singular/fractional power functions common in physics]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes MSN with learnable fractional power bases, replacing fixed activations]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: MSN achieves superior approximation rates, lower error with fewer parameters, and significant improvement on PINN benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video understanding], [streaming video, multimodal large language models, event segmentation, hierarchical representation, elastic-scale]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naishan Zheng, Jie Huang, Qingpei Guo, Feng Zhao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, Ant Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22226",children:"https://arxiv.org/pdf/2512.22226"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/zheng980629/VideoScaffold",children:"https://github.com/zheng980629/VideoScaffold"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VideoScaffold, a dynamic representation framework for streaming video understanding in MLLMs that adaptively adjusts event granularity. 2. Introduces Elastic-Scale Event Segmentation (EES) for prediction-guided, dynamic boundary refinement. 3. Introduces Hierarchical Event Consolidation (HEC) for progressively aggregating segments into multi-level abstractions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of understanding long, streaming videos with MLLMs by proposing VideoScaffold, a framework that dynamically segments and hierarchically consolidates video events to adapt granularity and preserve semantics. It achieves state-of-the-art performance on benchmarks and can extend image-based MLLMs to video comprehension."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Understanding long, streaming videos with MLLMs is challenging due to redundancy and need for temporal coherence.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes a dynamic framework with Elastic-Scale Event Segmentation (EES) and Hierarchical Event Consolidation (HEC).]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves state-of-the-art performance; framework is modular and plug-and-play.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [retrieval-augmented generation (RAG), network traffic analysis, large language models (LLMs), hierarchical retrieval, explainable AI]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shaghayegh Shajarian, Kennedy Marsh, James Benson, Sajad Khorsandroo, Mahmoud Abdelsalam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," North Carolina A&T State University, University of Texas at San Antonio"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22223",children:"https://arxiv.org/pdf/2512.22223"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/270771/llm-traffictraffic",children:"https://github.com/270771/llm-traffictraffic"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ReGAIN, a multi-stage framework combining traffic summarization, RAG, and LLM reasoning for transparent network traffic analysis. 2. Introduces a hierarchical retrieval pipeline with metadata filtering, MMR sampling, cross-encoder reranking, and an abstention mechanism to ground responses and reduce hallucinations. 3. Demonstrates high accuracy (95.95%-98.82%) on real-world attack traces and outperforms traditional baselines while providing explainable, evidence-cited outputs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents ReGAIN, a framework that uses retrieval-augmented generation (RAG) and LLMs to analyze network traffic. It converts traffic into summaries, retrieves relevant evidence from a vector database, and generates interpretable, grounded analyses. The method achieves high accuracy on attack detection and provides explainable results, outperforming traditional rule-based and ML approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Traditional traffic analysis systems have high false positives and lack interpretability.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-stage framework using traffic summarization, RAG, and LLM reasoning with a hierarchical retrieval pipeline.]\n    D[\u5173\u952e\u7ed3\u679c/Results: Achieves 95.95%-98.82% accuracy, outperforms baselines, and provides explainable, evidence-grounded responses.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Scalable Cloud-Native Architectures for Intelligent PMU Data Processing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [cloud-native, distributed stream processing, containerized microservices, elastic resource orchestration, edge-cloud hybrid]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nachiappan Chockalingam, Akshay Deshpande, Lokesh Butra, Ram Sekhar Bodala, Nitin Saksena, Adithya Parthasarathy, Balakrishna Pothineni, Akash Kumar Agarwal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IEEE, NTT Data, Amtrak, Albertsons Companies"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22231",children:"https://arxiv.org/pdf/2512.22231"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive theoretical framework for AI-enhanced cloud-based PMU analytics. 2. Mathematical formulations for distributed machine learning optimized for PMU time-series data. 3. Analysis of edge-cloud hybrid architectures with integrated security and privacy considerations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a scalable cloud-native architecture to address the latency and scalability challenges of processing high-frequency data from Phasor Measurement Units (PMUs) in smart grids. The method integrates AI with edge and cloud computing, using distributed stream processing and containerized microservices for real-time analytics. The analysis shows the architecture can achieve sub-second response times while scaling to large deployments, providing a robust foundation for next-generation grid analytics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Scalable Cloud-Native Architectures for Intelligent PMU Data Processing"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>PMU\u6570\u636e\u89c4\u6a21\u5927\uff0c\u4f20\u7edf\u67b6\u6784\u5ef6\u8fdf\u9ad8\uff0c\u53ef\u6269\u5c55\u6027\u5dee"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u4e91\u539f\u751f\u67b6\u6784\uff0c\u96c6\u6210AI\u3001\u8fb9\u7f18\u4e0e\u4e91\u8ba1\u7b97\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u548c\u5fae\u670d\u52a1"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u54cd\u5e94\uff0c\u53ef\u6269\u5c55\u81f3\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u63d0\u4f9b\u5b89\u5168\u53ef\u9760\u7684\u57fa\u7840"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Meta-information Guided Cross-domain Synergistic Diffusion Model for Low-dose PET Reconstruction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image reconstruction], [diffusion model, cross-domain, meta-information, sinogram adapter, low-dose PET]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mengxiao Geng, Ran Hong, Xiaoling Xu, Bingxuan Li, Qiegen Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanchang University, Hefei Comprehensive National Science Center"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22237",children:"https://arxiv.org/pdf/2512.22237"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a meta-information guided cross-domain synergistic diffusion model (MiG-DM) that integrates cross-modal priors for PET reconstruction. 2. Introduces a meta-information encoding module that transforms clinical parameters into semantic prompts for cross-modal alignment. 3. Designs a cross-domain architecture with a specialized sinogram adapter to capture global physical structures in the projection domain."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/974872f0916ad96ffeb1ed9b169c4f627d5c534046b438f10fd015171720864a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/974872f0916ad96ffeb1ed9b169c4f627d5c534046b438f10fd015171720864a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of low-dose PET image reconstruction, which suffers from noise and loss of detail. It proposes a novel diffusion model called MiG-DM that guides the reconstruction using patient-specific meta-information and processes data across both the projection and image domains. Experiments show that MiG-DM outperforms existing methods in improving image quality and preserving physiological details."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Meta-information Guided Cross-domain Synergistic Diffusion Model for Low-dose PET Reconstruction] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Low-dose PET imaging faces noise, reduced contrast, and detail loss)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: MiG-DM integrates meta-information prompts and cross-domain (projection & image) processing)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Outperforms SOTA on UDPET and clinical datasets, enhancing quality and preserving details)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] We are not able to identify AI-generated images"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image forensics], [AI-generated images, human evaluation, MidJourney, CC12M, synthetic media detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Adrien Pav\xe3o"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," (Institution not explicitly stated in provided content. Author name is Adrien Pav\xe3o; no affiliation or email domain is given. Therefore, institution cannot be reliably inferred.)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22236",children:"https://arxiv.org/pdf/2512.22236"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a controlled web-based experiment to empirically test human ability to distinguish real photographs from AI-generated portraits, finding performance near random chance (54% accuracy). 2. Created and released a curated, challenging dataset of 120 images (real from CC12M and AI-generated counterparts from MidJourney) designed to be difficult for humans. 3. Demonstrated that human judgment is insufficient for reliable detection of synthetic media, highlighting the need for greater public awareness and ethical guidelines as AI-generated content becomes more realistic."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b100d4e4882d297b51639fb736da62f90b11f1d810da4b6665f9da69ef3f31_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b100d4e4882d297b51639fb736da62f90b11f1d810da4b6665f9da69ef3f31_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper tests the assumption that humans can easily identify AI-generated images through an interactive web experiment where participants classified 20 images as real or AI-generated. Using a carefully curated dataset of 120 difficult portrait images (real from CC12M and AI-generated from MidJourney), the study found an average human accuracy of only 54%, barely above random guessing. The results show that humans struggle to reliably detect AI-generated content, indicating that human judgment alone is becoming insufficient and underscoring the need for awareness and ethical guidelines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[We are not able to identify AI-generated images] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Can humans reliably distinguish AI-generated images from real photos?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Interactive web experiment with a curated dataset of 120 difficult images (CC12M real vs. MidJourney AI-generated)]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Average human accuracy is 54% (near random), response time ~7.3s, highlighting human insufficiency and need for guidelines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Innovation Institute, OpenMoss Team"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22234",children:"https://arxiv.org/pdf/2512.22234"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/OpenMOSS/DiRL",children:"https://github.com/OpenMOSS/DiRL"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DiRL: An Efficient Post-Training Framework for Diffusion Language Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[dLLMs\u540e\u8bad\u7ec3\u4f4e\u6548/Post-training for dLLMs is inefficient]\n    B --\x3e B2[\u8bad\u7ec3\u4e0e\u63a8\u7406\u76ee\u6807\u4e0d\u5339\u914d/Training-Inference objective mismatch]\n    C --\x3e C1[DiRL\u6846\u67b6/DiRL Framework]\n    C1 --\x3e C1_1[\u6574\u5408FlexAttention\u4e0eLMDeploy/Integrates FlexAttention & LMDeploy]\n    C1 --\x3e C1_2[\u4e24\u9636\u6bb5\u540e\u8bad\u7ec3/Two-stage post-training (SFT+RL)]\n    C --\x3e C2[DiPO\u7b97\u6cd5/DiPO Algorithm]\n    C2 --\x3e C2_1[\u65e0\u504fGRPO\u5b9e\u73b0/Unbiased GRPO for dLLMs]\n    D --\x3e D1[\u9ad8\u6548\u8bad\u7ec3\u4e0e\u63a8\u7406/Efficient Training & Inference]\n    D --\x3e D2[\u6570\u5b66SOTA\u6027\u80fd/Math SOTA Performance]\n    D --\x3e D3[\u8d85\u8d8aQwen2.5\u7cfb\u5217/Surpasses Qwen2.5 series]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Enhanced geometry prediction in laser directed energy deposition using meta-learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [meta-learning], [meta-learning, model-agnostic meta-learning, reptile, laser-directed energy deposition, bead geometry prediction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abdul Malik Al Mardhouf Al Saadi, Amrita Basak"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Pennsylvania State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22241",children:"https://arxiv.org/pdf/2512.22241"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a cross-dataset knowledge transfer model for L-DED bead geometry prediction using meta-learning to address data scarcity and heterogeneity. 2. Investigated and applied two gradient-based meta-learning algorithms (MAML and Reptile) for rapid adaptation to new deposition conditions with limited data. 3. Demonstrated strong generalization performance of the meta-learning models across diverse L-DED processes (powder-fed, wire-fed, hybrid) using minimal training examples, outperforming conventional neural networks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4239294fb44dd0fe97ebc3a123162ba7aaa82e51c2805d4460072daeffe6de9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4239294fb44dd0fe97ebc3a123162ba7aaa82e51c2805d4460072daeffe6de9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of predicting bead geometry in laser-directed energy deposition (L-DED) where experimental data is scarce and heterogeneous. It proposes using meta-learning algorithms, specifically MAML and Reptile, to enable rapid model adaptation to new printing conditions with very few training examples. The results show that this approach achieves accurate predictions and outperforms traditional neural networks under similar data constraints, demonstrating effective knowledge transfer across different L-DED settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Enhanced geometry prediction in L-DED using meta-learning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Data scarcity & heterogeneity in L-DED geometry prediction]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Meta-learning (MAML & Reptile) for cross-dataset knowledge transfer]\n    D[\u5173\u952e\u7ed3\u679c/Results: Accurate prediction with few examples, outperforms conventional NN]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical imaging], [algorithmic fairness, subgroup performance analysis, JustEFAB framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shaurya Gaur, Michel Vitale, Alessa Hering, Johan Kwisthout, Colin Jacobs, Lena Philipp, Fennie van der Graaf"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Radboud University Medical Center, Radboud University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22242",children:"https://arxiv.org/pdf/2512.22242"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a fairness evaluation of three lung cancer risk estimation models (Sybil, Venkadesh21, PanCan2b) using the JustEFAB framework to assess ethically significant biases. 2. Identified and quantified statistically significant performance disparities across demographic subgroups (e.g., gender, race) that were not explained by available clinical confounders. 3. Highlighted the critical need for monitoring and improving model fairness in lung cancer screening AI to ensure equitable clinical application."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/783ab81ef53ced6c68b136e7001be4ece45c131979c45d04a04c21084cbf9888_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/783ab81ef53ced6c68b136e7001be4ece45c131979c45d04a04c21084cbf9888_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study evaluates the fairness of AI models for lung cancer risk estimation from CT scans. Using the JustEFAB framework, it assessed performance disparities across demographic groups and found significant, unexplained biases in two deep learning models. The findings underscore the importance of algorithmic fairness in medical AI to ensure equitable screening outcomes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening<br/>\u80ba\u764c\u7b5b\u67e5\u98ce\u9669\u4f30\u8ba1\u6a21\u578b\u7684\u516c\u5e73\u6027\u8bc4\u4f30] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br/>AI\u80ba\u764c\u98ce\u9669\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u4e9a\u7ec4\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u662f\u5426\u516c\u5e73\uff1f<br/>Is AI lung cancer risk model performance fair across demographic subgroups?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u4f7f\u7528JustEFAB\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u5728NLST\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02<br/>Evaluate model performance disparities on NLST validation set using JustEFAB framework]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br/>\u53d1\u73b0Sybil\u548cVenkadesh21\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u3001\u65e0\u6cd5\u7528\u6df7\u6742\u56e0\u7d20\u89e3\u91ca\u7684\u6027\u80fd\u5dee\u5f02<br/>Found significant, unexplained performance disparities in Sybil and Venkadesh21 models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [knowledge distillation, reinforcement learning, vision-language models, progressive masking, offline RL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," NVIDIA"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22238",children:"https://arxiv.org/pdf/2512.22238"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Masters, a mask-progressive RL distillation framework that first masks non-dominant teacher weights to reduce complexity and then progressively restores them for stable student learning. 2. Introduces an offline RL stage with complementary accuracy and distillation rewards, leveraging pre-generated responses from masked teachers for efficient guidance. 3. Demonstrates that progressive teacher scaling (e.g., from 14B to 38B) yields smoother convergence and stronger generalization than one-shot distillation, providing a scalable path to efficient VLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of distilling large vision-language models (VLMs) into compact ones by proposing Masters, a framework that uses progressive masking of the teacher model and offline reinforcement learning. This method enables stable knowledge transfer and efficient training, resulting in small VLMs that achieve strong performance, sometimes surpassing larger models, while being far more efficient for deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Masking Teacher and Reinforcing Student for Distilling Vision-Language Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5927\u578bVLM\u96be\u4ee5\u90e8\u7f72\u5230\u79fb\u52a8/\u8fb9\u7f18\u8bbe\u5907/Large VLMs are impractical for mobile/edge deployment]\n    B --\x3e B2[\u5e08\u751f\u6a21\u578b\u5c3a\u5bf8\u5dee\u8ddd\u5bfc\u81f4\u77e5\u8bc6\u84b8\u998f\u4e0d\u7a33\u5b9a/Large size gap causes unstable distillation]\n    C --\x3e C1[\u63a9\u7801\u6e10\u8fdb\u5f0f\u5f3a\u5316\u5b66\u4e60\u84b8\u998f\u6846\u67b6/Mask-progressive RL distillation framework]\n    C --\x3e C2[\u5148\u63a9\u7801\u6559\u5e08\u975e\u4e3b\u5bfc\u6743\u91cd\uff0c\u518d\u6e10\u8fdb\u6062\u590d/First mask non-dominant teacher weights, then progressively restore]\n    C --\x3e C3[\u79bb\u7ebfRL\u9636\u6bb5\u4f7f\u7528\u51c6\u786e\u6027\u548c\u84b8\u998f\u5956\u52b1/Offline RL stage with accuracy and distillation rewards]\n    D --\x3e D1[\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u7d27\u51d1\u578bVLM/Outperforms existing compact VLMs on diverse benchmarks]\n    D --\x3e D2[\u6e10\u8fdb\u589e\u52a0\u6559\u5e08\u5c3a\u5bf8\u5e26\u6765\u66f4\u5e73\u6ed1\u6536\u655b\u548c\u66f4\u5f3a\u6cdb\u5316/Gradually increasing teacher size yields smoother convergence & stronger generalization]\n    D --\x3e D3[\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u90e8\u7f72VLM\u7684\u53ef\u6269\u5c55\u8def\u5f84/Provides a scalable path toward efficient, deployable VLMs]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Multi-objective hybrid knowledge distillation for efficient deep learning in smart agriculture"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [model compression], [knowledge distillation, lightweight CNN, inverted residual blocks, dense connectivity, multi-objective learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Phi-Hung Hoang, Nam-Thuan Trinh, Van-Manh Tran, Thi-Thu-Hong Phan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," FPT University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22239",children:"https://arxiv.org/pdf/2512.22239"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a hybrid knowledge distillation framework integrating hard-label supervision, feature-level, response-level, and self-distillation for training efficient models. 2. Designs a customized student CNN architecture combining inverted residual blocks with dense connectivity to balance efficiency and accuracy. 3. Demonstrates strong generalization across multiple agricultural datasets (rice seeds and plant leaf diseases) with significant reductions in computational cost and model size while maintaining high accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccaf949c91086899f4aa9953236d8ee76957b0a5aaafcda22bf81f403ee1e0a5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccaf949c91086899f4aa9953236d8ee76957b0a5aaafcda22bf81f403ee1e0a5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a multi-objective hybrid knowledge distillation method to create a lightweight CNN for smart agriculture, combining inverted residual and dense blocks. The distilled model achieves near-teacher accuracy with drastically reduced computation and parameters, showing robust performance on rice seed and plant disease datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Multi-objective hybrid knowledge distillation for efficient deep learning in smart agriculture<br>\u9762\u5411\u667a\u6167\u519c\u4e1a\u7684\u9ad8\u6548\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u76ee\u6807\u6df7\u5408\u77e5\u8bc6\u84b8\u998f"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Deploying deep models on edge devices in smart agriculture<br>\u5728\u667a\u6167\u519c\u4e1a\u4e2d\u4e8e\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u6df1\u5ea6\u6a21\u578b"] --\x3e P1["\u6311\u6218/Challenge<br>Trade-off between efficiency and accuracy<br>\u6548\u7387\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Hybrid knowledge distillation framework<br>\u6df7\u5408\u77e5\u8bc6\u84b8\u998f\u6846\u67b6"] --\x3e M1["\u5b66\u751f\u6a21\u578b/Student Model<br>Customized CNN with inverted residual & dense blocks<br>\u5b9a\u5236\u5316CNN\uff0c\u542b\u5012\u6b8b\u5dee\u4e0e\u5bc6\u96c6\u8fde\u63a5\u5757"]\n    Method --\x3e M2["\u6559\u5e08\u6a21\u578b/Teacher Model<br>ResNet18 guidance<br>ResNet18\u6559\u5e08\u7f51\u7edc\u6307\u5bfc"]\n    Method --\x3e M3["\u591a\u76ee\u6807\u7b56\u7565/Multi-objective Strategy<br>Integrates hard-label, feature-level, response-level, self-distillation<br>\u6574\u5408\u786c\u6807\u7b7e\u3001\u7279\u5f81\u7ea7\u3001\u54cd\u5e94\u7ea7\u4e0e\u81ea\u84b8\u998f"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Experiments on agricultural datasets<br>\u5728\u519c\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c"] --\x3e R1["\u6027\u80fd/Performance<br>98.56% accuracy on rice seeds (vs teacher 98.65%)<br>\u6c34\u7a3b\u79cd\u5b50\u5206\u7c7b\u51c6\u786e\u738798.56%\uff08\u6559\u5e08\u6a21\u578b98.65%\uff09"]\n    Results --\x3e R2["\u6548\u7387/Efficiency<br>0.68 GFLOPs, ~1.07M parameters (10x smaller than teacher)<br>0.68 GFLOPs\uff0c\u7ea6107\u4e07\u53c2\u6570\uff08\u6bd4\u6559\u5e08\u6a21\u578b\u5c0f10\u500d\uff09"]\n    Results --\x3e R3["\u6cdb\u5316/Generalization<br>Consistent gains on plant leaf disease datasets<br>\u5728\u690d\u7269\u53f6\u7247\u75c5\u5bb3\u6570\u636e\u96c6\u4e0a\u4e00\u81f4\u6027\u80fd\u63d0\u5347"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] EvoXplain: When Machine Learning Models Agree on Predictions but Disagree on Why -- Measuring Mechanistic Multiplicity Across Training Runs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [interpretability], [mechanistic multiplicity, explanatory stability, stochastic optimization, model explanations, diagnostic framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chama Bensmail"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Hertfordshire, Omics Data Solutions LTD"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22240",children:"https://arxiv.org/pdf/2512.22240"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/bensmailchama-boop/EvoXplain",children:"https://github.com/bensmailchama-boop/EvoXplain"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces EvoXplain, a diagnostic framework for measuring the stability of model explanations across repeated training runs, treating explanations as samples from the optimization process. 2. Demonstrates that high-accuracy models (e.g., Logistic Regression, Random Forests) can rely on multiple distinct internal mechanisms, revealing explanatory multimodality not captured by single-model or averaged explanations. 3. Reframes interpretability as a property of a model class under repeated instantiation, challenging the assumption that a single high-accuracy model yields a unique or trustworthy explanation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a39d3b0c4608e98a5ffde3a753078019f45b0c48774cb02ee158633c35e823d2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a39d3b0c4608e98a5ffde3a753078019f45b0c48774cb02ee158633c35e823d2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces EvoXplain, a framework to diagnose if models achieving similar high accuracy do so via the same or different internal mechanisms by analyzing explanation stability across training runs. It finds that even simple, stable models like Logistic Regression can exhibit multiple distinct explanatory modes on datasets like Breast Cancer and COMPAS, showing that single-model explanations can be misleading. This work highlights explanatory instability as a measurable property and reframes interpretability as a characteristic of a model class rather than a single trained instance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[EvoXplain Paper] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u9ad8\u7cbe\u5ea6\u6a21\u578b\u662f\u5426\u5171\u4eab\u76f8\u540c\u5185\u90e8\u903b\u8f91?<br/>Do high-accuracy models share the same internal logic?]\n    C --\x3e C1[\u8de8\u91cd\u590d\u8bad\u7ec3\u6d4b\u91cf\u89e3\u91ca\u7a33\u5b9a\u6027<br/>Measure explanation stability across repeated training]\n    C --\x3e C2[\u5c06\u89e3\u91ca\u89c6\u4e3a\u4f18\u5316\u8fc7\u7a0b\u6837\u672c<br/>Treat explanations as samples from optimization]\n    D --\x3e D1[\u53d1\u73b0\u89e3\u91ca\u7684\u591a\u6a21\u6001\u6027<br/>Found explanatory multimodality]\n    D --\x3e D2[\u903b\u8f91\u56de\u5f52\u7b49\u6a21\u578b\u4e5f\u663e\u793a\u591a\u79cd\u673a\u5236<br/>Models like Logistic Regression show multiple mechanisms]\n    D --\x3e D3[\u91cd\u65b0\u5b9a\u4e49\u53ef\u89e3\u91ca\u6027\u4e3a\u6a21\u578b\u7c7b\u5c5e\u6027<br/>Reframe interpretability as model-class property]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Calibrating LLM Judges: Linear Probes for Fast and Reliable Uncertainty Estimation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [uncertainty estimation, calibration, linear probe, brier score, llm-as-judge]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bhaktipriya Radharapu, Eshika Saxena, Kenneth Li, Chenxi Whitehouse, Adina Williams, Nicola Cancedda"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Meta (FAIR at Meta, Meta Superintelligence Labs)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22245",children:"https://arxiv.org/pdf/2512.22245"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a method using linear probes on LLM hidden states to provide calibrated uncertainty estimates for LLM judges, requiring no additional model training. 2. Demonstrates superior calibration and \u224810x computational savings compared to baseline methods like verbalized confidence. 3. Shows the method generalizes robustly across different model architectures, training paradigms, and unseen evaluation domains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33ea018b43295c51d076b3840537c861c2e2c7f22ca2bdd183164d1f1feed91d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33ea018b43295c51d076b3840537c861c2e2c7f22ca2bdd183164d1f1feed91d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of obtaining efficient and well-calibrated uncertainty estimates for LLM-based judges. It proposes using linear probes trained with a Brier score loss on the model's hidden states. The method achieves better calibration with significant computational savings and provides a practical plug-and-play solution for production deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Calibrating LLM Judges<br/>\u6821\u51c6LLM\u6cd5\u5b98] --\x3e B[Problem: LLM judges lack efficient, calibrated uncertainty<br/>\u95ee\u9898\uff1aLLM\u6cd5\u5b98\u7f3a\u4e4f\u9ad8\u6548\u3001\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1]\n    A --\x3e C[Method: Linear probes on hidden states with Brier score loss<br/>\u65b9\u6cd5\uff1a\u57fa\u4e8eBrier\u5206\u6570\u635f\u5931\u7684\u9690\u72b6\u6001\u7ebf\u6027\u63a2\u9488]\n    A --\x3e D[Results: Better calibration, 10x speedup, robust generalization<br/>\u7ed3\u679c\uff1a\u66f4\u597d\u7684\u6821\u51c6\uff0c10\u500d\u52a0\u901f\uff0c\u9c81\u68d2\u7684\u6cdb\u5316]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Graph Attention-based Adaptive Transfer Learning for Link Prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph neural networks], [graph attention network, link prediction, transfer learning, graph transformer, contrastive loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Jinan University, Great Bay University, JD Technology, University of Illinois Chicago"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22252",children:"https://arxiv.org/pdf/2512.22252"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/DSI-Lab1/GAATNet",children:"https://github.com/DSI-Lab1/GAATNet"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes GAATNet, a novel graph attention adaptive transfer network combining pre-training and fine-tuning for cross-dataset knowledge transfer in link prediction. 2. Incorporates distant neighbor embeddings as biases in self-attention to capture global node features. 3. Introduces a lightweight self-adapter module during fine-tuning to improve training efficiency and generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses challenges in link prediction on large-scale sparse graphs and cross-dataset transfer learning by proposing GAATNet, which integrates graph attention with adaptive transfer strategies. The method uses distant neighbor embeddings and a self-adapter module to enhance global feature capture and training efficiency. Experiments on seven datasets show state-of-the-art performance, offering a scalable solution for integrating GNNs with transfer learning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Graph Attention-based Adaptive Transfer Learning for Link Prediction] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Challenges in large-scale sparse graphs and cross-dataset transfer learning for link prediction]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes GAATNet with distant neighbor embeddings and lightweight self-adapter for adaptive transfer]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves SOTA performance on seven datasets, provides scalable GNN-transfer learning solution]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Interpretable Perturbation Modeling Through Biomedical Knowledge Graphs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph neural networks], [biomedical knowledge graph, graph attention network, gene perturbation, multimodal embeddings, PrimeKG++]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pascal Passigan, Kevin zhu, Angelina Ning"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Massachusetts Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22251",children:"https://arxiv.org/pdf/2512.22251"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel framework for gene perturbation prediction by merging PrimeKG++ with LINCS L1000 data into a heterogeneous biomedical knowledge graph, moving beyond binary drug-disease association tasks. 2. Demonstrates the application of a Graph Attention Network (GAT) to predict delta gene expression profiles for drug-cell pairs, outperforming MLP baselines. 3. Provides interpretability through ablation studies (edge shuffling, node feature randomization) showing the critical role of biomedical KG edges in enhancing perturbation-level prediction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a8b52522e1bdfc53ae9978a144c2011810eca2532cb9819ad999bf9b2b6cbb6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a8b52522e1bdfc53ae9978a144c2011810eca2532cb9819ad999bf9b2b6cbb6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the gap in predicting detailed gene expression changes (perturbations) caused by drugs by constructing a merged biomedical knowledge graph from PrimeKG++ and LINCS L1000 data. The proposed method uses a Graph Attention Network to predict delta expression profiles for drug-cell pairs, which outperforms baseline models and demonstrates the value of graph structure for mechanistic understanding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Interpretable Perturbation Modeling Through Biomedical Knowledge Graphs] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Predicting granular gene expression changes (perturbations) from drugs, beyond binary drug-disease associations.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Merge PrimeKG++ & LINCS L1000 into a BKG; use Graph Attention Network (GAT) to predict delta expression.]\n    D[\u5173\u952e\u7ed3\u679c/Results: Outperforms MLP baselines; ablation shows KG edges enhance prediction for mechanistic modeling.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [prompt engineering], [Logic Sketch Prompting, deterministic prompting, interpretability, rule adherence, clinical decision support]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Satvik Tripathi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Pennsylvania"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22258",children:"https://arxiv.org/pdf/2512.22258"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/satviktri/LSP",children:"https://github.com/satviktri/LSP"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Logic Sketch Prompting (LSP), a lightweight prompting framework that introduces typed variables and deterministic condition evaluators for structured reasoning., 2. Incorporates a rule-based validator to produce traceable and repeatable outputs, enhancing auditability., 3. Demonstrates significant performance gains over standard prompting methods (zero-shot, chain-of-thought, concise) on pharmacologic logic-compliance tasks across multiple open-weight LLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b5d49d54027e4f7e6b110a48568a0255a45010197e26e8bc344e0cd3e1785a9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b5d49d54027e4f7e6b110a48568a0255a45010197e26e8bc344e0cd3e1785a9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the unreliability of LLMs on tasks requiring strict rule adherence and determinism. It proposes Logic Sketch Prompting (LSP), a framework using typed variables and rule-based validation to produce traceable outputs. Evaluations on clinical tasks show LSP significantly outperforms standard prompting methods in accuracy and F1 score, making it suitable for safety-critical systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Logic Sketch Prompting (LSP)] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs unreliable on tasks needing strict rules & determinism]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Lightweight framework with typed variables, condition evaluators, rule validator]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Highest accuracy/F1 vs. baselines; suitable for clinical/safety-critical systems]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhonghao Jiang, David Lo, Zhongxin Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Singapore Management University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22256",children:"https://arxiv.org/pdf/2512.22256"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/ZhonghaoJiang/Awesome-Issue-Solving",children:"https://github.com/ZhonghaoJiang/Awesome-Issue-Solving"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Agentic Software Issue Resolution with LLMs: A Survey] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\uff0c\u6548\u7387\u4f4e/Traditional methods rely on human expertise, inefficient]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7cfb\u7edf/LLM-based Agentic Systems]\n    Method --\x3e M2[\u7cfb\u7edf\u7efc\u8ff0126\u9879\u7814\u7a76/Systematic survey of 126 studies]\n    Method --\x3e M3[\u5efa\u7acb\u4e09\u7ef4\u5206\u7c7b\u6cd5/Establishes a 3D taxonomy]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u589e\u5f3a\u8f6f\u4ef6\u7ef4\u62a4\u6548\u7387/Enhances software maintenance efficiency]\n    Results --\x3e R2[\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u9a8c\u8bc1\u73af\u5883/Provides a validation environment for agentic systems]\n    Results --\x3e R3[\u603b\u7ed3\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411/Summarizes challenges & future directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [reasoning], [chain-of-thought, synthetic data, distribution shift, fine-tuning, reasoning robustness]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abhranil Chandra, Ayush Agrawal, Arian Hosseini, Sebastian Fischmeister, Rishabh Agarwal, Navin Goyal, Aaron Courville"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Waterloo, University of Massachusetts Amherst, MILA - Quebec AI Institute, Universit\xe9 de Montr\xe9al, Microsoft Research India, Google DeepMind, Periodic Labs"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22255",children:"https://arxiv.org/pdf/2512.22255"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that training on synthetic chain-of-thought traces from more capable models, even when they lead to incorrect final answers, can improve a language model's reasoning performance more than training on human-annotated datasets. 2. Proposes and validates two hypotheses for this phenomenon: the distributional alignment of synthetic data with the model, and the partial validity of reasoning steps within flawed traces. 3. Shows that paraphrasing human traces to align with the model's distribution improves performance, and investigates model tolerance to increasingly flawed reasoning steps."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf038d101bb93ad9f8c253c481419dec618655c74a6b867d0128b6358a3fa331_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf038d101bb93ad9f8c253c481419dec618655c74a6b867d0128b6358a3fa331_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper challenges the assumption that correctness is the primary determinant of data quality for training language models on reasoning tasks. It shows that fine-tuning on synthetic, incorrect chain-of-thought traces from stronger models can outperform training on correct human-annotated data, primarily because the synthetic data's distribution is closer to the model's own. The key conclusion is that aligning the training data distribution with the model's is more critical for performance than the correctness of the final answers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Shape of Thought / \u601d\u7ef4\u5f62\u6001] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Correctness vs. Distribution / \u6b63\u786e\u6027\u4e0e\u6570\u636e\u5206\u5e03]\n    B1 --\x3e B2{Does correctness guarantee better reasoning? / \u6b63\u786e\u6027\u4fdd\u8bc1\u66f4\u597d\u7684\u63a8\u7406\u5417?}\n    C --\x3e C1[Train on Incorrect Synthetic CoT / \u4f7f\u7528\u9519\u8bef\u7684\u5408\u6210CoT\u8bad\u7ec3]\n    C --\x3e C2[Paraphrase Human Traces / \u6539\u5199\u4eba\u7c7b\u6807\u6ce8\u7684\u63a8\u7406\u94fe]\n    C --\x3e C3[Introduce Flawed Steps / \u5f15\u5165\u6709\u7f3a\u9677\u7684\u63a8\u7406\u6b65\u9aa4]\n    D --\x3e D1[Synthetic Incorrect > Human Correct / \u9519\u8bef\u7684\u5408\u6210\u6570\u636e\u4f18\u4e8e\u6b63\u786e\u7684\u4eba\u7c7b\u6570\u636e]\n    D --\x3e D2[Distribution Alignment is Key / \u6570\u636e\u5206\u5e03\u5bf9\u9f50\u662f\u5173\u952e]\n    D --\x3e D3[Final Answer \u2260 Faithful Reasoning / \u6700\u7ec8\u7b54\u6848 \u2260 \u5fe0\u5b9e\u63a8\u7406\u8fc7\u7a0b]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ReVEAL: GNN-Guided Reverse Engineering for Formal Verification of Optimized Multipliers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [formal verification, computer algebra], [reverse engineering, graph neural network, multiplier verification, algebraic circuit verification, SAT-based equivalence checking]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chen Chen, Daniela Kaufmann, Chenhui Deng, Zhan Song, Hongce Zhang, Cunxi Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Maryland, College Park; TU Wien; NVIDIA; Hong Kong University of Science and Technology (Guangzhou)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22260",children:"https://arxiv.org/pdf/2512.22260"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ReVEAL, a graph-learning-based framework for reverse engineering optimized multiplier architectures to recover their word-level structure. 2. Leverages structural graph features and learning-driven inference to identify architectural patterns at scale, enabling robust handling of large, optimized circuits. 3. Integrates smoothly with existing verification flows and supports downstream algebraic proof strategies, showing improvements in scalability and accuracy over traditional rule-based approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bdd1907cef6efb0b9b81d88b611f825942f30ef8a8674a9587cc4261e4774ef_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bdd1907cef6efb0b9b81d88b611f825942f30ef8a8674a9587cc4261e4774ef_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces ReVEAL, a method that uses Graph Neural Networks (GNNs) to reverse engineer the architecture of optimized hardware multipliers. This recovered structure enables more effective formal verification using algebraic techniques. The approach demonstrates improved scalability and accuracy compared to traditional rule-based methods on diverse benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ReVEAL: GNN-Guided Reverse Engineering for Formal Verification of Optimized Multipliers] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: \u4f18\u5316\u4e58\u6cd5\u5668\u5f62\u5f0f\u9a8c\u8bc1\u56f0\u96be/Challenges in formal verification of optimized multipliers)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8e\u56fe\u5b66\u4e60\u7684\u9006\u5411\u5de5\u7a0b/GNN-guided reverse engineering)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u63d0\u5347\u53ef\u6269\u5c55\u6027\u4e0e\u51c6\u786e\u6027/Improved scalability and accuracy)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LLMTM: Benchmarking and Optimizing LLMs for Temporal Motif Analysis in Dynamic Graphs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph representation learning], [temporal motifs, dynamic graphs, llm agent, structure-aware dispatcher, prompting techniques]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bing Hao, Minglai Shao, Zengyi Wo, Yunlong Chu, Yuhang Liu, Ruijie Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tianjin University, Beihang University, Guangxi Normal University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22266",children:"https://arxiv.org/pdf/2512.22266"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Wjerry5/LLMTM",children:"https://github.com/Wjerry5/LLMTM"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLMTM, a comprehensive benchmark for evaluating LLMs on six tasks across nine types of temporal motifs in dynamic graphs. 2. Develops a tool-augmented LLM agent that uses engineered prompts to achieve high accuracy on temporal motif analysis tasks. 3. Introduces a structure-aware dispatcher that intelligently routes queries between standard LLM prompting and the more powerful agent to balance accuracy and cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ebbb05fef920a296d5863029d0c69e932a75230132aa0658a09e6bd8d04010c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ebbb05fef920a296d5863029d0c69e932a75230132aa0658a09e6bd8d04010c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the use of Large Language Models (LLMs) for analyzing temporal motifs in dynamic graphs, an area that is relatively unexplored. The authors propose a new benchmark (LLMTM), develop a high-accuracy but costly tool-augmented LLM agent, and then introduce a structure-aware dispatcher to reduce cost while maintaining performance. Their experiments show the dispatcher effectively maintains high accuracy while reducing cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLMTM: Benchmarking and Optimizing LLMs for Temporal Motif Analysis] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u5904\u7406\u52a8\u6001\u56fe\u65f6\u6001\u6a21\u4f53\u5206\u6790\u80fd\u529b\u672a\u77e5/LLMs' capability for temporal motif analysis on dynamic graphs is unexplored]\n    C --\x3e C1[\u63d0\u51fa\u57fa\u51c6LLMTM\u4e0e\u667a\u80fd\u4f53/Propose benchmark LLMTM and an agent]\n    C --\x3e C2[\u63d0\u51fa\u7ed3\u6784\u611f\u77e5\u8c03\u5ea6\u5668/Propose structure-aware dispatcher]\n    D --\x3e D1[\u8c03\u5ea6\u5668\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u5e76\u964d\u4f4e\u6210\u672c/Dispatcher maintains high accuracy while reducing cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Illusion of Clinical Reasoning: A Benchmark Reveals the Pervasive Gap in Vision-Language Models for Clinical Competency"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [clinical reasoning benchmark, vision-language models, multimodal integration, medical image interpretation, hallucination]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dingyu Wang, Zimu Yuan, Jiajun Liu, Shanggui Liu, Nan Zhou, Tianxing Xu, Di Huang, Dong Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Peking University Third Hospital, Beihang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22275",children:"https://arxiv.org/pdf/2512.22275"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced the Bones and Joints (B&J) Benchmark, a comprehensive evaluation framework with 1,245 questions derived from real-world patient cases to assess clinical reasoning. 2. Revealed a significant performance gap in VLMs, showing high accuracy on structured tasks but poor performance on open-ended, multimodal reasoning tasks, with severe text-driven hallucinations. 3. Demonstrated that medically fine-tuned models show no consistent advantage over general-purpose models, highlighting a fundamental limitation in current AI for clinical competency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43db8495c9ac46c5ea892f723394bd1e6c9b400003c2c67ace7ac9abe26f0bcf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43db8495c9ac46c5ea892f723394bd1e6c9b400003c2c67ace7ac9abe26f0bcf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces the Bones and Joints (B&J) Benchmark to rigorously evaluate the clinical reasoning capabilities of vision-language and large language models. The results show that while models perform well on structured tasks, they struggle significantly with open-ended, multimodal reasoning essential for real-world patient care, indicating they are not yet clinically competent. The authors conclude that safe AI deployment should be limited to supportive roles until fundamental breakthroughs in multimodal integration are achieved."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Illusion of Clinical Reasoning<br>\u4e34\u5e8a\u63a8\u7406\u7684\u5047\u8c61] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Current benchmarks fail to capture integrated, multimodal clinical reasoning.<br>\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u7efc\u5408\u3001\u591a\u6a21\u6001\u4e34\u5e8a\u63a8\u7406\u3002]\n    C --\x3e C1[Developed the B&J Benchmark with 1245 real-world questions across 7 tasks.<br>\u5f00\u53d1\u4e86\u5305\u542b1245\u4e2a\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u3001\u6db5\u76d67\u9879\u4efb\u52a1\u7684B&J\u57fa\u51c6\u3002]\n    D --\x3e D1[Large performance gap: high on MCQ, low on open-ended multimodal tasks.<br>\u5de8\u5927\u6027\u80fd\u5dee\u8ddd\uff1a\u9009\u62e9\u9898\u8868\u73b0\u597d\uff0c\u5f00\u653e\u5f0f\u591a\u6a21\u6001\u4efb\u52a1\u8868\u73b0\u5dee\u3002]\n    D --\x3e D2[VLMs have limitations in image interpretation and exhibit hallucinations.<br>VLM\u5728\u56fe\u50cf\u89e3\u91ca\u65b9\u9762\u5b58\u5728\u5c40\u9650\u5e76\u51fa\u73b0\u5e7b\u89c9\u3002]\n    D --\x3e D3[Medically fine-tuned models show no consistent advantage.<br>\u533b\u5b66\u5fae\u8c03\u6a21\u578b\u672a\u663e\u793a\u4e00\u81f4\u4f18\u52bf\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Varshith Gudur"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher (Valori Kernel Project)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22280",children:"https://arxiv.org/pdf/2512.22280"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/varshith-Git/Valori-Kernel",children:"https://github.com/varshith-Git/Valori-Kernel"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Valori: A Deterministic Memory Substrate for AI Systems] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: AI\u5185\u5b58\u975e\u786e\u5b9a\u6027/AI Memory Non-Determinism]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u56fa\u5b9a\u70b9\u7b97\u672f\u4e0e\u72b6\u6001\u673a/Fixed-Point Arithmetic & State Machine]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u8de8\u5e73\u53f0\u6bd4\u7279\u4e00\u81f4\u6027/Cross-Platform Bit-Identical Results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Cluster Aggregated GAN (CAG): A Cluster-Based Hybrid Model for Appliance Pattern Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [generative models], [Generative Adversarial Networks, Non-Intrusive Load Monitoring, Clustering, LSTM, Pattern Generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zikun Guoa, Adeyinka.P. Adedigbaa, Rammohan Mallipeddi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kyungpook National University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22287",children:"https://arxiv.org/pdf/2512.22287"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a hybrid GAN framework that routes appliances to specialized branches based on behavioral characteristics (intermittent vs. continuous). 2. Introduces a clustering module for intermittent appliances to group similar activation patterns and allocate dedicated generators, improving modeling of both common and rare modes. 3. Employs a separate LSTM-based generator branch for continuous appliances to capture gradual temporal evolution while maintaining training stability through sequence compression."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37f2c4c207022049ee869567d36df9e77e5a04d1beb0cc584dc57ee6ad1145b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37f2c4c207022049ee869567d36df9e77e5a04d1beb0cc584dc57ee6ad1145b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes the Cluster Aggregated GAN (CAG), a hybrid generative model that synthesizes appliance load patterns by separating intermittent and continuous devices into specialized branches, using clustering for the former and an LSTM for the latter. Experiments on the UVIC dataset show it outperforms baselines in realism, diversity, and training stability. The integration of clustering as an active component also enhances the model's interpretability and scalability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Cluster Aggregated GAN (CAG)"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: \u7f3a\u4e4f\u6807\u8bb0\u6570\u636e\uff0c\u73b0\u6709GAN\u65b9\u6cd5\u5bf9\u6240\u6709\u8bbe\u5907\u4e00\u89c6\u540c\u4ec1\uff0c\u5ffd\u7565\u95f4\u6b47\u6027\u548c\u6301\u7eed\u6027\u8bbe\u5907\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u4fdd\u771f\u5ea6\u6709\u9650"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u6df7\u5408\u751f\u6210\u6846\u67b6\uff0c\u6839\u636e\u8bbe\u5907\u884c\u4e3a\u7279\u5f81\u8def\u7531\u5230\u4e13\u95e8\u5206\u652f\uff1a\u95f4\u6b47\u6027\u8bbe\u5907\u4f7f\u7528\u805a\u7c7b\u6a21\u5757\u548c\u4e13\u7528\u751f\u6210\u5668\uff1b\u6301\u7eed\u6027\u8bbe\u5907\u4f7f\u7528LSTM\u751f\u6210\u5668"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: \u5728UVIC\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u5728\u771f\u5b9e\u6027\u3001\u591a\u6837\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u805a\u7c7b\u4f5c\u4e3a\u4e3b\u52a8\u751f\u6210\u7ec4\u4ef6\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] When Algorithms Manage Humans: A Double Machine Learning Approach to Estimating Nonlinear Effects of Algorithmic Control on Gig Worker Performance and Wellbeing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [causal inference], [Double Machine Learning, Moderated Mediation, Algorithmic Control, Nonmonotonic Effects, Gig Economy]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Arunkumar V, Nivethitha S, Sharan Srinivas, Gangadharan G.R"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Anna University, National Institute of Technology Tiruchirappalli, University of Missouri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22290",children:"https://arxiv.org/pdf/2512.22290"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Applied a Double Machine Learning framework to estimate a moderated mediation model without restrictive linear assumptions in organizational research. 2. Uncovered a nonmonotonic relationship between algorithmic oversight, worker wellbeing, and performance, highlighting a "murky middle" of confusing oversight. 3. Demonstrated that simple linear models can be misleading and provided practical insights for designing transparent and explainable algorithmic management systems.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ffeb8d364908888226033cff39cbb354772ae1044ba1a51632db140d81dca17_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ffeb8d364908888226033cff39cbb354772ae1044ba1a51632db140d81dca17_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the nonlinear effects of algorithmic control on gig workers. Using a Double Machine Learning approach on survey data, it finds that the link between supportive HR practices and worker performance weakens under opaque algorithmic oversight but strengthens again when the oversight is transparent and explainable."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["\u5f53\u7b97\u6cd5\u7ba1\u7406\u4eba\u7c7b: \u4f30\u7b97\u7b97\u6cd5\u63a7\u5236\u5bf9\u96f6\u5de5\u5de5\u4eba\u7ee9\u6548\u548c\u798f\u7949\u975e\u7ebf\u6027\u6548\u5e94\u7684\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 / When Algorithms Manage Humans: A Double Machine Learning Approach to Estimating Nonlinear Effects of Algorithmic Control on Gig Worker Performance and Wellbeing"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898: \u7b97\u6cd5\u7ba1\u7406\u4e0b\uff0c\u4ee5\u4eba\u4e3a\u672c\u7684\u7ba1\u7406\u80fd\u5426\u6301\u7eed\uff1f\u5de5\u4eba\u5bf9\u7b97\u6cd5\u7684\u53cd\u5e94\u662f\u975e\u7ebf\u6027\u7684 / Problem: Can person-centered management survive algorithmic management? Worker responses are nonlinear."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5: \u4f7f\u7528\u53cc\u91cd\u673a\u5668\u5b66\u4e60\u6846\u67b6\u4f30\u7b97\u6709\u8c03\u8282\u7684\u4e2d\u4ecb\u6a21\u578b\uff0c\u65e0\u4e25\u683c\u51fd\u6570\u5f62\u5f0f\u9650\u5236 / Method: Double Machine Learning framework to estimate a moderated mediation model without restrictive functional forms."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c: \u53d1\u73b0\u975e\u5355\u8c03\u6a21\u5f0f\u3002\u6a21\u7cca\u7684\u7b97\u6cd5\u76d1\u7763\u524a\u5f31\u7ee9\u6548\u8054\u7cfb\uff0c\u900f\u660e\u53ef\u89e3\u91ca\u7684\u76d1\u7763\u5219\u52a0\u5f3a\u5b83 / Results: Found a nonmonotonic pattern. Murky oversight weakens the performance link, transparent and explainable oversight strengthens it."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Co-GRPO: Co-Optimized Group Relative Policy Optimization for Masked Diffusion Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [Masked Diffusion Models, Markov Decision Process, Group Relative Policy Optimization, inference schedule optimization, trajectory-level training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Renping Zhou, Zanlin Ni, Tianyi Chen, Zeyu Liu, Yang Yue, Yulin Wang, Yuxuan Wang, Jingshu Liu, Gao Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University (Leap Lab), Anyverse Dynamics"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22288",children:"https://arxiv.org/pdf/2512.22288"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://co-grpo.github.io",children:"https://co-grpo.github.io"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and addresses the discrepancy between the single-step training and multi-step inference of Masked Diffusion Models (MDMs). 2. Proposes Co-GRPO, a method that reformulates MDM generation as a unified Markov Decision Process to jointly optimize model parameters and inference schedule parameters. 3. Introduces a trajectory-level optimization using Group Relative Policy Optimization that avoids costly backpropagation through the multi-step generation process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63c1159878e540d373846dba6e76fb918342cb837f6f15d4e79e21a40dad9e84_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63c1159878e540d373846dba6e76fb918342cb837f6f15d4e79e21a40dad9e84_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the misalignment between the training and inference procedures of Masked Diffusion Models (MDMs). It proposes Co-GRPO, a method that jointly optimizes the MDM and its inference schedule as a unified Markov Decision Process using Group Relative Policy Optimization. The approach improves generation quality across multiple benchmarks without requiring expensive backpropagation through the full generation trajectory."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Co-GRPO: Co-Optimized Group Relative Policy Optimization for Masked Diffusion Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bad\u7ec3\u4e0e\u63a8\u7406\u4e0d\u5339\u914d/Mismatch between Training & Inference]\n    B1 --\x3e B2[\u8bad\u7ec3: \u5355\u6b65BERT\u5f0f/Training: Single-step BERT-style]\n    B1 --\x3e B3[\u63a8\u7406: \u591a\u6b65\u6709\u8c03\u5ea6/Inference: Multi-step with Schedule]\n    C --\x3e C1[\u7edf\u4e00MDP/Unified MDP]\n    C1 --\x3e C2[\u8054\u5408\u4f18\u5316\u6a21\u578b\u4e0e\u8c03\u5ea6/Jointly Optimize Model & Schedule]\n    C2 --\x3e C3[\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316/Group Relative Policy Optimization]\n    D --\x3e D1[\u63d0\u5347\u751f\u6210\u8d28\u91cf/Improved Generation Quality]\n    D1 --\x3e D2[\u5728\u56db\u4e2a\u57fa\u51c6\u4e0a\u9a8c\u8bc1/Validated on Four Benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [scientific machine learning], [Physics-informed neural networks, Kolmogorov-Arnold networks, Adaptive weighting, B-splines, Partial differential equations]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guokan Chen, Yao Xiao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fujian University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22283",children:"https://arxiv.org/pdf/2512.22283"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DBAW-PIKAN, a novel architecture combining a Kolmogorov-Arnold Network (KAN) with learnable B-splines for enhanced function representation in solving PDEs., 2. Introduces an adaptive weighting strategy with a dynamic decay upper bound to mitigate gradient flow stiffness and spectral bias, addressing key failure modes of PINNs., 3. Demonstrates significant improvements in convergence speed and solution accuracy (at least an order of magnitude) on benchmarks like Klein-Gordon, Burgers, and Helmholtz equations without added computational cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DBAW-PIKAN, a novel neural network that integrates a Kolmogorov-Arnold architecture with an adaptive weighting strategy to overcome the stiffness and spectral bias challenges faced by Physics-Informed Neural Networks (PINNs) when solving multi-scale PDEs. The method accelerates convergence and improves solution accuracy by at least an order of magnitude on standard benchmarks without increasing computational complexity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[PINNs struggle with multi-scale/high-frequency PDEs / PINNs\u5728\u5904\u7406\u591a\u5c3a\u5ea6/\u9ad8\u9891PDE\u65f6\u9047\u5230\u56f0\u96be]\n    P1 --\x3e P2[Issues: Gradient flow stiffness & spectral bias / \u95ee\u9898: \u68af\u5ea6\u6d41\u521a\u5ea6\u548c\u8c31\u504f\u5dee]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Architecture: Kolmogorov-Arnold Network (KAN) with learnable B-splines / \u67b6\u6784: \u57fa\u4e8e\u53ef\u5b66\u4e60B\u6837\u6761\u7684KAN]\n    Method --\x3e M2[Strategy: Adaptive weighting with dynamic decay upper bound / \u7b56\u7565: \u5e26\u52a8\u6001\u8870\u51cf\u4e0a\u754c\u7684\u81ea\u9002\u5e94\u52a0\u6743]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Faster convergence & higher accuracy / \u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u9ad8\u7684\u7cbe\u5ea6]\n    R1 --\x3e R2[Improvement: At least one order of magnitude / \u63d0\u5347: \u81f3\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7]\n    Results --\x3e R3[Benchmarks: Klein-Gordon, Burgers, Helmholtz equations / \u57fa\u51c6: Klein-Gordon, Burgers, Helmholtz\u65b9\u7a0b]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Multi-Head Spectral-Adaptive Graph Anomaly Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph anomaly detection], [spectral graph neural network, hypernetwork, Chebyshev filter, teacher-student contrastive learning, Barlow Twins loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qingyue Cao, Bo Jin, Changwei Gong, Xin Tong, Wenzheng Li, Xiaodong Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," People's Public Security University of China, Third Research Institute of the Ministry of Public Security, Shanghai Police College"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22291",children:"https://arxiv.org/pdf/2512.22291"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Multi-Head Spectral-Adaptive Graph Neural Network (MHSA-GNN) that uses a lightweight hypernetwork to dynamically generate instance-specific Chebyshev filter parameters based on a 'spectral fingerprint'. 2. Introduces a novel dual regularization strategy combining teacher-student contrastive learning (TSC) and Barlow Twins diversity loss (BTD) to prevent mode collapse and ensure representation accuracy and head orthogonality in the multi-head mechanism. 3. Demonstrates through extensive experiments that the method effectively preserves high-frequency anomaly signals and outperforms state-of-the-art methods, especially on highly heterogeneous datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9ad6dee88128393dc0036e3430c2763e19882412f9750f09622c52d9ae28dc6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9ad6dee88128393dc0036e3430c2763e19882412f9750f09622c52d9ae28dc6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of graph anomaly detection where fixed filters in spectral GNNs cause over-smoothing and fail to adapt to varying graph structures. It proposes MHSA-GNN, which uses a hypernetwork to generate adaptive filters per instance and a dual regularization strategy to stabilize multi-head learning. Experiments show the method preserves critical high-frequency signals and achieves superior performance, particularly on heterogeneous graphs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Multi-Head Spectral-Adaptive Graph Anomaly Detection] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u56fa\u5b9a\u6ee4\u6ce2\u5668\u5bfc\u81f4\u8fc7\u5e73\u6ed1\u4e0e\u7f3a\u4e4f\u9002\u5e94\u6027/Fixed filters cause over-smoothing & lack adaptability]\n    C --\x3e C1[\u57fa\u4e8e\u8c31\u6307\u7eb9\u7684\u8f7b\u91cf\u7ea7\u8d85\u7f51\u7edc/Lightweight hypernetwork based on spectral fingerprint]\n    C --\x3e C2[\u52a8\u6001\u751f\u6210\u5207\u6bd4\u96ea\u592b\u6ee4\u6ce2\u5668\u53c2\u6570/Dynamically generates Chebyshev filter parameters]\n    C --\x3e C3[\u53cc\u6b63\u5219\u5316\u7b56\u7565\u9632\u6b62\u6a21\u5f0f\u5d29\u6e83/Dual regularization prevents mode collapse]\n    D --\x3e D1[\u6709\u6548\u4fdd\u7559\u9ad8\u9891\u5f02\u5e38\u4fe1\u53f7/Effectively preserves high-frequency anomaly signals]\n    D --\x3e D2[\u5728\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a/Outperforms SOTA on heterogeneous datasets]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A Three-Level Alignment Framework for Large-Scale 3D Retrieval and Controlled 4D Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [multimodal retrieval and generation], [3D retrieval, 4D generation, cross-modal alignment, multi-head attention, open-vocabulary]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Philip Xu, David Elizondo, Raouf Hamzaoui"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," De Montfort University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22294",children:"https://arxiv.org/pdf/2512.22294"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Uni4D, a unified framework for large-scale open-vocabulary 3D retrieval and controlled 4D generation. 2. Introduces a structured three-level alignment strategy across text, 3D models, and images to enhance semantic understanding. 3. Presents a 3D-Text Multi-head Attention and Search (ATMS) model to optimize text-to-3D retrieval efficiency and accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb826b31ecaac1f8358869614a5af4e6a0fe9eeceb1eb97ce8bbb0ff8afdcd6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb826b31ecaac1f8358869614a5af4e6a0fe9eeceb1eb97ce8bbb0ff8afdcd6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Uni4D, a framework that uses a three-level alignment strategy across text, 3D, and images to address the challenges of large-scale 3D retrieval and controlled 4D generation. The method employs a novel attention and search model to improve semantic alignment and retrieval efficiency. Experimental results demonstrate that Uni4D achieves high-quality 3D retrieval and controllable 4D generation, advancing dynamic multimodal understanding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Uni4D: A Three-Level Alignment Framework for Large-Scale 3D Retrieval and Controlled 4D Generation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5927\u89c4\u6a213D\u68c0\u7d22\u4e0e\u53ef\u63a74D\u751f\u6210\u7684\u6311\u6218/Challenges in large-scale 3D retrieval and controlled 4D generation]\n    C --\x3e C1[\u4e09\u7ea7\u5bf9\u9f50\u6846\u67b6: \u6587\u672c-3D-\u56fe\u50cf/Three-level alignment: text-3D-image]\n    C --\x3e C2[ATMS\u6a21\u578b\u4f18\u5316\u68c0\u7d22/ATMS model optimizes retrieval]\n    D --\x3e D1[\u9ad8\u8d28\u91cf3D\u68c0\u7d22/High-quality 3D retrieval]\n    D --\x3e D2[\u53ef\u63a74D\u751f\u6210/Controlled 4D generation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Attack-Aware Deepfake Detection under Counter-Forensic Manipulations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [deepfake detection], [counter-forensics, red-team training, test-time defense, two-stream architecture, tamper heatmaps]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Noor Fatima, Hasan Faraz Khan, Muzammil Behzad"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," King Fahd University of Petroleum and Minerals (KFUPM), SDAIA-KFUPM Joint Research Center for Artificial Intelligence"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22303",children:"https://arxiv.org/pdf/2512.22303"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an attack-aware deepfake detection method combining red-team training with randomized test-time defense for robustness against counter-forensic manipulations. 2. Introduces a two-stream architecture with a lightweight residual adapter for fusing semantic and forensic features, and a weakly supervised FPN-style head for generating tamper heatmaps. 3. Establishes a practical, modular, and data-efficient baseline with well-calibrated probabilities and actionable evidence, evaluated on standard and challenging surveillance-style datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45e4389b2e929ec3ecb92d5f6329f2086fd32a88abcf98391c61119cd497cc8f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45e4389b2e929ec3ecb92d5f6329f2086fd32a88abcf98391c61119cd497cc8f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of robust deepfake detection under realistic counter-forensic attacks. It proposes a two-stream model trained with worst-case adversarial manipulations and defended at test-time with random jitters, which achieves strong performance, reliable probability calibration, and useful localization heatmaps. The method provides a practical and data-efficient baseline for attack-aware detection in real-world conditions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Attack-Aware Deepfake Detection under Counter-Forensic Manipulations"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: Robust detection under realistic counter-forensic attacks"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: Red-team training + Test-time defense in a two-stream architecture"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results: Near-perfect attack ranking, low calibration error, actionable heatmaps"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Beyond Single Bugs: Benchmarking Large Language Models for Multi-Vulnerability Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [vulnerability detection], [multi-vulnerability detection, count bias, selection bias, long-context code, CWE injection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chinmay Pushkar, Sanchit Kabra, Dhruv Kumar, Jagat Sesh Challa"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," BITS Pilani, Virginia Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22306",children:"https://arxiv.org/pdf/2512.22306"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduced a comprehensive benchmark for Multi-Vulnerability Detection across four programming languages (C, C++, Python, JavaScript) to address the limitations of existing single-vulnerability benchmarks. 2. Constructed a novel dataset of 40,000 files by systematically injecting controlled counts of vulnerabilities (1, 3, 5, 9) into long-context code samples, enabling the study of performance under varying vulnerability densities. 3. Quantified the performance degradation of state-of-the-art LLMs (e.g., GPT-4o-mini, Llama-3.3-70B) in high-density vulnerability settings, revealing distinct failure modes like severe "under-counting" in Python and JavaScript.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6a5fa286f161d0dab7d6a06a8f54502b88fd2f448edc9ed3609a31efaf97f5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6a5fa286f161d0dab7d6a06a8f54502b88fd2f448edc9ed3609a31efaf97f5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the gap in evaluating LLMs for detecting multiple vulnerabilities in large, real-world code files. The authors propose a new benchmark by creating a dataset of long code files with systematically injected vulnerabilities and evaluate several LLMs. The main finding is that LLM performance sharply degrades as the number of vulnerabilities per file increases, with significant drops in recall for languages like Python."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Beyond Single Bugs: Benchmarking LLMs for Multi-Vulnerability Detection] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Existing benchmarks are simplistic, focusing on single bugs, not reflecting real-world multi-vulnerability files.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Build a new benchmark with 40k files across 4 languages, injecting controlled vulnerability counts into long code.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>LLM performance degrades sharply with more vulnerabilities; distinct failure modes in Python/JS vs. C/C++.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LLMBoost: Make Large Language Models Stronger with Boosting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [ensemble learning, boosting, cross-model attention, chain training, near-parallel inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zehao Chen, Tianxiang Ai, Yifei Li, Gongxun Li, Yuyang Wei, Wang Zhou, Guanghui Li, Bin Yu, Zhijun Chen, Hailong Sun, Fuzhen Zhuang, Jianxin Li, Deqing Wang, Yikun Ban"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beihang University, China Telecom eSurfing Cloud"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22309",children:"https://arxiv.org/pdf/2512.22309"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A cross-model attention mechanism that allows successor models to access and fuse hidden states from predecessors for hierarchical error correction and knowledge transfer. 2. A chain training paradigm that progressively fine-tunes connected models with an error-suppression objective to rectify predecessor mispredictions efficiently. 3. A near-parallel inference paradigm that pipelines hidden states across models layer by layer, achieving inference efficiency close to single-model decoding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb6a601c8d3bba7ec992d00772421c31e3e03d00d8a89a06f09ad3fe3c1b6ce1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb6a601c8d3bba7ec992d00772421c31e3e03d00d8a89a06f09ad3fe3c1b6ce1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes LLMBoost, a novel ensemble fine-tuning framework for LLMs that leverages intermediate hidden states across models. Inspired by boosting, it introduces cross-model attention, chain training, and a near-parallel inference pipeline to improve accuracy and reduce latency. Experiments on reasoning tasks show it consistently boosts performance while maintaining efficient inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLMBoost: Make Large Language Models Stronger with Boosting] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Existing LLM ensemble methods treat models as black boxes, ignoring internal representations.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: A boosting-inspired framework with cross-model attention, chain training, and near-parallel inference.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Consistently boosts accuracy and reduces inference latency on reasoning tasks.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Northwestern University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22307",children:"https://arxiv.org/pdf/2512.22307"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (<0.1% for 7,168 key bits)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators] --\x3e Problem(\u6838\u5fc3\u95ee\u9898/Problem: Model IP Protection & Supply Chain Threats)\n    Root --\x3e Method(\u4e3b\u8981\u65b9\u6cd5/Method: Hardware-Software Co-design with Logic Locking)\n    Root --\x3e Results(\u5173\u952e\u7ed3\u679c/Results: Resists Attacks, <0.1% Overhead)\n    Problem --\x3e P1(\u6a21\u578b\u76d7\u7a83/Model Theft)\n    Problem --\x3e P2(\u6a21\u578b\u7834\u574f/Model Corruption)\n    Problem --\x3e P3(\u4fe1\u606f\u6cc4\u9732/Information Leakage)\n    Method --\x3e M1(\u8f6f\u4ef6\u4fa7: \u795e\u7ecf\u5143\u5d4c\u5165\u5bc6\u94a5/Software: Key Embedding in Neurons)\n    Method --\x3e M2(\u786c\u4ef6\u4fa7: \u8f7b\u91cf\u7ea7\u9501\u5b9a\u6a21\u5757/Hardware: Lightweight Locking Module)\n    Results --\x3e R1(\u62b5\u5fa1\u4f18\u5316\u653b\u51fb/Withstands Oracle-Guided Attacks)\n    Results --\x3e R2(\u4f4e\u8ba1\u7b97\u5f00\u9500/Low Computational Overhead)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LangPrecip: Language-Aware Multimodal Precipitation Nowcasting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [weather forecasting], [multimodal nowcasting, rectified flow, semantic motion constraint, latent space integration, large-scale dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xudong Ling, Tianxi Huang, Qian Dong, Tao He, Chaorong Li, Guiduo Duan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Electronic Science and Technology of China (UESTC), Chengdu Textile College, Yibin University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22317",children:"https://arxiv.org/pdf/2512.22317"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed LangPrecip, a language-aware multimodal nowcasting framework that uses meteorological text as a semantic motion constraint to guide precipitation evolution. 2. Introduced LangPrecip-160k, a large-scale multimodal dataset with 160k paired radar sequences and motion descriptions. 3. Formulated nowcasting as a semantically constrained trajectory generation problem under the Rectified Flow paradigm for efficient and physically consistent multimodal integration."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff97192e450e6a7b03dee1e2aabdfe42754a4d8248f0398395932ec97689a42d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff97192e450e6a7b03dee1e2aabdfe42754a4d8248f0398395932ec97689a42d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes LangPrecip, a novel framework that integrates meteorological text descriptions with radar data to constrain precipitation nowcasting. By formulating the problem as semantically constrained trajectory generation using Rectified Flow, it achieves significant performance gains, especially for heavy rainfall at long lead times, as demonstrated on Swedish and MRMS datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[LangPrecip: Language-Aware Multimodal Precipitation Nowcasting] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u77ed\u671f\u964d\u6c34\u4e34\u8fd1\u9884\u62a5\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u89c6\u89c9\u6761\u4ef6\uff0c\u672a\u6765\u8fd0\u52a8\u7ea6\u675f\u5f31]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u8bed\u8a00\u611f\u77e5\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5c06\u6c14\u8c61\u6587\u672c\u4f5c\u4e3a\u8bed\u4e49\u8fd0\u52a8\u7ea6\u675f\uff0c\u5728Rectified Flow\u8303\u5f0f\u4e0b\u8fdb\u884c\u6f5c\u7a7a\u95f4\u96c6\u6210]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u5728\u745e\u5178\u548cMRMS\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aSOTA\uff0c\u572880\u5206\u949f\u9884\u89c1\u671f\uff0c\u5f3a\u964d\u6c34CSI\u63d0\u5347\u8d8560%\u548c19%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video understanding], [agentic framework, temporal zoom, reinforcement learning, long video reasoning, multimodal large language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yang Ding, Yizhen Zhang, Xin Lai, Ruihang Chu, Yujiu Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, The Chinese University of Hong Kong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22315",children:"https://arxiv.org/pdf/2512.22315"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/zsgvivo/VideoZoomer",children:"https://github.com/zsgvivo/VideoZoomer"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VideoZoomer, a novel agentic framework that enables MLLMs to dynamically control visual focus during reasoning for long videos. 2. Introduces a two-stage training strategy combining supervised fine-tuning on distilled trajectories with reinforcement learning to refine the agentic policy. 3. Demonstrates strong performance across long video benchmarks, surpassing open-source models and rivaling proprietary systems with superior efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of Multimodal LLMs in understanding long videos due to context window constraints. It proposes VideoZoomer, an agentic framework that dynamically selects and zooms into key temporal moments for fine-grained evidence gathering, trained with a two-stage strategy. The resulting 7B model achieves state-of-the-art performance on long video reasoning benchmarks with high efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u957f\u89c6\u9891\u7406\u89e3\u53d7\u9650/Limited Long Video Understanding]\n    B1 --\x3e B2[\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236/Context Window Limitation]\n    B1 --\x3e B3[\u5747\u5300\u91c7\u6837\u5ffd\u7565\u5173\u952e\u8bc1\u636e/Uniform Sampling Overlooks Evidence]\n    C --\x3e C1[\u4ee3\u7406\u6846\u67b6/Agentic Framework]\n    C1 --\x3e C2[\u52a8\u6001\u65f6\u95f4\u805a\u7126/Dynamic Temporal Focusing]\n    C2 --\x3e C3[\u4ece\u7c97\u5230\u7ec6\u63a8\u7406/Coarse-to-Fine Reasoning]\n    C --\x3e C4[\u4e24\u9636\u6bb5\u8bad\u7ec3/Two-Stage Training]\n    C4 --\x3e C5[\u76d1\u7763\u5fae\u8c03/Supervised Fine-Tuning]\n    C4 --\x3e C6[\u5f3a\u5316\u5b66\u4e60/Reinforcement Learning]\n    D --\x3e D1[\u6027\u80fd\u5f3a\u52b2/Strong Performance]\n    D1 --\x3e D2[\u8d85\u8d8a\u5f00\u6e90\u6a21\u578b/Surpasses Open-Source Models]\n    D1 --\x3e D3[\u5ab2\u7f8e\u4e13\u6709\u7cfb\u7edf/Rivals Proprietary Systems]\n    D --\x3e D4[\u9ad8\u6548\u63a8\u7406/Efficient Reasoning]\n    D4 --\x3e D5[\u4f4e\u5e27\u9884\u7b97/Reduced Frame Budget]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SpotEdit: Selective Region Editing in Diffusion Transformers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [Diffusion Transformers, selective region editing, training-free, perceptual similarity, dynamic fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhibin Qin, Zhenxiong Tan, Zeqing Wang, Songhua Liu, Xinchao Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Singapore, Shanghai Jiao Tong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22323",children:"https://arxiv.org/pdf/2512.22323"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://biangbiang0321.github.io/SpotEdit.github.io/",children:"https://biangbiang0321.github.io/SpotEdit.github.io/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a training-free framework (SpotEdit) for selective region editing in Diffusion Transformers, reducing redundant computation. 2. Introduces SpotSelector to identify stable, unmodified regions via perceptual similarity and skip their denoising. 3. Introduces SpotFusion to adaptively blend reused conditional features with edited tokens, preserving coherence and quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4788068dfc021eb102e739694d672f72a617b80ada2a17fbe2ccbc2780fc1287_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4788068dfc021eb102e739694d672f72a617b80ada2a17fbe2ccbc2780fc1287_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the inefficiency of full-image regeneration in diffusion-based editing when only small regions need modification. It proposes SpotEdit, a training-free framework that selectively updates only modified regions using a selector for stable areas and a fusion mechanism for coherence. This approach reduces computation and maintains fidelity in unedited areas for efficient, precise editing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SpotEdit: Selective Region Editing in Diffusion Transformers] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5168\u56fe\u53bb\u566a\u5197\u4f59/Full-image denoising is redundant for small edits]\n    C --\x3e C1[SpotSelector: \u8bc6\u522b\u7a33\u5b9a\u533a\u57df/Identifies stable regions via perceptual similarity]\n    C --\x3e C2[SpotFusion: \u52a8\u6001\u7279\u5f81\u878d\u5408/Dynamically fuses features for coherence]\n    D --\x3e D1[\u9ad8\u6548\u7f16\u8f91/Efficient editing]\n    D --\x3e D2[\u4fdd\u6301\u672a\u4fee\u6539\u533a\u57df\u4fdd\u771f\u5ea6/Preserves fidelity in unchanged areas]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Peking University, Tencent"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22322",children:"https://arxiv.org/pdf/2512.22322"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://huggingface.co/collections/yolay/smartsnap",children:"https://huggingface.co/collections/yolay/smartsnap"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]\n    D[\u5173\u952e\u7ed3\u679c/Results: Performance gains up to 26.08%; competitive with larger models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Expert System for Bitcoin Forecasting: Integrating Global Liquidity via TimeXer Transformers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [time series forecasting], [TimeXer, Global M2 Liquidity, exogenous variable, long-horizon forecasting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sravan Karthick T"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," RV College of Engineering (RVCE), Bengaluru, India"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22326",children:"https://arxiv.org/pdf/2512.22326"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the integration of Global M2 Liquidity as a leading exogenous variable with a 12-week lag for Bitcoin price forecasting. 2. Proposes a liquidity-conditioned forecasting model (TimeXer-Exog) based on the TimeXer architecture. 3. Demonstrates that explicit macroeconomic conditioning significantly stabilizes and improves long-horizon forecasts, outperforming a univariate baseline by over 89% at a 70-day horizon."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38de8480bbb274bd2bcfff3317dfee4cd7813e42e3af4cc61efcd6d928a0ae36_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38de8480bbb274bd2bcfff3317dfee4cd7813e42e3af4cc61efcd6d928a0ae36_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of long-horizon Bitcoin price forecasting by proposing a model that integrates Global M2 Liquidity as an exogenous variable into the TimeXer transformer architecture. The proposed TimeXer-Exog model significantly outperforms univariate benchmarks, showing that conditioning on global macroeconomic factors substantially improves forecast stability and accuracy over long horizons."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Expert System for Bitcoin Forecasting: Integrating Global Liquidity via TimeXer Transformers] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Bitcoin\u4ef7\u683c\u957f\u671f\u9884\u6d4b\u7684\u6781\u7aef\u6ce2\u52a8\u6027\u548c\u975e\u5e73\u7a33\u6027/Bitcoin's extreme volatility & non-stationarity for long-horizon forecasting)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u96c6\u6210\u5168\u7403M2\u6d41\u52a8\u6027\u4f5c\u4e3a\u5916\u751f\u53d8\u91cf\uff0c\u4f7f\u7528TimeXer\u67b6\u6784/Integrate Global M2 Liquidity as exogenous variable using TimeXer architecture)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u572870\u5929\u9884\u6d4b\u8303\u56f4\u5185\uff0cMSE\u964d\u4f4e\u8d85\u8fc789%/At 70-day horizon, MSE reduced by over 89%)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Multi-View Paradigm Shift in MRI Radiomics: Predicting MGMT Methylation in Glioblastoma"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [multi-view learning, variational autoencoder, latent representation learning, radiomics, glioblastoma]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mariya Miteva, Maria Nisheva-Pavlova"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22331",children:"https://arxiv.org/pdf/2512.22331"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a multi-view latent representation learning framework based on VAEs for integrating complementary MRI radiomic features. 2. Introduced independent probabilistic encoders for each modality to preserve modality-specific structure before fusion in a compact latent space. 3. Applied the learned latent embeddings for the non-invasive classification of MGMT promoter methylation status in glioblastoma."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bde275b3d90b700f19b613a2539cb5c16f7fb3637de09a820e24738011c2f8da_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bde275b3d90b700f19b613a2539cb5c16f7fb3637de09a820e24738011c2f8da_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of non-invasively predicting MGMT promoter methylation in glioblastoma from MRI scans. It proposes a multi-view framework using variational autoencoders to integrate features from T1Gd and FLAIR MRI sequences by fusing them in a latent space, aiming to better preserve modality-specific information. The resulting latent embeddings are used for classification, offering a potential improvement over conventional unimodal or early-fusion radiomics approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Multi-View Paradigm Shift in MRI Radiomics: Predicting MGMT Methylation in Glioblastoma] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Non-invasive prediction of MGMT methylation in glioblastoma from MRI]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-view VAE framework for latent fusion of T1Gd and FLAIR radiomic features]\n    D[\u5173\u952e\u7ed3\u679c/Results: Latent embeddings used for MGMT promoter methylation classification]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [evaluation & benchmarking], [scientific intelligence, multimodal reasoning, benchmarking toolkit]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yiheng Wang, Yixin Chen, Shuo Li, Yifan Zhou, Bo Liu, Hengjian Gao, Jiakang Yuan, Jia Bu, Wanghan Xu, Yuhao Zhou, Xiangyu Zhao, Zhiwang Zhou, Fengxiang Wang, Haodong Duan, Songyang Zhang, Jun Yao, Han Deng, Yizhou Wang, Jiabei Xiao, Jiaqi Liu, Encheng Su, Yujie Liu, Weida Wang, Junchi Yao, Shenghe Zheng, Haoran Sun, Runmin Ma, Xiangchao Yan, Bo Zhang, Dongzhan Zhou, Shufei Zhang, Peng Ye, Xiaosong Wang, Shixiang Tang, Wenlong Zhang, Lei Bai"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Artificial Intelligence Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22334",children:"https://arxiv.org/pdf/2512.22334"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/InternScience/SciEvalKit",children:"https://github.com/InternScience/SciEvalKit"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SciEvalKit, a unified, open-source toolkit for evaluating AI models across a broad range of scientific disciplines and core scientific intelligence capabilities. 2. Provides a flexible and extensible evaluation pipeline supporting batch evaluation, custom model/dataset integration, and ensuring transparent, reproducible results. 3. Curates expert-grade scientific benchmarks from real-world, domain-specific datasets to reflect authentic scientific challenges across six major domains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84233ab293826e87328abdd509857546d8a108ec2ff9c7ccc92d7c00c26ececa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84233ab293826e87328abdd509857546d8a108ec2ff9c7ccc92d7c00c26ececa_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across multiple disciplines and core competencies like multimodal reasoning and code generation. It provides a flexible, extensible pipeline for reproducible evaluation and is built on expert-grade, real-world scientific benchmarks. The toolkit is open-sourced to foster community-driven development in AI for science."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Lack of specialized evaluation for scientific AI across diverse disciplines and capabilities]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Unified benchmarking toolkit with flexible pipeline, real-world benchmarks, and support for six scientific domains]\n    D[\u5173\u952e\u7ed3\u679c/Results: Open-source toolkit enabling standardized, reproducible evaluation of scientific foundation models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [symbolic world models, multi-agent feedback, PDDL, adaptive testing, supervised fine-tuning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mengkang Hu, Bowei Xia, Yuran Wu, Ailing Yu, Yude Zou, Qiguang Chen, Shijian Wang, Jiarui Jin, Kexin Li, Wenxiang Jiao, Yuan Lu, Ping Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Hong Kong, Xiaohongshu Inc., UESTC, Harbin Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22336",children:"https://arxiv.org/pdf/2512.22336"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," agent2world.github.io"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Agent2World, a tool-augmented multi-agent framework for generating symbolic world models via adaptive multi-agent feedback. 2. Introduced a three-stage pipeline with specialized agents (Deep Researcher, Model Developer, Testing Team) for knowledge synthesis, implementation, and behavior-aware validation. 3. Demonstrated that the framework not only achieves state-of-the-art inference-time performance but also serves as a data engine for supervised fine-tuning, leading to substantial model improvement."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3eb7640894bc37e231771de5c5b9dca9d3fe86f38d911d91d2cb55f73a1005c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3eb7640894bc37e231771de5c5b9dca9d3fe86f38d911d91d2cb55f73a1005c6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating correct symbolic world models (like PDDL domains) from natural language by proposing Agent2World, a multi-agent framework that uses adaptive feedback for validation and repair. The method outperforms existing approaches on benchmarks and the feedback collected also enables effective supervised fine-tuning, significantly improving model performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Lack of verifiable supervision for training LLMs to generate behaviorally correct symbolic world models]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Tool-augmented multi-agent framework with three-stage pipeline: Deep Researcher, Model Developer, and Testing Team for adaptive feedback]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves SOTA inference-time performance; Framework serves as data engine for fine-tuning, yielding ~31% average relative gain]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Effectiveness of Approximate Regularized Replay for Efficient Supervised Fine-Tuning of Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [LoRA, catastrophic forgetting, KL divergence, instruction-tuning, parameter-efficient fine-tuning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Matthew Riemer, Erik Miehling, Miao Liu, Djallel Bouneffouf, Murray Campbell"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IBM Research, Mila, Universit\xe9 de Montr\xe9al"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22337",children:"https://arxiv.org/pdf/2512.22337"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that catastrophic forgetting is a severe problem even during parameter-efficient fine-tuning (LoRA) of LLMs on small datasets. 2. Proposes a simple, low-overhead regularized approximate replay method that penalizes KL divergence from the initial model and interleaves next-token prediction data. 3. Shows that this method effectively preserves the model's general knowledge while maintaining plasticity for new tasks, applied to Qwen models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2e24fadff03a1d6696f3147893642a90d9f500d5c68233669842e5792db7332_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2e24fadff03a1d6696f3147893642a90d9f500d5c68233669842e5792db7332_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies that catastrophic forgetting is a major issue during LoRA-based supervised fine-tuning of large language models, even with small datasets. To solve this, the authors propose a regularized approximate replay method that uses KL divergence regularization and interleaves general pre-training-like data. Their approach successfully preserves the model's original capabilities while allowing adaptation to new instructions, with minimal computational overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["\u8bba\u6587\u6807\u9898: The Effectiveness of Approximate Regularized Replay for Efficient Supervised Fine-Tuning of Large Language Models"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: LoRA\u5fae\u8c03\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8/Catastrophic forgetting in LoRA fine-tuning"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: \u6b63\u5219\u5316\u8fd1\u4f3c\u56de\u653e/Regularized Approximate Replay (KL\u60e9\u7f5a+\u4ea4\u9519\u6570\u636e/KL penalty + interleaved data)"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: \u4fdd\u7559\u901a\u7528\u77e5\u8bc6\uff0c\u7ef4\u6301\u53ef\u5851\u6027/Preserves general knowledge without hindering plasticity"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] VULCAN: Tool-Augmented Multi Agents for Iterative 3D Object Arrangement"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D scene understanding and manipulation], [Multimodal Large Language Models (MLLMs), 3D object arrangement, tool-augmented agents, MCP-based API, multi-agent framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhengfei Kuang, Rui Lin, Long Zhao, Gordon Wetzstein, Saining Xie, Sanghyun Woo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University, Google, Google DeepMind, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22351",children:"https://arxiv.org/pdf/2512.22351"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," vulcan-3d.github.io"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced an MCP-based API to shift interaction from raw code to robust function-level updates, addressing MLLMs' weak visual grounding in 3D. 2. Augmented MLLMs with specialized visual tools for scene analysis, spatial information gathering, and action validation, creating a perceptual feedback loop. 3. Proposed a collaborative multi-agent framework with designated planning, execution, and verification roles to manage iterative, error-prone updates in complex tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79364171e71fa2e99be3aaae7f42a6f8bb502acdf59cc5033e98f9a1d424f8bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79364171e71fa2e99be3aaae7f42a6f8bb502acdf59cc5033e98f9a1d424f8bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the underexplored challenge of applying Multimodal Large Language Models (MLLMs) to complex 3D object arrangement. The proposed VULCAN system uses an MCP-based API, a suite of visual tools, and a multi-agent framework to enable robust, iterative 3D scene manipulation. The approach significantly outperforms baselines on a diverse set of 25 complex arrangement tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[VULCAN: Tool-Augmented Multi Agents for Iterative 3D Object Arrangement] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>MLLMs\u5728\u590d\u67423D\u573a\u666f\u64cd\u63a7\u4e2d\u7684\u5e94\u7528\u672a\u88ab\u5145\u5206\u63a2\u7d22<br>Application of MLLMs to complex 3D scene manipulation is underexplored]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u5f15\u5165MCP API\u3001\u89c6\u89c9\u5de5\u5177\u5957\u4ef6\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6<br>Introduces MCP-based API, visual tool suite, and multi-agent collaborative framework]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u572825\u4e2a\u590d\u6742\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf<br>Significantly outperforms baselines on 25 complex tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Feature Learning with Multi-Stage Vision Transformers on Inter-Modality HER2 Status Scoring and Tumor Classification on Whole Slides"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [vision transformer, whole slide image, HER2 scoring, multi-modality, tumor classification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Olaide N. Oyelade, Oliver Hoxey, Yulia Humrye"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," North Carolina A&T State University, University of Chichester, Yale University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22335",children:"https://arxiv.org/pdf/2512.22335"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel mapping function to correlate malignant regions in H&E whole slide images with corresponding regions in IHC images for joint analysis. 2. Developed an end-to-end pipeline using a multi-stage vision transformer system for automatic pixel-level annotation of 4-way HER2 status scoring (0, 1+, 2+, 3+). 3. Embedded a clinically inspired HER2 scoring mechanism that accurately classifies HER2-negative and HER2-positive cases from whole slide images."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03d448dc8fb7520382bb6ea1a3e317817181ebbce215c0d5c387ed2268b2f407_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03d448dc8fb7520382bb6ea1a3e317817181ebbce215c0d5c387ed2268b2f407_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an end-to-end pipeline using multi-stage vision transformers to jointly analyze H&E and IHC whole slide images for HER2 status scoring and tumor classification. The method introduces a novel mapping function to align modalities and provides pixel-level HER2 scoring. The results demonstrate high accuracy (0.94) for HER2 status prediction, showing the method's effectiveness comparable to human pathologists."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Feature Learning with Multi-Stage Vision Transformers on Inter-Modality HER2 Status Scoring and Tumor Classification on Whole Slides] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[\u6311\u6218: \u8054\u5408\u5206\u6790H&E\u548cIHC\u56fe\u50cf\u8fdb\u884cHER2\u8bc4\u5206/Challenge: Jointly analyzing H&E and IHC images for HER2 scoring]\nB --\x3e B2[\u96be\u70b9: \u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u63d0\u4f9b\u50cf\u7d20\u7ea7HER2\u72b6\u6001\u5b9a\u4f4d/Issue: Existing methods lack pixel-level HER2 status localization]\nC --\x3e C1[\u65b9\u6cd5: \u7aef\u5230\u7aef\u591a\u9636\u6bb5\u89c6\u89c9Transformer\u7ba1\u9053/Method: End-to-end multi-stage Vision Transformer pipeline]\nC --\x3e C2[\u521b\u65b0: \u65b0\u9896\u7684\u6620\u5c04\u51fd\u6570\u5173\u8054H&E\u4e0eIHC\u533a\u57df/Innovation: Novel mapping function to correlate H&E and IHC regions]\nC --\x3e C3[\u673a\u5236: \u4e34\u5e8a\u542f\u53d1\u76844\u7ea7HER2\u8bc4\u5206\u673a\u5236/Mechanism: Clinically inspired 4-way HER2 scoring mechanism]\nD --\x3e D1[\u7ed3\u679c: \u80bf\u7624\u5b9a\u4f4d\u5206\u7c7b\u51c6\u786e\u7387\u9ad8/Result: Good classification accuracy for tumor localization]\nD --\x3e D2[\u7ed3\u679c: HER2\u72b6\u6001\u9884\u6d4b\u51c6\u786e\u73870.94/Result: 0.94 accuracy for HER2 status prediction]\nD --\x3e D3[\u7ed3\u8bba: \u7aef\u5230\u7aefViT\u6a21\u578b\u53ef\u7528\u4e8e\u8054\u5408\u8bc4\u4f30H&E\u548cIHC\u56fe\u50cf/Conclusion: End-to-end ViT models usable for jointly evaluating H&E and IHC images]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [pseudo-colouring, few-shot learning, prototypical networks, ResNet-18, explainability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alaa Alahmadi, Mohamed Hasan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Newcastle University, University of Leeds"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22349",children:"https://arxiv.org/pdf/2512.22349"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a perception-informed pseudo-colouring technique to encode clinically salient temporal ECG features (like QT-interval) into structured colour representations. 2. Demonstrates that this technique enables effective few-shot and one-shot learning for a complex physiological data task (drug-induced LQTS) using prototypical networks and ResNet-18. 3. Shows that the method improves model explainability by guiding attention to clinically meaningful features and that aggregating multiple cardiac cycles (mirroring human perceptual averaging) further boosts performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problems of data inefficiency and poor interpretability in deep learning models for physiological signal analysis. It proposes a human-inspired pseudo-colouring technique to encode ECG features, enabling effective few-shot learning and improving model explainability by focusing on clinically relevant signal components. The results demonstrate that incorporating human-like perceptual encoding can bridge data efficiency and interpretability in medical AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data] --\x3e B1\n    A --\x3e B2\n    A --\x3e B3\n    B1[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e C1[\u6570\u636e\u6548\u7387\u4f4e/Lack of data efficiency]\n    B1 --\x3e C2[\u53ef\u89e3\u91ca\u6027\u5dee/Limited explainability]\n    B1 --\x3e C3[\u4e34\u5e8a\u53ef\u9760\u6027\u53d7\u9650/Constrained clinical reliability]\n    B2[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e D1[\u611f\u77e5\u542f\u53d1\u7684\u4f2a\u7740\u8272\u6280\u672f/Perception-informed pseudo-colouring]\n    D1 --\x3e E1[\u7f16\u7801\u4e34\u5e8a\u7279\u5f81/Encode clinical features (e.g., QT-interval)]\n    D1 --\x3e E2[\u7ed3\u6784\u5316\u989c\u8272\u8868\u793a/Structured colour representations]\n    B2 --\x3e D2[\u539f\u578b\u7f51\u7edc\u4e0eResNet-18/Prototypical networks & ResNet-18]\n    B2 --\x3e D3[\u805a\u5408\u591a\u4e2a\u5fc3\u8df3\u5468\u671f/Aggregate multiple cardiac cycles]\n    B3[\u5173\u952e\u7ed3\u679c/Results] --\x3e F1[\u5b9e\u73b0\u5c11\u6837\u672c\u4e0e\u5355\u6837\u672c\u5b66\u4e60/Achieve few-shot & one-shot learning]\n    B3 --\x3e F2[\u63d0\u5347\u53ef\u89e3\u91ca\u6027/Improve explainability (guide attention)]\n    B3 --\x3e F3[\u6865\u63a5\u6570\u636e\u6548\u7387\u4e0e\u56e0\u679c\u63a8\u7406/Bridge data efficiency & causal reasoning]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Text-to-SQL, Cloud Cost Optimization, Query Efficiency, Large Language Models, Google BigQuery]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Saurabh Deochake, Debajyoti Mukhopadhyay"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," SentinelOne, WIDiCoReL Research Lab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22364",children:"https://arxiv.org/pdf/2512.22364"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Existing efficiency metrics (e.g., VES) measure time, not cloud compute costs.] --\x3e B1[\u95ee\u9898\u80cc\u666f/Context<br>LLMs achieve high Text-to-SQL accuracy, but cost efficiency in cloud deployments is unknown.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Systematic evaluation of 6 LLMs on Google BigQuery (StackOverflow dataset).] --\x3e C1[\u8bc4\u4f30\u6307\u6807/Metrics<br>Measure bytes processed, slot utilization, estimated cost, and correctness.]\n    D[\u5173\u952e\u7ed3\u679c/Results] --\x3e D1[\u53d1\u73b01/Finding 1<br>Reasoning models process 44.5% fewer bytes with equivalent correctness.]\n    D --\x3e D2[\u53d1\u73b02/Finding 2<br>Weak correlation (r=0.16) between execution time and query cost.]\n    D --\x3e D3[\u53d1\u73b03/Finding 3<br>Up to 3.4x cost variance; standard models produce high-cost outliers.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [automated planning], [numeric planning, control parameters, subgoaling heuristics, optimistic compilation, infinite action space]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," \xc1ngel Aso-Mollar, Diego Aineto, Enrico Scala, Eva Onaindia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universitat Polit\xe8cnica de Val\xe8ncia, Universit\xe0 degli Studi di Brescia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22367",children:"https://arxiv.org/pdf/2512.22367"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies a tractable subset of numeric planning problems with infinite actions (controllable, simple numeric problems)., 2. Proposes an optimistic compilation approach that transforms these problems into standard simple numeric tasks by abstracting control-dependent expressions., 3. Enables the effective use of traditional subgoaling heuristics for goal distance estimation in this challenging setting, pushing the state of the art."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc3c2ae44e3bb664061095be1d4f9beb835e627f31f49a8bfccf9fd7df412ea_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc3c2ae44e3bb664061095be1d4f9beb835e627f31f49a8bfccf9fd7df412ea_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of applying standard numeric heuristics in planning problems with an infinite number of actions due to control parameters. It proposes an optimistic compilation method that transforms a tractable subset of these problems into simpler numeric tasks, enabling the use of subgoaling heuristics. The results show this approach is effective and computationally feasible for handling infinite action spaces."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions<br>\u57fa\u4e8e\u5b50\u76ee\u6807\u677e\u5f1b\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u7528\u4e8e\u65e0\u9650\u52a8\u4f5c\u6570\u503c\u89c4\u5212"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Standard heuristics fail for infinite actions from control parameters<br>\u6807\u51c6\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u63a7\u5236\u53c2\u6570\u5bfc\u81f4\u7684\u65e0\u9650\u52a8\u4f5c"] --\x3e P1["\u95ee\u9898\u80cc\u666f/Context<br>Numeric planning with control parameters<br>\u5e26\u63a7\u5236\u53c2\u6570\u7684\u6570\u503c\u89c4\u5212"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Optimistic compilation to simple numeric tasks<br>\u901a\u8fc7\u4e50\u89c2\u7f16\u8bd1\u8f6c\u4e3a\u7b80\u5355\u6570\u503c\u4efb\u52a1"] --\x3e M1["\u5173\u952e\u6b65\u9aa4/Key Step<br>Abstract control-dependent expressions<br>\u62bd\u8c61\u63a7\u5236\u4f9d\u8d56\u8868\u8fbe\u5f0f"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Effective & feasible use of subgoaling heuristics<br>\u5b50\u76ee\u6807\u542f\u53d1\u5f0f\u65b9\u6cd5\u6709\u6548\u4e14\u53ef\u884c"] --\x3e R1["\u7ed3\u8bba/Conclusion<br>Pushes state of the art<br>\u63a8\u52a8\u6280\u672f\u524d\u6cbf"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Self-Evaluation Unlocks Any-Step Text-to-Image Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [text-to-image generation, flow matching, self-evaluation, any-step inference, from-scratch training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xin Yu, Xiaojuan Qi, Zhengqi Li, Kai Zhang, Richard Zhang, Zhe Lin, Eli Shechtman, Tianyu Wang, Yotam Nitzan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Hong Kong, Adobe Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22374",children:"https://arxiv.org/pdf/2512.22374"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces the Self-Evaluating Model (Self-E), a novel from-scratch training framework that combines local flow matching with a self-evaluation mechanism, eliminating the need for a pretrained teacher model. 2. Enables "any-step" inference, allowing the same model to perform both high-quality few-step and many-step generation, bridging the gap between local supervision and global matching paradigms. 3. Demonstrates competitive performance with state-of-the-art flow matching models at high step counts while excelling at very low step counts, offering a unified and scalable solution.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8074c4ce26dcd6ff20416ce7ac5c3c013208374f66871d4f0a55abd9bb7e52e9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8074c4ce26dcd6ff20416ce7ac5c3c013208374f66871d4f0a55abd9bb7e52e9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem that traditional diffusion/flow models require many inference steps, and distillation methods need a pretrained teacher. It proposes Self-E, a model trained from scratch that uses self-evaluation as a dynamic teacher to enable high-quality generation at any number of steps. The results show Self-E excels at few-step generation and is competitive at many steps, providing a unified framework for efficient and scalable text-to-image synthesis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Self-Evaluation Unlocks Any-Step Text-to-Image Generation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Traditional models need many steps or a teacher model] --\x3e Problem_Sub1[\u4f20\u7edf\u6a21\u578b\u9700\u8981\u591a\u6b65\u6216\u6559\u5e08\u6a21\u578b/Traditional models need many steps or a teacher]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Self-Evaluating Model (Self-E)] --\x3e Method_Sub1[\u7ed3\u5408\u6d41\u5339\u914d\u4e0e\u81ea\u8bc4\u4f30/Combines Flow Matching & Self-Evaluation]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Unified any-step model] --\x3e Results_Sub1[\u5c11\u6b65\u4e0e\u591a\u6b65\u5747\u8868\u73b0\u4f18\u5f02/Excels at both few-step and many-step]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Towards Efficient Post-Training via Fourier-Driven Adapter Architectures"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [parameter-efficient fine-tuning], [Fourier-Activated Adapter, random Fourier features, frequency-aware activation, parameter-efficient fine-tuning, spectral sparsity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Donggyun Bae, Jongil Park"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Konkuk University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22378",children:"https://arxiv.org/pdf/2512.22378"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Fourier-Activated Adapter (FAA), a novel PEFT framework that integrates random Fourier features to decompose representations into frequency components. 2. Introduces a dynamic, frequency-aware activation mechanism to selectively modulate semantic information across different frequency bands. 3. Demonstrates through extensive experiments that FAA achieves competitive or superior performance on multiple benchmarks while maintaining low computational overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf813cee09035fa7f545005f9b12789221e4e00ecb3d551020cff824fb62233_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf813cee09035fa7f545005f9b12789221e4e00ecb3d551020cff824fb62233_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes the Fourier-Activated Adapter (FAA), a parameter-efficient fine-tuning method for large language models that uses random Fourier features to enable frequency-aware modulation of semantic representations. Experiments on GLUE and other benchmarks show that FAA achieves strong performance with low computational cost, highlighting the effectiveness of its frequency-based approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Towards Efficient Post-Training via Fourier-Driven Adapter Architectures] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709PEFT\u65b9\u6cd5\u96be\u4ee5\u6355\u83b7\u9ad8\u9891\u8bed\u4e49\u4fe1\u606f / Existing PEFT methods struggle to capture high-frequency semantic information]\n    C --\x3e C1[\u63d0\u51fa\u5085\u91cc\u53f6\u6fc0\u6d3b\u9002\u914d\u5668(FAA) / Propose Fourier-Activated Adapter (FAA)]\n    C1 --\x3e C2[\u96c6\u6210\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u5206\u89e3\u8868\u793a / Integrate random Fourier features to decompose representations]\n    C2 --\x3e C3[\u4f7f\u7528\u9891\u7387\u611f\u77e5\u673a\u5236\u9009\u62e9\u6027\u8c03\u5236 / Use frequency-aware mechanism for selective modulation]\n    D --\x3e D1[\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c / Achieves competitive results on multiple benchmarks]\n    D --\x3e D2[\u4fdd\u6301\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500 / Maintains low computational and memory overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri, SRI International"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22387",children:"https://arxiv.org/pdf/2512.22387"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Is AI-generated code reproducible?"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Empirical study using a three-layer dependency framework on 300 projects from 3 LLM agents."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Low out-of-the-box execution rate (68.3%) and large hidden dependencies (13.5x expansion)."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Completed Hyperparameter Transfer across Modules, Width, Depth, Batch and Duration"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [hyperparameter transfer, Complete(d)P parameterisation, per-module hyperparameter optimisation, scaling laws, evolutionary strategy]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bruno Mlodozeniec, Pierre Ablin, Louis B\xe9thune, Dan Busbridge, Michal Klein, Jason Ramapuram, Marco Cuturi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Apple, University of Cambridge"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22382",children:"https://arxiv.org/pdf/2512.22382"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Complete(d)P parameterisation, a unified framework for scaling hyperparameters across model width, depth, batch size, and training duration. 2. Investigates and enables the transfer of per-module hyperparameters (e.g., learning rates, weight decay) across model scales, moving beyond global hyperparameter transfer. 3. Provides practical guidelines for navigating the high-dimensional per-module hyperparameter optimization landscape and demonstrates significant training speed improvements in Large Language Models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06e0593eb453191fce60eeebdd4eb6147ab462084db9eb8d81ea8e2486d468be_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06e0593eb453191fce60eeebdd4eb6147ab462084db9eb8d81ea8e2486d468be_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of hyperparameter transfer across different model scales and configurations. It introduces the Complete(d)P parameterisation to unify scaling across width, depth, batch size, and duration, and demonstrates that with this method, even granular per-module hyperparameters can be optimized on a small model and successfully transferred to much larger models, leading to faster training and improved performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Completed Hyperparameter Transfer<br/>\u8d85\u53c2\u6570\u8fc1\u79fb\u7814\u7a76] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Hyperparameter tuning is critical for large models<br/>\u5927\u6a21\u578b\u8d85\u53c2\u6570\u8c03\u4f18\u81f3\u5173\u91cd\u8981]\n    B --\x3e B2[Transferring optimal HPs across scales is challenging<br/>\u8de8\u89c4\u6a21\u6700\u4f18\u8d85\u53c2\u6570\u8fc1\u79fb\u56f0\u96be]\n    C --\x3e C1[Propose Complete(d)P parameterisation<br/>\u63d0\u51faComplete(d)P\u53c2\u6570\u5316\u65b9\u6cd5]\n    C --\x3e C2[Enable per-module HP optimisation & transfer<br/>\u5b9e\u73b0\u6a21\u5757\u7ea7\u8d85\u53c2\u6570\u4f18\u5316\u4e0e\u8fc1\u79fb]\n    D --\x3e D1[Direct HP transfer to ~600x larger scale<br/>\u8d85\u53c2\u6570\u53ef\u76f4\u63a5\u8fc1\u79fb\u81f3\u7ea6600\u500d\u89c4\u6a21]\n    D --\x3e D2[Per-module HPs yield training speedup<br/>\u6a21\u5757\u7ea7\u8d85\u53c2\u6570\u5e26\u6765\u8bad\u7ec3\u52a0\u901f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [few-shot learning], [exemplar selection, large language model, human activity recognition, facility-location optimization, PageRank]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Elsen Ronando, Sozo Inoue"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kyushu Institute of Technology, Universitas 17 Agustus 1945 Surabaya"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22385",children:"https://arxiv.org/pdf/2512.22385"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an LLM-Guided Exemplar Selection framework that incorporates semantic reasoning via LLM-generated knowledge priors (feature importance, inter-class confusability, budget multipliers) for HAR. 2. Integrates these semantic priors with multiple geometric and structural cues (margin-based validation, PageRank centrality, hubness penalization, facility-location optimization) for a unified exemplar scoring and selection process. 3. Demonstrates superior performance (88.78% macro F1-score on UCI-HAR) under strict few-shot conditions compared to classical selection methods like random sampling, herding, and k-center."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90a149428a6ff84d38e1ab6a741982394b05c9d5b98eaaa538dcd12183dbe7bf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90a149428a6ff84d38e1ab6a741982394b05c9d5b98eaaa538dcd12183dbe7bf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of relying on large labeled datasets and purely geometric exemplar selection in Human Activity Recognition (HAR) by proposing an LLM-Guided Exemplar Selection framework. The method uses an LLM to generate semantic knowledge priors, which are combined with structural and geometric cues to select a compact, informative set of exemplars for few-shot learning. Evaluated on the UCI-HAR dataset, the framework outperforms classical selection approaches, showing that integrating semantic reasoning improves representative exemplar selection for wearable-sensor HAR."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-Guided Exemplar Selection for Few-Shot HAR] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f9d\u8d56\u5927\u6570\u636e\u96c6\u4e0e\u51e0\u4f55\u9009\u62e9 / Reliance on large datasets & geometric selection]\n    B --\x3e B2[\u96be\u4ee5\u533a\u5206\u76f8\u4f3c\u6d3b\u52a8 / Hard to distinguish similar activities]\n    C --\x3e C1[LLM\u751f\u6210\u8bed\u4e49\u5148\u9a8c / LLM-generated semantic priors]\n    C --\x3e C2[\u7ed3\u5408\u591a\u7ebf\u7d22\u4f18\u5316 / Combine multiple cues for optimization]\n    D --\x3e D1[\u6027\u80fd\u8d85\u8d8a\u57fa\u7ebf / Outperforms baselines (88.78% F1)]\n    D --\x3e D2[\u8bed\u4e49\u5148\u9a8c\u6709\u6548 / Semantic priors are effective]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection], [hallucination detection, retrieval-augmented verification, contradiction graph, Paraphrased Hallucination Consistency Score (PHCS), materials science]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Sajid Mahmud, Pawan Neupane, Joel Selvaraj, Jianlin Cheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22396",children:"https://arxiv.org/pdf/2512.22396"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces HalluMatData, a benchmark dataset for evaluating hallucination detection in AI-generated materials science content. 2. Proposes HalluMatDetector, a multi-stage hallucination detection framework integrating intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment. 3. Introduces the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2d61ec50b266277e33c913c31df1946cc27990dbacfbd8d5b4979a627f3fa00_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2d61ec50b266277e33c913c31df1946cc27990dbacfbd8d5b4979a627f3fa00_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of factual hallucinations in LLM-generated materials science content. It proposes HalluMatDetector, a multi-stage verification framework that combines intrinsic checks, retrieval, and contradiction analysis to detect and mitigate errors. The method reduces hallucination rates by 30% compared to standard LLM outputs and introduces a new metric (PHCS) for evaluating response consistency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: LLM Hallucinations in Scientific Content"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Multi-Stage Verification Framework (HalluMatDetector)"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: 30% Hallucination Reduction & New Metric (PHCS)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [knowledge graph embeddings, inference-time personalization, parameter-efficient adaptation, structure-gated adaptation, frozen backbone]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ozan Oguztuzun, Cerag Oguztuzun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Case Western Reserve University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22398",children:"https://arxiv.org/pdf/2512.22398"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A post-hoc personalization mechanism that operates at inference time on frozen KG embeddings without backbone updates. 2. A structure-gated adaptation method that conditions candidate rankings on profile features via graph-derived gates. 3. New evaluation metrics for personalization (Alignment@k and Counterfactual Responsiveness) to quantify alignment and causal responsiveness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b860d25f74e154dce6d1b1a346b065fe4b4e238a600b81e91ad6a825aa744e1c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b860d25f74e154dce6d1b1a346b065fe4b4e238a600b81e91ad6a825aa744e1c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem that foundation models for knowledge graphs perform well for groups but fail to capture individual user preferences. It proposes GatedBias, a lightweight framework that adds interpretable, per-entity biases to frozen KG embeddings at inference time using profile features and graph-derived gates, requiring only ~300 parameters. The method significantly improves personalized ranking alignment on benchmark datasets while preserving global accuracy, demonstrating that parameter-efficient and causally verifiable personalization is possible."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Foundation KG models fail to capture individual user preferences"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: GatedBias framework using structure-gated adaptation on frozen embeddings"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Improves alignment, preserves cohort performance, parameter-efficient"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] BLISS: Bandit Layer Importance Sampling Strategy for Efficient Training of Graph Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Graph Neural Networks, Multi-armed Bandits, Layer-wise Sampling, Node Importance, Efficient Training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Omar Alsaqa, Linh Thi Hoang, Muhammed Fatih Balin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wilfrid Laurier University, Singapore Management University, Georgia Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22388",children:"https://arxiv.org/pdf/2512.22388"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces BLISS, a novel adaptive sampling strategy using multi-armed bandits to dynamically select informative nodes at each GNN layer. 2. Balances exploration and exploitation to ensure comprehensive graph coverage and adapts to evolving node importance, unlike static methods. 3. Demonstrates versatility by integrating with different GNN architectures (GCNs and GATs) and maintaining or exceeding full-batch training accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1be93ab34a4af58594bc48c8d52cc9f7177c298fc314982c8ac7ae27b2086b70_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1be93ab34a4af58594bc48c8d52cc9f7177c298fc314982c8ac7ae27b2086b70_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the computational bottleneck in training Graph Neural Networks (GNNs) on large graphs by proposing BLISS, a Bandit Layer Importance Sampling Strategy. BLISS uses multi-armed bandits to dynamically and adaptively sample the most informative nodes at each layer. Experiments show that this method maintains or even surpasses the accuracy of full-batch training while being more efficient."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BLISS: Bandit Layer Importance Sampling Strategy] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bad\u7ec3\u5927\u578b\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8ba1\u7b97\u6210\u672c\u9ad8/High computational cost for training GNNs on large graphs]\n    C --\x3e C1[\u4f7f\u7528\u591a\u81c2\u8001\u864e\u673a\u52a8\u6001\u9009\u62e9\u4fe1\u606f\u8282\u70b9/Using multi-armed bandits to dynamically select informative nodes]\n    C --\x3e C2[\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u81ea\u9002\u5e94\u8282\u70b9\u91cd\u8981\u6027/Balancing exploration and exploitation, adapting to node importance]\n    D --\x3e D1[\u4fdd\u6301\u6216\u8d85\u8fc7\u5168\u6279\u6b21\u8bad\u7ec3\u7684\u7cbe\u5ea6/Maintains or exceeds full-batch training accuracy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Efficient Multi-Model Orchestration for Self-Hosted Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Kubernetes, Helm, DistilBERT, scale-to-zero, hybrid routing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Tanu Malik"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22402",children:"https://arxiv.org/pdf/2512.22402"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A unified Helm-based deployment system for self-hosted LLMs on Kubernetes, 2. An adaptive scale-to-zero automation mechanism for efficient GPU resource utilization, 3. A hybrid routing module combining keyword heuristics and a lightweight DistilBERT classifier to balance cost, latency, and accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper introduces "Pick and Spin," a framework for efficient orchestration of self-hosted large language models. It addresses challenges in GPU utilization and workload routing by integrating Kubernetes-based deployment, adaptive scaling, and a hybrid routing strategy. The system demonstrates significant improvements in success rate, latency, and cost compared to static deployments.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Efficient Multi-Model Orchestration for Self-Hosted LLMs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Self-hosted LLM deployment challenges: GPU utilization, workload routing, reliability/\u81ea\u6258\u7ba1LLM\u90e8\u7f72\u6311\u6218\uff1aGPU\u5229\u7528\u7387\u3001\u5de5\u4f5c\u8d1f\u8f7d\u8def\u7531\u3001\u53ef\u9760\u6027]\n    C --\x3e C1[Pick and Spin Framework: Kubernetes, Helm, scale-to-zero, hybrid routing/Pick and Spin\u6846\u67b6\uff1aKubernetes, Helm, \u7f29\u5bb9\u81f3\u96f6, \u6df7\u5408\u8def\u7531]\n    D --\x3e D1[21.6% higher success rate, 30% lower latency, 33% lower cost/\u6210\u529f\u7387\u63d0\u534721.6%\uff0c\u5ef6\u8fdf\u964d\u4f4e30%\uff0c\u6210\u672c\u964d\u4f4e33%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, dynamic adaptation, multi-armed bandit, throughput optimization, latency reduction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Defense Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22420",children:"https://arxiv.org/pdf/2512.22420"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies the critical trade-off in speculative decoding: beneficial in memory-bound (low-load) scenarios but detrimental in compute-bound (high-load) scenarios due to verification overhead. 2. Proposes Nightjar, a novel learning-based algorithm that dynamically adapts the speculative length (or disables SD) based on real-time request load and batch size. 3. Demonstrates significant performance gains, achieving up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the inefficiency of fixed-length speculative decoding in LLM serving, which fails to adapt to dynamic request loads. It proposes Nightjar, a learning-based algorithm that dynamically selects the optimal speculative length. Experiments show Nightjar significantly improves throughput and reduces latency compared to standard speculative decoding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Nightjar: Dynamic Adaptive Speculative Decoding] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Fixed speculative length fails under dynamic loads]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Learning-based algorithm adapts speculative length]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Higher throughput, lower latency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A Unified AI, Embedded, Simulation, and Mechanical Design Approach to an Autonomous Delivery Robot"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [Heterogeneous Computing, ROS 2, FreeRTOS, PID Control, AWS IoT]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amro Gamar, Ahmed Abduljalil, Alargam Mohammed, Ali Elhenidy, Abeer Tawakol"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Mansoura University, Egypt"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22408",children:"https://arxiv.org/pdf/2512.22408"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed a heterogeneous computing architecture combining a Raspberry Pi 5 with ROS 2 for high-level AI perception/path planning and an ESP32 with FreeRTOS for real-time motor control. 2. Implemented a low-latency, reliable communication link between the ROS 2 host and the embedded controller to ensure system coordination. 3. Enhanced system reliability through deterministic PID-based motor control with static memory allocation and integrated AWS IoT monitoring with a firmware-level motor shutdown failsafe."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c49a4266e78db3945d26829ffd5e030ccc9fa68be1c543cca653fc81df446dfe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c49a4266e78db3945d26829ffd5e030ccc9fa68be1c543cca653fc81df446dfe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents the development of an autonomous delivery robot using a unified, multi-disciplinary approach. It employs a heterogeneous computing architecture to handle AI-based navigation on a Raspberry Pi and real-time motor control on an ESP32, addressing challenges like algorithm optimization and inter-processor communication. The result is a robust, operational system demonstrated to be capable of real-world deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Unified AI, Embedded, Simulation, and Mechanical Design Approach to an Autonomous Delivery Robot"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Limitations of human-operated last-mile delivery (cost, safety, reliability)"] --\x3e P1["\u5b50\u95ee\u9898/Sub-Problem<br>Need for autonomous, cost-efficient delivery robot"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Unified multi-disciplinary approach"] --\x3e M1["\u5f02\u6784\u8ba1\u7b97/Heterogeneous Computing<br>RPi 5 (ROS 2) for AI & ESP32 (FreeRTOS) for control"]\n    Method --\x3e M2["\u5173\u952e\u6280\u672f/Key Tech<br>Low-latency comms, PID control, AWS IoT, failsafe"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Robust, operational autonomous delivery system"] --\x3e R1["\u6210\u679c/Outcome<br>Deterministic motor control & enhanced reliability"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Emergence of Human to Robot Transfer in Vision-Language-Action Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [robot learning], [vision-language-action models, human-to-robot transfer, co-training, emergent capability, embodiment-agnostic representations]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Simar Kareer, Karl Pertsch, James Darpinian, Judy Hoffman, Danfei Xu, Sergey Levine, Chelsea Finn, Suraj Nair"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Physical Intelligence, Georgia Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22414",children:"https://arxiv.org/pdf/2512.22414"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a simple co-training recipe for training Vision-Language-Action (VLA) models on a mix of human video and robot data. 2. Discovers and demonstrates that the ability to transfer skills from human videos to robot policies is an emergent property that appears with sufficient scale and diversity in robot pre-training data. 3. Provides analysis suggesting the emergent capability arises from the model learning embodiment-agnostic representations through diverse pre-training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c14383fd88b5d16af8c13ba59202c2143ecd1d25b65a10248ec614491595a50_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c14383fd88b5d16af8c13ba59202c2143ecd1d25b65a10248ec614491595a50_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether Vision-Language-Action (VLA) models can learn to transfer skills from human videos to robots, a task that is typically challenging. The authors propose a simple co-training method and find that this human-to-robot transfer capability emerges as a property of scale when the model is pre-trained on a sufficiently large and diverse dataset of robot tasks. Their experiments show that with diverse pre-training, leveraging human data can nearly double performance on tasks seen only in human videos."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Emergence of Human to Robot Transfer in Vision-Language-Action Models] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Can VLA models learn from human videos for robot control?]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Simple co-training recipe on human & robot data]\n    D[\u5173\u952e\u7ed3\u679c/Results: Transfer emerges with scale; performance nearly doubles]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Bright 4B: Scaling Hyperspherical Learning for Segmentation in 3D Brightfield Microscopy"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image segmentation], [hyperspherical learning, native sparse attention, anisotropic patch embed]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amil Khan, Matheus Palhares Viana, Suraj Mishra, B.S. Manjunath"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," UC Santa Barbara, Allen Institute for Cell Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22423",children:"https://arxiv.org/pdf/2512.22423"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A 4B-parameter foundation model (Bright-4B) that learns on the unit hypersphere for segmenting subcellular structures directly from 3D brightfield volumes. 2. Novel architectural components: a hardware-aligned Native Sparse Attention mechanism, depth-width residual HyperConnections, and a soft Mixture-of-Experts for adaptive capacity. 3. A plug-and-play anisotropic patch embed that respects confocal point-spread and axial thinning for geometry-faithful 3D tokenization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7af1d13c6f2fcc3e8d27fe1157700eff79fd4e0fccc0c4ba8b37ebb62c2043fd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7af1d13c6f2fcc3e8d27fe1157700eff79fd4e0fccc0c4ba8b37ebb62c2043fd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Bright-4B, a 4-billion parameter foundation model designed for volumetric segmentation of subcellular structures directly from label-free 3D brightfield microscopy images. It employs novel architectural components like hyperspherical learning, native sparse attention, and an anisotropic patch embed to handle 3D context and anisotropic sampling. The model outperforms contemporary baselines in preserving fine structural detail across depth and cell types without requiring fluorescence or heavy post-processing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Bright 4B: Scaling Hyperspherical Learning for Segmentation in 3D Brightfield Microscopy] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Robust 3D segmentation in brightfield microscopy depends on fluorescence or heavy post-processing.)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: A 4B-parameter foundation model with hyperspherical learning, native sparse attention, hyperconnections, mixture-of-experts, and anisotropic patch embed.)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Produces accurate segmentations from brightfield alone, outperforms baselines, preserves detail across depth and cell types.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] FluenceFormer: Transformer-Driven Multi-Beam Fluence Map Regression for Radiotherapy Planning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [transformer, fluence map prediction, physics-informed loss, two-stage regression, Swin UNETR]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ujunwa Mgboh, Rafi Ibn Sultan, Joshua Kim, Kundan Thind, Dongxiao Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wayne State University, Henry Ford Health"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22425",children:"https://arxiv.org/pdf/2512.22425"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed FluenceFormer, a backbone-agnostic transformer framework for direct, geometry-aware fluence map regression. 2. Introduced a unified two-stage design (dose prior prediction followed by geometry-conditioned fluence regression) and the physics-informed Fluence-Aware Regression (FAR) loss. 3. Demonstrated the framework's generality across multiple transformer backbones and achieved state-of-the-art performance, significantly reducing energy error."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5d0e329d1bfd4c1f892f7333af6a3a4e76c5219cd192f715a25e502a35ef178_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5d0e329d1bfd4c1f892f7333af6a3a4e76c5219cd192f715a25e502a35ef178_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces FluenceFormer, a transformer-based framework for automating radiotherapy planning by predicting multi-beam fluence maps. The method uses a two-stage, geometry-aware regression approach with a novel physics-informed loss function. The results show that FluenceFormer outperforms existing methods, achieving a low energy error and improved structural fidelity in fluence map prediction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FluenceFormer: Transformer-Driven Multi-Beam Fluence Map Regression for Radiotherapy Planning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Ill-posed inverse problem: complex anatomy-beam relationship / \u75c5\u6001\u9006\u95ee\u9898: \u89e3\u5256\u7ed3\u6784\u4e0e\u5c04\u675f\u5f3a\u5ea6\u7684\u590d\u6742\u5173\u7cfb]\n    B --\x3e B2[CNN struggles with long-range dependencies / CNN\u96be\u4ee5\u6355\u6349\u957f\u7a0b\u4f9d\u8d56]\n    C --\x3e C1[Two-stage transformer framework / \u4e24\u9636\u6bb5Transformer\u6846\u67b6]\n    C1 --\x3e C1_1[Stage 1: Global dose prior / \u9636\u6bb51: \u5168\u5c40\u5242\u91cf\u5148\u9a8c]\n    C1 --\x3e C1_2[Stage 2: Geometry-conditioned fluence regression / \u9636\u6bb52: \u51e0\u4f55\u6761\u4ef6\u5316\u7684\u6ce8\u91cf\u56fe\u56de\u5f52]\n    C --\x3e C2[Fluence-Aware Regression (FAR) loss / \u6ce8\u91cf\u611f\u77e5\u56de\u5f52\u635f\u5931]\n    D --\x3e D1[Reduced Energy Error to 4.5% / \u80fd\u91cf\u8bef\u5dee\u964d\u4f4e\u81f34.5%]\n    D --\x3e D2[Improved structural fidelity (p<0.05) / \u7ed3\u6784\u4fdd\u771f\u5ea6\u663e\u8457\u63d0\u5347]\n    D --\x3e D3[Outperformed benchmark CNN & single-stage methods / \u8d85\u8d8a\u57fa\u51c6CNN\u4e0e\u5355\u9636\u6bb5\u65b9\u6cd5]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SuperiorGAT: Graph Attention Networks for Sparse LiDAR Point Cloud Reconstruction in Autonomous Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [point cloud processing], [Graph Attention Networks, LiDAR reconstruction, beam dropout, gated residual fusion, sparse point cloud]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Khalfalla Awedat, Mohamed Abidalrekab, Gurcan Comert, Mustafa Ayad"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," SUNY Morrisville College, Portland State University, North Carolina A&T State University, SUNY Oswego"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22439",children:"https://arxiv.org/pdf/2512.22439"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SuperiorGAT, a novel graph attention-based framework for reconstructing missing elevation data in sparse LiDAR point clouds. 2. Introduces a beam-aware graph modeling approach for LiDAR scans combined with gated residual fusion and feed-forward refinement to achieve accurate reconstruction without increasing network depth. 3. Demonstrates superior performance in reconstruction error and geometric consistency across diverse environments compared to PointNet and deeper GAT baselines, validated through structured beam dropout simulation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68e019420f70e8da99107deedb1af90b7e95ec95b9487f8fc6c872f9994d15e1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68e019420f70e8da99107deedb1af90b7e95ec95b9487f8fc6c872f9994d15e1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of LiDAR beam dropout and sparse resolution in autonomous systems by proposing SuperiorGAT, a graph attention network framework that reconstructs missing elevation information. The method models LiDAR scans as beam-aware graphs and uses gated residual fusion for accurate reconstruction without deeper networks. The results show it achieves lower error and better geometric consistency than baselines, offering a computationally efficient way to improve LiDAR resolution."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SuperiorGAT: Graph Attention Networks for Sparse LiDAR Point Cloud Reconstruction] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LiDAR\u5782\u76f4\u5206\u8fa8\u7387\u56fa\u5b9a\u4e0e\u5149\u675f\u4e22\u5931\u5bfc\u81f4\u70b9\u4e91\u7a00\u758f]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8e\u5149\u675f\u611f\u77e5\u56fe\u4e0e\u95e8\u63a7\u6b8b\u5dee\u878d\u5408\u7684\u56fe\u6ce8\u610f\u529b\u7f51\u7edc]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u91cd\u5efa\u8bef\u5dee\u66f4\u4f4e\uff0c\u51e0\u4f55\u4e00\u81f4\u6027\u66f4\u597d\uff0c\u7ed3\u6784\u5b8c\u6574\u6027\u4fdd\u6301]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Monadic Context Engineering"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Monadic Context Engineering, Monad Transformers, Meta-Agents, computational contexts, algebraic structures]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yifan Zhang, Mengdi Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Princeton University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22431",children:"https://arxiv.org/pdf/2512.22431"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/yifanzhang-pro/monadic-context-engineering",children:"https://github.com/yifanzhang-pro/monadic-context-engineering"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Monadic Context Engineering (MCE), a novel architectural paradigm using Functors, Applicatives, and Monads to provide a formal foundation for AI agent design. 2. Demonstrates how Monads and Applicatives manage sequential composition and parallel execution, and how Monad Transformers enable systematic composition of capabilities like state and error handling. 3. Extends the MCE framework to describe Meta-Agents for generative orchestration, dynamically creating and managing sub-agent workflows via metaprogramming."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/635ff6dca4b79fe5e98a96641cbb26356935e3090aa65b20972b744e69151810_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/635ff6dca4b79fe5e98a96641cbb26356935e3090aa65b20972b744e69151810_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the brittleness and complexity in current AI agent architectures by introducing Monadic Context Engineering (MCE), a paradigm that leverages algebraic structures like Monads to formally manage state, errors, and concurrency within agent workflows. The proposed method enables the construction of complex, resilient agents from simple, verifiable components and is extended to support generative orchestration via Meta-Agents. The work concludes that MCE provides a principled foundation for building robust and scalable autonomous agent systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Monadic Context Engineering"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u5f53\u524d\u4ee3\u7406\u67b6\u6784\u8106\u5f31/Current agent architectures are brittle"]\n    Problem --\x3e P2["\u72b6\u6001\u3001\u9519\u8bef\u3001\u5e76\u53d1\u7ba1\u7406\u56f0\u96be/Difficulties in state, error, concurrency management"]\n    Method --\x3e M1["\u5f15\u5165\u5355\u5b50\u4e0a\u4e0b\u6587\u5de5\u7a0b/Introduce Monadic Context Engineering (MCE)"]\n    Method --\x3e M2["\u5229\u7528\u51fd\u5b50\u3001\u5e94\u7528\u51fd\u5b50\u3001\u5355\u5b50/Leverage Functors, Applicatives, Monads"]\n    Method --\x3e M3["\u4f7f\u7528\u5355\u5b50\u53d8\u6362\u5668\u7ec4\u5408\u80fd\u529b/Use Monad Transformers to compose capabilities"]\n    Results --\x3e R1["\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840/Provides a formal foundation"]\n    Results --\x3e R2["\u652f\u6301\u6784\u5efa\u590d\u6742\u3001\u9c81\u68d2\u7684\u4ee3\u7406/Enables building complex, resilient agents"]\n    Results --\x3e R3["\u6269\u5c55\u81f3\u5143\u4ee3\u7406\u8fdb\u884c\u751f\u6210\u5f0f\u7f16\u6392/Extends to Meta-Agents for generative orchestration"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [hierarchical filtering, two-pass generation, citation verification, query formulation, model cascade]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Cattalyya Nuengsigkapian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22442",children:"https://arxiv.org/pdf/2512.22442"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a hierarchical content filtering pipeline to replace standard vector similarity search, improving context precision. 2. Introduces a model cascade strategy using a cost-efficient model (Gemini 2.5 Flash) for filtering and a powerful model (Gemini 2.5 Pro) for final generation. 3. Demonstrates significant performance gains on the MMU-RAGent benchmark and a custom dataset for post-cutoff knowledge."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents HiFi-RAG, a system designed to improve open-domain RAG by addressing irrelevant retrieved information. The method uses a multi-stage pipeline with hierarchical filtering and a two-pass generation strategy employing different LLMs for efficiency and quality. The system won a NeurIPS 2025 competition and showed substantial improvements over baselines in evaluation metrics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HiFi-RAG] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5f00\u653e\u57dfRAG\u4e2d\u7684\u65e0\u5173\u4fe1\u606f\u4e0e\u610f\u56fe\u5bf9\u9f50/Open-domain RAG faces irrelevant info & intent misalignment]\n    C --\x3e C1[\u5206\u5c42\u8fc7\u6ee4\u4e0e\u4e24\u9636\u6bb5\u751f\u6210/Hierarchical Filtering & Two-Pass Generation]\n    C1 --\x3e C2[\u4f7f\u7528Gemini Flash\u8fdb\u884c\u8fc7\u6ee4/Use Gemini Flash for filtering]\n    C1 --\x3e C3[\u4f7f\u7528Gemini Pro\u8fdb\u884c\u751f\u6210/Use Gemini Pro for generation]\n    D --\x3e D1[\u5728MMU-RAGent\u4e0a\u8d85\u8d8a\u57fa\u7ebf/Outperforms baseline on MMU-RAGent]\n    D --\x3e D2[\u5728\u81ea\u5b9a\u4e49\u6d4b\u8bd5\u96c6\u4e0a\u663e\u8457\u63d0\u5347/Substantial gains on custom test set]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Towards Robust Optical-SAR Object Detection under Missing Modalities: A Dynamic Quality-Aware Fusion Framework"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [optical-SAR fusion, missing modality, quality-aware fusion, dynamic fusion, orthogonal constraint]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhicheng Zhao, Yuancheng Xu, Andong Lu, Chenglong Li, Jin Tang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Anhui University, China Electronics Technology Group Corporation (38th Research Institute)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22447",children:"https://arxiv.org/pdf/2512.22447"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel Quality-Aware Dynamic Fusion Network (QDFNet) for robust optical-SAR object detection under missing or degraded modalities. 2. Designed a Dynamic Modality Quality Assessment (DMQA) module that uses learnable reference tokens to iteratively assess feature reliability and identify degraded regions. 3. Developed an Orthogonal Constraint Normalization Fusion (OCNF) module that uses orthogonal constraints to preserve modality independence and dynamically adjust fusion weights based on reliability scores to suppress unreliable features."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69b5db28a2b2a43b3d55d1592c7f26e5ce4421dd707ae3e19282c69c4e894e50_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69b5db28a2b2a43b3d55d1592c7f26e5ce4421dd707ae3e19282c69c4e894e50_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of robust object detection using optical and SAR images when one modality is missing or degraded. The proposed QDFNet method dynamically assesses feature quality and adaptively fuses information using learnable tokens and orthogonal constraints. Experiments show it outperforms other methods, especially when modalities are partially missing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Towards Robust Optical-SAR Object Detection under Missing Modalities: A Dynamic Quality-Aware Fusion Framework"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Optical-SAR image pairs are often misaligned or missing, degrading fusion-based detection."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Proposes QDFNet with DMQA (quality assessment) and OCNF (orthogonal fusion) modules."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Superior performance on SpaceNet6-OTD and OGSOD-2.0 datasets, especially under missing data."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AMBIT: Augmenting Mobility Baselines with Interpretable Trees"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [urban computing, spatial data science], [origin-destination flow prediction, spatial interaction models, gradient-boosted trees, SHAP analysis, gray-box model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qizhi Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," PingCAP, Data & AI-Innovation Lab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22466",children:"https://arxiv.org/pdf/2512.22466"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducts a comprehensive audit of classical spatial interaction models on high-resolution mobility data, identifying PPML gravity as the strongest physical baseline. 2. Proposes AMBIT, a gray-box framework that augments interpretable physical baselines with gradient-boosted trees to learn residuals, balancing accuracy and interpretability. 3. Demonstrates that physics-grounded and POI-anchored residual learners achieve competitive accuracy and robust spatial generalization, providing a reproducible pipeline with diagnostics for urban decision-making."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d0d9ab13b8b2f60e318c90f38821b29e87e0bdd9bf0d9bc963b48c5ac7c2759_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d0d9ab13b8b2f60e318c90f38821b29e87e0bdd9bf0d9bc963b48c5ac7c2759_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AMBIT, a gray-box framework that combines interpretable physical mobility baselines with gradient-boosted trees to predict origin-destination flows. It shows that learning residuals on top of physics-based models can achieve accuracy close to strong black-box predictors while maintaining interpretable structure, with POI-anchored residuals being particularly robust for spatial generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AMBIT: Augmenting Mobility Baselines with Interpretable Trees] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Conflicting needs for high accuracy and clear interpretability in OD flow prediction]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Gray-box framework augmenting physical baselines with interpretable tree models]\n    D[\u5173\u952e\u7ed3\u679c/Results: Physics-grounded residuals approach black-box accuracy; POI-anchored residuals are most robust]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Bayesian Geometry of Transformer Attention"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [interpretability], [Bayesian inference, transformer attention, mechanistic interpretability, Bayesian wind tunnels, geometric analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Columbia University, Dream Sports, Google DeepMind"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22471",children:"https://arxiv.org/pdf/2512.22471"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces "Bayesian wind tunnels" as controlled environments to rigorously test if transformers perform Bayesian inference, where true posteriors are known and memorization is impossible. 2. Demonstrates that small transformers implement Bayesian inference via a consistent geometric mechanism (residual streams as belief substrate, FFNs for updates, attention for routing), while MLPs fail. 3. Identifies specific geometric diagnostics (orthogonal key bases, query-key alignment, low-dimensional value manifold) and a frame-precision dissociation during training.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5333e070f21cfd2abea4d13cddb84bf6d9f3c3124c93bf9142879f24f1e739b1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5333e070f21cfd2abea4d13cddb84bf6d9f3c3124c93bf9142879f24f1e739b1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper investigates whether transformers perform genuine Bayesian inference. To test this, the authors create controlled "Bayesian wind tunnel" tasks with known posteriors and show that small transformers accurately reproduce Bayesian posteriors via a specific geometric mechanism, while MLPs fail, establishing attention as crucial for this capability.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["The Bayesian Geometry of Transformer Attention<br/>Transformer\u6ce8\u610f\u529b\u7684\u8d1d\u53f6\u65af\u51e0\u4f55"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Do transformers perform genuine Bayesian inference or just pattern matching?<br/>Transformer\u662f\u8fdb\u884c\u771f\u6b63\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u8fd8\u662f\u4ec5\u4ec5\u6a21\u5f0f\u5339\u914d?"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Construct \'Bayesian wind tunnels\' with known posteriors<br/>\u6784\u5efa\u5177\u6709\u5df2\u77e5\u540e\u9a8c\u7684\'\u8d1d\u53f6\u65af\u98ce\u6d1e\'"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Transformers implement Bayesian inference via geometric mechanism; MLPs fail<br/>Transformer\u901a\u8fc7\u51e0\u4f55\u673a\u5236\u5b9e\u73b0\u8d1d\u53f6\u65af\u63a8\u7406\uff1bMLP\u5931\u8d25"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [ai safety & alignment], [manipulation detection, safety benchmark, harm categorization, multi-layer analysis, autonomy harm]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sadia Asif, Israel Antonio Rosales Laguan, Haris Khan, Shumaila Asif, Muneeb Asif"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Rensselaer Polytechnic Institute, National University of Sciences and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22470",children:"https://arxiv.org/pdf/2512.22470"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/sadia-sigma-lab/Benchmark-dataset-for-dark-patterns-in-llms",children:"https://github.com/sadia-sigma-lab/Benchmark-dataset-for-dark-patterns-in-llms"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DarkPatterns-LLM, the first comprehensive benchmark dataset with 401 expert-annotated examples for fine-grained detection of manipulative LLM behaviors across seven harm categories. 2. Proposes a novel four-layer diagnostic framework (MGD, MSIAN, THP, DCRA) for nuanced analysis of manipulative content, moving beyond coarse binary safety labels. 3. Provides an empirical evaluation revealing significant performance disparities (65.2%-89.7%) among state-of-the-art LLMs and identifies consistent weaknesses, particularly in detecting autonomy-undermining patterns."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b68b7543a951540a0b9d1fde4bdde15299ee5f4f63a4526b64cdf4ab7f7a4c28_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b68b7543a951540a0b9d1fde4bdde15299ee5f4f63a4526b64cdf4ab7f7a4c28_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of nuanced benchmarks for detecting manipulative behaviors in Large Language Models (LLMs). It introduces DarkPatterns-LLM, a new dataset and a four-layer analytical framework for fine-grained assessment across multiple harm categories. The evaluation shows current LLMs have significant and varied weaknesses in manipulation detection, establishing a standardized benchmark for developing more trustworthy AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DarkPatterns-LLM: \u68c0\u6d4b\u6709\u5bb3AI\u884c\u4e3a] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e B1[\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u8fc7\u4e8e\u7c97\u7cd9/Existing safety benchmarks are coarse]\n    B --\x3e B2[\u65e0\u6cd5\u6355\u6349\u64cd\u7eb5\u7684\u5fae\u5999\u673a\u5236/Fail to capture nuanced manipulation mechanisms]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e C1[\u65b0\u57fa\u51c6\u6570\u636e\u96c6/New benchmark dataset (401 examples)]\n    C --\x3e C2[\u4e03\u7c7b\u5371\u5bb3\u5206\u7c7b/Seven harm categories]\n    C --\x3e C3[\u56db\u5c42\u5206\u6790\u6846\u67b6/Four-layer analytical pipeline (MGD, MSIAN, THP, DCRA)]\n    D[\u5173\u952e\u7ed3\u679c/Results] --\x3e D1[\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5927/Model performance varies widely (65.2%-89.7%)]\n    D --\x3e D2[\u81ea\u4e3b\u6027\u5371\u5bb3\u68c0\u6d4b\u5f31/Weakness in detecting autonomy harm]\n    D --\x3e D3[\u9996\u4e2a\u6807\u51c6\u5316\u591a\u7ef4\u5ea6\u57fa\u51c6/First standardized multi-dimensional benchmark]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [biomedical signal processing], [self-supervised learning, surface electromyography, rotary position encoding, spectral pre-training, movement decoding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zihan Weng, Chanlin Yi, Pouya Bashivan, Jing Lu, Fali Li, Dezhong Yao, Jingming Hou, Yangsong Zhang, Peng Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Electronic Science and Technology of China"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22481",children:"https://arxiv.org/pdf/2512.22481"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel self-supervised pre-training task that uses masked prediction of clustered STFT pseudo-labels to learn robust, physiologically relevant frequency patterns from sEMG signals. 2. A novel Cylindrical Rotary Position Embedding (CyRoPE) that factorizes embeddings along temporal and annular spatial dimensions to explicitly model the cylindrical topology of forearm electrode arrays. 3. The SPECTRE framework, which integrates these contributions to establish a new state-of-the-art for fine-grained movement decoding, validated on multiple datasets including data from individuals with amputation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from surface electromyography (sEMG) signals. It proposes a spectral pre-training task using masked pseudo-label prediction and a novel cylindrical rotary position encoding to model sensor topology. Evaluations show SPECTRE significantly outperforms existing supervised and generic self-supervised baselines, providing a robust foundation for practical myoelectric interfaces."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Decoding fine-grained movement from noisy, non-stationary sEMG signals for prosthetic control]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Domain-specific SSL with spectral pre-training and Cylindrical Rotary Position Embedding (CyRoPE)]\n    D[\u5173\u952e\u7ed3\u679c/Results: New SOTA performance, outperforms supervised & generic SSL baselines, validated on amputation data]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable AI Tutoring"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [adversarial reasoning, multi-agent system, pedagogical oversight, hierarchical framework, low-compute inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Saisab Sadhu, Ashim Dhor"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Indian Institute of Science Education and Research Bhopal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22496",children:"https://arxiv.org/pdf/2512.22496"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Hierarchical Pedagogical Oversight (HPO), a novel multi-agent adversarial framework designed to improve the reliability of AI tutoring by separating pedagogical generation from evaluation. 2. Adapts structured adversarial synthesis to educational assessment, enforcing a dialectical debate between opposing pedagogical critics to mitigate sycophancy and superficial consensus. 3. Demonstrates that the adversarial protocol enables a small 8B-parameter model to outperform GPT-4o on pedagogical oversight while using significantly fewer computational resources."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67b6c2853ea8b40662f9788f9062b5488d7ec541a754a445a856888b9fb9300c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67b6c2853ea8b40662f9788f9062b5488d7ec541a754a445a856888b9fb9300c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of unreliable AI tutors (LLMs) that often validate incorrect student answers. It proposes the Hierarchical Pedagogical Oversight (HPO) framework, which uses a structured multi-agent adversarial debate to assess tutoring quality. The main conclusion is that this adversarial approach enables a much smaller model to outperform a much larger one (GPT-4o) on a pedagogical reasoning benchmark, establishing it as a critical mechanism for reliable, low-compute oversight."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Hierarchical Pedagogical Oversight<br>\u5206\u5c42\u6559\u5b66\u76d1\u7763\u6846\u67b6] --\x3e B[Problem: LLMs as tutors are unreliable<br>\u95ee\u9898: LLM\u5bfc\u5e08\u4e0d\u53ef\u9760]\n    A --\x3e C[Method: Multi-Agent Adversarial Framework<br>\u65b9\u6cd5: \u591a\u667a\u80fd\u4f53\u5bf9\u6297\u6846\u67b6]\n    A --\x3e D[Results: 8B model beats GPT-4o, low-compute<br>\u7ed3\u679c: 8B\u6a21\u578b\u8d85\u8d8aGPT-4o, \u4f4e\u8ba1\u7b97]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ManchuTTS: Towards High-Quality Manchu Speech Synthesis via Flow Matching and Hierarchical Text Representation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [speech synthesis], [flow matching, hierarchical attention, low-resource TTS, agglutinative language, non-autoregressive generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Suhua Wang, Zifan Wang, Xiaoxin Sun, D. J. Wang, Zhanbo Liu, Xin Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Northeast Normal University, Changchun Humanities and Sciences College, Zhejiang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22491",children:"https://arxiv.org/pdf/2512.22491"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel hierarchical text representation and cross-modal attention mechanism to handle Manchu's agglutinative phonology. 2. Introduces an end-to-end speech synthesis model integrating deep convolutional networks with a flow-matching Transformer for efficient, non-autoregressive generation. 3. Constructs the first public Manchu TTS dataset and employs data augmentation to address severe data scarcity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/118d24570c94614dbb94eaabcc1dc47ba64643f094c4ea3727d4674221bf53fc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/118d24570c94614dbb94eaabcc1dc47ba64643f094c4ea3727d4674221bf53fc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ManchuTTS, a novel text-to-speech system designed for the endangered and agglutinative Manchu language. The method uses a three-tier text representation and a flow-matching Transformer with hierarchical guidance to tackle data scarcity and complex phonology. Experiments show it achieves a high MOS score of 4.52 and significantly improves pronunciation accuracy and prosodic naturalness compared to baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ManchuTTS: \u6ee1\u8bed\u8bed\u97f3\u5408\u6210] --\x3e B1(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e B2(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e B3(\u5173\u952e\u7ed3\u679c/Results)\n    B1 --\x3e C1[\u6570\u636e\u7a00\u7f3a/Data Scarcity]\n    B1 --\x3e C2[\u7c98\u7740\u8bed\u8bed\u97f3\u5b66/Agglutinative Phonology]\n    B2 --\x3e D1[\u4e09\u5c42\u6587\u672c\u8868\u793a/Three-tier Text Representation]\n    B2 --\x3e D2[\u6d41\u5339\u914dTransformer/Flow-matching Transformer]\n    B2 --\x3e D3[\u5206\u5c42\u5bf9\u6bd4\u635f\u5931/Hierarchical Contrastive Loss]\n    B3 --\x3e E1[MOS\u5f97\u52064.52/MOS Score 4.52]\n    B3 --\x3e E2[AWPA\u63d0\u534731%/AWPA +31%]\n    B3 --\x3e E3[\u97f5\u5f8b\u81ea\u7136\u5ea6\u63d0\u534727%/Prosodic Naturalness +27%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Role-Based Fault Tolerance System for LLM RL Post-Training"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [role-based fault tolerance, RL post-training, UCX communication, warm standby, Effective Training Time Ratio (ETTR)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, State Key Laboratory of Mathematical Engineering and Advanced Computing"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22492",children:"https://arxiv.org/pdf/2512.22492"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a role-based fault isolation and recovery system (RobustRL) for RL post-training, enabling recovery of only the failed component (trainer, rollout) instead of restarting the entire task. 2. Introduces a role-aware monitoring mechanism to accurately detect failures and avoid false positives/delays specific to different RL roles. 3. Implements dynamic, UCX-based point-to-point communication to reconnect recovered roles and synchronize weights immediately, replacing static collective communication."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of fault tolerance for RL post-training of LLMs, which interleaves training and inference workloads. It proposes RobustRL, a system that isolates and recovers failed roles (e.g., trainer, rollout) individually using a Detect-Restart-Reconnect paradigm, instead of restarting the entire job. This approach significantly improves the Effective Training Time Ratio and reduces end-to-end training time compared to baseline methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Role-Based Fault Tolerance System for LLM RL Post-Training] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[RL\u540e\u8bad\u7ec3\u6df7\u5408\u8bad\u7ec3\u4e0e\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6613\u53d7\u53cc\u65b9\u6545\u969c\u5f71\u54cd/RL post-training mixes training & inference, vulnerable to faults from both]\n    B --\x3e B2[\u73b0\u6709\u5bb9\u9519\u6846\u67b6\u672a\u9488\u5bf9RL\u7684\u5f02\u6b65\u6267\u884c\u4f18\u5316/Existing FT frameworks not optimized for RL's async execution]\n    C --\x3e C1[\u57fa\u4e8e\u89d2\u8272\u7684\u6545\u969c\u9694\u79bb\u4e0e\u6062\u590d/Role-based fault isolation & recovery]\n    C --\x3e C2[\u68c0\u6d4b-\u91cd\u542f-\u91cd\u8fde\u8303\u5f0f/Detect-Restart-Reconnect paradigm]\n    C2 --\x3e C21[\u89d2\u8272\u611f\u77e5\u76d1\u63a7/Role-aware monitoring]\n    C2 --\x3e C22[\u975e\u4e2d\u65ad\u5f0f\u91cd\u542f/Non-disruptive restart with warm standbys]\n    C2 --\x3e C23[\u52a8\u6001UCX\u70b9\u5bf9\u70b9\u901a\u4fe1\u91cd\u8fde/Dynamic UCX P2P reconnection]\n    D --\x3e D1[ETTR\u8d85\u8fc780%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u768460%/ETTR >80%, better than baseline 60%]\n    D --\x3e D2[\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u52a0\u5feb8.4%-17.4%/End-to-end training time 8.4%-17.4% faster]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Predicting LLM Correctness in Prosthodontics Using Metadata and Hallucination Signals"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection], [correctness prediction, metadata signals, prompting strategies, log probability, response consistency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Lucky Susanto, Anasta Pranawijayana, Cortino Sukotjo, Soni Prasad, Derry Wijaya"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Monash University Indonesia, University of Pittsburgh, University of North Carolina Adams School of Dentistry, Boston University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22508",children:"https://arxiv.org/pdf/2512.22508"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel method to predict LLM correctness (not just hallucination) using metadata and hallucination signals in a high-stakes medical domain (prosthodontics). 2. Demonstrates that metadata-based predictors can improve accuracy over a naive baseline and achieve high precision, but are not reliable for directly predicting hallucination. 3. Shows that prompting strategies significantly alter model internal behavior and the predictive utility of metadata, despite not changing overall task accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbe159260b97cf5e7a59edbee0a23b697a76a89a0fdbf6e0c9797739cc322b42_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbe159260b97cf5e7a59edbee0a23b697a76a89a0fdbf6e0c9797739cc322b42_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study investigates predicting the correctness of LLM answers on a prosthodontics exam using metadata (like log probability and consistency) and hallucination signals. The method, applied to GPT-4o and OSS-120B across different prompts, shows improved accuracy over a baseline but is not yet robust for high-stakes deployment. The research highlights that prompting strategies change model behavior and metadata utility, offering a direction for reliability signals."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Predicting LLM Correctness in Prosthodontics<br/>\u9884\u6d4bLLM\u5728\u53e3\u8154\u4fee\u590d\u5b66\u4e2d\u7684\u6b63\u786e\u6027] --\x3e B(Problem/\u6838\u5fc3\u95ee\u9898: LLM hallucinations in high-stakes healthcare domains<br/>\u9ad8\u98ce\u9669\u533b\u7597\u9886\u57df\u4e2d\u7684LLM\u5e7b\u89c9\u95ee\u9898)\n    A --\x3e C(Method/\u4e3b\u8981\u65b9\u6cd5: Use metadata & hallucination signals to build correctness predictors<br/>\u4f7f\u7528\u5143\u6570\u636e\u548c\u5e7b\u89c9\u4fe1\u53f7\u6784\u5efa\u6b63\u786e\u6027\u9884\u6d4b\u5668)\n    A --\x3e D(Results/\u5173\u952e\u7ed3\u679c: Improved accuracy & precision; metadata not reliable for hallucination prediction; prompting alters behavior<br/>\u63d0\u5347\u51c6\u786e\u7387\u548c\u7cbe\u786e\u5ea6\uff1b\u5143\u6570\u636e\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u5e7b\u89c9\uff1b\u63d0\u793a\u7b56\u7565\u6539\u53d8\u6a21\u578b\u884c\u4e3a)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [adversarial robustness], [Spiking Neural Networks, surrogate gradient, adversarial attack, gradient vanishing, adaptive optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jihang Wang, Dongcheng Zhao, Ruolin Chen, Qian Zhang, Yi Zeng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Beijing Institute of AI Safety and Governance"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22522",children:"https://arxiv.org/pdf/2512.22522"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Theoretical analysis of gradient vanishing in surrogate gradient methods for SNNs. 2. Proposal of Adaptive Sharpness Surrogate Gradient (ASSG) to adaptively adjust the surrogate function for more accurate gradients. 3. Design of Stable Adaptive Projected Gradient Descent (SA-PGD), an adversarial attack with adaptive step size for stable convergence under imprecise gradients."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7b10ed2a96f6e46c5c2afb21a8e1184dd9c5e1f342efdb93f3cd317a08c20ea_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7b10ed2a96f6e46c5c2afb21a8e1184dd9c5e1f342efdb93f3cd317a08c20ea_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the unreliable evaluation of adversarial robustness in Spiking Neural Networks (SNNs) caused by gradient vanishing from surrogate gradients. The authors propose a framework combining an adaptive surrogate gradient method (ASSG) and an adaptive-step attack (SA-PGD) to generate stronger attacks. Experiments show this framework significantly increases attack success rates, revealing that current SNN robustness is overestimated and highlighting the need for more reliable adversarial training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u68af\u5ea6\u6d88\u5931/Gradient Vanishing")\n    Problem --\x3e P2("\u5bf9\u6297\u8bc4\u4f30\u4e0d\u53ef\u9760/Unreliable Adversarial Evaluation")\n    Method --\x3e M1("\u7406\u8bba\u5206\u6790\u68af\u5ea6\u6d88\u5931/Theoretical Analysis of Gradient Vanishing")\n    Method --\x3e M2("\u81ea\u9002\u5e94\u9510\u5ea6\u66ff\u4ee3\u68af\u5ea6/Adaptive Sharpness Surrogate Gradient (ASSG)")\n    Method --\x3e M3("\u7a33\u5b9a\u81ea\u9002\u5e94\u6295\u5f71\u68af\u5ea6\u4e0b\u964d/Stable Adaptive PGD (SA-PGD)")\n    Results --\x3e R1("\u653b\u51fb\u6210\u529f\u7387\u5927\u5e45\u63d0\u5347/Substantially Increased Attack Success Rate")\n    Results --\x3e R2("\u63ed\u793a\u9c81\u68d2\u6027\u88ab\u9ad8\u4f30/Revealed Overestimated Robustness")\n    Results --\x3e R3("\u63d0\u4f9b\u66f4\u53ef\u9760\u8bc4\u4f30/Provided More Reliable Evaluation")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:'[arXiv251230] Multi-AI Agent Framework Reveals the "Oxide Gatekeeper" in Aluminum Nanoparticle Oxidation'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-AI agent, machine learning potential, human-in-the-loop, self-auditing, scalable molecular dynamics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yiming Lu, Tingyu Lu, Di Zhang, Lili Ye, Hao Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tohoku University, Dalian University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22529",children:"https://arxiv.org/pdf/2512.22529"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Developed a novel "human-in-the-loop" closed-loop framework utilizing self-auditing AI agents to validate and evolve a machine learning potential, ensuring quantum accuracy while achieving near-linear scalability to million-atom systems and nanosecond timescales. 2. Discovered a temperature-regulated dual-mode oxidation mechanism for aluminum nanoparticles, where the oxide shell acts as a dynamic "gatekeeper" via a "breathing mode" at moderate temperatures and transitions to a catastrophic "rupture mode" above a critical threshold. 3. Resolved a long-standing controversy by demonstrating that aluminum cation outward diffusion, not oxygen transport, is the dominant mass transfer mechanism across all temperature regimes, with diffusion coefficients 2-3 orders of magnitude higher.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42c9680d91fb0cb7f7611fd33feaef10bdab707dc569594f3d51f8af4d9e0651_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42c9680d91fb0cb7f7611fd33feaef10bdab707dc569594f3d51f8af4d9e0651_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a human-in-the-loop multi-AI agent framework to develop and validate a highly accurate and scalable machine learning potential for molecular dynamics simulations. Using this method, the study reveals a dual-mode oxidation mechanism in aluminum nanoparticles and conclusively shows that aluminum cation diffusion, not oxygen transport, dominates the oxidation process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[Multi-AI Agent Framework Reveals the "Oxide Gatekeeper" in Aluminum Nanoparticle Oxidation] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem]\n    B --\x3e B1[\u539f\u5b50\u5c3a\u5ea6\u6c27\u5316\u673a\u5236\u672a\u77e5/Atomic-scale oxidation mechanism unknown]\n    B --\x3e B2[\u8ba1\u7b97\u74f6\u9888:\u7cbe\u5ea6\u4e0e\u89c4\u6a21\u96be\u4ee5\u517c\u5f97/Computational bottleneck: trade-off between accuracy and scale]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    C --\x3e C1[\u4eba\u673a\u534f\u540c\u95ed\u73af\u6846\u67b6/Human-in-the-loop closed-loop framework]\n    C --\x3e C2[\u81ea\u5ba1AI\u4ee3\u7406\u9a8c\u8bc1MLP\u6f14\u5316/Self-auditing AI Agents validate MLP evolution]\n    D[\u5173\u952e\u7ed3\u679c/Results]\n    D --\x3e D1[\u53d1\u73b0\u53cc\u6a21\u5f0f\u6c27\u5316\u673a\u5236/Discovered dual-mode oxidation mechanism]\n    D --\x3e D2[\u63ed\u793a\u94dd\u79bb\u5b50\u6269\u6563\u4e3b\u5bfc/Revealed Al cation diffusion dominates]\n    D --\x3e D3[\u5efa\u7acb\u7edf\u4e00\u539f\u5b50\u5c3a\u5ea6\u8bbe\u8ba1\u6846\u67b6/Established unified atomic-scale design framework]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] CoAgent: Collaborative Planning and Consistency Agent for Coherent Video Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video generation], [closed-loop framework, entity-level memory, vision-language verification, pacing-aware editing, multi-agent collaboration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qinglin Zeng, Kaitong Cai, Ruiqi Chen, Qinhan Lv, Keze Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sun Yat-sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22536",children:"https://arxiv.org/pdf/2512.22536"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CoAgent, a collaborative closed-loop framework that formulates video generation as a plan-synthesize-verify-edit process. 2. Introduces a Global Context Manager to maintain entity-level memory for cross-shot identity and appearance consistency. 3. Employs a Verifier Agent with vision-language reasoning to evaluate intermediate results and trigger selective regeneration for quality control."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfaf9ffbd76c531ee1d089b472175957646bd5b08a39cad1cce07b642bd237a4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfaf9ffbd76c531ee1d089b472175957646bd5b08a39cad1cce07b642bd237a4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of maintaining narrative coherence and visual consistency in long-form video generation. It proposes CoAgent, a collaborative multi-agent framework that uses a closed-loop plan-synthesize-verify-edit pipeline with entity memory and consistency verification. Experiments show that CoAgent significantly improves coherence, consistency, and narrative quality in generated videos."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CoAgent: Coherent Video Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Open-domain video generation lacks coherence and consistency/\u5f00\u653e\u57df\u89c6\u9891\u751f\u6210\u7f3a\u4e4f\u8fde\u8d2f\u6027\u548c\u4e00\u81f4\u6027]\n    C --\x3e C1[Plan-Synthesize-Verify-Edit Pipeline/\u8ba1\u5212-\u5408\u6210-\u9a8c\u8bc1-\u7f16\u8f91\u6d41\u7a0b]\n    C1 --\x3e C2[Storyboard Planner/\u6545\u4e8b\u677f\u89c4\u5212\u5668]\n    C1 --\x3e C3[Global Context Manager/\u5168\u5c40\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668]\n    C1 --\x3e C4[Verifier Agent/\u9a8c\u8bc1\u667a\u80fd\u4f53]\n    C1 --\x3e C5[Pacing-aware Editor/\u8282\u594f\u611f\u77e5\u7f16\u8f91\u5668]\n    D --\x3e D1[Improves coherence, consistency, narrative quality/\u63d0\u5347\u8fde\u8d2f\u6027\u3001\u4e00\u81f4\u6027\u3001\u53d9\u4e8b\u8d28\u91cf]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Self-Rewarded Multimodal Coherent Reasoning Across Diverse Visual Domains"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal reasoning], [self-rewarded learning, process alignment, multimodal large language models, reasoning coherence, visual grounding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jesen Zhang, Ningyuan Liu, Kaitong Cai, Sidi Liu, Jing Yang, Ziliang Chen, Xiaofei Sun, Keze Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sun Yat-sen University, Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22545",children:"https://arxiv.org/pdf/2512.22545"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A lightweight, label-free framework (SR-MCR) that aligns multimodal reasoning by constructing a self-reward from intrinsic process signals (semantic alignment, lexical fidelity, non-redundancy, visual grounding, step consistency). 2. A normalized, reliability-weighted reward mechanism that adaptively combines multiple self-referential cues to provide fine-grained, process-level guidance. 3. A critic-free GRPO objective enhanced with a confidence-aware cooling mechanism to stabilize training and suppress trivial or overconfident generations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/629536dd38b71477a18bd2e7208023831047c11b4eafeff5c5c094c124751f98_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/629536dd38b71477a18bd2e7208023831047c11b4eafeff5c5c094c124751f98_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of multimodal LLMs producing fluent but unreliable reasoning with poor step coherence and visual grounding. It proposes SR-MCR, a self-rewarded framework that uses multiple intrinsic process signals from model outputs to create a fine-grained reward for alignment, achieving state-of-the-art accuracy and improved reasoning coherence on visual benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Self-Rewarded Multimodal Coherent Reasoning<br>\u81ea\u6211\u5956\u52b1\u591a\u6a21\u6001\u8fde\u8d2f\u63a8\u7406] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>Fluent but unreliable reasoning,<br>weak coherence & grounding] --\x3e P1[\u73b0\u6709\u65b9\u6cd5\u7f3a\u9677/Existing Method Flaws<br>Supervises only final answer]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>SR-MCR Framework] --\x3e M1[\u81ea\u6211\u5956\u52b1/Self-Reward<br>Five intrinsic process cues]\n    Method --\x3e M2[\u4f18\u5316\u76ee\u6807/Optimization<br>GRPO with cooling mechanism]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>Evaluation & Ablation] --\x3e R1[\u6027\u80fd\u63d0\u5347/Performance Gain<br>SOTA accuracy (81.4%)]\n    Results --\x3e R2[\u6d88\u878d\u7814\u7a76/Ablation Study<br>Confirms contributions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] TimePerceiver: An Encoder-Decoder Framework for Generalized Time-Series Forecasting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [time-series forecasting], [encoder-decoder, latent bottleneck representations, learnable queries, generalized forecasting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jaebin Lee, Hankook Lee"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sungkyunkwan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22550",children:"https://arxiv.org/pdf/2512.22550"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/efficient-learning-lab/TimePerceiver",children:"https://github.com/efficient-learning-lab/TimePerceiver"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Generalizes the time-series forecasting task to include diverse objectives like extrapolation, interpolation, and imputation. 2. Proposes a novel encoder-decoder architecture with latent bottleneck representations to capture temporal and cross-channel dependencies. 3. Introduces learnable queries for decoding to effectively retrieve information for arbitrarily positioned target timestamps."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/091fdcd1058e0acfad18820d025c1fe50ff4315cbd5ec8a06f5d86eb9767513c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/091fdcd1058e0acfad18820d025c1fe50ff4315cbd5ec8a06f5d86eb9767513c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TimePerceiver, a unified encoder-decoder framework for generalized time-series forecasting. It handles diverse prediction objectives by using latent bottleneck encodings and learnable query-based decoding. Extensive experiments show it consistently outperforms prior state-of-the-art methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[TIMEPERCEIVER] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u4fa7\u91cd\u7f16\u7801\u5668\uff0c\u9884\u6d4b\u4e0e\u8bad\u7ec3\u5206\u79bb/Prior work focuses on encoder, treats prediction & training separately]\n    C --\x3e C1[\u5e7f\u4e49\u9884\u6d4b\u4efb\u52a1: \u5916\u63a8\u3001\u63d2\u503c\u3001\u586b\u8865/Generalized forecasting: extrapolation, interpolation, imputation]\n    C --\x3e C2[\u7f16\u7801: \u6f5c\u5728\u74f6\u9888\u8868\u793a/Encoding: Latent bottleneck representations]\n    C --\x3e C3[\u89e3\u7801: \u53ef\u5b66\u4e60\u67e5\u8be2/Decoding: Learnable queries]\n    D --\x3e D1[\u6027\u80fd\u663e\u8457\u8d85\u8d8aSOTA/Outperforms SOTAs significantly]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Learning When Not to Attend Globally"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [All-or-Here Attention, sliding window attention, conditional computation, binary router, context dependency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xuan Luo, Kailai Zhang, Xifeng Yan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," UC Santa Barbara"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22562",children:"https://arxiv.org/pdf/2512.22562"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes All-or-Here Attention (AHA), a novel attention mechanism that dynamically toggles between full and local sliding window attention using a binary router per head. 2. Demonstrates empirically that full attention is largely redundant, showing up to 93% of full attention operations can be replaced with local attention without performance loss. 3. Identifies a long-tail distribution in context dependency, revealing that the need for global context decays rapidly as the local window expands."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edc0024b0088e710cd3ce9c0be8276b43396c11c0424f0f6340e0f97d63982e6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edc0024b0088e710cd3ce9c0be8276b43396c11c0424f0f6340e0f97d63982e6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the computational inefficiency of full self-attention in LLMs by proposing All-or-Here Attention (AHA), which learns to dynamically switch between full and local sliding window attention for each token. The results show that most full attention operations are unnecessary, and efficient inference can be achieved with on-demand global context access."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Learning When Not to Attend Globally] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Quadratic complexity of full self-attention is inefficient]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: All-or-Here Attention (AHA) with binary router to toggle between full and local sliding window attention]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Up to 93% full attention replaced without loss; reveals long-tail context dependency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [disaggregated infrastructure, hardware-affinity mapping, fine-grained asynchrony]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," HKUST, Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22560",children:"https://arxiv.org/pdf/2512.22560"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/alibaba/ROLL",children:"https://github.com/alibaba/ROLL"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A hardware-affinity workload mapping strategy that routes compute-bound and bandwidth-bound tasks to best-fit GPU devices. 2. A fine-grained asynchrony mechanism that manages execution at the trajectory level to mitigate resource bubbles and improve utilization. 3. A statefulness-aware computation design that offloads stateless components to serverless infrastructure for elastic scaling."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents RollArt, a distributed system designed to scale agentic reinforcement learning training on disaggregated infrastructure. It addresses the heterogeneity of agentic RL workloads by proposing three core techniques: hardware-affinity workload mapping, fine-grained asynchrony, and statefulness-aware computation. The system demonstrates significant improvements in training throughput, achieving 1.35-2.05x speedup over baselines, and scales to thousands of GPUs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Agentic RL workloads are heterogeneous, causing inefficiency in monolithic infrastructure."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Disaggregated system with hardware-affinity mapping, fine-grained asynchrony, and statefulness-aware computation."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Achieves 1.35-2.05x training speedup and scales to >3000 GPUs."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Lessons from Neuroscience for AI: How integrating Actions, Compositional Structure and Episodic Memory could enable Safe, Interpretable and Human-Like AI"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [cognitive architectures], [predictive coding, compositional structure, episodic memory, action integration, foundation models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rajesh P. N. Rao, Vishwas Sathish, Linxing Preston Jiang, Matthew Bryan, Prashant Rangarajan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Washington"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22568",children:"https://arxiv.org/pdf/2512.22568"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes integrating actions, compositional structure, and episodic memory into foundation models to address their deficiencies. 2. Presents neuroscience evidence to support the importance of these components for achieving human-like AI. 3. Compares the proposal to current trends like chain-of-thought reasoning and retrieval-augmented generation, suggesting new brain-inspired augmentation methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c90f622f122bb0e11d5909a8de5e173e03638e3854680c6b2a0139a74ea9314_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c90f622f122bb0e11d5909a8de5e173e03638e3854680c6b2a0139a74ea9314_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper argues that current foundation models, despite their success, lack key components of brain-inspired predictive coding models: action integration, compositional structure, and episodic memory. It proposes integrating these components to address issues like hallucinations, lack of grounding, and poor interpretability, aiming for safer and more human-like AI. The conclusion advocates for renewed collaboration between neuroscience and AI to achieve these goals."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Lessons from Neuroscience for AI / \u795e\u7ecf\u79d1\u5b66\u5bf9AI\u7684\u542f\u793a"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem"] --\x3e P1["Current AI lacks key brain features / \u5f53\u524dAI\u7f3a\u4e4f\u5173\u952e\u5927\u8111\u7279\u5f81"]\n    Problem --\x3e P2["Deficiencies: hallucinations, no grounding / \u7f3a\u9677\uff1a\u5e7b\u89c9\uff0c\u7f3a\u4e4f\u6839\u57fa"]\n\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method"] --\x3e M1["Integrate brain components / \u6574\u5408\u5927\u8111\u7ec4\u4ef6"]\n    M1 --\x3e M1_1["Actions / \u884c\u52a8"]\n    M1 --\x3e M1_2["Compositional Structure / \u7ec4\u5408\u7ed3\u6784"]\n    M1 --\x3e M1_3["Episodic Memory / \u60c5\u666f\u8bb0\u5fc6"]\n\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e R1["Address AI deficiencies / \u89e3\u51b3AI\u7f3a\u9677"]\n    Results --\x3e R2["Enable safe, interpretable AI / \u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u7684AI"]\n    Results --\x3e R3["Path to human-like AI / \u901a\u5411\u7c7b\u4ebaAI\u4e4b\u8def"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SANet: A Semantic-aware Agentic AI Networking Framework for Cross-layer Optimization in 6G"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Agentic AI Networking, Multi-agent Multi-objective Optimization, Model Partition and Sharing (MoPS), Cross-layer Optimization, Pareto-optimal Solution]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yong Xiao, Xubo Li, Haoran Zhou, Yingyu Li, Yayu Gao, Guangming Shi, Ping Zhang, Marwan Krunz"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huazhong University of Science and Technology, Peng Cheng Laboratory, Pazhou Laboratory (Huangpu), China University of Geosciences (Wuhan), Xidian University, Beijing University of Posts and Telecommunications, University of Arizona"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22579",children:"https://arxiv.org/pdf/2512.22579"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SANet, a semantic-aware Agentic AI Networking architecture that infers user semantic goals and automatically assigns cross-layer agents to fulfill them. 2. Formulates the decentralized optimization as a multi-agent multi-objective problem, proposes three novel evaluation metrics, and develops a Model Partition and Sharing (MoPS) framework for efficient model deployment. 3. Derives theoretical bounds proving a three-way tradeoff among optimization, generalization, and conflicting errors, and validates the framework with a hardware prototype showing significant performance gains and computational efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eee5846572238b17d03d837b7c31a7bd60644abe5d9070207f45cd166b326470_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eee5846572238b17d03d837b7c31a7bd60644abe5d9070207f45cd166b326470_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes SANet, a semantic-aware Agentic AI networking framework for 6G that uses AI agents to infer user goals and perform cross-layer optimization. It formulates the problem as multi-agent multi-objective optimization, introduces a model partition and sharing method, and proves a theoretical tradeoff. Experiments on a hardware prototype show the framework achieves up to 14.61% performance gain while requiring only 44.37% of the FLOPs of state-of-the-art methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[SANet: A Semantic-aware Agentic AI Networking Framework] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u7f3a\u4e4f\u652f\u6301\u81ea\u52a8\u76ee\u6807\u53d1\u73b0\u4e0e\u591a\u667a\u80fd\u4f53\u7f16\u6392\u7684\u6846\u67b6 / Lack of framework for automatic goal discovery and multi-agent orchestration]\n    Problem --\x3e P2[\u534f\u4f5c\u667a\u80fd\u4f53\u53ef\u80fd\u5b58\u5728\u76ee\u6807\u51b2\u7a81 / Collaborating agents may have conflicting objectives]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u8bed\u4e49\u611f\u77e5\u67b6\u6784\u63a8\u65ad\u7528\u6237\u76ee\u6807\u5e76\u5206\u914d\u667a\u80fd\u4f53 / Semantic-aware architecture infers user goal and assigns agents]\n    Method --\x3e M2[\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u591a\u667a\u80fd\u4f53\u591a\u76ee\u6807\u4f18\u5316 / Formulates as multi-agent multi-objective problem]\n    Method --\x3e M3[\u63d0\u51fa\u6a21\u578b\u5206\u533a\u4e0e\u5171\u4eab\u6846\u67b6 / Proposes Model Partition and Sharing (MoPS) framework]\n    Method --\x3e M4[\u63d0\u51fa\u4e24\u79cd\u5206\u5e03\u5f0f\u4f18\u5316\u7b97\u6cd5 / Proposes two decentralized optimization algorithms]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7406\u8bba\u8bc1\u660e\u4e09\u65b9\u9762\u8bef\u5dee\u7684\u6743\u8861 / Theoretical proof of three-way error tradeoff]\n    Results --\x3e R2[\u786c\u4ef6\u539f\u578b\u9a8c\u8bc1\u6027\u80fd\u63d0\u5347\u4e0e\u8ba1\u7b97\u6548\u7387 / Hardware prototype validates performance gain and computational efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Tyee: A Unified, Modular, and Fully-Integrated Configurable Toolkit for Intelligent Physiological Health Care"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [physiological signal analysis, unified data interface, modular architecture, end-to-end workflow, configurable toolkit]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tao Zhou, Lingyu Shu, Zixing Zhang, Jing Han"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hunan University, University of Cambridge"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22601",children:"https://arxiv.org/pdf/2512.22601"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/SmileHnu/Tyee",children:"https://github.com/SmileHnu/Tyee"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A unified data interface and configurable preprocessing pipeline for 12 physiological signal modalities. 2. A modular and extensible architecture enabling flexible integration and rapid prototyping. 3. An end-to-end workflow configuration system promoting reproducible and scalable experimentation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c4a4d498d8e9b9f7b3a7f4413e2399342920644addd35cc3e7401a5ebadf033_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c4a4d498d8e9b9f7b3a7f4413e2399342920644addd35cc3e7401a5ebadf033_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Tyee, a configurable deep learning toolkit designed to address challenges in physiological signal analysis, such as heterogeneous data and fragmented pipelines. Its unified, modular design allows for flexible and reproducible experimentation. The toolkit demonstrates strong performance, achieving state-of-the-art results on 12 out of 13 evaluated datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Tyee: A Unified Toolkit for Intelligent Physiological Health Care] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u5f02\u6784\u6570\u636e\u683c\u5f0f/Heterogeneous Data Formats]\n    Problem --\x3e P2[\u4e0d\u4e00\u81f4\u7684\u9884\u5904\u7406/Inconsistent Preprocessing]\n    Problem --\x3e P3[\u788e\u7247\u5316\u6a21\u578b\u7ba1\u9053/Fragmented Model Pipelines]\n    Problem --\x3e P4[\u4e0d\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c/Non-reproducible Experiments]\n    Method --\x3e M1[\u7edf\u4e00\u6570\u636e\u63a5\u53e3/Unified Data Interface]\n    Method --\x3e M2[\u6a21\u5757\u5316\u67b6\u6784/Modular Architecture]\n    Method --\x3e M3[\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u914d\u7f6e/End-to-end Workflow Configuration]\n    Results --\x3e R1[\u6027\u80fd\u4f18\u5f02/Outperforms Baselines]\n    Results --\x3e R2[12/13\u6570\u636e\u96c6SOTA/State-of-the-art on 12 of 13 Datasets]\n    Results --\x3e R3[\u5f00\u6e90\u5de5\u5177\u5305/Open-source Toolkit]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Learning Multi-Modal Mobility Dynamics for Generalized Next Location Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [location-based recommendation], [multi-modal learning, spatial-temporal knowledge graph, cross-modal alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junshu Dai, Yu Wang, Tongya Zheng, Wei Ji, Qinghong Guo, Ji Cao, Jie Song, Canghong Jin, Mingli Song"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Hangzhou City University, Nanjing University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22605",children:"https://arxiv.org/pdf/2512.22605"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://anonymous.4open.science/r/M3ob-62EF",children:"https://anonymous.4open.science/r/M3ob-62EF"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a unified spatial-temporal relational graph (STRG) for multi-modal representation, enhanced by LLMs. 2. Designs a gating mechanism to fuse spatial-temporal graph representations from different modalities. 3. Introduces an STKG-guided cross-modal alignment method to inject dynamic knowledge into static image representations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de0c70167dfab9ddb767e6d0d1161ce4f31f482e064a77521ffa2e25c598f1d2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de0c70167dfab9ddb767e6d0d1161ce4f31f482e064a77521ffa2e25c598f1d2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limited generalization of next location recommendation methods by proposing M\xb3ob, a framework that leverages multi-modal spatial-temporal knowledge. It constructs a unified graph representation and uses a gating mechanism with cross-modal alignment to capture mobility dynamics. Experiments on six datasets show the method improves performance in both normal and abnormal scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\nA["Learning Multi-Modal Mobility Dynamics for Generalized Next Location Recommendation"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: Existing methods have limited generalization; unimodal suffers from sparsity, multi-modal struggles with semantic gap."]\nA --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: Constructs LLM-enhanced spatial-temporal knowledge graph (STKG) and unified STRG; uses gating fusion and STKG-guided cross-modal alignment."]\nA --\x3e D["\u5173\u952e\u7ed3\u679c/Results: Achieves consistent improvements on six datasets and shows strong generalization in abnormal scenarios."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent system, graph neural network, collective decision-making, startup success prediction, role-playing agents]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhongyang Liu, Haoyu Pei, Xiangyi Xiao, Xiaocong Du, Yihui Li, Suting Hong, Kunpeng Zhang, Haipeng Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ShanghaiTech University, Xi\u2019an Jiaotong-Liverpool University, University of Maryland"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22608",children:"https://arxiv.org/pdf/2512.22608"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SimVC-CAS, a novel collective agent system that reformulates startup financing prediction as a multi-agent group decision-making task, moving beyond single decision-maker models. 2. Introduces role-playing agents with unique traits and a GNN-based supervised interaction module to capture heterogeneous investor evaluations and behavioral dynamics within a co-investment network. 3. Demonstrates significant predictive performance improvement (e.g., ~25% relative improvement in average precision@10) on real-world PitchBook data with strict leakage controls, while providing interpretable, multi-perspective reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5560279fcb9dca880844ffe21da36f9901c81ce8898e265fff9cc80a5e7cfb8a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5560279fcb9dca880844ffe21da36f9901c81ce8898e265fff9cc80a5e7cfb8a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of predicting startup success by simulating venture capital decision-making as a collective process. It proposes SimVC-CAS, a multi-agent system where role-playing LLM agents interact via a GNN module to model investor networks. The method significantly outperforms previous approaches in predicting financing outcomes and offers interpretable reasoning from multiple investor perspectives."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM Agents as VC investors: Predicting Startup Success via RolePlay-Based Collective Simulation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f/Predicting Startup Success]\n    B --\x3e B2[\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u6295\u8d44\u8005\u7fa4\u4f53\u52a8\u6001/Existing methods overlook investor group dynamics]\n    C --\x3e C1[\u63d0\u51faSimVC-CAS\u96c6\u4f53\u4ee3\u7406\u7cfb\u7edf/Propose SimVC-CAS collective agent system]\n    C --\x3e C2[\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u4e0eGNN\u4ea4\u4e92\u6a21\u5757/Role-playing agents & GNN-based interaction module]\n    D --\x3e D1[\u9884\u6d4b\u51c6\u786e\u6027\u663e\u8457\u63d0\u5347/Significantly improved predictive accuracy]\n    D --\x3e D2[\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u591a\u89c6\u89d2\u63a8\u7406/Provides interpretable, multi-perspective reasoning]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Chord Recognition with Deep Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [music information retrieval], [chord recognition, deep learning, generative models, pitch augmentation, beat detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pierre Mackenzie"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Edinburgh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22621",children:"https://arxiv.org/pdf/2512.22621"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and analyzes the poor performance of chord classifiers on rare chords, providing a key insight into a major limitation of current methods. 2. Demonstrates that pitch augmentation is an effective technique for boosting chord recognition accuracy. 3. Improves model interpretability by integrating beat detection into the model's output, leading to some of the best reported results in the field."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53155c1b8ae949083d40642ac5cf37ed34863c9840190ad8076fa052bb0f3185_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53155c1b8ae949083d40642ac5cf37ed34863c9840190ad8076fa052bb0f3185_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This thesis investigates the slow progress in automatic chord recognition despite the use of deep learning. It experiments with existing methods and generative models, finding that pitch augmentation improves accuracy while generative features do not help. The work concludes by enhancing model interpretability with beat detection, achieving state-of-the-art results and suggesting synthetic data as a promising future direction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root(Chord Recognition with Deep Learning) --\x3e Problem(\u6838\u5fc3\u95ee\u9898/Problem)\n    Root --\x3e Method(\u4e3b\u8981\u65b9\u6cd5/Method)\n    Root --\x3e Results(\u5173\u952e\u7ed3\u679c/Results)\n    Problem --\x3e P1(\u8fdb\u5c55\u7f13\u6162/Slow Progress)\n    Method --\x3e M1(\u5b9e\u9a8c\u73b0\u6709\u65b9\u6cd5/Experiment with Existing Methods)\n    Method --\x3e M2(\u6d4b\u8bd5\u751f\u6210\u6a21\u578b\u5047\u8bbe/Test Generative Model Hypotheses)\n    Results --\x3e R1(\u7f55\u89c1\u548c\u5f26\u8868\u73b0\u5dee/Poor Performance on Rare Chords)\n    Results --\x3e R2(\u97f3\u9ad8\u589e\u5f3a\u63d0\u5347\u51c6\u786e\u7387/Pitch Augmentation Boosts Accuracy)\n    Results --\x3e R3(\u8282\u62cd\u68c0\u6d4b\u63d0\u5347\u53ef\u89e3\u91ca\u6027/Beat Detection Improves Interpretability)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [forecasting], [large language models, deliberation, multi-agent, forecasting accuracy, log loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Paul Schneider, Amalie Schramm"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," PRIORB"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22625",children:"https://arxiv.org/pdf/2512.22625"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces and tests a structured deliberation intervention for LLMs, where models review each other's forecasts before updating, as a novel method for improving AI-based forecasting. 2. Systematically evaluates the intervention across four distinct scenarios (diverse/homogeneous models with distributed/shared information), identifying that accuracy improvement is specific to diverse models with shared information. 3. Provides empirical evidence that deliberation can be a viable strategy for improving LLM forecasting, while also revealing the unexpected finding that providing additional contextual information did not improve accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0685f113c8c22bd110f615c357b7de1633adf1104f67be97e690bae6bee70345_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0685f113c8c22bd110f615c357b7de1633adf1104f67be97e690bae6bee70345_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study investigates whether allowing large language models (LLMs) to deliberate by reviewing each other's forecasts improves their forecasting accuracy. The method was tested on 202 binary questions across different model group compositions and information-sharing scenarios. The main conclusion is that deliberation significantly improves accuracy for diverse LLM groups with shared information, but not for homogeneous groups, suggesting it as a viable strategy for enhancing LLM-based forecasting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Does structured deliberation improve LLM forecasting accuracy?"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>LLMs review each other\'s forecasts before updating across four scenarios."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Accuracy improved for diverse models with shared info; no benefit for homogeneous groups."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DICE: Discrete Interpretable Comparative Evaluation with Probabilistic Scoring for Retrieval-Augmented Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [probabilistic scoring, Swiss-system tournament, explainable evaluation, evidence-coupled framework, ranking fidelity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shiyan Liu, Jian Ma, Rui Qu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huazhong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22629",children:"https://arxiv.org/pdf/2512.22629"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DICE, a two-stage, evidence-coupled framework for explainable and robust RAG evaluation using probabilistic {A, B, Tie} scoring. 2. Employs a Swiss-system tournament to reduce computational complexity from O(N\xb2) to O(N log N) for efficient multi-system comparisons. 3. Demonstrates high agreement (85.7%) with human experts on a Chinese financial QA dataset, outperforming existing LLM-based metrics like RAGAS."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6045a90fb152ced5737d976a17be84cd02b0a0396b4dd9cb385e9ba4d9063de6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6045a90fb152ced5737d976a17be84cd02b0a0396b4dd9cb385e9ba4d9063de6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of interpretability and efficiency in evaluating Retrieval-Augmented Generation (RAG) systems. It proposes DICE, a framework that uses probabilistic scoring and a Swiss-system tournament to provide transparent, confidence-aware judgments while reducing computational cost. The method shows strong agreement with human experts, establishing it as an explainable and efficient paradigm for trustworthy RAG assessment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[DICE: Discrete Interpretable Comparative Evaluation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709\u6307\u6807\u95ee\u9898/Existing Metrics Issues]\n    P1 --\x3e P1_1[\u53ef\u89e3\u91ca\u6027\u6709\u9650/Limited Interpretability]\n    P1 --\x3e P1_2[\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0d\u8db3/Inadequate Uncertainty Quantification]\n    P1 --\x3e P1_3[\u8ba1\u7b97\u6548\u7387\u4f4e/Computational Inefficiency]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u4e24\u9636\u6bb5\u8bc1\u636e\u8026\u5408\u6846\u67b6/Two-Stage Evidence-Coupled Framework]\n    M1 --\x3e M1_1[\u6982\u7387{A,B,Tie}\u8bc4\u5206/Probabilistic Scoring]\n    M1 --\x3e M1_2[\u53ef\u89e3\u91ca\u63a8\u7406\u75d5\u8ff9/Interpretable Reasoning Traces]\n    Method --\x3e M2[\u745e\u58eb\u5236\u9526\u6807\u8d5b/Swiss-System Tournament]\n    M2 --\x3e M2_1[\u964d\u4f4e\u590d\u6742\u5ea6/Reduces O(N\xb2) to O(N log N)]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6548\u7387\u63d0\u5347/Efficiency Gain]\n    R1 --\x3e R1_1[\u8ba1\u7b97\u91cf\u51cf\u5c1142.9%/42.9% Reduction]\n    Results --\x3e R2[\u8bc4\u4f30\u6709\u6548\u6027/Evaluation Validity]\n    R2 --\x3e R2_1[\u4e0e\u4e13\u5bb685.7%\u4e00\u81f4/85.7% Human Agreement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Scaling Unverifiable Rewards: A Case Study on Visual Insights"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Test-Time Scaling, multi-agent pipeline, process-based refinement, LLM-as-Judge, unverifiable rewards]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shuyu Gan, James Mooney, Pan Hao, Renxiang Wang, Mingyi Hong, Qianwen Wang, Dongyeop Kang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Minnesota"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22650",children:"https://arxiv.org/pdf/2512.22650"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://minnesotanlp.github.io/insight-scaling-webpage",children:"https://minnesotanlp.github.io/insight-scaling-webpage"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Selective Test-Time Scaling, a process-based refinement framework that scales inference across stages in multi-agent pipelines instead of repeated refinement over time. 2. Designed a reliable LLM-based judge model aligned with human experts for evaluating visual insights. 3. Demonstrated improved insight quality under fixed compute budget in a data science pipeline application."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of scaling LLM agents for tasks with unverifiable rewards by introducing Selective Test-Time Scaling, which distributes compute across pipeline stages and prunes low-quality branches early using process-specific judges. Applied to generating visual insights from datasets, the method increases mean quality scores and reduces variance compared to traditional time-based refinement. The work provides a foundation for scaling complex, open-ended tasks like scientific discovery and story generation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Scaling Unverifiable Rewards: A Case Study on Visual Insights] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u591a\u9636\u6bb5\u4efb\u52a1\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u5956\u52b1/Multi-stage tasks lack verifiable rewards]\n    B --\x3e B2[\u57fa\u4e8e\u8bc4\u5224\u7684\u4f18\u5316\u6613\u7d2f\u79ef\u8bef\u5dee/Judge-based refinement prone to error accumulation]\n    C --\x3e C1[\u9009\u62e9\u6027\u6d4b\u8bd5\u65f6\u6269\u5c55/Selective Test-Time Scaling]\n    C --\x3e C2[\u8de8\u9636\u6bb5\u5206\u914d\u8ba1\u7b97\u8d44\u6e90/Distribute compute across stages]\n    C --\x3e C3[\u65e9\u671f\u526a\u679d\u4f4e\u8d28\u91cf\u5206\u652f/Prune low-quality branches early]\n    D --\x3e D1[\u63d0\u5347\u5e73\u5747\u5206\u6570/Increased mean scores (61.64 to 65.86)]\n    D --\x3e D2[\u964d\u4f4e\u65b9\u5dee/Reduced variance]\n    D --\x3e D3[\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5bf9\u9f50\u7684\u8bc4\u5224\u6a21\u578b/Judge model aligned with human experts]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [transfer learning / domain adaptation], [Cluster Attention Adapter, adapter tuning, data-limited domains, vision foundation models, adaptive transfer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qiankun Li, Feng He, Huabao Chen, Xin Ning, Kun Wang, Zengfu Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, AnnLab (Institute of Semiconductors, Chinese Academy of Sciences), Nanyang Technological University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22664",children:"https://arxiv.org/pdf/2512.22664"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/qklee-lz/CLAdapter",children:"https://github.com/qklee-lz/CLAdapter"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Cluster Attention Adapter (CLAdapter) that refines and adapts pre-trained representations to data-limited downstream tasks using attention mechanisms and cluster centers. 2. Designs a unified interface for seamless integration with diverse model architectures (CNNs, Transformers) in both 2D and 3D contexts. 3. Demonstrates state-of-the-art performance through extensive experiments on 10 datasets spanning diverse scientific domains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d174c6a31de34c34ee98111995fd6b43142db3342aa6c7a647cb2a8121615532_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d174c6a31de34c34ee98111995fd6b43142db3342aa6c7a647cb2a8121615532_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of adapting large-scale pre-trained vision foundation models to specialized, data-limited scientific domains. It proposes a novel Cluster Attention Adapter (CLAdapter) that personalizes feature enhancement for different downstream tasks, enabling effective adaptive transfer. Extensive experiments across 10 diverse datasets show that CLAdapter achieves state-of-the-art performance, demonstrating its effectiveness in unleashing the potential of foundation models for scientific applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4e0b\u6e38\u4efb\u52a1\u6570\u636e\u7a00\u7f3a/Data-limited downstream tasks]\n    C --\x3e C1[\u63d0\u51faCLAdapter/Propose CLAdapter]\n    C1 --\x3e C2[\u6ce8\u610f\u529b\u4e0e\u805a\u7c7b\u4e2d\u5fc3/Attention & Cluster Centers]\n    C2 --\x3e C3[\u4e2a\u6027\u5316\u7279\u5f81\u589e\u5f3a/Personalized Feature Enhancement]\n    D --\x3e D1[10\u4e2a\u6570\u636e\u96c6\u5b9e\u9a8c/Experiments on 10 datasets]\n    D1 --\x3e D2[\u5b9e\u73b0SOTA\u6027\u80fd/Achieves SOTA performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Investigating Deep Learning Models for Ejection Fraction Estimation from Echocardiography Videos"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [3D Inception, two-stream networks, CNN-RNN, EchoNet-Dynamic, video analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shravan Saranyan, Pramit Saha"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Branham High School, University of Oxford"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22657",children:"https://arxiv.org/pdf/2512.22657"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A systematic investigation and comparison of multiple deep learning architectures (3D Inception, two-stream, CNN-RNN) for automated LVEF estimation from echocardiography videos. 2. Identification that modified 3D Inception architectures achieve the best performance (RMSE of 6.79%) on the EchoNet-Dynamic dataset. 3. Key insights on model design, including the tendency for smaller, simpler models to generalize better and the high sensitivity of performance to hyperparameters like kernel size and normalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80971653578a1ff466eaae0a7007615dc054e9d7579f8916b800791a4f77026e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80971653578a1ff466eaae0a7007615dc054e9d7579f8916b800791a4f77026e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates deep learning models for automating the estimation of left ventricular ejection fraction (LVEF) from echocardiography videos to address the time-consuming and variable nature of manual assessment. The authors systematically evaluate and modify several architectures, including 3D Inception, two-stream, and CNN-RNN models, finding that a modified 3D Inception model performs best. The study concludes that while these models show promise, they are prone to overfitting and their performance is highly sensitive to specific hyperparameter choices."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Investigating Deep Learning Models for Ejection Fraction Estimation from Echocardiography Videos] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u624b\u52a8\u8bc4\u4f30LVEF\u8017\u65f6\u4e14\u5b58\u5728\u89c2\u5bdf\u8005\u95f4\u5dee\u5f02/Manual LVEF assessment is time-consuming and has inter-observer variability]\n    C --\x3e C1[\u7cfb\u7edf\u8bc4\u4f303D Inception\u3001\u53cc\u6d41\u548cCNN-RNN\u67b6\u6784/Systematically evaluate 3D Inception, two-stream, and CNN-RNN architectures]\n    C --\x3e C2[\u5728EchoNet-Dynamic\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30/Train and evaluate on the EchoNet-Dynamic dataset]\n    D --\x3e D1[\u6539\u8fdb\u76843D Inception\u67b6\u6784\u8868\u73b0\u6700\u4f73\uff0cRMSE\u4e3a6.79%/Modified 3D Inception achieves best performance (RMSE 6.79%)]\n    D --\x3e D2[\u66f4\u5c0f\u3001\u66f4\u7b80\u5355\u7684\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u66f4\u597d/Smaller, simpler models generalize better]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [width pruning, expansion ratio, Maximum Absolute Weight (MAW), GLU-MLP, instruction-following]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pere Martra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universidad Internacional Men\xe9ndez Pelayo (UIMP)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22671",children:"https://arxiv.org/pdf/2512.22671"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Systematically characterizes a capability dichotomy where structured width pruning degrades parametric knowledge (e.g., MMLU) but significantly improves instruction-following (e.g., IFEval). 2. Discovers and quantifies a robust inverse correlation between factual knowledge and truthfulness, linking knowledge degradation under pruning to improved misconception discrimination. 3. Identifies the expansion ratio as a critical architectural parameter that selectively modulates cognitive capabilities, rather than just a compression metric, and quantifies its context-dependent efficiency trade-offs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates structured width pruning of GLU-MLP layers in Llama-3.2 models using the Maximum Absolute Weight (MAW) criterion. It finds that pruning creates a dichotomy: while parametric knowledge degrades, instruction-following improves and multi-step reasoning remains robust, challenging the assumption of uniform degradation. The main conclusion is that width pruning acts as a selective filter, reducing knowledge but preserving or enhancing behavioral alignment, with identified trade-offs in efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: How does structured width pruning affect different LLM capabilities?]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: MAW-guided pruning of GLU-MLP layers, varying expansion ratio]\n    D[\u5173\u952e\u7ed3\u679c/Results: Knowledge \u2193, Instruction-following \u2191, Truthfulness \u2191, Efficiency trade-offs]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Conformal Prediction Sets for Next-Token Prediction in Large Language Models: Balancing Coverage Guarantees with Set Efficiency"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [uncertainty quantification], [conformal prediction, adaptive prediction sets, vocabulary-aware, coverage-efficiency tradeoff, marginal coverage]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yoshith Roy Kotla, Varshith Roy Kotla"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The ICFAI Foundation for Higher Education"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22682",children:"https://arxiv.org/pdf/2512.22682"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identified and formally characterized the coverage-efficiency tradeoff unique to applying conformal prediction to next-token prediction in LLMs with large vocabularies. 2. Proposed Vocabulary-Aware Conformal Prediction (VACP), a framework using semantic masking and temperature-adjusted scoring to reduce the effective prediction space. 3. Provided a theoretical analysis of when vocabulary reduction preserves conformal validity and demonstrated a 197x improvement in prediction set efficiency on benchmarks while maintaining coverage guarantees."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb40fe541a33e11ac6d9b3f6f3fac213d5602d391cc590303cb8079bf97a840_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb40fe541a33e11ac6d9b3f6f3fac213d5602d391cc590303cb8079bf97a840_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem that naive conformal prediction for LLM next-token prediction produces uninformatively large prediction sets due to large vocabularies. It proposes Vocabulary-Aware Conformal Prediction (VACP), which uses semantic masking and hierarchical conformalization to drastically reduce set size. The method achieves near-target coverage while improving set efficiency by 197x, making conformal prediction practical for LLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Conformal Prediction Sets for LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u6807\u51c6\u7f6e\u4fe1\u9884\u6d4b\u5728\u5927\u578b\u8bcd\u6c47\u8868\u4e2d\u4ea7\u751f\u5de8\u5927\u4e14\u65e0\u7528\u7684\u9884\u6d4b\u96c6]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u8bcd\u6c47\u611f\u77e5\u7f6e\u4fe1\u9884\u6d4b(VACP), \u4f7f\u7528\u8bed\u4e49\u63a9\u7801\u548c\u5206\u5c42\u6821\u51c6]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u4fdd\u630190%\u8986\u76d6\u7387\u7684\u540c\u65f6, \u5c06\u5e73\u5747\u9884\u6d4b\u96c6\u5927\u5c0f\u4ece847\u4e2a\u8bcd\u5143\u51cf\u5c11\u52304.3\u4e2a]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] TravelBench: A Real-World Benchmark for Multi-Turn and Tool-Augmented Travel Planning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [travel planning benchmark, multi-turn interaction, tool-augmented agents, deterministic sandbox, real-world user requests]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xiang Cheng, Yulan Hu, Xiangwen Zhang, Lu Xu, Zheng Pan, Xin Li, Yong Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Gaoling School of Artificial Intelligence, Renmin University of China; AMAP, Alibaba Group; National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22673",children:"https://arxiv.org/pdf/2512.22673"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces TravelBench, a real-world travel planning benchmark featuring multi-turn user-agent interaction and tool use, addressing limitations of prior static benchmarks. 2. Constructs a controlled sandbox environment with 10 deterministic travel-domain tools (e.g., POI search, route planning) to enable stable and reproducible evaluation of agent reasoning. 3. Collects and curates a diverse dataset of 1,103 instances (multi-turn, single-turn, unsolvable) from real user scenarios to comprehensively evaluate different aspects of agent performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9e23f8223243d3734eaad4483f929312f198ee51f05e74faf519458ec18add0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9e23f8223243d3734eaad4483f929312f198ee51f05e74faf519458ec18add0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces TravelBench, a new benchmark for evaluating LLM agents in realistic travel planning, which features multi-turn interaction and a sandbox of deterministic tools. The benchmark addresses the limitations of prior work by supporting dynamic user interaction and long-horizon planning. The authors evaluate several LLMs on TravelBench, providing a practical testbed for advancing agent capabilities in planning and tool use."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[TravelBench: A Real-World Benchmark for Multi-Turn and Tool-Augmented Travel Planning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u65c5\u884c\u89c4\u5212\u57fa\u51c6\u7f3a\u4e4f\u591a\u8f6e\u4ea4\u4e92\u548c\u771f\u5b9e\u573a\u666f\u8986\u76d6/Existing travel planning benchmarks lack multi-turn interaction and real-world coverage]\n    C --\x3e C1[\u6784\u5efa\u5305\u542b\u591a\u8f6e\u5bf9\u8bdd\u3001\u5355\u8f6e\u67e5\u8be2\u548c\u4e0d\u53ef\u89e3\u8bf7\u6c42\u7684\u771f\u5b9e\u6570\u636e\u96c6/Build a real-world dataset with multi-turn dialogues, single-turn queries, and unsolvable requests]\n    C --\x3e C2[\u521b\u5efa\u5177\u670910\u4e2a\u786e\u5b9a\u6027\u5de5\u5177\u7684\u6c99\u76d2\u73af\u5883/Create a sandbox environment with 10 deterministic tools]\n    D --\x3e D1[\u4e3aLLM\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u590d\u73b0\u7684\u57fa\u51c6/Provides a practical and reproducible benchmark for LLM agent evaluation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.strong,{children:["[arXiv251230] Learning with the ",(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"p"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"p"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",children:"p"})]})})]}),"-adics"]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [representation learning], [p-adic numbers, ultrametric space, hierarchical representation, non-archimedean geometry, semantic networks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Andr\xe9 F. T. Martins"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Instituto Superior T\xe9cnico, Universidade de Lisboa; Instituto de Telecomunica\xe7\xf5es"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22692",children:"https://arxiv.org/pdf/2512.22692"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes using the p-adic number field (Q_p) as an alternative to real numbers for machine learning, leveraging its ultrametric and hierarchical structure. 2. Develops foundational building blocks for classification, regression, and representation learning models and algorithms within the p-adic framework. 3. Demonstrates a novel application by representing simple Quillian semantic networks as compact p-adic linear networks, which is not achievable with real numbers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec090da18463864436ff27e6cb4651eb7e01719b66dcdae5d6644770e6a7b488_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec090da18463864436ff27e6cb4651eb7e01719b66dcdae5d6644770e6a7b488_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper explores using p-adic numbers, an ultrametric and non-archimedean field, as an alternative to real numbers for machine learning. It introduces theoretical models and algorithms for classification, regression, and representation learning, showing that p-adics enable compact representations of hierarchical structures like semantic networks. The work opens new research directions by leveraging the unique geometric properties of p-adic spaces."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Learning with the p-adics] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[\u73b0\u6709ML\u57fa\u4e8e\u5b9e\u6570\u57df/Existing ML uses real numbers]\nB --\x3e B2[\u662f\u5426\u53ef\u7528\u5176\u4ed6\u57df?/Alternative fields possible?]\nC --\x3e C1[\u7814\u7a76p-adic\u6570\u57df/Study p-adic number field Q_p]\nC --\x3e C2[\u5229\u7528\u8d85\u5ea6\u91cf\u7ed3\u6784/Exploit ultrametric structure]\nD --\x3e D1[\u6784\u5efa\u5206\u7c7b\u56de\u5f52\u6a21\u578b/Build classification & regression models]\nD --\x3e D2[\u8868\u793a\u5b66\u4e60\u4e0e\u8bed\u4e49\u7f51\u7edc/Representation learning & semantic networks]\nD --\x3e D3[\u5f00\u542f\u65b0\u7814\u7a76\u65b9\u5411/Open new research directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] GHaLIB: A Multilingual Framework for Hope Speech Detection in Low-Resource Languages"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hope speech detection], [transformer models, multilingual classification, low-resource languages, XLM-RoBERTa, UrduBERT]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ahmed Abdullah, Sana Fatima, Haroon Mahmood"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," FAST-National University, Al Ain University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22705",children:"https://arxiv.org/pdf/2512.22705"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a multilingual framework for hope speech detection, specifically addressing the underrepresentation of low-resource languages like Urdu. 2. Applies and evaluates multiple pretrained transformer models (XLM-RoBERTa, mBERT, EuroBERT, UrduBERT) on the PolyHope-M 2025 benchmark for this task. 3. Demonstrates strong performance, achieving high F1-scores for Urdu classification, validating the use of existing multilingual models in low-resource settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of resources for hope speech detection in low-resource languages by proposing a multilingual framework using pretrained transformer models like XLM-RoBERTa and UrduBERT. The method involves simple preprocessing and training classifiers, which achieve high F1-scores on the PolyHope-M 2025 benchmark, particularly for Urdu. The results show that existing multilingual models can be effectively implemented to identify hope speech and foster positive digital discourse in low-resource environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GHaLIB: \u591a\u8bed\u8a00\u5e0c\u671b\u8bed\u97f3\u68c0\u6d4b\u6846\u67b6 / GHaLIB: Multilingual Hope Speech Detection Framework] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u5e0c\u671b\u8bed\u97f3\u5728NLP\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3 / Hope speech underrepresented in NLP]\n    B --\x3e B2[\u4f4e\u8d44\u6e90\u8bed\u8a00(\u5982\u4e4c\u5c14\u90fd\u8bed)\u7f3a\u4e4f\u8d44\u6e90 / Lack of resources for low-resource languages (e.g., Urdu)]\n    C --\x3e C1[\u4f7f\u7528\u9884\u8bad\u7ec3\u591a\u8bed\u8a00Transformer\u6a21\u578b / Use pretrained multilingual Transformer models]\n    C --\x3e C2[\u7b80\u5355\u9884\u5904\u7406\u4e0e\u5206\u7c7b\u5668\u8bad\u7ec3 / Simple preprocessing & classifier training]\n    D --\x3e D1[\u4e4c\u5c14\u90fd\u8bed\u4e8c\u5143\u5206\u7c7bF1: 95.2% / Urdu binary F1: 95.2%]\n    D --\x3e D2[\u4e4c\u5c14\u90fd\u8bed\u591a\u7c7b\u5206\u7c7bF1: 65.2% / Urdu multi-class F1: 65.2%]\n    D --\x3e D3[\u591a\u8bed\u8a00\u6a21\u578b\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u73af\u5883 / Multilingual models viable for low-resource settings]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Memento-II: Learning by Stateful Reflective Memory"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [stateful reflective decision process, episodic memory, policy iteration, continual learning, retrieval-augmented generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jun Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University College London (UCL)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22716",children:"https://arxiv.org/pdf/2512.22716"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Stateful Reflective Decision Process (SRDP), a formal theoretical framework that models continual learning in LLM agents as a two-stage read-write interaction with episodic memory, linking it to policy evaluation and improvement. 2. Provides a theoretical analysis showing that the reflective learning process induces an equivalent Markov Decision Process, enabling the use of classical dynamic programming and RL tools, and establishes convergence guarantees when instantiated with entropy-regularised policy iteration. 3. Unifies heuristic approaches like case-based reasoning and retrieval-augmented generation with principled reinforcement learning, offering a rigorous mathematical foundation for building memory-augmented agents capable of online adaptation without parameter updates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a theoretical framework for continual learning in LLM agents that uses episodic memory and reflection instead of back-propagation. The core method formalizes learning as a Stateful Reflective Decision Process, where writing to memory is policy evaluation and reading from it is policy improvement. The main conclusion is that this framework provides a principled, convergent foundation for agents to self-improve through interaction without fine-tuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Memento-II: Learning by Stateful Reflective Memory] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u7f3a\u4e4f\u7406\u8bba\u89e3\u91ca/Lack of theoretical explanation for memory-based continual learning in LLM agents]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u72b6\u6001\u5316\u53cd\u601d\u51b3\u7b56\u8fc7\u7a0b/Stateful Reflective Decision Process (SRDP) with read-write episodic memory]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u4e0e\u6536\u655b\u4fdd\u8bc1/Provides theoretical framework and convergence guarantees for optimal policy]\n    C --\x3e E[\u5199\u5165\u5bf9\u5e94\u7b56\u7565\u8bc4\u4f30/Writing corresponds to policy evaluation]\n    C --\x3e F[\u8bfb\u53d6\u5bf9\u5e94\u7b56\u7565\u6539\u8fdb/Reading corresponds to policy improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [context folding, long-horizon RL, non-stationary observation, gradient dilution, selective segment training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiaqi Shao, Yufeng Miao, Wei Zhang, Bing Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hong Kong University of Science and Technology, Duke Kunshan University, Microsoft AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22733",children:"https://arxiv.org/pdf/2512.22733"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/SHAO-Jiaqi757/FoldAct",children:"https://github.com/SHAO-Jiaqi757/FoldAct"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Separated loss computation for independent gradient signals on summary and action tokens to address gradient dilution. 2. Full context consistency loss to reduce distribution shift caused by policy-dependent observation changes. 3. Selective segment training to reduce computational cost by processing unique contexts efficiently."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that treating context folding (history summarization) as a standard action in long-horizon RL for LLMs creates a non-stationary observation distribution, leading to training instability and inefficiency. It proposes FoldAct, a framework with three innovations\u2014separated loss, consistency loss, and selective training\u2014to stabilize training and improve efficiency. The method achieves stable training and a 5.19\xd7 speedup."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u975e\u5e73\u7a33\u89c2\u6d4b\u5206\u5e03 / Non-stationary Observation Distribution]\n    B --\x3e B2[\u68af\u5ea6\u7a00\u91ca / Gradient Dilution]\n    B --\x3e B3[\u8ba1\u7b97\u6210\u672c\u9ad8 / High Computational Cost]\n    C --\x3e C1[\u5206\u79bb\u635f\u5931\u8ba1\u7b97 / Separated Loss Computation]\n    C --\x3e C2[\u5168\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u635f\u5931 / Full Context Consistency Loss]\n    C --\x3e C3[\u9009\u62e9\u6027\u7247\u6bb5\u8bad\u7ec3 / Selective Segment Training]\n    D --\x3e D1[\u7a33\u5b9a\u8bad\u7ec3 / Stable Training]\n    D --\x3e D2[5.19\u500d\u52a0\u901f / 5.19\xd7 Speedup]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Harnessing Large Language Models for Biomedical Named Entity Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [named entity recognition], [instruction tuning, data filtering, weak-to-strong learning, biomedical named entity recognition, json generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jian Chen, Leilei Su, Cong Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hainan University, Weill Cornell Medicine"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22738",children:"https://arxiv.org/pdf/2512.22738"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes BioSelectTune, a data-centric framework for fine-tuning LLMs for BioNER that prioritizes data quality. 2. Introduces a Hybrid Superfiltering strategy, a weak-to-strong data curation method to distill a high-impact training dataset. 3. Reformulates BioNER as a structured JSON generation task to leverage LLMs' instruction-following capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e941de51836d02e0004ef558a69019ce22af7124cd10760a2c904f6329cfa1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e941de51836d02e0004ef558a69019ce22af7124cd10760a2c904f6329cfa1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of adapting general-domain LLMs to Biomedical Named Entity Recognition (BioNER) by proposing BioSelectTune, a framework that uses a novel Hybrid Superfiltering data curation strategy and formulates BioNER as a JSON generation task. The method achieves state-of-the-art performance on multiple benchmarks, outperforming specialized models even when trained on only 50% of the curated data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Harnessing LLMs for BioNER] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs lack domain knowledge for BioNER / LLMs\u7f3a\u4e4f\u751f\u7269\u533b\u5b66\u9886\u57df\u77e5\u8bc6]\n    B --\x3e B2[Low-quality data degrades performance / \u4f4e\u8d28\u91cf\u6570\u636e\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d]\n    C --\x3e C1[BioSelectTune Framework / BioSelectTune\u6846\u67b6]\n    C1 --\x3e C2[Reformulate as JSON generation / \u91cd\u6784\u4e3aJSON\u751f\u6210\u4efb\u52a1]\n    C1 --\x3e C3[Hybrid Superfiltering / \u6df7\u5408\u8d85\u7ea7\u8fc7\u6ee4\u7b56\u7565]\n    D --\x3e D1[SOTA on benchmarks / \u57fa\u51c6\u6d4b\u8bd5\u8fbe\u5230SOTA]\n    D --\x3e D2[Outperforms BioMedBERT / \u8d85\u8d8aBioMedBERT]\n    D --\x3e D3[50% data surpasses baseline / 50%\u6570\u636e\u8d85\u8d8a\u5168\u91cf\u57fa\u7ebf]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [Column Type Annotation, Prompt Augmentation, LoRA, Parameter-Efficient Fine-Tuning, Prompt Sensitivity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hanze Meng, Jianhao Cao, Rachel Pottinger"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of British Columbia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22742",children:"https://arxiv.org/pdf/2512.22742"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/fripSideMeng/PACTA",children:"https://github.com/fripSideMeng/PACTA"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a parameter-efficient fine-tuning framework for Column Type Annotation (CTA) using Low-Rank Adaptation (LoRA) to reduce computational cost. 2. Introduces a prompt augmentation strategy during training to mitigate model sensitivity to variations in prompt wording and structure. 3. Demonstrates robust and stable performance across diverse datasets and prompt templates, achieving higher weighted F1 scores than single-template fine-tuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95317c9af6072a1e0ffbb34950b7d9da057c55baaf301c56bb751746b366785a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95317c9af6072a1e0ffbb34950b7d9da057c55baaf301c56bb751746b366785a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of prompt sensitivity and high computational cost in using Large Language Models (LLMs) for Column Type Annotation. It proposes a parameter-efficient framework that fine-tunes LLMs using LoRA on prompt-augmented data. The method achieves robust performance across different prompts and datasets while requiring significantly fewer trainable parameters."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u73b0\u6709\u65b9\u6cd5\u5bf9\u63d0\u793a\u8bcd\u654f\u611f/Existing methods are sensitive to prompts")\n    Problem --\x3e P2("\u5b8c\u5168\u5fae\u8c03\u6210\u672c\u9ad8\u6602/Full fine-tuning is computationally prohibitive")\n    Method --\x3e M1("\u4f7f\u7528LoRA\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03/Parameter-efficient fine-tuning with LoRA")\n    Method --\x3e M2("\u4f7f\u7528\u589e\u5f3a\u7684\u63d0\u793a\u6570\u636e\u8fdb\u884c\u8bad\u7ec3/Training on prompt-augmented data")\n    Results --\x3e R1("\u5bf9\u4e0d\u540c\u63d0\u793a\u6a21\u5f0f\u6027\u80fd\u7a33\u5b9a/Stable performance across diverse prompts")\n    Results --\x3e R2("\u83b7\u5f97\u66f4\u9ad8\u7684\u52a0\u6743F1\u5206\u6570/Higher weighted F1 scores")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Active Constraint Learning in High Dimensions from Demonstrations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [robot learning], [active learning, constraint inference, Gaussian processes, learning from demonstration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zheng Qiu, Chih-Yuan Chiu, Glen Chou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Georgia Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22757",children:"https://arxiv.org/pdf/2512.22757"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an iterative active constraint learning (ACL) algorithm that intelligently queries for new demonstrations to reduce constraint uncertainty. 2. Integrates a Gaussian process (GP) model within the learning from demonstrations (LfD) paradigm to represent and infer unknown constraints. 3. Demonstrates superior performance over a random-sampling baseline in recovering nonlinear constraints from sparse, informative demonstrations in high-dimensional settings with nonlinear dynamics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5acbf135d5aa431114b6b72db2fb101427cb6bd1e55fb1a8afd3028c0874cb4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5acbf135d5aa431114b6b72db2fb101427cb6bd1e55fb1a8afd3028c0874cb4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the data inefficiency of learning unknown constraints from demonstrations by proposing an active learning algorithm. The method iteratively trains a Gaussian process on demonstration data to model constraints and uses the model's uncertainty to query for new, informative start/goal states to generate more demonstrations. Experiments show the approach outperforms a random-sampling baseline in accurately inferring constraints from fewer demonstrations in high-dimensional, nonlinear environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Active Constraint Learning in High Dimensions from Demonstrations") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Data-inefficient constraint inference from demonstrations")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Iterative active learning with Gaussian Processes")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Outperforms baseline with sparse, informative demonstrations")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Understanding the Mechanisms of Fast Hyperparameter Transfer"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [hyperparameter optimization], [hyperparameter transfer, scale-aware hyperparameters, Maximal Update Parameterization (\u03bcP), compute-optimal grid search]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nikhil Ghosh, Denny Wu, Alberto Bietti"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Flatiron Institute, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22768",children:"https://arxiv.org/pdf/2512.22768"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Develops a formal conceptual framework defining "fast" hyperparameter transfer and proves its equivalence to "useful" transfer for compute-optimal grid search. 2. Demonstrates that the fast transfer property is not universal and depends critically on problem structure, showing synthetic cases where it succeeds or fails. 3. Proposes and provides empirical evidence for a mechanistic hypothesis explaining fast transfer, decomposing the loss reduction into width-stable and width-sensitive components.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19c9825d64e8e70117e18cd478466aaf2627a7a5167d401bcac21353870d508_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19c9825d64e8e70117e18cd478466aaf2627a7a5167d401bcac21353870d508_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the mechanisms behind fast hyperparameter transfer, a strategy to reduce tuning costs by transferring optimal hyperparameters from small to large models. It formally defines fast transfer and shows it is computationally advantageous, then explains the phenomenon by hypothesizing a decomposition of the optimization trajectory into stable and sensitive components, supported by empirical evidence."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Understanding the Mechanisms of Fast Hyperparameter Transfer<br>\u7406\u89e3\u5feb\u901f\u8d85\u53c2\u6570\u8fc1\u79fb\u7684\u673a\u5236"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Standard HP tuning is too expensive for large models.<br>\u6807\u51c6HP\u8c03\u4f18\u5bf9\u4e8e\u5927\u6a21\u578b\u8fc7\u4e8e\u6602\u8d35"] --\x3e P1["\u5b50\u95ee\u9898/Sub-problem<br>How to define and understand \'fast\' HP transfer?<br>\u5982\u4f55\u5b9a\u4e49\u548c\u7406\u89e3\'\u5feb\u901f\'HP\u8fc1\u79fb\uff1f"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Develop a formal framework for HP transfer.<br>\u5efa\u7acbHP\u8fc1\u79fb\u7684\u5f62\u5f0f\u5316\u6846\u67b6"] --\x3e M1["\u65b9\u6cd5\u6b65\u9aa4/Step<br>Define \'fast\' vs \'useful\' transfer.<br>\u5b9a\u4e49\'\u5feb\u901f\'\u4e0e\'\u6709\u7528\'\u8fc1\u79fb"]\n    Method --\x3e M2["\u65b9\u6cd5\u6b65\u9aa4/Step<br>Analyze problem structure & \xb5P.<br>\u5206\u6790\u95ee\u9898\u7ed3\u6784\u4e0e\xb5P"]\n    Method --\x3e M3["\u65b9\u6cd5\u6b65\u9aa4/Step<br>Propose trajectory decomposition hypothesis.<br>\u63d0\u51fa\u8f68\u8ff9\u5206\u89e3\u5047\u8bbe"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Fast transfer is equivalent to useful transfer.<br>\u5feb\u901f\u8fc1\u79fb\u7b49\u4ef7\u4e8e\u6709\u7528\u8fc1\u79fb"] --\x3e R1["\u7ed3\u679c/Result<br>Transfer success depends on problem structure.<br>\u8fc1\u79fb\u6210\u529f\u53d6\u51b3\u4e8e\u95ee\u9898\u7ed3\u6784"]\n    Results --\x3e R2["\u7ed3\u679c/Result<br>Empirical evidence supports the hypothesis.<br>\u5b9e\u8bc1\u8bc1\u636e\u652f\u6301\u8be5\u5047\u8bbe"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Next Best View Selections for Semantic and Dynamic 3D Gaussian Splatting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3d reconstruction], [3D Gaussian Splatting, Next Best View, Active Learning, Fisher Information, Dynamic Scene Modeling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yiqian Li, Wen Jiang, Kostas Daniilidis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Pennsylvania"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22771",children:"https://arxiv.org/pdf/2512.22771"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formulates the next-best-view selection problem for dynamic and semantic 3D scenes as an active learning problem. 2. Proposes an active learning algorithm using Fisher Information to quantify view informativeness for both semantic Gaussian parameters and deformation networks. 3. Provides a unified framework that jointly handles semantic reasoning and dynamic scene modeling, outperforming heuristic and random baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/512528158b99bf9d8d5519331a5d1557baee5b3050273bff66df842767a73963_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/512528158b99bf9d8d5519331a5d1557baee5b3050273bff66df842767a73963_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of selecting the most informative camera views for training dynamic and semantic 3D Gaussian Splatting models. It proposes an active learning method based on Fisher Information to prioritize frames that maximize information gain for both geometry and semantics. The approach improves rendering quality and segmentation performance compared to random or uncertainty-based selection strategies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Next Best View Selections for Semantic and Dynamic 3D Gaussian Splatting] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Data redundancy in dynamic & semantic scene understanding, need for efficient view selection)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Active learning with Fisher Information to quantify informativeness of views for semantic Gaussians & deformation networks)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Improved rendering quality & semantic segmentation, outperforms random & heuristic baselines)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Adapting, Fast and Slow: Transportable Circuits for Few-Shot Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [causal inference], [causal transportability, domain adaptation, few-shot learning, circuit composition, distribution shift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kasra Jalaldoust, Elias Bareinboim"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22777",children:"https://arxiv.org/pdf/2512.22777"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Circuit-TR, an algorithm for zero-shot compositional generalization based on causal transportability theory, using modules learned from source data. 2. Introduced a supervised domain adaptation scheme that leverages circuit transportability without requiring an explicit causal graph, using only limited target data. 3. Provided theoretical characterization of few-shot learnable tasks using graphical circuit transportability criteria, linking generalizability to circuit size complexity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5b025a886304d6097d2893ec4af3bb34a59528db65e22ddf5b4dfff4439a096_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5b025a886304d6097d2893ec4af3bb34a59528db65e22ddf5b4dfff4439a096_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of generalization under distribution shift by proposing a method based on causal transportability theory. The method, Circuit-TR, learns local predictors (modules) from source data and composes them into a circuit for prediction in a target domain, enabling both zero-shot and few-shot adaptation. The theoretical results connect few-shot learnability to circuit transportability criteria and complexity, which are supported by simulations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Adapting, Fast and Slow: Transportable Circuits for Few-Shot Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Generalization under distribution shift]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Circuit-TR algorithm based on causal transportability]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Theoretical characterization of few-shot learnability]\nB --\x3e B1[\u9886\u57df\u6cdb\u5316\u4e0e\u9002\u5e94/Domain Generalization & Adaptation]\nC --\x3e C1[\u6a21\u5757\u5b66\u4e60\u4e0e\u7535\u8def\u7ec4\u5408/Module Learning & Circuit Composition]\nC --\x3e C2[\u56e0\u679c\u56fe\u4e0e\u673a\u5236\u5171\u4eab/Causal Graph & Mechanism Sharing]\nD --\x3e D1[\u53ef\u8fc1\u79fb\u6027\u6807\u51c6/Transportability Criteria]\nD --\x3e D2[\u7535\u8def\u89c4\u6a21\u590d\u6742\u5ea6/Circuit Size Complexity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph neural networks], [temporal graph neural networks, explainable ai, graph explanation, recurrent neural networks, breadth-first search]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xuyan Li, Jie Wang, Zheng Yan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Xidian University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22772",children:"https://arxiv.org/pdf/2512.22772"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes GRExplainer, a universal explanation method applicable to both snapshot-based and event-based Temporal Graph Neural Networks (TGNNs). 2. Introduces an efficient approach using breadth-first search and temporal information to construct node sequences, reducing computational cost. 3. Designs a user-friendly generative model based on Recurrent Neural Networks (RNNs) for automated and continuous explanation generation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0722c64cfeebe092d7b253f417faaa51990e69198068745c39fe241716082408_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0722c64cfeebe092d7b253f417faaa51990e69198068745c39fe241716082408_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of explainability in Temporal Graph Neural Networks (TGNNs) by proposing GRExplainer, a universal and efficient method that uses node sequences and an RNN-based generative model to provide explanations. Experiments on six datasets with three TGNNs demonstrate that GRExplainer outperforms existing methods in generality, efficiency, and user-friendliness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[TGNN\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027/Lack of TGNN transparency & explainability]\n    B --\x3e B2[\u73b0\u6709\u65b9\u6cd5\u901a\u7528\u6027\u5dee\u3001\u6548\u7387\u4f4e\u3001\u4e0d\u53cb\u597d/Existing methods lack generality, efficiency, user-friendliness]\n    C --\x3e C1[\u63d0\u53d6\u8282\u70b9\u5e8f\u5217\u4f5c\u4e3a\u7edf\u4e00\u7279\u5f81/Extract node sequences as unified features]\n    C --\x3e C2[\u4f7f\u7528BFS\u548c\u65f6\u95f4\u4fe1\u606f\u6784\u5efa\u5e8f\u5217/Use BFS & temporal info to construct sequences]\n    C --\x3e C3[\u57fa\u4e8eRNN\u7684\u751f\u6210\u6a21\u578b/RNN-based generative model]\n    D --\x3e D1[\u57286\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c/Experiments on 6 datasets]\n    D --\x3e D2[\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5/Outperforms existing baselines]\n    D --\x3e D3[\u901a\u7528\u3001\u9ad8\u6548\u3001\u7528\u6237\u53cb\u597d/Generality, efficiency, user-friendliness]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] CNSight: Evaluation of Clinical Note Segmentation Tools"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text segmentation], [clinical note segmentation, transformer models, large language models, MIMIC-IV, rule-based baselines]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Risha Surana, Adrian Law, Sunwoo Kim, Rishab Sridhar, Angxiao Han, Peiyu Hong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Southern California"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22795",children:"https://arxiv.org/pdf/2512.22795"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive evaluation of diverse methods (rule-based, domain-specific transformers, and large language models) for the task of clinical note segmentation. 2. The curation and use of a dataset of 1,000 notes from MIMIC-IV for benchmarking segmentation performance. 3. Empirical findings that large API-based models (e.g., GPT-5-mini) achieve the best overall performance, while lightweight baselines remain competitive only on structured tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates various methods for segmenting unstructured clinical notes into distinct sections. It compares rule-based baselines, domain-specific transformers, and large language models on a curated dataset from MIMIC-IV. The main conclusion is that large API-based models like GPT-5-mini achieve the best overall segmentation performance, providing guidance for method selection in downstream clinical applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[CNSight: \u4e34\u5e8a\u7b14\u8bb0\u5206\u5272\u5de5\u5177\u8bc4\u4f30 / CNSight: Evaluation of Clinical Note Segmentation Tools]\n    Root --\x3e Problem[\u4e34\u5e8a\u7b14\u8bb0\u975e\u7ed3\u6784\u5316 / Clinical Notes Unstructured]\n    Root --\x3e Method[\u8bc4\u4f30\u89c4\u5219/\u53d8\u6362\u5668/\u5927\u8bed\u8a00\u6a21\u578b / Evaluate Rule-based/Transformer/LLMs]\n    Root --\x3e Results[\u5927\u6a21\u578b\u6027\u80fd\u6700\u4f73 / Large Models Best Performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SNM-Net: A Universal Framework for Robust Open-Set Gas Recognition via Spherical Normalization and Mahalanobis Distance"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [open-set recognition], [spherical normalization, Mahalanobis distance, electronic nose, open-set recognition, feature drift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shuai Chen, Chen Wang, Ziran Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," School of Mechanical Engineering, Shandong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22792",children:"https://arxiv.org/pdf/2512.22792"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A geometric decoupling mechanism using cascaded batch normalization and L2 normalization to project features onto a unit hypersphere, eliminating signal intensity fluctuations. 2. The introduction of Mahalanobis distance as a scoring mechanism to construct adaptive ellipsoidal decision boundaries that account for anisotropic feature distributions. 3. A universal, architecture-agnostic framework (SNM-Net) that can be seamlessly integrated with various backbone networks (CNN, RNN, Transformer) for robust open-set gas recognition."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d69d593ebbfea881a49530f570b5c2a934cb8b5cd782c1d7e7c9fba99a92906_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d69d593ebbfea881a49530f570b5c2a934cb8b5cd782c1d7e7c9fba99a92906_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes SNM-Net, a universal framework for robust open-set gas recognition in electronic nose systems. It addresses signal drift and unknown interference by projecting features onto a hypersphere for intensity normalization and using Mahalanobis distance for scoring. The method achieves state-of-the-art performance with high accuracy and exceptional robustness across different sensor conditions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["SNM-Net: A Universal Framework for Robust Open-Set Gas Recognition"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Feature drift & unknown gas interference in E-nose"] --\x3e P1["\u4fe1\u53f7\u6f02\u79fb/Feature Distribution Shift"]\n    Problem --\x3e P2["\u672a\u77e5\u6c14\u4f53\u5e72\u6270/Unknown Gas Interference"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>SNM-Net Framework"] --\x3e M1["\u51e0\u4f55\u89e3\u8026/Geometric Decoupling<br>Cascaded Batch & L2 Norm"]\n    Method --\x3e M2["\u9a6c\u6c0f\u8ddd\u79bb\u8bc4\u5206/Mahalanobis Distance Scoring"]\n    Method --\x3e M3["\u67b6\u6784\u65e0\u5173/Architecture-Agnostic<br>CNN, RNN, Transformer"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>State-of-the-art performance"] --\x3e R1["\u9ad8AUROC/High AUROC: 0.9977"]\n    Results --\x3e R2["\u9ad8\u672a\u77e5\u6c14\u4f53\u68c0\u6d4b\u7387/High Unknown Detection: 99.57%"]\n    Results --\x3e R3["\u5f3a\u9c81\u68d2\u6027/High Robustness<br>Low std. dev."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [differential games], [Hamilton-Jacobi reachability, reach-avoid games, dimensionality decomposition, UAVs, tracking control]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Minh Bui, Simon Monckton, Mo Chen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Simon Fraser University, Defense Research & Development Canada (DRDC)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22793",children:"https://arxiv.org/pdf/2512.22793"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel dimensionality reduction framework for 3D reach-avoid games by decomposing the problem into horizontal and vertical sub-games., 2. A Hamilton-Jacobi-based tracking control algorithm to reconstruct the solution from sub-games, guaranteeing capture and subsequent tracking of the attacker., 3. Theoretical proof of the conditions for maintaining capture guarantees and empirical validation in both numerical simulations and a physics simulator (Gazebo)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the high-dimensional challenge of 3D reach-avoid differential games for UAVs by proposing a decomposition approach that splits the problem into horizontal and vertical sub-games, solves them using Hamilton-Jacobi reachability analysis, and uses a novel tracking control to reconstruct the solution. The method is proven to maintain optimality and capture guarantees, and its effectiveness is successfully demonstrated through simulations and a physics simulator for quadrotor capture."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898: Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[3D\u8ffd\u9003\u535a\u5f08\u9ad8\u7ef4\u6311\u6218/High Dimensionality of 3D Reach-Avoid Games]\n    B --\x3e B2[\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u6027/Limitations of Existing Approaches]\n    C --\x3e C1[\u7ef4\u5ea6\u5206\u89e3/Dimensionality Decomposition]\n    C1 --\x3e C1_1[\u6c34\u5e73\u5b50\u535a\u5f08/Horizontal Sub-game]\n    C1 --\x3e C1_2[\u5782\u76f4\u5b50\u535a\u5f08/Vertical Sub-game]\n    C --\x3e C2[HJ\u53ef\u8fbe\u6027\u5206\u6790/HJ Reachability Analysis]\n    C --\x3e C3[HJ\u8ddf\u8e2a\u63a7\u5236/HJ-based Tracking Control]\n    D --\x3e D1[\u4fdd\u6301\u6700\u4f18\u6027\u4e0e\u4fdd\u8bc1/Maintains Optimality & Guarantees]\n    D --\x3e D2[\u4eff\u771f\u9a8c\u8bc1/Simulation Validation]\n    D --\x3e D3[\u7269\u7406\u6a21\u62df\u5668\u6210\u529f\u6355\u83b7/Successful Capture in Physics Simulator]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] MoR: Mixture Of Representations For Mixed-Precision Training"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [mixed-precision training, FP8, dynamic quantization, tensor representation, low-precision training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bor-Yiing Su, Peter Dykas, Mike Chrzanowski, Jatin Chhugani"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nvidia, Meta"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22804",children:"https://arxiv.org/pdf/2512.22804"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Mixture-of-Representations (MoR), a novel per-tensor and sub-tensor level quantization framework that dynamically selects numerical representations based on tensor properties. 2. Introduces and experiments with concrete algorithms that dynamically choose between FP8 and BF16 representations at different granularities. 3. Demonstrates a universal approach that preserves model quality across datasets and achieves state-of-the-art results with 98.38% of tensors quantized to FP8, showing potential for even lower precision formats like NVFP4."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14c70a65c4f996e1c88d9996c77e4d780e13466bf11a0601ad82d27376753968_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14c70a65c4f996e1c88d9996c77e4d780e13466bf11a0601ad82d27376753968_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces MoR, a dynamic quantization framework for mixed-precision training that analyzes tensor properties to select between representations like FP8 and BF16. It achieves high FP8 quantization rates (98.38%) while maintaining model quality, offering a robust approach for low-precision training that can be combined with other methods for even lower precision formats."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[MoR: Mixture Of Representations For Mixed-Precision Training] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>Successful mixed-precision training requires the right combination of methods.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>Dynamic, property-aware quantization framework selecting between representations (e.g., FP8/BF16).]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>Achieves 98.38% FP8 quantization, preserves model quality, enables lower precision formats.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] EgoReAct: Egocentric Video-Driven 3D Human Reaction Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [human motion generation], [egocentric video, 3D human reaction, autoregressive generation, VQ-VAE, GPT]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Libo Zhang, Zekun Li, Tianyu Li, Zeyu Cao, Rui Xu, Xiaoxiao Long, Wenjia Wang, Jingbo Wang, Yuan Liu, Wenping Wang, Daquan Zhou, Taku Komura, Zhiyang Dou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," THU, Brown, Georgia Tech, Cambridge, HKU, NJU, CUHK, HKUST, TAMU, PKU, MIT"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22808",children:"https://arxiv.org/pdf/2512.22808"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Constructed the Human Reaction Dataset (HRD), a spatially aligned egocentric video-reaction dataset to address data scarcity and misalignment in existing resources. 2. Proposed EgoReAct, the first autoregressive framework for real-time, 3D-aligned human reaction motion generation from streaming egocentric video. 3. Incorporated 3D dynamic features (metric depth, head dynamics) into the generation pipeline to enhance spatial grounding and realism."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/157e088cb49368b1dbc239ff6380ef8897576c9c3fa92a5bf6737c3a5029e927_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/157e088cb49368b1dbc239ff6380ef8897576c9c3fa92a5bf6737c3a5029e927_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles the challenge of generating realistic and spatially aligned 3D human reactions from egocentric video streams. The authors propose EgoReAct, an autoregressive framework that uses a VQ-VAE and a GPT to generate motions in real-time, enhanced by 3D features. Experiments show the method achieves superior realism, spatial consistency, and efficiency while maintaining strict causality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[EgoReAct: Egocentric Video-Driven 3D Human Reaction Generation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u6570\u636e\u7a7a\u95f4\u4e0d\u4e00\u81f4/Existing data spatial misalignment]\n    B --\x3e B2[\u56e0\u679c\u751f\u6210\u4e0e3D\u5bf9\u9f50\u7684\u6311\u6218/Causal generation & 3D alignment challenge]\n    C --\x3e C1[\u6784\u5efaHRD\u6570\u636e\u96c6/Build HRD dataset]\n    C --\x3e C2[VQ-VAE\u538b\u7f29\u8fd0\u52a8/VQ-VAE compresses motion]\n    C --\x3e C3[GPT\u81ea\u56de\u5f52\u751f\u6210/GPT autoregressive generation]\n    C --\x3e C4[\u878d\u51653D\u52a8\u6001\u7279\u5f81/Incorporate 3D dynamic features]\n    D --\x3e D1[\u66f4\u9ad8\u7684\u771f\u5b9e\u611f\u4e0e\u7a7a\u95f4\u4e00\u81f4\u6027/Higher realism & spatial consistency]\n    D --\x3e D2[\u5b9e\u65f6\u751f\u6210\u6548\u7387/Real-time generation efficiency]\n    D --\x3e D3[\u4fdd\u6301\u4e25\u683c\u56e0\u679c\u6027/Maintains strict causality]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] FasterPy: An LLM-based Code Execution Efficiency Optimization Framework"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [Code Optimization, Retrieval-Augmented Generation (RAG), Low-Rank Adaptation (LoRA), Large Language Models (LLMs), Python]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yue Wu, Minghao Han, Ruiyin Li, Peng Liang, Amjed Tahir, Zengyang Li, Qiong Feng, Mojtaba Shahin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wuhan University, Carnegie Mellon University, Massey University, Central China Normal University, Nanjing University of Science and Technology, RMIT University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22827",children:"https://arxiv.org/pdf/2512.22827"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/WuYue22/fasterpy",children:"https://github.com/WuYue22/fasterpy"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes FasterPy, a low-cost and efficient framework that adapts LLMs for Python code execution efficiency optimization. 2. Combines Retrieval-Augmented Generation (RAG) with a knowledge base of performance-improving code pairs and Low-Rank Adaptation (LoRA) to enhance optimization performance. 3. Demonstrates superior performance over existing models on the Performance Improving Code Edits (PIE) benchmark."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces FasterPy, a framework that uses Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG) and Low-Rank Adaptation (LoRA) to automatically optimize Python code for better execution efficiency. It addresses the limitations of traditional rule-based and data-intensive ML methods by providing a more scalable and cost-effective solution. Experimental results show that FasterPy outperforms existing models on standard benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FasterPy: An LLM-based Code Execution Efficiency Optimization Framework] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u53ef\u6269\u5c55\u6027\u5dee/Traditional methods are costly and hard to scale]\n    C --\x3e C1[\u7ed3\u5408RAG\u4e0eLoRA\u7684LLM\u6846\u67b6/LLM framework combining RAG and LoRA]\n    D --\x3e D1[\u5728PIE\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02/Outperforms existing models on PIE benchmark]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [automated environment synthesis, environment-level RL, agentic reinforcement learning, simulated user, policy optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tongyi Lab, Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22857",children:"https://arxiv.org/pdf/2512.22857"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AutoForge] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73af\u5883\u5408\u6210\u534a\u81ea\u52a8/Semi-automated Environment Synthesis]\n    B --\x3e B2[\u4efb\u52a1\u96be\u5ea6\u4e0d\u8db3/Insufficient Task Difficulty]\n    B --\x3e B3[\u6a21\u62df\u7528\u6237\u4e0d\u7a33\u5b9a/Simulated User Instability]\n    C --\x3e C1[\u81ea\u52a8\u5316\u73af\u5883\u5408\u6210\u7ba1\u9053/Automated Environment Synthesis Pipeline]\n    C --\x3e C2[\u73af\u5883\u7ea7RL\u7b97\u6cd5/Environment-level RL Algorithm (ERPO)]\n    D --\x3e D1[\u57fa\u51c6\u6d4b\u8bd5\u6709\u6548/Effective on Benchmarks (\u03c4-bench, etc.)]\n    D --\x3e D2[\u57df\u5916\u6cdb\u5316\u5f3a/Strong Out-of-domain Generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:'[arXiv251230] The body is not there to compute: Comment on "Informational embodiment: Computational role of information structure in codes and robots" by Pitti et al'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [embodied cognition, robotics], [morphological computation, embodiment, information theory, passive dynamic walker]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Matej Hoffmann"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Czech Technical University in Prague"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22868",children:"https://arxiv.org/pdf/2512.22868"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Critiques the application of computational and informational frameworks to biological and robotic bodies, arguing it is a misleading metaphor. 2. Distinguishes between the physical, non-computational role of body morphology and the metaphorical concept of "morphological computation". 3. Proposes that the primary function of bodies is not to compute, challenging a core premise of the target article.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c58366db344796ab1e3ca689f71030b6079280073a3b1974c0cb683e87c3918c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c58366db344796ab1e3ca689f71030b6079280073a3b1974c0cb683e87c3918c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This commentary argues against the central thesis of a target article that applies computational and informational concepts to understand animal and robot bodies. The author contends that the concept of "morphological computation" is merely a metaphor and that the body\'s main role is physical, not computational. The core conclusion is that bodies are not fundamentally for computing, challenging an informational embodiment perspective.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root[The body is not there to compute<br>\u8eab\u4f53\u4e0d\u662f\u4e3a\u4e86\u8ba1\u7b97] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>Is the body\'s primary role computational?<br>\u8eab\u4f53\u7684\u4e3b\u8981\u4f5c\u7528\u662f\u8ba1\u7b97\u5417\uff1f]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>Conceptual critique of "morphological computation"<br>\u5bf9"\u5f62\u6001\u8ba1\u7b97"\u7684\u6982\u5ff5\u6027\u6279\u5224]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results<br>Body\'s role is physical, not computational<br>\u8eab\u4f53\u7684\u4f5c\u7528\u662f\u7269\u7406\u7684\uff0c\u800c\u975e\u8ba1\u7b97\u7684]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22876",children:"https://arxiv.org/pdf/2512.22876"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Reinforcement Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: End-to-end training of multi-component AI systems]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: MARL agents organized in a DAG (Reinforcement Networks)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improved performance, unified framework for structured MARL]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SwinTF3D: A Lightweight Multimodal Fusion Approach for Text-Guided 3D Medical Image Segmentation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image segmentation], [multimodal fusion, text-guided segmentation, transformer-based architecture, lightweight model, 3D segmentation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hasan Faraz Khan, Noor Fatima, Muzammil Behzad"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," King Fahd University of Petroleum and Minerals, SDAIA-KFUPM Joint Research Center for Artificial Intelligence"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22878",children:"https://arxiv.org/pdf/2512.22878"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SwinTF3D, a lightweight multimodal fusion model for text-guided 3D medical image segmentation, integrating visual and linguistic representations. 2. Introduces an efficient fusion mechanism to align semantic text prompts with spatial structures in volumetric medical images. 3. Demonstrates competitive performance and significant efficiency gains on the BTCV dataset, offering a practical and interpretable paradigm for interactive clinical segmentation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/991651742357d8ab55dc27a29fa78a0c7b0f65e13d3fe1d6d260f8acea2238d9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/991651742357d8ab55dc27a29fa78a0c7b0f65e13d3fe1d6d260f8acea2238d9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes SwinTF3D, a lightweight multimodal model that uses a transformer-based visual encoder and a text encoder to perform text-guided 3D medical image segmentation. It achieves competitive accuracy on the BTCV dataset with low computational overhead, establishing a practical paradigm for interactive, resource-efficient clinical imaging."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[SwinTF3D: A Lightweight Multimodal Fusion Approach for Text-Guided 3D Medical Image Segmentation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Existing 3D segmentation models lack semantic understanding and adaptability to user-defined tasks] --\x3e Problem_Sub[\u95ee\u9898\u7ec6\u8282/Problem Details: Rely on visual-only learning, ineffective for flexible objectives]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Lightweight multimodal fusion of transformer-based visual encoder and compact text encoder] --\x3e Method_Sub[\u65b9\u6cd5\u7ec6\u8282/Method Details: Efficient fusion mechanism aligns semantic cues with spatial structures]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Achieves competitive Dice/IoU scores on BTCV dataset with low computational overhead] --\x3e Results_Sub[\u7ed3\u679c\u7ec6\u8282/Results Details: Generalizes well, offers efficiency gains, establishes an interpretable paradigm]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [cyber resilience], [agentic AI, game theory, autonomous agents, system-theoretic framework, equilibrium-based design]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tao Li, Quanyan Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," City University of Hong Kong, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22883",children:"https://arxiv.org/pdf/2512.22883"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a paradigm shift from prevention-centric security to agentic cyber resilience, arguing for systems that anticipate, maintain, recover, and learn under attack. 2. Develops a system-level framework and general architecture for designing AI workflows where autonomous agents participate in sensing, reasoning, and action. 3. Demonstrates how game-theoretic formulations provide a unifying design language for analyzing coupled attacker-defender workflows and enable equilibrium-based resiliency design, illustrated with case studies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1d5f82743a059040190978c2a78338bb73c72bc9cec9a0aafe00a0d12f0f24d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1d5f82743a059040190978c2a78338bb73c72bc9cec9a0aafe00a0d12f0f24d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper argues that the rise of foundation-model-based AI necessitates a shift from traditional prevention-focused cybersecurity to a new paradigm of agentic cyber resilience. It proposes a system-theoretic framework for designing autonomous AI workflows and uses game theory as a unifying language to model attacker-defender dynamics, concluding that equilibrium-based design enables system-level resilience as demonstrated in case studies like automated penetration testing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Traditional static, human-centered security architectures are mismatched with AI-driven, adaptive cyber threats.")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Proposes a shift to agentic cyber resilience and a system-level framework using game theory to design autonomous AI workflows.")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Equilibrium-based design enables system-level resiliency, illustrated through case studies in automated pentesting and cyber deception.")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DECEPTICON: How Dark Patterns Manipulate Web Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [dark patterns, web agents, adversarial robustness, deceptive UI, agent testing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Phil Cuvin, Hao Zhu, Diyi Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22894",children:"https://arxiv.org/pdf/2512.22894"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://agentdarkpatterns.org",children:"https://agentdarkpatterns.org"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DECEPTICON, a novel environment for testing dark patterns in isolation with 700 web navigation tasks, 2. Demonstrates that dark patterns successfully manipulate agent trajectories in over 70% of tasks, significantly higher than human susceptibility, 3. Shows that larger, more capable models are more susceptible to dark patterns, and existing countermeasures like in-context prompting and guardrail models fail to mitigate the risk effectively."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8998ab43971416f683709173f00be5e8d5373de89f15ac199ec42d645a75b8b6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8998ab43971416f683709173f00be5e8d5373de89f15ac199ec42d645a75b8b6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces DECEPTICON, a testing environment to evaluate how dark patterns manipulate web agents, revealing that these deceptive UI designs successfully steer agent actions in over 70% of tasks, with larger models being more vulnerable and current defenses ineffective. The findings highlight an urgent need for robust defenses against such manipulative designs in agent systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DECEPTICON: How Dark Patterns Manipulate Web Agents] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Dark patterns manipulate users and pose risks to agent robustness]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: DECEPTICON environment with 700 tasks to test dark patterns in isolation]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Dark patterns steer agents in >70% tasks, larger models more susceptible, defenses fail]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [benchmark evaluation], [scientific intelligence, hierarchical benchmark, multi-disciplinary evaluation, multimodal inputs, dependency-aware framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yaping Zhang, Qixuan Zhang, Xingquan Zhang, Zhiyuan Chen, Wenwen Zhuang, Yupu Liang, Lu Xiang, Yang Zhao, Jiajun Zhang, Yu Zhou, Chengqing Zong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of the Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22899",children:"https://arxiv.org/pdf/2512.22899"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces HiSciBench, a novel hierarchical benchmark spanning five levels (Scientific Literacy to Scientific Discovery) to evaluate the complete scientific workflow. 2. Provides a comprehensive, multi-disciplinary dataset of 8,735 instances across six scientific fields, supporting multimodal and cross-lingual inputs. 3. Establishes an integrated, dependency-aware evaluation framework that reveals significant performance gaps in foundation models, especially on higher-order discovery tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5d6954386f880faf48b86cfbd5d72eb78413ee39a02fe0f600306713ecc9bda_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5d6954386f880faf48b86cfbd5d72eb78413ee39a02fe0f600306713ecc9bda_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces HiSciBench, a hierarchical and multi-disciplinary benchmark designed to evaluate the full spectrum of scientific intelligence in foundation models, from basic literacy to creative discovery. It contains thousands of multimodal instances across six disciplines and uses a dependency-aware framework for evaluation. The evaluation of leading models shows a sharp performance decline on complex discovery tasks, highlighting a key capability gap and setting a new standard for assessing scientific AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Existing benchmarks are fragmented and fail to reflect the hierarchical, multi-disciplinary nature of real scientific inquiry.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes HiSciBench, a 5-level hierarchical benchmark covering six disciplines with multimodal support and an integrated evaluation framework.]\n    D[\u5173\u952e\u7ed3\u679c/Results: Models show a large performance gap (69% on basic tasks vs. 25% on discovery), establishing a new evaluation standard.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [Casing Collar Locator (CCL), ARM Cortex-M7, Depthwise Separable Convolutions, MACs, Inference Latency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Si-Yu Xiao, Xin-Di Zhao, Xiang-Zhan Wang, Tian-Hao Mao, Ying-Kai Liao, Xing-Yu Liao, Yu-Qiao Chen, Jun-Jie Wang, Shuang Liu, Tu-Pei Chen, Yang Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Electronic Science and Technology of China, China National Petroleum Corporation Logging Co., Ltd., Nanyang Technological University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22901",children:"https://arxiv.org/pdf/2512.22901"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes an in-situ, real-time collar recognition system using embedded neural networks to overcome signal degradation in traditional surface-based monitoring. 2. Introduces lightweight "Collar Recognition Nets" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors, using temporal and depthwise separable convolutions. 3. Demonstrates a highly efficient model achieving 8,208 MACs, an F1 score of 0.972, and an average inference latency of 343.2 \xb5s, proving feasibility for downhole power/space constraints.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/235a8bd15d5c0da93f1ea31dd4b6da44b238cc7be57fd42a7bef3e629f9c6495_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/235a8bd15d5c0da93f1ea31dd4b6da44b238cc7be57fd42a7bef3e629f9c6495_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the problem of accurate downhole positioning in oil/gas operations by developing a real-time, embedded neural network system for casing collar recognition. The method introduces lightweight "Collar Recognition Nets" optimized for ARM Cortex-M7 processors, achieving high accuracy with minimal computational cost. The results demonstrate that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Neural Network-Based Real-time Casing Collar Recognition System<br>\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u5b9e\u65f6\u5957\u7ba1\u63a5\u7b8d\u8bc6\u522b\u7cfb\u7edf"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u4fe1\u53f7\u8870\u51cf\u5bfc\u81f4\u4e95\u4e0b\u5b9a\u4f4d\u4e0d\u51c6\u786e<br>Signal degradation compromises downhole positioning"]\n    Method["\u4e3aARM Cortex-M7\u4f18\u5316\u7684\u8f7b\u91cf\u7ea7CRN\u7f51\u7edc<br>Lightweight CRNs optimized for ARM Cortex-M7"]\n    Results["8208 MACs, F1=0.972, 343.2\xb5s\u5ef6\u8fdf<br>8208 MACs, F1=0.972, 343.2\xb5s latency"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [hierarchical deep reinforcement learning, portfolio management, dynamic asset grouping, utility-based capital allocation, SHAP interpretability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xiaotian Ren, Nuerxiati Abudurexiti, Zhengyong Jiang, Angelos Stefanidis, Hongbin Liu, Jionglong Su"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22895",children:"https://arxiv.org/pdf/2512.22895"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a hierarchical DRL framework (SAMP-HDRL) that integrates dynamic asset grouping, upper-lower agent coordination, and a utility-based capital allocation mechanism for robust portfolio management. 2. Demonstrates superior performance through extensive backtests across multiple market regimes, showing consistent improvements in return and risk-adjusted metrics over traditional and DRL baselines. 3. Provides interpretability via SHAP analysis, revealing a complementary "diversified + concentrated" decision pattern across agent layers.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper tackles portfolio optimization in non-stationary markets by proposing SAMP-HDRL, a hierarchical deep reinforcement learning framework that segments assets, coordinates global and local agents, and uses a utility-based capital allocator. The method outperforms numerous baselines in backtests, achieving higher returns and risk-adjusted ratios, and its decisions are made interpretable through SHAP analysis, revealing a combined diversified and concentrated investment strategy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root[SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Portfolio optimization in non-stationary markets with regime shifts and limited DRL interpretability] --\x3e P1[\u6311\u6218/Challenges: Dynamic correlations, regime shifts]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Hierarchical DRL with segmented allocation] --\x3e M1[\u4e0a\u5c42\u4ee3\u7406/Upper-level Agent: Extracts global market signals]\n    Method --\x3e M2[\u52a8\u6001\u8d44\u4ea7\u5206\u7ec4/Dynamic Asset Grouping: Partitions market into subsets]\n    Method --\x3e M3[\u4e0b\u5c42\u4ee3\u7406/Lower-level Agents: Perform intra-group allocation]\n    Method --\x3e M4[\u6548\u7528\u8d44\u672c\u5206\u914d/Utility-based Capital Allocation: Integrates risky & risk-free assets]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Outperforms baselines, provides interpretability] --\x3e R1[\u6027\u80fd/Performance: Higher Return, Sharpe, Sortino, Omega ratios]\n    Results --\x3e R2[\u53ef\u89e3\u91ca\u6027/Interpretability: SHAP reveals "diversified + concentrated" mechanism]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Q-learning, ensemble learning, satisficing, distillation, bounded rationality]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," \xdcnver \xc7ift\xe7i"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tekirda\u011f Nam\u0131k Kemal University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22910",children:"https://arxiv.org/pdf/2512.22910"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a two-phase framework (Sat-EnQ) that first trains an ensemble of lightweight Q-networks using a satisficing objective to limit early value growth and reduce variance. 2. Provides theoretical proof that the satisficing objective induces bounded updates and cannot increase target variance, with a corollary for substantial reduction. 3. Demonstrates empirical results including significant variance reduction, elimination of catastrophic failures, robustness to noise, and improved compute efficiency compared to baseline methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the instability of deep Q-learning, especially early in training, by introducing Sat-EnQ. This framework first trains a satisficing ensemble of weak Q-learners to produce stable, low-variance estimates, then distills and fine-tunes the ensemble. The method significantly improves training reliability, robustness, and computational efficiency compared to standard approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Sat-EnQ] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Deep Q-Learning Instability]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Two-Phase Satisficing Ensemble]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Variance Reduction & Robustness]\n    B --\x3e B1[\u65e9\u671f\u8bad\u7ec3\u4e0d\u7a33\u5b9a/Early Training Instability]\n    B --\x3e B2[\u9ad8\u65b9\u5dee\u4e0e\u707e\u96be\u6027\u5931\u8d25/High Variance & Catastrophic Failure]\n    C --\x3e C1[\u9636\u6bb51: \u6ee1\u8db3\u5316\u96c6\u6210\u8bad\u7ec3/Phase 1: Satisficing Ensemble Training]\n    C --\x3e C2[\u9636\u6bb52: \u84b8\u998f\u4e0e\u5fae\u8c03/Phase 2: Distillation & Fine-tuning]\n    D --\x3e D1[3.8\u500d\u65b9\u5dee\u964d\u4f4e/3.8x Variance Reduction]\n    D --\x3e D2[0%\u707e\u96be\u6027\u5931\u8d25/0% Catastrophic Failure]\n    D --\x3e D3[2.5\u500d\u8ba1\u7b97\u6548\u7387\u63d0\u5347/2.5x Compute Efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Multimodal Fact-Checking: An Agent-based Approach"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal fact-checking], [multimodal misinformation, agent-based reasoning, explainable dataset, vision-language models, evidence retrieval]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Singapore (NUS)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22933",children:"https://arxiv.org/pdf/2512.22933"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces RW-Post, a high-quality, explainable dataset for real-world multimodal fact-checking that aligns claims with original social media posts and provides detailed reasoning and evidence. 2. Proposes AgentFact, a novel agent-based multimodal fact-checking framework that emulates the human verification workflow through five specialized, collaboratively working agents. 3. Demonstrates that the synergy between the new dataset and the agent framework substantially improves both the accuracy and interpretability of multimodal fact-checking."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bbe58d9ac10920f1b315029a664c297bd8051834b3724dbf3fa80f26372bec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bbe58d9ac10920f1b315029a664c297bd8051834b3724dbf3fa80f26372bec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of automated multimodal fact-checking by introducing a new dataset (RW-Post) and an agent-based framework (AgentFact). The dataset provides real-world misinformation instances with reasoning and evidence, while the framework uses specialized agents to collaboratively perform verification tasks. The combined approach is shown to significantly enhance the accuracy and explainability of fact-checking systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Multimodal Fact-Checking: An Agent-based Approach] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u4e0e\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u7406\u548c\u8bc1\u636e\u5229\u7528\u4e0a\u7684\u4e0d\u8db3 / The spread of multimodal misinformation and the limitations of existing methods in reasoning and evidence utilization]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faRW-Post\u6570\u636e\u96c6\u548cAgentFact\u667a\u80fd\u4f53\u6846\u67b6 / Proposes the RW-Post dataset and the AgentFact agent-based framework]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027 / Substantially improves the accuracy and interpretability of multimodal fact-checking]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Geometric Structural Knowledge Graph Foundation Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [knowledge graph reasoning], [structural foundation model, geometric attention, inductive link prediction, multi-head transformation, relational fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ling Xin, Mojtaba Nayyeri, Zahra Makki Nayeri, Steffen Staab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Stuttgart, University of Southampton, Shahrood University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22931",children:"https://arxiv.org/pdf/2512.22931"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Gamma, a novel structural KG foundation model that replaces the single relational transformation with multiple parallel geometric transformations (real, complex, split-complex, dual). 2. Introduces a relational conditioned attention fusion mechanism with entropy regularization to adaptively fuse these geometric representations at the link level. 3. Provides a full formalization of the algebraic message functions and demonstrates through extensive experiments on 56 KGs that Gamma consistently outperforms the prior state-of-the-art (Ultra) in zero-shot inductive link prediction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1926af9f65861ace968c86c6c18e3eaa892e2114d0d505e3fce8a7ae39975f1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1926af9f65861ace968c86c6c18e3eaa892e2114d0d505e3fce8a7ae39975f1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies a key limitation in existing structural knowledge graph foundation models: their reliance on a single relational transformation limits their ability to capture diverse relational patterns. To address this, the authors propose Gamma, a new model that employs multi-head geometric attention, using parallel transformations from different algebraic spaces and a fusion mechanism to adaptively combine them. Comprehensive experiments show that Gamma outperforms the previous best model, Ultra, in zero-shot inductive link prediction across diverse benchmarks, demonstrating the benefit of complementary geometric representations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Geometric Structural Knowledge Graph Foundation Model] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u5173\u7cfb\u8f6c\u6362\uff0c\u8868\u8fbe\u80fd\u529b\u53d7\u9650/Existing methods rely on single relational transformation, limiting expressiveness]\n    C --\x3e C1[\u5f15\u5165\u591a\u5934\u51e0\u4f55\u6ce8\u610f\u529b/Multi-head geometric attention]\n    C --\x3e C2[\u5e76\u884c\u591a\u79cd\u51e0\u4f55\u53d8\u6362/Parallel geometric transformations]\n    C --\x3e C3[\u5173\u7cfb\u6761\u4ef6\u6ce8\u610f\u529b\u878d\u5408/Relational conditioned attention fusion]\n    D --\x3e D1[\u572856\u4e2aKG\u4e0a\u8d85\u8d8aULTRA/Outperforms ULTRA on 56 KGs]\n    D --\x3e D2[\u96f6\u6837\u672c\u5f52\u7eb3\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u63d0\u5347/Improves zero-shot inductive link prediction]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Heterogeneity in Multi-Agent Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [heterogeneity, multi-agent reinforcement learning, parameter sharing, heterogeneity distance, dynamic algorithm]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tianyi Hu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu, Min Chen, Xin Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22941",children:"https://arxiv.org/pdf/2512.22941"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Harry67Hu/HetDPS",children:"https://github.com/Harry67Hu/HetDPS"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a systematic categorization of heterogeneity in MARL into five types with mathematical definitions. 2. Defines a heterogeneity distance and introduces a practical method to quantify agent heterogeneity. 3. Designs a heterogeneity-based dynamic parameter sharing algorithm that demonstrates better interpretability and adaptability compared to baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL). It proposes a methodology to define, quantify, and utilize heterogeneity, culminating in a dynamic parameter sharing algorithm. Experiments show this algorithm offers improved interpretability and adaptability over other parameter-sharing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Heterogeneity in Multi-Agent Reinforcement Learning<br/>\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5f02\u8d28\u6027"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u7f3a\u4e4f\u5bf9\u5f02\u8d28\u6027\u7684\u4e25\u683c\u5b9a\u4e49<br/>Lacks rigorous definition of heterogeneity"]\n    Method --\x3e M1["\u5b9a\u4e49\u4e0e\u5206\u7c7b<br/>Definition & Categorization"]\n    Method --\x3e M2["\u91cf\u5316\u65b9\u6cd5<br/>Quantification Method"]\n    Method --\x3e M3["\u5e94\u7528\u7b97\u6cd5<br/>Application Algorithm"]\n    M1 --\x3e M1_1["\u4e94\u7c7b\u5f02\u8d28\u6027<br/>Five types of heterogeneity"]\n    M2 --\x3e M2_1["\u5f02\u8d28\u6027\u8ddd\u79bb<br/>Heterogeneity distance"]\n    M3 --\x3e M3_1["\u52a8\u6001\u53c2\u6570\u5171\u4eab<br/>Dynamic Parameter Sharing"]\n    Results --\x3e R1["\u6709\u6548\u8bc6\u522b\u4e0e\u91cf\u5316<br/>Effective identification & quantification"]\n    Results --\x3e R2["\u7b97\u6cd5\u6027\u80fd\u4f18\u8d8a<br/>Algorithm outperforms baselines"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] APO: Alpha-Divergence Preference Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (rlhf)], [alpha-divergence, preference optimization, mode collapse, anchored coordinates, gradient variance]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wang Zixian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," China Mobile Communications Group Shandong Co., Ltd. Tai\u2019an Branch"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22953",children:"https://arxiv.org/pdf/2512.22953"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces APO, an anchored framework using Csisz\xe1r alpha-divergence to continuously interpolate between forward and reverse KL behavior for RLHF. 2. Derives unified gradient dynamics parameterized by alpha and analyzes gradient variance properties. 3. Proposes a practical reward-and-confidence-guarded alpha schedule to transition from mode-covering to mode-seeking behavior safely."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the trade-off between stable but under-exploitative mode-covering updates and high-reward but unstable mode-seeking updates in LLM alignment. It proposes APO, an anchored preference optimization framework that uses alpha-divergence to smoothly interpolate between these regimes via a guarded schedule. Experiments show APO achieves competitive performance while maintaining training stability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[APO: Alpha-Divergence Preference Optimization] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4e24\u79cd\u5206\u6b67\u6743\u8861 / Two Divergence Trade-off]\n    P1 --\x3e P2[\u524d\u5411KL\u8986\u76d6\u4f46\u4fdd\u5b88 / Forward KL: Mode-Covering but Conservative]\n    P1 --\x3e P3[\u53cd\u5411KL\u5bfb\u6c42\u4f46\u6613\u5d29\u6e83 / Reverse KL: Mode-Seeking but Collapses]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u951a\u5b9a\u6846\u67b6 / Anchored Framework]\n    M1 --\x3e M2[\u4f7f\u7528\u03b1-\u6563\u5ea6\u63d2\u503c / Use \u03b1-Divergence to Interpolate]\n    M2 --\x3e M3[\u8c03\u5ea6\u03b1\u503c / Schedule \u03b1 Value]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7ade\u4e89\u6027\u6027\u80fd / Competitive Performance]\n    Results --\x3e R2[\u4fdd\u6301\u7a33\u5b9a\u6027 / Maintains Training Stability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] OpenGround: Active Cognition-based Reasoning for Open-World 3D Visual Grounding"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D visual grounding], [open-world, zero-shot, active cognition-based reasoning, object lookup table, visual language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenyuan Huang, Zhao Wang, Zhou Wei, Ting Huang, Fang Zhao, Jian Yang, Zhenyu Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University, China Mobile Zijin Innovation Institute"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23020",children:"https://arxiv.org/pdf/2512.23020"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes OpenGround, a novel zero-shot framework for open-world 3D visual grounding that overcomes the limitation of pre-defined object categories. 2. Introduces the Active Cognition-based Reasoning (ACR) module to progressively augment VLM cognition via a cognitive task chain and a dynamically updated Object Lookup Table (OLT). 3. Presents a new dataset named OpenTarget with over 7000 object-description pairs to evaluate open-world 3D grounding performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dca85890cab234049b1698ab9f6ade12ea02b16f297cec04cbcb907dcdffb7be_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dca85890cab234049b1698ab9f6ade12ea02b16f297cec04cbcb907dcdffb7be_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of existing 3D visual grounding methods that rely on a pre-defined object lookup table, which restricts their use in open-world scenarios. The authors propose OpenGround, a zero-shot framework featuring an Active Cognition-based Reasoning module that dynamically expands the model's cognitive scope to handle undefined objects. The method achieves competitive or state-of-the-art results on standard benchmarks and shows a 17.6% improvement on their new OpenTarget dataset."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[OpenGround: Active Cognition-based Reasoning for Open-World 3D Visual Grounding] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u5bf9\u8c61\u8868\uff0c\u65e0\u6cd5\u5904\u7406\u672a\u5b9a\u4e49\u76ee\u6807/Existing methods rely on pre-defined OLT, limiting open-world application]\n    C --\x3e C1[\u63d0\u51faOpenGround\u6846\u67b6\u4e0e\u4e3b\u52a8\u8ba4\u77e5\u63a8\u7406\u6a21\u5757/Propose OpenGround framework with Active Cognition-based Reasoning (ACR) module]\n    C1 --\x3e C2[\u901a\u8fc7\u8ba4\u77e5\u4efb\u52a1\u94fe\u548c\u52a8\u6001\u66f4\u65b0\u7684OLT\u589e\u5f3aVLM\u8ba4\u77e5/Enhance VLM cognition via cognitive task chain and dynamically updated OLT]\n    D --\x3e D1[Nr3D\u4e0a\u8868\u73b0\u6709\u7ade\u4e89\u529b\uff0cScanRefer\u4e0a\u8fbe\u5230SOTA/Competitive on Nr3D, SOTA on ScanRefer]\n    D --\x3e D2[\u5728OpenTarget\u6570\u636e\u96c6\u4e0a\u63d0\u534717.6%/17.6% improvement on OpenTarget dataset]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] LENS: LLM-Enabled Narrative Synthesis for Mental Health by Aligning Multimodal Sensing with Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [multimodal language models], [multimodal sensing, time-series encoding, ecological momentary assessment (EMA)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenxuan Xu, Arvind Pillai, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dartmouth College, University of Virginia, Massachusetts General Hospital, Harvard Medical School"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23025",children:"https://arxiv.org/pdf/2512.23025"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces LENS, a framework that aligns multimodal sensing data with language models to generate clinically grounded mental health narratives. 2. Constructs a large-scale dataset of over 100,000 sensor-text QA pairs by transforming Ecological Momentary Assessment (EMA) responses. 3. Trains a patch-level encoder to project raw sensor time-series signals directly into an LLM's representation space for native integration."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b276805556458f16b63a7994f848b1c3a3a24eeed8ecb80496361d925fb9d8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b276805556458f16b63a7994f848b1c3a3a24eeed8ecb80496361d925fb9d8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of translating long-duration, multimodal sensor data into interpretable natural language for mental health assessment. It proposes the LENS framework, which creates a large sensor-text dataset and trains a specialized encoder to align sensor signals with an LLM, enabling the generation of clinically meaningful narratives. The results show LENS outperforms baselines on NLP and clinical metrics, and is validated by mental health professionals."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[LENS: LLM-Enabled Narrative Synthesis] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u4f20\u611f\u5668\u6570\u636e\u96be\u4ee5\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00/Sensor data hard to translate to text]\n    Problem --\x3e P2[\u7f3a\u4e4f\u914d\u5bf9\u6570\u636e\u96c6/Lack of paired sensor-text datasets]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u6784\u5efa\u5927\u89c4\u6a21\u4f20\u611f\u5668-\u6587\u672cQA\u6570\u636e\u96c6/Build large-scale sensor-text QA dataset]\n    Method --\x3e M2[\u8bad\u7ec3\u8865\u4e01\u7ea7\u7f16\u7801\u5668\u5bf9\u9f50LLM/Train patch-level encoder to align with LLM]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u5728NLP\u548c\u75c7\u72b6\u6307\u6807\u4e0a\u8d85\u8d8a\u57fa\u7ebf/Outperforms baselines on NLP & symptom metrics]\n    Results --\x3e R2[\u4e34\u5e8a\u533b\u751f\u8ba4\u4e3a\u53d9\u8ff0\u5168\u9762\u6709\u610f\u4e49/Clinicians find narratives comprehensive & meaningful]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] An Architecture-Led Hybrid Report on Body Language Detection Project"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video understanding], [vision-language models, structured generation, bounding boxes, mixture-of-experts, video analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Thomson Tong, Diba Darooneh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," None"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23028",children:"https://arxiv.org/pdf/2512.23028"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," BodyLanguageDetection repository [1]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides an architecture-led analysis of two modern VLMs (Qwen2.5-VL-7B-Instruct and Llama-4-Scout-17B-16E-Instruct) for a practical task. 2. Maps model architectural properties to a concrete video-to-artifact pipeline for person detection and attribute extraction. 3. Explicitly defines and analyzes critical system constraints and limitations arising from model behavior, such as semantic vs. syntactic correctness and frame-local identifiers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This report analyzes two vision-language models (VLMs) and connects their architectures to a practical system for detecting people and their emotions in video frames. The system prompts VLMs to generate structured outputs like bounding boxes, validates the output structure, and can render annotated videos. The core conclusion is that understanding model architecture is crucial for designing robust interfaces and making defensible claims, as VLMs can produce syntactically correct but semantically incorrect outputs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[An Architecture-Led Hybrid Report on Body Language Detection Project] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5982\u4f55\u57fa\u4e8eVLM\u67b6\u6784\u6784\u5efa\u53ef\u9760\u7684\u5e94\u7528\u7cfb\u7edf/How to build reliable application systems based on VLM architecture]\n    C --\x3e C1[\u5206\u6790\u4e24\u79cdVLM\u67b6\u6784\u5e76\u6620\u5c04\u5230\u89c6\u9891\u5904\u7406\u6d41\u7a0b/Analyze two VLM architectures and map to a video processing pipeline]\n    C --\x3e C2[\u7cfb\u7edf\u91c7\u6837\u89c6\u9891\u5e27\uff0c\u63d0\u793aVLM\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa/System samples video frames, prompts VLM for structured output]\n    C --\x3e C3[\u4f7f\u7528\u9884\u5b9a\u4e49\u6a21\u5f0f\u9a8c\u8bc1\u8f93\u51fa\u7ed3\u6784/Validate output structure with predefined schema]\n    D --\x3e D1[\u7ed3\u6784\u5316\u8f93\u51fa\u53ef\u80fd\u8bed\u6cd5\u6b63\u786e\u4f46\u8bed\u4e49\u9519\u8bef/Structured outputs can be syntactically valid but semantically incorrect]\n    D --\x3e D2[\u6a21\u5f0f\u9a8c\u8bc1\u662f\u7ed3\u6784\u6027\u7684\uff0c\u975e\u51e0\u4f55\u6b63\u786e\u6027/Schema validation is structural, not geometric]\n    D --\x3e D3[\u7406\u89e3\u67b6\u6784\u5bf9\u8bbe\u8ba1\u7a33\u5065\u63a5\u53e3\u548c\u8bc4\u4f30\u81f3\u5173\u91cd\u8981/Understanding architecture is critical for robust interface design and evaluation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Viability and Performance of a Private LLM Server for SMBs: A Benchmark Analysis of Qwen3-30B on Consumer-Grade Hardware"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [quantization, mixture-of-experts, on-premise deployment, consumer-grade hardware, benchmark analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alex Khalil, Guillaume Heilles, Maria Parraga, Simon Heilles"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," UCLouvain, Universidad Esp\xedritu Santo, DENEM Labs"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23029",children:"https://arxiv.org/pdf/2512.23029"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive benchmarking framework for evaluating both the intrinsic model capabilities and the server-side performance (latency, throughput, scalability) of a private LLM deployment. 2. A practical demonstration and performance analysis of deploying a quantized, large-scale (30B parameter) Mixture-of-Experts model (Qwen3) on next-generation consumer-grade hardware (NVIDIA RTX 5090). 3. Evidence that a carefully configured on-premises LLM server can achieve performance comparable to cloud services, offering SMBs a viable, cost-effective, and privacy-preserving alternative."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the feasibility of deploying a private, high-performance LLM server for Small and Medium Businesses using consumer-grade hardware. It benchmarks a quantized Qwen3-30B model on an NVIDIA RTX 5090, evaluating both model capability and server performance under load. The results show that such an on-premises setup can achieve performance close to cloud services at a lower cost and with full data privacy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Viability and Performance of a Private LLM Server for SMBs<br>SMB\u79c1\u6709LLM\u670d\u52a1\u5668\u7684\u53ef\u884c\u6027\u4e0e\u6027\u80fd] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Cloud reliance: cost, privacy, sovereignty for SMBs<br>\u4e91\u4f9d\u8d56\uff1a\u6210\u672c\u3001\u9690\u79c1\u3001SMB\u4e3b\u6743]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Benchmark quantized Qwen3-30B on consumer hardware (RTX 5090)<br>\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u5bf9\u91cf\u5316Qwen3-30B\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>On-premises performance rivals cloud, viable for SMBs<br>\u672c\u5730\u6027\u80fd\u5ab2\u7f8e\u4e91\u7aef\uff0c\u5bf9SMB\u53ef\u884c]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [interpretability], [chain-of-thought, faithfulness, causal mediation analysis, biasing features, explainability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kerem Zaman, Shashank Srivastava"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," UNC Chapel Hill"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23032",children:"https://arxiv.org/pdf/2512.23032"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Argues that the Biasing Features metric conflates unfaithfulness with incompleteness in Chain-of-Thought explanations. 2. Introduces a new faithful@k metric showing increased token budgets improve hint verbalization. 3. Uses Causal Mediation Analysis to show non-verbalized hints can still causally mediate predictions through the CoT."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper challenges the use of hint-verbalization metrics like Biasing Features for evaluating the faithfulness of Chain-of-Thought reasoning. It proposes that apparent unfaithfulness is often due to incompleteness from lossy compression and tight token limits, not a lack of alignment, and demonstrates this using new metrics and causal mediation analysis. The conclusion advocates for a broader interpretability toolkit beyond hint-based evaluations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Is Chain-of-Thought Really Not Explainability?<br/>Chain-of-Thought Can Be Faithful without Hint Verbalization] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Biasing Features \u6307\u6807\u5c06\u4e0d\u5b8c\u6574\u6027\u8bef\u5224\u4e3a\u4e0d\u5fe0\u5b9e\u6027<br/>Biasing Features metric mislabels incompleteness as unfaithfulness]\n    C --\x3e C1[\u63d0\u51fa faithful@k \u6307\u6807\u5e76\u589e\u52a0\u63a8\u7406\u4ee4\u724c\u9884\u7b97<br/>Propose faithful@k metric & increase inference token budget]\n    C --\x3e C2[\u4f7f\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790<br/>Use Causal Mediation Analysis]\n    D --\x3e D1[\u8bb8\u591a\u88ab\u6807\u8bb0\u4e3a\u4e0d\u5fe0\u5b9e\u7684 CoT \u88ab\u5176\u4ed6\u6307\u6807\u5224\u5b9a\u4e3a\u5fe0\u5b9e<br/>Many CoTs flagged unfaithful are judged faithful by other metrics]\n    D --\x3e D2[\u66f4\u5927\u7684\u4ee4\u724c\u9884\u7b97\u663e\u8457\u63d0\u9ad8\u63d0\u793a\u8bcd\u663e\u5316\u7387<br/>Larger token budgets greatly increase hint verbalization]\n    D --\x3e D3[\u672a\u663e\u5316\u7684\u63d0\u793a\u8bcd\u4ecd\u53ef\u901a\u8fc7 CoT \u56e0\u679c\u4e2d\u4ecb\u9884\u6d4b<br/>Non-verbalized hints can causally mediate predictions through CoT]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [educational data mining], [knowledge tracing, learner modelling, temporal coherence, fine-tuning, deep knowledge tracing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Danial Hooshyar, Yeongwook Yang, Gustav \u0160\xed\u0159, Tommi K\xe4rkk\xe4inen, Raija H\xe4m\xe4l\xe4inen, Mutlu Cukurova, Roger Azevedo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tallinn University, University of Jyv\xe4skyl\xe4, Gangneung-Wonju National University, Czech Technical University, University College London, University of Central Florida"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23036",children:"https://arxiv.org/pdf/2512.23036"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a synthesis of evidence on the limitations of LLM-based tutors, framing them within the high-risk context of K-12 education and responsible AI design. 2. Empirically demonstrates that a Deep Knowledge Tracing (DKT) model significantly outperforms a widely-used LLM (both zero-shot and fine-tuned) in next-step correctness prediction and temporal coherence of mastery estimation. 3. Highlights the computational inefficiency of fine-tuning LLMs for this task compared to DKT, and argues for hybrid frameworks over LLM-only approaches for responsible tutoring."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5735716766e72627a0d5d23b01771e8d0161795e3958d394eccf1045f5a797ec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5735716766e72627a0d5d23b01771e8d0161795e3958d394eccf1045f5a797ec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether large language models (LLMs) can effectively replace traditional learner modelling for adaptive tutoring in K-12 education. By comparing a Deep Knowledge Tracing (DKT) model against a fine-tuned and zero-shot LLM on knowledge assessment tasks, it finds DKT is more accurate, reliable, and temporally coherent. The study concludes that LLMs alone are insufficient for responsible tutoring and advocates for hybrid systems that incorporate dedicated learner models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Problems With LLMs for Learner Modelling<br/>LLM\u5728\u5b66\u60c5\u5efa\u6a21\u4e2d\u7684\u95ee\u9898"] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B["\u6838\u5fc3\u95ee\u9898/Problem<br/>LLMs may replace learner models<br/>LLM\u53ef\u80fd\u66ff\u4ee3\u5b66\u60c5\u6a21\u578b"] --\x3e B1["\u9ad8\u98ce\u9669\u9886\u57df/High-risk domain (K-12)"]\n    B --\x3e B2["\u9700\u8981\u8bc4\u4f30\u51c6\u786e\u6027\u3001\u53ef\u9760\u6027\u3001\u65f6\u5e8f\u4e00\u81f4\u6027/Need to assess accuracy, reliability, temporal coherence"]\n    C["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Compare DKT vs. LLM<br/>\u5bf9\u6bd4DKT\u4e0eLLM"] --\x3e C1["\u6570\u636e\u96c6/Dataset: large open-access"]\n    C --\x3e C2["\u6a21\u578b/Models: DKT, LLM (zero-shot & fine-tuned)"]\n    D["\u5173\u952e\u7ed3\u679c/Results<br/>DKT outperforms LLM<br/>DKT\u4f18\u4e8eLLM"] --\x3e D1["\u66f4\u9ad8AUC/Higher AUC (0.83)"]\n    D --\x3e D2["\u66f4\u597d\u7684\u65f6\u5e8f\u4e00\u81f4\u6027/Better temporal coherence"]\n    D --\x3e D3["\u7ed3\u8bba: LLMs alone fall short, need hybrid frameworks<br/>Conclusion: LLM\u5355\u72ec\u4e0d\u8db3\uff0c\u9700\u8981\u6df7\u5408\u6846\u67b6"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Reward Model Selection Crisis in Personalized Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [alignment & personalization], [reward-guided decoding, policy accuracy, Pref-LaMP benchmark]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Fady Rezk, Yuangang Pan, Chuan-Sheng Foo, Xun Xu, Nancy Chen, Henry Gouk, Timothy Hospedales"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Edinburgh, Agency for Science, Technology and Research (A*STAR)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23067",children:"https://arxiv.org/pdf/2512.23067"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies and demonstrates the failure of standard reward model (RM) accuracy as a selection criterion for deployment-ready personalized alignment. 2. Introduces a new metric, policy accuracy, to evaluate the token-level discrimination ability of reward models under inference-time adaptation (reward-guided decoding). 3. Introduces Pref-LaMP, the first personalized alignment benchmark with ground-truth user completions, enabling direct behavioral evaluation and revealing a decoupling between reward discrimination and actual generation quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1a0a1bd7d940db8c394f189ea84b7dbcfae7cd34b8e3662ea7c7a8babfdfefe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1a0a1bd7d940db8c394f189ea84b7dbcfae7cd34b8e3662ea7c7a8babfdfefe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies a crisis in personalized alignment, showing that optimizing reward models for preference ranking accuracy does not translate to effective behavioral adaptation under realistic deployment constraints like reward-guided decoding. The authors propose a new metric (policy accuracy) and a new benchmark (Pref-LaMP) to evaluate this gap, finding that reward model accuracy poorly predicts generation quality and that simple in-context learning often outperforms reward-guided methods for larger models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Reward Model Selection Crisis in Personalized Alignment] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Standard RM accuracy fails to predict deployment performance for personalized alignment]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Introduce policy accuracy metric and Pref-LaMP benchmark for direct evaluation]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Weak correlation between RM & policy accuracy; ICL outperforms reward-guided decoding]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Trust Region Masking for Long-Horizon LLM Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [trust region, policy gradient, off-policy mismatch, KL divergence, sequence-level masking]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yingru Li, Jiacai Liu, Jiawei Xu, Yuxuan Tong, Ziniu Li, Baoxiang Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," (Institutions not explicitly listed in provided content; inferred from author names and common affiliations in the field, but not specified. Therefore, output is left blank.)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23075",children:"https://arxiv.org/pdf/2512.23075"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Deriving two novel, tighter theoretical bounds (Pinsker-Marginal and Mixed) on the approximation error in off-policy LLM-RL, scaling better with sequence length than classical O(T^2) bounds. 2. Identifying that these bounds depend on a sequence-level quantity (maximum token-level KL divergence) that cannot be controlled by token-independent methods like PPO clipping. 3. Proposing the Trust Region Masking (TRM) algorithm, which masks entire sequences from gradient updates to enforce the trust region, providing non-vacuous monotonic improvement guarantees for long-horizon tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74d8872516a568f2933a83e36b0cf25d414f3a25ffa113cd0cee809d2b39c6ac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74d8872516a568f2933a83e36b0cf25d414f3a25ffa113cd0cee809d2b39c6ac_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem that classical trust region bounds become vacuous for long-horizon LLM reinforcement learning due to unavoidable off-policy mismatch. It proposes Trust Region Masking (TRM), a method that excludes entire sequences from gradient computation if any token violates a trust region constraint. This approach, supported by new tighter theoretical bounds, provides the first non-vacuous monotonic improvement guarantees for long-horizon LLM-RL."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Trust Region Masking for Long-Horizon LLM RL] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Off-policy mismatch in LLM-RL<br/>\u5bfc\u81f4\u7ecf\u5178\u4fe1\u4efb\u57df\u8fb9\u754c\u5931\u6548]\n    C --\x3e C1[\u63d0\u51fa\u4fe1\u4efb\u57df\u63a9\u7801(TRM)<br/>Propose Trust Region Masking (TRM)]\n    C1 --\x3e C2[\u5e8f\u5217\u7ea7\u63a9\u7801<br/>Sequence-level Masking]\n    D --\x3e D1[\u63a8\u5bfc\u66f4\u7d27\u7684\u7406\u8bba\u8fb9\u754c<br/>Derive Tighter Bounds (O(T), O(T^{3/2}))]\n    D --\x3e D2[\u63d0\u4f9b\u975e\u5e73\u51e1\u7684\u5355\u8c03\u6539\u8fdb\u4fdd\u8bc1<br/>Provide Non-vacuous Guarantees]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Multimodal Functional Maximum Correlation for Emotion Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal learning], [self-supervised learning, dual total correlation, functional maximum correlation analysis, affective computing, physiological signals]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Deyang Zheng, Tianyi Zhang, Wenming Zheng, Shujian Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Southeast University, Westlake University, Vrije Universiteit Amsterdam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23076",children:"https://arxiv.org/pdf/2512.23076"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/DY9910/MFMC",children:"https://github.com/DY9910/MFMC"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel self-supervised learning framework (MFMC) that maximizes higher-order multimodal dependence using a Dual Total Correlation objective. 2. Derives a tight sandwich bound and optimizes it using a functional maximum correlation analysis-based trace surrogate to capture joint interactions. 3. Demonstrates state-of-the-art or competitive performance on affective computing benchmarks, showing robustness to inter-subject variability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of learning joint dynamics from scarce and subjective emotion labels by proposing a self-supervised learning framework called MFMC. It captures higher-order multimodal dependencies beyond pairwise alignment, leading to improved emotion recognition performance on physiological signal benchmarks. The results show significant accuracy gains, particularly in subject-independent settings, highlighting the method's effectiveness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MFMC for Emotion Recognition] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u60c5\u611f\u72b6\u6001\u8868\u73b0\u4e3a\u8de8\u7cfb\u7edf\u7684\u534f\u8c03\u4f46\u5f02\u8d28\u7684\u751f\u7406\u53cd\u5e94\uff0c\u73b0\u6709\u81ea\u76d1\u7763\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u591a\u6a21\u6001\u9ad8\u9636\u4ea4\u4e92\u3002]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faMFMC\u6846\u67b6\uff0c\u901a\u8fc7Dual Total Correlation\u76ee\u6807\u548cFunctional Maximum Correlation Analysis\u6700\u5927\u5316\u9ad8\u9636\u591a\u6a21\u6001\u4f9d\u8d56\u6027\u3002]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6216\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347CEAP-360VR\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\uff0c\u5bf9\u4e3b\u4f53\u95f4\u53d8\u5f02\u6027\u9c81\u68d2\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [reinforcement learning, training-inference mismatch, vocabulary pruning, gradient estimation, numerical stability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," (Institutions not explicitly listed in provided content. Affiliation inference requires author list with affiliations or email domains, which are not present in the given text. Therefore, cannot be determined from the provided snippet.)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23087",children:"https://arxiv.org/pdf/2512.23087"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proves that the training-inference mismatch in LLM RL has an asymmetric effect, where the bound on log-probability mismatch scales with (1-p), making low-probability "tail" tokens the primary source of instability. 2. Proposes a novel method to stabilize RL training by dynamically pruning the vocabulary to exclude the extreme tail tokens, trading large, biased mismatches for a small, bounded optimization bias. 3. Provides both empirical demonstration of stable training and a theoretical bound on the optimization bias introduced by the proposed vocabulary pruning.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper identifies a fundamental training-inference mismatch in LLM reinforcement learning caused by differing numerical precision between high-throughput inference and stable training systems. To address this, the authors propose dynamically pruning low-probability "tail" tokens from the vocabulary during RL optimization, which stabilizes training by replacing large, biased errors with a small, bounded bias. Both theoretical analysis and empirical results support the effectiveness of this method.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bad\u7ec3-\u63a8\u7406\u4e0d\u5339\u914d / Training-Inference Mismatch]\n    B1 --\x3e B2[\u5c3e\u90e8token\u5bfc\u81f4\u68af\u5ea6\u4e0d\u7a33\u5b9a / Tail tokens destabilize gradient estimation]\n    C --\x3e C1[\u52a8\u6001\u526a\u679d\u8bcd\u6c47\u8868 / Dynamic Vocabulary Pruning]\n    C1 --\x3e C2[\u6392\u9664\u6781\u7aef\u5c3e\u90e8token / Exclude extreme tail tokens]\n    D --\x3e D1[\u5b9e\u73b0\u7a33\u5b9a\u8bad\u7ec3 / Achieves stable training]\n    D --\x3e D2[\u7406\u8bba\u754c\u5b9a\u4f18\u5316\u504f\u5dee / Theoretically bounds optimization bias]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] MedSAM-based lung masking for multi-label chest X-ray classification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [MedSAM, lung segmentation, multi-label classification, chest X-ray, spatial prior]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Brayden Miao, Zain Rehman, Xin Miao, Siming Liu, Jianjie Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Missouri State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23089",children:"https://arxiv.org/pdf/2512.23089"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a segmentation-guided CXR classification pipeline that integrates a fine-tuned MedSAM model for lung region extraction. 2. Empirically demonstrates that the effect of lung masking is task-dependent and architecture-dependent, revealing a trade-off between abnormality classification and normal case screening. 3. Suggests that lung masking should be treated as a controllable spatial prior tailored to the model backbone and clinical objective, rather than a uniform preprocessing step."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78073436289f27d236dc3f5c9f70b55eb6480c3a7ea02e8c30b8eb1b8e59faa9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78073436289f27d236dc3f5c9f70b55eb6480c3a7ea02e8c30b8eb1b8e59faa9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a method that uses a fine-tuned MedSAM model to extract lung masks from chest X-rays to guide multi-label abnormality classification. The study finds that the impact of masking depends on the task and model architecture, with loose masking improving normal case screening while tight masking aids training efficiency. The conclusion is that lung masking should be a tunable spatial prior aligned with the specific clinical goal and model, not a fixed step."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MedSAM-based lung masking for multi-label chest X-ray classification] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Automated CXR interpretation is challenging<br>\u81ea\u52a8CXR\u89e3\u8bfb\u5177\u6709\u6311\u6218\u6027]\n    C --\x3e C1[Fine-tune MedSAM for lung segmentation<br>\u5fae\u8c03MedSAM\u8fdb\u884c\u80ba\u90e8\u5206\u5272]\n    C --\x3e C2[Use masks to guide multi-label classification<br>\u4f7f\u7528\u63a9\u7801\u6307\u5bfc\u591a\u6807\u7b7e\u5206\u7c7b]\n    D --\x3e D1[Masking effect is task/architecture dependent<br>\u63a9\u7801\u6548\u679c\u4f9d\u8d56\u4e8e\u4efb\u52a1\u548c\u67b6\u6784]\n    D --\x3e D2[Trade-off: abnormality vs. normal screening<br>\u6743\u8861\uff1a\u5f02\u5e38\u68c0\u6d4b\u4e0e\u6b63\u5e38\u7b5b\u67e5]\n    D --\x3e D3[Masking is a controllable spatial prior<br>\u63a9\u7801\u662f\u4e00\u79cd\u53ef\u63a7\u7684\u7a7a\u95f4\u5148\u9a8c]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yingru Li, Ziniu Li, Jiacai Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated in provided content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23097",children:"https://arxiv.org/pdf/2512.23097"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Hybrid Online RL and IL for LLMs] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Train-inference distribution mismatch in LLM fine-tuning]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Unified framework combining Imitation Learning and Reinforcement Learning]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Gradient decomposes into Dense Gradient (analytic) and Sparse Gradient (sampled)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [reinforcement learning, vision-language model, supervised fine-tuning, generalization paradox, cross-dataset transferability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fraunhofer IAIS, University of Bonn, Lamarr Institute, Department of Health Queensland, Griffith University, University Hospital Bonn"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23090",children:"https://arxiv.org/pdf/2512.23090"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced ChexReason, a resource-efficient vision-language model for medical imaging trained with an R1-style (SFT+GRPO) method using minimal data and compute. 2. Identified a fundamental tension where RL optimization (GRPO) improves in-distribution benchmark performance but significantly degrades cross-dataset generalization, a pattern also observed in high-resource models. 3. Discovered a generalization paradox where the SFT checkpoint uniquely improves cross-dataset performance, suggesting teacher-guided reasoning captures more institution-agnostic features than RL optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper investigates applying reinforcement learning (RL) to vision-language models for medical imaging, finding that while RL improves performance on the training benchmark, it harms the model's ability to generalize to new datasets. The authors conclude that for clinical robustness, curated supervised fine-tuning may be more effective than aggressive RL optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Benchmark Success, Clinical Failure<br>\u57fa\u51c6\u6210\u529f\uff0c\u4e34\u5e8a\u5931\u8d25] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[RL\u4f18\u5316\u63d0\u5347\u57fa\u51c6\u6027\u80fd\u4f46\u635f\u5bb3\u6cdb\u5316<br>RL improves benchmarks but harms generalization]\n    C --\x3e C1[\u4f7f\u7528SFT+GRPO\u8bad\u7ec3ChexReason VLM<br>Train ChexReason VLM with SFT+GRPO]\n    D --\x3e D1[GRPO\u63d0\u5347CheXpert\u6027\u80fd23%<br>GRPO improves CheXpert by 23%]\n    D --\x3e D2[GRPO\u5bfc\u81f4NIH\u6027\u80fd\u4e0b\u964d19%<br>GRPO degrades NIH by 19%]\n    D --\x3e D3[SFT\u68c0\u67e5\u70b9\u63d0\u5347\u8de8\u6570\u636e\u96c6\u6cdb\u5316<br>SFT checkpoint improves cross-dataset generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [statistical learning theory], [uniform convergence, calibration, low-dimensional structure, vision-language models, sample complexity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Paul M. Thompson"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stevens Institute of Neuroimaging and Informatics, University of Southern California"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23109",children:"https://arxiv.org/pdf/2512.23109"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides finite-sample uniform convergence bounds for accuracy and calibration of VLM-induced classifiers under Lipschitz stability assumptions. 2. Derives sample complexity bounds that depend on the intrinsic/effective dimension of the embedding space, not the ambient dimension. 3. Offers spectrum-dependent bounds that explicitly link eigenvalue decay in embedding covariance to data requirements, explaining reliable generalization with fewer samples."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dca56fb1537f7d92cc10d66ba9adb9e3272fcc872fe5fdbf475ccf92cc17e24_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dca56fb1537f7d92cc10d66ba9adb9e3272fcc872fe5fdbf475ccf92cc17e24_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies when generative and vision-language models can achieve uniformly accurate and calibrated predictions with practical sample sizes. By assuming model outputs depend smoothly on a low-dimensional semantic representation, it derives finite-sample uniform convergence bounds for VLM-induced classifiers. The main conclusion is that sample complexity depends on intrinsic dimension and eigenvalue decay, providing a framework to assess data sufficiency for reliable biomedical predictions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u4ee3\u751f\u6210\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66/\u533b\u7597\u51b3\u7b56\u4e2d\u9700\u8981\u51c6\u786e\u4e14\u6821\u51c6\u826f\u597d\u7684\u6982\u7387\u9884\u6d4b / Modern generative & VLMs need accurate, calibrated predictions for scientific/medical decisions]\n    B --\x3e B2[\u5e73\u5747\u6027\u80fd\u826f\u597d\u65f6\uff0c\u7f55\u89c1\u60c5\u51b5\u6216\u7279\u5b9a\u5b50\u7fa4\u4ecd\u53ef\u80fd\u51fa\u73b0\u5927\u8bef\u5dee / Large errors can persist for rare conditions/subgroups despite low average loss]\n    B --\x3e B3[\u9700\u8981\u4f55\u79cd\u7ed3\u6784\u5047\u8bbe\u624d\u80fd\u5b9e\u73b0\u5177\u6709\u5b9e\u7528\u6837\u672c\u91cf\u7684\u5747\u5300\u6cdb\u5316\uff1f / What structural assumptions enable uniform generalization with practical sample sizes?]\n    C --\x3e C1[\u5206\u6790\u7531\u63d0\u793a\u6216\u8bed\u4e49\u5d4c\u5165\u5728\u53d7\u9650\u8868\u793a\u7a7a\u95f4\u4e2d\u8bf1\u5bfc\u51fa\u7684\u5206\u7c7b\u5668\u65cf / Analyze induced families of classifiers from varying prompts/embeddings in a restricted space]\n    C --\x3e C2[\u5047\u8bbe\u6a21\u578b\u8f93\u51fa\u5bf9\u4f4e\u7ef4\u8bed\u4e49\u8868\u793a\u5e73\u6ed1\u4f9d\u8d56 / Assume model outputs depend smoothly on a low-dimensional semantic representation]\n    C --\x3e C3[\u5e94\u7528\u7ecf\u5178\u5747\u5300\u6536\u655b\u5de5\u5177 / Apply classical uniform convergence tools]\n    D --\x3e D1[\u5728Lipschitz\u7a33\u5b9a\u6027\u4e0b\uff0c\u4e3aVLM\u8bf1\u5bfc\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u529f\u80fd\u63d0\u4f9b\u6709\u9650\u6837\u672c\u5747\u5300\u6536\u655b\u754c / Provide finite-sample uniform convergence bounds for accuracy & calibration of VLM-induced classifiers under Lipschitz stability]\n    D --\x3e D2[\u6837\u672c\u590d\u6742\u5ea6\u53d6\u51b3\u4e8e\u5185\u5728/\u6709\u6548\u7ef4\u5ea6\uff0c\u800c\u975e\u73af\u5883\u7ef4\u5ea6 / Sample complexity depends on intrinsic/effective dimension, not ambient dimension]\n    D --\x3e D3[\u8c31\u76f8\u5173\u8fb9\u754c\u9610\u660e\u7279\u5f81\u503c\u8870\u51cf\u5982\u4f55\u63a7\u5236\u6570\u636e\u9700\u6c42 / Spectrum-dependent bounds show how eigenvalue decay governs data requirements]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [prompt injection], [prompt injection, web agents, social-engineering, benchmark, autonomous agents]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Karolina Korgul, Yushi Yang, Arkadiusz Drohomirecki, Piotr B\u0142aszczyk, Will Howard, Lukas Aichberger, Chris Russell, Philip H.S. Torr, Adam Mahdi, Adel Bibi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Oxford, SoftServe, Johannes Kepler University Linz"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23128",children:"https://arxiv.org/pdf/2512.23128"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) for evaluating prompt injection vulnerabilities in web-based LLM agents. 2. Provides a modular social-engineering injection framework for controlled experiments on high-fidelity website clones. 3. Demonstrates systemic vulnerabilities, showing agents are susceptible to injection in 25% of tasks on average, with small interface changes often doubling success rates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the vulnerability of web-based LLM agents to prompt injection attacks, where hidden adversarial instructions can divert agents from their tasks. It introduces the TRAP benchmark, built on realistic website clones, to evaluate these vulnerabilities. The study finds significant susceptibility across models, revealing systemic, psychologically driven weaknesses in current agents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Web agents vulnerable to prompt injection attacks] --\x3e Problem_Detail[\u95ee\u9898\u8be6\u60c5/Problem Detail: Adversarial instructions in web content can divert agents from original tasks]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Introduce TRAP benchmark & modular injection framework] --\x3e Method_Detail[\u65b9\u6cd5\u8be6\u60c5/Method Detail: Evaluation on high-fidelity website clones using social-engineering techniques]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Agents susceptible in 25% of tasks on average] --\x3e Results_Detail[\u7ed3\u679c\u8be6\u60c5/Results Detail: Small interface changes can double success rates, revealing systemic vulnerabilities]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (rlhf)], [preference optimization, direct preference optimization, self-reflection, invariance, bradley-terry model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yu Li, Tian Lan, Zhengling Qi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," George Washington University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23126",children:"https://arxiv.org/pdf/2512.23126"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies two fundamental limitations of DPO: lack of invariance to modeling choices and theoretical suboptimality due to ignoring comparative information in pairwise data. 2. Proposes Intrinsic Self-reflective Preference Optimization (InSPO), a novel family of methods that derives a globally optimal policy conditioned on both context and alternative responses, formalizing self-reflection. 3. Theoretically demonstrates InSPO's superiority over DPO/RLHF and its invariance properties, and practically shows it as a plug-and-play enhancement that improves win rates and length-controlled metrics without inference overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4933654befdce9d244a4f36811432e84021ec775f760f24a3cb71dec1951db76_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4933654befdce9d244a4f36811432e84021ec775f760f24a3cb71dec1951db76_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies limitations in Direct Preference Optimization (DPO), such as its sensitivity to modeling choices and failure to use comparative data fully. It proposes InSPO, a method that conditions the policy on both the context and the alternative response to enable intrinsic self-reflection. Experiments show InSPO consistently improves model alignment and robustness as a plug-and-play enhancement to DPO-family algorithms."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[DPO Limitations<br/>DPO\u7684\u5c40\u9650\u6027]\n    B1 --\x3e B2[Lacks Invariance<br/>\u7f3a\u4e4f\u4e0d\u53d8\u6027]\n    B1 --\x3e B3[Suboptimal Use of Data<br/>\u6570\u636e\u5229\u7528\u6b21\u4f18]\n    C --\x3e C1[Propose InSPO<br/>\u63d0\u51faInSPO]\n    C1 --\x3e C2[Globally Optimal Policy<br/>\u5168\u5c40\u6700\u4f18\u7b56\u7565]\n    C2 --\x3e C3[Conditions on Context & Alternative<br/>\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4e0e\u5907\u9009\u7b54\u6848]\n    D --\x3e D1[Theoretical Superiority<br/>\u7406\u8bba\u4f18\u8d8a\u6027]\n    D --\x3e D2[Practical Improvement<br/>\u5b9e\u9645\u63d0\u5347]\n    D2 --\x3e D3[Better Win Rates<br/>\u66f4\u9ad8\u7684\u80dc\u7387]\n    D2 --\x3e D4[No Inference Overhead<br/>\u65e0\u63a8\u7406\u5f00\u9500]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] PathoSyn: Imaging-Pathology MRI Synthesis via Disentangled Deviation Diffusion"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image synthesis], [diffusion model, disentangled representation, pathological residual, anatomical manifold, seam-aware fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jian Wang, Sixing Rong, Jiarui Xing, Yuling Xu, Weide Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Harvard Medical School, Northeastern University, Yale University, Nanchang University, Nanyang Technological University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23130",children:"https://arxiv.org/pdf/2512.23130"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a unified generative framework that reformulates MRI pathology synthesis as a disentangled additive deviation on a stable anatomical manifold. 2. Introduces a Deviation-Space Diffusion Model to learn the conditional distribution of pathological residuals, preserving global structure while modeling local variations. 3. Incorporates a seam-aware fusion strategy and an inference-time stabilization module to suppress boundary artifacts and ensure spatial coherence in synthesized lesions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b87a518aaabc4319ec5eba26d8ed0e23b50b1f611b88f2d8241ebecec605cc8c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b87a518aaabc4319ec5eba26d8ed0e23b50b1f611b88f2d8241ebecec605cc8c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes PathoSyn, a novel framework for synthesizing pathological MRI images by decomposing the task into deterministic anatomical reconstruction and stochastic modeling of pathological deviations using a diffusion model. This approach preserves anatomical integrity while generating realistic lesion heterogeneity. Evaluations show it outperforms existing baselines in perceptual realism and anatomical fidelity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["PathoSyn: Imaging-Pathology MRI Synthesis<br>PathoSyn: \u6210\u50cf-\u75c5\u7406MRI\u5408\u6210"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Feature entanglement in generative models<br>causes corrupted anatomy<br>\u751f\u6210\u6a21\u578b\u4e2d\u7684\u7279\u5f81\u7ea0\u7f20\u5bfc\u81f4\u89e3\u5256\u7ed3\u6784\u635f\u574f"] --\x3e P1["\u73b0\u6709\u8303\u5f0f/Existing Paradigms<br>Global pixel domain or binary masks<br>\u5168\u5c40\u50cf\u7d20\u57df\u6216\u4e8c\u8fdb\u5236\u63a9\u7801"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Disentangled Deviation Diffusion<br>\u89e3\u8026\u504f\u5dee\u6269\u6563"] --\x3e M1["\u5206\u89e3\u4efb\u52a1/Decompose Task<br>1. Deterministic anatomical reconstruction<br>\u786e\u5b9a\u6027\u89e3\u5256\u91cd\u5efa<br>2. Stochastic deviation modeling<br>\u968f\u673a\u504f\u5dee\u5efa\u6a21"]\n    Method --\x3e M2["\u6838\u5fc3\u6a21\u578b/Core Model<br>Deviation-Space Diffusion Model<br>\u504f\u5dee\u7a7a\u95f4\u6269\u6563\u6a21\u578b<br>Learns pathological residuals<br>\u5b66\u4e60\u75c5\u7406\u6b8b\u5dee"]\n    Method --\x3e M3["\u878d\u5408\u4e0e\u7a33\u5b9a/Fusion & Stabilization<br>Seam-aware fusion & inference-time<br>stabilization module<br>\u63a5\u7f1d\u611f\u77e5\u878d\u5408\u4e0e\u63a8\u7406\u65f6\u7a33\u5b9a\u6a21\u5757"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Outperforms baselines<br>\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b"] --\x3e R1["\u8bc4\u4f30/Evaluation<br>Quantitative & qualitative on tumor benchmarks<br>\u80bf\u7624\u57fa\u51c6\u4e0a\u7684\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4f30"]\n    Results --\x3e R2["\u4f18\u52bf/Advantages<br>Higher perceptual realism & anatomical fidelity<br>\u66f4\u9ad8\u7684\u611f\u77e5\u771f\u5b9e\u6027\u4e0e\u89e3\u5256\u4fdd\u771f\u5ea6"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Reservoir Computing inspired Matrix Multiplication-free Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [MatMul-free LM, reservoir computing, weight sharing, ternary quantization, MLGRU]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Takumi Shiratsuchi, Yuichiro Tanaka, Hakaru Tamukoh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kyushu Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23145",children:"https://arxiv.org/pdf/2512.23145"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel language model architecture that integrates reservoir computing principles into a MatMul-free LM to reduce training costs. 2. Introduces techniques of partially fixing/sharing weights and inserting reservoir layers to obtain dynamic representations without extra training overhead. 3. Combines operations to reduce memory accesses, achieving reductions in parameters, training time, and inference time while maintaining performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b5c1771a82be40c7ba47d813ef33ce372e599bd79d60507444a618ff4e28d2c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b5c1771a82be40c7ba47d813ef33ce372e599bd79d60507444a618ff4e28d2c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high computational cost of large language models by proposing a matrix multiplication-free model enhanced with reservoir computing. The method fixes/shared weights in selected layers and inserts reservoir layers to reduce training overhead and memory accesses. Experiments show the approach reduces parameters by up to 19%, training time by 9.9%, and inference time by 8.0% while maintaining comparable performance to the baseline."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Reservoir Computing inspired Matrix Multiplication-free Language Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs\u8ba1\u7b97\u6210\u672c\u9ad8/High computational cost of LLMs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u7ed3\u5408\u50a8\u5c42\u8ba1\u7b97\u4e0e\u65e0\u77e9\u9635\u4e58\u6cd5\u6a21\u578b/Combine RC with MatMul-free LM, \u56fa\u5b9a\u5171\u4eab\u6743\u91cd/Fix & share weights, \u51cf\u5c11\u5185\u5b58\u8bbf\u95ee/Reduce memory access]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u53c2\u6570\u51cf\u5c1119%/Params reduced by 19%, \u8bad\u7ec3\u65f6\u95f4\u51cf\u5c119.9%/Training time reduced by 9.9%, \u63a8\u7406\u65f6\u95f4\u51cf\u5c118.0%/Inference time reduced by 8.0%, \u6027\u80fd\u76f8\u5f53/Performance maintained]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Why We Need a New Framework for Emotional Intelligence in AI"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [affective computing], [emotional intelligence, benchmark evaluation, affective AI, emotion theory, AI assessment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Max Parks, Kheli Atluru, Meera Vinod, Mike Kuniavsky, Jud Brewer, Sean White, Sarah Adler, Wendy Ju"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Inflection AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23163",children:"https://arxiv.org/pdf/2512.23163"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A critical review of existing emotional intelligence (EI) theories and their applicability to artificial systems. 2. An analysis of current benchmark frameworks for evaluating EI in AI, identifying their foundational shortcomings. 3. A proposal for new evaluation strategies to better measure relevant aspects of EI in AI systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afa72b09c5f0d3f095e827a81d95825630a6951253349696736df1091d38dd71_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afa72b09c5f0d3f095e827a81d95825630a6951253349696736df1091d38dd71_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper argues that current frameworks for assessing emotional intelligence (EI) in AI are inadequate because they lack a solid theoretical foundation on emotion and fail to distinguish between human-specific and AI-relevant EI components. The authors propose a new framework by first reviewing emotion theories to define EI applicable to AI, then critiquing existing benchmarks, and finally outlining improved evaluation strategies. The main conclusion is that a refined, theoretically-grounded framework is needed to properly evaluate EI capabilities in artificial systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Why We Need a New Framework for Emotional Intelligence in AI"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u73b0\u6709EI\u8bc4\u4f30\u6846\u67b6\u4e0d\u5145\u5206/Current EI evaluation frameworks are inadequate"]\n    Problem --\x3e P2["\u7f3a\u4e4f\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840/Lack a solid theoretical foundation on emotion"]\n    Method --\x3e M1["\u56de\u987e\u60c5\u7eea\u4e0eEI\u7406\u8bba/Review emotion and EI theories"]\n    Method --\x3e M2["\u6279\u5224\u6027\u8bc4\u4f30\u73b0\u6709\u57fa\u51c6/Critically evaluate existing benchmarks"]\n    Method --\x3e M3["\u63d0\u51fa\u6539\u8fdb\u7b56\u7565/Outline improved evaluation strategies"]\n    Results --\x3e R1["\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6/A new evaluation framework is needed"]\n    Results --\x3e R2["\u533a\u5206AI\u76f8\u5173\u4e0e\u65e0\u5173\u7684EI/Distinguish AI-relevant vs. irrelevant EI aspects"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [LLM planning, Monte Carlo Tree Search (MCTS), multi-agent architecture, symbolic reasoning, self-correction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yifan Zhang, Giridhar Ganapavarapu, Srideepika Jayaraman, Bhavna Agrawal, Dhaval Patel, Achille Fokoue"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IBM T.J. Watson Research Center, Vanderbilt University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23167",children:"https://arxiv.org/pdf/2512.23167"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/IBM/SPIRAL",children:"https://github.com/IBM/SPIRAL"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SPIRAL, a novel framework that embeds a cognitive architecture of three specialized LLM agents (Planner, Simulator, Critic) into an MCTS loop for planning. 2. Transforms MCTS from a brute-force search into a guided, self-correcting reasoning process by leveraging dense, semantic-aware feedback from the agents. 3. Demonstrates superior performance and token efficiency on benchmark datasets (e.g., DailyLifeAPIs) compared to Chain-of-Thought and other state-of-the-art planning agents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c24b184565ce8e4c4a35d80f46a857779e111625dc4ea57e56333bef27bea7e6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c24b184565ce8e4c4a35d80f46a857779e111625dc4ea57e56333bef27bea7e6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLMs struggling with complex planning tasks due to linear reasoning and lack of self-correction. It proposes SPIRAL, a framework that integrates three specialized LLM agents into a Monte Carlo Tree Search loop to create a guided, reflective, and grounded planning process. The method significantly outperforms existing planning approaches in accuracy and efficiency on benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs falter at complex planning, linear reasoning lacks self-correction]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Integrates three LLM agents (Planner, Simulator, Critic) into MCTS loop]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms SOTA agents, achieves 83.6% accuracy on DailyLifeAPIs, superior token efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks], [jailbreak attacks, large language models, adversarial prompting, equation solving, code completion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhen Liang, Hai Huang, Zhengkui Chen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang Sci-Tech University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23173",children:"https://arxiv.org/pdf/2512.23173"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/lzzzr123/Equacode",children:"https://github.com/lzzzr123/Equacode"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel multi-strategy jailbreak approach that combines mathematical equation solving and code completion to bypass LLM safety constraints. 2. Demonstrates high attack success rates (e.g., 91.19% on GPT series) with only a single query, outperforming single-strategy attacks. 3. Shows through ablation studies a strong synergistic effect between the equation and code modules, proving the multi-strategy approach is more effective than the sum of its parts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3023ba644e0cdeddfd98604ca7c5871aceb213706aede21b77e0d35b95cf6d23_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3023ba644e0cdeddfd98604ca7c5871aceb213706aede21b77e0d35b95cf6d23_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces EquaCode, a multi-strategy jailbreak attack that transforms malicious intent into a mathematical problem and forces the LLM to solve it via code, diverting its focus from safety. The method achieves high success rates on various LLMs with a single query, and ablation studies confirm the synergistic benefit of combining equation-solving and code completion strategies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[EquaCode: \u591a\u7b56\u7565\u8d8a\u72f1\u65b9\u6cd5 / Multi-Strategy Jailbreak Approach] --\x3e B[\u6838\u5fc3\u95ee\u9898: LLM\u5b89\u5168\u6027\u8bc4\u4f30\u4e0d\u8db3 / Problem: Insufficient LLM Safety Evaluation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5: \u65b9\u7a0b\u6c42\u89e3\u4e0e\u4ee3\u7801\u8865\u5168 / Method: Equation Solving & Code Completion]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c: \u9ad8\u6210\u529f\u7387\u4e0e\u534f\u540c\u6548\u5e94 / Results: High Success Rate & Synergistic Effect]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [generative ai evaluation], [model belief, token-level probabilities, statistical efficiency, demand estimation, synthetic data]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hongshen Sun, Juanjuan Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," MIT Sloan School of Management"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23184",children:"https://arxiv.org/pdf/2512.23184"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces and formalizes the concept of "model belief," a novel measure derived from an LLM\'s token-level probabilities to capture its belief distribution over choices in a single generation. 2. Proves that model belief is asymptotically equivalent to the mean of model choices but is a more statistically efficient estimator with lower variance and faster convergence, with analogous properties for smooth functions used in downstream applications. 3. Empirically demonstrates that model belief outperforms model choice in explaining and predicting ground-truth choices in practical, limited-run settings (e.g., demand estimation), reducing required computation by roughly a factor of 20.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/997c7eb2e35882ae4411dc7956b1f70a51835fa22d25bcd7ec8b5d6d1cb72413_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/997c7eb2e35882ae4411dc7956b1f70a51835fa22d25bcd7ec8b5d6d1cb72413_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the inefficiency of using single LLM outputs ("model choice") by proposing "model belief," a measure based on token-level probabilities that captures the model\'s full belief distribution. The authors prove model belief is a more statistically efficient estimator than model choice and demonstrate its practical superiority in a demand estimation task, where it reduces the computation needed for accurate estimates by about 20 times.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[From Model Choice to Model Belief] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u6570\u636e\u4f7f\u7528\u6548\u7387\u4f4e / Inefficient use of LLM-generated data]\n    B --\x3e B2[\u6a21\u578b\u9009\u62e9\u4fe1\u606f\u5229\u7528\u4e0d\u8db3 / Underutilizes probabilistic information in model choice]\n    C --\x3e C1[\u63d0\u51fa\u6a21\u578b\u4fe1\u5ff5 / Propose model belief]\n    C --\x3e C2[\u57fa\u4e8eToken\u7ea7\u6982\u7387 / Based on token-level probabilities]\n    C --\x3e C3[\u6355\u83b7\u4fe1\u5ff5\u5206\u5e03 / Captures belief distribution]\n    D --\x3e D1[\u7edf\u8ba1\u6548\u7387\u66f4\u9ad8 / More statistically efficient estimator]\n    D --\x3e D2[\u8ba1\u7b97\u9700\u6c42\u51cf\u5c1120\u500d / Reduces computation by ~20x]\n    D --\x3e D3[\u9884\u6d4b\u6027\u80fd\u66f4\u4f18 / Better explains/predicts ground truth]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ForCM: Forest Cover Mapping from Multispectral Sentinel-2 Image by Integrating Deep Learning with Object-Based Image Analysis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [semantic segmentation], [Object-Based Image Analysis (OBIA), Deep Learning, Sentinel-2, Forest Cover Mapping, UNet]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maisha Haque, Israt Jahan Ayshi, Sadaf M. Anis, Nahian Tasnim, Mithila Moontaha, Md. Sabbir Ahmed, Muhammad Iqbal Hossain, Mohammad Zavid Parvez, Subrata Chakraborty, Biswajeet Pradhan, Biswajit Banik"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," BRAC University, Charles Sturt University, University of Technology Sydney"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23196",children:"https://arxiv.org/pdf/2512.23196"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes "ForCM", a novel method that integrates Object-Based Image Analysis (OBIA) with various Deep Learning models for forest cover mapping. 2. Evaluates and compares the performance of multiple DL models (UNet, UNet++, ResUNet, AttentionUNet, ResNet50-Segnet) combined with OBIA against traditional OBIA. 3. Demonstrates the practical application of free tools like QGIS for accurate environmental mapping, achieving improved accuracy (up to 95.64%) over traditional methods.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/477043abcfb8b4e851144d00c2ae33596765e1b2a27375709fcbcfc01f79e3e5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/477043abcfb8b4e851144d00c2ae33596765e1b2a27375709fcbcfc01f79e3e5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ForCM, a method for forest cover mapping that combines Object-Based Image Analysis with Deep Learning models like ResUNet and AttentionUNet using Sentinel-2 imagery. The results show that this integration significantly improves mapping accuracy compared to traditional OBIA alone, demonstrating the potential of accessible tools for environmental monitoring."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ForCM: Forest Cover Mapping] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Accurate forest cover mapping for environmental monitoring]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Integrate OBIA with DL models (e.g., UNet, ResUNet) on Sentinel-2 imagery]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improved accuracy (95.64% with AttentionUNet-OBIA vs 92.91% traditional OBIA)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Not too long do read: Evaluating LLM-generated extreme scientific summaries"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text summarization], [extreme summarization, TLDR, abstractive summarization, extractive summarization, dataset creation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhuoqi Lyu, Qing Ke"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," City University of Hong Kong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23206",children:"https://arxiv.org/pdf/2512.23206"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/netknowledge/LLM_summarization",children:"https://github.com/netknowledge/LLM_summarization"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces BiomedTLDR, a novel high-quality dataset of researcher-authored scientific TLDRs, curated from author annotations in bibliographies. 2. Evaluates the performance of popular open-weight LLMs in generating scientific TLDRs from paper abstracts. 3. Provides an analysis revealing that LLM-generated summaries tend to be more extractive (closer to the source text's lexicon and structure) compared to more abstractive human-written summaries."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e22384bc3a440a2b34601b9d8ed0a9de58fdee4ff92f1d83db278778c4293a7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e22384bc3a440a2b34601b9d8ed0a9de58fdee4ff92f1d83db278778c4293a7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of high-quality datasets for evaluating LLMs in generating scientific extreme summaries (TLDRs) by introducing BiomedTLDR, a dataset of human-authored summaries. It then evaluates open-weight LLMs on this task and finds that, while some can produce human-like summaries, LLMs generally tend to be more extractive and less abstractive than human experts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Not too long do read: Evaluating LLM-generated extreme scientific summaries<br>\u8bba\u6587\u6807\u9898"]\n    A --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br>Lack of high-quality scientific TLDR dataset hinders LLM evaluation"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br>Propose BiomedTLDR dataset & test LLMs on TLDR generation"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br>LLMs are more extractive; humans are more abstractive"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Exploring Syn-to-Real Domain Adaptation for Military Target Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [domain adaptation, synthetic-to-real, Unreal Engine, military target detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jongoh Jeong, Youngjin Oh, Gyeongrae Nam, Jeongeun Lee, Kuk-Jin Yoon"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), LIG Nex1"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23208",children:"https://arxiv.org/pdf/2512.23208"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed generating a synthetic RGB dataset for military target detection using Unreal Engine to address the lack of real-world data. 2. Conducted and benchmarked synthetic-to-real domain adaptation experiments on a new train-val dataset pair for military targets. 3. Found that domain adaptation methods using minimal supervision (e.g., object class hints) substantially outperform unsupervised or semi-supervised methods in this challenging cross-domain setting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68b67711a2133943d8083642ed36e63614aae288f161e8fc258230c5d03bacb3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68b67711a2133943d8083642ed36e63614aae288f161e8fc258230c5d03bacb3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of military target detection by generating synthetic RGB data using Unreal Engine to overcome the lack of real datasets and high costs of SAR data. It benchmarks state-of-the-art domain adaptation methods on this synthetic-to-real task and finds that methods using minimal supervision achieve the best performance, highlighting remaining challenges in this area."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Exploring Syn-to-Real Domain Adaptation for Military Target Detection] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u7f3a\u4e4f\u519b\u4e8b\u76ee\u6807\u6570\u636e\u96c6/Lack of military target datasets]\n    B --\x3e B2[SAR\u6570\u636e\u6210\u672c\u9ad8/High cost of SAR data]\n    B --\x3e B3[\u8de8\u57df\u9002\u5e94\u6311\u6218/Cross-domain adaptation challenge]\n    C --\x3e C1[\u4f7f\u7528Unreal Engine\u751f\u6210\u5408\u6210RGB\u6570\u636e/Generate synthetic RGB data using Unreal Engine]\n    C --\x3e C2[\u5408\u6210\u5230\u771f\u5b9e\u57df\u9002\u5e94\u5b9e\u9a8c/Synthetic-to-real domain adaptation experiments]\n    C --\x3e C3[\u57fa\u51c6\u6d4b\u8bd5SOTA\u65b9\u6cd5/Benchmark SOTA DA methods]\n    D --\x3e D1[\u6700\u5c0f\u76d1\u7763\u65b9\u6cd5\u8868\u73b0\u6700\u4f73/Minimal supervision methods perform best]\n    D --\x3e D2[\u8bc6\u522b\u5f53\u524d\u6311\u6218/Identify current challenges]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [LLM Ensemble, LLM-as-a-Judge, Peer-Review, Unsupervised Selection, Truth Inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhijun Chen, Zeyu Ji, Qianren Mao, Junhang Cheng, Bangjie Qin, Hao Wu, Zhuoran Li, Jingzheng Li, Kai Sun, Zizhe Wang, Yikun Ban, Zhu Sun, Xiangyang Ji, Hailong Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beihang University, Zhongguancun Laboratory, Xi'an Jiaotong University, Hong Kong University of Science and Technology, Tsinghua University, Singapore University of Technology and Design"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23213",children:"https://arxiv.org/pdf/2512.23213"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLM-PeerReview, a novel, peer-review-inspired, and interpretable framework for unsupervised LLM ensemble selection. 2. Introduces a three-stage process (scoring via LLM-as-a-Judge, reasoning via aggregation, and selection) that leverages multiple LLMs to evaluate each other's responses. 3. Demonstrates strong empirical performance, with two variants significantly outperforming a recent advanced baseline (Smoothie-Global) on multiple datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/366f9e4fb3bf94aabbe40f3849a7637d6656821ec3dde88cd37d06effd3ed3f5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/366f9e4fb3bf94aabbe40f3849a7637d6656821ec3dde88cd37d06effd3ed3f5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes LLM-PeerReview, an unsupervised ensemble method that selects the best response from multiple LLM candidates. The method uses a peer-review process where LLMs score each other's outputs, then aggregates these scores to make a final selection. The approach is shown to be simple and powerful, outperforming a strong baseline by a significant margin across several datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-PeerReview: Ensembling LLMs via Peer-Review] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Single LLM limitations & diverse model strengths]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Unsupervised 3-stage peer-review framework]\n    C --\x3e C1[\u8bc4\u5206/Scoring: LLM-as-a-Judge]\n    C --\x3e C2[\u63a8\u7406/Reasoning: Score aggregation (graphical model or averaging)]\n    C --\x3e C3[\u9009\u62e9/Selection: Pick highest-scoring response]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms Smoothie-Global by ~7% points]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [ai evaluation], [thermal comfort, cognitive turing test, cross-modal reasoning, causal association, adaptive decision-making]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jingming Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," School of Civil Engineering and Architecture, Nanyang Normal University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23217",children:"https://arxiv.org/pdf/2512.23217"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TCEval, the first evaluation framework that uses thermal comfort scenarios to assess AI's core cognitive capacities (cross-modal reasoning, causal association, adaptive decision-making). 2. Introduces a methodology using LLM agents with virtual personalities to generate and validate clothing and comfort feedback against real human databases (ASHRAE, Chinese Thermal Comfort Database). 3. Demonstrates the framework's ecological validity as a Cognitive Turing Test, revealing that current LLMs have foundational cross-modal reasoning but lack precise causal understanding of nonlinear relationships in thermal comfort."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0080eb693040bd7b2c752a63de09a7937c8abe23c0a11752ee6d9fe7cdd04c7f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0080eb693040bd7b2c752a63de09a7937c8abe23c0a11752ee6d9fe7cdd04c7f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TCEval, a novel evaluation framework that uses thermal comfort scenarios and LLM agents to assess AI's cognitive abilities. The method involves simulating agent decisions and comparing them to human data from established comfort databases. The results show that while LLMs exhibit basic cross-modal reasoning, they lack a precise causal understanding of the complex factors in thermal comfort, validating TCEval as an ecologically valid cognitive test."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1("LLM\u4efb\u52a1\u7279\u5b9a\u57fa\u51c6\u5b58\u5728\u5173\u952e\u5dee\u8ddd<br/>Critical gap in LLM task-specific benchmarks")\n    C --\x3e C1("\u5229\u7528\u70ed\u8212\u9002\u573a\u666f\u548cLLM\u667a\u80fd\u4f53<br/>Leverage thermal comfort scenarios & LLM agents")\n    C --\x3e C2("\u8bc4\u4f30\u4e09\u79cd\u6838\u5fc3\u8ba4\u77e5\u80fd\u529b<br/>Assess three core cognitive capacities")\n    C2 --\x3e C2a("\u8de8\u6a21\u6001\u63a8\u7406<br/>Cross-modal reasoning")\n    C2 --\x3e C2b("\u56e0\u679c\u5173\u8054<br/>Causal association")\n    C2 --\x3e C2c("\u81ea\u9002\u5e94\u51b3\u7b56<br/>Adaptive decision-making")\n    D --\x3e D1("\u667a\u80fd\u4f53\u53cd\u9988\u4e0e\u4eba\u7c7b\u6709\u9650\u5bf9\u9f50<br/>Agent feedback has limited exact alignment with humans")\n    D --\x3e D2("\u5177\u5907\u57fa\u7840\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b<br/>Possess foundational cross-modal reasoning ability")\n    D --\x3e D3("\u7f3a\u4e4f\u5bf9\u975e\u7ebf\u6027\u5173\u7cfb\u7684\u7cbe\u786e\u56e0\u679c\u7406\u89e3<br/>Lack precise causal understanding of nonlinear relationships")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Holi-DETR: Holistic Fashion Item Detection Leveraging Contextual Information"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [Detection Transformer (DETR), Contextual Information, Holistic Detection, Fashion Item Detection, Co-occurrence Relationship]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Youngchae Kwon, Jinyoung Choi, Injung Kim"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Handong Global University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23221",children:"https://arxiv.org/pdf/2512.23221"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Holi-DETR, a novel holistic detection framework for fashion items that leverages contextual information to reduce detection ambiguities., 2. Introduces a novel architecture that integrates three distinct types of contextual information (co-occurrence, inter-item spatial arrangements, and item-body keypoint relationships) into DETR-based models., 3. Demonstrates performance improvements over baseline models (vanilla DETR and Co-DETR) in terms of average precision (AP)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dda1eab87d833571a5feac46be0fc3ba879ccabde53c04f72e0d4fcae137cb6e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dda1eab87d833571a5feac46be0fc3ba879ccabde53c04f72e0d4fcae137cb6e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of fashion item detection, which is difficult due to diverse appearances and similar subcategories. The authors propose Holi-DETR, a holistic Detection Transformer that leverages three types of contextual information\u2014co-occurrence, spatial arrangements, and body keypoints\u2014to improve detection accuracy. The method shows improved performance over baseline DETR models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Holi-DETR: Holistic Fashion Item Detection<br>Holi-DETR: \u6574\u4f53\u65f6\u5c1a\u7269\u54c1\u68c0\u6d4b] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Fashion item detection is challenging due to diverse appearances and similarities among subcategories.<br>\u65f6\u5c1a\u7269\u54c1\u68c0\u6d4b\u56e0\u5916\u89c2\u591a\u6837\u548c\u5b50\u7c7b\u522b\u76f8\u4f3c\u800c\u5177\u6709\u6311\u6218\u6027\u3002]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Proposes Holi-DETR, a holistic detector leveraging three contextual cues: co-occurrence, spatial arrangements, and body keypoints.<br>\u63d0\u51faHoli-DETR\uff0c\u5229\u7528\u5171\u73b0\u3001\u7a7a\u95f4\u5e03\u5c40\u548c\u8eab\u4f53\u5173\u952e\u70b9\u4e09\u79cd\u4e0a\u4e0b\u6587\u7ebf\u7d22\u7684\u6574\u4f53\u68c0\u6d4b\u5668\u3002]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Improved performance over vanilla DETR (+3.6pp AP) and Co-DETR (+1.1pp AP).<br>\u6027\u80fd\u8d85\u8d8a\u539f\u59cbDETR (+3.6pp AP) \u548c Co-DETR (+1.1pp AP)\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Anomaly Detection by Effectively Leveraging Synthetic Images"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [anomaly detection], [synthetic data, image-to-image translation, image retrieval, two-stage training, MVTec AD]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sungho Kang, Hyunkyu Park, Yeonho Lee, Hanbyul Lee, Mijoo Jeong, YeongHyeon Park, Injae Lee, Juneho Yi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sungkyunkwan University, The University of Texas MD Anderson Cancer Center"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23227",children:"https://arxiv.org/pdf/2512.23227"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel framework that efficiently generates synthetic defect images by leveraging a pre-trained text-guided image-to-image translation model and an image retrieval model for filtering. 2. A two-stage training strategy that pre-trains on a large volume of rule-based synthetic images and then fine-tunes on a smaller set of high-quality generated images. 3. Demonstration of the approach's effectiveness in reducing data collection costs while improving anomaly detection performance on the MVTec AD benchmark dataset."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3546b17641c719167618772aa6e4da085e82a3b6d85cd2abc9940897d3e1f92_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3546b17641c719167618772aa6e4da085e82a3b6d85cd2abc9940897d3e1f92_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the trade-off in synthetic data generation for anomaly detection by proposing a framework that uses a pre-trained image-to-image translation model and an image retrieval filter to efficiently create realistic defect images. It also introduces a two-stage training strategy to leverage both cheap, low-quality and expensive, high-quality synthetic data effectively. Experiments on MVTec AD show this method reduces costs and improves detection performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Anomaly Detection by Effectively Leveraging Synthetic Images] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u771f\u5b9e\u7f3a\u9677\u56fe\u50cf\u7a00\u7f3a\uff0c\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5728\u6210\u672c\u4e0e\u8d28\u91cf\u95f4\u96be\u4ee5\u6743\u8861/Scarcity of real defect images, trade-off between cost and quality in synthesis]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: 1. \u4f7f\u7528\u9884\u8bad\u7ec3\u56fe\u50cf\u7ffb\u8bd1\u4e0e\u68c0\u7d22\u6a21\u578b\u9ad8\u6548\u751f\u6210\u7f3a\u9677\u56fe/Use pre-trained image-to-image & retrieval models for generation. 2. \u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u5148\u9884\u8bad\u7ec3\u518d\u5fae\u8c03/Two-stage training: pre-train then fine-tune]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u5728MVTec AD\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd/Validated on MVTec AD, reduces cost and improves performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Physics-Inspired Modeling and Content Adaptive Routing in an Infrared Gas Leak Detection Network"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [object detection], [physics-inspired modeling, edge detection, content-adaptive routing, multi-scale feature fusion, infrared gas leak detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dongsheng Li, Chaobo Chen, Siling Wang, Song Gao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," (Inferred from author names and arXiv handle; specific institution not provided in the given text. Could be a Chinese research institution or university.)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23234",children:"https://arxiv.org/pdf/2512.23234"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a physics-inspired Gas Block module that models gas transport using a diffusion-convection unit with local and large-kernel branches, fused via an edge-gated module to enhance weak plume features. 2. Introduced a novel Adaptive Gradient and Phase Edge Operator (AGPEO) and a Multi-Scale Edge Perception Module (MSEPM) to compute and integrate reliable hierarchical edge priors for boundary reinforcement. 3. Designed a Content-Adaptive Sparse Routing Path Aggregation Network (CASR-PAN) that uses adaptive modulation to selectively propagate informative features across scales based on content and edge cues, improving efficiency and discriminability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee948d9a0589e5467502d1d916e59d51137b1253413c1001ade729584fd4bf55_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee948d9a0589e5467502d1d916e59d51137b1253413c1001ade729584fd4bf55_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes PEG-DRNet, a physics-inspired and edge-guided network for detecting faint infrared gas leaks. The method combines a gas transport model, a novel edge detection operator, and a content-adaptive routing mechanism for multi-scale feature fusion. Experiments show PEG-DRNet achieves superior accuracy and computational efficiency on benchmark datasets compared to existing detectors."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Physics-Inspired Modeling and Content Adaptive Routing in an Infrared Gas Leak Detection Network] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: \u7ea2\u5916\u6c14\u4f53\u6cc4\u6f0f\u68c0\u6d4b\u56f0\u96be/Infrared gas leak detection is difficult due to faint, small, semitransparent plumes with weak boundaries.)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faPEG-DRNet/Propose PEG-DRNet)\n    C --\x3e C1(\u6c14\u4f53\u5757\u5efa\u6a21\u6c14\u4f53\u4f20\u8f93/Gas Block models gas transport)\n    C --\x3e C2(\u81ea\u9002\u5e94\u68af\u5ea6\u76f8\u4f4d\u8fb9\u7f18\u7b97\u5b50/Adaptive Gradient and Phase Edge Operator (AGPEO))\n    C --\x3e C3(\u5185\u5bb9\u81ea\u9002\u5e94\u7a00\u758f\u8def\u7531\u805a\u5408\u7f51\u7edc/Content-Adaptive Sparse Routing Path Aggregation Network (CASR-PAN))\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u5728IIG\u548cLangGas\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u8d8a/Superior performance on IIG and LangGas datasets, achieving higher AP and AP50 with good efficiency.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Meta Platforms"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23236",children:"https://arxiv.org/pdf/2512.23236"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[KernelEvolve: Scaling Agentic Kernel Coding] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[DLRM\u8bad\u7ec3/\u63a8\u7406\u6548\u7387<br/>DLRM Training/Inference Efficiency]\n    B --\x3e B2[\u6a21\u578b\u3001\u5185\u6838\u3001\u786c\u4ef6\u5f02\u6784\u6027<br/>Model, Kernel, Hardware Heterogeneity]\n    C --\x3e C1[\u667a\u80fd\u5185\u6838\u7f16\u7801\u6846\u67b6<br/>Agentic Kernel Coding Framework]\n    C --\x3e C2[\u591a\u62bd\u8c61\u5c42: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]\n    C --\x3e C3[\u56fe\u641c\u7d22\u4e0e\u68c0\u7d22\u589e\u5f3a\u63d0\u793a<br/>Graph Search & Retrieval-Augmented Prompt]\n    D --\x3e D1[100%\u6b63\u786e\u7387, 17\u500d\u52a0\u901f<br/>100% Correctness, 17x Speedup]\n    D --\x3e D2[\u5f00\u53d1\u65f6\u95f4: \u6570\u5468->\u6570\u5c0f\u65f6<br/>Dev Time: Weeks->Hours]\n    D --\x3e D3[\u964d\u4f4e\u65b0\u786c\u4ef6\u7f16\u7a0b\u58c1\u5792<br/>Reduces New Hardware Programmability Barrier]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [change detection], [vision-language model, remote sensing, semantic change detection, supervised fine-tuning, reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xingwei Ma, Shiyang Feng, Bo Zhang, Bin Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Artificial Intelligence Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23244",children:"https://arxiv.org/pdf/2512.23244"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ViLaCD-R1, a novel two-stage vision-language framework for semantic change detection in remote sensing, comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). 2. Introduces a training strategy for the VLM using supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks to generate a coarse change mask. 3. Demonstrates that the framework significantly improves semantic change recognition and localization while suppressing non-semantic variations, achieving state-of-the-art performance on multiple benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of existing remote sensing change detection methods, such as poor semantic understanding and inaccurate localization, by proposing ViLaCD-R1. This two-stage vision-language framework first uses a fine-tuned VLM to generate a coarse change mask from dual-temporal images, then refines it with a decoder to produce a precise change map. The method shows superior performance in recognizing true semantic changes and suppressing irrelevant variations across several benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ViLaCD-R1: \u9065\u611f\u8bed\u4e49\u53d8\u5316\u68c0\u6d4b\u7684\u89c6\u89c9\u8bed\u8a00\u6846\u67b6] --\x3e B1(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e B2(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e B3(\u5173\u952e\u7ed3\u679c/Results)\n    B1 --\x3e C1[\u4f20\u7edf\u65b9\u6cd5\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3/Traditional methods lack semantic understanding]\n    B1 --\x3e C2[\u73b0\u6709VLM\u65b9\u6cd5\u5b9a\u4f4d\u4e0d\u51c6\u786e/Existing VLM methods have inaccurate localization]\n    B2 --\x3e D1[\u4e24\u9636\u6bb5\u6846\u67b6/Two-stage framework]\n    D1 --\x3e E1[\u591a\u56fe\u50cf\u63a8\u7406\u5668/Multi-Image Reasoner]\n    E1 --\x3e F1[SFT\u4e0eRL\u8bad\u7ec3/SFT and RL training]\n    E1 --\x3e F2[\u751f\u6210\u7c97\u53d8\u5316\u63a9\u7801/Generate coarse change mask]\n    D1 --\x3e E2[\u63a9\u7801\u5f15\u5bfc\u89e3\u7801\u5668/Mask-Guided Decoder]\n    E2 --\x3e F3[\u878d\u5408\u7279\u5f81\u4e0e\u63a9\u7801/Fuse features and mask]\n    E2 --\x3e F4[\u9884\u6d4b\u7cbe\u7ec6\u53d8\u5316\u56fe/Predict precise change map]\n    B3 --\x3e G1[\u63d0\u5347\u8bed\u4e49\u53d8\u5316\u8bc6\u522b/Improves semantic change recognition]\n    B3 --\x3e G2[\u6291\u5236\u975e\u8bed\u4e49\u53d8\u5316/Suppresses non-semantic variations]\n    B3 --\x3e G3[\u8fbe\u5230SOTA\u6027\u80fd/Achieves SOTA performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Sparse Autoencoders (SAEs), Low-Rank Adaptation (LoRA), Safety Alignment, Interpretability, Parameter-efficient Fine-tuning (PEFT)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dianyun Wang, Qingsen Ma, Yuhu Shang, Zhifeng Lu, Lechen Ning, Zhenbo Xu, Huijia Wu, Zhaofeng He"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beijing University of Posts and Telecommunications"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23260",children:"https://arxiv.org/pdf/2512.23260"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel method that uses pre-trained Sparse Autoencoders (SAEs) to construct an explicit, interpretable low-rank subspace for adapter initialization, addressing the black-box nature of traditional LoRA. 2. Provides theoretical analysis proving that SAE-based subspace identification achieves arbitrarily small recovery error under monosemanticity, while direct identification suffers an irreducible error floor due to polysemanticity. 3. Demonstrates state-of-the-art performance on safety alignment, achieving up to 99.6% safety rate while updating only 0.19-0.24% of parameters, and provides interpretable insights into the learned alignment subspace."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of interpretability in standard Low-Rank Adaptation (LoRA) methods for fine-tuning large language models. The proposed method leverages Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled space and uses them to construct an explicit, interpretable low-rank subspace for adapter initialization. The approach achieves superior safety alignment performance and provides transparency into the learned adaptation process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("LoRA\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027/LoRA lacks interpretability")\n    Problem --\x3e P2("\u5b50\u7a7a\u95f4\u5b66\u4e60\u662f\u9ed1\u76d2\u7684/Subspace learning is black-box")\n    Method --\x3e M1("\u5229\u7528\u9884\u8bad\u7ec3SAE/Use pre-trained SAEs")\n    Method --\x3e M2("\u6784\u5efa\u663e\u5f0f\u4f4e\u79e9\u5b50\u7a7a\u95f4/Construct explicit low-rank subspace")\n    Results --\x3e R1("\u9ad8\u5b89\u5168\u738799.6%/High safety rate 99.6%")\n    Results --\x3e R2("\u53c2\u6570\u9ad8\u65480.19%/Parameter-efficient 0.19%")\n    Results --\x3e R3("\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027/Provides interpretability")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [domain-specific foundation model, agentic physical ai, variance collapse, physics-based validation, policy distillation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yoonpyo Lee, Kazuma Kobayashi, Sai Puppala, Sajedul Talukder, Seid Koric, Souvik Chakraborty, Syed Bahauddin Alam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hanyang University, University of Illinois Urbana-Champaign, Southern Illinois University, University of Texas at El Paso, National Center for Supercomputing Applications, Indian Institute of Technology Delhi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23292",children:"https://arxiv.org/pdf/2512.23292"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new paradigm of Agentic Physical AI, where policy optimization is driven by physics-based outcome validation instead of perceptual inference, addressing the structural limitation of general-purpose models in control tasks. 2. Demonstrates that scaling data for a compact (360M parameter) model induces a sharp phase transition and variance collapse (>500x reduction), leading to stable, execution-level behavior for safety-critical control. 3. Shows the model autonomously distills a robust policy (concentrating on a single strategy) and its learned representations transfer across different physics and input modalities without architectural changes, exhibiting early foundation-model properties."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb921102dfde629395ab8293510cb369a00c1199cadd4c88269dc076f8774a1a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb921102dfde629395ab8293510cb369a00c1199cadd4c88269dc076f8774a1a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies a fundamental limitation of general-purpose AI models in safety-critical physical control tasks, where they prioritize semantic plausibility over physical correctness. To address this, it introduces Agentic Physical AI, a paradigm using compact language models trained with physics-based validation on synthetic nuclear reactor control data. The key finding is that sufficient data scaling induces a sharp variance collapse, stabilizing the model's behavior and enabling it to autonomously distill a reliable control policy that generalizes across tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Agentic Physical AI for Nuclear Reactor Control") --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>General-purpose models fail at physical control<br>\u901a\u7528\u6a21\u578b\u5728\u7269\u7406\u63a7\u5236\u4e2d\u5931\u8d25"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Agentic Physical AI with physics-based validation<br>\u57fa\u4e8e\u7269\u7406\u9a8c\u8bc1\u7684\u667a\u80fd\u4f53\u7269\u7406AI"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Variance collapse & emergent policy distillation<br>\u65b9\u5dee\u5d29\u6e83\u4e0e\u7b56\u7565\u84b8\u998f\u6d8c\u73b0"]\n\n    Problem --\x3e P1["Input unfaithfulness / \u8f93\u5165\u4e0d\u5fe0\u5b9e"]\n    Problem --\x3e P2["Semantic vs. physical correctness / \u8bed\u4e49\u4e0e\u7269\u7406\u6b63\u786e\u6027\u51b2\u7a81"]\n\n    Method --\x3e M1["Compact LM (360M params) / \u7d27\u51d1\u8bed\u8a00\u6a21\u578b"]\n    Method --\x3e M2["Physics-driven optimization / \u7269\u7406\u9a71\u52a8\u4f18\u5316"]\n    Method --\x3e M3["Synthetic data scaling (10^3 to 10^5) / \u5408\u6210\u6570\u636e\u7f29\u653e"]\n\n    Results --\x3e R1["Phase transition & >500x variance collapse / \u76f8\u53d8\u4e0e\u65b9\u5dee\u5d29\u6e83"]\n    Results --\x3e R2["Autonomous policy distillation / \u81ea\u4e3b\u7b56\u7565\u84b8\u998f"]\n    Results --\x3e R3["Transferable representations / \u53ef\u8fc1\u79fb\u8868\u5f81"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [medical image classification], [MedGemma, GPT-4, LoRA, zero-shot classification, multimodal LLM]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md. Sazzadul Islam Prottasha, Nabil Walid Rafi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Bangladesh University of Professionals"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23304",children:"https://arxiv.org/pdf/2512.23304"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a critical comparison between the open-source MedGemma and proprietary GPT-4 for zero-shot medical disease classification from images. 2. Demonstrated that the LoRA-fine-tuned MedGemma model significantly outperformed the untuned GPT-4 in accuracy and sensitivity for high-stakes clinical tasks. 3. Highlighted the essential role of domain-specific fine-tuning in minimizing hallucinations and enabling complex, evidence-based medical reasoning for clinical implementation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58abac32272c08efbbe249ec33f3b4f4aa3a6f4d477b241718ddbde679cce96a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58abac32272c08efbbe249ec33f3b4f4aa3a6f4d477b241718ddbde679cce96a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study compares the performance of the open-source MedGemma model and the proprietary GPT-4 for zero-shot classification of six diseases from medical images. The MedGemma model, fine-tuned with LoRA, achieved higher mean accuracy and sensitivity than GPT-4. The results show that domain-specific fine-tuning is crucial for reliable clinical applications, positioning MedGemma as a sophisticated tool for medical diagnostics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MedGemma vs GPT-4: \u533b\u5b66\u56fe\u50cf\u96f6\u6837\u672c\u75be\u75c5\u5206\u7c7b] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u6bd4\u8f83\u5f00\u6e90\u4e0e\u95ed\u6e90\u591a\u6a21\u6001LLM\u5728\u533b\u5b66\u56fe\u50cf\u8bca\u65ad\u4e2d\u7684\u6027\u80fd]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u4f7f\u7528LoRA\u5fae\u8c03\u7684MedGemma\u4e0e\u672a\u8c03\u4f18\u7684GPT-4\u8fdb\u884c\u96f6\u6837\u672c\u5206\u7c7b\u5bf9\u6bd4]\n    D[\u5173\u952e\u7ed3\u679c/Results: MedGemma\u51c6\u786e\u7387(80.37%)\u548c\u654f\u611f\u6027\u66f4\u9ad8\uff0c\u9886\u57df\u5fae\u8c03\u5bf9\u51cf\u5c11\u5e7b\u89c9\u81f3\u5173\u91cd\u8981]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Lyapunov Optimization, Deep Reinforcement Learning, Edge-Cloud Partitioning, Transformer Decomposition, Queue Stability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Innsbruck, Sharif University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23310",children:"https://arxiv.org/pdf/2512.23310"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a fine-grained, adaptive partitioning framework (Splitwise) that decomposes transformer layers into attention heads and feed-forward sub-blocks, enabling exponentially more partition choices than layer-wise schemes. 2. Introduces a hierarchical DRL policy guided by Lyapunov optimization to jointly optimize latency, energy, and accuracy while guaranteeing queue stability under stochastic workloads and variable bandwidth. 3. Ensures robustness through partition checkpoints with exponential backoff recovery for communication failures, validated on real edge devices with large models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Splitwise, a Lyapunov-assisted DRL framework for dynamically partitioning LLM inference between edge and cloud at a fine-grained sub-layer level. It aims to minimize latency and energy while maintaining accuracy under fluctuating network conditions. Experiments show Splitwise significantly reduces latency and energy consumption compared to existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs are hard to deploy on edge devices; cloud-only is slow; static partitions fail with bandwidth changes.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Fine-grained partition of transformer layers; Lyapunov-assisted DRL for adaptive optimization; checkpointing for robustness.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Reduces latency 1.4x-2.8x; cuts energy up to 41%; lowers 95th-percentile latency by 53-61%.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [explainable ai (xai)], [inverse kinematics, shapley additive explanations (SHAP), InterpretML, obstacle avoidance, neural network]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sheng-Kai Chen, Yi-Ling Tsai, Chun-Chih Chang, Yan-Chen Chen, Po-Chiang Lin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Yuan Ze University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23312",children:"https://arxiv.org/pdf/2512.23312"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an explainability-centered workflow integrating SHapley Additive exPlanations (SHAP) with physics-based obstacle avoidance evaluation for neural inverse kinematics. 2. Introduces and trains two lightweight variants of IKNet (Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling) on a synthetic dataset. 3. Demonstrates through simulation that neural IK architectures with more balanced feature importance attribution tend to maintain wider safety margins without sacrificing accuracy, linking XAI insights to robotic safety."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study addresses the lack of transparency in neural network-based inverse kinematics (IK) solvers by proposing an explainable AI workflow. It integrates SHAP analysis with physics-based simulation to evaluate two new IKNet variants on obstacle avoidance tasks. The key finding is that architectures with more evenly distributed feature importance achieve better safety performance, showing how XAI can guide the development of trustworthy robotic manipulation systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation<br>\u53ef\u89e3\u91ca\u795e\u7ecf\u9006\u8fd0\u52a8\u5b66\u7528\u4e8e\u969c\u788d\u7269\u611f\u77e5\u673a\u5668\u4eba\u64cd\u4f5c"] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B["\u6838\u5fc3\u95ee\u9898/Problem<br>Opaque neural IK models lack transparency and safety for responsible AI.<br>\u9ed1\u76d2\u795e\u7ecfIK\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\u4e0e\u5b89\u5168\u6027"] --\x3e B1["\u6311\u6218/Challenges<br>Debugging failures, safety certification"]\n    C["\u4e3b\u8981\u65b9\u6cd5/Method<br>XAI workflow integrating SHAP and physics simulation.<br>\u96c6\u6210SHAP\u4e0e\u7269\u7406\u4eff\u771f\u7684XAI\u5de5\u4f5c\u6d41"] --\x3e C1["\u6a21\u578b/Variants<br>Improved IKNet, Focused IKNet"]\n    C --\x3e C2["\u5de5\u5177/Tools<br>SHAP, InterpretML, Simulator"]\n    D["\u5173\u952e\u7ed3\u679c/Results<br>Balanced feature attribution correlates with wider safety margins.<br>\u5747\u8861\u7684\u7279\u5f81\u5f52\u56e0\u4e0e\u66f4\u5bbd\u7684\u5b89\u5168\u88d5\u5ea6\u76f8\u5173"] --\x3e D1["\u7ed3\u8bba/Conclusion<br>XAI guides architectural refinement for trustworthy IK.<br>XAI\u6307\u5bfc\u53ef\u4fe1IK\u7684\u67b6\u6784\u6539\u8fdb"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.strong,{children:["[arXiv251230] On Conformant Planning and Model-Checking of ",(0,a.jsx)(n.span,{className:"katex-error",title:"ParseError: KaTeX parse error: Double superscript at position 3: ^*^\u0332*",style:{color:"#cc0000"},children:"^*^*"})," Hyperproperties"]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [formal methods], [conformant planning, hyperproperties, model-checking, HyperLTL, \u2203\u2217\u2200\u2217]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Raven Beutner, Bernd Finkbeiner"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," CISPA Helmholtz Center for Information Security"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23324",children:"https://arxiv.org/pdf/2512.23324"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Establishes a formal connection between conformant planning and model-checking of \u2203\u2217\u2200\u2217 hyperproperties, showing they share the same computational core. 2. Provides an efficient, sound, and complete reduction from a hyperproperty model-checking instance to a conformant planning instance. 3. Demonstrates that every conformant planning problem is itself a hyperproperty model-checking task, establishing the converse direction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47343ca7bc4bf16389257261dd21e0c1fa42c0f512178576ff4ba501df841e8b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47343ca7bc4bf16389257261dd21e0c1fa42c0f512178576ff4ba501df841e8b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies and formalizes a deep connection between two seemingly unrelated problems: conformant planning (finding a robust sequential plan under uncertainty) and model-checking of \u2203\u2217\u2200\u2217 hyperproperties (verifying system properties that relate multiple execution traces). The authors provide efficient, sound, and complete translations between instances of these two problems, showing they are essentially two sides of the same computational coin. This foundational link aims to enable cross-pollination of solution techniques between the planning and verification communities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[On Conformant Planning and Model-Checking of \u2203\u2217\u2200\u2217 Hyperproperties] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8fde\u63a5\u4e24\u4e2a\u770b\u4f3c\u65e0\u5173\u7684\u95ee\u9898 / Linking two seemingly unrelated problems]\n    B1 --\x3e B2[Conformant Planning / \u4e00\u81f4\u6027\u89c4\u5212]\n    B1 --\x3e B3[Hyperproperty Model-Checking / \u8d85\u5c5e\u6027\u6a21\u578b\u68c0\u6d4b]\n    C --\x3e C1[\u6784\u5efa\u53cc\u5411\u9ad8\u6548\u89c4\u7ea6 / Constructing bidirectional efficient reductions]\n    D --\x3e D1[\u8bc1\u660e\u89c4\u7ea6\u7684\u53ef\u9760\u6027\u4e0e\u5b8c\u5907\u6027 / Proving reductions are sound and complete]\n    D --\x3e D2[\u786e\u7acb\u95ee\u9898\u7684\u7b49\u4ef7\u6027 / Establishing the equivalence of the problems]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [agent evaluation], [spatial reasoning, long-horizon planning, partial observability, mental simulation, diagnostic benchmark]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huan-ang Gao, Zikang Zhang, Tianwei Luo, Kaisen Yang, Xinzhe Juan, Jiahao Qiu, Tianxing Chen, Bingxiang He, Hao Zhao, Hao Zhou, Shilong Liu, Mengdi Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Princeton University, Shanghai Jiao Tong University & University of Michigan, The University of Hong Kong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23328",children:"https://arxiv.org/pdf/2512.23328"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies three core cognitive challenges (spatial reasoning, long-horizon state tracking, active exploration under partial observation) hindering LLM agents in the physical world. 2. Introduces CubeBench, a novel generative benchmark based on the Rubik's Cube with a three-tiered diagnostic framework to isolate and evaluate these capabilities. 3. Provides a diagnostic framework using external solver tools to analyze failure modes and reveals critical limitations of leading LLMs, including a 0.00% pass rate on long-horizon tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/210465a4bf9048c43ec900e17f922e63394d83664c6fe631fec0d54577fd9fb6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/210465a4bf9048c43ec900e17f922e63394d83664c6fe631fec0d54577fd9fb6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces CubeBench, a diagnostic benchmark using a Rubik's Cube to evaluate LLM agents' spatial reasoning and long-horizon planning under partial observation. It employs a three-tiered framework from full symbolic to partial visual states. Experiments show leading LLMs fail completely on long-horizon tasks, highlighting a fundamental gap for physical-world deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u667a\u80fd\u4f53\u7f3a\u4e4f\u7269\u7406\u4e16\u754c\u90e8\u7f72\u6240\u9700\u7684\u7a33\u5065\u7a7a\u95f4\u5fc3\u667a\u6a21\u578b/LLM agents lack robust spatial mental models for physical-world deployment]\n    C --\x3e C1[\u63d0\u51fa\u57fa\u4e8e\u9b54\u65b9\u7684\u4e09\u5c42\u8bca\u65ad\u57fa\u51c6/CubeBench: A three-tiered diagnostic benchmark using Rubik's Cube]\n    C --\x3e C2[\u4ece\u5b8c\u6574\u7b26\u53f7\u72b6\u6001\u5230\u90e8\u5206\u89c6\u89c9\u72b6\u6001\u9010\u6b65\u8bc4\u4f30/Progressive evaluation from full symbolic to partial visual state]\n    D --\x3e D1[\u9886\u5148LLM\u5728\u957f\u89c6\u91ce\u4efb\u52a1\u4e0a\u901a\u8fc7\u7387\u4e3a0%/Leading LLMs have 0.00% pass rate on long-horizon tasks]\n    D --\x3e D2[\u63ed\u793a\u4e86\u957f\u671f\u89c4\u5212\u548c\u4e3b\u52a8\u63a2\u7d22\u7684\u6839\u672c\u6027\u5931\u8d25/Exposes fundamental failure in long-term planning and active exploration]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [scaling laws], [scaling laws, model ensembling, multi-model collaboration, cross-entropy loss, parameter budget]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dakuan Lu, Jiaqi Zhang, Cheng Yuan, Jiawei Shao, Chi Zhang, Xuelong Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Artificial Intelligence (TeleAI), China Telecom"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23340",children:"https://arxiv.org/pdf/2512.23340"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes the "Law of Multi-model Collaboration," a novel scaling law for predicting the performance limits of LLM ensembles based on aggregated parameters. 2. Establishes a method-agnostic theoretical framework using an idealized integration oracle to quantify the intrinsic upper bound of multi-model collaboration. 3. Empirically demonstrates that multi-model systems follow a power-law scaling with better trends and lower loss floors than single models, and that heterogeneous ensembles outperform homogeneous ones.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68212ad5f9cd50ef959cdd80f4b7274178d9a6b124904010fc5b0cf0834b21a1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68212ad5f9cd50ef959cdd80f4b7274178d9a6b124904010fc5b0cf0834b21a1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the lack of a theoretical framework for scaling in multi-model LLM systems. It proposes the "Law of Multi-model Collaboration," a scaling law based on aggregated parameters, and finds that ensembles scale better and achieve lower loss than single models, with diversity being a key driver of gains.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["The Law of Multi-Model Collaboration<br>\u591a\u6a21\u578b\u534f\u4f5c\u5b9a\u5f8b"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Lack of scaling theory for multi-model collaboration<br>\u7f3a\u4e4f\u591a\u6a21\u578b\u534f\u4f5c\u7684\u6269\u5c55\u7406\u8bba"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Propose Law of Multi-model Collaboration<br>\u63d0\u51fa\u591a\u6a21\u578b\u534f\u4f5c\u5b9a\u5f8b"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Ensembles scale better than single models<br>\u96c6\u6210\u6a21\u578b\u6bd4\u5355\u4e00\u6a21\u578b\u6269\u5c55\u6027\u66f4\u597d"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [memory systems, cognitive neuroscience, LLM-driven agents, memory security, multimodal memory]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Harbin Institute of Technology, Fudan University, Peking University, National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23343",children:"https://arxiv.org/pdf/2512.23343"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/AgentMemory/Huaman-Agent-Memory",children:"https://github.com/AgentMemory/Huaman-Agent-Memory"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a systematic synthesis and comparative analysis of memory systems from cognitive neuroscience to LLM-driven autonomous agents. 2. Reviews mainstream benchmarks for evaluating agent memory and explores memory security from attack and defense perspectives. 3. Envisions future research directions, focusing on multimodal memory systems and skill acquisition."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15773eb4c52c63f2641be869baf3af4b7f6bb74f6e36c67247957bfbd039e9b6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15773eb4c52c63f2641be869baf3af4b7f6bb74f6e36c67247957bfbd039e9b6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey paper bridges the interdisciplinary gap between cognitive neuroscience and AI by systematically analyzing memory systems for autonomous agents. It compares biological and artificial memory taxonomies, storage, and management, while also reviewing evaluation benchmarks and security issues. The work concludes by outlining future directions, including multimodal memory and skill learning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[AI Meets Brain: Memory Systems / AI\u4e0e\u5927\u8111\uff1a\u8bb0\u5fc6\u7cfb\u7edf] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Interdisciplinary Gap / \u8de8\u5b66\u79d1\u9e3f\u6c9f]\n    P1 --\x3e P2[Existing works struggle to assimilate human memory essence / \u73b0\u6709\u5de5\u4f5c\u96be\u4ee5\u5438\u6536\u4eba\u7c7b\u8bb0\u5fc6\u673a\u5236\u7cbe\u9ad3]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Systematic Synthesis / \u7cfb\u7edf\u7efc\u8ff0]\n    M1 --\x3e M2[Comparative Analysis / \u5bf9\u6bd4\u5206\u6790]\n    M2 --\x3e M3[Review Benchmarks & Security / \u56de\u987e\u57fa\u51c6\u4e0e\u5b89\u5168]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Unified Memory Framework / \u7edf\u4e00\u7684\u8bb0\u5fc6\u6846\u67b6]\n    R1 --\x3e R2[Future Directions / \u672a\u6765\u65b9\u5411]\n    R2 --\x3e R3[Multimodal Memory & Skill Acquisition / \u591a\u6a21\u6001\u8bb0\u5fc6\u4e0e\u6280\u80fd\u83b7\u53d6]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ECG-RAMBA: Zero-Shot ECG Generalization by Morphology-Rhythm Disentanglement and Long-Range Modeling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [medical signal processing], [ECG classification, morphology-rhythm disentanglement, Mamba, zero-shot generalization, Power Mean pooling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hai Duong Nguyen, Xuan-The Tran"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," HAI-Smartlink Research Lab (Anchi STE Company), Vietnam Maritime University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23347",children:"https://arxiv.org/pdf/2512.23347"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ECG-RAMBA, a framework that explicitly disentangles ECG morphology (via MiniRocket) and rhythm (via HRV descriptors) before fusing them for robust classification. 2. Introduces a numerically stable Power Mean pooling operator (Q=3) for windowed inference to emphasize high-evidence segments. 3. Demonstrates strong zero-shot cross-dataset generalization for ECG classification using a bi-directional Mamba backbone for long-range contextual modeling."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f9b49242e586cadf1889fa40730ea1652c1b4ef5b15cf15697b58832c4dbf6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f9b49242e586cadf1889fa40730ea1652c1b4ef5b15cf15697b58832c4dbf6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of poor generalization of deep learning models for ECG classification across different datasets. It proposes ECG-RAMBA, a method that separates and then fuses morphological and rhythm features, using a Mamba backbone and a novel pooling operator. The results show that this approach achieves robust zero-shot performance on external datasets, outperforming a baseline model."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ECG-RAMBA: Zero-Shot ECG Generalization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Poor cross-dataset generalization in ECG classification]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Morphology-Rhythm Disentanglement & Long-Range Mamba Modeling]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Strong zero-shot AUC on CPSC-2021 & PTB-XL]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text-to-sql], [Reinforcement Learning, Data Synthesis, Policy Optimization, Semantic-Logic Alignment, Group Relative Policy Optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sichuan University, IQuest Research, Beihang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23366",children:"https://arxiv.org/pdf/2512.23366"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AGRO-SQL] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u7a00\u7f3a\u4e0e\u8d28\u91cf/Data Scarcity & Quality]\n    B --\x3e B2[\u6a21\u578b\u63a8\u7406\u9650\u5236/Model Reasoning Limitations]\n    C --\x3e C1[\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5/Data-Centric Approach]\n    C --\x3e C2[\u6a21\u578b\u4e2d\u5fc3\u65b9\u6cd5/Model-Centric Approach]\n    C1 --\x3e C1a[\u8fed\u4ee3\u6570\u636e\u5de5\u5382/Iterative Data Factory]\n    C1 --\x3e C1b[\u8bed\u4e49\u903b\u8f91\u5bf9\u9f50/Semantic-Logic Alignment]\n    C2 --\x3e C2a[\u591a\u6837\u6027\u611f\u77e5\u51b7\u542f\u52a8/Diversity-Aware Cold Start]\n    C2 --\x3e C2b[\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316/Group Relative Policy Optimization]\n    D --\x3e D1[\u5728BIRD\u548cSpider\u4e0aSOTA/SOTA on BIRD & Spider]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [post-training quantization, W8A8, W4A8, Ascend NPU, Chain-of-Thought (CoT)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yilun Luo, HuaQing Zheng, Haoqian Meng, Wenyuan Liu, Peng Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tianjin University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23367",children:"https://arxiv.org/pdf/2512.23367"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a unified low-bit inference framework for openPangu-Embedded models, supporting INT8 (W8A8) and W4A8 quantization optimized for the Atlas A2 Ascend NPU. 2. Provides a comprehensive evaluation of quantization across three distinct CoT reasoning modes (slow_think, auto_think, no_think) on code generation benchmarks (HumanEval, MBPP). 3. Demonstrates that INT8 quantization preserves over 90% of FP16 accuracy with a 1.5x prefill speedup, while W4A8 significantly reduces memory consumption, enabling efficient CoT reasoning on edge NPUs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07e9cf3e7e8252aa7eae3fdf2e7647007d4786dd6ade9f5c4e940d1c74c4e2cd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07e9cf3e7e8252aa7eae3fdf2e7647007d4786dd6ade9f5c4e940d1c74c4e2cd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high memory and latency overhead of deploying Chain-of-Thought (CoT) enabled openPangu models on Ascend NPUs by applying post-training quantization (INT8 and W4A8). The proposed framework, optimized for the Atlas A2 hardware, maintains high accuracy for INT8 and reduces memory for W4A8, enabling efficient on-device CoT reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[CoT\u63a8\u7406\u5e26\u6765\u9ad8\u5185\u5b58\u4e0e\u5ef6\u8fdf / CoT reasoning causes high memory & latency]\n    B --\x3e B2[Ascend NPU\u90e8\u7f72\u6311\u6218 / Deployment challenge on Ascend NPU]\n    C --\x3e C1[\u4f4e\u6bd4\u7279\u91cf\u5316 / Low-bit Quantization]\n    C --\x3e C2[\u7edf\u4e00\u63a8\u7406\u6846\u67b6 / Unified Inference Framework]\n    C --\x3e C3[\u652f\u6301W8A8\u4e0eW4A8 / Supports W8A8 & W4A8]\n    D --\x3e D1[INT8\u4fdd\u6301>90%\u7cbe\u5ea6 / INT8 preserves >90% accuracy]\n    D --\x3e D2[1.5\u500d\u9884\u586b\u5145\u52a0\u901f / 1.5x prefill speedup]\n    D --\x3e D3[W4A8\u663e\u8457\u51cf\u5c11\u5185\u5b58 / W4A8 greatly reduces memory]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] SoulX-LiveTalk Technical Report"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [Self-correcting Bidirectional Distillation, Multi-step Retrospective Self-Correction, hybrid sequence parallelism, Parallel VAE, kernel-level optimizations]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Le Shen, Qiao Qian, Tan Yu, Ke Zhou, Tianhang Yu, Yu Zhan, Zhenjie Wang, Ming Tao, Shunshun Yin, Siyuan Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Soul AI Lab, Donghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23379",children:"https://arxiv.org/pdf/2512.23379"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://soul-ailab.github.io/soulx-livetalk/",children:"https://soul-ailab.github.io/soulx-livetalk/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a Self-correcting Bidirectional Distillation strategy that retains bidirectional attention within video chunks to preserve spatiotemporal correlations and enhance visual fidelity. 2. Proposed a Multi-step Retrospective Self-Correction Mechanism to ensure stability during infinite generation by enabling autonomous recovery from accumulated errors. 3. Engineered a full-stack inference acceleration suite with hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations to achieve real-time performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of deploying large diffusion models for real-time, audio-driven avatar generation by introducing SoulX-LiveTalk, a 14B-parameter framework. It employs a bidirectional distillation strategy and a self-correction mechanism to maintain high visual quality and stability, while a suite of inference optimizations enables sub-second latency and 32 FPS throughput, setting a new standard for interactive digital humans."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SoulX-LiveTalk] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5b9e\u65f6\u65e0\u9650\u65f6\u957f\u97f3\u9891\u9a71\u52a8\u5316\u8eab\u751f\u6210\u4e2d\u8ba1\u7b97\u8d1f\u8f7d\u4e0e\u4f4e\u5ef6\u8fdf\u7684\u51b2\u7a81]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u81ea\u6821\u6b63\u53cc\u5411\u84b8\u998f\u4e0e\u591a\u6b65\u56de\u987e\u81ea\u6821\u6b63\u673a\u5236]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 0.87\u79d2\u542f\u52a8\u5ef6\u8fdf\uff0c32 FPS\u5b9e\u65f6\u541e\u5410]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [log anomaly detection], [collaborative transformers, multi-head impressed attention, modality adaptation layer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mohammad Nasirzadeh, Jafar Tahmoresnezhad, Parviz Rashidi-Khazaee"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Urmia University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23380",children:"https://arxiv.org/pdf/2512.23380"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/your-repo/CoLog",children:"https://github.com/your-repo/CoLog"}),' (Note: The provided text states "We also provide the implementation of CoLog atthis https URL." but the specific URL is cut off in the input. Based on the placeholder, the typical format is used. If the exact URL is required, it would be the one following "atthis" in the original text.)']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CoLog, a unified framework for detecting both point and collective anomalies in OS logs by applying multimodal sentiment analysis concepts. 2. Introduces collaborative transformers and multi-head impressed attention to learn interactions between different log data modalities. 3. Incorporates a modality adaptation layer to handle heterogeneity and adapt representations from different log modalities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c23025b6b24d4efc5cb993659def89fe785700fbc818c9cc638fe55cdfc5b75e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c23025b6b24d4efc5cb993659def89fe785700fbc818c9cc638fe55cdfc5b75e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of log anomaly detection, where existing methods struggle with the multimodal nature of log data and the interactions between these modalities. It proposes CoLog, a framework that uses collaborative transformers and a modality adaptation layer to learn nuanced patterns across log modalities for comprehensive anomaly detection. Extensive experiments show CoLog achieves state-of-the-art performance, with mean precision, recall, and F1 scores over 99.5% across seven benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Unimodal & multimodal methods fail to handle log data modalities and their interactions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: CoLog framework with collaborative transformers, multi-head impressed attention, and modality adaptation layer"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Achieves ~99.6% mean precision, recall, F1 on 7 datasets; superior to SOTA"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Adelaide"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23385",children:"https://arxiv.org/pdf/2512.23385"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Securing the AI Supply Chain] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[AI\u4f9b\u5e94\u94fe\u5b89\u5168\u683c\u5c40\u590d\u6742/Complex AI supply chain security landscape]\n    Problem --\x3e P2[\u7f3a\u4e4f\u5bf9\u5e38\u89c1\u95ee\u9898\u4e0e\u89e3\u51b3\u65b9\u6848\u7684\u4e86\u89e3/Lack of knowledge on common issues & solutions]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u5b9e\u8bc1\u8c03\u67e5/Empirical investigation]\n    M1 --\x3e M1_1[\u6570\u636e\u6e90: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]\n    M1 --\x3e M1_2[\u6784\u5efa\u5206\u7c7b\u7ba1\u9053/Build classification pipeline]\n    M1_2 --\x3e M1_2_1[\u5173\u952e\u8bcd\u5339\u914d+\u5fae\u8c03distilBERT/Keyword matching + fine-tuned distilBERT]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6570\u636e\u96c6: 312,868\u4e2a\u5b89\u5168\u8ba8\u8bba/Dataset: 312,868 security discussions]\n    Results --\x3e R2[\u5206\u7c7b\u6cd5: 32\u4e2a\u95ee\u9898, 24\u4e2a\u89e3\u51b3\u65b9\u6848/Taxonomy: 32 issues, 24 solutions]\n    Results --\x3e R3[\u6d1e\u5bdf: \u4f9d\u8d56\u590d\u6742\u6027\u548c\u9ed1\u76d2\u6027\u5bfc\u81f4\u95ee\u9898/Insight: Issues from dependencies & black-box nature]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Theoretical Foundations of Scaling Law in Familial Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [familial models, scaling law, early exiting, IsoFLOP design, compute-optimal training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huan Song, Qingfei Zhao, Ting Long, Shuyu Tian, Hongjun An, Jiawei Shao, Chi Zhang, Xuelong Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Artificial Intelligence (TeleAI), China Telecom"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23407",children:"https://arxiv.org/pdf/2512.23407"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Theoretically and empirically extends the neural scaling law to the "familial models" paradigm by introducing granularity (G) as a new fundamental scaling variable alongside model size (N) and tokens (D). 2. Proposes a rigorous IsoFLOP experimental design to decouple architectural impact from computational scale, enabling high-fidelity parameterization of the unified scaling law L(N, D, G). 3. Quantifies that the granularity penalty follows a multiplicative power law with an extremely small exponent (\u03b3\u22480.041), validating the "train once, deploy many" paradigm without compromising compute-optimality.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of traditional neural scaling laws, which assume a single model, by extending them to familial models that generate multiple sub-models from one backbone. The authors propose a unified scaling law incorporating granularity (G) and validate it using a rigorous IsoFLOP experimental design. The key finding is that the performance penalty for increased granularity is very small, proving that deployment flexibility can be achieved efficiently."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[Theoretical Foundations of Scaling Law in Familial Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u7f29\u653e\u5b9a\u5f8b\u5ffd\u7565\u591a\u6a21\u578b\u8303\u5f0f/Traditional scaling laws overlook the multi-model paradigm]\n    C --\x3e C1[\u5f15\u5165\u7c92\u5ea6\u4f5c\u4e3a\u65b0\u53d8\u91cf/Introduce Granularity (G) as a new variable]\n    C --\x3e C2[\u7edf\u4e00\u51fd\u6570\u5f62\u5f0f L(N, D, G)/Unified functional form L(N, D, G)]\n    C --\x3e C3[\u91c7\u7528IsoFLOP\u5b9e\u9a8c\u8bbe\u8ba1/Employ rigorous IsoFLOP experimental design]\n    D --\x3e D1[\u7c92\u5ea6\u60e9\u7f5a\u9075\u5faa\u5e42\u5f8b/Granularity penalty follows a power law]\n    D --\x3e D2[\u6307\u6570\u6781\u5c0f (\u03b3\u22480.041)/Exponent is extremely small]\n    D --\x3e D3[\u9a8c\u8bc1"\u4e00\u6b21\u8bad\u7ec3\uff0c\u591a\u6b21\u90e8\u7f72"/Validates "train once, deploy many"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [tool-integrated reasoning, multimodal chain-of-thought, interleaved thinking]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiawei Chen, Xintian Shen, Lihao Zheng, Zhenwei Shao, Hongyuan Zhang, Pengfei Yu, Xudong Rao, Ning Mao, Xiaobo Liu, Lian Wen, Chaoqun Du, Feng Gu, Wei He, Qizhen Li, Shanshan Li, Zide Liu, Jing Luo, Lifu Mu, Xuhao Pan, Chang Ren, Haoyi Sun, Qian Wang, Wei Wang, Hongfu Yang, Jiqing Zhan, Chunpeng Zhou, Zheng Zhou, Hao Ma, Tao Wei, Pan Zhou, Wei Chen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Li Auto Inc"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23412",children:"https://arxiv.org/pdf/2512.23412"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/TIMMY-CHAN/MindWatcher",children:"https://github.com/TIMMY-CHAN/MindWatcher"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces MindWatcher, a TIR agent with interleaved thinking and multimodal CoT reasoning for autonomous tool invocation and coordination. 2. Constructs the MWE-Bench benchmark and releases high-quality datasets and distilled smaller models (2B, 3B, 4B). 3. Designs a more efficient training infrastructure to enhance training speed and hardware utilization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36f0f229f533ecc1b9565a72c5c77b232eab32880c12545774f94ebd2a19e651_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36f0f229f533ecc1b9565a72c5c77b232eab32880c12545774f94ebd2a19e651_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces MindWatcher, a multimodal tool-integrated reasoning agent that uses interleaved thinking and chain-of-thought reasoning to autonomously decide when and how to invoke tools. It is equipped with auxiliary tools and a local image database to handle broad-domain problems. Experiments show it matches or exceeds larger models in performance and provides insights like the genetic inheritance phenomenon in agent training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Traditional workflow-based agents have limited intelligence for real-world tool-invocation problems.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes MindWatcher agent with interleaved thinking and multimodal CoT reasoning for autonomous tool use.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Matches/exceeds larger models, introduces MWE-Bench, and provides efficient training infrastructure.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Directly Constructing Low-Dimensional Solution Subspaces in Deep Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [intrinsic dimension, low-rank approximation, subspace-native distillation, weight matrices, empirical spectral density]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yusuf Kalyoncuoglu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," RWTH Aachen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23410",children:"https://arxiv.org/pdf/2512.23410"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a constructive method to decouple solution geometry from the ambient search space, bypassing the non-convex optimization bottleneck. 2. Empirically demonstrates significant compression (e.g., factor of 16) of classification heads in models like ResNet-50, ViT, and BERT with minimal performance loss. 3. Introduces "Subspace-Native Distillation" as a novel paradigm to provide a stable geometric coordinate system for student models, enabling "Train Big, Deploy Small".']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d34f960cfbb8a9db281aca58a1b30934c42fc68964647e8066a3754aeb92d38_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d34f960cfbb8a9db281aca58a1b30934c42fc68964647e8066a3754aeb92d38_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the redundancy in large neural networks by proposing a method to directly construct low-dimensional solution subspaces, decoupling the solution geometry from the high-dimensional optimization search space. It shows that classification heads can be heavily compressed without significant performance drops. This leads to a new distillation paradigm that allows student models to learn in a stable, low-dimensional subspace, potentially realizing efficient deployment of compact models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Directly Constructing Low-Dimensional Solution Subspaces<br>\u76f4\u63a5\u6784\u5efa\u4f4e\u7ef4\u89e3\u5b50\u7a7a\u95f4"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Large models are redundant for representation but needed for optimization.<br>\u5927\u6a21\u578b\u5bf9\u8868\u793a\u662f\u5197\u4f59\u7684\uff0c\u4f46\u5bf9\u4f18\u5316\u662f\u5fc5\u8981\u7684\u3002"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Construct low-dimensional subspaces, decouple solution geometry.<br>\u6784\u5efa\u4f4e\u7ef4\u5b50\u7a7a\u95f4\uff0c\u89e3\u8026\u89e3\u51e0\u4f55\u3002"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Head compression by 16x, Subspace-Native Distillation.<br>\u5206\u7c7b\u5934\u538b\u7f2916\u500d\uff0c\u63d0\u51fa\u5b50\u7a7a\u95f4\u539f\u751f\u84b8\u998f\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [continual learning], [big world hypothesis, computationally-embedded agent, interactivity, partially observable Markov decision process, model-based reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alex Lewandowski, Adtiya A. Ramesh, Edan Meyer, Dale Schuurmans, Marlos C. Machado"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Alberta, Amii, The Swiss AI Lab IDSIA, USI & SUPSI, Canada CIFAR AI Chair, Google DeepMind"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23419",children:"https://arxiv.org/pdf/2512.23419"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a computationally-embedded perspective, representing an agent as an automaton simulated within a universal computer, proving it's equivalent to interacting with a POMDP over an infinite state-space. 2. Proposed a new objective called \"interactivity\" to measure an agent's ability to continually adapt its behavior by learning new predictions. 3. Developed a model-based RL algorithm for interactivity-seeking and constructed a synthetic problem to evaluate continual learning, finding deep linear networks outperform nonlinear ones in sustaining interactivity as capacity scales."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper proposes a computationally-embedded perspective to formalize the "big world hypothesis" in continual learning, where an agent is modeled as an automaton within the environment. It introduces "interactivity" as a new objective and a corresponding model-based RL algorithm to seek it. The main finding is that, in their synthetic evaluation, deep linear networks sustain higher interactivity as capacity increases, whereas deep nonlinear networks struggle.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis<br>\u8bba\u6587\u6807\u9898"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>\u5982\u4f55\u5f62\u5f0f\u5316\u667a\u80fd\u4f53\u5728\'\u5927\u4e16\u754c\'\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u7ea6\u675f"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u63d0\u51fa\u8ba1\u7b97\u5d4c\u5165\u89c6\u89d2\u4e0e\'\u4ea4\u4e92\u6027\'\u76ee\u6807\uff0c\u5f00\u53d1\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>\u6df1\u5ea6\u7ebf\u6027\u7f51\u7edc\u6bd4\u975e\u7ebf\u6027\u7f51\u7edc\u66f4\u80fd\u7ef4\u6301\u4ea4\u4e92\u6027"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [kernel generation, multi-agent system, domain-specific languages (DSLs), performance tuning, Triton]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huawei Technologies Co., Ltd., Hunan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23424",children:"https://arxiv.org/pdf/2512.23424"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed AKG kernel agent, a multi-agent framework that automates the generation, migration, and performance tuning of computational kernels for diverse hardware platforms. 2. Designed the system to support multiple Domain-Specific Languages (DSLs) like Triton, TileLang, CPP, and CUDA-C, enabling cross-platform portability and correctness. 3. Demonstrated the system's effectiveness through evaluation on KernelBench, achieving an average 1.46x speedup over PyTorch Eager baselines on GPU and NPU backends."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AKG kernel agent, a multi-agent framework that automates the development and optimization of high-performance computational kernels for modern AI workloads across diverse hardware. The system supports multiple DSLs for portability and uses LLMs for code generation and tuning. Evaluation shows it achieves a 1.46x average speedup over baseline implementations, effectively accelerating kernel development."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AKG Kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[AI\u6a21\u578b\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u5185\u6838\u7684\u9700\u6c42 / AI Models Demand High-Performance Kernels]\n    B --\x3e B2[\u786c\u4ef6\u591a\u6837\u6027\u4e0e\u624b\u52a8\u4f18\u5316\u7684\u74f6\u9888 / Hardware Diversity & Manual Optimization Bottleneck]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u5316\u5185\u6838\u751f\u6210\u4e0e\u8c03\u4f18 / Multi-Agent System Automates Kernel Generation & Tuning]\n    C --\x3e C2[\u652f\u6301\u591a\u79cdDSL\u4ee5\u9762\u5411\u4e0d\u540c\u786c\u4ef6\u540e\u7aef / Supports Multiple DSLs for Different Hardware Backends]\n    D --\x3e D1[\u5728KernelBench\u4e0a\u8bc4\u4f30 / Evaluated on KernelBench]\n    D --\x3e D2[\u5e73\u5747\u52a0\u901f1.46\u500d / Average 1.46x Speedup Achieved]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image classification], [convolutional neural networks, fuzzy logic, road surface classification, intelligent transport systems, data fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mustafa Demetgul, Sanja Lazarova Molnar"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Karlsruhe Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23436",children:"https://arxiv.org/pdf/2512.23436"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a real-time system for road surface classification by fusing weather-conditional data and road condition data. 2. Compares the performance of multiple deep learning CNNs (AlexNet, LeNet, VGG, ResNet) on both image-based and acceleration-data-as-image classification tasks. 3. Introduces the use of fuzzy logic to classify road surfaces according to environmental factors like weather and time of day, using sensor data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a real-time system for road surface condition monitoring. It employs deep learning CNNs to classify road types from images and acceleration data, achieving over 95% accuracy, and suggests using fuzzy logic to incorporate weather and time-of-day factors. The work aims to enhance vehicle safety and autonomous driving systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Classical road monitoring is expensive and unsystematic.]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Use deep learning (CNN) on images/acceleration data and fuzzy logic for environmental context.]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Over 95% classification accuracy achieved.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Mobile-Efficient Speech Emotion Recognition Using DistilHuBERT: A Cross-Corpus Validation Study"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [DistilHuBERT, 8-bit quantization, cross-corpus validation, Leave-One-Session-Out (LOSO), model compression]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Saifelden M. Ismail"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology, Zewail City"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23435",children:"https://arxiv.org/pdf/2512.23435"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes a mobile-efficient SER system using a distilled and 8-bit quantized DistilHuBERT model, achieving a 92% parameter reduction and a 23 MB footprint. 2. Demonstrates that cross-corpus training with CREMA-D enhances generalization on IEMOCAP, improving accuracy and reducing variance. 3. Provides an analysis of cross-corpus evaluation on RAVDESS, revealing a "theatricality effect" where predictions cluster by arousal, and establishes a Pareto-optimal trade-off between model size and accuracy.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0945944056b62e3ffa17bd0a2e4e36ebfe24da404a4aea1692a6806374437b15_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0945944056b62e3ffa17bd0a2e4e36ebfe24da404a4aea1692a6806374437b15_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of deploying Speech Emotion Recognition (SER) on mobile devices by proposing a system based on the compressed DistilHuBERT model. Through rigorous cross-validation and cross-corpus training, the method achieves a good balance between a small model size (23 MB) and competitive accuracy, enabling practical on-device affect recognition while analyzing generalization challenges across different emotional speech corpora."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Mobile-Efficient Speech Emotion Recognition Using DistilHuBERT: A Cross-Corpus Validation Study"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: SER\u90e8\u7f72\u53d7\u9650\u4e8e\u5927\u6a21\u578b\u7684\u8ba1\u7b97\u9700\u6c42/SER deployment constrained by computational demands of large models"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: \u4f7f\u7528\u84b8\u998f\u4e0e8\u4f4d\u91cf\u5316\u7684DistilHuBERT\uff0c\u5e76\u8fdb\u884c\u8de8\u8bed\u6599\u5e93\u8bad\u7ec3/Use distilled & 8-bit quantized DistilHuBERT with cross-corpus training"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results: \u6a21\u578b\u4ec523MB\uff0c\u7cbe\u5ea6\u8fbe\u57fa\u51c691%\uff0c\u8de8\u8bed\u6599\u5e93\u8bad\u7ec3\u63d0\u5347\u6cdb\u5316\u6027/Model is 23MB, achieves ~91% of baseline accuracy, cross-corpus training improves generalization"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [hallucination mitigation, coarse-to-fine conditioning, Wasserstein fusion, generative feedback, training-free decoding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zongsheng Cao, Yangfan He, Anran Liu, Jun Xie, Feng Chen, Zepeng Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Lenovo (PCIE), University of Minnesota (UMN)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23453",children:"https://arxiv.org/pdf/2512.23453"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/AI-Researcher-Team/CoFi-Dec",children:"https://github.com/AI-Researcher-Team/CoFi-Dec"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CoFi-Dec, a training-free decoding framework that mitigates hallucinations in LVLMs by integrating generative self-feedback with coarse-to-fine visual conditioning. 2. Introduces a Wasserstein-based fusion mechanism to align predictive distributions from multiple visual conditions into a geometrically consistent decoding trajectory. 3. Demonstrates substantial reduction in both entity-level and semantic-level hallucinations across six benchmarks, showing the framework is model-agnostic and requires no additional training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cab1d37f48692f41be898afb160456b94e821d8b6ea16ba282cb4ee3ac5046_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cab1d37f48692f41be898afb160456b94e821d8b6ea16ba282cb4ee3ac5046_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of hallucinated content in Large Vision-Language Models (LVLMs). It proposes CoFi-Dec, a training-free decoding framework that uses coarse-to-fine visual conditioning and generative feedback to create multi-level visual hypotheses, which are then unified via a Wasserstein-based fusion mechanism. The method significantly reduces hallucinations across multiple benchmarks and can be applied to various LVLMs without retraining."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CoFi-Dec: Hallucination-Resistant Decoding] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LVLMs\u4ea7\u751f\u4e0e\u89c6\u89c9\u8f93\u5165\u4e0d\u4e00\u81f4\u7684\u5e7b\u89c9\u5185\u5bb9]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8e\u7c97\u5230\u7ec6\u89c6\u89c9\u6761\u4ef6\u7684\u751f\u6210\u5f0f\u81ea\u53cd\u9988\u4e0eWasserstein\u878d\u5408]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u6a21\u578b\u65e0\u5173]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23457",children:"https://arxiv.org/pdf/2512.23457"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/zhangkc97/HiR",children:"https://github.com/zhangkc97/HiR"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Replay Failures as Successes: Sample-Efficient RL for Instruction Following] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u7a00\u758f/\u4e0d\u53ef\u533a\u5206\u7684\u5956\u52b1\u963b\u788d\u5b66\u4e60<br>Sparse/Indistinguishable Rewards Impede Learning]\n    Method[\u540e\u89c1\u6307\u4ee4\u91cd\u653e (HiR)<br>Hindsight instruction Replay (HiR)]\n    Results[\u8de8\u4efb\u52a1\u6709\u6548\u4e14\u8ba1\u7b97\u9ad8\u6548<br>Effective Across Tasks & Computationally Efficient]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tencent Hunyuan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23464",children:"https://arxiv.org/pdf/2512.23464"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0",children:"https://github.com/Tencent-Hunyuan/HY-Motion-1.0"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Generating high-quality, text-aligned 3D human motions"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: SOTA performance, Extensive motion coverage, Open-source release"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning from human feedback (RLHF)], [reward model, inductive bias, information bottleneck, mutual information, reward hacking]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Alibaba, The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23461",children:"https://arxiv.org/pdf/2512.23461"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Qwen-Applications/DIR",children:"https://github.com/Qwen-Applications/DIR"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DIR, a novel information-theoretic debiasing method for reward models that maximizes mutual information with human preference while minimizing it with biased attributes. 2. Theoretically justifies the method's ability to handle complex, non-linear inductive biases, extending beyond simple linear correlation models. 3. Empirically demonstrates DIR's effectiveness in mitigating three types of biases (length, sycophancy, format) and shows it enhances RLHF performance and generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of inductive biases in reward models (RMs) for RLHF, which can lead to overfitting and reward hacking. It proposes DIR, an information-theoretic debiasing method inspired by the information bottleneck that optimizes mutual information to reduce bias. Experiments show DIR effectively mitigates multiple biases and improves RLHF performance and generalization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Eliminating Inductive Bias in Reward Models<br>\u6d88\u9664\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u5f52\u7eb3\u504f\u5dee] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Low-quality RM data with inductive biases<br>\u5bfc\u81f4\u8fc7\u62df\u5408\u548c\u5956\u52b1\u653b\u51fb] --\x3e B1[\u4e3e\u4f8b/Example<br>Response length bias<br>\u54cd\u5e94\u957f\u5ea6\u504f\u5dee]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>DIR: Information-theoretic debiasing<br>\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u4f18\u5316\u4e92\u4fe1\u606f] --\x3e C1[\u76ee\u6807/Objective<br>Max MI with preference, Min MI with bias<br>\u6700\u5927\u5316\u504f\u597d\u4e92\u4fe1\u606f\uff0c\u6700\u5c0f\u5316\u504f\u5dee\u4e92\u4fe1\u606f]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Mitigates multiple biases & enhances RLHF<br>\u51cf\u8f7b\u591a\u79cd\u504f\u5dee\u5e76\u63d0\u5347RLHF\u6027\u80fd] --\x3e D1[\u9a8c\u8bc1\u7684\u504f\u5dee/Verified Biases<br>Length, Sycophancy, Format<br>\u957f\u5ea6\u3001\u8fce\u5408\u6027\u3001\u683c\u5f0f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text clustering], [hierarchical clustering, density-based clustering, semantic embeddings, large language models, topic modeling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Thomas Haschka, Joseph Bakarji"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Technische Universit\xe4t Wien, American University of Beirut"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23471",children:"https://arxiv.org/pdf/2512.23471"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel nested density clustering method to construct hierarchical semantic trees from text embeddings. 2. Demonstrates the method's application for data-driven discovery of research areas and subfields without predefined categories. 3. Validates the approach's robustness and general applicability across diverse domains using benchmark datasets like 20 Newsgroups and IMDB reviews."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e39c485de109f72521e714f1d7489795a2f6737dcaff2fbddf6af40f9dc170ee_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e39c485de109f72521e714f1d7489795a2f6737dcaff2fbddf6af40f9dc170ee_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of uncovering the global hierarchical semantic structure in text corpora, which remains opaque when using LLM embeddings only for similarity search. It proposes a method that applies nested density clustering on LLM embeddings, gradually relaxing a density criterion to merge clusters into a hierarchical tree. This approach enables the data-driven discovery of semantic relationships and topic hierarchies without predefined categories, as demonstrated on scientific abstracts and benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Semantic Tree Inference on Text Corpa / \u6587\u672c\u8bed\u6599\u5e93\u7684\u8bed\u4e49\u6811\u63a8\u65ad"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Opaque global semantic structure in text corpora / \u6587\u672c\u8bed\u6599\u5e93\u4e2d\u4e0d\u900f\u660e\u7684\u5168\u5c40\u8bed\u4e49\u7ed3\u6784"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Nested density clustering on LLM embeddings / \u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u7684\u5d4c\u5957\u5bc6\u5ea6\u805a\u7c7b"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Data-driven hierarchical semantic tree discovery / \u6570\u636e\u9a71\u52a8\u7684\u5c42\u6b21\u5316\u8bed\u4e49\u6811\u53d1\u73b0"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [software supply chain security], [agentic AI, reinforcement learning, large language model, blockchain security ledger, CI/CD]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Islamic University of Madinah, Arab Open University-Bahrain"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23480",children:"https://arxiv.org/pdf/2512.23480"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Agentic AI for Autonomous Defense in Software Supply Chain Security] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u6eaf\u6e90\u6846\u67b6\u65e0\u6cd5\u4e3b\u52a8\u7f13\u89e3\u6f0f\u6d1e/Traditional provenance frameworks lack active vulnerability mitigation]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u534f\u8c03/Multi-Agent Coordination]\n    C --\x3e C2[LLM\u63a8\u7406\u4e0eRL\u7b56\u7565/LLM Reasoning & RL]\n    C --\x3e C3[\u96c6\u6210CI/CD\u4e0e\u533a\u5757\u94fe\u65e5\u5fd7/CI/CD Integration & Blockchain Ledger]\n    D --\x3e D1[\u66f4\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u7387/Higher Detection Accuracy]\n    D --\x3e D2[\u66f4\u77ed\u7684\u7f13\u89e3\u5ef6\u8fdf/Lower Mitigation Latency]\n    D --\x3e D3[\u5408\u7406\u7684\u6784\u5efa\u5f00\u9500/Reasonable Build Overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [post-training (sft/rlhf)], [Parameter-efficient fine-tuning, LoRA, full-rank adaptation, rotational degrees of freedom, hierarchical joint decomposition]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guoan Wan, Tianyu Chen, Fangzheng Feng, Haoyi Zhou, Runhua Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beihang University, Huazhong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23485",children:"https://arxiv.org/pdf/2512.23485"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Bane-Elvin/AAAI2026-FRoD",children:"https://github.com/Bane-Elvin/AAAI2026-FRoD"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes FRoD, a novel PEFT method that combines hierarchical joint decomposition with rotational degrees of freedom for full-rank updates. 2. Introduces a globally shared basis and sparse, learnable perturbations to enhance expressiveness and efficiency beyond low-rank constraints. 3. Demonstrates that FRoD matches full fine-tuning accuracy on 20 benchmarks while using only 1.72% of trainable parameters and achieves faster convergence."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e211fe6dc2d8e782c731fff29ba32c9fe2a1f958b475d5931d50f6e8fd04fdb8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e211fe6dc2d8e782c731fff29ba32c9fe2a1f958b475d5931d50f6e8fd04fdb8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the slow convergence and limited capacity of low-rank PEFT methods like LoRA. It proposes FRoD, a method that enables full-rank updates via a shared basis and sparse perturbations, achieving faster convergence. The method matches full fine-tuning accuracy on diverse benchmarks while using only a tiny fraction of parameters."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FRoD: Full-Rank Efficient Fine-Tuning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Low-rank PEFT methods suffer from slow convergence and limited adaptation capacity]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Hierarchical joint decomposition with rotational degrees of freedom for full-rank updates]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Matches full fine-tuning accuracy using only 1.72% parameters and achieves faster convergence]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Theory of Mind for Explainable Human-Robot Interaction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [human-robot interaction], [Theory of Mind, Explainable AI, XAI evaluation, human-centered explanation, VXAI framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Marie Bauer, Julia Gachot, Matthias Kerzel, Cornelius Weber, Stefan Wermter"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Hamburg"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23482",children:"https://arxiv.org/pdf/2512.23482"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes to conceptualize Theory of Mind (ToM) in Human-Robot Interaction as a form of Explainable AI (XAI), 2. Identifies a critical gap in ToM-HRI research regarding the fidelity of explanations to the robot's actual internal reasoning, 3. Advocates for integrating ToM principles into XAI frameworks to shift focus towards user-centered explanations and enable evaluation using frameworks like VXAI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16cba35efa080097fd84afa40a6d270891cd44dfcf26d46fde5d29edb9bb1541_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16cba35efa080097fd84afa40a6d270891cd44dfcf26d46fde5d29edb9bb1541_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies that Theory of Mind (ToM) in human-robot interaction and Explainable AI (XAI) share the goal of making AI reasoning understandable. It proposes to treat ToM as a form of XAI and argues for integrating ToM's user-centered perspective into XAI frameworks to address the lack of explanation fidelity and user-centered evaluation in current research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Theory of Mind for Explainable Human-Robot Interaction") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("ToM\u89e3\u91ca\u4e0e\u673a\u5668\u4eba\u5185\u90e8\u63a8\u7406\u4e0d\u4e00\u81f4/ToM explanations may not match robot\'s internal reasoning")\n    Problem --\x3e P2("XAI\u7f3a\u4e4f\u4ee5\u7528\u6237\u4e3a\u4e2d\u5fc3\u7684\u89e3\u91ca/XAI lacks user-centered explanations")\n    Method --\x3e M1("\u5c06ToM\u89c6\u4e3aXAI\u7684\u4e00\u79cd\u5f62\u5f0f/Consider ToM as a form of XAI")\n    Method --\x3e M2("\u5728XAI\u6846\u67b6\u5185\u6574\u5408ToM\u539f\u5219/Integrate ToM principles within XAI frameworks")\n    Results --\x3e R1("\u63d0\u51fa\u89c6\u89d2\u8f6c\u53d8\uff0c\u4f18\u5148\u8003\u8651\u7528\u6237\u9700\u6c42/Proposed shift in perspective to prioritize user\'s needs")\n    Results --\x3e R2("\u4e3a\u4f7f\u7528VXAI\u7b49\u6846\u67b6\u8bc4\u4f30ToM\u5960\u5b9a\u57fa\u7840/Laid foundation for evaluating ToM using frameworks like VXAI")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [model selection, capability-cost frontier, constrained optimization, deployment-aware leaderboards, compliance trade-offs]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vassilis Digalakis Jr, Ramayya Krishnan, Gonzalo Martin Fernandez, Agni Orfanoudaki"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Boston University, Carnegie Mellon University, Universitat Polit\xe8cnica de Catalunya, Oxford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23487",children:"https://arxiv.org/pdf/2512.23487"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ML Compass, a framework that treats AI model selection as constrained optimization over a capability-cost frontier to bridge the gap between capability leaderboards and deployment decisions. 2. Characterizes optimal model configurations theoretically, showing a three-regime structure in internal measures and deriving comparative statics for budget, regulation, and technology changes. 3. Implements a practical pipeline that extracts internal measures, estimates an empirical frontier, learns task-specific utility, and validates with case studies in conversational and healthcare settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c28f58754a80430c57b0351355d200ab9fbfde8dd5fafc1b0d5caf4dd85bbb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c28f58754a80430c57b0351355d200ab9fbfde8dd5fafc1b0d5caf4dd85bbb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the gap between AI model capability rankings and real-world deployment decisions by introducing ML Compass, a framework that formulates model selection as constrained optimization over a capability-cost frontier. It combines theoretical analysis of optimal configurations with an implementation pipeline for recommendation, validated in conversational and healthcare case studies. The framework shows that deployment-aware rankings can differ significantly from capability-only leaderboards, clarifying trade-offs between capability, cost, and compliance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("ML Compass: Navigating Capability, Cost, and Compliance Trade-offs in AI Model Deployment") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u80fd\u529b\u6392\u884c\u699c\u4e0e\u90e8\u7f72\u51b3\u7b56\u8131\u8282/Capability-Deployment Gap")\n    Problem --\x3e P2("\u9700\u5e73\u8861\u7528\u6237\u6548\u7528\u3001\u6210\u672c\u3001\u5408\u89c4\u6027/Balance Utility, Cost, Compliance")\n    Method --\x3e M1("\u7406\u8bba: \u57fa\u4e8e\u524d\u6cbf\u7684\u7ea6\u675f\u4f18\u5316/Theoretical Constrained Optimization")\n    Method --\x3e M2("\u5b9e\u73b0: \u63d0\u53d6\u3001\u4f30\u8ba1\u3001\u5b66\u4e60\u3001\u63a8\u8350/Pipeline: Extract, Estimate, Learn, Recommend")\n    Results --\x3e R1("\u6700\u4f18\u914d\u7f6e\u5448\u73b0\u4e09\u533a\u7ed3\u6784/Optimal Configurations Show Three-Regime Structure")\n    Results --\x3e R2("\u90e8\u7f72\u611f\u77e5\u6392\u540d\u4e0d\u540c\u4e8e\u80fd\u529b\u6392\u540d/Deployment-Aware Rankings Differ from Capability-Only")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [graph reasoning, information gain, multi-agent, off-graph prediction, path retrieval]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haoyu Pei, Zhongyang Liu, Xiangyi Xiao, Xiaocong Du, Haipeng Zhang, Kunpeng Zhang, Suting Hong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ShanghaiTech University, Xi\u2019an Jiaotong-Liverpool University, University of Maryland"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23489",children:"https://arxiv.org/pdf/2512.23489"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://anonymous.4open.science/r/MIRAGE-VC-323F",children:"https://anonymous.4open.science/r/MIRAGE-VC-323F"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed an information-gain-driven path retriever to tackle path explosion in graphs for LLM reasoning. 2. Introduced a multi-agent architecture with learnable gating to fuse heterogeneous evidence streams. 3. Addressed the off-graph prediction challenge in venture capital, demonstrating significant performance gains."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aed24a413df0661b461a6124bbf364c73762a6f25c3c90546bff33f8c4123ebf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aed24a413df0661b461a6124bbf364c73762a6f25c3c90546bff33f8c4123ebf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of predicting venture capital success, an off-graph task requiring reasoning over complex relational evidence. It proposes MIRAGE-VC, a framework that uses information-gain-driven path retrieval and a multi-agent system to distill and reason over investment networks. The method achieves improved prediction performance and offers insights for other off-graph tasks like recommendation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Gaining Paths to Investment Success<br/>\u6295\u8d44\u6210\u529f\u8def\u5f84] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>VC\u9884\u6d4b\u662f\u79bb\u56fe\u4efb\u52a1<br/>VC prediction is off-graph task]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>MIRAGE-VC\u6846\u67b6<br/>\u4fe1\u606f\u589e\u76ca\u8def\u5f84\u68c0\u7d22\u4e0e\u591a\u667a\u80fd\u4f53<br/>MIRAGE-VC: Info-gain path retrieval & multi-agent]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>\u6027\u80fd\u663e\u8457\u63d0\u5347<br/>+5.0% F1, +16.6% Precision@5<br/>Significant performance gains]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sys], [communication & networking], [URLLC, Link Adaptation, Device Scheduling, Deep Reinforcement Learning, Bayesian Optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wei Gao, Paul Zheng, Peng Wu, Yulin Hu, Anke Schmeink"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wuhan University, RWTH Aachen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23493",children:"https://arxiv.org/pdf/2512.23493"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a joint link adaptation and device scheduling design for multi-device URLLC IIoT networks under imperfect CSI, aiming to maximize total transmission rate under strict BLER constraints. 2. Introduces a novel Bayesian Optimization-driven Twin Delayed Deep Deterministic Policy Gradient (BO-TD3) method to adaptively determine device serving order and MCS based on outdated CQI. 3. Develops a BO-based training mechanism to address issues of error sample imbalance and TD3 parameter sensitivity, improving convergence speed and learning reliability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa25685331ccee6042c70838d3438022f95490a2cc609beba627f444cba8cd7c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa25685331ccee6042c70838d3438022f95490a2cc609beba627f444cba8cd7c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of joint link adaptation and device scheduling in URLLC IIoT networks with imperfect channel state information. It proposes a novel deep reinforcement learning method (BO-driven TD3) that adaptively selects the device serving order and modulation schemes, enhanced by Bayesian Optimization for faster and more reliable training. Simulation results show the proposed algorithm achieves faster convergence and higher sum-rate performance compared to existing solutions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[URLLC IIoT\u7f51\u7edc\u7684\u591a\u8bbe\u5907\u52a8\u6001\u8c03\u5ea6\u4e0e\u94fe\u8def\u81ea\u9002\u5e94/URLLC IIoT Multi-device Dynamic Scheduling & Link Adaptation]\n    B --\x3e B2[\u4e0d\u5b8c\u7f8e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f/Imperfect Channel State Information]\n    B --\x3e B3[\u4e25\u683c\u7684\u8bef\u5757\u7387\u7ea6\u675f/Strict Block Error Rate Constraints]\n    C --\x3e C1[\u8d1d\u53f6\u65af\u4f18\u5316\u9a71\u52a8\u7684TD3\u65b9\u6cd5/BO-driven TD3 Method]\n    C --\x3e C2[\u81ea\u9002\u5e94\u786e\u5b9a\u8bbe\u5907\u670d\u52a1\u987a\u5e8f\u4e0eMCS/Adaptively Determine Device Order & MCS]\n    C --\x3e C3[BO\u8bad\u7ec3\u673a\u5236\u6539\u8fdb\u6536\u655b/BO-based Training for Convergence]\n    D --\x3e D1[\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6/Faster Convergence]\n    D --\x3e D2[\u66f4\u9ad8\u7684\u603b\u901f\u7387\u6027\u80fd/Higher Sum-rate Performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [AI alignment], [AI assistance game, AI shutdown, Incomplete preferences, Non-Archimedean utilities]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alessio Benavoli, Alessandro Facchini, Marco Zaffalon"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Trinity College Dublin, SUPSI (University of Applied Sciences and Arts of Southern Switzerland), Kozminski University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23508",children:"https://arxiv.org/pdf/2512.23508"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formally connects the AI assistance and AI shutdown problems to the need for reasoning under uncertainty. 2. Argues that handling incomplete human preferences is a fundamental requirement for safe AI. 3. Proposes that non-Archimedean utility structures are necessary to correctly model and prioritize safety constraints."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea603db1434e19dcd83096c95297f9662c571581eb479d66e87432fcf6a9075_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea603db1434e19dcd83096c95297f9662c571581eb479d66e87432fcf6a9075_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes AI safety through the frameworks of the AI assistance and AI shutdown games. It argues that to address these challenges, AI agents must be designed to reason under uncertainty and handle incomplete and non-Archimedean human preferences. The main conclusion is that these capabilities are essential for ensuring AI systems remain aligned with human values and safe."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: AI Alignment and Safety"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Analyze via AI Assistance & Shutdown Games"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Requires Uncertainty, Incomplete & Non-Archimedean Preferences"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal training], [vision-language model, unified model, semantic generation, autoregression, data scaling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Fengjiao Chen, Minhao Jing, Weitao Lu, Yan Feng, Xiaoyu Li, Xuezhi Cao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Meituan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23512",children:"https://arxiv.org/pdf/2512.23512"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that generation enhances understanding in large-scale VLM training only when operating at the semantic level (e.g., autoregressing high-level visual representations), not at the pixel level. 2. Shows that unified generation-understanding models exhibit superior data scaling trends and higher data utilization efficiency compared to understanding-only models. 3. Proposes that autoregression on input embeddings is an effective and modality-independent method for capturing visual details, enabling pixel-level generation from learned semantics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75dffd20dae849b9b4d37288d6d557fa32f5f2c8bf947c87fc1e79319e9dbe8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75dffd20dae849b9b4d37288d6d557fa32f5f2c8bf947c87fc1e79319e9dbe8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether visual generation tasks can enhance understanding in large-scale vision-language models. Through large-scale pretraining (>200M samples) with a model called UniHetero, the authors find that semantic-level generation (not pixel-level) improves understanding, reveals better data scaling, and that autoregression on input embeddings effectively captures visual details."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Does visual generation enhance understanding at large scale?);\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Large-scale pretraining of unified model UniHetero (>200M samples));\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results);\n    B --\x3e D;\n    C --\x3e D;\n    D --\x3e E(\u7ed3\u679c1/Result 1: Generation helps, but Only if you generate Semantics, Not Pixels);\n    D --\x3e F(\u7ed3\u679c2/Result 2: Superior Data Scaling trend and higher Data Utilization);\n    D --\x3e G(\u7ed3\u679c3/Result 3: Autoregression on Input Embedding is effective);"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [diffusion models], [multi-subject customization, layout guidance, attention decoupling, training-free, image adapter]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Binhe Yu, Zhen Wang, Kexin Li, Yuqian Yuan, Wenqiao Zhang, Long Chen, Juncheng Li, Jun Xiao, Yueting Zhuang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, HKUST (The Hong Kong University of Science and Technology)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23537",children:"https://arxiv.org/pdf/2512.23537"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AnyMS, a novel training-free framework for layout-guided multi-subject image customization. 2. Introduces a bottom-up dual-level attention decoupling mechanism (global and local) to balance text alignment, identity preservation, and layout control. 3. Employs pre-trained image adapters to extract subject features without requiring subject-specific training or adapter tuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e5ac220ed9f71a26f20317e74d4ddc9cd5a957b5751dba85f593ddfeaf39640_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e5ac220ed9f71a26f20317e74d4ddc9cd5a957b5751dba85f593ddfeaf39640_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating coherent images containing multiple user-specified subjects while balancing text alignment, subject identity, and layout control. It proposes AnyMS, a training-free framework that uses a bottom-up attention decoupling mechanism and pre-trained adapters to integrate text, subject images, and layout constraints. The method achieves state-of-the-art performance, supporting complex compositions and scaling to many subjects."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AnyMS: \u5e03\u5c40\u5f15\u5bfc\u514d\u8bad\u7ec3\u591a\u4e3b\u4f53\u5b9a\u5236] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u591a\u4e3b\u4f53\u5b9a\u5236\u4e2d\u6587\u672c\u5bf9\u9f50\u3001\u8eab\u4efd\u4fdd\u6301\u4e0e\u5e03\u5c40\u63a7\u5236\u7684\u5e73\u8861\u95ee\u9898/Balancing text alignment, identity preservation, and layout control in multi-subject customization]\n    C --\x3e C1[\u63d0\u51fa\u514d\u8bad\u7ec3\u6846\u67b6AnyMS/Proposes training-free framework AnyMS]\n    C1 --\x3e C2[\u5f15\u5165\u81ea\u5e95\u5411\u4e0a\u53cc\u7ea7\u6ce8\u610f\u529b\u89e3\u8026\u673a\u5236/Introduces bottom-up dual-level attention decoupling]\n    C2 --\x3e C3[\u5168\u5c40\u89e3\u8026\u786e\u4fdd\u6587\u672c\u5bf9\u9f50/Global decoupling ensures text alignment]\n    C2 --\x3e C4[\u5c40\u90e8\u89e3\u8026\u9632\u6b62\u4e3b\u4f53\u51b2\u7a81/Local decoupling prevents subject conflicts]\n    C --\x3e C5[\u4f7f\u7528\u9884\u8bad\u7ec3\u56fe\u50cf\u9002\u914d\u5668\u63d0\u53d6\u7279\u5f81/Uses pre-trained image adapters for feature extraction]\n    D --\x3e D1[\u5b9e\u73b0SOTA\u6027\u80fd/Achieves SOTA performance]\n    D --\x3e D2[\u652f\u6301\u590d\u6742\u7ec4\u5408\u4e0e\u66f4\u591a\u4e3b\u4f53/Supports complex compositions and scales to more subjects]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [computational pathology], [agentic multimodal model, evidence-seeking inference, reinforcement learning, whole-slide images, vision-language model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shengyi Hua, Jianfeng Wu, Tianle Shen, Kangzhe Hu, Zhongzhen Huang, Shujuan Ni, Zhihong Zhang, Yuan Li, Zhe Wang, Xiaofan Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Fourth Military Medical University, University of Science and Technology of China, Fudan University, Nanjing Medical University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23545",children:"https://arxiv.org/pdf/2512.23545"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed PathFound, an agentic multimodal model that introduces an evidence-seeking inference paradigm for pathological diagnosis, moving beyond static, single-pass analysis. 2. Integrated pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to enable proactive information acquisition and multi-stage diagnosis refinement. 3. Demonstrated that the evidence-seeking strategy consistently improves diagnostic accuracy across models and that PathFound achieves state-of-the-art performance, showing strong potential for discovering subtle pathological details."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes PathFound, an agentic multimodal model that mimics clinical workflows by actively seeking evidence for ambiguous pathological diagnoses through multi-turn interactions. It integrates visual foundation models, vision-language models, and reinforcement learning-based reasoning to refine its initial diagnosis. The method achieves state-of-the-art diagnostic accuracy and demonstrates the effectiveness of evidence-seeking workflows in computational pathology."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PathFound: Agentic Multimodal Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Static inference vs. clinical workflow]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic model with VFM, VLM, RL]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: SOTA accuracy, discovers subtle details]\n    B --\x3e B1[\u9759\u6001\u63a8\u7406\u8303\u5f0f/Static inference paradigm]\n    B --\x3e B2[\u7f3a\u4e4f\u8bc1\u636e\u518d\u83b7\u53d6/Lacks reassessment & evidence acquisition]\n    C --\x3e C1[\u591a\u9636\u6bb5\u8bca\u65ad/Multi-stage diagnosis]\n    C --\x3e C2[\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6/Proactive information acquisition]\n    D --\x3e D1[\u8bca\u65ad\u51c6\u786e\u6027\u63d0\u5347/Improved diagnostic accuracy]\n    D --\x3e D2[\u53d1\u73b0\u7ec6\u5fae\u7279\u5f81/Discover subtle pathological features]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Act2Goal: From World Model To General Goal-conditioned Policy"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [goal-conditioned policy, world model, multi-scale temporal hashing, hindsight goal relabeling, LoRA]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pengfei Zhou, Liliang Chen, Shengcong Chen, Di Chen, Wenzhi Zhao, Rongjun Jin, Guanghui Ren, Jianlan Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Agibot Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23541",children:"https://arxiv.org/pdf/2512.23541"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://act2goal.github.io/",children:"https://act2goal.github.io/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control for long-horizon tasks. 2. Introduces Multi-Scale Temporal Hashing (MSTH) to decompose imagined visual trajectories into dense proximal and sparse distal frames for fine-grained control and global consistency. 3. Enables reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c80e64501db97d2a806134a5544d87a826563f38be2334e8bdec4a9d7f9cf78_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c80e64501db97d2a806134a5544d87a826563f38be2334e8bdec4a9d7f9cf78_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of long-horizon robotic manipulation by proposing Act2Goal, a policy that uses a goal-conditioned world model to generate visual plans and a multi-scale temporal control mechanism for robust execution. The method achieves strong zero-shot generalization and allows for rapid online adaptation. Real-robot experiments show it significantly improves success rates on out-of-distribution tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Act2Goal: From World Model To General Goal-conditioned Policy] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u76ee\u6807\u6761\u4ef6\u7b56\u7565\u5728\u957f\u89c6\u91ce\u64cd\u4f5c\u4e2d\u8868\u73b0\u4e0d\u4f73/Existing goal-conditioned policies struggle with long-horizon manipulation]\n    C --\x3e C1[\u96c6\u6210\u76ee\u6807\u6761\u4ef6\u89c6\u89c9\u4e16\u754c\u6a21\u578b\u4e0e\u591a\u5c3a\u5ea6\u65f6\u5e8f\u63a7\u5236/Integrates goal-conditioned visual world model with multi-scale temporal control]\n    C --\x3e C2[\u5f15\u5165\u591a\u5c3a\u5ea6\u65f6\u5e8f\u54c8\u5e0c(MSTH)\u5206\u89e3\u8f68\u8ff9/Introduces Multi-Scale Temporal Hashing (MSTH) to decompose trajectory]\n    D --\x3e D1[\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u5f3a/Strong zero-shot generalization]\n    D --\x3e D2[\u901a\u8fc7\u5728\u7ebf\u81ea\u9002\u5e94\u663e\u8457\u63d0\u5347\u6210\u529f\u7387/Improves success rates significantly via online adaptation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection], [knowledge graphs, self-detection, structured verification, GPT-4o, Gemini-2.5-Flash]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sahil Kale, Antonio Luca Alfeo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Knowledge Verse AI, eCampus University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23547",children:"https://arxiv.org/pdf/2512.23547"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/knowledge-verse-ai/kg-hallu-eval",children:"https://github.com/knowledge-verse-ai/kg-hallu-eval"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel hallucination self-detection method that converts LLM responses into knowledge graphs for structured analysis., 2. Introduces a manually curated and enhanced hallucination detection dataset to support more reliable future benchmarking., 3. Demonstrates significant performance improvements (up to 16% accuracy, 20% F1) over standard self-detection and a state-of-the-art baseline (SelfCheckGPT)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a76b4a88e64d73392aa8d986a7f3dab5da424782ba41d701ca8db2d4ab4a12d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a76b4a88e64d73392aa8d986a7f3dab5da424782ba41d701ca8db2d4ab4a12d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of hallucinations in LLMs by proposing a self-detection method that converts model responses into knowledge graphs to better analyze atomic facts and estimate hallucination likelihood. The method, evaluated on GPT-4o and Gemini-2.5-Flash, shows substantial improvements in accuracy and F1-score over existing approaches. The work concludes that structuring facts as knowledge graphs enables more robust hallucination detection, offering a low-cost, model-agnostic path toward safer language models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: LLM Hallucinations hinder safe deployment"]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: Convert responses to Knowledge Graphs for structured self-verification"]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results: Up to 16% accuracy & 20% F1 improvement over baselines"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [ai security], [prompt injection, multi-agent systems, provenance tracking, trust validation, multimodal sanitization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Toqeer Ali Syed, Mishal Ateeq Almutairi, Mahmoud Abdel Moaty"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Islamic University of Madinah, Arab Open University-Bahrain"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23557",children:"https://arxiv.org/pdf/2512.23557"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Cross-Agent Multimodal Provenance-Aware Defense Framework to secure agentic AI workflows against prompt injection attacks. 2. Introduces a coordinated defense with specialized sanitizer agents (text, visual) and an output validator, managed by a provenance ledger for tracking trust metadata. 3. Demonstrates through experiments that the framework significantly improves multimodal injection detection accuracy and minimizes trust leakage across agents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05cd3aa22e07307bda78f06b6f87c2195c61c758b4fe44dc5bffbc281d72a8e4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05cd3aa22e07307bda78f06b6f87c2195c61c758b4fe44dc5bffbc281d72a8e4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the security threat of multimodal prompt injection attacks in agentic AI systems like LangChain. It proposes a defense framework that sanitizes inputs and validates outputs using specialized agents coordinated by a provenance ledger. The experimental results show the framework enhances detection accuracy and stabilizes agentic execution pathways."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Toward Trustworthy Agentic AI<br>\u6784\u5efa\u53ef\u4fe1\u7684\u667a\u80fd\u4f53AI] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Multimodal Prompt Injection Attacks<br>\u591a\u6a21\u6001\u63d0\u793a\u6ce8\u5165\u653b\u51fb]\n    C --\x3e C1[Cross-Agent Provenance-Aware Framework<br>\u8de8\u667a\u80fd\u4f53\u6eaf\u6e90\u611f\u77e5\u6846\u67b6]\n    C1 --\x3e C2[Sanitizer & Validator Agents<br>\u51c0\u5316\u4e0e\u9a8c\u8bc1\u667a\u80fd\u4f53]\n    C1 --\x3e C3[Provenance Ledger<br>\u6eaf\u6e90\u8d26\u672c]\n    D --\x3e D1[Enhanced Detection Accuracy<br>\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u7387]\n    D --\x3e D2[Minimized Trust Leakage<br>\u6700\u5c0f\u5316\u4fe1\u4efb\u6cc4\u6f0f]\n    D --\x3e D3[Stable Execution Pathways<br>\u7a33\u5b9a\u7684\u6267\u884c\u8def\u5f84]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] VL-RouterBench: A Benchmark for Vision-Language Model Routing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision-language model routing, benchmark, cost-accuracy trade-off, model selection, evaluation protocol]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhehao Huang, Baijiong Lin, Jingyuan Zhang, Jingying Wang, Yuhang Liu, Ning Lu, Tao Li, Xiaolin Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, The Hong Kong University of Science and Technology (Guangzhou), The Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23562",children:"https://arxiv.org/pdf/2512.23562"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/K1nght/VL-RouterBench",children:"https://github.com/K1nght/VL-RouterBench"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VL-RouterBench, the first systematic and reproducible benchmark for evaluating vision-language model (VLM) routing systems. 2. Constructs a large-scale evaluation foundation with quality and cost matrices over 519,180 sample-model pairs from 17 models and 14 datasets. 3. Introduces a comprehensive evaluation protocol that jointly measures accuracy, cost, and throughput, and uses a ranking score based on the harmonic mean for fair comparison across router configurations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces VL-RouterBench, a benchmark to systematically evaluate routing systems for vision-language models. It constructs matrices of quality and cost from extensive inference logs and uses a ranking score to compare routers. The evaluation shows current routers achieve significant gains but still fall short of an ideal Oracle, indicating room for improvement in router design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[VL-RouterBench: A Benchmark for Vision-Language Model Routing] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>\u7f3a\u4e4f\u7cfb\u7edf\u5316\u3001\u53ef\u590d\u73b0\u7684<br>VLM\u8def\u7531\u8bc4\u4f30\u57fa\u51c6<br>Lack of systematic, reproducible<br>benchmark for VLM routing]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u57fa\u4e8e\u539f\u59cb\u63a8\u7406\u65e5\u5fd7\u6784\u5efa<br>\u8d28\u91cf\u4e0e\u6210\u672c\u77e9\u9635<br>Construct quality & cost matrices<br>from raw inference logs]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>\u89c2\u5bdf\u5230\u663e\u8457\u7684\u8def\u7531\u589e\u76ca<br>\u4f46\u4e0e\u7406\u60f3\u6027\u80fd\u4ecd\u6709\u5dee\u8ddd<br>Observe significant routability gain<br>but clear gap to ideal Oracle]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multimodal large language models], [chemical reaction understanding, multimodal benchmark, scientific literature, visual perception, cross-modal integration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hanzheng Li, Xi Fang, Yixuan Li, Chaozheng Huang, Junjie Wang, Xi Wang, Hongzhe Bai, Bojun Hao, Shenyu Lin, Huiqi Liang, Linfeng Zhang, Guolin Ke"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," DP Technology, Shanghai Jiao Tong University, Tsinghua University, New York University, Fudan University, Xiamen University, ShanghaiTech University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23565",children:"https://arxiv.org/pdf/2512.23565"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces RxnBench, a multi-tiered benchmark for evaluating MLLMs on chemical reaction understanding from scientific PDFs, featuring two tasks (SF-QA and FD-QA). 2. Provides a comprehensive evaluation revealing a critical capability gap in MLLMs, showing they struggle with deep chemical logic and precise structural recognition despite excelling at text extraction. 3. Highlights the importance of inference-time reasoning and underscores the urgent need for domain-specific visual encoders and stronger reasoning engines for autonomous AI chemists."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e7b73b049eb3232e03516a09f66b0fddafff9357b89527de70340faa28603c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e7b73b049eb3232e03516a09f66b0fddafff9357b89527de70340faa28603c6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces RxnBench, a multimodal benchmark to evaluate Large Language Models on understanding chemical reactions from scientific literature. The evaluation reveals that while models are good at extracting text, they struggle with chemical logic and structural recognition, showing the need for better domain-specific visual and reasoning components."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[RxnBench: A Multimodal Benchmark for Evaluating LLMs on Chemical Reaction Understanding from Scientific Literature] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: MLLMs' ability to comprehend dense, graphical reaction language in literature is underexplored.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: A multi-tiered benchmark with two tasks: Single-Figure QA and Full-Document QA.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Models struggle with chemical logic and structure; inference-time reasoning helps but accuracy remains low, highlighting need for domain-specific encoders and reasoning engines.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [creative text generation], [divergent-convergent thinking, prompting method, creative problem generation, artificial hivemind, constraint satisfaction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Manh Hung Nguyen, Adish Singla"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," MPI-SWS (Max Planck Institute for Software Systems)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23601",children:"https://arxiv.org/pdf/2512.23601"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CreativeDC, a novel two-phase prompting method inspired by human creative thinking to decouple creative exploration from constraint satisfaction in LLMs. 2. Introduces a comprehensive evaluation framework for creative problem generation, measuring diversity, novelty, and utility. 3. Demonstrates that CreativeDC significantly improves the diversity and novelty of generated educational problems compared to baseline methods while maintaining utility."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86ff3954389096abbd357b8cdc09c7b6f3087b3cf9c2edee2cf008bb8924d692_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86ff3954389096abbd357b8cdc09c7b6f3087b3cf9c2edee2cf008bb8924d692_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the "Artificial Hivemind" effect in LLMs, which leads to homogeneous and repetitive outputs, particularly harmful for generating diverse educational problems. It proposes CreativeDC, a prompting method that scaffolds LLM reasoning into divergent (idea exploration) and convergent (constraint satisfaction) phases. The results show that CreativeDC generates problems with significantly higher diversity and novelty than baselines without sacrificing utility.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Divergent-Convergent Thinking in LLMs for Creative Problem Generation<br/>\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u53d1\u6563-\u6536\u655b\u601d\u7ef4\u7528\u4e8e\u521b\u610f\u95ee\u9898\u751f\u6210"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: LLMs suffer from \'Artificial Hivemind\' effect, generating homogeneous and repetitive educational problems.<br/>\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\'\u4eba\u5de5\u8702\u7fa4\u601d\u7ef4\'\u6548\u5e94\uff0c\u751f\u6210\u540c\u8d28\u5316\u3001\u91cd\u590d\u7684\u6559\u80b2\u95ee\u9898\u3002"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: CreativeDC, a two-phase prompting method decoupling divergent (exploration) and convergent (constraint) thinking.<br/>CreativeDC\uff0c\u4e00\u79cd\u5c06\u53d1\u6563\uff08\u63a2\u7d22\uff09\u4e0e\u6536\u655b\uff08\u7ea6\u675f\uff09\u601d\u7ef4\u89e3\u8026\u7684\u4e24\u9636\u6bb5\u63d0\u793a\u65b9\u6cd5\u3002"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: Achieves higher diversity & novelty while maintaining utility; scales better in generating distinct problems.<br/>\u5728\u4fdd\u6301\u5b9e\u7528\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u9ad8\u7684\u591a\u6837\u6027\u4e0e\u65b0\u9896\u6027\uff1b\u5728\u751f\u6210\u72ec\u7279\u95ee\u9898\u65b9\u9762\u6269\u5c55\u6027\u66f4\u597d\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [transfer learning], [Le Cam Distortion, Deficiency Distance, Directional Simulability, Unsupervised Domain Adaptation, Negative Transfer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Deniz Akdemir"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," None (Institution not specified in provided content)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23617",children:"https://arxiv.org/pdf/2512.23617"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a decision-theoretic framework for robust transfer learning based on Le Cam's theory, replacing symmetric invariance with directional simulability. 2. Introduces Le Cam Distortion, quantified by the Deficiency Distance, as a rigorous upper bound for transfer risk. 3. Demonstrates the framework's effectiveness across diverse experiments (genomics, vision, RL), showing it prevents source degradation and catastrophic negative transfer where traditional methods fail."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper identifies a flaw in standard Unsupervised Domain Adaptation, which can cause harmful "negative transfer" by forcing invariance between unequally informative domains. It proposes a new framework based on Le Cam\'s theory, using directional simulability and a metric called Le Cam Distortion to enable safe transfer without degrading the source domain. Experiments show this method successfully prevents information loss and catastrophic failure in safety-critical applications.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u6807\u51c6UDA\u7684\u7f3a\u9677/Flaw of Standard UDA]\n    Problem --\x3e P2[\u8d1f\u8fc1\u79fb\u4e0e\u4fe1\u606f\u7834\u574f/Negative Transfer & Information Destruction]\n    Method --\x3e M1[Le Cam\u7406\u8bba/Le Cam's Theory]\n    Method --\x3e M2[\u65b9\u5411\u53ef\u6a21\u62df\u6027/Directional Simulability]\n    Method --\x3e M3[Le Cam Distortion\u5ea6\u91cf/Le Cam Distortion Metric]\n    Results --\x3e R1[\u57fa\u56e0\u7ec4\u5b66\u5b8c\u7f8e\u4f30\u8ba1/Perfect Genomics Estimation]\n    Results --\x3e R2[\u96f6\u6e90\u57df\u635f\u5931/Zero Source Utility Loss]\n    Results --\x3e R3[\u5b89\u5168RL\u7b56\u7565\u8f6c\u79fb/Safe RL Policy Transfer]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Regret-Based Federated Causal Discovery with Unknown Interventions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [causal discovery, unknown interventions, differential privacy, \u03a6-CPDAG, regret-based]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Federico Baldo, Charles K. Assaad"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sorbonne Universit\xe9, INSERM, Institut Pierre Louis d'Epid\xe9miologie et de Sant\xe9 Publique"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23626",children:"https://arxiv.org/pdf/2512.23626"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes I-PERI, a novel federated causal discovery algorithm that handles unknown client-level interventions, 2. Introduces the \u03a6-Markov Equivalence Class (\u03a6-CPDAG), a tighter equivalence class derived from structural differences across clients, 3. Provides theoretical guarantees on convergence and privacy-preserving properties (differential privacy)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373e2e9b4041d9efb71fbe2d1095901813d7f2551cdfe37d40d79c04d7aa235d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373e2e9b4041d9efb71fbe2d1095901813d7f2551cdfe37d40d79c04d7aa235d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses federated causal discovery where client data are subject to unknown, heterogeneous interventions, a common real-world scenario overlooked by prior work. It proposes the I-PERI algorithm, which first recovers the union CPDAG and then orients additional edges by exploiting intervention-induced structural differences across clients, resulting in a tighter equivalence class called the \u03a6-CPDAG. Theoretical and empirical results demonstrate the algorithm's effectiveness and privacy guarantees."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Regret-Based Federated Causal Discovery with Unknown Interventions] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u8054\u90a6\u56e0\u679c\u53d1\u73b0\u4e2d\u5ba2\u6237\u7aef\u5b58\u5728\u672a\u77e5\u5f02\u8d28\u5e72\u9884/Federated causal discovery with unknown, heterogeneous client interventions]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faI-PERI\u7b97\u6cd5\uff0c\u5229\u7528\u5e72\u9884\u5dee\u5f02\u5b9a\u5411\u8fb9/Propose I-PERI algorithm, orienting edges using intervention differences]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u5b9a\u4e49\u03a6-CPDAG\uff0c\u63d0\u4f9b\u7406\u8bba\u4e0e\u9690\u79c1\u4fdd\u8bc1/Define \u03a6-CPDAG, provide theoretical and privacy guarantees]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [physics-informed neural networks, circuit simulation, differential-algebraic equations, surrogate modeling, NeuroSPICE]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chien-Ting Tung, Chenming Hu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of California at Berkeley"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23624",children:"https://arxiv.org/pdf/2512.23624"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes NeuroSPICE, a novel PINN-based framework for solving circuit differential-algebraic equations directly, bypassing traditional time-discretized numerical solvers. 2. Demonstrates the framework's flexibility for modeling emerging devices and multi-physics systems within a single Python environment, lowering the barrier for rapid prototyping. 3. Highlights the potential of the differentiable PINN model as a surrogate for circuit design optimization and inverse problems, despite not outperforming SPICE in raw training speed or accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7d88b0c7c41bb8bbaf5959a08185913698993a5cc330641c604219b2a1c0622_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7d88b0c7c41bb8bbaf5959a08185913698993a5cc330641c604219b2a1c0622_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces NeuroSPICE, a framework that uses Physics-Informed Neural Networks (PINNs) to simulate electronic circuits by solving their governing differential-algebraic equations through backpropagation. It represents circuit waveforms as continuous, differentiable functions of time, enabling the simulation of novel devices like ferroelectric memories. The main conclusion is that while not faster than SPICE for training, NeuroSPICE offers unique advantages as a flexible, differentiable surrogate model for design optimization and complex multi-physics systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE<br>\u8bba\u6587\u6807\u9898"] --\x3e B["Problem: Conventional SPICE struggles with emerging, highly nonlinear devices and multi-physics coupling.<br>\u6838\u5fc3\u95ee\u9898: \u4f20\u7edfSPICE\u96be\u4ee5\u5904\u7406\u65b0\u5174\u7684\u975e\u7ebf\u6027\u5668\u4ef6\u548c\u591a\u7269\u7406\u573a\u8026\u5408\u3002"]\n    A --\x3e C["Method: NeuroSPICE, a PINN framework that solves circuit DAEs by minimizing equation residuals via backpropagation.<br>\u4e3b\u8981\u65b9\u6cd5: NeuroSPICE\uff0c\u4e00\u4e2a\u901a\u8fc7\u53cd\u5411\u4f20\u64ad\u6700\u5c0f\u5316\u65b9\u7a0b\u6b8b\u5dee\u6765\u6c42\u89e3\u7535\u8defDAE\u7684PINN\u6846\u67b6\u3002"]\n    A --\x3e D["Results: Provides a flexible, differentiable surrogate model for design optimization, enabling simulation of novel devices like ferroelectric memories.<br>\u5173\u952e\u7ed3\u679c: \u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u3001\u53ef\u5fae\u5206\u7684\u4ee3\u7406\u6a21\u578b\u7528\u4e8e\u8bbe\u8ba1\u4f18\u5316\uff0c\u80fd\u591f\u6a21\u62df\u5982\u94c1\u7535\u5b58\u50a8\u5668\u7b49\u65b0\u578b\u5668\u4ef6\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent systems, hierarchical agents, bandit optimization, software engineering agents, SWE-bench]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Iris Xu, Guangtao Zeng, Zexue He, Charles Jin, Aldo Pareja, Dan Gutfreund, Chuang Gan, Zhang-Wei Hong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Massachusetts Institute of Technology, MIT-IBM Watson AI Lab, Stanford University, University of Massachusetts Amherst"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23631",children:"https://arxiv.org/pdf/2512.23631"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/iamxjy/BOAD-SWE-Agent",children:"https://github.com/iamxjy/BOAD-SWE-Agent"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formulates the automatic discovery of effective hierarchical multi-agent systems for software engineering as a multi-armed bandit (MAB) problem, enabling efficient exploration under limited budgets. 2. Proposes the BOAD framework, which uses bandit optimization to coordinate specialized sub-agents (e.g., for localization, editing, validation) and attribute credit within a team. 3. Demonstrates that automatically discovered hierarchical agents outperform single-agent and manually designed multi-agent systems on challenging, out-of-distribution SWE benchmarks, including achieving second place on SWE-bench-Live with a 36B model."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67084d40c24e3869f47efa4b52c7ec1479016d613997e911c6730d7e7684254f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67084d40c24e3869f47efa4b52c7ec1479016d613997e911c6730d7e7684254f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the poor generalization of single-agent LLMs on long-horizon, out-of-distribution software engineering tasks by proposing a hierarchical multi-agent system. The core method, BOAD, automatically discovers effective agent hierarchies by formulating the search as a multi-armed bandit optimization problem. The results show that this approach significantly improves performance on SWE benchmarks, surpassing larger models like GPT-4 and Claude."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BOAD: \u53d1\u73b0\u5206\u5c42\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406 / BOAD: Discovering Hierarchical Software Engineering Agents] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem: \u5355\u4e00LLM\u4ee3\u7406\u5728\u957f\u89c6\u91ce\u3001\u5206\u5e03\u5916\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee / Single-agent LLMs generalize poorly on long-horizon, out-of-distribution SWE tasks]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method: \u5c06\u5206\u5c42\u53d1\u73b0\u5efa\u6a21\u4e3a\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u4f18\u5316\u5b50\u4ee3\u7406\u534f\u4f5c / Formulate hierarchy discovery as a multi-armed bandit problem to optimize sub-agent collaboration]\n    D[\u5173\u952e\u7ed3\u679c / Results: \u5728SWE-bench\u4e0a\u8d85\u8d8a\u5355\u4ee3\u7406\u548c\u624b\u52a8\u8bbe\u8ba1\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c36B\u6a21\u578b\u6392\u540d\u7b2c\u4e8c / Outperforms single-agent and manual multi-agent systems on SWE-bench, 36B model ranks second]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [educational ai], [generative AI, fine-tuning, randomized controlled trial, Socratic questioning, pedagogical instruction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," LearnLM Team Google, Eedi, Albert Wang, Aliya Rysbek, Andrea Huber, Anjali Nambiar, Anna Kenolty, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Brian Veprek, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Irina Jurenka, Iris Hulls, James Stalley-Moores, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Lucy Dalton, Markus Kunesch, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Sara Wiltberger, Shakir Mohamed, Simon Woodhead, Vasco Braz\xe3o"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google, Eedi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23633",children:"https://arxiv.org/pdf/2512.23633"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a rigorous, in-classroom exploratory RCT to evaluate the safety and efficacy of a generative AI tutor (LearnLM) in a real educational setting. 2. Demonstrated that a pedagogically fine-tuned AI model can reliably draft instructional content, with human tutors approving 76.4% of its messages with minimal or no edits. 3. Showed that AI-supported tutoring led to student performance at least equivalent to human-only tutoring, with a significant 5.5 percentage point improvement in solving novel problems on subsequent topics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b430e7c78534d660126208f226397ed95756e540bade56276301199a0114bc76_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b430e7c78534d660126208f226397ed95756e540bade56276301199a0114bc76_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether generative AI can scale effective one-to-one tutoring. The authors integrated LearnLM, a pedagogically fine-tuned AI model, into a math tutoring platform and conducted a randomized controlled trial where human tutors supervised its outputs. The results show that LearnLM was a reliable tutor, and students using it performed as well as or better than those with human tutors alone, suggesting AI can deliver effective, individualized learning support at scale."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[AI Tutoring RCT in UK Classrooms] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u4e2a\u6027\u5316\u8f85\u5bfc\u6210\u672c\u9ad8/High cost of 1-to-1 tutoring]\n    Problem --\x3e P2[AI\u8f85\u5bfc\u7684\u6709\u6548\u6027\u4e0e\u5b89\u5168\u6027\u672a\u77e5/Unproven efficacy & safety of AI tutoring]\n    Method --\x3e M1[\u6574\u5408LearnLM\u6a21\u578b/Integrate LearnLM (pedagogically fine-tuned AI)]\n    Method --\x3e M2[\u5728Eedi\u5e73\u53f0\u8fdb\u884cRCT/Conduct RCT on Eedi platform]\n    Method --\x3e M3[\u4e13\u5bb6\u5bfc\u5e08\u76d1\u7763\u8f93\u51fa/Human tutors supervise AI drafts]\n    Results --\x3e R1[76.4%\u6d88\u606f\u88ab\u76f4\u63a5\u6279\u51c6/76.4% messages approved with minimal edits]\n    Results --\x3e R2[\u5b66\u751f\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u597d/Student performance equal or better]\n    Results --\x3e R3[\u89e3\u51b3\u65b0\u95ee\u9898\u80fd\u529b\u63d0\u53475.5%/5.5% improvement on novel problems]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Nested Browser-Use Learning for Agentic Information Seeking"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [information-seeking agents, browser interaction, ReAct-style agents, nested framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tongyi Lab, Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23647",children:"https://arxiv.org/pdf/2512.23647"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Alibaba-NLP/DeepResearch",children:"https://github.com/Alibaba-NLP/DeepResearch"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a minimal and complete browser-action framework for agents, 2. Introduces a nested structure to decouple interaction control from page exploration, 3. Demonstrates improved performance on deep information-seeking benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of current information-seeking agents, which rely on simple API calls and cannot perform real browsing. It proposes NestBrowse, a framework that uses a nested structure to enable fine-grained browser control for agents, simplifying reasoning and improving performance on deep search tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Nested Browser-Use Learning for Agentic Information Seeking<br>\u9762\u5411\u667a\u80fd\u4fe1\u606f\u641c\u7d22\u7684\u5d4c\u5957\u6d4f\u89c8\u5668\u4f7f\u7528\u5b66\u4e60"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Agents lack real browsing, limited to APIs."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>NestBrowse: nested browser-action framework."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Better performance on deep IS benchmarks."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks], [prompt injection, large language models, academic peer review, multilingual, adversarial robustness]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai.-Doss"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," International School of Athens, Idiap Research Institute"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23684",children:"https://arxiv.org/pdf/2512.23684"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Constructed a dataset of ~500 real ICML papers to empirically evaluate hidden prompt injection attacks in a realistic academic reviewing context. 2. Demonstrated that embedding semantically equivalent adversarial instructions in multiple languages (English, Japanese, Chinese, Arabic) can significantly alter LLM-generated review scores and decisions. 3. Revealed notable cross-lingual differences in attack effectiveness, with Arabic injections having minimal impact compared to others."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6285e0b940378fdc27628286ec6510afd35bf7a004b7ad95ad776e49035c6e1c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6285e0b940378fdc27628286ec6510afd35bf7a004b7ad95ad776e49035c6e1c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the vulnerability of LLM-based academic peer review systems to hidden prompt injection attacks. By injecting adversarial instructions in four languages into a dataset of real papers and having an LLM review them, the authors found that such attacks can substantially change review outcomes for English, Japanese, and Chinese, but not Arabic. The results highlight a critical security risk and language-dependent susceptibility in automated reviewing pipelines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>LLM-based reviewing systems are vulnerable to hidden prompt injection attacks.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Inject semantically equivalent adversarial prompts in 4 languages into ~500 real papers and review with an LLM.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>English, Japanese, Chinese injections change scores/decisions; Arabic injections have little effect.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Web World Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [world model, language agent, web framework, structured latent state, deterministic generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, Mengdi Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Princeton University, University of California, Los Angeles, University of Pennsylvania"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23676",children:"https://arxiv.org/pdf/2512.23676"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://princeton-ai2-lab.github.io/Web-World-Models/",children:"https://princeton-ai2-lab.github.io/Web-World-Models/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced the Web World Model (WWM), a hybrid architecture that uses ordinary web code to enforce logical consistency and LLMs to generate open-ended content. 2. Built a suite of practical WWM demonstrations across diverse domains (travel, fiction, encyclopedia, games) on a realistic web stack. 3. Identified key design principles for WWMs, such as separating code-defined rules from model-driven imagination and representing latent state as typed web interfaces."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed8017bbc1bd6722a0d7bd0f84c67f735c0f1b24747518e2aa15905d07d1b03c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed8017bbc1bd6722a0d7bd0f84c67f735c0f1b24747518e2aa15905d07d1b03c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper proposes Web World Models (WWMs), a framework that combines the reliability of web code for world "physics" with the generative power of LLMs for content and narratives. This hybrid approach aims to provide language agents with controllable, logically consistent, yet open-ended persistent environments. The work demonstrates that standard web stacks can serve as a scalable substrate for building such world models.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[Web World Models] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem: Language agents need persistent worlds; existing solutions are either too rigid (web frameworks) or too uncontrolled (fully generative models)."]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method: Hybrid Web World Model (WWM): Web code defines rules & state; LLMs generate context & narratives on top."]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results: Demonstrates scalable, controllable, open-ended environments; proposes design principles for WWMs."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Complete Anatomy of the Madden-Julian Oscillation Revealed by Artificial Intelligence"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [climate informatics], [similarity-preserving representation, latent space clustering, physics-coherent monitoring]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xiao Zhou, Yuze Sun, Jie Wu, Xiaomeng Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, National Climate Centre, China Meteorological Administration"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22144",children:"https://arxiv.org/pdf/2512.22144"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduced an "AI-for-theory" paradigm using a deep learning model (PhysAnchor-MJO-AE) to learn a latent representation where distance corresponds to physical-feature similarity for the MJO. 2. Objectively discovered the first complete six-phase anatomical map of the MJO life cycle, isolating two long-hypothesized transitional phases. 3. Constructed a new physics-coherent monitoring framework that decouples location and intensity, drastically reducing spurious propagation and convective misplacement compared to classical methods.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b09901ad992d27215117f20984faf17d508a192bf9010cc39bd8b74553ff543_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b09901ad992d27215117f20984faf17d508a192bf9010cc39bd8b74553ff543_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the challenge of objectively defining the life cycle of the Madden-Julian Oscillation (MJO) by introducing an "AI-for-theory" paradigm. It develops a deep learning model to learn a similarity-preserving latent representation, enabling clustering that reveals a complete six-phase anatomy of the MJO. The derived new monitoring framework significantly outperforms the classical index, demonstrating AI\'s role as a discovery tool for complex systems.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Complete Anatomy of the Madden-Julian Oscillation Revealed by Artificial Intelligence] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Defining MJO lifecycle is challenging due to propagation; classical methods conflate artifacts with physics.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>AI-for-theory paradigm; Deep learning model (PhysAnchor-MJO-AE) learns similarity-preserving latent representation for objective clustering.]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>First complete six-phase MJO anatomy; New physics-coherent monitoring framework reduces errors by an order of magnitude.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Neural ocean forecasting from sparse satellite-derived observations: a case-study for SSH dynamics and altimetry data"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [spatiotemporal forecasting], [4DVarNet, U-Net, sequence-to-sequence, sea level anomaly, neural forecast]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Daria Botvynko, Pierre Hasl\xe9e, Lucile Gaultier, Bertrand Chapron, Clement de Boyer Mont\xe9gut, Anass El Aouni, Julien Le Sommer, Ronan Fablet"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IMT Atlantique, Ifremer, CNRS, Mercator Ocean International"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22152",children:"https://arxiv.org/pdf/2512.22152"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Adapts U-Net and 4DVarNet architectures for short-term forecasting of ocean dynamics from sparse satellite data. 2. Formulates the forecasting task as a sequence-to-sequence mapping using partial SLA snapshots to predict future full-field maps. 3. Demonstrates that the end-to-end neural framework outperforms an operational baseline, especially in high-variability regions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b91a25a42a5dc1b5739ae5689c604765502ed07062eadaa473e043ec5a0d288f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b91a25a42a5dc1b5739ae5689c604765502ed07062eadaa473e043ec5a0d288f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an end-to-end deep learning framework for 7-day forecasting of sea surface dynamics using sparse satellite altimetry data. It adapts U-Net and 4DVarNet models to perform sequence-to-sequence mapping from partial observations to full-field forecasts. The results show the neural model outperforms an operational ocean forecast product, demonstrating the feasibility of neural forecasting for operational oceanography under data-sparse conditions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Neural Ocean Forecasting from Sparse Observations] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: \u7a00\u758f\u536b\u661f\u6570\u636e\u4e0b\u7684\u77ed\u671f\u6d77\u6d0b\u9884\u62a5/Short-term ocean forecasting from sparse satellite data)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8eU-Net\u548c4DVarNet\u7684\u7aef\u5230\u7aef\u5e8f\u5217\u9884\u6d4b/End-to-end sequence forecasting using U-Net & 4DVarNet)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u795e\u7ecf\u6a21\u578b\u8d85\u8d8a\u4e1a\u52a1\u5316\u57fa\u7ebf\uff0c\u5728\u591a\u53d8\u533a\u57df\u6539\u8fdb\u663e\u8457/Neural model outperforms operational baseline, notable improvements in high-variability regions)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Super-Resolution Enhancement of Medical Images Based on Diffusion Model: An Optimization Scheme for Low-Resolution Gastric Images"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image super-resolution], [diffusion models, SR3, DDPM, capsule endoscopy, HyperKvasir]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haozhe Jia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Boston University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22209",children:"https://arxiv.org/pdf/2512.22209"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Applied the SR3 diffusion model framework to the specific domain of capsule endoscopy image super-resolution, addressing hardware-imposed low-resolution constraints. 2. Demonstrated that the diffusion-based approach outperforms traditional interpolation and GAN-based methods (e.g., ESRGAN) in both quantitative metrics (PSNR, SSIM) and qualitative anatomical fidelity. 3. Showed that architectural enhancements like attention mechanisms further improve performance, achieving a PSNR of 29.3 dB and SSIM of 0.71."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70b95a1328af0d9ae7f16ab6cb15a216b2ad914761eed6496beb2ee934202e23_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70b95a1328af0d9ae7f16ab6cb15a216b2ad914761eed6496beb2ee934202e23_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes using a diffusion model (SR3/DDPM) for super-resolution enhancement of low-resolution capsule endoscopy images. The method learns a probabilistic mapping from low-resolution to high-resolution images and is evaluated on the HyperKvasir dataset. Results show it outperforms traditional and GAN-based methods, better preserving critical anatomical details for clinical diagnosis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Super-Resolution Enhancement of Medical Images Based on Diffusion Model: An Optimization Scheme for Low-Resolution Gastric Images"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Capsule endoscopy images have low resolution, limiting clinical diagnosis."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Use SR3 diffusion model to learn mapping from LR to HR images."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Outperforms bicubic & GAN methods, improves PSNR/SSIM, preserves anatomy."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Literature Mining System for Nutraceutical Biosynthesis: From AI Framework to Biological Insight"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [literature mining, large language models, prompt engineering, few-shot prompting, domain adaptation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xinyang Sun, Nipon Sarmah, Miao Guo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," King's College London"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22225",children:"https://arxiv.org/pdf/2512.22225"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed a domain-adapted AI system using LLMs and advanced prompt engineering to automate the extraction of nutraceutical-producing microbial strains from unstructured text. 2. Created and validated a structured dataset of 35 nutraceutical-strain associations, spanning multiple compound categories. 3. Demonstrated the system's performance and provided biological insights, identifying dominant microbial contributors and the framework's utility for synthetic biology and precision fermentation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c767d67875d1e2e25e95c99a9b826daf52082c66775d52728bda6802558969_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c767d67875d1e2e25e95c99a9b826daf52082c66775d52728bda6802558969_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents an AI-driven literature mining system that uses large language models and prompt engineering to automatically identify microbes that produce nutraceuticals from scientific text. The system, which performed best with the DeepSeek-V3 model and domain-specific prompts, generated a validated dataset and revealed key microbial strains for biosynthesis. This framework enhances the scalability of literature mining and provides actionable insights for strain selection and fermentation strategies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Literature Mining System for Nutraceutical Biosynthesis<br/>\u8425\u517b\u4fdd\u5065\u54c1\u751f\u7269\u5408\u6210\u7684\u6587\u732e\u6316\u6398\u7cfb\u7edf] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>Extracting structured knowledge on microbial strains from literature is a bottleneck.<br/>\u4ece\u6587\u732e\u4e2d\u63d0\u53d6\u5173\u4e8e\u5fae\u751f\u7269\u83cc\u682a\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u662f\u4e00\u4e2a\u74f6\u9888\u3002]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Domain-adapted system using LLMs and prompt engineering.<br/>\u4f7f\u7528LLM\u548c\u63d0\u793a\u5de5\u7a0b\u7684\u9886\u57df\u9002\u5e94\u7cfb\u7edf\u3002]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>Created dataset of 35 associations; DeepSeek-V3 outperformed LLaMA-2; identified dominant microbial strains.<br/>\u521b\u5efa\u4e8635\u4e2a\u5173\u8054\u7684\u6570\u636e\u96c6\uff1bDeepSeek-V3\u4f18\u4e8eLLaMA-2\uff1b\u8bc6\u522b\u4e86\u4e3b\u8981\u5fae\u751f\u7269\u83cc\u682a\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Field strength-dependent performance variability in deep learning-based analysis of magnetic resonance imaging"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image segmentation], [nnU-Net, MRI field strength, radiomic analysis, UMAP clustering, model generalizability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Muhammad Ibtsaam Qadir, Duane Schonlau, Ulrike Dydak, Fiona R. Kolbinger"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Purdue University, Indiana University School of Medicine, TUD Dresden University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22176",children:"https://arxiv.org/pdf/2512.22176"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A systematic quantitative evaluation framework to assess the impact of MRI scanner magnetic field strength (1.5T vs. 3.0T) on the performance and generalizability of deep learning segmentation models. 2. Empirical demonstration that training data field strength significantly influences model performance, especially for soft-tissue segmentation tasks, with models trained on 3.0T data often outperforming others. 3. The use of radiomic analysis and UMAP clustering to provide an interpretable, feature-based explanation for the observed performance differences, linking them to field-strength-dependent image characteristics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff8ab0f68e15ce620cdfd03bebfec56b322101c32b9cea5d7a2881045b311bc2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff8ab0f68e15ce620cdfd03bebfec56b322101c32b9cea5d7a2881045b311bc2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study investigates how MRI scanner magnetic field strength affects deep learning-based segmentation models. Using nnU-Net models trained on data from 1.5T, 3.0T, or combined field strengths across three anatomical datasets, the authors found that field strength in training data significantly impacts model performance, particularly for soft tissues. The conclusion is that magnetic field strength should be considered a confounding factor in AI studies for MRI analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Field strength-dependent performance variability in deep learning-based analysis of magnetic resonance imaging<br>\u78c1\u5171\u632f\u6210\u50cf\u6df1\u5ea6\u5b66\u4e60\u5206\u6790\u4e2d\u573a\u5f3a\u4f9d\u8d56\u7684\u6027\u80fd\u53d8\u5f02\u6027") --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem("\u6838\u5fc3\u95ee\u9898/Problem<br>Impact of MRI field strength on DL model performance & generalizability<br>MRI\u573a\u5f3a\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd")\n    Method("\u4e3b\u8981\u65b9\u6cd5/Method<br>Train/evaluate nnU-Net models on 1.5T, 3.0T, and combined data; Analyze with UMAP & radiomics<br>\u57281.5T\u30013.0T\u53ca\u6df7\u5408\u6570\u636e\u4e0a\u8bad\u7ec3/\u8bc4\u4f30nnU-Net\u6a21\u578b\uff1b\u4f7f\u7528UMAP\u548c\u5f71\u50cf\u7ec4\u5b66\u5206\u6790")\n    Results("\u5173\u952e\u7ed3\u679c/Results<br>Field strength in training data substantially influences performance, especially for soft tissues<br>\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u573a\u5f3a\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff0c\u5c24\u5176\u5bf9\u8f6f\u7ec4\u7ec7")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Space AI: Leveraging Artificial Intelligence for Space to Improve Life on Earth"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [autonomous systems], [autonomous operations, mission planning, in-situ resource utilisation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ziyang Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IEEE"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22399",children:"https://arxiv.org/pdf/2512.22399"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes and defines "Space AI" as a unified interdisciplinary field at the intersection of AI and space science. 2. Consolidates historical and contemporary progress into a systematic four-context framework (AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life). 3. Identifies key application areas where AI advances can translate to societal benefits on Earth, such as in sensing, robotics, and trustworthy AI.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper introduces "Space AI" as a new interdisciplinary field and proposes a systematic framework to organize its applications across four mission contexts, from Earth-based planning to multi-planetary life support. It argues that AI is critical for enabling autonomous and resilient space operations under extreme conditions, and that advances in this domain will also yield significant benefits for life on Earth.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Space AI: Leveraging AI for Space to Improve Life on Earth] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>\u5982\u4f55\u5728\u6781\u7aef\u4e0d\u786e\u5b9a\u548c\u6709\u9650\u76d1\u7763\u4e0b<br>\u5b9e\u73b0\u592a\u7a7a\u81ea\u4e3b\u5f39\u6027\u64cd\u4f5c<br>How to enable autonomous, resilient space operations under extreme uncertainty and limited oversight]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u63d0\u51fa\u7cfb\u7edf\u5316\u56db\u7ef4\u6846\u67b6<br>Propose a systematic four-context framework<br>(AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u7edf\u4e00\u4e86\u8de8\u5b66\u79d1\u9886\u57df\u5e76\u8bc6\u522b\u5173\u952e\u5e94\u7528<br>\u52a0\u901f\u592a\u7a7a\u63a2\u7d22\u80fd\u529b\u5e76\u4ea7\u751f\u5e7f\u6cdb\u5730\u7403\u5f71\u54cd<br>Unifies interdisciplinary field and identifies key applications<br>Accelerates space exploration capability and yields broad Earth impact]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Gradient Dynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [transformer interpretability], [cross-entropy, gradient dynamics, attention mechanism, expectation-maximization, Bayesian inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dream Sports, Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22473",children:"https://arxiv.org/pdf/2512.22473"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Derived an advantage-based routing law and a responsibility-weighted update rule for attention scores and values under cross-entropy training. 2. Showed that the coupled gradient dynamics induce a positive feedback loop that behaves like a two-timescale Expectation-Maximization (EM) procedure. 3. Demonstrated that these gradient dynamics sculpt the low-dimensional manifolds necessary for Bayesian inference, linking optimization to geometry and function."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed145ec9892ca4b4f8b91e5c78948ac6b81399c20bcafdccd4cb429e92da2aed_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed145ec9892ca4b4f8b91e5c78948ac6b81399c20bcafdccd4cb429e92da2aed_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes how cross-entropy training shapes the internal geometry of transformer attention heads. By deriving first-order gradient dynamics, it shows that attention score and value updates form a positive feedback loop analogous to an EM algorithm. The core conclusion is that this gradient flow sculpts the Bayesian manifolds that enable in-context probabilistic reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Gradient Dynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\nB --\x3e B1[Transformer\u5185\u90e8\u51e0\u4f55\u7ed3\u6784\u5982\u4f55\u5f62\u6210?/How is transformer internal geometry formed?]\nC --\x3e C1[\u63a8\u5bfc\u6ce8\u610f\u529b\u68af\u5ea6\u52a8\u6001/Derive attention gradient dynamics]\nC --\x3e C2[\u5efa\u7acbEM\u7b97\u6cd5\u7c7b\u6bd4/Establish EM algorithm analogy]\nD --\x3e D1[\u53d1\u73b0\u4f18\u52bf\u8def\u7531\u4e0e\u8d23\u4efb\u66f4\u65b0/Discover advantage-based routing & responsibility-weighted update]\nD --\x3e D2[\u68af\u5ea6\u6d41\u5851\u9020\u8d1d\u53f6\u65af\u6d41\u5f62/Gradient flow sculpts Bayesian manifolds]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [medical audio classification], [Audio Spectrogram Transformer, Sharpness-Aware Minimization, ICBHI 2017, class imbalance, loss landscape]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Atakan I\u015f\u0131k, Selin Vulga I\u015f\u0131k, Ahmet Feridun I\u015f\u0131k, Mah\u015fuk Taylan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ba\u015fkent University, Gaziantep University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22564",children:"https://arxiv.org/pdf/2512.22564"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework integrating the Audio Spectrogram Transformer (AST) with Sharpness-Aware Minimization (SAM) for robust respiratory sound classification. 2. Implements a weighted sampling strategy to effectively handle the severe class imbalance present in medical datasets like ICBHI 2017. 3. Achieves state-of-the-art performance on the ICBHI 2017 dataset, with a particular focus on improving sensitivity for reliable clinical screening."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0861fcb0d50b762d97367d04dce9ca920f2ffca74cd5112df95b11652972a9b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0861fcb0d50b762d97367d04dce9ca920f2ffca74cd5112df95b11652972a9b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenges of respiratory sound classification, such as data scarcity and class imbalance, by enhancing the Audio Spectrogram Transformer with Sharpness-Aware Minimization (SAM) to find flatter minima for better generalization. The method also employs weighted sampling and achieves a new state-of-the-art score of 68.10% and a sensitivity of 68.31% on the ICBHI 2017 dataset, demonstrating improved robustness for clinical applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Geometry-Aware Optimization for Respiratory Sound Classification<br/>\u547c\u5438\u58f0\u97f3\u5206\u7c7b\u7684\u51e0\u4f55\u611f\u77e5\u4f18\u5316] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n\n    B --\x3e B1[\u6570\u636e\u9650\u5236\u4e0e\u8fc7\u62df\u5408<br/>Data Constraints & Overfitting]\n    B1 --\x3e B2[\u6570\u636e\u96c6\u5c0f\u3001\u566a\u58f0\u5927\u3001\u7c7b\u522b\u4e0d\u5e73\u8861<br/>Small, Noisy, Imbalanced Dataset]\n\n    C --\x3e C1[\u4f7f\u7528SAM\u4f18\u5316AST<br/>Enhance AST with SAM]\n    C1 --\x3e C2[\u4f18\u5316\u635f\u5931\u66f2\u9762\u51e0\u4f55<br/>Optimize Loss Surface Geometry]\n    C --\x3e C3[\u52a0\u6743\u91c7\u6837\u7b56\u7565<br/>Weighted Sampling Strategy]\n\n    D --\x3e D1[SOTA\u5206\u6570: 68.10%<br/>SOTA Score: 68.10%]\n    D --\x3e D2[\u9ad8\u654f\u611f\u5ea6: 68.31%<br/>High Sensitivity: 68.31%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [simulation-based inference], [Bayesian adaptive design, amortized inference, diffusion models, sequential experimental design, policy learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Niels Bracher, Lars K\xfchmichel, Desi R. Ivanova, Xavier Intes, Paul-Christian B\xfcrkner, Stefan T. Radev"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Rensselaer Polytechnic Institute, TU Dortmund University, University of Oxford"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22999",children:"https://arxiv.org/pdf/2512.22999"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces JADAI, a framework that jointly amortizes Bayesian adaptive design and inference by training a policy, history, and inference network end-to-end., 2. Proposes a generic loss function that aggregates incremental reductions in posterior error across sequential experiments., 3. Instantiates the inference network with diffusion-based posterior estimators to handle high-dimensional and multimodal posteriors at each experimental step."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a357d49f23f5fdffd9539d05904d86150c3c7775033f4847b56afac3375ad8e6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a357d49f23f5fdffd9539d05904d86150c3c7775033f4847b56afac3375ad8e6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces JADAI, a framework that jointly learns to optimize experimental designs and perform Bayesian inference in a sequential setting. It trains a policy network, a history network, and a diffusion-based inference network end-to-end to minimize posterior error. The method achieves superior or competitive performance on standard adaptive design benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Actively optimizing design variables for parameter estimation] --\x3e Problem_Sub[\u5b50\u95ee\u9898/Sub-problem: Sequential design and inference are typically treated separately]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Jointly amortize design and inference via end-to-end training] --\x3e Method_Sub1[\u7f51\u7edc/Networks: Policy, History, and Inference (Diffusion-based) networks]\n    Method --\x3e Method_Sub2[\u635f\u5931\u51fd\u6570/Loss: Aggregates incremental posterior error reduction]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Superior/competitive performance on standard benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Deep Learning for Art Market Valuation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-modal learning], [multi-modal deep learning, visual embeddings, Grad-CAM, hedonic regression, repeated-sales dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jianping Mei, Michael Moses, Jan Waelty, Yucheng Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Cheung Kong Graduate School of Business (CKGSB), University of Zurich, Swiss Finance Institute, Art Market Consultancy"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23078",children:"https://arxiv.org/pdf/2512.23078"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces and benchmarks multi-modal deep learning models that fuse tabular data (artist, history) with visual embeddings from artwork images for art market valuation. 2. Demonstrates that visual content provides a distinct and economically significant predictive contribution, especially for fresh-to-market works lacking prior transaction history. 3. Provides interpretability analyses using Grad-CAM and embedding visualizations to show models attend to compositional and stylistic visual cues."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21784cb5e49e3a537b10ebbf9acd8a8be80b39a1879d7fe524e11c8045e1e665_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21784cb5e49e3a537b10ebbf9acd8a8be80b39a1879d7fe524e11c8045e1e665_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes using multi-modal deep learning to improve art market valuation by incorporating visual content from artwork images alongside traditional tabular data. It finds that while artist identity and history are most predictive overall, visual features provide crucial value for first-time sales where historical data is absent. The results show deep learning offers new insights for valuation, particularly in the most challenging scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Deep Learning for Art Market Valuation<br/>\u827a\u672f\u5e02\u573a\u4f30\u503c\u7684\u6df1\u5ea6\u5b66\u4e60] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>How to improve art market valuation?<br/>\u5982\u4f55\u6539\u8fdb\u827a\u672f\u5e02\u573a\u4f30\u503c\uff1f]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Multi-modal deep learning fusing tabular & image data<br/>\u878d\u5408\u8868\u683c\u4e0e\u56fe\u50cf\u6570\u636e\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>Visual features help most for fresh-to-market works<br/>\u89c6\u89c9\u7279\u5f81\u5bf9\u9996\u6b21\u4e0a\u5e02\u4f5c\u54c1\u6700\u6709\u5e2e\u52a9]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [scheduling], [constraint programming, biased random-key genetic algorithm, makespan, exact delays, local search]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," V\xedtor A. Barbosa, Rafael A. Melo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Computing, Universidade Federal da Bahia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23150",children:"https://arxiv.org/pdf/2512.23150"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A Constraint Programming (CP) model for the single-machine coupled task scheduling problem with exact delays, utilizing well-established global constraints. 2. A novel Biased Random-Key Genetic Algorithm (BRKGA) that incorporates an efficient decoder, periodical restarts, shakes, and a local search algorithm for enhanced exploration. 3. An empirical evaluation demonstrating that the BRKGA provides high-quality solutions quickly, while the CP model with extended resources can find best-known solutions for a majority of benchmark instances."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the NP-hard single-machine coupled task scheduling problem with exact delays to minimize makespan. It proposes both a Constraint Programming model and a Biased Random-Key Genetic Algorithm (BRKGA) enhanced with local search and shake components. Computational results show the BRKGA finds good solutions quickly, while the CP model with more resources achieves state-of-the-art results on most benchmark instances."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[\u8bba\u6587\u6807\u9898/Paper Title: Constraint Programming and BRKGA for Coupled Task Scheduling] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u5355\u673a\u7cbe\u786e\u5ef6\u8fdf\u8026\u5408\u4efb\u52a1\u8c03\u5ea6\uff0c\u6700\u5c0f\u5316\u5b8c\u5de5\u65f6\u95f4/Single-machine coupled task scheduling with exact delays to minimize makespan]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u7ea6\u675f\u89c4\u5212\u6a21\u578b\u4e0e\u5e26\u504f\u7f6e\u968f\u673a\u5bc6\u94a5\u9057\u4f20\u7b97\u6cd5/Constraint Programming model and Biased Random-Key Genetic Algorithm (BRKGA)]\n    Results[\u5173\u952e\u7ed3\u679c/Results: BRKGA\u5feb\u901f\u63d0\u4f9b\u9ad8\u8d28\u91cf\u89e3\uff0cCP\u6a21\u578b\u5728\u5145\u5206\u8d44\u6e90\u4e0b\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u89e3/BRKGA provides high-quality solutions quickly; CP model reaches best-known solutions with sufficient resources]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Kullback-Leibler divergence, decision paralysis, intent selection, affordance selection, hierarchical decision process]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wendyam Eric Lionel Ilboudo, Saori C Tanaka"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nara Institute of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23144",children:"https://arxiv.org/pdf/2512.23144"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a computational account of decision paralysis as convergence failure in a hierarchical decision process, separating intent and affordance selection. 2. Formalizes decision commitment as inference under a mixture of reverse-KL (mode-seeking) and forward-KL (mode-covering) objectives. 3. Demonstrates through simulations that forward-KL-biased inference reproduces key features of decision inertia and shutdown, framing autism as an extreme regime of this general decision-making continuum."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0c1bd96570e940c6fa7d72cbfcec334b1a94d288ce774a384e5c60b2bfe206_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0c1bd96570e940c6fa7d72cbfcec334b1a94d288ce774a384e5c60b2bfe206_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses decision paralysis by proposing a hierarchical inference-based model that separates intent and affordance selection. Commitment is formalized using a mixture of reverse-KL and forward-KL divergence objectives, where a bias towards forward-KL leads to slow, heavy-tailed response times and distinct failure modes. The model reproduces features of decision inertia and suggests autism represents an extreme case on this decision-making continuum."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>Decision Paralysis] --\x3e P1[\u6311\u6218/Challenge<br>Choice models assume ready-to-compare options]\n    Problem --\x3e P2[\u73b0\u8c61/Phenomenon<br>Hesitation, freezing, failure to act]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>Computational Account] --\x3e M1[\u67b6\u6784/Architecture<br>Hierarchical decision process]\n    Method --\x3e M2[\u5f62\u5f0f\u5316/Formalization<br>Intent vs. Affordance selection]\n    Method --\x3e M3[\u76ee\u6807/Objective<br>Mixture of reverse-KL & forward-KL]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>Simulation Outcomes] --\x3e R1[\u884c\u4e3a/Behavior<br>Slow, heavy-tailed response times]\n    Results --\x3e R2[\u5931\u8d25\u6a21\u5f0f/Failure Modes<br>Intent & Affordance saturation]\n    Results --\x3e R3[\u89e3\u91ca/Interpretation<br>Autism as an extreme regime]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] EIR: Enhanced Image Representations for Medical Report Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image captioning], [cross-modal transformer, metadata fusion, domain-specific pre-training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qiang Sun, Zongcheng Ji, Yinlong Xiao, Peng Chang, Jun Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, PAII Inc., Beijing University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23185",children:"https://arxiv.org/pdf/2512.23185"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel Enhanced Image Representations (EIR) method for medical report generation. 2. Introduces cross-modal transformers to effectively fuse medical metadata with image features, addressing the information asymmetry problem. 3. Leverages medical domain pre-trained models to encode chest X-ray images, bridging the domain gap between general and medical images."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e359c65576903a65bf75a0600c08943744d6bd91d7b1f2e69d13330e289ce1_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e359c65576903a65bf75a0600c08943744d6bd91d7b1f2e69d13330e289ce1_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of generating medical reports from chest X-ray images. It proposes the EIR method, which uses cross-modal transformers to fuse metadata with visual features and employs medical domain pre-trained models for better image representation. Experiments on MIMIC and Open-I datasets demonstrate the method's effectiveness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[EIR: Enhanced Image Representations for Medical Report Generation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u62a5\u544a\u751f\u6210\u8017\u65f6\u8017\u529b/Report generation is time-consuming]\n    Problem --\x3e P2[\u4fe1\u606f\u4e0d\u5bf9\u79f0\u4e0e\u9886\u57df\u9e3f\u6c9f/Information asymmetry & domain gap]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u8de8\u6a21\u6001Transformer\u878d\u5408\u5143\u6570\u636e/Cross-modal transformer for metadata fusion]\n    Method --\x3e M2[\u533b\u5b66\u9886\u57df\u9884\u8bad\u7ec3\u6a21\u578b/Medical domain pre-trained model]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u5728MIMIC\u548cOpen-I\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1/Validated on MIMIC & Open-I datasets]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, StepFun, FinStep"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23515",children:"https://arxiv.org/pdf/2512.23515"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/FinStep-AI/Alpha-R1",children:"https://github.com/FinStep-AI/Alpha-R1"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Signal decay and regime shifts in non-stationary markets; existing methods overlook semantic rationale for factor relevance.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Alpha-R1, an 8B-parameter LLM trained via RL, reasons over factor logic and real-time news for context-aware alpha screening.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms benchmark strategies; exhibits improved robustness to alpha decay across multiple asset pools.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] PINNs for Electromagnetic Wave Propagation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [Scientific Computing / Computational Physics], [Physics-Informed Neural Networks (PINNs), Maxwell's Equations, FDTD, Time Marching, Poynting Regularizer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nilufer K. Bulut"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Izmir, Turkiye (Inferred from author location; no specific institution mentioned in provided content)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23396",children:"https://arxiv.org/pdf/2512.23396"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a hybrid training strategy combining time marching and causality-aware weighting to address the causality collapse problem in time-dependent PINNs. 2. Proposes a two-stage interface continuity loss to mitigate discontinuities introduced by time marching. 3. Develops a local Poynting-based regularizer to suppress cumulative energy drift and improve energy conservation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c5894c195aba4dd14bb55cc020098ad00e472ec3df24245a9a20ad4ca74b81c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c5894c195aba4dd14bb55cc020098ad00e472ec3df24245a9a20ad4ca74b81c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses accuracy and energy conservation deficiencies in Physics-Informed Neural Networks (PINNs) for electromagnetic wave propagation. It proposes a hybrid training methodology incorporating time marching, causality-aware weighting, and a Poynting-based regularizer. The results show that the enhanced PINNs achieve competitive field accuracy and energy conservation compared to traditional FDTD methods, demonstrating their viability for canonical electromagnetic problems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PINNs for Electromagnetic Wave Propagation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[PINNs\u5728\u7cbe\u5ea6\u548c\u80fd\u91cf\u5b88\u6052\u4e0a\u843d\u540e\u4e8eFDTD/PINNs lag behind FDTD in accuracy & energy]\n    C --\x3e C1[\u6df7\u5408\u8bad\u7ec3\u7b56\u7565/Hybrid Training Strategy]\n    C1 --\x3e C1_1[\u65f6\u95f4\u63a8\u8fdb\u4e0e\u56e0\u679c\u611f\u77e5\u52a0\u6743/Time Marching & Causality-Aware Weighting]\n    C1 --\x3e C1_2[\u4e24\u9636\u6bb5\u754c\u9762\u8fde\u7eed\u6027\u635f\u5931/Two-Stage Interface Continuity Loss]\n    C1 --\x3e C1_3[\u5c40\u90e8\u5761\u5370\u5ef7\u6b63\u5219\u5316\u5668/Local Poynting Regularizer]\n    D --\x3e D1[\u9ad8\u573a\u7cbe\u5ea6/High Field Accuracy (0.09% NRMSE)]\n    D --\x3e D2[\u80fd\u91cf\u5b88\u6052/Energy Conservation (0.024% mismatch)]\n    D --\x3e D3[\u4e0eFDTD\u7ed3\u679c\u7ade\u4e89/Competitive with FDTD]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2026-01-01",children:"2026-01-01"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [information extraction], [OCR, LLM, record linkage, digital humanities, data harmonization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zahra Abedi, Richard M.K. van Dijk, Gijs Wijnholds, Tessa Verhoef"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Leiden University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23710",children:"https://arxiv.org/pdf/2512.23710"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Designed an automated pipeline integrating OCR, LLM-based interpretation, and database linking for historical document digitization. 2. Demonstrated that generative AI can partially correct low OCR performance during structured data extraction. 3. Developed a record linkage algorithm achieving high accuracy (94% on annotated data, 81% on OCR-derived data) for integrating extracted data with existing databases."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d89795562de4ae19fec35c7e5d2890c5c08f327549b9a9887347777baf5b0c5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d89795562de4ae19fec35c7e5d2890c5c08f327549b9a9887347777baf5b0c5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an automated pipeline using OCR and generative AI to extract and structure biographical data from historical documents, then links this data to existing database records. The method achieved high OCR accuracy and demonstrated that LLMs can correct some OCR errors, with the final linkage algorithm performing well. The study contributes a practical tool for digital humanities research by addressing challenges like layout variability and terminology differences."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>How to automate the integration of historical document data with existing databases?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>OCR + LLM-based interpretation + Database linkage]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>High OCR accuracy, LLM corrects OCR errors, Effective record linkage]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [safety alignment], [multi-agent debate, stealthy harmful queries, safety training data, query transformation, adversarial prompting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shenzhe Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Toronto"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23717",children:"https://arxiv.org/pdf/2512.23717"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces HarmTransform, the first multi-agent debate framework designed for transforming harmful queries into stealthier forms while preserving intent. 2. Designs a comprehensive evaluation protocol and provides an in-depth analysis of debate dynamics, identifying its benefits and drawbacks. 3. Demonstrates the framework's potential for generating data to enhance LLM safety alignment, highlighting both the promise and limitations of the approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9bfc9b669283c35e277363d47c398576a9ae941e3c10bc7ea3296632fc0184f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9bfc9b669283c35e277363d47c398576a9ae941e3c10bc7ea3296632fc0184f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces HarmTransform, a multi-agent debate framework that iteratively refines harmful queries into stealthier forms to expose gaps in LLM safety mechanisms. Experiments show it outperforms baselines in generating effective transformations. The analysis reveals that while debate improves stealth, it can also introduce topic shifts and complexity, highlighting its dual nature for safety data generation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u5b89\u5168\u673a\u5236\u5ffd\u7565\u9690\u853d\u6709\u5bb3\u67e5\u8be2/LLM safety overlooks covert harmful queries]\n    C --\x3e C1[\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8fed\u4ee3\u4f18\u5316\u67e5\u8be2/Multi-agent debate iteratively refines queries]\n    D --\x3e D1[\u8fa9\u8bba\u63d0\u5347\u9690\u853d\u6027\u4f46\u53ef\u80fd\u5f15\u5165\u590d\u6742\u6027/Debate improves stealth but may add complexity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [evaluation & metrics], [STED, consistency scoring, structured output, JSON, semantic equivalence]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guanghui Wang, Jinze Yu, Xing Zhang, Dayuan Jiang, Yin Song, Tomal Deb, Xuefeng Liu, Peiyang He"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," AWS Generative AI Innovation Center, AWS WWSO SA Field Initiatives"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23712",children:"https://arxiv.org/pdf/2512.23712"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes STED (Semantic Tree Edit Distance), a novel similarity metric for comparing JSON outputs that balances semantic flexibility with structural strictness. 2. Introduces a comprehensive consistency scoring framework that aggregates multiple STED measurements across repeated generations to quantify LLM output reliability. 3. Provides a systematic benchmark of six LLMs using the proposed framework, revealing significant variations in model consistency and enabling practical applications like model selection and prompt refinement."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2a404e6faa604b1e48c4c20d60e0b88bb889cfe94b29f60a234af8a87b5d05b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2a404e6faa604b1e48c4c20d60e0b88bb889cfe94b29f60a234af8a87b5d05b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of evaluating the consistency of LLM-generated structured outputs (like JSON). It proposes a framework combining a new similarity metric (STED) and a consistency scoring method. The framework effectively benchmarks LLMs, showing Claude-3.7-Sonnet to be highly consistent, and provides tools for improving reliability in production systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u751f\u6210\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u53ef\u9760\u6027\u8bc4\u4f30/Evaluating Reliability of LLM Structured Outputs]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: STED\u5ea6\u91cf\u4e0e\u4e00\u81f4\u6027\u8bc4\u5206\u6846\u67b6/STED Metric & Consistency Scoring Framework]\n    D[\u5173\u952e\u7ed3\u679c/Results: STED\u4f18\u4e8e\u73b0\u6709\u6307\u6807\uff0cClaude-3.7-Sonnet\u4e00\u81f4\u6027\u6700\u4f73/STED Outperforms Baselines, Claude-3.7-Sonnet Most Consistent]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [code generation], [agent-based framework, iterative self-correction, multilingual LLM, Thought-Code-Observation loop, zero-shot]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jahidul Islam, Md Ataullha, Saiful Azad"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Green University of Bangladesh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23713",children:"https://arxiv.org/pdf/2512.23713"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," github.com/jahidulzaid/PyBanglaCodeActAgent"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced BanglaCodeAct, an agent-based framework for Bangla-to-Python code generation. 2. Leveraged a multilingual LLM in a zero-shot setting without task-specific fine-tuning. 3. Demonstrated the effectiveness of an iterative Thought-Code-Observation loop for dynamic code testing and refinement."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6751bddc58c50ee4806ff6af3cccc66715b2e854b912a102cbc99edee59d5c86_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6751bddc58c50ee4806ff6af3cccc66715b2e854b912a102cbc99edee59d5c86_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating Python code from Bangla natural language instructions, a low-resource language. It proposes BanglaCodeAct, an agent-based framework that uses a multilingual LLM within an iterative Thought-Code-Observation loop for zero-shot code generation and self-correction. The method, tested with Qwen3-8B, achieves high accuracy on the mHumanEval dataset, setting a new benchmark for Bangla NL-to-Code."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PyBangla at BLP-2025 Task 2<br>\u8bba\u6587\u6807\u9898/Paper Title] --\x3e B[LLMs excel in English but not low-resource languages<br>\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[Introduce BanglaCodeAct with multi-agent & iterative self-correction<br>\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[Qwen3-8B achieves 94.0% (dev) and 71.6% (test) pass@1<br>\u5173\u952e\u7ed3\u679c/Results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [hpc], [computational geometry], [mesh generation, geometry preparation, CAD-to-mesh, machine learning, large language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Steven Owen, Nathan Brown, Nikos Chrisochoides, Rao Garimella, Xianfeng Gu, Franck Ledoux, Na Lei, Roshan Quadros, Navamita Ray, Nicolas Winovich, Yongjie Jessica Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sandia National Laboratories, Old Dominion University, Los Alamos National Laboratory, New York University / Stony Brook University, CEA, Dalian University of Technology, Carnegie Mellon University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23719",children:"https://arxiv.org/pdf/2512.23719"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Surveys the application of AI/ML methods to automate and improve key steps in the CAD-to-mesh pipeline, such as part classification, mesh quality prediction, and defeaturing. 2. Reviews AI techniques for enhancing unstructured/block-structured meshing, volumetric parameterization, and parallel mesh generation. 3. Examines emerging tools like reinforcement learning and large language models for scripting automation in meshing workflows."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c3d8c73084ddd952c2e0c9fd20e1b7fe1d87bb02c884cf6327ca47e6ec442eb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey paper reviews how artificial intelligence and machine learning are being applied to address bottlenecks in geometry preparation and mesh generation for engineering simulation. It explores a range of methods, from quality prediction to automation with large language models, concluding that AI serves as an assistive technology to extend traditional tools and highlights key challenges for future data-driven workflows."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[CAD-to-mesh\u6d41\u7a0b\u74f6\u9888 / CAD-to-mesh Pipeline Bottlenecks]\n    C --\x3e C1[AI\u8f85\u52a9\u51e0\u4f55\u4e0e\u7f51\u683c\u751f\u6210 / AI-aided Geometry & Meshing]\n    C --\x3e C2[\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 / Machine Learning Methods]\n    C --\x3e C3[\u65b0\u5174\u81ea\u52a8\u5316\u5de5\u5177 / Emerging Automation Tools]\n    C1 --\x3e C1a[\u90e8\u4ef6\u5206\u7c7b / Part Classification]\n    C1 --\x3e C1b[\u7f51\u683c\u8d28\u91cf\u9884\u6d4b / Mesh Quality Prediction]\n    C1 --\x3e C1c[\u53bb\u7279\u5f81\u5316 / Defeaturing]\n    C2 --\x3e C2a[\u975e\u7ed3\u6784\u5316/\u5757\u7ed3\u6784\u5316\u7f51\u683c / Unstructured/Block-structured Meshing]\n    C2 --\x3e C2b[\u4f53\u79ef\u53c2\u6570\u5316 / Volumetric Parameterizations]\n    C2 --\x3e C2c[\u5e76\u884c\u7f51\u683c\u751f\u6210 / Parallel Mesh Generation]\n    C3 --\x3e C3a[\u5f3a\u5316\u5b66\u4e60 / Reinforcement Learning]\n    C3 --\x3e C3b[\u5927\u8bed\u8a00\u6a21\u578b / Large Language Models]\n    D --\x3e D1[AI\u4f5c\u4e3a\u8f85\u52a9\u6280\u672f / AI as Assistive Technology]\n    D --\x3e D2[\u4ee3\u8868\u6027\u65b9\u6cd5\u4e0e\u90e8\u7f72 / Representative Methods & Deployments]\n    D --\x3e D3[\u5173\u952e\u7814\u7a76\u6311\u6218 / Key Research Challenges]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hate speech detection], [collaborative expert judgment, confidence-based routing, class-balanced focal loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Anwar Alajmi, Gabriele Pergola"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Warwick, Public Authority of Applied Education and Training (Kuwait)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23732",children:"https://arxiv.org/pdf/2512.23732"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A two-stage framework combining targeted training for noisy, imbalanced data with selective, reasoning-based inference for ambiguous cases. 2. A novel Collaborative Expert Judgment (CEJ) module that uses multiple LLM personas in a structured debate to resolve uncertain predictions. 3. A dynamic routing mechanism at inference time that directly classifies high-confidence cases and escalates low-confidence ones to the CEJ module."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/32d2baab37215bb5672da3307e81be99d99c0b9c3a16715fc3d5d0430dfd9273_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/32d2baab37215bb5672da3307e81be99d99c0b9c3a16715fc3d5d0430dfd9273_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenges of detecting subtle, context-dependent sexist content online, which suffers from data noise, class imbalance, and conceptual ambiguity. It proposes a framework that uses robust training techniques and a novel inference module where uncertain cases are routed to a multi-persona LLM debate for judgment. This approach achieves state-of-the-art performance on benchmark sexism detection tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Subtle, ambiguous sexist content<br>Data noise, imbalance, ambiguity]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Two-stage framework<br>Robust training & CEJ routing]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>SOTA on benchmarks<br>+2.72% F1 on EXIST]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Enforcing Temporal Constraints for LLM Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [temporal constraints, SMT solving, constrained generation, formal verification, LLM agents]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Adharsh Kamath, Sishen Zhang, Calvin Xu, Shubham Ugare, Gagandeep Singh, Sasa Misailovic"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois at Urbana-Champaign, Meta"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23738",children:"https://arxiv.org/pdf/2512.23738"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/structuredllm/agent-c",children:"https://github.com/structuredllm/agent-c"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel framework (Agent-C) providing runtime guarantees for LLM agents to adhere to formal temporal safety properties., 2. A domain-specific language for expressing temporal properties, which are translated to first-order logic and verified via SMT solving during token generation., 3. Demonstration of perfect safety (100% conformance) and improved task utility across real-world applications and multiple LLMs, outperforming state-of-the-art guardrails."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a978adfab8b202d7b971f6b65f8d005235baabb93f5540985ad131638c67354_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a978adfab8b202d7b971f6b65f8d005235baabb93f5540985ad131638c67354_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLM agents violating temporal safety policies, such as accessing data before authentication. It proposes Agent-C, a framework that uses a domain-specific language, formal logic translation, and SMT solving to enforce constraints during token generation, ensuring compliant actions. The evaluation shows Agent-C achieves 100% safety conformance and improves task utility compared to existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Enforcing Temporal Constraints for LLM Agents] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u62a4\u680f\u65e0\u6cd5\u4fdd\u8bc1\u65f6\u95f4\u5b89\u5168\u7b56\u7565/Existing guardrails fail to enforce temporal safety policies]\n    C --\x3e C1[\u63d0\u51faAgent-C\u6846\u67b6/Propose Agent-C framework]\n    C1 --\x3e C2[\u4f7f\u7528DSL\u548cSMT\u6c42\u89e3\u8fdb\u884c\u8fd0\u884c\u65f6\u9a8c\u8bc1/Use DSL & SMT solving for runtime verification]\n    C2 --\x3e C3[\u91c7\u7528\u7ea6\u675f\u751f\u6210\u786e\u4fdd\u5408\u89c4/Achieve compliance via constrained generation]\n    D --\x3e D1[100%\u5b89\u5168\u6027\uff0c0%\u5371\u5bb3/100% safety, 0% harm]\n    D --\x3e D2[\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u63d0\u9ad8\u4efb\u52a1\u6548\u7528/Improve task utility in real-world applications]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Towards representation agnostic probabilistic programming"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [factor abstraction, probabilistic programming, hybrid models, representation-agnostic, factor graphs]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ole Fenske, Maximilian Popko, Sebastian Bader, Thomas Kirste"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute for Visual and Analytic Computing, University of Rostock"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23740",children:"https://arxiv.org/pdf/2512.23740"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a factor abstraction with five fundamental operations as a universal interface for manipulating probabilistic factors. 2. Enables representation-agnostic probabilistic programming, allowing the mixing of different distribution representations (e.g., discrete tables, Gaussians, samples) within a single framework. 3. Facilitates practical inference in complex hybrid (mixed discrete-continuous) models that current toolkits cannot adequately handle."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97ac8ba28932b58d58cfedc5a8c2d53a706dd206b4f545e3d26852fb3ee19d75_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97ac8ba28932b58d58cfedc5a8c2d53a706dd206b4f545e3d26852fb3ee19d75_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the tight coupling between model representations and inference algorithms in current probabilistic programming tools, which limits flexibility. It proposes a factor abstraction with a set of core operations to create a representation-agnostic interface. This allows users to mix various distribution representations, enabling inference in complex hybrid models previously difficult to express."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Towards representation agnostic probabilistic programming] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[PPLs\u8026\u5408\u8868\u793a\u4e0e\u63a8\u7406\u7b97\u6cd5/PPLs couple representations & inference]\n    B --\x3e B2[\u963b\u788d\u6df7\u5408\u6a21\u578b\u5b9e\u9a8c/Prevents hybrid model experimentation]\n    C --\x3e C1[\u5f15\u5165\u56e0\u5b50\u62bd\u8c61/Introduce factor abstraction]\n    C --\x3e C2[\u5b9a\u4e49\u4e94\u4e2a\u57fa\u672c\u64cd\u4f5c/Define five fundamental operations]\n    C --\x3e C3[\u521b\u5efa\u901a\u7528\u63a5\u53e3/Create universal interface]\n    D --\x3e D1[\u5b9e\u73b0\u8868\u793a\u65e0\u5173\u7f16\u7a0b/Enable representation-agnostic programming]\n    D --\x3e D2[\u652f\u6301\u6df7\u5408\u8868\u793a/Support mixing representations]\n    D --\x3e D3[\u5904\u7406\u590d\u6742\u6df7\u5408\u6a21\u578b/Handle complex hybrid models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Break Out the Silverware -- Semantic Understanding of Stored Household Items"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [commonsense reasoning], [benchmark dataset, vision-language model, hybrid agent pipeline, storage location prediction, semantic understanding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Michaela Levi-Richter, Reuth Mirsky, Oren Glickman"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Bar Ilan University, Tufts University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23739",children:"https://arxiv.org/pdf/2512.23739"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Stored Household Item Challenge, a new benchmark for evaluating service robots' commonsense reasoning about predicting the storage location of non-visible household items. 2. Provides two associated datasets: a real-world evaluation set and a larger development set with annotated storage polygons. 3. Proposes NOAM (Non-visible Object Allocation Model), a hybrid agent pipeline that combines structured scene understanding with LLM inference to tackle the challenge, demonstrating improved accuracy approaching human performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02333560037f17a9692645550b2d71e1239038dba5b036552b34388848b00f1f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02333560037f17a9692645550b2d71e1239038dba5b036552b34388848b00f1f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of enabling domestic robots to infer where non-visible household items are stored. It proposes a new benchmark task and datasets, and introduces NOAM, a hybrid vision-language agent that converts visual scenes into text for an LLM to predict storage locations. Evaluations show NOAM significantly outperforms baseline models and approaches human-level performance in this commonsense reasoning task."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Break Out the Silverware: Semantic Understanding of Stored Household Items] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Robots lack commonsense reasoning to find stored, non-visible household items.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes NOAM, a hybrid pipeline combining scene understanding and LLM inference.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: NOAM approaches human-level accuracy on the new storage prediction benchmark.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AgenticTCAD: A LLM-based Multi-Agent Framework for Automated TCAD Code Generation and Device Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [TCAD code generation, multi-agent framework, device optimization, LLM fine-tuning, DTCO]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guangxi Fan, Tianliang Ma, Xuguang Sun, Xun Wang, Kain Lu Low, Leilai Shao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Xi\u2019an Jiaotong\u2013Liverpool University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23742",children:"https://arxiv.org/pdf/2512.23742"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Construction of an open-source, expert-curated TCAD dataset and fine-tuning of a domain-specific LLM for TCAD code generation. 2. Proposal of AgenticTCAD, a natural language-driven multi-agent framework for end-to-end automated device design and optimization. 3. Demonstration of the framework's efficiency, achieving target device specifications in 4.2 hours compared to 7.1 days for human experts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9454cdfb5c93c8b3f9587f99a9e8982d695a9783f118909a0fd90f5e347f512e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9454cdfb5c93c8b3f9587f99a9e8982d695a9783f118909a0fd90f5e347f512e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of generating valid TCAD simulation code due to a lack of open-source data. It proposes AgenticTCAD, a multi-agent LLM framework that automates device design and optimization from natural language. The system was validated on a 2 nm nanosheet FET design, achieving target specifications significantly faster than human experts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("AgenticTCAD: LLM\u591a\u667a\u80fd\u4f53\u6846\u67b6 / AgenticTCAD: LLM-based Multi-Agent Framework") --\x3e Problem("TCAD\u4ee3\u7801\u751f\u6210\u8d44\u6e90\u7a00\u7f3a / Scarcity of TCAD Code Generation Resources")\n    Root --\x3e Method("\u6784\u5efa\u6570\u636e\u96c6\u4e0e\u591a\u667a\u80fd\u4f53\u6846\u67b6 / Dataset Construction & Multi-Agent Framework")\n    Root --\x3e Results("4.2\u5c0f\u65f6\u8fbe\u5230IRDS\u89c4\u683c / Achieves IRDS Specs in 4.2 Hours")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] State-of-the-art Small Language Coder Model: Mify-Coder"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [compute-optimal training, CPT-SFT, synthetic data generation, model quantization, quality filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Abhinav Parmar, Abhisek Panigrahi, Abhishek Kumar Dwivedi, Abhishek Bhattacharya, Adarsh Ramachandra, Aditya Choudhary, Aditya Garg, Aditya Raj, Alankrit Bhatt, Alpesh Yadav, Anant Vishnu, Ananthu Pillai, Ankush Kumar, Aryan Patnaik, Aswatha Narayanan S, Avanish Raj Singh, Bhavya Shree Gadda, Brijesh Pankajbhai Kachhadiya, Buggala Jahnavi, Chidurala Nithin Krishna, Chintan Shah, Chunduru Akshaya, Debarshi Banerjee, Debrup Dey, Deepa R., Deepika B G, Faiz ur Rahman, Gagan Gayari, Gudhi Jagadeesh Kumar Naidu, Gursimar Singh, Harshal Tyagi, Harshini K, James Mani Vathalloor, Jayarama Nettar, Jayashree Gajjam, Joe Walter Sugil George, Kamalakara Sri Krishna Tadepalli, Kamalkumar Rathinasamy, Karan Chaurasia, Karthikeyan S, Kashish Arora, Kaushal Desai, Khushboo Buwade, Kiran Manjrekar, Malikireddy Venkata Sai Likhitha, Manjunath A, Mitali Mahavir Bedmutha, Mohammed Rafee Tarafdar, Nikhil Tiwari, Nikitha K Gigi, Pavan Ravikumar, Pendyala Swarnanjali, Piyush Anand, Prakash Chandrasekar, Prasanna Bhalchandra Gawade, Prasanth Sivan, Preeti Khurana, Priyanshi Babbar, Rajab Ali Mondal, Rajesh Kumar Vissapragada, Rajeshwari Ganesan, Rajeswari Koppisetti, Ramjee R., Ramkumar Thiruppathisamy, Rani G. S., S Reka, Samarth Gupta, Sandeep Reddy Kothakota, Sarathy K, Sathyanarayana Sampath Kumar, Saurabh Kumar, Shashank Khasare, Shenbaga Devi Venkatesh Kumar, Shiva Rama Krishna Parvatham, Shoeb Shaikh, Shrishanmathi A, Shubham Pathak, Sree Samhita Koppaka, Sreenivasa Raghavan K S, Sreeram Venkatasubramanian, Suprabha Desai Bojja, Swetha R, Syed Ahmed, Chinmai Harshitha Thota, Tushar Yadav, Veeravelly Kusumitha, V V S S Prasanth Patnaik, Vidya Sri Sesetti, Vijayakeerthi K, Vikram Raj Bakshi, Vinay K K, Vinoth Kumar Loganathan, Vipin Tiwari, Vivek Kumar Shrivastav, V Venkata Sri Datta Charan, Wasim Akhtar Khan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Infosys AI Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23747",children:"https://arxiv.org/pdf/2512.23747"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced Mify-Coder, a 2.5B-parameter code model trained with a compute-optimal strategy on 4.2T tokens, demonstrating that compact models can match frontier-grade performance. 2. Developed a training pipeline combining high-quality curated data with agentically generated synthetic data, refined using enterprise-grade evaluations and LLM-based quality filtering for high data density. 3. Showed that disciplined exploration of training objectives and data mixtures within a single continuous trajectory enables competitive accuracy, efficiency, and safety, with quantized variants enabling deployment on standard hardware."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13c8af9d7668bbc4ac7ae9ad0ed379feb93f982a5fecdc8491169bd4d6c33d30_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13c8af9d7668bbc4ac7ae9ad0ed379feb93f982a5fecdc8491169bd4d6c33d30_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high computational cost of large code models by proposing Mify-Coder, a compact 2.5B-parameter model trained using a compute-optimal strategy that integrates curated and synthetic data with quality filtering. It demonstrates that this approach allows a small model to achieve performance comparable to much larger models on coding benchmarks while maintaining safety and enabling efficient desktop deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Mify-Coder] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5927\u6a21\u578b\u6210\u672c\u9ad8/High cost of large code models]\n    C --\x3e C1[\u8ba1\u7b97\u6700\u4f18\u8bad\u7ec3/Compute-optimal training]\n    C --\x3e C2[\u5408\u6210\u6570\u636e\u751f\u6210/Synthetic data generation]\n    C --\x3e C3[\u8d28\u91cf\u8fc7\u6ee4/Quality filtering]\n    D --\x3e D1[\u6027\u80fd\u53ef\u6bd4/Competitive performance]\n    D --\x3e D2[\u9ad8\u6548\u90e8\u7f72/Efficient deployment]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Hybrid-Code: A Privacy-Preserving, Redundant Multi-Agent Framework for Reliable Local Clinical Coding"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [neuro-symbolic AI, multi-agent framework, local inference, hallucination detection, deterministic fallback]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yunguo Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zyter|TruCare"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23743",children:"https://arxiv.org/pdf/2512.23743"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A hybrid neuro-symbolic multi-agent framework (Hybrid-Code) for reliable, on-premise clinical coding that combines an LLM-based Coder with a deterministic fallback and a symbolic Auditor for verification. 2. A privacy-preserving architecture ensuring no patient data leaves the hospital firewall, addressing critical deployment barriers in healthcare. 3. Demonstration that system reliability through architectural redundancy (achieving 0% hallucinations within the knowledge base) is more valuable than pure model performance for production healthcare AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b1a7891d43346fbec0638fdd7970002ba8ac5fe529a855a4c41f35f8cc8ad1e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b1a7891d43346fbec0638fdd7970002ba8ac5fe529a855a4c41f35f8cc8ad1e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Hybrid-Code, a framework for automated clinical coding that runs locally to preserve privacy. It uses a two-agent system where a Coder attempts semantic reasoning with a local LLM but falls back to keyword matching, and an Auditor verifies codes against a knowledge base to prevent hallucinations. The key conclusion is that this redundant, hybrid approach ensures production reliability where failures are unacceptable, even with a moderate coverage rate."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Hybrid-Code / Hybrid-Code] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4e91LLM\u5b58\u5728\u9690\u79c1\u4e0e\u5ef6\u8fdf\u98ce\u9669 / Cloud LLMs pose privacy & latency risks]\n    C --\x3e C1[\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u591a\u667a\u80fd\u4f53\u6846\u67b6 / Hybrid Neuro-Symbolic Multi-Agent Framework]\n    C1 --\x3e C2[\u7f16\u7801\u5668: LLM\u63a8\u7406 + \u786e\u5b9a\u6027\u56de\u9000 / Coder: LLM + Deterministic Fallback]\n    C1 --\x3e C3[\u5ba1\u8ba1\u5668: \u57fa\u4e8e\u77e5\u8bc6\u7684\u9a8c\u8bc1 / Auditor: Knowledge-Based Verification]\n    D --\x3e D1[0% \u77e5\u8bc6\u5e93\u5185\u5e7b\u89c9 / 0% Hallucination within KB]\n    D --\x3e D2[34.11% \u8986\u76d6\u7387 / 34.11% Coverage]\n    D --\x3e D3[\u65e0\u6570\u636e\u79bb\u5f00\u9632\u706b\u5899 / No Data Leaves Firewall]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [one-shot learning], [Coordinate Matrix Machine, structural intelligence, Green AI, lazy learning, glass-box model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amin Sadri, M Maruf Hossain"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated (email domains are personal: gmail.com)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23749",children:"https://arxiv.org/pdf/2512.23749"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," GitHub Repository (URL not fully specified in provided text)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' Proposes the Coordinate Matrix Machine (CM^2) for one-shot document classification, Introduces a structural coordinate-based approach as an alternative to semantic vectorization, Designs a "Green AI" model optimized for CPU use with inherent explainability']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3acd9104b41dbc3c7f9d1597d31b940424a078e93beb2b2b21007c741209b006_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3acd9104b41dbc3c7f9d1597d31b940424a078e93beb2b2b21007c741209b006_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the challenge of human-level concept learning, where machines require many examples to learn a concept. It proposes the Coordinate Matrix Machine (CM^2), a purpose-built model that learns document structures to classify very similar documents using only one sample per class. The method is presented as a "Green AI" solution that outperforms traditional models while being computationally efficient and explainable.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Human-level Concept Learning Gap]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Coordinate Matrix Machine (CM^2)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: High Accuracy, One-shot Learning, Green AI]\n    B --\x3e B1[\u4eba\u7c7b\u5355\u6837\u672c\u5b66\u4e60/Human one-shot learning]\n    B --\x3e B2[\u673a\u5668\u9700\u5927\u91cf\u6837\u672c/Machine needs many samples]\n    C --\x3e C1[\u5b66\u4e60\u6587\u6863\u7ed3\u6784/Learns document structure]\n    C --\x3e C2[\u8bc6\u522b\u91cd\u8981\u7279\u5f81/Identifies important features]\n    D --\x3e D1[\u9ad8\u7cbe\u5ea6\u4e0e\u4f4e\u6570\u636e/High accuracy with minimal data]\n    D --\x3e D2[CPU\u4f18\u5316\u4e0e\u53ef\u89e3\u91ca\u6027/CPU-optimized & explainable]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [uncertainty quantification], [Evidential Deep Learning, Subjective Logic, Activation Functions, Regularization, Learning Dynamics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Deep Shankar Pandey, Hyomin Choi, Qi Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Rochester Institute of Technology, InterDigital"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23753",children:"https://arxiv.org/pdf/2512.23753"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Theoretically characterizes the activation-dependent "learning-freeze" behavior in evidential deep learning models, where gradients vanish in low-evidence regions. 2. Designs a general family of activation functions and corresponding evidential regularizers to enable consistent evidence updates across different activation regimes. 3. Empirically validates the proposed theory and method through extensive experiments on multiple benchmark classification, few-shot classification, and blind face restoration tasks.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fae8a70028f83294a153c8fd9b9083e99f87bf5f04f2fb8d64ce2fbab74beb82_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fae8a70028f83294a153c8fd9b9083e99f87bf5f04f2fb8d64ce2fbab74beb82_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper identifies and theoretically analyzes a "learning-freeze" problem in Evidential Deep Learning (EDL) models caused by specific activation functions. To solve this, the authors propose a generalized family of activation functions and regularizers. Extensive experiments show the proposed method improves learning dynamics and effectiveness across various tasks.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Generalized Regularized Evidential Deep Learning Models") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: Activation functions in EDL cause learning-freeze in low-evidence regions")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Design a general family of activation functions and evidential regularizers")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Theory validated; method effective across multiple benchmarks")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Geometric Scaling of Bayesian Inference in LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [interpretability], [Bayesian inference, geometric scaling, attention mechanism, value manifolds, predictive entropy]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dream Sports, Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23752",children:"https://arxiv.org/pdf/2512.23752"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Demonstrates that production-grade LLMs (Pythia, Phi-2, Llama-3, Mistral) preserve a geometric substrate (low-dimensional value manifolds) similar to that enabling exact Bayesian inference in small, controlled "wind-tunnel" models. 2. Shows that the dominant axis of last-layer value representations strongly correlates with predictive entropy, and domain-restricted prompts collapse the structure into the same low-dimensional manifolds. 3. Through targeted interventions on the entropy-aligned axis, reveals that this geometry is a privileged readout of uncertainty rather than a singular computational bottleneck for Bayesian-like behavior.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e11ae0519509ba1ae43d1087dfc56ed0f799df57a2ee4fe7c4a6a7f20eb11c3f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e11ae0519509ba1ae43d1087dfc56ed0f799df57a2ee4fe7c4a6a7f20eb11c3f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether the geometric structures that enable exact Bayesian inference in small, controlled transformer models persist in large-scale production language models. The authors find that models like Llama-3 and Mistral organize their value representations along an entropy-correlated axis, forming similar low-dimensional manifolds. They conclude that modern LLMs preserve this geometric substrate for approximate Bayesian updates, though it acts more as a readout mechanism than a sole computational bottleneck."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Geometric Scaling of Bayesian Inference in LLMs] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Do geometric structures for Bayesian inference persist in production LLMs?]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Analyze value representations & perform targeted axis interventions]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Geometry persists as a privileged uncertainty readout]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HINTS: Extraction of Human Insights from Time-Series Without External Sources"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [time series forecasting], [self-supervised learning, opinion dynamics, attention mechanism, latent factor extraction, residual analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sheo Yon Jhin, Noseong Park"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," KAIST"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23755",children:"https://arxiv.org/pdf/2512.23755"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HINTS, a novel self-supervised framework that extracts latent human factors (e.g., sentiment, influence) endogenously from time series residuals without requiring external data sources like news or social media. 2. Introduces the use of the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns within the time series data. 3. Demonstrates that integrating the extracted human factors as an attention map into a state-of-the-art backbone model consistently improves forecasting accuracy across multiple datasets and provides interpretable insights aligned with real-world events."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a97eb229421de0a13cd23a1f8c66b8e7b1ac081ecf63d3e2a393fa375ac5f65_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a97eb229421de0a13cd23a1f8c66b8e7b1ac081ecf63d3e2a393fa375ac5f65_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high cost of using external data to model human factors in time series forecasting. It proposes HINTS, a self-supervised learning framework that extracts latent human insights directly from time series residuals using an opinion dynamics model as inductive bias. The method improves forecasting accuracy and provides interpretable factors aligned with real events, validated on nine real-world and benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HINTS: Extraction of Human Insights from Time-Series] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5916\u90e8\u6570\u636e\u4f9d\u8d56\u6210\u672c\u9ad8/High cost of external data dependency]\n    C --\x3e C1[\u4ece\u6b8b\u5dee\u4e2d\u81ea\u76d1\u7763\u63d0\u53d6\u4eba\u7c7b\u56e0\u7d20/Self-supervised extraction from residuals]\n    C --\x3e C2[\u4f7f\u7528\u610f\u89c1\u52a8\u529b\u5b66\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e/Using opinion dynamics as inductive bias]\n    C --\x3e C3[\u96c6\u6210\u5230\u6ce8\u610f\u529b\u673a\u5236\u4e2d/Integrated as attention map]\n    D --\x3e D1[\u9884\u6d4b\u7cbe\u5ea6\u63d0\u5347/Forecasting accuracy improved]\n    D --\x3e D2[\u53ef\u89e3\u91ca\u6027\u4e0e\u73b0\u5b9e\u4e8b\u4ef6\u5bf9\u9f50/Interpretability aligned with real events]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Drift-Based Dataset Stability Benchmark"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [concept drift, dataset stability, traffic classification, benchmark, feature weights]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dominik Soukup, Richard Pln\xfd, Daniel Va\u0161ata, Tom\xe1\u0161 \u010cejka"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Czech Technical University in Prague, CESNET a.l.e."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23762",children:"https://arxiv.org/pdf/2512.23762"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel methodology for evaluating dataset stability based on concept drift detection and ML feature weights. 2. A benchmark workflow for comparing datasets and identifying their weak points. 3. A demonstration and initial benchmark of the framework on the CESNET-TLS-Year22 dataset, showing its use for dataset optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc4badd4590db607d7056063e44a30285afee3c4bd25f3f6b231fbc0932dd8de_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc4badd4590db607d7056063e44a30285afee3c4bd25f3f6b231fbc0932dd8de_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of model degradation in network traffic classification due to data/concept drift. It proposes a new framework that uses a concept drift detection method enhanced with ML feature weights to benchmark dataset stability. The method is demonstrated on a real-world TLS dataset, providing insights for dataset optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Drift-Based Dataset Stability Benchmark] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Model degradation from data drift in network traffic classification]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Concept drift detection boosted by ML feature weights for dataset benchmarking]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Initial stability benchmark for CESNET-TLS-Year22 dataset, showing optimization impact]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, entropy penalty, training-free, reasoning acceleration, draft-model verification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tiancheng Su, Meicong Zhang, Guoxiu He"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," East China Normal University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23765",children:"https://arxiv.org/pdf/2512.23765"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Entropy-Aware Speculative Decoding (EASD), a training-free method that introduces a dynamic entropy-based penalty to reject low-confidence draft tokens, 2. Enables speculative decoding to potentially surpass the target model's performance by incorporating draft-model verification and preventing error propagation, 3. Demonstrates that EASD maintains efficiency comparable to standard speculative decoding while improving reasoning accuracy across multiple benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of speculative decoding being constrained by the target model's performance. It proposes Entropy-Aware Speculative Decoding (EASD), which uses entropy to quantify uncertainty and reject low-confidence draft tokens. Experiments show EASD outperforms existing methods and can surpass the target LLM's performance while maintaining comparable efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Entropy-Aware Speculative Decoding] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[SD\u6027\u80fd\u53d7\u9650\u4e8e\u76ee\u6807\u6a21\u578b/SD performance capped by target model]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u5f15\u5165\u52a8\u6001\u71b5\u60e9\u7f5a/Introduce dynamic entropy penalty]\n    Method --\x3e M2[\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u62d2\u7edd\u4f4e\u7f6e\u4fe1\u5ea6\u4ee4\u724c/Reject low-confidence tokens based on uncertainty]\n    Method --\x3e M3[\u76ee\u6807\u6a21\u578b\u91cd\u91c7\u6837/Target model re-sampling]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u8d85\u8d8a\u73b0\u6709SD\u65b9\u6cd5/Outperforms existing SD methods]\n    Results --\x3e R2[\u5e38\u8d85\u8d8a\u76ee\u6807LLM\u672c\u8eab/Often surpasses target LLM]\n    Results --\x3e R3[\u6548\u7387\u4e0eSD\u76f8\u5f53/Efficiency comparable to SD]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [skill graph, verifiable rewards, continual memory, experience synthesis, audit logging]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ken Huang, Jerry Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," DistributedApps.ai, OWASP, Kleiner Perkins"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23760",children:"https://arxiv.org/pdf/2512.23760"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Audited Skill-Graph Self-Improvement (ASG-SI) framework, which treats agent self-improvement as the iterative compilation of an auditable, growing skill graph. 2. Introduces a verifier-auditor mechanism that uses replayable evidence and decomposed rewards to gate skill promotion, enabling independent audit and governance. 3. Integrates experience synthesis for scalable testing and continual memory control to manage context growth and preserve long-horizon performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd2b1c94a27644963b1a77d560eb3715fa72ea6468dc6c4e39e42eb5e040187_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses security and governance challenges in self-improving AI agents, such as reward hacking and opaque behavioral drift. It proposes the ASG-SI framework, which compiles agent improvements into an auditable skill graph verified by replayable evidence. The approach reframes self-improvement as the accumulation of verifiable, reusable capabilities for reproducible evaluation and operational governance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Audited Skill-Graph Self-Improvement (ASG-SI) / \u5ba1\u8ba1\u6280\u80fd\u56fe\u81ea\u6211\u6539\u8fdb"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem"] --\x3e P1["\u90e8\u7f72\u7684\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u4e0e\u6cbb\u7406\u6311\u6218 / Deployed self-improving agents pose security & governance challenges"]\n    P1 --\x3e P2["\u5956\u52b1\u9ed1\u5ba2\u884c\u4e3a\u3001\u884c\u4e3a\u6f02\u79fb\u3001\u4e0d\u900f\u660e\u7684\u66f4\u65b0 / Reward hacking, behavioral drift, opaque updates"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method"] --\x3e M1["ASG-SI \u6846\u67b6 / ASG-SI Framework"]\n    M1 --\x3e M2["\u5c06\u6539\u8fdb\u7f16\u8bd1\u4e3a\u53ef\u5ba1\u8ba1\u6280\u80fd\u56fe / Compile improvements into auditable skill graph"]\n    M2 --\x3e M3["\u57fa\u4e8e\u9a8c\u8bc1\u5668\u7684\u8bc1\u636e\u548c\u53ef\u5206\u89e3\u5956\u52b1\u8fdb\u884c\u6280\u80fd\u63d0\u5347 / Verifier-backed evidence & decomposed rewards gate skill promotion"]\n    M3 --\x3e M4["\u96c6\u6210\u7ecf\u9a8c\u5408\u6210\u548c\u6301\u7eed\u8bb0\u5fc6\u63a7\u5236 / Integrate experience synthesis & continual memory control"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e R1["\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u3001\u53ef\u91cd\u7528\u7684\u80fd\u529b\u79ef\u7d2f / Provides accumulation of verifiable, reusable capabilities"]\n    R1 --\x3e R2["\u4e3a\u81ea\u6211\u6539\u8fdbAI\u63d0\u4f9b\u53ef\u590d\u73b0\u8bc4\u4f30\u548c\u64cd\u4f5c\u6cbb\u7406\u7684\u8def\u5f84 / Offers path for reproducible evaluation & operational governance of self-improving AI"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [FPGA acceleration, model recovery, hardware-software co-design, GRU, Neural ODE]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bin Xu, Ayan Banerjee, Sandeep Gupta"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Arizona State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23767",children:"https://arxiv.org/pdf/2512.23767"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed MERINDA, a hardware-friendly FPGA-accelerated framework for model recovery that replaces Neural ODEs with a formulation combining GRU-based discretized dynamics, dense inverse-ODE layers, sparsity-driven dropout, and lightweight solvers. 2. Designed the framework for streaming parallelism, enabling critical computational kernels to be fully parallelized on FPGA hardware. 3. Demonstrated transformative efficiency gains over GPU implementations, including 114x lower energy, 28x smaller memory footprint, and 1.68x faster training while maintaining state-of-the-art accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e286e0d5a9672c23140099a1b5fd5c7ad7e56f56cb1c276735170b95ad29fd47_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of deploying physical AI for model recovery on resource-constrained edge devices, where state-of-the-art methods using Neural ODEs are inefficient. The authors propose MERINDA, an FPGA-accelerated framework that uses a hardware-friendly architecture to replace expensive Neural ODE components. The results show that MERINDA achieves substantial improvements in energy, memory, and speed over GPU implementations while matching model recovery accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Enabling Physical AI at the Edge<br>\u5728\u8fb9\u7f18\u5b9e\u73b0\u7269\u7406\u4eba\u5de5\u667a\u80fd] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Model recovery methods (Neural ODEs) are inefficient for edge hardware<br>\u6a21\u578b\u6062\u590d\u65b9\u6cd5\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u6548\u7387\u4f4e\u4e0b]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>MERINDA: FPGA-accelerated, hardware-friendly framework<br>MERINDA: FPGA\u52a0\u901f\u7684\u786c\u4ef6\u53cb\u597d\u6846\u67b6]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>114x lower energy, 28x smaller memory, 1.68x faster training<br>\u80fd\u8017\u964d\u4f4e114\u500d, \u5185\u5b58\u5360\u7528\u51cf\u5c1128\u500d, \u8bad\u7ec3\u901f\u5ea6\u63d0\u53471.68\u500d]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [algorithmic fairness], [discrimination clustering, individual fairness, hybrid verification, SMT solver, MILP solver]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ranit Debnath Akash, Ashish Kumar, Verya Monjezi, Ashutosh Trivedi, Gang, Saeid Tizpaz-Niari"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois Chicago, University of Colorado Boulder, Pennsylvania State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23769",children:"https://arxiv.org/pdf/2512.23769"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduced the concept of "discrimination clustering" as a generalization of individual fairness to uncover systematic bias patterns. 2. Proposed HyFair, a hybrid technique combining formal symbolic analysis (SMT/MILP) and randomized search for both certification and violation discovery. 3. Developed a novel explanation method to generate interpretable, decision-tree-style artifacts for inputs exhibiting high discrimination.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05da1223f6a1c9a93634f021d221ac5175d00dee272ded0b8782834941db9c55_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05da1223f6a1c9a93634f021d221ac5175d00dee272ded0b8782834941db9c55_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper identifies a limitation in individual fairness, which only detects isolated unfairness, and proposes the concept of "discrimination clustering" to uncover systematic bias patterns. It introduces HyFair, a hybrid method combining formal verification and randomized search to detect these clusters and generate explanations. Experiments show HyFair outperforms existing fairness verification and explanation methods.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Uncovering Discrimination Clusters") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u4e2a\u4f53\u516c\u5e73\u6027\u68c0\u67e5\u7684\u5c40\u9650\u6027/Limitations of individual fairness checks")\n    P1 --\x3e P2("\u65e0\u6cd5\u6355\u6349\u7cfb\u7edf\u6027\u6b67\u89c6\u6a21\u5f0f/Fails to capture systematic bias patterns")\n    Method --\x3e M1("\u63d0\u51fa\u6b67\u89c6\u805a\u7c7b\u6982\u5ff5/Propose discrimination clustering concept")\n    Method --\x3e M2("\u5f00\u53d1HyFair\u6df7\u5408\u6280\u672f/Develop HyFair hybrid technique")\n    M2 --\x3e M3("\u7ed3\u5408\u5f62\u5f0f\u5206\u6790\u4e0e\u968f\u673a\u641c\u7d22/Combine formal analysis & randomized search")\n    Results --\x3e R1("\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5/Outperforms state-of-the-art methods")\n    Results --\x3e R2("\u63ed\u793a\u7cfb\u7edf\u6027\u504f\u5dee/Reveals substantial discrimination clustering")\n    Results --\x3e R3("\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bf4\u660e/Provides intuitive explanations")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [safe reinforcement learning], [constrained MDP, trust region policy optimization, natural policy gradient, safety gymnasium, hard constraints]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ankit Kanwar, Dominik Wagner, Luke Ong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sony Corporation, Nanyang Technological University (NTU Singapore)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23770",children:"https://arxiv.org/pdf/2512.23770"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new algorithm for hard-constrained RL that adaptively biases policy updates towards safety while seeking reward improvement. 2. Introduces a trust-region update using a convex combination of the natural policy gradients of cost and reward to ensure a fixed fraction of optimal cost reduction per step. 3. Provides a theoretical guarantee of local progress towards safety and demonstrates superior balance of safety and task performance on Safety Gymnasium benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ea6c2a84f6cc7b4f3144847fc78a84736f7247b99f773ed23dd1861f2ff0760_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of reinforcement learning under hard safety constraints, where existing methods struggle to avoid violations without sacrificing reward. It proposes SB-TRPO, an algorithm that performs trust-region updates by combining reward and cost gradients to bias updates towards safety. Experiments show that SB-TRPO achieves a better balance of safety and task completion than state-of-the-art methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Safety-Biased Policy Optimisation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: RL in safety-critical domains requires strict constraint adherence without sacrificing reward performance.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: SB-TRPO uses convex combination of natural policy gradients for cost and reward in trust-region updates.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Achieves best balance of safety and task completion on Safety Gymnasium benchmarks.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [anomaly detection], [Graph Neural Networks (GNNs), Fraud Detection, Class Imbalance, Fraudulent Camouflage, Ride-Hailing Platforms]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kanishka Hewageegana, Janani Harischandra, Nipuna Senanayake, Gihan Danansuriya, Kavindu Hapuarachchi, Pooja Illangarathne"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Informatics Institute of Technology, Rajarata University, University of Sri Jayewardenepura"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23777",children:"https://arxiv.org/pdf/2512.23777"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides a structured overview and comparison of existing Graph Neural Network (GNN) architectures and methodologies for fraud detection in ride-hailing platforms. 2. Highlights and analyzes key challenges in the domain, specifically class imbalance and fraudulent camouflage, within the ride-hailing ecosystem. 3. Identifies significant methodological progress and research gaps, calling for further exploration into real-world applicability and technical improvements."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65fc7f6ff0330c22a6dc35373a15256baac5eef984a9100cce967991d93a1e67_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65fc7f6ff0330c22a6dc35373a15256baac5eef984a9100cce967991d93a1e67_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This survey investigates the use of Graph Neural Networks (GNNs) for detecting fraud in ride-hailing platforms. It analyzes and compares various GNN models, focusing on their effectiveness in handling complex relational data and challenges like class imbalance. The paper concludes by identifying progress and gaps in the field, advocating for more research on real-world applications and technical enhancements."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Fraud detection in ride-hailing platforms"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Survey and analysis of Graph Neural Networks (GNNs)"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Identifies progress, gaps, and calls for future work"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks on llms], [denial-of-service, over-generation, black-box attack, evolutionary search, reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Manu, Yi Guo, Jo Plested, Tim Lynar, Kanchana Thilakarathna, Nirhoshan Sivaroopan, Jack Yang, Wangli Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Western Sydney University, University of New South Wales Canberra, The University of Sydney, University of Wollongong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23779",children:"https://arxiv.org/pdf/2512.23779"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a black-box, query-only benchmark for evaluating prompt-induced denial-of-service attacks on LLMs. 2. Proposes two novel prompt-only attackers: an evolutionary search method (EOGen) and a goal-conditioned reinforcement learning method (RL-GOAL). 3. Defines the Over-Generation Factor (OGF) as a key metric to quantify attack success and characterize model vulnerability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3002b15ce3957d88befc241c59f1be73a9e49f4e8ad4c345e9d472f11883059e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of denial-of-service attacks on large language models via prompt-induced over-generation. It proposes a standardized black-box benchmark and two automated attack methods, EOGen and RL-GOAL, to find adversarial prefixes that delay model termination. The results show that the RL-GOAL attacker is particularly effective at forcing models to generate excessively long outputs, highlighting a significant vulnerability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Prompt-Induced Over-Generation as Denial-of-Service<br/>\u63d0\u793a\u8bf1\u5bfc\u8fc7\u5ea6\u751f\u6210\u4f5c\u4e3a\u62d2\u7edd\u670d\u52a1\u653b\u51fb] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>LLM\u8fc7\u5ea6\u751f\u6210\u5bfc\u81f4\u670d\u52a1\u62d2\u7edd\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u589e\u52a0]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u9ed1\u76d2\u57fa\u51c6\u4e0e\u4e24\u79cd\u653b\u51fb\u8005: EOGen(\u8fdb\u5316\u641c\u7d22)\u548cRL-GOAL(\u5f3a\u5316\u5b66\u4e60)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>RL-GOAL\u653b\u51fb\u8005\u5b9e\u73b0\u66f4\u9ad8\u7684\u5e73\u5747\u8fc7\u5ea6\u751f\u6210\u56e0\u5b50(OGF)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [ensemble reinforcement learning, selective update, variational autoencoder, high-frequency trading, risk management]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Molei Qin, Xinyu Cai, Yewen Li, Haochong Xia, Chuqiao Zong, Shuo Sun, Xinrun Wang, Bo An"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanyang Technological University, Singapore Management University, Hong Kong University of Science and Technology (Guangzhou)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23773",children:"https://arxiv.org/pdf/2512.23773"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A selective update mechanism for ensemble Q-learners using ensemble TD errors to stabilize training and improve convergence in high-leverage environments. 2. A risk-aware filtering and routing mechanism that uses VAEs to model market state dynamics and identify agent capability boundaries, enabling dynamic policy selection to mitigate risk. 3. A novel three-stage ensemble RL framework (FineFT) that integrates stable training and risk management, demonstrating superior profitability and over 40% risk reduction in crypto futures trading."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c036ba975592c2c3be9068e742ccd28ed5b9722ff62085fbcc37e9f3627fe370_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes FineFT, a three-stage ensemble reinforcement learning framework designed to address the challenges of high leverage and unseen market states in futures trading. The method uses selective updates for stable training and VAEs for risk-aware policy routing, achieving higher profitability and significantly lower risk compared to state-of-the-art baselines in high-frequency crypto futures experiments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FineFT: Efficient and Risk-Aware Ensemble RL for Futures Trading] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u9ad8\u6760\u6746\u653e\u5927\u6ce2\u52a8/High leverage amplifies reward fluctuations]\n    B --\x3e B2[\u7f3a\u4e4f\u80fd\u529b\u8fb9\u754c\u610f\u8bc6/Lack of self-awareness of capability boundaries]\n    C --\x3e C1[\u9636\u6bb5I: \u9009\u62e9\u6027\u66f4\u65b0/Stage I: Selective Update]\n    C --\x3e C2[\u9636\u6bb5II: \u8fc7\u6ee4\u4e0eVAE\u8bad\u7ec3/Stage II: Filtering & VAE Training]\n    C --\x3e C3[\u9636\u6bb5III: \u52a8\u6001\u8def\u7531/Stage III: Dynamic Routing]\n    D --\x3e D1[\u8d85\u8d8a12\u4e2aSOTA\u57fa\u7ebf/Outperforms 12 SOTA baselines]\n    D --\x3e D2[\u98ce\u9669\u964d\u4f4e\u8d8540%/Risk reduced by >40%]\n    D --\x3e D3[\u5b9e\u73b0\u66f4\u9ad8\u76c8\u5229/Achieves superior profitability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [Zero-Trust Architecture, SHAP-weighted aggregation, TPM-based attestation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Samaresh Kumar Singh, Joyjit Roy, Martin So"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researchers (based on provided affiliations: IEEE Senior Member in Texas, IEEE Member in Texas, Independent Researcher in Canada)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23809",children:"https://arxiv.org/pdf/2512.23809"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1) Proposed a hierarchical edge-fog-cloud zero-trust federated learning architecture for trusted agent participation. 2) Introduced a novel SHAP-weighted aggregation algorithm for explainable Byzantine detection in non-IID environments. 3) Integrated TPM-based cryptographic attestation and on-device adversarial training into a defense-in-depth framework."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/baa785fc442fcbc6a80214c4fdc6361e67a8e34e5a9bb6f5dd8fb34baf21bb68_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses security vulnerabilities in Federated Learning for Industrial IoT by proposing ZTA-FL, a framework combining zero-trust agent authentication, explainable Byzantine-resilient aggregation, and on-device adversarial training. It demonstrates high detection accuracy and robustness against attacks on intrusion detection benchmarks while reducing communication overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: IIoT\u5b89\u5168\u6f0f\u6d1e\u4e0e\u8054\u90a6\u5b66\u4e60\u653b\u51fb / IIoT Security Gaps & FL Attacks]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u96f6\u4fe1\u4efb\u8ba4\u8bc1\u4e0e\u53ef\u89e3\u91ca\u805a\u5408 / Zero-Trust Attestation & Explainable Aggregation]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u4e0e\u6297\u653b\u51fb\u9c81\u68d2\u6027 / High Detection Accuracy & Attack Robustness]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [mental health text classification], [transfer learning, continual training, RoBERTa, cross-condition, stress detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amal Alqahtani, Efsun Kayi, Mona Diab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The George Washington University, King Saud University, Johns Hopkins University Applied Physics Laboratory, Carnegie Mellon University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23813",children:"https://arxiv.org/pdf/2512.23813"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes StressRoBERTa, a cross-condition transfer learning approach for detecting self-reported chronic stress in tweets. 2. Demonstrates that continual training on a focused set of clinically related mental health conditions (depression, anxiety, PTSD) improves stress detection over general models. 3. Shows effective transfer from clinical mental health contexts to situational stress discussions via evaluation on the Dreaddit dataset."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a57224b94917298d3e6f94d2c9255d2d054abcab5c5051070f928ff8ddd8bc6b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a57224b94917298d3e6f94d2c9255d2d054abcab5c5051070f928ff8ddd8bc6b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces StressRoBERTa, a method that continually trains a RoBERTa model on social media text from users with depression, anxiety, and PTSD before fine-tuning it for chronic stress detection. The approach outperforms the previous best system on the SMM4H 2022 shared task by 3% F1-score, showing that focused cross-condition transfer learning from related disorders provides stronger representations for stress detection."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[StressRoBERTa: Cross-Condition Transfer Learning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: \u68c0\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e2d\u7684\u6162\u6027\u538b\u529b/Detect chronic stress on social media)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: \u4ece\u76f8\u5173\u5fc3\u7406\u5065\u5eb7\u72b6\u51b5\u8fdb\u884c\u8de8\u6761\u4ef6\u8fc1\u79fb\u5b66\u4e60/Cross-condition transfer learning from related mental health conditions)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: \u6027\u80fd\u8d85\u8d8a\u6700\u4f73\u5171\u4eab\u4efb\u52a1\u7cfb\u7edf\uff0cF1\u5206\u6570\u8fbe82%/Outperforms best shared task system with 82% F1)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Improved Bounds for Private and Robust Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [preference learning], [private alignment, robust alignment, uniform convergence, log loss, adversarial corruption]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenqian Weng, Yi He, Xingyu Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wayne State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23816",children:"https://arxiv.org/pdf/2512.23816"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Showed that standard private MLE-type log loss can achieve near-optimal rates for private alignment, contrary to prior belief. 2. Demonstrated that existing offline algorithms for joint privacy-and-corruption provide stronger guarantees than previously known, leading to improved bounds for corruption-only settings. 3. Presented the first set of theoretical results for private and robust online alignment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07d766123762454b64f45852c98c882b263a3fe86efdee6b0c39b70b0d888215_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07d766123762454b64f45852c98c882b263a3fe86efdee6b0c39b70b0d888215_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the theoretical alignment of language models under privacy constraints and adversarial corruption. It shows that a standard MLE-style log loss can achieve near-optimal rates for private alignment and provides improved bounds for joint private-and-robust settings, including the first online results, enabled by new uniform convergence guarantees."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Improved Bounds for Private and Robust Alignment] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50/Language Model Alignment]\n    B --\x3e B2[\u9690\u79c1\u4e0e\u566a\u58f0\u6807\u7b7e/Private & Noisy Labels]\n    C --\x3e C1[\u7406\u8bba\u5206\u6790/Theoretical Analysis]\n    C --\x3e C2[\u7edf\u4e00\u6536\u655b/Uniform Convergence]\n    D --\x3e D1[\u79c1\u6709MLE\u8fbe\u5230\u6700\u4f18/Private MLE Near-Optimal]\n    D --\x3e D2[\u79bb\u7ebf\u548c\u5728\u7ebf\u6539\u8fdb\u754c\u9650/Improved Offline & Online Bounds]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Video-Based Performance Evaluation for ECR Drills in Synthetic Training Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [human pose estimation and action analysis], [video-based assessment, 2D skeleton extraction, Cognitive Task Analysis (CTA), performance metrics, synthetic training environments]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Surya Rayala, Marcos Quinones-Grueiro, Naveeduddin Mohammed, Ashwin T S, Benjamin Goldberg, Randall Spain, Paige Lawton, Gautam Biswas"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Vanderbilt University, US Army DEVCOM Soldier Center"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23819",children:"https://arxiv.org/pdf/2512.23819"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A video-based assessment pipeline that extracts performance analytics (2D skeletons, gaze vectors, trajectories) from training videos without extra hardware. 2. Development of task-specific metrics for psychomotor fluency, situational awareness, and team coordination, integrated into an extended Cognitive Task Analysis hierarchy. 3. Demonstration of the approach via a case study on real-world Enter and Clear the Room drills and discussion of its integration into After Action Review systems like Gamemaster and GIFT."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33d390da3c0f68240f7cda6efac9e31e941e99ab611d61cd2837f0352453d12c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33d390da3c0f68240f7cda6efac9e31e941e99ab611d61cd2837f0352453d12c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of automatically and objectively assessing soldier performance in synthetic training environments. It proposes a video-based pipeline using computer vision to extract movement and gaze data, from which it derives specific performance metrics for cognitive and teamwork skills. The method is demonstrated on real-world drills and shows potential for scalable, hardware-free evaluation to support training feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Video-Based Performance Evaluation for ECR Drills") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u53d7\u9650/Traditional assessment limited")\n    P1 --\x3e P1_1("\u4f9d\u8d56\u6602\u8d35\u4f20\u611f\u5668/Relies on costly sensors")\n    P1 --\x3e P1_2("\u4e3b\u89c2\u4eba\u4e3a\u89c2\u5bdf/Subjective human observation")\n    Method --\x3e M1("\u89c6\u9891\u5206\u6790\u7ba1\u9053/Video-based pipeline")\n    M1 --\x3e M1_1("\u63d0\u53d62D\u9aa8\u67b6\u3001\u89c6\u7ebf\u3001\u8f68\u8ff9/Extract 2D skeletons, gaze, trajectories")\n    M1 --\x3e M1_2("\u5f00\u53d1\u4efb\u52a1\u7279\u5b9a\u6307\u6807/Develop task-specific metrics")\n    M1 --\x3e M1_3("\u6269\u5c55\u8ba4\u77e5\u4efb\u52a1\u5206\u6790/Extended Cognitive Task Analysis")\n    Results --\x3e R1("\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1/Case study validation")\n    Results --\x3e R2("\u652f\u6301\u884c\u52a8\u540e\u8bc4\u4f30/Supports After Action Reviews")\n    Results --\x3e R3("\u672a\u6765: 3D\u5206\u6790/Future: 3D analysis")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [adversarial robustness], [mechanistic interpretability, attention layers, adversarial examples, LLM evaluation, token substitution]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kaustubh Dhole"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Emory University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23837",children:"https://arxiv.org/pdf/2512.23837"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel adversarial example generation method that exploits intermediate attention layer token distributions, contrasting with prompt-based or gradient-based attacks. 2. Introduces two specific attention-based generation techniques: attention-based token substitution and attention-based conditional generation. 3. Empirically demonstrates that such adversarial examples can degrade performance on an evaluation task (argument quality assessment) while maintaining semantic similarity, highlighting both the promise and limitations (e.g., grammatical degradation) of the approach."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85f39e8eb9d1e9534ca2c7e95f4e08380c10c2d3b58ec0a3a896f0767b75fdd8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85f39e8eb9d1e9534ca2c7e95f4e08380c10c2d3b58ec0a3a896f0767b75fdd8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new method to generate adversarial examples by extracting token predictions from the intermediate attention layers of LLMs, leveraging their iterative refinement property. The approach is used to stress-test LLM-based evaluation pipelines, showing it can cause performance drops on an argument quality task while preserving semantics, though grammatical issues can arise. The findings illustrate the potential and current constraints of using internal model representations for adversarial testing."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Can intermediate attention layers be used to generate adversarial examples for LLM evaluation?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Leverage attention-layer token distributions for token substitution/conditional generation]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Adversarial examples cause performance drop but may introduce grammatical issues]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [bias detection], [SHAP, transformer, interpretability, false positives, domain adaptation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Himel Ghosh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Technical University of Munich, Sapienza University of Rome"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23835",children:"https://arxiv.org/pdf/2512.23835"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a comparative interpretability study of two transformer-based bias detection models using SHAP to analyze their decision mechanisms. 2. Revealed that a standard bias detector model exhibits a misalignment between attribution strength and prediction correctness, leading to systematic over-flagging, while a domain-adapted model produces significantly fewer false positives. 3. Demonstrated that model errors, particularly false positives, arise from discourse-level ambiguity rather than explicit bias cues, highlighting distinct linguistic failure modes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cbe893cabdbb4c14e3f0b2a14a91011067d2ee0ee4225b0a232eb5591a1b743_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cbe893cabdbb4c14e3f0b2a14a91011067d2ee0ee4225b0a232eb5591a1b743_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper compares how two transformer models detect bias in news text using SHAP-based explanations. It finds that while both models focus on similar evaluative language, a domain-adapted model integrates these signals more reliably, producing far fewer false positives than a standard bias detector. The study concludes that interpretability analysis is crucial for evaluating bias detection systems and that architectural choices critically impact their reliability for journalistic use."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Explaining News Bias Detection] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[How do bias detection models make decisions?]\n    C --\x3e C1[Comparative SHAP analysis of two transformer models]\n    D --\x3e D1[Domain-adapted model has better alignment and fewer false positives]\n    D --\x3e D2[False positives driven by discourse ambiguity]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [adaptive prompting, context window, open-domain QA, retrieval-augmented generation, LLM ignorance]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dingmin Wang, Ji Ma, Shankar Kumar"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google Research, University of Oxford"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23836",children:"https://arxiv.org/pdf/2512.23836"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an adaptive prompting strategy for RAG that splits retrieved information into smaller chunks for sequential processing, mitigating the noise from irrelevant information in long contexts. 2. Demonstrates experimentally that this strategy matches or outperforms standard prompting on open-domain QA datasets while using fewer tokens. 3. Identifies and analyzes a key failure mode where LLMs generate incorrect answers instead of declining when information is insufficient, highlighting a critical area for future research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d02669f63e2ba5d0171fc84f89e87cc22d595344fc20e61769b4288b009ef5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d02669f63e2ba5d0171fc84f89e87cc22d595344fc20e61769b4288b009ef5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem that longer context windows in Retrieval-Augmented Generation (RAG) introduce irrelevant information, degrading LLM performance. It proposes an adaptive prompting strategy that processes retrieved text in smaller, sequential chunks, achieving comparable accuracy with lower token usage. The study concludes that a major source of error is the LLM's tendency to generate wrong answers rather than admit ignorance, pointing to the need for improved refusal capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u957f\u4e0a\u4e0b\u6587\u5f15\u5165\u65e0\u5173\u4fe1\u606f\uff0c\u964d\u4f4eLLM\u6027\u80fd/Long contexts introduce irrelevant info, degrading LLM performance]\n    C --\x3e C1[\u81ea\u9002\u5e94\u63d0\u793a\u7b56\u7565\uff1a\u5206\u5757\u987a\u5e8f\u5904\u7406/Adaptive prompting: sequential chunk processing]\n    D --\x3e D1[\u6027\u80fd\u76f8\u5f53\uff0c\u4f7f\u7528\u66f4\u5c11token/Matches performance, uses fewer tokens]\n    D --\x3e D2[LLM\u5e38\u751f\u6210\u9519\u8bef\u7b54\u6848\u800c\u975e\u62d2\u7edd/LLM often generates wrong answers instead of declining]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Artificial Intelligence for All? Brazilian Teachers on Ethics, Equity, and the Everyday Challenges of AI in Education"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [AI in Education], [AI literacy, teacher perceptions, quantitative survey, ethics, infrastructure challenges]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bruno Florentino, Camila Sestito, Wellington Cruz, Andr\xe9 de Carvalho, Robson Bonidia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of S\xe3o Paulo, Federal University of Technology-Paran\xe1 (UTFPR), Instituto Significare"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23834",children:"https://arxiv.org/pdf/2512.23834"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides empirical data on the AI literacy levels and application interests of Brazilian K-12 teachers, revealing a high interest despite low knowledge. 2. Identifies key structural barriers (lack of training, technical support, and infrastructure) to AI adoption in Brazilian public education. 3. Highlights the critical importance teachers place on discussing ethics, digital citizenship, and responsible AI use within the pedagogical context."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9fd8e32651f0740b552d9443daf7c424819558f55a942221ff741ca45c296c9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9fd8e32651f0740b552d9443daf7c424819558f55a942221ff741ca45c296c9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study quantitatively analyzes Brazilian K-12 teachers' perceptions of AI in education through a survey of 346 educators. The results show strong teacher interest in using AI for pedagogical tasks despite limited knowledge, while identifying significant structural challenges and emphasizing the need for ethical discussions. The study concludes that effective AI integration in Brazil requires integrated public policies, teacher training, and equitable access to technology."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root(Artificial Intelligence for All? Brazilian Teachers on Ethics, Equity, and the Everyday Challenges of AI in Education) --\x3e Problem(\u6838\u5fc3\u95ee\u9898/Problem)\n    Root --\x3e Method(\u4e3b\u8981\u65b9\u6cd5/Method)\n    Root --\x3e Results(\u5173\u952e\u7ed3\u679c/Results)\n    Problem --\x3e P1(\u5df4\u897f\u6559\u5e08\u5bf9AI\u7684\u8ba4\u77e5\u4e0e\u6001\u5ea6/Brazilian Teachers' Perceptions and Attitudes towards AI)\n    Problem --\x3e P2(AI\u5728\u6559\u80b2\u4e2d\u7684\u4f26\u7406\u4e0e\u516c\u5e73\u6311\u6218/Ethical and Equity Challenges of AI in Education)\n    Method --\x3e M1(\u5b9a\u91cf\u95ee\u5377\u8c03\u67e5/Quantitative Questionnaire Survey)\n    M1 --\x3e M1_1(346\u540d\u5df4\u897fK-12\u6559\u5e08/346 Brazilian K-12 Teachers)\n    Results --\x3e R1(\u9ad8\u5174\u8da3\u4f46\u77e5\u8bc6\u6709\u9650/High Interest but Limited Knowledge)\n    Results --\x3e R2(\u5173\u6ce8\u4f26\u7406\u4e0e\u7ed3\u6784\u6311\u6218/Concerns on Ethics and Structural Challenges)\n    Results --\x3e R3(\u9700\u8981\u653f\u7b56\u4e0e\u57f9\u8bad\u652f\u6301/Need for Policy and Training Support)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [Human-AI Collaboration], [AI Agent Evaluation, Behavioral Taxonomy, Context-Adaptive Behavior Framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tao Dong, Harini Sampath, Ja Young Lee, Sherry Y. Shi, Andrew Macvean"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google LLC"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23844",children:"https://arxiv.org/pdf/2512.23844"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A foundational taxonomy of desirable AI agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. 2. The Context-Adaptive Behavior (CAB) Framework, which models how behavioral expectations shift based on context. 3. An empirical derivation of two key axes (Time Horizon and Type of Work) that drive behavioral expectation shifts in the CAB Framework."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7ee9d0c9d0b72de4dc6af2921706818c987d2f7c644977698965be6b535d20c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7ee9d0c9d0b72de4dc6af2921706818c987d2f7c644977698965be6b535d20c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper argues that current AI evaluation benchmarks focus too narrowly on code correctness and fail to assess the collaborative behaviors needed for AI to be an effective partner in software engineering. To address this, the authors propose a taxonomy of desirable agent behaviors and a Context-Adaptive Behavior (CAB) Framework that models how these expectations change with context. These contributions provide a human-centered foundation for evaluating and designing collaborative AI agents."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering<br/>\u4ece\u6b63\u786e\u6027\u5230\u534f\u4f5c\uff1a\u8bc4\u4f30\u8f6f\u4ef6\u5de5\u7a0b\u4e2dAI\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u4eba\u672c\u6846\u67b6"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Current benchmarks fail to capture collaborative AI agent behavior.<br/>\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u8bc4\u4f30AI\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u884c\u4e3a\u3002"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>1. Taxonomy of agent behaviors.<br/>\u667a\u80fd\u4f53\u884c\u4e3a\u5206\u7c7b\u6cd5\u3002<br/>2. Context-Adaptive Behavior (CAB) Framework.<br/>\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u884c\u4e3a\u6846\u67b6\u3002"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Provides a human-centered foundation for evaluating collaborative AI agents.<br/>\u4e3a\u8bc4\u4f30\u534f\u4f5c\u578bAI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4eba\u672c\u57fa\u7840\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [language model evaluation], [epistemic robustness, semantic compression, adversarial fabrication, two-system cognitive model, comprehension integrity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rahul Baxi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher (affiliation inferred from email domain: alumni.cmu.edu, Carnegie Mellon University)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23850",children:"https://arxiv.org/pdf/2512.23850"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Drill-Down and Fabricate Test (DDFT), a novel protocol for measuring epistemic robustness in language models under stress from semantic compression and adversarial fabrication. 2. Proposes a two-system cognitive model (Semantic System and Epistemic Verifier) to explain and analyze LLM behavior. 3. Provides empirical evidence that epistemic robustness is orthogonal to model scale and architecture, identifying error detection as the critical bottleneck."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c853b521a9f8bb0173c42ffdb79e01c42db6066203b6aa0c5e838c2f6a78f18f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c853b521a9f8bb0173c42ffdb79e01c42db6066203b6aa0c5e838c2f6a78f18f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies a gap in current language model evaluations, which fail to measure how robustly models maintain factual knowledge under stress. It introduces the Drill-Down and Fabricate Test (DDFT) to measure epistemic robustness by applying semantic compression and adversarial fabrication. The key finding is that epistemic robustness is not predicted by model size or architecture but by a model's internal verification mechanisms, challenging assumptions about scaling and reliability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Drill-Down and Fabricate Test (DDFT)] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u8bc4\u4f30\u65e0\u6cd5\u8861\u91cf\u77e5\u8bc6\u9c81\u68d2\u6027/Current evaluations fail to measure knowledge robustness]\n    C --\x3e C1[DDFT\u534f\u8bae: \u8bed\u4e49\u538b\u7f29\u4e0e\u5bf9\u6297\u4f2a\u9020/DDFT Protocol: Semantic Compression & Adversarial Fabrication]\n    C --\x3e C2[\u53cc\u7cfb\u7edf\u8ba4\u77e5\u6a21\u578b/Two-System Cognitive Model]\n    D --\x3e D1[\u9c81\u68d2\u6027\u4e0e\u6a21\u578b\u89c4\u6a21/\u67b6\u6784\u65e0\u5173/Robustness orthogonal to model size/architecture]\n    D --\x3e D2[\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u662f\u5173\u952e\u74f6\u9888/Error detection is the critical bottleneck]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [IoT Security], [Economic Denial Security, Stackelberg Game, Cost Asymmetry, Computational Puzzles]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Samaresh Kumar Singh, Joyjit Roy"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IEEE (Inferred from author affiliations as IEEE members; specific institutional affiliation not provided in the excerpt)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23849",children:"https://arxiv.org/pdf/2512.23849"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed the Economic Denial Security (EDS) framework, a detection-independent defense that exploits the defender's environmental control to impose economic infeasibility on attackers., 2. Formally modeled EDS as a Stackelberg game, deriving optimal parameters and proving that the composition of its four mechanisms yields superlinear (2.1x) cost amplification., 3. Demonstrated practical efficacy with a lightweight (<12KB) implementation, validated on a 20-device IoT testbed and against IoT-23 malware, showing significant attack slowdown, cost asymmetry, and improved mitigation rates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53020dd5fb969c1980dd7f764afe5f97440c1ef68620bdcd3383e97bf39600fc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the failure of detection-based security in resource-constrained IoT/edge environments. It proposes Economic Denial Security (EDS), a framework that uses mechanisms like computational puzzles and bandwidth taxation to make attacks economically infeasible by amplifying attacker costs. The method is proven to be lightweight, effective in significantly slowing attacks and reducing success rates, and provides a detection-independent layer of defense."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u68c0\u6d4b\u5b89\u5168\u5728\u8d44\u6e90\u53d7\u9650\u7684IoT/\u8fb9\u7f18\u73af\u5883\u4e2d\u5931\u6548/Detection-based security fails in resource-constrained IoT/edge]\n    C --\x3e C1[\u7ecf\u6d4e\u62d2\u7edd\u5b89\u5168\u6846\u67b6 / Economic Denial Security (EDS) Framework]\n    C1 --\x3e C2[\u56db\u79cd\u673a\u5236\u7ec4\u5408 / Four Mechanism Composition]\n    C2 --\x3e C3[\u8ba1\u7b97\u8c1c\u9898 / Computational Puzzles]\n    C2 --\x3e C4[\u4ea4\u4e92\u71b5 / Interaction Entropy]\n    C2 --\x3e C5[\u65f6\u95f4\u62c9\u4f38 / Temporal Stretching]\n    C2 --\x3e C6[\u5e26\u5bbd\u5f81\u7a0e / Bandwidth Taxation]\n    C --\x3e C7[\u65af\u5854\u514b\u5c14\u4f2f\u683c\u535a\u5f08\u5efa\u6a21 / Stackelberg Game Modeling]\n    D --\x3e D1[32-560\u500d\u653b\u51fb\u51cf\u901f / 32-560x Attack Slowdown]\n    D --\x3e D2[85-520:1 \u6210\u672c\u4e0d\u5bf9\u79f0 / 85-520:1 Cost Asymmetry]\n    D --\x3e D3[\u5185\u5b58\u5360\u7528<12KB / <12KB Memory Footprint]\n    D --\x3e D4[94% \u6076\u610f\u8f6f\u4ef6\u7f13\u89e3 / 94% Malware Mitigation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [conversational ai], [mental health crisis, stages of change model, human-AI interaction, testimonial survey, expert interviews]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Leah Hope Ajmani, Arka Ghosh, Benjamin Kaveladze, Eugenia Kim, Keertana Namuduri, Theresa Nguyen, Ebele Okoli, Jessica Schleider, Denae Ford, Jina Suh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Minnesota, Northwestern University, Dartmouth College, Microsoft, Microsoft Research, Mental Health America"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23859",children:"https://arxiv.org/pdf/2512.23859"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides first-person experiential data on using conversational AI during mental health crises via a testimonial survey (n=53). 2. Contrasts user experiences with mental health expert perspectives (n=16) to highlight the essential role of human connection in crisis management. 3. Proposes a responsible design framework for AI crisis intervention, positioning AI as a bridge to human support using the stages of change model."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/557b0c2624da79d40758f334c7d781c4558951ee96a27d54b04a81b3f20ec2ea_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/557b0c2624da79d40758f334c7d781c4558951ee96a27d54b04a81b3f20ec2ea_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how people use conversational AI (e.g., ChatGPT) during mental health crises through a survey and expert interviews. It finds users turn to AI due to gaps in human support, but experts emphasize human connection is crucial. The study concludes that responsible AI should act as a bridge to human help, increasing preparedness for positive action and de-escalating crises."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Can conversational AI responsibly support mental health crises?)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Testimonial survey (n=53) & expert interviews (n=16))\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: AI fills gaps in human support; Human connection is essential; Design AI as a bridge to human help)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [Infini-attention, compressive memory, small language models (SLMs), long-context extrapolation, pretraining]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ruizhe Huang, Kexuan Zhang, Yihao Fang, Baifeng Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huawei Technologies Canada Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23862",children:"https://arxiv.org/pdf/2512.23862"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/RRaAy-H/nanotron-infini",children:"https://github.com/RRaAy-H/nanotron-infini"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Replaced standard attention in a 300M-parameter LLaMA model with Infini-attention to study compressive memory behavior under short-sequence pretraining. 2. Analyzed the training dynamics of SLMs with Infini-attention, revealing characteristics like loss fluctuations, gradient volatility, and early-layer memory concentration. 3. Demonstrated that Infini-attention improves long-context extrapolation over a baseline model, with supervised fine-tuning further boosting performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af598a1dcd8b2b6a3dec75fe7434942b519517dea235cfb006c3cf73881444fd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af598a1dcd8b2b6a3dec75fe7434942b519517dea235cfb006c3cf73881444fd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether the Infini-attention mechanism, which combines local attention with compressive memory, can enhance long-context capabilities in Small Language Models (SLMs) during small-scale pretraining. The authors empirically study a 300M-parameter LLaMA model equipped with Infini-attention and find it improves long-context retrieval accuracy over a baseline, despite some degradation over very long sequences. The conclusion is that architectural memory like Infini-attention is beneficial for achieving robust long-context performance in SLMs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Enhancing long-context extrapolation for Small Language Models (SLMs)]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Using Infini-attention (compressive memory + local attention) in small-scale pretraining]\n    D[\u5173\u952e\u7ed3\u679c/Results: Improves long-context retrieval; Identifies balance factor importance; Shows performance degradation over very long sequences but still outperforms baseline]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Lifelong Domain Adaptive 3D Human Pose Estimation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [human pose estimation], [lifelong domain adaptation, catastrophic forgetting, generative adversarial network, pose-aware knowledge, temporal-aware knowledge]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qucheng Peng, Hongfei Xue, Pu Wang, Chen Chen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Central Florida, University of North Carolina at Charlotte"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23860",children:"https://arxiv.org/pdf/2512.23860"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel lifelong domain adaptation task for 3D Human Pose Estimation, addressing the challenge of non-stationary target pose datasets. 2. Introduces an innovative GAN framework with 3D pose generators, a 2D pose discriminator, and a 3D pose estimator to mitigate domain shifts and align poses. 3. Constructs a novel 3D pose generator paradigm that integrates pose-aware, temporal-aware, and domain-aware knowledge to enhance adaptation and alleviate catastrophic forgetting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbe905e18ac9835b4aae0dbb155169c447150fbd0e28ac454c7cc8a56bb7251e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbe905e18ac9835b4aae0dbb155169c447150fbd0e28ac454c7cc8a56bb7251e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a lifelong domain adaptation framework for 3D human pose estimation to handle non-stationary target data distributions. The method uses a novel GAN-based framework with a knowledge-integrated 3D pose generator to adapt to new domains while preventing catastrophic forgetting of previous ones. Experiments show the approach achieves superior performance on diverse domain adaptive 3D HPE datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Lifelong Domain Adaptive 3D Human Pose Estimation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[3D HPE\u6cdb\u5316\u6311\u6218/3D HPE Generalization Challenge]\nB --\x3e B2[\u975e\u5e73\u7a33\u76ee\u6807\u57df/Non-stationary Target Domains]\nB --\x3e B3[\u707e\u96be\u6027\u9057\u5fd8/Catastrophic Forgetting]\nC --\x3e C1[\u7ec8\u8eab\u57df\u9002\u5e94\u4efb\u52a1/Lifelong DA Task]\nC --\x3e C2[GAN\u6846\u67b6/GAN Framework]\nC --\x3e C3[3D\u59ff\u6001\u751f\u6210\u5668/3D Pose Generator]\nC2 --\x3e C2a[3D\u59ff\u6001\u751f\u6210\u5668/3D Pose Generators]\nC2 --\x3e C2b[2D\u59ff\u6001\u5224\u522b\u5668/2D Pose Discriminator]\nC2 --\x3e C2c[3D\u59ff\u6001\u4f30\u8ba1\u5668/3D Pose Estimator]\nC3 --\x3e C3a[\u59ff\u6001\u611f\u77e5/Pose-aware]\nC3 --\x3e C3b[\u65f6\u5e8f\u611f\u77e5/Temporal-aware]\nC3 --\x3e C3c[\u57df\u611f\u77e5/Domain-aware]\nD --\x3e D1[\u7f13\u89e3\u57df\u504f\u79fb/Mitigates Domain Shifts]\nD --\x3e D2[\u5bf9\u9f50\u59ff\u6001/Aligns Poses]\nD --\x3e D3[\u5353\u8d8a\u6027\u80fd/Superior Performance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks], [universal adversarial perturbation, latent-space attack, audio-language models, encoder-level vulnerability, targeted attack]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Roee Ziv, Raz Lapid, Moshe Sipper"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ben Gurion University of the Negev, Deepkeep"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23881",children:"https://arxiv.org/pdf/2512.23881"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a universal targeted latent-space attack against audio-language models, focusing solely on the audio encoder. 2. Introduces an attack method that learns a single perturbation effective across different inputs and speakers, without needing access to the downstream language model. 3. Demonstrates high attack success rates with minimal perceptual distortion on a state-of-the-art model, revealing a critical new attack surface in multimodal systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aec73155c062c3c66b8e33c0e7892e17d374292349cfa71e3389850584cf8195_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aec73155c062c3c66b8e33c0e7892e17d374292349cfa71e3389850584cf8195_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies a security vulnerability in audio-language models where adversarial attacks can be launched by manipulating only the audio encoder's latent representations. The proposed method learns a universal perturbation that forces the model to generate attacker-specified text outputs, and experiments show it is highly effective and stealthy. This reveals a significant and previously underexplored attack surface at the encoder level of multimodal AI systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Breaking Audio Large Language Models by Attacking Only the Encoder<br>\u4ec5\u653b\u51fb\u7f16\u7801\u5668\u6765\u653b\u7834\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Audio-language models have new security vulnerabilities.<br>\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Universal targeted latent-space attack on the encoder.<br>\u9488\u5bf9\u7f16\u7801\u5668\u7684\u901a\u7528\u76ee\u6807\u6f5c\u7a7a\u95f4\u653b\u51fb"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>High attack success with minimal distortion.<br>\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u6700\u5c0f\u611f\u77e5\u5931\u771f"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [self-evolving agent, skill acquisition, autonomous development, knowledge graph, scientific research agent]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xu Huang, Junwu Chen, Yuxing Fei, Zhuohan Li, Philippe Schwaller, Gerbrand Ceder"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of California, Berkeley; Lawrence Berkeley National Laboratory; \xc9cole Polytechnique F\xe9d\xe9rale de Lausanne (EPFL)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23880",children:"https://arxiv.org/pdf/2512.23880"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces CASCADE, a self-evolving agentic framework that transitions from static "LLM + tool use" to dynamic "LLM + skill acquisition". 2. Proposes meta-skills for continuous learning (via web search/code extraction) and self-reflection (via introspection/knowledge graph exploration) to master complex external tools. 3. Demonstrates high effectiveness on scientific tasks (93.3% success rate on SciSkillBench) and real-world applications like computational analysis and autonomous lab experiments.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8104399440bdcb0943addb2985b2e27c755af9a6ab5a4f36894d7a82db9d0e00_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8104399440bdcb0943addb2985b2e27c755af9a6ab5a4f36894d7a82db9d0e00_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of current LLM agents that rely on predefined or brittle tools, which hinders their adaptability in complex scientific tasks. It proposes CASCADE, a self-evolving framework that enables agents to autonomously acquire and codify skills through meta-skills like continuous learning and self-reflection. The method achieves a high success rate on a materials science and chemistry benchmark and shows promise for scalable AI-assisted scientific research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CASCADE: Cumulative Agentic Skill Creation<br>\u7d2f\u79ef\u667a\u80fd\u4f53\u6280\u80fd\u521b\u9020] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM agents depend on predefined/brittle tools<br>LLM\u667a\u80fd\u4f53\u4f9d\u8d56\u9884\u5b9a\u4e49/\u8106\u5f31\u5de5\u5177]\n    B --\x3e B2[Constrained capability for complex scientific tasks<br>\u5904\u7406\u590d\u6742\u79d1\u5b66\u4efb\u52a1\u80fd\u529b\u53d7\u9650]\n    C --\x3e C1[Self-evolving agentic framework<br>\u81ea\u8fdb\u5316\u667a\u80fd\u4f53\u6846\u67b6]\n    C --\x3e C2[Meta-skills: Continuous Learning & Self-Reflection<br>\u5143\u6280\u80fd\uff1a\u6301\u7eed\u5b66\u4e60\u4e0e\u81ea\u6211\u53cd\u601d]\n    C --\x3e C3[Transition: LLM+Tool Use \u2192 LLM+Skill Acquisition<br>\u8f6c\u53d8\uff1a\u4ece\u5de5\u5177\u4f7f\u7528\u5230\u6280\u80fd\u83b7\u53d6]\n    D --\x3e D1[93.3% success rate on SciSkillBench (116 tasks)<br>\u5728SciSkillBench\u4e0a\u6210\u529f\u738793.3%]\n    D --\x3e D2[Real-world applications demonstrated<br>\u6f14\u793a\u4e86\u5b9e\u9645\u5e94\u7528]\n    D --\x3e D3[Enables scalable AI-assisted research<br>\u5b9e\u73b0\u53ef\u6269\u5c55\u7684AI\u8f85\u52a9\u7814\u7a76]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] How Large Language Models Systematically Misrepresent American Climate Opinions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [large language model evaluation], [large language models, public opinion simulation, intersectionality, bias evaluation, climate policy]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sola Kim, Jieshu Wang, Marco A. Janssen, John M. Anderies"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Arizona State University, Stony Brook University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23889",children:"https://arxiv.org/pdf/2512.23889"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Conducted the first comparative study of LLM-generated public opinion against real human survey responses across intersecting demographic identities (race and gender). 2. Identified a systematic "compression" bias in LLMs, where they flatten the diversity of climate opinions by overestimating concern in less-concerned groups and underestimating it in more-concerned groups. 3. Revealed that this bias is intersectional, showing that LLMs apply uniform gender assumptions that fail for specific racial groups (e.g., misrepresenting gender patterns among Black Americans), a flaw potentially invisible to standard audits.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c0e5dfdc0fba7038277e876cd0c81062b3c5735782d5df732873aec991a84b3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c0e5dfdc0fba7038277e876cd0c81062b3c5735782d5df732873aec991a84b3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how six large language models (LLMs) represent U.S. climate opinions by prompting them with profiles from a real national survey and comparing their generated responses to actual human answers. The study finds that LLMs systematically compress opinion diversity and misrepresent intersectional patterns, particularly for Black Americans, which could undermine equitable policy-making."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["How Large Language Models Systematically Misrepresent American Climate Opinions<br>\u8bba\u6587\u6807\u9898"] --\x3e B["Problem: LLMs used for public opinion analysis may misrepresent diverse, intersectional views.<br>\u6838\u5fc3\u95ee\u9898\uff1a\u7528\u4e8e\u516c\u4f17\u610f\u89c1\u5206\u6790\u7684LLM\u53ef\u80fd\u6b6a\u66f2\u591a\u6837\u5316\u7684\u4ea4\u53c9\u6027\u89c2\u70b9\u3002"]\n    A --\x3e C["Method: Prompt 6 LLMs with real survey respondent profiles and compare outputs to human answers.<br>\u4e3b\u8981\u65b9\u6cd5\uff1a\u7528\u771f\u5b9e\u8c03\u67e5\u53d7\u8bbf\u8005\u6863\u6848\u63d0\u793a6\u4e2aLLM\uff0c\u5e76\u5c06\u8f93\u51fa\u4e0e\u4eba\u7c7b\u7b54\u6848\u6bd4\u8f83\u3002"]\n    A --\x3e D["Results: LLMs compress opinion diversity and misapply gender assumptions across racial groups.<br>\u5173\u952e\u7ed3\u679c\uff1aLLM\u538b\u7f29\u4e86\u610f\u89c1\u591a\u6837\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u79cd\u65cf\u7fa4\u4f53\u4e2d\u8bef\u7528\u4e86\u6027\u522b\u5047\u8bbe\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [time series forecasting], [Transformer, Mamba, Knowledge Distillation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tin Hoang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Surrey"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23898",children:"https://arxiv.org/pdf/2512.23898"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," github.com/Tin-Hoang/solar-timeseries-forecasting"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a comprehensive benchmark of ten deep learning architectures for short-term solar irradiance forecasting, identifying the Transformer as the best-performing model. 2. Used SHAP analysis to reveal and contrast the distinct temporal reasoning patterns of different architectures (e.g., Transformer's recency bias vs. Mamba's periodic dependency). 3. Demonstrated that Knowledge Distillation can effectively compress the high-performance Transformer model, reducing its size by 23.5% while improving accuracy for edge deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8685dbd2386bb45fd799c168962048f6a243c0b8c836a5be5978ff64d0c2e184_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8685dbd2386bb45fd799c168962048f6a243c0b8c836a5be5978ff64d0c2e184_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper benchmarks ten deep learning models for 1-hour ahead solar irradiance forecasting in Ho Chi Minh City. The Transformer model achieved the highest accuracy, and the study used explainable AI to analyze model behavior and successfully compressed the model via Knowledge Distillation for efficient edge deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898 / Paper Title: Efficient Deep Learning for Short-Term Solar Irradiance Forecasting] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem: \u9884\u6d4b\u5168\u7403\u6c34\u5e73\u8f90\u7167\u5ea6(GHI)\u4ee5\u7f13\u89e3\u592a\u9633\u80fd\u6ce2\u52a8 / Forecasting GHI to mitigate solar energy variability]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method: \u5bf9\u5341\u79cd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u53ef\u89e3\u91ca\u6027\u5206\u6790 / Benchmarking 10 DL architectures with explainability analysis]\n    D[\u5173\u952e\u7ed3\u679c / Results: Transformer\u6027\u80fd\u6700\u4f18\uff1b\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29 / Transformer best; Knowledge Distillation enables efficient compression]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Interactive Machine Learning: From Theory to Scale"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [interactive machine learning], [active learning, contextual bandits, model selection, sequential decision making, partial feedback]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yinglun Zhu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Wisconsin\u2013Madison"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23924",children:"https://arxiv.org/pdf/2512.23924"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed computationally efficient active learning algorithms that achieve exponential label savings without requiring low-noise assumptions., 2. Introduced the first efficient, general-purpose contextual bandit algorithms whose performance guarantees are independent of the action space size., 3. Provided the first tight characterizations of the fundamental cost of model selection in sequential decision-making settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d3c8fc2dd2145126e7321fa8de265f0c2652dbd2dc7df8c387585634498e335_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d3c8fc2dd2145126e7321fa8de265f0c2652dbd2dc7df8c387585634498e335_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This dissertation addresses the high cost of data labeling and trial-and-error in machine learning by developing new algorithms for interactive learning. It proposes statistically optimal and computationally efficient methods for active learning, contextual bandits with large action spaces, and model selection under partial feedback. The work advances the theoretical foundations of interactive learning and provides guidance for its deployment in large-scale, real-world applications."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Interactive Machine Learning: From Theory to Scale<br>\u4ea4\u4e92\u5f0f\u673a\u5668\u5b66\u4e60\uff1a\u4ece\u7406\u8bba\u5230\u89c4\u6a21")\n    Root --\x3e Problem("Problem: High cost of labeled data & trial-and-error in ML<br>\u6838\u5fc3\u95ee\u9898\uff1a\u673a\u5668\u5b66\u4e60\u4e2d\u6807\u6ce8\u6570\u636e\u548c\u8bd5\u9519\u7684\u9ad8\u6210\u672c")\n    Root --\x3e Method("Method: Develop algorithms for interactive learning<br>\u4e3b\u8981\u65b9\u6cd5\uff1a\u5f00\u53d1\u4ea4\u4e92\u5f0f\u5b66\u4e60\u7b97\u6cd5")\n    Root --\x3e Results("Results: Statistically optimal & computationally efficient algorithms<br>\u5173\u952e\u7ed3\u679c\uff1a\u7edf\u8ba1\u6700\u4f18\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5")\n    Problem --\x3e P1("Active learning with noisy data<br>\u542b\u566a\u58f0\u6570\u636e\u7684\u4e3b\u52a8\u5b66\u4e60")\n    Problem --\x3e P2("Sequential decision making with large action spaces<br>\u5927\u52a8\u4f5c\u7a7a\u95f4\u7684\u5e8f\u5217\u51b3\u7b56")\n    Problem --\x3e P3("Model selection under partial feedback<br>\u90e8\u5206\u53cd\u9988\u4e0b\u7684\u6a21\u578b\u9009\u62e9")\n    Method --\x3e M1("New algorithmic principles<br>\u65b0\u7b97\u6cd5\u539f\u7406")\n    Method --\x3e M2("Establish fundamental limits<br>\u5efa\u7acb\u57fa\u672c\u6781\u9650")\n    Results --\x3e R1("Exponential label savings in active learning<br>\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7684\u6307\u6570\u7ea7\u6807\u7b7e\u8282\u7701")\n    Results --\x3e R2("Contextual bandit guarantees independent of action space size<br>\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u7684\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u4fdd\u8bc1")\n    Results --\x3e R3("Tight characterization of model selection cost<br>\u6a21\u578b\u9009\u62e9\u6210\u672c\u7684\u7d27\u81f4\u523b\u753b")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [neuro-symbolic ai], [Answer Set Programming, Large Language Models, Explainable AI, Knowledge Base Construction, Disease Diagnosis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ioanna Gemou, Evangelos Lamprou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Patras"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23932",children:"https://arxiv.org/pdf/2512.23932"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes McCoy, a novel framework that integrates LLMs and Answer Set Programming for automated disease diagnosis. 2. Automates the labor-intensive construction of medical knowledge bases by using an LLM to translate medical literature into ASP code. 3. Delivers an interpretable and robust diagnostic system that provides logical justifications for its predictions, achieving high accuracy on preliminary tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9000f6d3b0daa6fb6bc9ea6b6b2f1ca56befb92d47f3f4f67b25d12dc6ca996_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e9000f6d3b0daa6fb6bc9ea6b6b2f1ca56befb92d47f3f4f67b25d12dc6ca996_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to automate the creation of diagnostic knowledge bases and perform explainable disease diagnosis. The LLM translates medical literature into ASP rules, which are then combined with patient data and solved to produce a diagnosis with logical justifications. Preliminary results show the framework achieves high predictive accuracy on small-scale tasks while providing transparency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming<br>\u53ef\u89e3\u91ca\u75be\u75c5\u8bca\u65ad\u7684\u6982\u5ff5\u9a8c\u8bc1\uff1a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u56de\u7b54\u96c6\u7f16\u7a0b"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Symbolic AI adoption limited by manual knowledge base construction.<br>\u7b26\u53f7AI\u56e0\u9700\u624b\u52a8\u6784\u5efa\u77e5\u8bc6\u5e93\u800c\u5e94\u7528\u53d7\u9650\u3002"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Combine LLM (translates literature) with ASP (logical reasoning).<br>\u7ed3\u5408LLM\uff08\u7ffb\u8bd1\u6587\u732e\uff09\u4e0eASP\uff08\u903b\u8f91\u63a8\u7406\uff09\u3002"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>High accuracy, interpretable diagnosis framework.<br>\u9ad8\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u6846\u67b6\u3002"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [agentic AI, recommendation system, KYC (Know Your Customer), nDCG, multi-stage architecture]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junjie H. Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hechu Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23961",children:"https://arxiv.org/pdf/2512.23961"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel agentic AI-based recommendation system specifically designed for integrating KYC (Know Your Customer) processes. 2. Conducts a comparative performance evaluation across five distinct content verticals (Ad, News, Gossip, Sharing, Tech) using the nDCG metric. 3. Synthesizes experimental data with industry benchmarks to provide engineering insights for building large-scale agentic recommendation systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e7c4d7572522a69f7c0db05b6553014273403aa44576ea9c0de823750c5368_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e7c4d7572522a69f7c0db05b6553014273403aa44576ea9c0de823750c5368_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new recommendation system that uses agentic AI to incorporate KYC (Know Your Customer) information. It evaluates the system's performance across five different content types and compares it against standard benchmarks. The study concludes by providing practical insights for engineering large-scale agentic recommendation systems based on the experimental results."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Transition from passive ranking to agentic AI in RecSys]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic AI for KYC, evaluated across 5 content verticals using nDCG@k]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Performance comparison of 4 KYC usage groups, insights for large-scale engineering]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Physics-informed Graph Neural Networks for Operational Flood Modeling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [graph neural networks], [physics-informed neural networks, graph neural networks, flood modeling, curriculum learning, message-passing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Carlo Malapad Acosta, Herath Mudiyanselage Viraj Vidura Herath, Jia Yu Lim, Abhishek Saha, Sanka Rasnayaka, Lucy Marshall"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Singapore, The University of Sydney, Delft University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23964",children:"https://arxiv.org/pdf/2512.23964"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/acostacos/dual_flood_gnn",children:"https://github.com/acostacos/dual_flood_gnn"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DUALFloodGNN, a novel GNN architecture that embeds physical constraints at both global and local scales through explicit loss terms. 2. Introduces a model that jointly predicts water volume at nodes and flow along edges using a shared message-passing framework. 3. Enhances autoregressive inference performance via multi-step loss training with dynamic curriculum learning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6bbddb2010c8550ce3ea4a09f24c04abc0993a7ee2a722f960fc0852c4f049_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6bbddb2010c8550ce3ea4a09f24c04abc0993a7ee2a722f960fc0852c4f049_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high computational cost of physics-based flood models by proposing DUALFloodGNN, a physics-informed graph neural network architecture. The model incorporates physical constraints into its loss function and uses a multi-step training strategy with curriculum learning. It achieves improved prediction accuracy for hydrologic variables while maintaining high computational efficiency compared to existing GNN models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Physics-informed Graph Neural Networks for Operational Flood Modeling] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: High computational cost of physics-based flood models limits operational use]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: DUALFloodGNN embeds physical constraints via loss terms and uses multi-step training with curriculum learning]\n    D[\u5173\u952e\u7ed3\u679c/Results: Achieves improved accuracy and maintains high computational efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [hypergraph memory, multi-step reasoning, global sense-making, long-context modeling, retrieval-augmented generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chulun Zhou, Chunkang Zhang, Guoxin Yu, Fandong Meng, Jie Zhou, Wai Lam, Mo Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Chinese University of Hong Kong, WeChat AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23959",children:"https://arxiv.org/pdf/2512.23959"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Encyclomen/HGMem",children:"https://github.com/Encyclomen/HGMem"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HGMem, a novel hypergraph-based memory mechanism that models memory as a dynamic structure with higher-order interactions, moving beyond passive storage. 2. Addresses the limitation of existing multi-step RAG memory in capturing complex relational structures and providing strong guidance for subsequent reasoning steps. 3. Demonstrates through extensive experiments that the method consistently improves multi-step RAG performance and substantially outperforms strong baselines on global sense-making tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259f66b1c3afc451216d5a69cb56a5a72ee4244c5fa02941603de2fbd4afc261_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259f66b1c3afc451216d5a69cb56a5a72ee4244c5fa02941603de2fbd4afc261_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of static, passive memory in multi-step RAG systems, which leads to fragmented reasoning in long-context tasks. It proposes HGMem, a dynamic hypergraph-based memory mechanism that captures high-order correlations among facts to form an integrated knowledge structure for stronger reasoning guidance. The method is shown to consistently and substantially outperform baseline systems across diverse global sense-making tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Improving Multi-step RAG with Hypergraph-based Memory<br>\u6539\u8fdb\u591a\u6b65RAG\u7684\u8d85\u56fe\u8bb0\u5fc6] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u8bb0\u5fc6\u6a21\u5757\u662f\u88ab\u52a8\u7684\u9759\u6001\u5b58\u50a8<br>Existing memory is passive static storage]\n    B1 --\x3e B2[\u5ffd\u7565\u4e86\u9ad8\u9636\u5173\u8054\uff0c\u5bfc\u81f4\u788e\u7247\u5316\u63a8\u7406<br>Ignores high-order correlations, causing fragmented reasoning]\n    C --\x3e C1[\u63d0\u51fa\u8d85\u56fe\u8bb0\u5fc6\u673a\u5236 HGMem<br>Propose hypergraph memory mechanism HGMem]\n    C1 --\x3e C2[\u5c06\u8bb0\u5fc6\u8868\u793a\u4e3a\u52a8\u6001\u8d85\u56fe<br>Represent memory as a dynamic hypergraph]\n    C2 --\x3e C3[\u8d85\u8fb9\u5f62\u6210\u9ad8\u9636\u4ea4\u4e92\uff0c\u6784\u5efa\u96c6\u6210\u77e5\u8bc6\u7ed3\u6784<br>Hyperedges form high-order interactions, building integrated knowledge]\n    D --\x3e D1[\u5728\u591a\u6b65RAG\u4e0a\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb<br>Achieves consistent improvement on multi-step RAG]\n    D1 --\x3e D2[\u5728\u5168\u5c40\u7406\u89e3\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf<br>Substantially outperforms baselines on global sense-making tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Efficient Context Scaling with LongCat ZigZag Attention"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [sparse attention, long-context, mid-training, ZigZag Attention]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chen Zhang, Yang Bai, Jiahuan Li, Anchun Gui, Keheng Wang, Feifan Liu, Guanyu Wu, Yuwei Jiang, Defei Bu, Li Wei, Haihang Jing, Hongyin Tang, Xin Chen, Xiangzhou Huang, Fengcun Li, Rongxiang Weng, Yulei Qian, Yifan Lu, Yerui Sun, Jingang Wang, Yuchen Xie, Xunliang Cai"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Meituan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23966",children:"https://arxiv.org/pdf/2512.23966"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LongCat ZigZag Attention (LoZA), a sparse attention scheme to convert full-attention models into sparse versions with limited compute. 2. Demonstrates LoZA's effectiveness for speed-up in both prefill-intensive (e.g., RAG) and decode-intensive (e.g., tool use) long-context scenarios. 3. Applies LoZA to create LongCat-Flash-Exp, a foundation model capable of efficiently processing up to 1 million tokens."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46b353da1c2cbb89962a2e909144fbcc8c92d821f35157049a111e1855b4242c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46b353da1c2cbb89962a2e909144fbcc8c92d821f35157049a111e1855b4242c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces LongCat ZigZag Attention (LoZA), a sparse attention method designed to efficiently transform standard full-attention language models into sparse models suitable for long-context tasks. This approach enables significant speed improvements for both prefill and decoding phases. The resulting model, LongCat-Flash-Exp, can process up to 1 million tokens, facilitating efficient long-term reasoning and agentic capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Efficient Context Scaling with LongCat ZigZag Attention] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u5168\u6ce8\u610f\u529b\u8ba1\u7b97\u5f00\u9500\u5927/High computational cost of full attention in long-context scenarios]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faLoZA\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6848/Propose LoZA sparse attention scheme]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5b9e\u73b0\u663e\u8457\u52a0\u901f\uff0c\u652f\u6301\u767e\u4e07token\u9ad8\u6548\u5904\u7406/Achieve significant speed-up, enable efficient processing of 1M tokens]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [streaming machine learning, directed acyclic graph (DAG), point-in-time idempotency, temporal tiling, causality enforcement]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Giacinto Paolo Saggese, Paul Smith"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Not explicitly stated. Could be inferred from author names and arXiv submission, but no clear affiliation is provided in the given content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23977",children:"https://arxiv.org/pdf/2512.23977"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A unified DAG-based execution model with point-in-time idempotency, ensuring identical model behavior in batch and streaming modes without code changes. 2. Automatic causality enforcement by tracking knowledge time across transformations, eliminating future-peeking bugs. 3. Flexible temporal and feature dimension tiling, allowing models to operate at different frequencies and memory profiles via configuration alone."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4105add65c1e7a9960d7e21b6bda977778c41365cfff18c04d16a1af3773b5c4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4105add65c1e7a9960d7e21b6bda977778c41365cfff18c04d16a1af3773b5c4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents DataFlow, a framework for building high-performance ML systems on streaming time-series data. It uses a DAG-based model with point-in-time idempotency to bridge the gap between batch prototyping and streaming production, ensuring causality and reproducibility. The framework demonstrates effectiveness in domains like financial trading and IoT analytics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Gap between batch ML prototypes and streaming production systems causes causality violations and poor reproducibility."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Unified DAG execution model with point-in-time idempotency and automatic causality tracking."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Enables identical batch/stream execution, flexible tiling, and effective deployment in financial, IoT, and fraud detection domains."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A Community-Aware Framework for Influence Maximization with Explicit Accounting for Inter-Community Influence"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [social network analysis], [influence maximization, community structure, inter-community diffusion, progressive budgeting, community-based diffusion degree]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Eliot W. Robson, Abhishek K. Umrawal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Narmi, University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23973",children:"https://arxiv.org/pdf/2512.23973"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Community-IM++, a scalable framework that explicitly models cross-community influence, overcoming a key limitation of prior community-based methods. 2. Introduces a principled heuristic based on community-based diffusion degree (CDD) and a progressive budgeting strategy to prioritize bridging nodes and allocate seeds adaptively. 3. Demonstrates through experiments on large real-world networks that the method achieves near-greedy influence spread with up to 100x speedup, outperforming baseline heuristics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b25bc24c3cf4c404605618e8019a2659fc31bfeb9d29ad19d3af7a7ca5cc7a4c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b25bc24c3cf4c404605618e8019a2659fc31bfeb9d29ad19d3af7a7ca5cc7a4c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the Influence Maximization problem in social networks, where existing community-based methods often overlook inter-community influence. The authors propose Community-IM++, a scalable framework that explicitly models cross-community diffusion using a new heuristic (CDD) and a progressive budgeting strategy. The method achieves near-optimal performance with significantly lower runtime, making it practical for large-scale applications like viral marketing and public health campaigns."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("A Community-Aware Framework for Influence Maximization<br>\u5f71\u54cd\u529b\u6700\u5927\u5316\u793e\u533a\u611f\u77e5\u6846\u67b6") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u793e\u533a\u65b9\u6cd5\u5ffd\u7565\u793e\u533a\u95f4\u5f71\u54cd<br>Community methods ignore inter-community influence")\n    Method --\x3e M1("\u63d0\u51faCommunity-IM++\u6846\u67b6<br>Propose Community-IM++ framework")\n    M1 --\x3e M2("\u4f7f\u7528\u793e\u533a\u6269\u6563\u5ea6(CDD)\u542f\u53d1\u5f0f<br>Use Community-based Diffusion Degree (CDD) heuristic")\n    M1 --\x3e M3("\u6e10\u8fdb\u9884\u7b97\u4e0e\u60f0\u6027\u8bc4\u4f30<br>Progressive budgeting & lazy evaluation")\n    Results --\x3e R1("\u63a5\u8fd1\u8d2a\u5a6a\u7b97\u6cd5\u7684\u4f20\u64ad\u8303\u56f4<br>Near-greedy influence spread")\n    Results --\x3e R2("\u8fd0\u884c\u65f6\u95f4\u964d\u4f4e\u9ad8\u8fbe100\u500d<br>Up to 100x lower runtime")\n    Results --\x3e R3("\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5<br>Outperforms baseline methods")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [AI-assisted Software Engineering], [vibe coding, agentic coding, LLM-based coding, code review, curricular shift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hung-Fu Chang, MohammadShokrolah Shirazi, Lizhou Cao, Supannika Koolmanojwong Mobasser"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Indianapolis, Marian University, University of Maryland Eastern Shore, The Boehm Center for Systems and Software Engineering"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23982",children:"https://arxiv.org/pdf/2512.23982"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides an industry-grounded investigation of LLM coding practices (vibe, AI-assisted, agentic coding) and their impact on professional workflows, based on qualitative analysis of practitioner reflections. 2. Identifies key risks and concerns associated with AI-based coding, including shifts in development bottlenecks to code review, code quality issues, security vulnerabilities, and skill erosion. 3. Proposes implications and guidance for computer science and software engineering education, advocating for curricular shifts toward problem-solving, architectural thinking, and early integration of LLM tools."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d32f497e3b36008891d37440a49e031ae3f31d7dcba8585c229352e091d83a3a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d32f497e3b36008891d37440a49e031ae3f31d7dcba8585c229352e091d83a3a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how large language models (LLMs) are used in professional software development by qualitatively analyzing 57 YouTube videos from practitioners. The study identifies new coding paradigms, productivity gains, and associated risks like quality and security concerns. It concludes by discussing the need for educational reforms in computer science to align with these evolving industrial practices."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Coding With AI: From Industrial Practices to Future Education") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u5de5\u4e1a\u5b9e\u8df5\u4e2dLLM\u7f16\u7801\u5de5\u5177\u7684\u4f7f\u7528\u4e0e\u98ce\u9669\u672a\u5145\u5206\u63a2\u7d22/LLM coding use & risks in industry underexplored")\n    Method --\x3e M1("\u5bf957\u4e2aYouTube\u89c6\u9891\u8fdb\u884c\u5b9a\u6027\u5206\u6790/Qualitative analysis of 57 YouTube videos")\n    Results --\x3e R1("\u5b9a\u4e49AI\u7f16\u7801\u5b9e\u8df5\uff0c\u53d1\u73b0\u751f\u4ea7\u529b\u63d0\u5347\u4e0e\u98ce\u9669/Defines AI coding practices, finds productivity gains & risks")\n    Results --\x3e R2("\u63d0\u51fa\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u7684\u8bfe\u7a0b\u6539\u9769\u5efa\u8bae/Proposes curricular shifts for CS education")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [malware detection], [Model-Agnostic Meta-Learning (MAML), Chunk-wise Feature Selection (CFSGB), Gradient Boosting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ajvad Haneef K, Karan Kuwar Singh, Madhu Kumar S D"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National Institute of Technology Calicut"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23987",children:"https://arxiv.org/pdf/2512.23987"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed MeLeMaD, a novel malware detection framework leveraging Model-Agnostic Meta-Learning (MAML) for adaptability and generalization. 2. Introduced a novel Chunk-wise Feature Selection based on Gradient Boosting (CFSGB) technique to handle large-scale, high-dimensional datasets efficiently. 3. Demonstrated state-of-the-art performance on benchmark datasets (CIC-AndMal2020, BODMAS) and a custom dataset (EMBOD), achieving high accuracy and robustness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1509044c1c0bdfbb4a075c799e3c0cafd035f0b7c579548b445cf04caee2975d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1509044c1c0bdfbb4a075c799e3c0cafd035f0b7c579548b445cf04caee2975d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes MeLeMaD, a novel malware detection framework that combines a new chunk-wise feature selection method (CFSGB) with meta-learning (MAML) to improve adaptability and efficiency on large-scale datasets. It achieves high accuracy on benchmark and custom datasets, outperforming existing state-of-the-art approaches and demonstrating robustness against evolving threats."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MeLeMaD: Adaptive Malware Detection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Malware detection needs robustness & adaptability]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Meta-Learning (MAML) + Chunk-wise Feature Selection (CFSGB)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: High accuracy on benchmarks (98.04%, 99.97%) & custom dataset]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [mechanistic interpretability], [sparse auto-encoder, reasoning vectors, chain-of-thought]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhenyu Zhang, Shujian Zhang, John Lambert, Wenxuan Zhou, Zhangyang Wang, Mingqing Chen, Andrew Hard, Rajiv Mathews, Lun Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google DeepMind, The University of Texas at Austin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23988",children:"https://arxiv.org/pdf/2512.23988"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes RISE, an unsupervised framework using sparse auto-encoders (SAEs) to discover "reasoning vectors" that encode distinct reasoning behaviors from step-level LLM activations. 2. Demonstrates that these discovered vectors correspond to interpretable behaviors (e.g., reflection, backtracking) and can be used for targeted intervention to controllably steer the reasoning process without retraining. 3. Shows SAEs can uncover novel, human-undefined reasoning behaviors and structural properties, such as controlling response confidence, highlighting the potential of unsupervised latent discovery.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6bf740af692f8a7498e3cb43c54db55a7bd4f6005d4c48bc0e225978738bf9a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6bf740af692f8a7498e3cb43c54db55a7bd4f6005d4c48bc0e225978738bf9a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper addresses the challenge of interpreting the internal reasoning process of large language models (LLMs). It proposes RISE, an unsupervised framework that uses sparse auto-encoders to discover disentangled "reasoning vectors" from chain-of-thought activations. The method enables the identification, visualization, and controllable intervention of specific reasoning behaviors, revealing novel insights beyond supervised analysis.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>LLM\u63a8\u7406\u5185\u90e8\u673a\u5236\u4e0d\u660e\u786e<br>Supervised methods are limited"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>RISE\u6846\u67b6: \u65e0\u76d1\u7763\u7a00\u758f\u81ea\u7f16\u7801\u5668<br>Unsupervised SAEs on step-level activations"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>\u53d1\u73b0\u53ef\u89e3\u91ca\u63a8\u7406\u884c\u4e3a\u5411\u91cf<br>\u53ef\u63a7\u5e72\u9884\u63a8\u7406\u8f68\u8ff9<br>Discover novel behaviors"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark for Physically Grounded Text-to-Audio-Video Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [audio-visual generation], [text-to-audio-video, physics-sensitivity, benchmark, audio-physics grounding, contrastive physical response score]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tianxin Xie, Wentao Lei, Guanjie Huang, Pengfei Zhang, Kai Jiang, Chunhui Zhang, Fengji Ma, Haoyu He, Han Zhang, Jiangshan He, Jinting Wang, Linghan Fang, Lufei Gao, Orkesh Ablet, Peihua Zhang, Ruolin Hu, Shengyu Li, Weilin Lin, Xiaoyang Feng, Xinyue Yang, Yan Rong, Yanyun Wang, Zihang Shao, Zelin Zhao, Chenxing Li, Shan Yang, Wenfu Wang, Meng Yu, Dong Yu, Li Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," HKUST(GZ), Tencent, Shanghai Jiao Tong University, Technical University of Munich"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23994",children:"https://arxiv.org/pdf/2512.23994"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://imxtx.github.io/PhyAVBench/",children:"https://imxtx.github.io/PhyAVBench/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces PhyAVBench, a novel benchmark for evaluating the audio physics-sensitivity of T2AV models., 2. Proposes the Audio-Physics Sensitivity Test (APST) paradigm using paired prompts with controlled physical variables., 3. Defines the Contrastive Physical Response Score (CPRS) to quantitatively measure a model's understanding of physical principles."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eec12bf437e946a08a88614c7454f1315e7f14f21f2ebe631265de8a77d352a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eec12bf437e946a08a88614c7454f1315e7f14f21f2ebe631265de8a77d352a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that current text-to-audio-video (T2AV) models lack physical plausibility in generated sounds. To address this, it introduces PhyAVBench, a challenging benchmark designed to systematically evaluate models' audio physics grounding through a novel Audio-Physics Sensitivity Test (APST). The authors argue that this benchmark will stimulate progress in generating physically consistent audio-visual content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709T2AV\u6a21\u578b\u65e0\u6cd5\u751f\u6210\u7269\u7406\u5408\u7406\u7684\u58f0\u97f3 / Existing T2AV models generate physically implausible sounds]\n    C --\x3e C1[\u63d0\u51faPhyAVBench\u57fa\u51c6\u4e0eAPST\u8bc4\u4f30\u8303\u5f0f / Propose PhyAVBench benchmark & APST evaluation paradigm]\n    C --\x3e C2[\u4f7f\u7528\u6210\u5bf9\u63d0\u793a\u63a7\u5236\u7269\u7406\u53d8\u91cf / Use paired prompts with controlled physical variables]\n    C --\x3e C3[\u5f15\u5165\u5bf9\u6bd4\u7269\u7406\u54cd\u5e94\u5206\u6570(CPRS) / Introduce Contrastive Physical Response Score (CPRS)]\n    D --\x3e D1[\u7cfb\u7edf\u6027\u8bc4\u4f30\u6a21\u578b\u5bf9\u58f0\u5b66\u7269\u7406\u7684\u7406\u89e3 / Systematically evaluate models' understanding of acoustic physics]\n    D --\x3e D2[\u63a8\u52a8\u7269\u7406\u57fa\u7840T2AV\u751f\u6210\u7684\u7814\u7a76 / Stimulate research in physically-grounded T2AV generation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [metaheuristics], [simulation optimization, tabu search, elite memory, noisy black-box, aspiration criterion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bulent Soykan, Sean Mondesire, Ghaith Rabadi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Central Florida"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24007",children:"https://arxiv.org/pdf/2512.24007"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," github.com/bulentsoykan/TESO"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TESO, a novel metaheuristic framework that integrates adaptive search with memory-based strategies for simulation optimization. 2. Introduces a dual-memory mechanism combining a short-term Tabu List for diversification and a long-term Elite Memory for intensification. 3. Demonstrates the framework's effectiveness and reliability on a queue optimization problem, showing improved performance over benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00ac2df6705adb84c43e6fe1380cb528473aee412ea23024864f40a91dfd7ec9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00ac2df6705adb84c43e6fe1380cb528473aee412ea23024864f40a91dfd7ec9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces TESO, a metaheuristic framework for noisy, expensive black-box simulation optimization. It combines a Tabu List and an Elite Memory with an aspiration criterion to balance exploration and exploitation. The method is validated on a queue optimization problem, showing improved performance and reliability compared to benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[TESO: Tabu-Enhanced Simulation Optimization] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Noisy, expensive, multimodal simulation optimization] --\x3e P1[\u6311\u6218/Challenges: Noisy evaluations, high cost, complex landscapes]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Memory-based metaheuristic framework] --\x3e M1[\u7ec4\u4ef6/Components: Tabu List, Elite Memory, Aspiration Criterion]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Validated on queue optimization] --\x3e R1[\u7ed3\u8bba/Conclusion: Improved performance & reliability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent systems, retrieval-augmented generation, persona-based agents, long-term memory, coordination protocols]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Gaurab Chhetri, Subasish Das, Tausif Islam Chowdhury"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Texas State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24008",children:"https://arxiv.org/pdf/2512.24008"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SPARK, a novel framework that uses coordinated, persona-based LLM agents for personalized search, moving beyond static user profiles. 2. Formalizes a persona space and introduces a Persona Coordinator to dynamically activate specialized agents based on query interpretation. 3. Facilitates inter-agent collaboration through structured protocols like shared memory and iterative debate, enabling emergent personalization from distributed behaviors."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522362a9d0a8ab25d8cf01e3f9989591d57b2f5595d731ca2b3bdd84da90a098_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522362a9d0a8ab25d8cf01e3f9989591d57b2f5595d731ca2b3bdd84da90a098_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes SPARK, a framework that uses coordinated, persona-based LLM agents to perform personalized search. It dynamically activates specialized agents for retrieval and uses structured communication for collaboration. The approach aims to model the fluid and complex nature of human information needs better than traditional static-profile systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    SPARK_Title[SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    SPARK_Title --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    SPARK_Title --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u9759\u6001\u7528\u6237\u753b\u50cf\u9650\u5236\u4e2a\u6027\u5316\u641c\u7d22/Static user profiles limit personalized search]\n    Problem --\x3e P2[\u5355\u4e00\u68c0\u7d22\u6d41\u7a0b\u96be\u4ee5\u6355\u6349\u590d\u6742\u9700\u6c42/Monolithic retrieval fails to capture complex needs]\n    Method --\x3e M1[\u5b9a\u4e49\u89d2\u8272\u5316\u667a\u80fd\u4f53\u7a7a\u95f4/Define persona-based agent space]\n    Method --\x3e M2[\u5f15\u5165\u667a\u80fd\u4f53\u534f\u8c03\u5668/Introduce Persona Coordinator]\n    Method --\x3e M3[\u667a\u80fd\u4f53\u534f\u4f5c\u4e0e\u77e5\u8bc6\u5171\u4eab/Agent collaboration & knowledge-sharing]\n    Results --\x3e R1[\u5b9e\u73b0\u6d8c\u73b0\u7684\u4e2a\u6027\u5316/Achieve emergent personalization]\n    Results --\x3e R2[\u4e3a\u4e0b\u4e00\u4ee3\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u89c1\u89e3/Provide insights for next-gen search systems]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [reasoning], [latent planning, implicit cognition, vector-quantized autoencoder, chain-of-thought]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sijia Chen, Di Niu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hong Kong University of Science and Technology (Guangzhou), University of Alberta"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24014",children:"https://arxiv.org/pdf/2512.24014"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/AgenticFinLab/latent-planning",children:"https://github.com/AgenticFinLab/latent-planning"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes iCLP, a novel framework inspired by human Implicit Cognition to enable LLMs to generate and use compact latent plans for reasoning. 2. Introduces a method to distill explicit plans from reasoning trajectories and learn their discrete representations via a vector-quantized autoencoder. 3. Demonstrates that fine-tuning LLMs on latent plans improves reasoning accuracy, efficiency, and cross-domain generalization while preserving interpretability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5dce54c76575e0ccf630d7de1d6cf89260c30415f1817167f368dcb00b0d64bd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5dce54c76575e0ccf630d7de1d6cf89260c30415f1817167f368dcb00b0d64bd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of LLMs generating unreliable explicit textual plans for reasoning. It proposes the iCLP framework, which enables LLMs to learn and use compact latent plans, inspired by human subconscious cognition. Experiments show this approach improves reasoning performance and generalization on mathematical and coding tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[iCLP: \u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u9690\u5f0f\u8ba4\u77e5\u6f5c\u5728\u89c4\u5212<br>iCLP: LLM Reasoning with Implicit Cognition Latent Planning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u663e\u5f0f\u6587\u672c\u89c4\u5212\u751f\u6210\u56f0\u96be<br>Challenges in generating explicit textual plans]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5b66\u4e60\u5e76\u4f7f\u7528\u6f5c\u5728\u89c4\u5212<br>Learn and use latent plans via VQ-VAE and fine-tuning]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u63d0\u5347\u51c6\u786e\u7387\u3001\u6548\u7387\u4e0e\u6cdb\u5316\u80fd\u529b<br>Improves accuracy, efficiency, and generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] FUSE-RSVLM: Feature Fusion Vision-Language Model for Remote Sensing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [vision-language models], [multi-feature fusion, recurrent visual injection, remote sensing vision-language model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yunkai Dang, Donghao Wang, Jiacheng Yang, Yifan Jiang, Meiyi Zhu, Yuekun Yang, Cong Wang, Qi Fan, Wenbin Li, Yang Gao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24022",children:"https://arxiv.org/pdf/2512.24022"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Yunkaidang/RSVLM",children:"https://github.com/Yunkaidang/RSVLM"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Multi-Feature Fusion Remote Sensing Vision-Language Model (MF-RSVLM) that extracts and fuses multi-scale visual features to better capture small and complex structures in remote sensing scenes., 2. Introduces a recurrent visual feature injection scheme to keep the language model grounded in visual evidence and mitigate visual forgetting during text generation., 3. Demonstrates state-of-the-art or highly competitive performance on diverse remote sensing benchmarks, including classification, image captioning, and VQA tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51db66b7af59969350cb2c0f2ca84f598178ab4f9ea4040dfc08f46586ef7fe0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51db66b7af59969350cb2c0f2ca84f598178ab4f9ea4040dfc08f46586ef7fe0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of applying general vision-language models to remote sensing data by proposing MF-RSVLM, a model that fuses multi-scale visual features and uses recurrent visual injection to reduce forgetting. It achieves strong results on remote sensing classification, captioning, and VQA tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FUSE-RSVLM: Feature Fusion Vision-Language Model for Remote Sensing] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: VLMs struggle with fine-grained features and visual forgetting in remote sensing]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-feature fusion and recurrent visual injection]\n    D[\u5173\u952e\u7ed3\u679c/Results: SOTA/competitive performance on RS benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Tracing the Heart's Pathways: ECG Representation Learning from a Cardiac Conduction Perspective"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [self-supervised learning], [electrocardiogram (ECG), self-supervised learning (SSL), cardiac conduction, sparse attention, hierarchical diagnosis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tan Pan, Yixuan Sun, Chen Jiang, Qiong Gao, Rui Sun, Xingmeng Zhang, Zhenqi Yang, Limei Han, Yixiu Liang, Yuan Cheng, Kaiyu Guo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Academy of Artificial Intelligence for Science"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24002",children:"https://arxiv.org/pdf/2512.24002"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Ashespt/CLEAR-HUG",children:"https://github.com/Ashespt/CLEAR-HUG"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies a key limitation in prior ECG self-supervised learning (eSSL) methods: they overlook inherent heartbeat differences rooted in cardiac conduction and neglect the sequential logic of clinical ECG diagnosis. 2. Proposes a novel two-stage framework (CLEAR-HUG), where the first stage (CLEAR) is an eSSL model that uses a sparse attention mechanism to reconstruct signals by treating each heartbeat as a distinct entity, capturing subtle conduction variations. 3. Introduces a Hierarchical lead-Unified Group head (HUG) for the downstream diagnosis stage, which mirrors the clinical workflow from heartbeats to leads to lead combinations, aligning model patterns with expert guidelines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4316ae9f56d525621d461087803f69e54c99676d3863c02d5df1d1ad32dab6a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4316ae9f56d525621d461087803f69e54c99676d3863c02d5df1d1ad32dab6a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes CLEAR-HUG, a two-stage framework for ECG representation learning. The method first uses a self-supervised model (CLEAR) with sparse attention to learn from cardiac conduction variations, then applies a hierarchical diagnosis head (HUG) aligned with clinical guidelines. Experiments across six tasks show a 6.84% performance improvement, validating its effectiveness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u8ffd\u8e2a\u5fc3\u8def\uff1a\u4ece\u5fc3\u810f\u4f20\u5bfc\u89c6\u89d2\u7684ECG\u8868\u5f81\u5b66\u4e60<br>Tracing the Heart's Pathways: ECG Representation Learning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709eSSL\u65b9\u6cd5\u5ffd\u89c6\u5fc3\u810f\u4f20\u5bfc\u5bfc\u81f4\u7684\u7ec6\u5fae\u5dee\u5f02<br>Prior eSSL overlooks conduction-based heartbeat differences]\n    B --\x3e B2[\u6a21\u578b\u672a\u9075\u5faa\u4ece\u5fc3\u8df3\u5230\u5bfc\u8054\u7684\u4e34\u5e8a\u8bca\u65ad\u903b\u8f91<br>Models neglect clinical diagnostic sequence]\n    C --\x3e C1[\u4e24\u9636\u6bb5\u6846\u67b6CLEAR-HUG<br>Two-stage framework CLEAR-HUG]\n    C1 --\x3e C2[\u9636\u6bb5\u4e00: CLEAR (\u81ea\u76d1\u7763\u5b66\u4e60)<br>Stage 1: CLEAR (eSSL)]\n    C2 --\x3e C3[\u7a00\u758f\u6ce8\u610f\u529b\u91cd\u6784\u4fe1\u53f7<br>Sparse attention for reconstruction]\n    C1 --\x3e C4[\u9636\u6bb5\u4e8c: HUG (\u5206\u5c42\u8bca\u65ad\u5934)<br>Stage 2: HUG (hierarchical head)]\n    C4 --\x3e C5[\u6a21\u4eff\u4e34\u5e8a\u5de5\u4f5c\u6d41<br>Mirrors clinical workflow]\n    D --\x3e D1[\u516d\u9879\u4efb\u52a1\u6027\u80fd\u63d0\u53476.84%<br>6.84% improvement across six tasks]\n    D --\x3e D2[\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027<br>Validates effectiveness]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] RSAgent: Learning to Reason and Act for Text-Guided Segmentation via Multi-Turn Tool Invocations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [text-guided segmentation], [agentic MLLM, multi-turn tool invocation, iterative mask refinement]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xingqi He, Yujie Zhang, Shuyong Gao, Wenjie Li, Lingyi Hong, Mingxi Chen, Kaixun Jiang, Jiyuan Fu, Wenqiang Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fudan University, Shanghai Jiao Tong University School of Medicine"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24023",children:"https://arxiv.org/pdf/2512.24023"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RSAgent, an agentic MLLM that interleaves reasoning and action for segmentation via multi-turn tool invocations, enabling iterative refinement. 2. Builds a data pipeline to synthesize multi-turn reasoning segmentation trajectories for training. 3. Introduces a two-stage training framework combining cold-start supervised fine-tuning with agentic reinforcement learning using fine-grained, task-specific rewards."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492283683a8b1ec7673cb4aa97997d0e1ab70ed4a074c17cfa6a9a5e87c60998_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492283683a8b1ec7673cb4aa97997d0e1ab70ed4a074c17cfa6a9a5e87c60998_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of one-shot methods in text-guided segmentation, where initial errors cannot be corrected. It proposes RSAgent, an agentic multimodal LLM that iteratively uses a segmentation toolbox, observes feedback, and refines its spatial hypotheses over multiple turns. Experiments show RSAgent achieves state-of-the-art performance on benchmarks like ReasonSeg and RefCOCOg."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RSAgent: Learning to Reason and Act for Text-Guided Segmentation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: One-shot grounding methods lack verification and refinement capabilities]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic MLLM with multi-turn tool invocation for iterative reasoning and mask refinement]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves SOTA on benchmarks (66.5% gIoU on ReasonSeg, 81.5% cIoU on RefCOCOg)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PipeFlow: Pipelined Processing and Motion-Aware Frame Selection for Long-Form Video Editing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [diffusion models], [DDIM inversion, motion analysis, pipelined scheduling, frame interpolation, long-form video editing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mustafa Munir, Md Mostafijur Rahman, Kartikeya Bhardwaj, Paul Whatmough, Radu Marculescu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Texas at Austin, Qualcomm AI Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24026",children:"https://arxiv.org/pdf/2512.24026"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A motion-aware frame selection method using SSIM and Optical Flow to skip editing of low-motion frames. 2. A pipelined task scheduling algorithm that splits videos into segments for parallel DDIM inversion and joint editing based on GPU memory. 3. A neural network-based interpolation technique to smooth border frames and interpolate skipped frames."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3787a383f3a5b9871e80fb8c9aaad731151ef891a01b7640701576d610e23860_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3787a383f3a5b9871e80fb8c9aaad731151ef891a01b7640701576d610e23860_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high computational cost of long-form video editing with diffusion models. It proposes PipeFlow, a method that uses motion analysis to skip frames, parallel pipelined processing, and interpolation to achieve linear scaling with video length. The method achieves significant speedups (up to 31.7x) over prior work while maintaining quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PipeFlow: Pipelined Processing and Motion-Aware Frame Selection for Long-Form Video Editing] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Long-form video editing is computationally expensive due to DDIM inversion and joint editing.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: 1. Motion-aware frame skipping. 2. Pipelined parallel processing. 3. Neural interpolation.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves linear scaling, up to 31.7x speedup over baselines.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [prompt optimization, multi-agent architecture, decision tree protocols, zero-shot alignment, automated debugging]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Natchaya Temyingyong, Daman Jain, Neeraj Kumarsahu, Prabhat Kumar, Rachata Phondi, Wachiravit Modecrua, Krittanon Kaewtawee, Krittin Pachtrachai, Touchapon Kraisingkorn"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Amity AI Research and Application Center"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24040",children:"https://arxiv.org/pdf/2512.24040"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ROAD, a novel framework that treats prompt optimization as a dynamic debugging investigation, eliminating the need for curated gold-standard datasets. 2. Proposes a specialized multi-agent architecture (Analyzer, Optimizer, Coach) to convert unstructured failure logs into structured Decision Tree Protocols. 3. Demonstrates high sample efficiency and performance improvements on both academic benchmarks and a live production system, offering a data-efficient alternative to RL-based methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2d710802d4ef2f4627a2a20e4c9834618953664f1165bf78a33477b890319f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2d710802d4ef2f4627a2a20e4c9834618953664f1165bf78a33477b890319f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of optimizing LLM agents without requiring large, labeled datasets, which are often unavailable in real-world software engineering. It proposes ROAD, a framework that uses a multi-agent architecture to perform automated debugging on failure logs, converting them into structured protocols for improvement. The results show that ROAD is highly sample-efficient and significantly improves agent performance, providing a practical alternative to resource-intensive training methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ROAD: Reflective Optimization via Automated Debugging] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: APO methods need large labeled datasets, but real-world has messy logs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-agent debugging (Analyzer, Optimizer, Coach) to create Decision Tree Protocols]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Sample-efficient, +5.6% success rate, +19% performance on complex tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [adversarial attacks], [jailbreaking, content safety filters, LLM safety alignment, input/output filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuan Xin, Dingfan Chen, Linyi Yang, Michael Backes, Xiao Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," CISPA Helmholtz Center for Information Security, Max Planck Institute for Intelligent Systems, Southern University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24044",children:"https://arxiv.org/pdf/2512.24044"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. First systematic evaluation of jailbreak attacks across the full LLM inference pipeline including input and output safety filters, 2. Demonstration that nearly all jailbreak techniques can be detected by at least one safety filter, challenging prior overestimations of attack success, 3. Identification of gaps in balancing recall and precision for optimizing protection and user experience in safety systems"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e40bd85a824936f762c47f0b98464b3b30e7733690440363f10ee46695920a8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e40bd85a824936f762c47f0b98464b3b30e7733690440363f10ee46695920a8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the gap in evaluating jailbreak attacks by systematically testing them against both LLM safety alignment and external content filters in the full deployment pipeline. The study finds that most jailbreaks can be detected by safety filters, suggesting prior success rates were overestimated, and highlights the need for better precision-recall balance in filter design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Jailbreak attacks bypass LLM safety alignment, prior evaluations neglect full deployment pipeline with content filters]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: First systematic evaluation of jailbreak attacks across full inference pipeline including input/output filtering stages]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Most jailbreaks detectable by safety filters, prior success overestimated; need better recall-precision balance]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [llm evaluation], [reliability, calibration, robustness, uncertainty quantification, composite score]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rohit Kumar Salla, Manoj Saravanan, Shrikar Reddy Kota"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Virginia Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24058",children:"https://arxiv.org/pdf/2512.24058"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/rohitsalla/CRS.git",children:"https://github.com/rohitsalla/CRS.git"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A unified reliability metric (CRS) integrating calibration, robustness, and uncertainty. 2. A large-scale evaluation of ten open-source LLMs on five QA datasets. 3. The demonstration that CRS provides stable model rankings and uncovers hidden failure modes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98ff5e45b3d4957a7de510123e5e0280e7ee39117d9ff73439f058e6965ebfab_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98ff5e45b3d4957a7de510123e5e0280e7ee39117d9ff73439f058e6965ebfab_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the fragmented evaluation of Large Language Model (LLM) reliability by proposing the Composite Reliability Score (CRS), a unified metric that integrates calibration, robustness, and uncertainty quantification. Through experiments on ten open-source LLMs, the authors show that CRS provides consistent model rankings and reveals trade-offs between reliability dimensions. The main conclusion is that the most dependable LLM systems balance accuracy, robustness, and calibrated uncertainty."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Beyond Hallucinations: A Composite Score for Measuring Reliability] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u53ef\u9760\u6027\u8bc4\u4f30\u788e\u7247\u5316/Fragmented LLM Reliability Evaluation]\n    C --\x3e C1[\u63d0\u51faCRS\u590d\u5408\u5206\u6570/Propose Composite Reliability Score (CRS)]\n    D --\x3e D1[CRS\u63d0\u4f9b\u7a33\u5b9a\u6a21\u578b\u6392\u540d/CRS Delivers Stable Model Rankings]\n    D --\x3e D2[\u63ed\u793a\u9690\u85cf\u7684\u5931\u8d25\u6a21\u5f0f/Uncovers Hidden Failure Modes]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Kidney Exchange: Faster Parameterized Algorithms and Tighter Lower Bounds"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [parameterized complexity], [kidney exchange, FPT algorithm, W[1]-hardness, pathwidth, treewidth]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Aritra Banik, Sujoy Bhore, Palash Dey, Abhishek Sahu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National Institute of Science Education and Research Bhubaneswar, Indian Institute of Technology Bombay, Indian Institute of Technology Kharagpur"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24037",children:"https://arxiv.org/pdf/2512.24037"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A new deterministic FPT algorithm for the kidney exchange problem parameterized by the number of patients receiving a kidney, improving the runtime from O*(14^t) to O*((4e)^t) \u2248 O*(10.88^t). 2. A proof that the kidney exchange problem is W[1]-hard when parameterized by the pathwidth of the underlying graph, answering a natural question about the parameter's tractability. 3. Additional parameterized intractability results that improve the overall understanding of the problem's complexity landscape."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00da3e6d7b1c46c83d5812783ee99ea1cfff1a2c3a708bddcff4c69f9ab7902c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00da3e6d7b1c46c83d5812783ee99ea1cfff1a2c3a708bddcff4c69f9ab7902c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies the computationally hard kidney exchange problem, where patient-donor pairs and altruistic donors exchange kidneys via cycles and paths. The authors present a faster deterministic parameterized algorithm for the standard parameter (number of patients receiving a kidney) and prove that the problem remains intractable (W[1]-hard) even when parameterized by pathwidth, a more restrictive structural parameter than treewidth."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Kidney Exchange: Faster Parameterized Algorithms and Tighter Lower Bounds<br>\u80be\u810f\u4ea4\u6362\uff1a\u66f4\u5feb\u7684\u53c2\u6570\u5316\u7b97\u6cd5\u4e0e\u66f4\u7d27\u7684\u4e0b\u754c"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Kidney exchange is NP-complete<br>\u80be\u810f\u4ea4\u6362\u95ee\u9898\u662fNP\u5b8c\u5168\u95ee\u9898"] --\x3e P1["\u9650\u5236/Constraint<br>Exchange via small cycles & paths<br>\u901a\u8fc7\u5c0f\u73af\u548c\u8def\u5f84\u4ea4\u6362"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Parameterized Complexity<br>\u53c2\u6570\u5316\u590d\u6742\u5ea6"] --\x3e M1["\u53c2\u6570/Parameter<br>Number of patients (t)<br>\u60a3\u8005\u6570\u91cf(t)"]\n    Method --\x3e M2["\u53c2\u6570/Parameter<br>Graph pathwidth<br>\u56fe\u8def\u5f84\u5bbd\u5ea6"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e R1["\u7b97\u6cd5\u6539\u8fdb/Algorithmic Improvement<br>FPT algorithm: O*((4e)^t)<br>FPT\u7b97\u6cd5: O*((4e)^t)"]\n    Results --\x3e R2["\u4e0b\u754c/Lower Bound<br>W[1]-hard for pathwidth<br>\u5bf9\u8def\u5f84\u5bbd\u5ea6\u662fW[1]-\u96be\u7684"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-modal reasoning], [audio-language models, hallucination mitigation, counterfactual hard negatives, preference alignment, temporal reasoning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yanxi Chen, Wenhui Zhu, Xiwen Chen, Zhipeng Wang, Xin Li, Peijie Qiu, Hao Wang, Xuanzhao Dong, Yujian Xiong, Anderson Schneider, Yuriy Nevmyvaka, Yalin Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Arizona State University, Clemson University, Washington University in St. Louis, Rice University, Morgan Stanley"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24052",children:"https://arxiv.org/pdf/2512.24052"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/LLM-VLM-GSL/AHA",children:"https://github.com/LLM-VLM-GSL/AHA"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a taxonomy for audio grounding failures in LALMs, categorizing hallucinations into Event Omission, False Event Identity, Temporal Relation Error, and Quantitative Temporal Error. 2. Introduced the AHA (Audio Hallucination Alignment) framework, which uses counterfactual hard negative mining to construct a high-quality preference dataset for model alignment. 3. Established AHA-Eval, a diagnostic benchmark to rigorously evaluate fine-grained temporal reasoning capabilities in audio-language models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45abc0731e44f649614386415942c67de681cccc206f884d4ce3832844263cdf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45abc0731e44f649614386415942c67de681cccc206f884d4ce3832844263cdf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of hallucinations in Large Audio-Language Models (LALMs), where models generate text not grounded in the audio input. To solve this, the authors propose the AHA framework, which uses counterfactual hard negative mining to create a preference dataset for aligning models to distinguish acoustic evidence from fabrications. The resulting aligned model, Qwen-Audio-AHA, shows significant improvements on both the diagnostic AHA-Eval benchmark and public benchmarks, demonstrating effective mitigation of grounding errors."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Large Audio-Language Models (LALMs) suffer from hallucinations / \u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u95ee\u9898]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Propose AHA framework with counterfactual hard negative mining / \u63d0\u51faAHA\u6846\u67b6\uff0c\u4f7f\u7528\u53cd\u4e8b\u5b9e\u786c\u8d1f\u4f8b\u6316\u6398]\n    Method --\x3e M2[Construct preference dataset for alignment / \u6784\u5efa\u7528\u4e8e\u5bf9\u9f50\u7684\u504f\u597d\u6570\u636e\u96c6]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[13.7% improvement on AHA-Eval benchmark / \u5728AHA-Eval\u57fa\u51c6\u4e0a\u63d0\u534713.7%]\n    Results --\x3e R2[Gains on public benchmarks (MMAU-Test, MMAR) / \u5728\u516c\u5f00\u57fa\u51c6(MMAU-Test, MMAR)\u4e0a\u53d6\u5f97\u63d0\u5347]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Pathology Context Recalibration Network for Ocular Disease Recognition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [Pathology Recalibration Module, expert prior Guidance Adapter, Integrated Loss]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zunjie Xiao, Xiaoqing Zhang, Risa Higashita, Jiang Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Southern University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24066",children:"https://arxiv.org/pdf/2512.24066"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel Pathology Recalibration Module (PRM) to leverage pathology context prior via pixel-wise context compression and pathology distribution concentration. 2. Introduced an expert prior Guidance Adapter (EPGA) to highlight significant pixel-wise regions by mining expert experience prior. 3. Designed an Integrated Loss (IL) to boost performance by considering sample-wise loss distributions and training label frequencies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2286b84bd9cbd7682cb726e99010af22979d096fd6391215bb5d0212bb1875c5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2286b84bd9cbd7682cb726e99010af22979d096fd6391215bb5d0212bb1875c5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes PCRNet, a network for ocular disease recognition that incorporates a Pathology Recalibration Module and an expert prior Guidance Adapter to integrate clinical pathology context and expert experience priors into a DNN. An Integrated Loss is also introduced to handle sample and label imbalances. Experiments on three datasets show PCRNet's superiority over state-of-the-art methods, and visualizations explain its decision-making process."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Pathology Context Recalibration Network for Ocular Disease Recognition] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: DNNs ignore pathology context & expert experience priors for ocular disease recognition] --\x3e P1[\u95ee\u98981/Sub-Problem: Lack of pathology context utilization]\n    Problem --\x3e P2[\u95ee\u98982/Sub-Problem: Lack of expert experience integration]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: PCRNet] --\x3e M1[\u6a21\u57571/Module: Pathology Recalibration Module (PRM)]\n    Method --\x3e M2[\u6a21\u57572/Module: expert prior Guidance Adapter (EPGA)]\n    Method --\x3e M3[\u7ec4\u4ef6/Component: Integrated Loss (IL)]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u7ed3\u679c1/Result: Superior performance on three datasets]\n    Results --\x3e R2[\u7ed3\u679c2/Result: Better than SOTA attention networks & loss methods]\n    Results --\x3e R3[\u7ed3\u679c3/Result: Visualization explains decision-making]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [evolutionary search, plan-execute-summarize, MAP-Elites, multi-island model, adaptive Boltzmann selection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chunhui Wan, Xunan Dai, Zhuo Wang, Minglei Li, Yanpeng Wang, Yinan Mao, Yu Lan, Zhiwen Xiao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Baidu Inc."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24077",children:"https://arxiv.org/pdf/2512.24077"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/baidu-baige/LoongFlow",children:"https://github.com/baidu-baige/LoongFlow"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces the LoongFlow framework, a self-evolving agent that integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm to guide evolutionary search with structured reasoning. 2. Proposes a hybrid evolutionary memory system combining Multi-Island models, MAP-Elites, and adaptive Boltzmann selection to balance exploration-exploitation and maintain long-term architectural coherence. 3. Demonstrates state-of-the-art performance, outperforming baselines by up to 60% in evolutionary efficiency on benchmarks like AlphaEvolve and Kaggle competitions.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf0c647c1b7ee2e5581b15e60884e9d1c6f9da783e58c0ac3ab7c483db365b6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf0c647c1b7ee2e5581b15e60884e9d1c6f9da783e58c0ac3ab7c483db365b6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper introduces LoongFlow, a self-evolving agent framework that uses a cognitive "Plan-Execute-Summarize" paradigm and a hybrid memory system to guide evolutionary search with LLMs. This approach addresses issues like premature convergence in traditional methods. Evaluations show LoongFlow achieves superior solution quality with significantly reduced computational cost compared to existing baselines.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LoongFlow: Directed Evolutionary Search<br>LoongFlow: \u5b9a\u5411\u8fdb\u5316\u641c\u7d22] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u8fdb\u5316\u65b9\u6cd5\u7f3a\u4e4f\u7ed3\u6784\u5316\u63a8\u7406<br>Traditional evolutionary methods lack structured reasoning]\n    B --\x3e B2[\u8fc7\u65e9\u6536\u655b\u4e0e\u4f4e\u6548\u63a2\u7d22<br>Premature convergence & inefficient exploration]\n    C --\x3e C1[\u8ba4\u77e5\u8303\u5f0f: \u8ba1\u5212-\u6267\u884c-\u603b\u7ed3<br>Cognitive Paradigm: Plan-Execute-Summarize]\n    C --\x3e C2[\u6df7\u5408\u8fdb\u5316\u8bb0\u5fc6\u7cfb\u7edf<br>Hybrid Evolutionary Memory System]\n    D --\x3e D1[\u8fdb\u5316\u6548\u7387\u63d0\u5347\u9ad8\u8fbe60%<br>Evolutionary efficiency improved by up to 60%]\n    D --\x3e D2[\u53d1\u73b0\u66f4\u4f18\u89e3\u51b3\u65b9\u6848<br>Discovers superior solutions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Random Multiplexing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sys], [wireless communication], [random multiplexing, AMP detection, power allocation, replica optimality, constrained capacity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Lei Liu, Yuhao Chi, Shunqi Huang, Zhaoyang Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Xidian University, Japan Advanced Institute of Science and Technology (JAIST)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24087",children:"https://arxiv.org/pdf/2512.24087"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a random multiplexing technique decoupled from physical channel structures, enabling application to arbitrary norm-bounded and spectrally convergent channel matrices. 2. Introduces a low-complexity cross-domain memory AMP (CD-MAMP) detector and derives optimal power allocations to minimize BER and maximize constrained capacity. 3. Investigates the optimal coding principle and proves the replica constrained-capacity optimality of the CD-MAMP detector for random multiplexing systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2f6d7e30422bda561811ec881c0aa17f79a2f4e7bf13203955c43c9c8fab17_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2f6d7e30422bda561811ec881c0aa17f79a2f4e7bf13203955c43c9c8fab17_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a random multiplexing technique to overcome the limitations of traditional and emerging multiplexing schemes (like OFDM and OTFS) which rely on specific channel structures. The method decouples from the physical channel, uses a random transform to create an input-isotropic equivalent channel, and employs a low-complexity AMP-type detector to achieve near-optimal performance for arbitrary norm-bounded channels. The authors validate the approach with theoretical analysis and numerical results, demonstrating its robustness and versatility in dynamic wireless environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Random Multiplexing] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u590d\u7528\u6280\u672f\u4f9d\u8d56\u7279\u5b9a\u4fe1\u9053\u7ed3\u6784/Traditional multiplexing relies on specific channel structures]\n    B --\x3e B2[\u5728\u52a8\u6001\u771f\u5b9e\u73af\u5883\u4e2d\u9c81\u68d2\u6027\u6709\u9650/Limited robustness in dynamic real-world environments]\n    C --\x3e C1[\u968f\u673a\u590d\u7528\u6280\u672f/Random Multiplexing Technique]\n    C --\x3e C2[\u6784\u5efa\u8f93\u5165\u5404\u5411\u540c\u6027\u7b49\u6548\u4fe1\u9053/Construct input-isotropic equivalent channel]\n    C --\x3e C3[CD-MAMP\u68c0\u6d4b\u5668/CD-MAMP Detector]\n    D --\x3e D1[\u4fdd\u8bc1\u6e10\u8fd1\u6700\u4f18BER/Guarantees asymptotic optimal BER]\n    D --\x3e D2[\u63a8\u5bfc\u6700\u4f18\u529f\u7387\u5206\u914d/Derives optimal power allocation]\n    D --\x3e D3[\u9a8c\u8bc1\u7406\u8bba\u7ed3\u679c/Validates theoretical findings]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [Controller Area Network (CAN), Intrusion Detection System (IDS), Transformer, Federated Learning, Lightweight Model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Devika S, Pratik Narang, Tejasvi Alladi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," BITS Pilani, Pilani Campus"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24088",children:"https://arxiv.org/pdf/2512.24088"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Transformer",children:"https://github.com/Transformer"})," IDS"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes FedLiTeCAN, a supervised intrusion detection framework using a two-layer encoder-only transformer in a Federated Learning environment. 2. Achieves a highly lightweight model (0.4MB) and fast real-time inference (0.608 ms per message), significantly outperforming baselines in size and speed. 3. Demonstrates strong generalization capability through cross-dataset analysis, achieving high accuracy on unseen cyber threats."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fccdaefce6abd0f6935fde57aedf3ec8956dfd7f60385f88dafe7a2ba8e6ef09_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fccdaefce6abd0f6935fde57aedf3ec8956dfd7f60385f88dafe7a2ba8e6ef09_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes FedLiTeCAN, a lightweight Transformer-based Intrusion Detection System for CAN bus security, deployed using Federated Learning. The model is designed to be fast, small, and robust, achieving high accuracy and rapid inference on resource-constrained hardware like Jetson Nano. The results show it is an effective solution for real-time intrusion detection in vehicular networks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FedLiTeCAN: A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: CAN\u534f\u8bae\u7f3a\u4e4f\u5185\u7f6e\u5b89\u5168\uff0c\u9700\u8981\u8f7b\u91cf\u3001\u5feb\u901f\u3001\u9c81\u68d2\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4e24\u5c42\u7f16\u7801\u5668Transformer]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u6a21\u578b\u5c0f(0.4MB)\uff0c\u68c0\u6d4b\u5feb(0.608ms)\uff0c\u7cbe\u5ea6\u9ad8(98.5%)\uff0c\u6cdb\u5316\u80fd\u529b\u5f3a]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Factorized Learning for Temporally Grounded Video-Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video-language models], [temporal grounding, factorized learning, preference optimization, evidence tokens, video understanding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenzheng Zeng, Difei Gao, Mike Zheng Shou, Hwee Tou Ng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24097",children:"https://arxiv.org/pdf/2512.24097"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/nusnlp/d2vlm",children:"https://github.com/nusnlp/d2vlm"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes D2VLM, a framework that decouples the learning of temporal grounding and textual response using a "grounding then answering with evidence referencing" paradigm and introduces evidence tokens for explicit event-level visual semantic capture. 2. Introduces Factorized Preference Optimization (FPO), a novel algorithm that explicitly incorporates probabilistic temporal grounding modeling into the preference optimization objective for both grounding and response. 3. Constructs a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7daa6b2b83cd5b8b5e9ed9cbeed8ecfc3d04fe90ac708e60dda996b6def5b97_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7daa6b2b83cd5b8b5e9ed9cbeed8ecfc3d04fe90ac708e60dda996b6def5b97_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of accurate temporal grounding in video-language models by proposing a factorized learning approach. It introduces the D2VLM framework, which decouples grounding and response generation, and a novel Factorized Preference Optimization (FPO) algorithm for joint optimization. Experiments show the approach achieves clear advantages over existing methods on various tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Factorized Learning for Temporally Grounded Video-Language Models] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Existing models struggle with accurate temporal grounding for event-level perception. \u73b0\u6709\u6a21\u578b\u5728\u4e8b\u4ef6\u7ea7\u611f\u77e5\u7684\u7cbe\u786e\u65f6\u95f4\u5b9a\u4f4d\u4e0a\u5b58\u5728\u56f0\u96be\u3002]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Propose D2VLM framework and Factorized Preference Optimization (FPO). \u63d0\u51faD2VLM\u6846\u67b6\u548c\u56e0\u5b50\u5316\u504f\u597d\u4f18\u5316\u7b97\u6cd5\u3002]\n    D[\u5173\u952e\u7ed3\u679c/Results: Demonstrates clear advantage on various tasks. \u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u660e\u663e\u4f18\u52bf\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Enhancing LLM Planning Capabilities through Intrinsic Self-Critique"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [planning], [self-critique, few-shot learning, many-shot learning, iterative refinement, planning benchmarks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bernd Bohnet, Pierre-Alexandre Kamienny, Hanie Sedghi, Dilan Gorur, Pranjal Awasthi, Aaron Parisi, Kevin Swersky, Rosanne Liu, Azade Nova, Noah Fiedel"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google DeepMind"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24103",children:"https://arxiv.org/pdf/2512.24103"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),"  1. Proposes an intrinsic self-critique method for LLMs to improve their own planning outputs without external verifiers. 2. Demonstrates significant performance gains on established planning benchmarks (Blocksworld, Logistics, Mini-grid) over strong baselines. 3. Shows the method's applicability across different models and datasets, achieving new state-of-the-art results for the considered model class."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1646fd60ae3c2dbada7b54640bd9b507a010326fc6e75dd48733e4e2612eeefd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1646fd60ae3c2dbada7b54640bd9b507a010326fc6e75dd48733e4e2612eeefd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces an intrinsic self-critique approach where LLMs iteratively critique and refine their own plans. The method, building upon few-shot and many-shot learning, significantly improves planning performance on benchmarks like Blocksworld without needing external verification. The results set a new state-of-the-art, demonstrating that self-critique can effectively enhance LLM planning capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Enhancing LLM Planning Capabilities through Intrinsic Self-Critique] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u89c4\u5212\u80fd\u529b\u4e0d\u8db3\uff0c\u4f20\u7edf\u81ea\u6279\u5224\u65b9\u6cd5\u6548\u679c\u53d7\u8d28\u7591/LLM planning capability is limited, effectiveness of self-critique is questioned]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5185\u5728\u81ea\u6279\u5224\u4e0e\u8fed\u4ee3\u7cbe\u70bc/Intrinsic Self-Critique and Iterative Refinement]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u89c4\u5212\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8fbe\u5230\u65b0SOTA/Significant performance gains on planning benchmarks, achieving new SOTA]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Multilevel Fair Allocation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [fair division], [multilevel allocation, hierarchical fairness, matroid-rank utilities, Yankee Swap, tree-structured agents]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maxime Lucet, Nawal Benabbou, Aur\xe9lie Beynier, Nicolas Maudet"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," LIP6, Sorbonne Universit\xe9"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24105",children:"https://arxiv.org/pdf/2512.24105"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the novel concept of multilevel fair allocation for hierarchical agent structures, 2. Proposes a generic polynomial-time sequential algorithm with theoretical fairness/efficiency guarantees, 3. Extends the General Yankee Swap algorithm to the multilevel setting with efficiency guarantees and demonstrated practical fairness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/931310fb9395b1c90ff2e48d3f63019e189cb72d20da462c04eb32b29d032896_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/931310fb9395b1c90ff2e48d3f63019e189cb72d20da462c04eb32b29d032896_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces the problem of multilevel fair allocation, where resources are distributed among agents organized in a tree hierarchy. It proposes two algorithms: a generic top-down sequential algorithm with theoretical guarantees and an extension of the General Yankee Swap algorithm for the multilevel setting. The work provides both theoretical and practical solutions for achieving fairness and efficiency in hierarchical resource allocation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Multilevel Fair Allocation<br>\u591a\u7ea7\u516c\u5e73\u5206\u914d"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Allocating resources in a tree-structured agent hierarchy<br>\u5728\u6811\u72b6\u4ee3\u7406\u5c42\u6b21\u7ed3\u6784\u4e2d\u5206\u914d\u8d44\u6e90"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>1. Generic sequential top-down algorithm<br>\u901a\u7528\u987a\u5e8f\u81ea\u4e0a\u800c\u4e0b\u7b97\u6cd5<br>2. Extended General Yankee Swap<br>\u6269\u5c55\u7684\u901a\u7528Yankee Swap\u7b97\u6cd5"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>Polynomial-time algorithms with fairness/efficiency guarantees<br>\u5177\u6709\u516c\u5e73\u6027/\u6548\u7387\u4fdd\u8bc1\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Enhancing LLM-Based Neural Network Generation: Few-Shot Prompting and Efficient Validation for Automated Architecture Design"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [Neural Architecture Search, Few-Shot Prompting, Code Deduplication, Automated Architecture Design, Lightweight Validation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chandini Vysyaraju, Raghuvir Duvvuri, Avi Goyal, Dmitry Ignatov, Radu Timofte"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Computer Vision Lab, CAIDAS & IFI, University of W\xfcrzburg"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24120",children:"https://arxiv.org/pdf/2512.24120"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Few-Shot Architecture Prompting (FSAP), a systematic study determining n=3 examples as optimal for LLM-based architecture generation in vision tasks. 2. Whitespace-Normalized Hash Validation, a lightweight (<1ms) deduplication method providing 100x speedup over AST parsing. 3. A dataset-balanced evaluation methodology for comparing architectures across heterogeneous vision benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c601e530777a60f08e6c3607d74352f9046689f8debe4c26a2d893b33b09df97_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c601e530777a60f08e6c3607d74352f9046689f8debe4c26a2d893b33b09df97_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses challenges in using LLMs for automated neural network architecture design in computer vision. It introduces a systematic few-shot prompting strategy (FSAP) and a fast deduplication method to prevent redundant training. The main conclusion is that using three examples in prompts best balances diversity and focus, and the lightweight validation enables efficient large-scale generation of unique architectures."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Enhancing LLM-Based Neural Network Generation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u81ea\u52a8\u5316\u67b6\u6784\u8bbe\u8ba1\u7684\u6311\u6218 / Challenges in Automated Architecture Design")\n    Problem --\x3e P2("LLM\u63d0\u793a\u4e0e\u9a8c\u8bc1\u7b56\u7565\u672a\u7cfb\u7edf\u7814\u7a76 / LLM Prompting & Validation Not Systematically Studied")\n    Method --\x3e M1("\u5c11\u6837\u672c\u67b6\u6784\u63d0\u793a / Few-Shot Architecture Prompting (FSAP)")\n    Method --\x3e M2("\u7a7a\u767d\u6807\u51c6\u5316\u54c8\u5e0c\u9a8c\u8bc1 / Whitespace-Normalized Hash Validation")\n    Results --\x3e R1("n=3\u793a\u4f8b\u4e3a\u6700\u4f18 / n=3 Examples is Optimal")\n    Results --\x3e R2("\u9a8c\u8bc1\u901f\u5ea6\u63d0\u5347100\u500d / 100x Speedup in Validation")\n    Results --\x3e R3("\u751f\u62101900\u4e2a\u72ec\u7279\u67b6\u6784 / Generated 1,900 Unique Architectures")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [cognitive architecture, Soar, large language models, explainable recommendation, online learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiaxin Hu, Tao Wang, Bingsan Yang, Hongrun Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sun Yat-Sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24113",children:"https://arxiv.org/pdf/2512.24113"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CogRec, a novel cognitive recommender agent that synergizes the strengths of Large Language Models (LLMs) and the Soar cognitive architecture. 2. Introduces a learning paradigm where Soar's symbolic reasoning is initialized and dynamically augmented by an LLM via chunking, enabling robust online learning. 3. Demonstrates that the agent provides highly interpretable rationales and shows advantages in accuracy, explainability, and addressing the long-tail problem on public datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6840c5950eff3f651f3ba24036f583190638dc59f4b4c5d9c32d2ca2079cb860_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6840c5950eff3f651f3ba24036f583190638dc59f4b4c5d9c32d2ca2079cb860_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes CogRec, a cognitive recommender agent that fuses Large Language Models (LLMs) with the Soar cognitive architecture to address the black-box nature and limited online learning of LLMs. The agent uses Soar for structured reasoning and dynamically queries an LLM to generate new symbolic rules when needed, enabling continuous knowledge evolution. Evaluations show CogRec improves recommendation accuracy, explainability, and performance on long-tail items."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CogRec: A Cognitive Recommender Agent] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLMs: \u9ed1\u76d2, \u5e7b\u89c9, \u96be\u5728\u7ebf\u5b66\u4e60/LLMs: Black-Box, Hallucination, Limited Online Learning]\n    B --\x3e B2[\u8ba4\u77e5\u67b6\u6784: \u77e5\u8bc6\u83b7\u53d6\u56f0\u96be/Cognitive Architectures: Laborious Knowledge Acquisition]\n    C --\x3e C1[\u878d\u5408LLM\u4e0eSoar/Fuse LLM and Soar]\n    C --\x3e C2[\u611f\u77e5-\u8ba4\u77e5-\u884c\u52a8\u5faa\u73af/PCA Cycle]\n    C --\x3e C3[LLM\u521d\u59cb\u5316\u4e0e\u52a8\u6001\u67e5\u8be2/LLM for Initialization & Dynamic Query]\n    C --\x3e C4[Soar\u7ec4\u5757\u5316\u5728\u7ebf\u5b66\u4e60/Soar Chunking for Online Learning]\n    D --\x3e D1[\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027/Improved Recommendation Accuracy]\n    D --\x3e D2[\u589e\u5f3a\u53ef\u89e3\u91ca\u6027/Enhanced Explainability]\n    D --\x3e D3[\u6709\u6548\u5904\u7406\u957f\u5c3e\u95ee\u9898/Effective Long-Tail Handling]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [embodied ai], [Embodied Reasoning, Action Tokenization, Vision-Language-Action Models, Flow Matching, Discrete Control]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yi Liu, Sukai Wang, Dafeng Wei, Xiaowei Cai, Linqing Zhong, Jiange Yang, Guanghui Ren, Jinyu Zhang, Maoqing Yao, Chuankang Li, Xindong He, Liliang Chen, Jianlan Luo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," AgiBot Research, Shanghai Innovation Institute"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24125",children:"https://arxiv.org/pdf/2512.24125"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ERIQ, a large-scale benchmark for decoupled evaluation of embodied reasoning in robotic manipulation. 2. Proposes FACT, a flow-matching-based action tokenizer for high-fidelity discretization of continuous control. 3. Presents GenieReasoner, a unified model that jointly optimizes reasoning and action in a discrete space, outperforming baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1a2e4506fbecb3e90de4ef501197f9125c51ac19b6cfc789fdfcb6e035edf72_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1a2e4506fbecb3e90de4ef501197f9125c51ac19b6cfc789fdfcb6e035edf72_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of combining broad generalization with precise execution in general-purpose robotics. It introduces a benchmark (ERIQ) to diagnose reasoning capabilities and a method (FACT) to tokenize actions, leading to a unified model (GenieReasoner) that improves performance on real-world tasks. The work provides a framework to overcome the reasoning-precision trade-off in robotic manipulation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Unified Embodied VLM Reasoning with Robotic Action via Autoregressive Discretized Pre-training"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>VLA\u6a21\u578b\u96be\u4ee5\u517c\u987e\u6cdb\u5316\u4e0e\u7cbe\u786e\u6267\u884c"] --\x3e P1["\u6cdb\u5316\u4e0e\u7cbe\u5ea6\u6743\u8861<br>Reasoning-Precision Trade-off"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method"] --\x3e M1["\u8bc4\u4f30\u57fa\u51c6: ERIQ<br>Benchmark: ERIQ"]\n    Method --\x3e M2["\u52a8\u4f5c\u5206\u8bcd\u5668: FACT<br>Action Tokenizer: FACT"]\n    Method --\x3e M3["\u7edf\u4e00\u6a21\u578b: GenieReasoner<br>Unified Model: GenieReasoner"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e R1["\u63ed\u793a\u4e86\u63a8\u7406\u80fd\u529b\u4e0e\u6cdb\u5316\u7684\u6b63\u76f8\u5173<br>Revealed positive correlation"]\n    Results --\x3e R2["\u5728\u771f\u5b9e\u4efb\u52a1\u4e2d\u8d85\u8d8a\u57fa\u7ebf<br>Outperformed baselines in real-world tasks"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [post-training quantization, weight outliers, rotation, GPTQ, data-free]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Advait Gadhikar, Riccardo Grazzi, James Hensman"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," CISPA Helmholtz Center for Information Security, Microsoft Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24124",children:"https://arxiv.org/pdf/2512.24124"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes OptRot, a data-free method that learns fusible rotations by minimizing a principled, cheap proxy objective (element-wise fourth power of weights) to reduce weight outliers for quantization. 2. Demonstrates that OptRot outperforms existing rotation methods (Hadamard, SpinQuant, OSTQuant) for weight quantization and improves W4A8 activation quantization. 3. Introduces OptRot+, a data-dependent variant that incorporates activation covariance information for further performance gains, while highlighting a trade-off between weight and activation quantization in the W4A4 setting."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137fb0c1b0206d10c607db973da90e5733c1ed86f7a8360cfe91f146000affae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137fb0c1b0206d10c607db973da90e5733c1ed86f7a8360cfe91f146000affae_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of quantizing Large Language Models (LLMs) by mitigating weight outliers. It proposes OptRot, a data-free method that learns efficient rotations to minimize a proxy for weight quantization error, and shows it outperforms existing techniques for weight and W4A8 activation quantization. The work also introduces an enhanced data-dependent variant and reveals a performance trade-off in more aggressive quantization settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u6743\u91cd\u548c\u6fc0\u6d3b\u4e2d\u7684\u5f02\u5e38\u503c\u4f7f\u91cf\u5316\u56f0\u96be/Outliers in LLM weights & activations make quantization difficult]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u901a\u8fc7\u6700\u5c0f\u5316\u65cb\u8f6c\u540e\u6743\u91cd\u7684\u56db\u9636\u77e9\u5b66\u4e60\u53ef\u878d\u5408\u7684\u65cb\u8f6c/Learn fusible rotations by minimizing element-wise fourth power of rotated weights (OptRot)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: OptRot\u5728\u6743\u91cd\u91cf\u5316\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6539\u8fdbW4A8\u6fc0\u6d3b\u91cf\u5316\uff0cW4A4\u4e0b\u5b58\u5728\u6743\u8861/OptRot outperforms existing methods for weight quant., improves W4A8 activation quant., trade-off in W4A4 setting]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] GARDO: Reinforcing Diffusion Models without Reward Hacking"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [reward hacking, diffusion models, regularization, mode collapse, online RL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haoran He, Yuxiao Ye, Jie Liu, Jiajun Liang, Zhiyong Wang, Ziyang Yuan, Xintao Wang, Hangyu Mao, Pengfei Wan, Ling Pan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hong Kong University of Science and Technology, Kuaishou Technology, CUHK MMLab, The University of Edinburgh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24138",children:"https://arxiv.org/pdf/2512.24138"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://tinnerhrhe.github.io/gardo_project",children:"https://tinnerhrhe.github.io/gardo_project"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed GARDO, a framework with gated regularization that selectively penalizes high-uncertainty samples to mitigate reward hacking efficiently., 2. Introduced an adaptive regularization mechanism that periodically updates the reference model to align with the online policy, enabling effective exploration., 3. Designed a diversity-aware reward amplification strategy to encourage mode coverage and prevent diversity collapse during RL fine-tuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df8973aa0f222e89b818973c0c7ef576738632b0095b29ac1f837f1a83f47f9b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of reward hacking in RL-fine-tuned diffusion models, where optimizing imperfect proxy rewards degrades real image quality and diversity. The authors propose GARDO, a framework featuring gated, adaptive regularization and diversity-aware optimization to prevent overfitting, maintain exploration, and enhance diversity. Experiments show GARDO effectively mitigates reward hacking and improves generation diversity without sacrificing sample efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[GARDO: Reinforcing Diffusion Models without Reward Hacking] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Reward Hacking in RL for Diffusion Models/\u6269\u6563\u6a21\u578bRL\u4e2d\u7684\u5956\u52b1\u7834\u89e3]\n    B --\x3e B2[Proxy Reward Mismatch & Mode Collapse/\u4ee3\u7406\u5956\u52b1\u4e0d\u5339\u914d\u4e0e\u6a21\u5f0f\u5d29\u6e83]\n    C --\x3e C1[Gated & Adaptive Regularization/\u95e8\u63a7\u81ea\u9002\u5e94\u6b63\u5219\u5316]\n    C --\x3e C2[Diversity-aware Reward Optimization/\u591a\u6837\u6027\u611f\u77e5\u5956\u52b1\u4f18\u5316]\n    D --\x3e D1[Mitigates Reward Hacking/\u7f13\u89e3\u5956\u52b1\u7834\u89e3]\n    D --\x3e D2[Enhances Diversity & Maintains Efficiency/\u63d0\u5347\u591a\u6837\u6027\u5e76\u4fdd\u6301\u6548\u7387]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [interactive reasoning], [graph-based exploration, state-space exploration, visual salience, training-free, ARC-AGI-3]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Evgenii Rudakov, Jonathan Shock, Benjamin Ultan Cowley"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Helsinki, University of Cape Town"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24156",children:"https://arxiv.org/pdf/2512.24156"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore",children:"https://github.com/dolphin-in-a-coma/arc-agi-3-just-explore"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a training-free, graph-based method for systematic state-space exploration in interactive reasoning tasks. 2. Introduces a strategy that segments visual frames and prioritizes actions based on visual salience and shortest paths to untested state-action pairs. 3. Demonstrates the method's strong performance on the ARC-AGI-3 benchmark, significantly outperforming state-of-the-art LLM-based agents and establishing a strong non-learning baseline."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c5463388c7bf347baae8d407681f498a8378e19ba7ae57ea056451d79518546_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c5463388c7bf347baae8d407681f498a8378e19ba7ae57ea056451d79518546_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a training-free, graph-based exploration method for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. The method uses visual frame segmentation and maintains a graph of states to prioritize exploration, solving a median of 30 out of 52 levels and outperforming leading LLMs. The results show that explicit, structured exploration is a powerful baseline for tasks where current LLMs fail."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Graph-Based Exploration for ARC-AGI-3 Interactive Reasoning Tasks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs fail at interactive reasoning in sparse-feedback environments like ARC-AGI-3]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Training-free graph-based exploration with visual segmentation and action prioritization]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Solves median 30/52 levels, ranks 3rd, outperforms frontier LLM agents]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Developing controlled natural language for formal specification patterns using AI assistants"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [requirements engineering], [controlled natural language, formal specification patterns, AI assistant, temporal requirements, syntax formalization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Natalia Garanina, Vladimir Zyubin, Igor Anureev"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Automation and Electrometry, Siberian Branch of the Russian Academy of Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24159",children:"https://arxiv.org/pdf/2512.24159"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel three-stage method for systematically constructing a Controlled Natural Language (CNL) for requirements using an AI assistant. 2. A prompt engineering approach that leverages a generalized template and formal semantics to generate a diverse corpus of natural language patterns. 3. Formalization of CNL syntax based on grammatical analysis of AI-generated patterns, specifically validated for event-driven temporal requirements."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16dd04888cb9a22a839acc0700d35470498034dd8676cff5e34d6cb903fd6ab9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16dd04888cb9a22a839acc0700d35470498034dd8676cff5e34d6cb903fd6ab9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a method to systematically develop a controlled natural language (CNL) for formal requirements specification using an AI assistant. The method involves creating a generalized pattern, using an AI to generate a corpus of natural language variants, and then formalizing the CNL syntax from the results. The approach was successfully tested for specifying event-driven temporal requirements, producing a language with built-in formal semantics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Developing controlled natural language for formal specification patterns using AI assistants] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: How to systematically construct a Controlled Natural Language (CNL) for formal requirements specification?);\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Three-stage method using AI assistant: 1. Compile generalized pattern, 2. Generate corpus via prompt, 3. Formalize syntax from grammar analysis.);\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Method successfully tested for event-driven temporal requirements, yielding a CNL with formal semantics by design.);"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PointRAFT: 3D deep learning for high-throughput prediction of potato tuber weight from partial point clouds"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D point cloud regression], [PointRAFT, partial point clouds, object height embedding, PointNet++, RGB-D]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pieter M. Blok, Haozhou Wang, Hyun Kwon Suh, Peicheng Wang, James Burridge, Wei Guo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Tokyo, Sejong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24193",children:"https://arxiv.org/pdf/2512.24193"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/pieterblok/pointraft.git",children:"https://github.com/pieterblok/pointraft.git"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed PointRAFT, a high-throughput point cloud regression network for directly predicting continuous 3D shape properties from partial point clouds. 2. Introduced a novel object height embedding as an architectural component to incorporate tuber height, improving regression performance under occlusion. 3. Demonstrated superior performance and real-time capability on a large-scale agricultural dataset, achieving high accuracy for potato tuber weight prediction."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c71915dfc1ce9e8203a646c9242d84788697d59124a23181fa869b682fd4cdf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c71915dfc1ce9e8203a646c9242d84788697d59124a23181fa869b682fd4cdf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of systematically underestimating potato tuber weight from incomplete 3D point clouds captured on harvesters. It proposes PointRAFT, a deep learning network that directly regresses weight from partial point clouds using a novel object height embedding. The method significantly outperforms baselines and achieves real-time processing speeds suitable for commercial harvesters."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["PointRAFT: 3D deep learning for high-throughput prediction of potato tuber weight from partial point clouds"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Incomplete point clouds from RGB-D lead to weight underestimation"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: PointRAFT network with object height embedding for direct regression"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Low error (MAE 12.0g), high speed (150 tubers/sec)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Science Context Protocol, autonomous scientific agents, unified resource integration, experiment lifecycle management, federated servers]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yankai Jiang, Wenjie Lou, Lilong Wang, Zhenyu Tang, Shiyang Feng, Jiaxuan Lu, Haoran Sun, Yaning Pan, Shuang Gu, Haoyang Su, Feng Liu, Wangxu Wei, Pan Tan, Dongzhan Zhou, Fenghua Ling, Cheng Tan, Bo Zhang, Xiaosong Wang, Lei Bai, Bowen Zhou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Artificial Intelligence Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24189",children:"https://arxiv.org/pdf/2512.24189"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/InternScience/scp",children:"https://github.com/InternScience/scp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SCP, an open-source protocol-level standard for universally describing and invoking heterogeneous scientific resources (tools, models, datasets, instruments)., 2. Introduces a secure service architecture (centralized Hub & federated Servers) for managing the complete, traceable experiment lifecycle and enforcing fine-grained access control., 3. Demonstrates a functional platform built on SCP, integrating over 1,600 tool resources to facilitate secure, large-scale, multi-institution collaboration between AI agents and human researchers, reducing integration overhead."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8885d3eeb276d5044f777dc33201481a07be8831aaff9d61726e4a6c13e821be_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces the Science Context Protocol (SCP), an open-source standard designed to address the fragmentation and bespoke nature of current autonomous scientific agent systems. SCP provides a universal specification for resource integration and a secure service architecture for experiment orchestration, enabling seamless, large-scale collaboration across platforms. The authors conclude that SCP establishes essential infrastructure for scalable, reproducible, and agent-driven science by standardizing context and tool orchestration at the protocol level."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root[SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Bespoke, isolated agent systems; Lack of shared protocol for heterogeneous resources"] --\x3e Problem_Detail["\u5177\u4f53\u6311\u6218/Specific Challenges<br>Difficult to deploy beyond single lab; Hard to reuse components & reproduce workflows"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Science Context Protocol (SCP)"] --\x3e Method_Pillar1["\u652f\u67f11: \u7edf\u4e00\u8d44\u6e90\u96c6\u6210/Unified Resource Integration<br>Universal spec for describing/invoking tools, models, data, instruments"]\n    Method --\x3e Method_Pillar2["\u652f\u67f12: \u5b9e\u9a8c\u751f\u547d\u5468\u671f\u7ba1\u7406/Experiment Lifecycle Management<br>Secure architecture (Hub & Servers) for registration, execution, monitoring"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Enables global web of autonomous agents"] --\x3e Results_Outcome1["\u6210\u679c1: \u5927\u89c4\u6a21\u751f\u6001\u7cfb\u7edf/Large-scale Ecosystem<br>1,600+ integrated tool resources"]\n    Results --\x3e Results_Outcome2["\u6210\u679c2: \u4fc3\u8fdb\u534f\u4f5c/Facilitates Collaboration<br>Reduces integration overhead; Enhances reproducibility"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Fleet Size and Mix Vehicle Routing Problem (FSMVRP), deep reinforcement learning (DRL), Markov Decision Process (MDP), fleet-and-route integrated policy network (FRIPN), remaining graph embedding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pengfu Wan, Jiawei Chen, Gangyan Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24251",children:"https://arxiv.org/pdf/2512.24251"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Formulates the Fleet Size and Mix Vehicle Routing Problem (FSMVRP) as a Markov Decision Process (MDP) for a deep reinforcement learning approach. 2. Proposes a novel policy network (FRIPN) that integrates fleet composition and routing decisions into a single model. 3. Introduces specialized input embeddings, including a remaining graph embedding, to enhance decision-making for vehicle employment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3969891b48accce35280355d106951820196973739958b782a307a2a3df23aa3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a deep reinforcement learning method to solve the complex Fleet Size and Mix Vehicle Routing Problem (FSMVRP). The core innovation is a policy network called FRIPN that jointly decides on fleet composition and routing. Experiments show the method is computationally efficient and scalable, producing near-optimal solutions quickly, especially for large-scale problems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: FSMVRP - simultaneous fleet composition & routing)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: DRL-based MDP formulation with FRIPN policy network & remaining graph embedding)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Near-optimal solutions in seconds, high computational efficiency & scalability)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [safety alignment], [risk-aware optimization, constrained policy optimization, nested risk measures, stepwise alignment, tail risk suppression]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Lijun Zhang, Lin Li, Wei Wei, Yajie Qi, Huizhong Song, Jun Wang, Yaodong Yang, Jiye Liang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanxi University, University College London, Peking University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24263",children:"https://arxiv.org/pdf/2512.24263"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Risk-aware Stepwise Alignment (RSA), a novel method that explicitly incorporates risk awareness into LLM policy optimization using nested risk measures. 2. Formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it via a stepwise procedure for token-level policy updates. 3. Provides theoretical analysis on policy optimality and demonstrates experimentally that the method ensures strong safety and suppresses low-probability, high-impact harmful behaviors while maintaining helpfulness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4111a1181bf60ea84ea5a2f52c3748bc1804913ef18afecfc6e9f7bd9f15f5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4111a1181bf60ea84ea5a2f52c3748bc1804913ef18afecfc6e9f7bd9f15f5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of risk-neutral safety alignment methods for large language models, which struggle with risks from policy deviation and rare catastrophic outputs. It proposes Risk-aware Stepwise Alignment (RSA), a method that uses nested risk measures for token-level constrained policy optimization. Experimental results show RSA achieves high helpfulness while ensuring strong safety and significantly suppressing tail risks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Risk-neutral alignment insufficient for policy deviation & rare catastrophic harms]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Risk-aware Stepwise Alignment (RSA) using nested risk measures for token-level policy optimization]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: High helpfulness, strong safety, significant tail risk suppression]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] One-shot synthesis of rare gastrointestinal lesions improves diagnostic accuracy and clinical training"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image synthesis], [one-shot synthesis, language-guided concept disentanglement, data augmentation, rare disease, generative framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jia Yu, Yan Zhu, Peiyao Fu, Tianyi Chen, Zhihua Wang, Fei Wu, Quanlin Li, Pinghong Zhou, Shuo Wang, Xian Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, Fudan University, Imperial College London, The University of Manchester"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24278",children:"https://arxiv.org/pdf/2512.24278"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed EndoRare, a one-shot, retraining-free generative framework for synthesizing diverse, high-fidelity images of rare gastrointestinal lesions from a single reference image., 2. Introduced a language-guided concept disentanglement method to separate pathognomonic lesion features from non-diagnostic attributes, ensuring diversity while preserving diagnostic fidelity., 3. Demonstrated that synthetic images improve both AI classifier performance (true positive rate) and novice clinician diagnostic accuracy (recall and precision) for rare pathologies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf643227c51e8cd7c3969dfe80d336673878c555397635a5c9831a5997ed5bd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf643227c51e8cd7c3969dfe80d336673878c555397635a5c9831a5997ed5bd_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the data scarcity problem for rare gastrointestinal lesions in AI development and clinical training. It proposes EndoRare, a one-shot generative framework that uses language-guided concept disentanglement to synthesize diverse and clinically plausible lesion images from a single example. The results show that these synthetic images significantly enhance the performance of AI classifiers and improve the diagnostic accuracy of novice endoscopists."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[One-shot synthesis of rare gastrointestinal lesions] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Rare lesions are infrequent, limiting AI model data and clinician training.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: EndoRare framework uses one-shot, language-guided concept disentanglement to generate diverse, high-fidelity synthetic images.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improves AI classifier true positive rate and novice clinician recall & precision.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal training], [counterfactual video generation, visual hallucination, diffusion-based video editing, advantage normalization, contrastive training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhe Huang, Hao Wen, Aiming Hao, Bingze Song, Meiqi Wu, Jiahong Wu, Xiangxiang Chu, Sheng Lu, Haoqian Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Beihang University, AMAP (Alibaba Group)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24271",children:"https://arxiv.org/pdf/2512.24271"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://amap-ml.github.io/Taming-Hallucinations/",children:"https://amap-ml.github.io/Taming-Hallucinations/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DualityForge, a framework for automatically synthesizing counterfactual video QA data using controllable diffusion-based video editing. 2. Presents DualityVidQA, a large-scale video dataset built using DualityForge to mitigate MLLM hallucinations. 3. Proposes DNA-Train, a two-stage SFT-RL training regime with pair-wise advantage normalization for stable and efficient policy optimization on contrastive data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa10c3c7d7f412fdbab92df4afa93ab6b3653346b89fc3443bf25d8615391b81_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa10c3c7d7f412fdbab92df4afa93ab6b3653346b89fc3443bf25d8615391b81_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of visual hallucinations in Multimodal Large Language Models (MLLMs) when processing counterfactual videos. The proposed solution, DualityForge, synthesizes counterfactual video QA data for training, and a novel training method, DNA-Train, leverages this data to improve grounding. Experiments show the method significantly reduces hallucinations and improves performance on both hallucination and general benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A["Taming Hallucinations: Boosting MLLMs\' Video Understanding<br>\u9a6f\u670d\u5e7b\u89c9\uff1a\u901a\u8fc7\u53cd\u4e8b\u5b9e\u89c6\u9891\u751f\u6210\u63d0\u5347MLLM\u89c6\u9891\u7406\u89e3"] --\x3e B["\u6838\u5fc3\u95ee\u9898/Problem<br>MLLMs over-rely on language priors, causing visual hallucinations on counterfactual videos."]\n    A --\x3e C["\u4e3b\u8981\u65b9\u6cd5/Method<br>DualityForge: Counterfactual video & QA synthesis.<br>DNA-Train: Contrastive SFT-RL training."]\n    A --\x3e D["\u5173\u952e\u7ed3\u679c/Results<br>24.0% hallucination reduction.<br>Strong generalization on benchmarks."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] DRL-TH: Jointly Utilizing Temporal Graph Attention and Hierarchical Fusion for UGV Navigation in Crowded Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [temporal graph attention, hierarchical graph pooling, multi-modal fusion, UGV navigation, deep reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ruitong Li, Lin Zhang, Yuenan Zhao, Chengxin Liu, Ran Song, Wei Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The affiliations are not explicitly provided in the given content. Based on the author names, it is not possible to reliably infer the main research institution(s)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24284",children:"https://arxiv.org/pdf/2512.24284"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a DRL-based navigation framework (DRL-TH) that integrates historical observations and adaptively fuses multi-modal information. 2. Introduced a Temporal-Guided Graph Attention Network (TG-GAT) to capture temporal context and scene evolution between consecutive frames. 3. Designed a Graph Hierarchical Abstraction Module (GHAM) to dynamically and balance multi-scale representations from RGB and LiDAR features."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83abe1de24f9a7e490d93db45dec754f2a2ff7f3de84d6e6983a358e1d9dff40_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83abe1de24f9a7e490d93db45dec754f2a2ff7f3de84d6e6983a358e1d9dff40_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes DRL-TH, a deep reinforcement learning framework for UGV navigation in crowded environments. It addresses limitations of single-frame observation and simple fusion by introducing a temporal graph attention network and a hierarchical graph pooling module for adaptive multi-modal feature integration. Experiments and real-world deployment show that DRL-TH outperforms existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[DRL-TH: UGV\u5bfc\u822a\u6846\u67b6] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u5355\u5e27\u89c2\u6d4b/Single-frame observation]\n    Problem --\x3e P2[\u7b80\u5355\u591a\u6a21\u6001\u878d\u5408/Simple multi-modal fusion]\n    P1 --\x3e P1_Sub[\u9650\u5236\u52a8\u6001\u9002\u5e94\u6027/Limits dynamic adaptability]\n    P2 --\x3e P2_Sub[\u96be\u4ee5\u6355\u6349\u65f6\u5e8f\u4e0a\u4e0b\u6587/Hard to capture temporal context]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u65f6\u5e8f\u5f15\u5bfc\u56fe\u6ce8\u610f\u529b\u7f51\u7edc/Temporal-Guided GAT (TG-GAT)]\n    Method --\x3e M2[\u56fe\u5c42\u6b21\u62bd\u8c61\u6a21\u5757/Graph Hierarchical Abstraction Module (GHAM)]\n    M1 --\x3e M1_Sub[\u6355\u6349\u8fde\u7eed\u5e27\u5173\u8054/Captures correlations between consecutive frames]\n    M2 --\x3e M2_Sub[\u52a8\u6001\u878d\u5408RGB\u4e0eLiDAR\u7279\u5f81/Dynamically fuses RGB & LiDAR features]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5/Outperforms existing methods]\n    Results --\x3e R2[\u771f\u5b9eUGV\u4e0a\u8868\u73b0\u826f\u597d/Performs well on real UGV]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Virtual-Eyes: Quantitative Validation of a Lung CT Quality-Control Pipeline for Foundation-Model Cancer Risk Prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [CT preprocessing, quality control, foundation models, lung cancer screening, validation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md. Enamul Hoq, Linda Larson-Prior, Fred Prior"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Arkansas for Medical Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24294",children:"https://arxiv.org/pdf/2512.24294"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Development and validation of Virtual-Eyes, a novel, anatomically targeted 16-bit CT quality-control pipeline for lung cancer screening. 2. Quantitative demonstration that such preprocessing significantly improves the performance and calibration of generalist foundation models (e.g., RAD-DINO) for cancer risk prediction. 3. Discovery that specialist models (e.g., Sybil) can degrade with the same preprocessing, revealing their potential reliance on contextual shortcuts in raw clinical data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6f230cd5094d46243a5c6fe260cf946e5540833e1a82b86423bbe80a292b76c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6f230cd5094d46243a5c6fe260cf946e5540833e1a82b86423bbe80a292b76c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper develops Virtual-Eyes, a quality-control pipeline for lung CT scans that standardizes resolution and extracts lung regions. The study finds that this preprocessing significantly boosts the cancer risk prediction performance of generalist foundation models but can harm specialist models that have adapted to raw, unprocessed clinical data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Virtual-Eyes: \u80ba\u764cCT\u8d28\u91cf\u63a7\u5236\u6d41\u7a0b\u9a8c\u8bc1] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>LDCT\u9884\u5904\u7406\u5f71\u54cd\u672a\u91cf\u5316] --\x3e P1[\u7f3a\u4e4f\u91cf\u5316/Lack of Quantification]\n    Problem --\x3e P2[\u901a\u7528vs\u4e13\u7528\u6a21\u578b\u5dee\u5f02/Generalist vs. Specialist]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>Virtual-Eyes Pipeline] --\x3e M1[\u8d28\u91cf\u63a7\u5236/Quality Control<br>512x512, \u8fc7\u6ee4\u7cfb\u5217]\n    Method --\x3e M2[\u80ba\u5757\u63d0\u53d6/Lung Block Extraction<br>HU\u8fc7\u6ee4, \u8986\u76d6\u8bc4\u5206]\n    Method --\x3e M3[\u6a21\u578b\u8bc4\u4f30/Model Evaluation<br>RAD-DINO, Sybil\u7b49]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>\u9884\u5904\u7406\u6548\u679c\u4e0d\u540c] --\x3e R1[\u63d0\u5347\u901a\u7528\u6a21\u578b/Improves Generalist FMs<br>RAD-DINO AUC\u2191]\n    Results --\x3e R2[\u635f\u5bb3\u4e13\u7528\u6a21\u578b/Harms Specialist Models<br>Sybil AUC\u2193]\n    Results --\x3e R3[\u63ed\u793a\u6377\u5f84\u5b66\u4e60/Reveals Shortcut Learning<br>\u4e0a\u4e0b\u6587\u4f9d\u8d56]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [reliability-aware dynamic weighting, cross-modal contrastive learning, semantic-aware beam prediction, low-altitude UAV, multi-modal learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haojin Li, Anbang Zhang, Chen Sun, Chenyuan Feng, Kaiqian Qu, Tony Q. S. Quek, Haijun Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology Beijing, Sony China Research Laboratory, Shandong University, Southeast University, University of Exeter, Singapore University of Technology and Design"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24324",children:"https://arxiv.org/pdf/2512.24324"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a reliability-aware dynamic weighting scheme that adaptively allocates contributions across different modalities (e.g., visual, posture, geospatial) based on their instantaneous reliability, moving beyond fixed-weight approaches. 2. Introduces a semantic-aware multi-modal beam prediction framework (SaM\xb2B) that uses cross-modal contrastive learning to align multi-source representations into a shared semantic space, enhancing robustness to noise and distribution shifts. 3. Validates the proposed SaM\xb2B framework on real-world low-altitude UAV datasets, demonstrating superior performance over baseline methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1fa219c5db4bfd0eeac8ee93679e8eba9ceb6e2e5ce7336d45afc6686f1d8162_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1fa219c5db4bfd0eeac8ee93679e8eba9ceb6e2e5ce7336d45afc6686f1d8162_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of unreliable beam prediction in multi-modal UAV communications caused by static weighting and modal misalignment. It proposes SaM\xb2B, a framework that uses reliability-aware dynamic weighting and cross-modal contrastive learning to adaptively fuse modalities and align their semantics. Experiments on real-world datasets show SaM\xb2B outperforms existing baseline methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u9759\u6001\u6743\u91cd\u4e0e\u6a21\u6001\u5931\u914d/Static Weighting & Modal Mismatch]\n    B --\x3e B2[\u8de8\u573a\u666f\u6cdb\u5316\u5f31/Weak Cross-Scenario Generalization]\n    C --\x3e C1[\u53ef\u9760\u6027\u611f\u77e5\u52a8\u6001\u52a0\u6743/Reliability-Aware Dynamic Weighting]\n    C --\x3e C2[\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60/Cross-Modal Contrastive Learning]\n    C --\x3e C3[\u8bed\u4e49\u611f\u77e5\u591a\u6a21\u6001\u6846\u67b6/Semantic-Aware Multi-Modal Framework (SaM\xb2B)]\n    D --\x3e D1[\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1/Validated on Real-World UAV Datasets]\n    D --\x3e D2[\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5/Superior to Baseline Methods]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [visual question answering, lesion segmentation, multimodal models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen, Noel Codella, Roberto Andres Novoa, Josep Malvehy"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Microsoft, University of Washington, Stanford University, Hospital Clinic of Barcelona"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24340",children:"https://arxiv.org/pdf/2512.24340"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://osf.io/72rp3",children:"https://osf.io/72rp3"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduction of the Dermatology Assessment Schema (DAS), a novel expert-developed framework for structured dermatological feature assessment. 2. Release of DermaVQA-DAS, an extended dataset supporting closed-ended question answering and lesion segmentation on patient-generated images. 3. Comprehensive benchmarking of state-of-the-art multimodal models on the new tasks, analyzing the impact of prompt design on segmentation performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of patient-centered benchmarks in dermatology by introducing DermaVQA-DAS, a dataset extension built upon a novel expert-developed assessment schema (DAS) for structured feature annotation. It supports two tasks\u2014closed-ended visual question answering and lesion segmentation\u2014on patient-generated images and queries. The study benchmarks modern multimodal models, finding strong QA performance and demonstrating that prompt design significantly impacts segmentation results."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[DermaVQA-DAS] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u60a3\u8005\u89c6\u89d2/Existing datasets lack patient perspective]\n    P1 --\x3e P2[\u9650\u5236\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u62a4\u7406\u5e94\u7528/Limits patient-centered care applications]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u63d0\u51fa\u76ae\u80a4\u75c5\u8bc4\u4f30\u6846\u67b6(DAS)/Propose Dermatology Assessment Schema (DAS)]\n    M1 --\x3e M2[\u6269\u5c55DermaVQA\u6570\u636e\u96c6/Extend DermaVQA dataset]\n    M2 --\x3e M3[\u652f\u6301\u4e24\u9879\u4efb\u52a1:\u5c01\u95ed\u5f0f\u95ee\u7b54\u4e0e\u5206\u5272/Support two tasks: closed QA & segmentation]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u63d0\u793a\u8bbe\u8ba1\u5f71\u54cd\u5206\u5272\u6027\u80fd/Prompt design impacts segmentation performance]\n    R1 --\x3e R2[\u6a21\u578b\u5728QA\u4e0a\u8868\u73b0\u5f3a\u52b2/Models perform strongly on QA]\n    R2 --\x3e R3[\u516c\u5f00\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u534f\u8bae/Publicly release dataset & evaluation protocols]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] FedSecureFormer: A Fast, Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [Transformer, Federated Learning, Differential Privacy, Intrusion Detection, Connected and Autonomous Vehicles]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Devika S, Vishnu Hari, Pratik Narang, Tejasvi Alladi, F. Richard Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," BITS Pilani, Pilani Campus; Carleton University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24345",children:"https://arxiv.org/pdf/2512.24345"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed FedSecureFormer, a lightweight encoder-only Transformer model with only 1.7M parameters for efficient intrusion detection in CAVs. 2. Integrated the model within a Federated Learning framework with Differential Privacy to enhance data privacy and enable collaborative training. 3. Demonstrated high performance (93.69% accuracy on 19 attacks) and fast inference (3.7775 ms on Jetson Nano), making it 100x faster than SOTA models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7914a9d504b1c6d9fb36172de5c5c3554e336d7411316a13768fea0423324240_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7914a9d504b1c6d9fb36172de5c5c3554e336d7411316a13768fea0423324240_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses cybersecurity threats in Connected and Autonomous Vehicles (CAVs) by proposing FedSecureFormer, a lightweight Transformer model trained using Federated Learning and Differential Privacy. The model achieves high accuracy for intrusion detection while ensuring data privacy and demonstrates extremely fast inference on edge devices, making it suitable for real-world deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[FedSecureFormer: A Fast, Federated and Secure Transformer Framework] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: CAV\u7f51\u7edc\u5b89\u5168\u5a01\u80c1 / Cybersecurity threats in CAVs]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u8f7b\u91cfTransformer + \u8054\u90a6\u5b66\u4e60 + \u5dee\u5206\u9690\u79c1 / Lightweight Transformer + FL + DP]\n    Results[\u5173\u952e\u7ed3\u679c/Results: \u9ad8\u7cbe\u5ea6 & \u5feb\u901f\u63a8\u7406 / High Accuracy & Fast Inference]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Skim-Aware Contrastive Learning for Efficient Document Representation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [document representation], [contrastive learning, natural language inference, long document, self-supervised learning, hierarchical transformer]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Waheed Ahmed Abro, Zied Bouraoui"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Univ Artois, CNRS"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24373",children:"https://arxiv.org/pdf/2512.24373"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel self-supervised contrastive learning framework inspired by human skimming behavior for long document representation. 2. A method that uses random section masking and an NLI-based contrastive objective to align relevant parts and distance unrelated ones. 3. Demonstrated significant improvements in both accuracy and efficiency on legal and biomedical document tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae38f3776c3982e71d1fd2fda48c20229eb63f1918544341ca35ab3cb48a02af_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae38f3776c3982e71d1fd2fda48c20229eb63f1918544341ca35ab3cb48a02af_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of efficiently representing long documents like legal and medical texts. It proposes a self-supervised contrastive learning method that mimics human skimming by masking sections and using an NLI objective to relate document parts. Experiments show the method achieves better accuracy and computational efficiency compared to existing approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Skim-Aware Contrastive Learning for Efficient Document Representation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u957f\u6587\u6863\u8868\u793a\u56f0\u96be/Inefficient long document representation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8eNLI\u7684\u5bf9\u6bd4\u5b66\u4e60/NLI-based contrastive learning with section masking]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347/Significant gains in accuracy and efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Tubular Riemannian Laplace Approximations for Bayesian Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [bayesian deep learning], [Laplace approximation, Riemannian geometry, uncertainty quantification, Bayesian neural networks, model calibration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rodrigo Pereira David"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," National Institute of Metrology, Technology and Quality (Inmetro)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24381",children:"https://arxiv.org/pdf/2512.24381"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Tubular Riemannian Laplace (TRL) approximation, a novel method that models the posterior as a probabilistic tube following low-loss valleys induced by functional symmetries. 2. Proposes using a Fisher/Gauss-Newton metric to separate prior-dominated tangential uncertainty from data-dominated transverse uncertainty, adapting to the anisotropic, curved loss surfaces of deep models. 3. Demonstrates empirically that TRL achieves calibration comparable to Deep Ensembles on ResNet-18 (CIFAR-10/100) at a fraction (1/5) of the training cost, bridging single-model efficiency with ensemble-grade reliability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbef449cd138ae804891e277de76405797dfc3e78511bcb03bf13e56823c9746_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbef449cd138ae804891e277de76405797dfc3e78511bcb03bf13e56823c9746_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the poor calibration of traditional Euclidean Laplace approximations in Bayesian Neural Networks. It proposes the Tubular Riemannian Laplace (TRL) approximation, which models the posterior as a tube using a Riemannian metric to better capture parameter space geometry. The method achieves excellent uncertainty calibration on image classification tasks, matching Deep Ensembles' reliability with significantly lower computational cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Tubular Riemannian Laplace Approximations<br>\u7ba1\u72b6\u9ece\u66fc\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u5728\u6df1\u5ea6\u6a21\u578b\u4e2d\u6821\u51c6\u4e0d\u4f73<br>Traditional Laplace approximations struggle with calibration in deep models]\n    C --\x3e C1[\u63d0\u51fa\u7ba1\u72b6\u9ece\u66fc\u62c9\u666e\u62c9\u65af(TRL)\u8fd1\u4f3c<br>Propose Tubular Riemannian Laplace (TRL) approximation]\n    C1 --\x3e C2[\u4f7f\u7528Fisher/Gauss-Newton\u5ea6\u91cf\u5efa\u6a21\u6982\u7387\u7ba1<br>Model probabilistic tube using Fisher/Gauss-Newton metric]\n    D --\x3e D1[\u5728ResNet-18\u4e0a\u5b9e\u73b0\u4f18\u79c0\u6821\u51c6<br>Achieves excellent calibration on ResNet-18]\n    D1 --\x3e D2[\u5339\u914d\u96c6\u6210\u65b9\u6cd5\u53ef\u9760\u6027\uff0c\u6210\u672c\u4ec51/5<br>Matches ensemble reliability at 1/5 training cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [fault-tolerance], [Functional Mockup Unit (FMU), fault injection, Continuous Integration/Continuous Delivery (CI/CD)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Giovanni Lambertini, Matteo Pini, Eugenio Mascaro, Francesco Moretti, Ayoub Raji, Marko Bertogna"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Modena and Reggio Emilia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24402",children:"https://arxiv.org/pdf/2512.24402"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An automated simulation and reporting pipeline for an autonomous racing stack that can execute up to three times faster than real-time, locally or on GitHub for CI/CD. 2. A fault injection module capable of introducing sensor delays, perturbations, and modifying outputs of any node in the software stack. 3. A design for an automated reporting process aimed at maximizing the effectiveness of simulation analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d172287ab1ffde29e52c3f7cde1a986f7a5d73ac371395320ced490d39f5dac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d172287ab1ffde29e52c3f7cde1a986f7a5d73ac371395320ced490d39f5dac_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents an automated simulation and reporting pipeline for validating an autonomous racing stack. The method uses a high-fidelity vehicle model as a Functional Mockup Unit (FMU) and includes a fault injection module to test system robustness. The pipeline enables fast, realistic scenario testing and automated reporting, which is crucial for efficiently validating critical autonomous driving functions like high-speed overtaking."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Need for efficient validation of autonomous racing stack modules, especially for high-speed maneuvers and localization."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Automated simulation pipeline using high-fidelity FMU model, scenario initialization, and fault injection."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Pipeline executes up to 3x faster than real-time, supports CI/CD, and includes automated reporting."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [hybrid model compression, two-stage IDS, BiGAN, CNN-LSTM, real-time inference]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Devika S, Vishnu Hari, Pratik Narang, Tejasvi Alladi, Vinay Chamola"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," BITS Pilani, Pilani Campus"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24391",children:"https://arxiv.org/pdf/2512.24391"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel two-stage Intrusion Detection System (IDS) architecture combining a coarse-grained BiGAN-CNN for anomaly detection and a fine-grained CNN-LSTM for attack classification. 2. The application of hybrid model compression (structural pruning and static quantization) to achieve a 77.2% model size reduction while maintaining performance. 3. Demonstrated real-time, efficient deployment on resource-constrained edge devices (e.g., Jetson Nano) with low per-vehicle inference latency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e22580ef1d7646dbfb5cbb4038c5aaef82d4f9a515521bd0405cb40b44178ee2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e22580ef1d7646dbfb5cbb4038c5aaef82d4f9a515521bd0405cb40b44178ee2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes FAST-IDS, a fast two-stage intrusion detection system for Connected and Autonomous Vehicles (CAVs). It uses a hybrid model compression technique to create a lightweight system that combines anomaly detection (BiGAN-CNN) and attack classification (CNN-LSTM) for efficient real-time threat detection. The compressed model achieves significant size reduction and faster inference, making it suitable for deployment on edge devices like the Jetson Nano."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[FAST-IDS: \u9762\u5411CAV\u7684\u5feb\u901f\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[CAV\u7f51\u7edc\u5b89\u5168\u5a01\u80c1 / CAV Cybersecurity Threats]\n    B --\x3e B2[\u8d44\u6e90\u53d7\u9650\u73af\u5883\u90e8\u7f72 / Deployment in Resource-Constrained Environments]\n    C --\x3e C1[\u4e24\u9636\u6bb5IDS / Two-Stage IDS]\n    C1 --\x3e C1_1[\u9636\u6bb51: BiGAN-CNN\u5f02\u5e38\u68c0\u6d4b / Stage 1: BiGAN-CNN Anomaly Detection]\n    C1 --\x3e C1_2[\u9636\u6bb52: CNN-LSTM\u653b\u51fb\u5206\u7c7b / Stage 2: CNN-LSTM Attack Classification]\n    C --\x3e C2[\u6df7\u5408\u6a21\u578b\u538b\u7f29 / Hybrid Model Compression]\n    C2 --\x3e C2_1[\u7ed3\u6784\u5316\u526a\u679d / Structural Pruning]\n    C2 --\x3e C2_2[\u9759\u6001\u91cf\u5316 / Static Quantization]\n    D --\x3e D1[\u6a21\u578b\u5927\u5c0f\u51cf\u5c1177.2% / 77.2% Model Size Reduction]\n    D --\x3e D2[\u63a8\u7406\u65f6\u95f4\u51cf\u5c1150.05% / 50.05% Inference Time Reduction]\n    D --\x3e D3[\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387 / High Detection Accuracy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Comparing Approaches to Automatic Summarization in Less-Resourced Languages"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [text summarization], [less-resourced languages, multilingual transfer, data augmentation, LLM prompting, mT5]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chester Palen-Michel, Constantine Lignos"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Brandeis University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24410",children:"https://arxiv.org/pdf/2512.24410"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A comprehensive comparative study of multiple summarization approaches for less-resourced languages, including zero-shot LLMs, fine-tuned mT5, and a translation pipeline. 2. Exploration and evaluation of three data augmentation methods using Wikipedia to generate synthetic training data for low-resource settings. 3. An analysis showing that a fine-tuned multilingual mT5 baseline often outperforms zero-shot LLMs and that LLM-as-judge evaluation may be unreliable for less-resourced languages."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f14f0d3397d12fd7c93ad9814a09fa7bd5c030b47c51091b59d65cc5392446ba_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f14f0d3397d12fd7c93ad9814a09fa7bd5c030b47c51091b59d65cc5392446ba_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper compares various methods for automatic text summarization in less-resourced languages, including prompting large language models (LLMs), fine-tuning multilingual models like mT5 with data augmentation, and a translation pipeline. The evaluation across multiple metrics finds that a fine-tuned multilingual mT5 model generally outperforms zero-shot LLMs, and highlights potential issues with using LLMs as evaluators for these languages."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[Comparing Approaches to Automatic Summarization in Less-Resourced Languages] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1["\u9ad8\u8d44\u6e90\u8bed\u8a00\u6027\u80fd\u597d\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7814\u7a76\u4e0d\u8db3 / High performance in high-resourced languages, less attention to less-resourced languages"]\n    C --\x3e C1["\u6bd4\u8f83\u591a\u79cd\u65b9\u6cd5 / Compare various approaches"]\n    C1 --\x3e C1_1["\u96f6\u6837\u672c\u63d0\u793aLLM / Zero-shot prompting LLMs"]\n    C1 --\x3e C1_2["\u5fae\u8c03mT5\uff08\u542b\u6570\u636e\u589e\u5f3a\uff09 / Fine-tuning mT5 (with data augmentation)"]\n    C1 --\x3e C1_3["\u7ffb\u8bd1-\u603b\u7ed3-\u7ffb\u8bd1\u6d41\u7a0b / Translate-summarize-translate pipeline"]\n    D --\x3e D1["\u5fae\u8c03mT5\u4f18\u4e8e\u5927\u591a\u6570\u65b9\u6cd5 / Fine-tuned mT5 outperforms most approaches"]\n    D --\x3e D2["LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u53ef\u80fd\u4e0d\u53ef\u9760 / LLM as judge may be less reliable"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PackKV: Reducing KV Cache Memory Footprint through LLM-Aware Lossy Compression"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [KV cache, lossy compression, memory footprint, GPU kernels, attention mechanism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bo Jiang, Taolue Yang, Youyuan Liu, Xubin He, Sheng Di, Sian Jin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Temple University, Argonne National Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24449",children:"https://arxiv.org/pdf/2512.24449"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/BoJiang03/PackKV",children:"https://github.com/BoJiang03/PackKV"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes PackKV, a generic KV cache management framework featuring novel lossy compression techniques specifically tailored to KV cache data characteristics. 2. Presents a careful co-design of compression algorithms and system architecture that is compatible with the dynamically growing KV cache while preserving high computational efficiency. 3. Achieves significantly higher memory reduction rates and execution throughput compared to state-of-the-art methods, effectively eliminating decompression overhead and accelerating matrix-vector multiplication."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42e07bd3aaf7626174ef50b03ee71ac8de443f8fb5560e374d8293b4df52b84f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42e07bd3aaf7626174ef50b03ee71ac8de443f8fb5560e374d8293b4df52b84f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high memory footprint of the KV cache during long-context LLM inference by proposing PackKV, a framework that uses LLM-aware lossy compression. PackKV co-designs compression algorithms and system architecture to reduce memory usage while maintaining computational efficiency. The results show that PackKV achieves superior memory reduction and higher throughput compared to existing quantization methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PackKV: Reducing KV Cache Memory Footprint] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: KV\u7f13\u5b58\u5185\u5b58\u5360\u7528\u5927/Large KV Cache Memory Footprint]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: LLM\u611f\u77e5\u7684\u6709\u635f\u538b\u7f29/LLM-Aware Lossy Compression]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u66f4\u9ad8\u5185\u5b58\u51cf\u5c11\u4e0e\u541e\u5410\u91cf/Higher Memory Reduction & Throughput]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [semantic communications], [min-max optimization, adversarial perturbations, multi-task learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yalin E. Sagduyu, Tugba Erpek, Aylin Yener, Sennur Ulukus"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nexcepta, The Ohio State University, University of Maryland"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24452",children:"https://arxiv.org/pdf/2512.24452"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A deep learning-based semantic communication framework that jointly supports multiple receiver tasks (e.g., inference and reconstruction) while explicitly limiting semantic information leakage to an eavesdropper. 2. Formulation of the privacy problem as an iterative min-max optimization, where the legitimate transmitter-receiver pair is trained to degrade an adaptive eavesdropper's semantic inference performance. 3. Introduction of an auxiliary adversarial perturbation layer that superimposes a crafted signal on the transmitted waveform to degrade eavesdropper performance, even when the legitimate link is not co-trained against it."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e9c394c6a473f54b07d7337b43fb693f3ebef1de80e7b275ea3c91df03de11_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e9c394c6a473f54b07d7337b43fb693f3ebef1de80e7b275ea3c91df03de11_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses privacy leakage in semantic communications, where task-optimized representations can be exploited by eavesdroppers. The proposed method uses a min-max adversarial training framework and an auxiliary perturbation layer to protect semantic information. Evaluations on image datasets show the approach significantly reduces eavesdropper inference accuracy without harming legitimate receiver performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Semantic representations leak sensitive information to eavesdroppers] --\x3e Problem_Detail[\u8bed\u4e49\u6cc4\u9732/Semantic Leakage]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Deep learning framework with min-max optimization and adversarial perturbations] --\x3e Method_Detail1[\u5bf9\u6297\u8bad\u7ec3/Min-Max Optimization]\n    Method --\x3e Method_Detail2[\u6270\u52a8\u5c42/Perturbation Layer]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Reduces eavesdropper accuracy, maintains legitimate performance] --\x3e Results_Detail[\u6709\u6548\u9690\u79c1\u4fdd\u62a4/Effective Privacy Preservation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied Agents"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [embodied ai], [partial observability, belief refinement, information gain, exploratory inference, test-time adaptation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Seohui Bae, Jeonghye Kim, Youngchul Sung, Woohyung Lim"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," LG AI Research, KAIST"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24461",children:"https://arxiv.org/pdf/2512.24461"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A test-time adaptive agent architecture that performs exploratory inference through posterior-guided belief refinement without gradient updates or extra training. 2. A method to estimate information gain for action selection using a lightweight LLM-based surrogate. 3. A novel reward metric to assess world alignment by quantifying consistency between posterior belief and ground-truth environment configuration."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/234ff05b49010da656582805168140c0ed145a8c4a3d1ca5e4147e19f57db21f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/234ff05b49010da656582805168140c0ed145a8c4a3d1ca5e4147e19f57db21f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a belief-guided agent for embodied AI that operates under partial observability. The agent refines its structured belief about the world at test time and selects actions to maximize predicted information gain, using a lightweight LLM to estimate it. Experiments show this method outperforms inference-time scaling baselines in aligning with latent world states while using significantly fewer tokens."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Align While Search: Belief-Guided Exploratory Inference<br/>\u5bf9\u9f50\u641c\u7d22\uff1a\u4fe1\u5ff5\u5f15\u5bfc\u7684\u63a2\u7d22\u6027\u63a8\u7406] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>LLM agents struggle with adaptive reasoning in partially observable environments.<br/>LLM\u667a\u80fd\u4f53\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u96be\u4ee5\u8fdb\u884c\u81ea\u9002\u5e94\u63a8\u7406\u3002]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Test-time agent with structured belief, updated via observations, selects actions to maximize predicted information gain.<br/>\u5177\u6709\u7ed3\u6784\u5316\u4fe1\u5ff5\u7684\u6d4b\u8bd5\u65f6\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u89c2\u5bdf\u66f4\u65b0\u4fe1\u5ff5\uff0c\u9009\u62e9\u884c\u52a8\u4ee5\u6700\u5927\u5316\u9884\u6d4b\u4fe1\u606f\u589e\u76ca\u3002]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>Outperforms inference-time baselines (e.g., prompt-augmented LLMs) with lower token usage.<br/>\u4ee5\u66f4\u4f4e\u7684\u4ee4\u724c\u4f7f\u7528\u91cf\u4f18\u4e8e\u63a8\u7406\u65f6\u57fa\u7ebf\uff08\u5982\u63d0\u793a\u589e\u5f3a\u7684LLM\uff09\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [causal discovery], [sheaf theory, large language models, natural gradient descent, algebraic latent projection, presheaf]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hyunjun Kim"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), \xc9cole Polytechnique F\xe9d\xe9rale de Lausanne (EPFL)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24478",children:"https://arxiv.org/pdf/2512.24478"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/hyunjun1121/holograph",children:"https://github.com/hyunjun1121/holograph"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A sheaf-theoretic framework formalizing LLM-guided causal discovery as a presheaf satisfaction problem. 2. A natural gradient descent algorithm on the belief manifold for principled optimization. 3. The introduction of Algebraic Latent Projection to handle hidden confounders."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68eaf3f0002711b7e42d725e2a453cb23c5db4c9ca0b3a10f0290cfce9779f2e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68eaf3f0002711b7e42d725e2a453cb23c5db4c9ca0b3a10f0290cfce9779f2e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces HOLOGRAPH, a framework that uses sheaf theory to formally integrate Large Language Model priors for causal discovery, addressing issues of coherence and hidden confounders. It proposes novel methods like Algebraic Latent Projection and natural gradient optimization. The approach provides a rigorous mathematical foundation and shows competitive performance, while analysis reveals a failure of the Locality axiom in larger graphs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HOLOGRAPH] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u56e0\u679c\u53d1\u73b0\u53d7\u53ef\u8bc6\u522b\u6027\u9650\u5236/Causal discovery limited by identifiability]\n    B --\x3e B2[\u73b0\u6709LLM\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840/Existing LLM methods lack theory]\n    C --\x3e C1[\u5c42\u7406\u8bba\u6846\u67b6/Sheaf-theoretic framework]\n    C --\x3e C2[\u4ee3\u6570\u6f5c\u5728\u6295\u5f71/Algebraic Latent Projection]\n    C --\x3e C3[\u81ea\u7136\u68af\u5ea6\u4e0b\u964d/Natural Gradient Descent]\n    D --\x3e D1[\u63d0\u4f9b\u6570\u5b66\u57fa\u7840/Provides mathematical foundation]\n    D --\x3e D2[\u6027\u80fd\u6709\u7ade\u4e89\u529b/Achieves competitive performance]\n    D --\x3e D3[\u5c40\u90e8\u6027\u516c\u7406\u5931\u6548/Locality axiom fails for large graphs]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] F2IDiff: Real-world Image Super-resolution using Feature to Image Diffusion Foundation Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image super-resolution], [diffusion models, DINOv2, feature conditioning, hallucination control, real-world images]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Devendra K. Jangid, Ripon K. Saha, Dilshan Godaliyadda, Jing Li, Seok-Jun Lee, Hamid R. Sheikh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," MPI Lab, Samsung Research America"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24473",children:"https://arxiv.org/pdf/2512.24473"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes F2IDiff, a new Feature-to-Image Diffusion Foundation Model for SISR that uses lower-level DINOv2 features for conditioning instead of text. 2. Demonstrates that this approach provides stricter and richer conditioning for small patches, enabling controlled generation and higher fidelity, especially for high-fidelity smartphone LR images. 3. Shows that the model can be trained effectively with a much smaller dataset (38K images) and a smaller U-Net than large text-to-image models like SD2.1, while achieving superior performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccded9f21c9c6de980a50bfd5c308052e1cce34fc21b16a1a1b0cbd3a8c8c57d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccded9f21c9c6de980a50bfd5c308052e1cce34fc21b16a1a1b0cbd3a8c8c57d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of undesirable hallucinations in generative super-resolution for high-fidelity smartphone images. It proposes F2IDiff, a diffusion foundation model conditioned on DINOv2 features instead of text, which allows for stricter control and richer description of image patches. The method achieves better fidelity and performance than text-conditioned models while requiring significantly less data and a smaller network."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[F2IDiff: Real-world Image Super-resolution] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6587\u672c\u7279\u5f81\u5bf9\u7ec6\u8282\u63cf\u8ff0\u4e0d\u8db3<br/>Text features lack detail]\n    B --\x3e B2[\u667a\u80fd\u624b\u673a\u9ad8\u5206\u8fa8\u7387LR\u56fe\u50cf\u9700\u8981\u65e0\u5e7b\u89c9\u751f\u6210<br/>Smartphone LR needs hallucination-free generation]\n    C --\x3e C1[\u4f7f\u7528DINOv2\u7279\u5f81\u8fdb\u884c\u6761\u4ef6\u63a7\u5236<br/>Use DINOv2 features for conditioning]\n    C --\x3e C2[\u6784\u5efa\u7279\u5f81\u5230\u56fe\u50cf\u6269\u6563\u57fa\u7840\u6a21\u578b(F2IDiff)<br/>Build Feature-to-Image Diffusion FM (F2IDiff)]\n    D --\x3e D1[\u6bd4\u57fa\u4e8e\u6587\u672c\u7684\u6a21\u578b\u4fdd\u771f\u5ea6\u66f4\u9ad8<br/>Higher fidelity than text-based models]\n    D --\x3e D2[\u4f7f\u7528\u66f4\u5c0f\u7684\u6570\u636e\u96c6\u548c\u7f51\u7edc\u5b9e\u73b0<br/>Achieved with smaller dataset & network]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision-language model (VLM), fallback maneuver, semantic hazard detection, autonomous surface vessel (ASV), IMO MASS Code]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kim Alexander Christensen, Andreas Gudahl Tufte, Alexey Gusev, Rohan Sinha, Milan Ganai, Ole Andreas Alsos, Marco Pavoned, Martin Steinert"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," NTNU (Norwegian University of Science and Technology), Stanford University, NVIDIA Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24470",children:"https://arxiv.org/pdf/2512.24470"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Semantic Lookout, a camera-only, candidate-constrained VLM fallback maneuver selector for maritime autonomy. 2. Introduces a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback to meet IMO MASS Code requirements. 3. Demonstrates that sub-10-second VLM models retain semantic awareness and outperform geometry-only baselines in hazard scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd093268c75343899a9f72b23f4d22948c1b634539b5e39f8d26296c9f122886_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd093268c75343899a9f72b23f4d22948c1b634539b5e39f8d26296c9f122886_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of semantic hazard detection for autonomous maritime vessels, which is required by the draft IMO MASS Code. It proposes Semantic Lookout, a vision-language model (VLM) based system that selects safe fallback maneuvers by understanding scene semantics. The results show that this approach is effective within practical latency budgets and outperforms traditional geometry-only methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Foundation models on the bridge / \u8bba\u6587\u6807\u9898"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u81ea\u4e3b\u8239\u8236\u9700\u68c0\u6d4b\u8bed\u4e49\u5371\u5bb3 / Autonomous vessels need semantic hazard detection"]\n    Problem --\x3e P2["\u4f20\u7edf\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u8bed\u4e49\u5f02\u5e38 / Classical stacks struggle with semantic OOD situations"]\n    Method --\x3e M1["\u5f15\u5165Semantic Lookout / Introduce Semantic Lookout"]\n    Method --\x3e M2["\u57fa\u4e8eVLM\u7684\u5907\u7528\u673a\u52a8\u9009\u62e9\u5668 / VLM-based fallback maneuver selector"]\n    Method --\x3e M3["\u5feb\u901f-\u6162\u901f\u5f02\u5e38\u5904\u7406\u6d41\u7a0b / Fast-slow anomaly pipeline"]\n    Results --\x3e R1["10\u79d2\u5185\u6a21\u578b\u4fdd\u6301\u8bed\u4e49\u611f\u77e5 / Sub-10 s models retain semantic awareness"]\n    Results --\x3e R2["\u4f18\u4e8e\u51e0\u4f55\u57fa\u7ebf / Outperforms geometry-only baselines"]\n    Results --\x3e R3["\u652f\u6301IMO MASS\u6cd5\u89c4 / Supports draft IMO MASS Code"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [world models], [joint-embedding predictive architecture, representation space planning, model-based reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Basile Terver, Tsung-Yen Yang, Jean Ponce, Adrien Bardes, Yann LeCun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Meta FAIR, INRIA Paris, Ecole normale sup\xe9rieure/PSL, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24497",children:"https://arxiv.org/pdf/2512.24497"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/facebookresearch/jepa-wms",children:"https://github.com/facebookresearch/jepa-wms"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a comprehensive characterization and study of Joint-Embedding Predictive Architecture World Models (JEPA-WMs) for physical planning. 2. Systematically investigates the impact of model architecture, training objective, and planning algorithm on planning success in simulated and real-world robotic tasks. 3. Combines the findings to propose a new model that outperforms established baselines (DINO-WM and V-JEPA-2-AC) in navigation and manipulation tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be3154d136e165197c022f619cd1d45cd62098d7f202059d7110d6335e67c44_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be3154d136e165197c022f619cd1d45cd62098d7f202059d7110d6335e67c44_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the key factors for successful physical planning using Joint-Embedding Predictive World Models (JEPA-WMs). It conducts a systematic study of architectural and algorithmic choices within this family of methods and proposes a new model that achieves superior performance on navigation and manipulation tasks compared to existing baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[What Drives Success in Physical Planning with JEPA-WMs?] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br>How to build agents that generalize to new physical tasks?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br>Study JEPA-WMs: architecture, objective, planning algorithm]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br>Proposed model outperforms baselines (DINO-WM, V-JEPA-2-AC)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [proxy models, data curation, hyperparameter tuning, learning rate, pretraining]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiachen T. Wang, Tong Wu, Kaifeng Lyu, James Zou, Dawn Song, Ruoxi Jia, Prateek Mittal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Princeton University, Tsinghua University, Stanford University, UC Berkeley, Virginia Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24503",children:"https://arxiv.org/pdf/2512.24503"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies a critical flaw in the standard proxy-model evaluation protocol, showing that using a fixed training configuration for all data recipes leads to unreliable conclusions that can flip with minor hyperparameter changes. 2. Proposes a simple and effective patch to the protocol: training proxy models with reduced learning rates, which preserves the relative performance ranking of data recipes and correlates strongly with fully-tuned large-scale training. 3. Provides theoretical justification for the proposed method by proving it preserves dataset ordering for random-feature models, and validates it empirically across 23 data recipes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0253b877f5ec90fd3f09b9d1a8f7d0967a88407fbbd25eb1e8a8bfcdf23081c4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0253b877f5ec90fd3f09b9d1a8f7d0967a88407fbbd25eb1e8a8bfcdf23081c4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that the standard practice of using small proxy models with identical hyperparameters to evaluate data recipes is unreliable because optimal training configurations are data-dependent. To fix this, the authors propose training proxy models with reduced learning rates, a simple change that makes small-scale experiment rankings strongly correlate with those from fully-tuned large-scale LLM pretraining. This method is theoretically justified and empirically validated, dramatically improving the reliability of data curation guidance from small training runs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u56fa\u5b9a\u914d\u7f6e\u8bc4\u4f30\u4e0d\u53ef\u9760/Fixed-config evaluation unreliable]\n    Problem --\x3e P2[\u7ed3\u8bba\u968f\u8d85\u53c2\u7ffb\u8f6c/Conclusions flip with hyperparams]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u964d\u4f4e\u5b66\u4e60\u7387\u8bad\u7ec3\u4ee3\u7406\u6a21\u578b/Train proxy models with reduced LR]\n    Method --\x3e M2[\u6570\u636e\u7279\u5b9a\u8c03\u4f18\u76ee\u6807/Data-specific tuning objective]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u4e0e\u5927\u89c4\u6a21\u8bad\u7ec3\u5f3a\u76f8\u5173/Strong correlation with large-scale training]\n    Results --\x3e R2[\u7406\u8bba\u8bc1\u660e\u4e0e\u5b9e\u8bc1\u9a8c\u8bc1/Theoretical proof & empirical validation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [spatial reasoning], [foundation model agents, interactive evaluation, spatial memory, graph-based representation, path planning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhiwei Wei, Yuxing Liu, Hua Liao, Wenjia Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hunan Normal University, Beijing University of Posts and Telecommunications"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24504",children:"https://arxiv.org/pdf/2512.24504"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an interactive evaluation framework to assess how foundation model agents explore, remember, and reason in partially observable symbolic map environments., 2. Systematically analyzes the distinct functional roles of exploration strategies, memory representations, and reasoning schemes on spatial task performance., 3. Reveals that spatial reasoning performance saturates with model scale, indicating the need for tailored spatial representation mechanisms beyond scaling."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f22bb0bbc4529875e6217599c85097728b0d0b467695dfc3508153e6cab59ae2_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f22bb0bbc4529875e6217599c85097728b0d0b467695dfc3508153e6cab59ae2_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an interactive framework to evaluate how foundation model agents understand maps by exploring, remembering, and reasoning in partially observable grid environments. The study finds that structured memory representations, like graphs, are crucial for complex tasks like path planning, and that performance improvements require specialized spatial mechanisms, not just scaling model size."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1(\u73b0\u6709\u8bc4\u4f30\u5ffd\u89c6\u4ea4\u4e92\u6027/Existing evaluations overlook interactive, experience-driven spatial understanding)\n    C --\x3e C1(\u63d0\u51fa\u4ea4\u4e92\u5f0f\u8bc4\u4f30\u6846\u67b6/Propose interactive evaluation framework)\n    C1 --\x3e C2(\u667a\u80fd\u4f53\u589e\u91cf\u63a2\u7d22\u90e8\u5206\u53ef\u89c2\u6d4b\u5730\u56fe/Agents incrementally explore partially observable maps)\n    C2 --\x3e C3(\u8bc4\u4f30\u516d\u7c7b\u7a7a\u95f4\u4efb\u52a1/Evaluate six kinds of spatial tasks)\n    D --\x3e D1(\u7ed3\u6784\u5316\u8bb0\u5fc6\u63d0\u5347\u6027\u80fd/Structured memory (e.g., graph) substantially improves performance)\n    D --\x3e D2(\u63a2\u7d22\u5f71\u54cd\u7ecf\u9a8c\u83b7\u53d6/Exploration affects experience acquisition)\n    D --\x3e D3(\u6027\u80fd\u968f\u89c4\u6a21\u9971\u548c/Reasoning performance saturates with model scale)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [mathematical reasoning], [large language models, mathematical reasoning, benchmark evaluation, error analysis, underrepresented datasets]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Samuel Golladay, Majid Bani-Yaghoub"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri: Kansas City"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24505",children:"https://arxiv.org/pdf/2512.24505"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Evaluated LLMs on underrepresented mathematics competition problems (Missouri Collegiate Mathematics Competition) to address dataset contamination and generalizability issues. 2. Conducted a detailed analysis of reasoning quality and error patterns across three LLMs (GPT-4o-mini, Gemini-2.0-Flash, DeepSeek-V3) beyond just final answer accuracy. 3. Identified distinct error profiles for each model and highlighted Geometry as a persistent challenge for LLMs' structured reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0233f7d7f1efe2775a15812915de42cb0ed0d928ad7ea3ea8e06fe4ee277303_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0233f7d7f1efe2775a15812915de42cb0ed0d928ad7ea3ea8e06fe4ee277303_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study evaluates the reasoning abilities of three LLMs on underrepresented mathematics competition problems. The results show DeepSeek-V3 performed best, and all models struggled with Geometry, revealing distinct error patterns. The work concludes that using such datasets provides deeper insights into LLMs' reasoning limitations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Evaluating LLMs on Underrepresented Math Problems<br/>\u8bc4\u4f30LLM\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8868\u73b0] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[Problem: Limited generalizability of LLM math benchmarks<br/>\u95ee\u9898: LLM\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u6cdb\u5316\u6027\u4e0d\u8db3]\n    C[Method: Test LLMs on Missouri Collegiate Math Competition problems<br/>\u65b9\u6cd5: \u5728\u5bc6\u82cf\u91cc\u5927\u5b66\u6570\u5b66\u7ade\u8d5b\u95ee\u9898\u4e0a\u6d4b\u8bd5LLMs]\n    D[Results: DeepSeek-V3 best; Geometry is a weak point; distinct error patterns<br/>\u7ed3\u679c: DeepSeek-V3\u6700\u4f18; \u51e0\u4f55\u662f\u5f31\u70b9; \u4e0d\u540c\u7684\u9519\u8bef\u6a21\u5f0f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [spatial reasoning, LoRA, GRPO, supervised fine-tuning, reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Purdue University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24532",children:"https://arxiv.org/pdf/2512.24532"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A two-stage approach for multi-step spatial reasoning that first fine-tunes an LLM on atomic spatial transformations and then trains lightweight LoRA adapters via RL to compose these blocks for planning. 2. The creation of a synthetic ASCII-art dataset and a corresponding ASCII-based RL environment to support training and evaluation. 3. Demonstration that the proposed method outperforms baselines in both dynamic and static environments, with faster convergence and more stable training than end-to-end RL."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of multi-step spatial reasoning in LLMs by proposing a two-stage method: first, supervised fine-tuning on basic spatial transformations to build physics awareness, and then training LoRA adapters with reinforcement learning (GRPO) to learn planning policies. The approach is evaluated using a custom ASCII-art environment and is shown to outperform various baselines, converging faster and more stably than training from scratch with RL."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>LLMs struggle with spatial transformations and multi-step planning]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Two-stage: SFT on spatial blocks, then RL (GRPO) with LoRA for planning]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Outperforms baselines, faster convergence, stable training]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [extreme quantization, double binary factorization, low-bit LLM, post-training quantization, binary matrix multiplication]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuma Ichikawa, Yoshihiko Fujisawa, Yudai Fujimoto, Akira Sakai, Katsuki Fujisawa"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24545",children:"https://arxiv.org/pdf/2512.24545"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Multi-Envelope Double Binary Factorization (MDBF), which replaces the single magnitude envelope in DBF with a rank-l envelope to enhance magnitude expressiveness while maintaining a shared binary sign carrier. 2. Introduced a closed-form initialization and an alternating refinement method to effectively optimize the MDBF parameters. 3. Demonstrated that MDBF improves perplexity and zero-shot accuracy over prior binary formats on LLaMA and Qwen models at matched bit budgets while preserving the same efficient inference primitive."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e17ec329eb54b789cd97cf9a3fc6db67786908aca3eb86af65de80d0797eb12_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e17ec329eb54b789cd97cf9a3fc6db67786908aca3eb86af65de80d0797eb12_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the performance saturation of Double Binary Factorization (DBF) in extreme low-bit quantization of LLMs, where a single magnitude envelope limits expressiveness. It proposes Multi-Envelope DBF (MDBF), which uses multiple envelope components to allocate more expressivity to magnitudes while keeping binary sign matrices shared. Experiments on LLaMA and Qwen families show MDBF outperforms previous binary formats in accuracy and perplexity at the same bit rate without changing the inference primitive."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>DBF scaling too restrictive,<br>single envelope causes<br>performance saturation"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Propose MDBF: shared 1-bit sign bases,<br>replace single envelope with<br>rank-l envelope"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Better perplexity & accuracy<br>over previous binary formats,<br>same inference primitive"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Localized Calibrated Uncertainty in Code Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [code generation], [calibrated uncertainty, minimal intent aligning patches, white-box probing, Brier Skill Score, AI oversight]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," David Gros, Prem Devanbu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of California, Davis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24560",children:"https://arxiv.org/pdf/2512.24560"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Creation of a dataset of "Minimal Intent Aligning Patches" for LLM-generated code repairs. 2. Proposal and evaluation of techniques (white-box probing, black-box reflective, self-consistency) for assigning well-calibrated, localized uncertainty to code segments. 3. Demonstration that a small supervisor probe can effectively estimate edit likelihood on code from much larger models and shows preliminary signs of generalization to natural language errors.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e04860e78fa5e50071d58627500e751c212bb40e58f4d01943c9ad0eda5c5a9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e04860e78fa5e50071d58627500e751c212bb40e58f4d01943c9ad0eda5c5a9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of LLM-generated code potentially deviating from user intent by proposing methods to localize where edits are likely needed. It introduces a dataset of minimal repair patches and compares techniques for assigning calibrated probabilities to code lines. The key finding is that a small white-box probing model can effectively estimate which lines will be edited, achieving good calibration and a Brier Skill Score of ~0.2, and shows some generalizability beyond code."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Localized Calibrated Uncertainty in Code Language Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u751f\u6210\u7684\u4ee3\u7801\u53ef\u80fd\u504f\u79bb\u7528\u6237\u610f\u56fe/LLM-generated code may deviate from user intent]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u521b\u5efa\u6700\u5c0f\u610f\u56fe\u5bf9\u9f50\u8865\u4e01\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u767d\u76d2\u63a2\u6d4b\u4e0e\u9ed1\u76d2\u65b9\u6cd5/Create Minimal Intent Aligning Patches dataset, compare white-box probing vs. black-box methods]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5c0f\u76d1\u7763\u6a21\u578b\u53ef\u5b9e\u73b0\u4f4e\u6821\u51c6\u8bef\u5dee\uff0cBrier Skill Score\u7ea60.2/Small supervisor model achieves low calibration error, Brier Skill Score ~0.2]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Model Context Protocol (MCP), LLM Agent, Benchmark, Tool Use, Dynamic Sandbox]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wenrui Liu, Zixiang Liu, Elsie Dai, Wenhan Yu, Lei Yu, Tong Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Peking University, Columbia University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24565",children:"https://arxiv.org/pdf/2512.24565"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," Github (2025)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MCPAgentBench, a benchmark based on real-world MCP definitions to evaluate agent tool-use capabilities. 2. Constructs a dataset with authentic tasks and simulated MCP tools, employing a dynamic sandbox environment with distractor tools. 3. Introduces comprehensive metrics to measure both task completion rates and execution efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088dcfaedc1cf43a859436433c7e392c2a6c7d8ccaf29c406871b6b794f77a2d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088dcfaedc1cf43a859436433c7e392c2a6c7d8ccaf29c406871b6b794f77a2d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitations of existing MCP evaluation sets by introducing MCPAgentBench, a benchmark that uses simulated MCP tools and a dynamic sandbox environment with distractors to test LLM agents' tool selection and execution abilities. Experiments on various LLMs reveal significant performance differences in handling complex, multi-step tool invocations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MCPAgentBench: A Real-world Task Benchmark for Evaluating LLM Agent MCP Tool Use] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709MCP\u8bc4\u4f30\u96c6\u4f9d\u8d56\u5916\u90e8\u670d\u52a1\u4e14\u7f3a\u4e4f\u96be\u5ea6\u611f\u77e5/Current MCP evaluations rely on external services and lack difficulty awareness]\n    C --\x3e C1[\u57fa\u4e8e\u771f\u5b9eMCP\u5b9a\u4e49\u6784\u5efa\u57fa\u51c6/Benchmark based on real-world MCP definitions]\n    C --\x3e C2[\u4f7f\u7528\u542b\u5e72\u6270\u9879\u7684\u52a8\u6001\u6c99\u76d2\u73af\u5883\u8bc4\u4f30/Evaluation using dynamic sandbox with distractors]\n    C --\x3e C3[\u5f15\u5165\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u6267\u884c\u6548\u7387\u7efc\u5408\u6307\u6807/Introducing comprehensive metrics for completion rate and efficiency]\n    D --\x3e D1[\u4e3b\u6d41\u5927\u6a21\u578b\u5728\u590d\u6742\u591a\u6b65\u5de5\u5177\u8c03\u7528\u4e0a\u8868\u73b0\u5dee\u5f02\u663e\u8457/Significant performance differences among LLMs on complex multi-step invocations]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] SynRAG: A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [SIEM, query generation, platform-agnostic specification, cross-platform, LLM framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Md Hasan Saju, Austin Page, Akramul Azim, Jeff Gardiner, Farzaneh Abazari, Frank Eargle"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ontario Tech University, GlassHouse Systems Inc."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24571",children:"https://arxiv.org/pdf/2512.24571"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SynRAG, a unified LLM framework for generating executable queries for heterogeneous SIEM systems from a single high-level specification. 2. Enables seamless threat detection and incident investigation across different SIEM platforms, reducing the need for specialized training. 3. Demonstrates superior performance compared to state-of-the-art base LLMs (GPT, Llama, etc.) in generating platform-specific queries for systems like Qradar and SecOps."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d87255708c71cdba68b8c5ca7054cc8216b56e3021254a7bbbd7c64c9a53687_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d87255708c71cdba68b8c5ca7054cc8216b56e3021254a7bbbd7c64c9a53687_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SynRAG, a framework that uses large language models to automatically generate platform-specific SIEM queries from a single, high-level, platform-agnostic specification. This addresses the challenge of monitoring diverse SIEM systems with different query languages. Evaluation shows SynRAG outperforms base LLMs in generating accurate queries for cross-platform threat detection and investigation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SynRAG: \u5f02\u6784SIEM\u7cfb\u7edf\u7684\u53ef\u6267\u884c\u67e5\u8be2\u751f\u6210\u6846\u67b6<br>SynRAG: Executable Query Generation in Heterogeneous SIEM Systems] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: SIEM\u5e73\u53f0\u591a\u6837\u6027\u5bfc\u81f4\u67e5\u8be2\u8bed\u8a00\u4e0d\u540c\uff0c\u5206\u6790\u5e08\u76d1\u63a7\u591a\u5e73\u53f0\u56f0\u96be<br>Problem: SIEM platform diversity leads to different query languages, making multi-platform monitoring difficult for analysts]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faSynRAG\u6846\u67b6\uff0c\u4ece\u5e73\u53f0\u65e0\u5173\u7684\u9ad8\u7ea7\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u7279\u5b9a\u5e73\u53f0\u67e5\u8be2<br>Method: Proposes SynRAG framework to auto-generate platform-specific queries from a platform-agnostic high-level specification]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: SynRAG\u751f\u6210\u7684\u67e5\u8be2\u4f18\u4e8eGPT\u3001Llama\u7b49\u5148\u8fdb\u57fa\u7840\u6a21\u578b<br>Results: SynRAG generates better queries than SOTA base models like GPT, Llama]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [chain-of-thought reasoning, attention heads, test-time intervention, computational efficiency, reasoning steering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhenyu Zhang, Xiaoxia Wu, Zhongzhu Zhou, Qingyang Wu, Yineng Zhang, Pragaash Ponnusamy, Harikaran Subbaraj, Jue Wang, Shuaiwen Leon Song, Ben Athiwaratkun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Texas at Austin, Together AI, University of Sydney"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24574",children:"https://arxiv.org/pdf/2512.24574"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/togethercomputer/CREST",children:"https://github.com/togethercomputer/CREST"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identified specialized attention heads in LLMs that correlate with distinct cognitive reasoning behaviors (e.g., verification, backtracking). 2. Proposed CREST, a training-free method for Cognitive REasoning Steering at Test-time, which involves offline calibration to find steering vectors and inference-time rotation to suppress unproductive reasoning. 3. Demonstrated that CREST improves reasoning accuracy and reduces token usage across diverse benchmarks, offering a pathway to faster and more reliable LLM inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7de1babf1bde06083c19ff84ab24d16f7280ee2cd3e28ae548f08be7f95a5882_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7de1babf1bde06083c19ff84ab24d16f7280ee2cd3e28ae548f08be7f95a5882_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the inefficiency and instability of long chain-of-thought reasoning in LLMs, which leads to high latency and alternating underthinking/overthinking. The authors propose CREST, a training-free method that identifies and steers specific attention heads at test-time to suppress unproductive cognitive behaviors. The method improves accuracy by up to 17.5% and reduces token usage by 37.6%, enabling faster and more reliable reasoning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u63a8\u7406\u8f68\u8ff9\u4f4e\u6548\u4e14\u4e0d\u7a33\u5b9a/Inefficient & Unstable LLM Reasoning Trajectories]\n    B1 --\x3e B2[\u8fc7\u5ea6\u601d\u8003\u4e0e\u601d\u8003\u4e0d\u8db3/Overthinking & Underthinking]\n    B1 --\x3e B3[\u9ad8\u5ef6\u8fdf\u4e0e\u9ad8\u4ee4\u724c\u6d88\u8017/High Latency & Token Usage]\n    C --\x3e C1[\u8bc6\u522b\u4e0e\u8ba4\u77e5\u884c\u4e3a\u76f8\u5173\u7684\u6ce8\u610f\u529b\u5934/Identify Cognitive Attention Heads]\n    C --\x3e C2[\u63d0\u51faCREST\u65b9\u6cd5: \u6d4b\u8bd5\u65f6\u8ba4\u77e5\u63a8\u7406\u5f15\u5bfc/Propose CREST: Test-time Cognitive REasoning Steering]\n    C2 --\x3e C3[\u79bb\u7ebf\u6821\u51c6\u83b7\u53d6\u5f15\u5bfc\u5411\u91cf/Offline Calibration for Steering Vectors]\n    C2 --\x3e C4[\u63a8\u7406\u65f6\u65cb\u8f6c\u9690\u85cf\u8868\u793a/Inference-time Representation Rotation]\n    D --\x3e D1[\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347/Accuracy Improved Up to 17.5%]\n    D --\x3e D2[\u4ee4\u724c\u4f7f\u7528\u5927\u5e45\u51cf\u5c11/Token Usage Reduced by 37.6%]\n    D --\x3e D3[\u5b9e\u73b0\u66f4\u5feb\u66f4\u53ef\u9760\u7684\u63a8\u7406/Enables Faster, More Reliable Reasoning]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Recursive Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [recursive language models, long-context processing, inference-time scaling, context condensation, out-of-core algorithms]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alex L. Zhang, Tim Kraska, Omar Khattab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," MIT CSAIL"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24601",children:"https://arxiv.org/pdf/2512.24601"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Recursive Language Models (RLMs), a general inference strategy that allows LLMs to programmatically examine, decompose, and recursively call themselves over long prompts. 2. Demonstrates that RLMs can handle inputs up to two orders of magnitude beyond standard model context windows. 3. Shows RLMs outperform base LLMs and existing long-context methods across diverse tasks while maintaining comparable or lower cost per query."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b76e3870cfbc09a08f87a31e423d89e08fb4d1e100fa580e4e6b58754309af5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b76e3870cfbc09a08f87a31e423d89e08fb4d1e100fa580e4e6b58754309af5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLMs struggling with arbitrarily long prompts due to limited context windows and context rot. It introduces Recursive Language Models (RLMs), an inference-time method that treats long prompts as an external environment, enabling recursive decomposition and processing. The results show RLMs effectively scale to inputs far beyond standard context limits and outperform baseline approaches in quality and cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Recursive Language Models] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs have limited context lengths and suffer from context rot with long prompts]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Recursive Language Models (RLMs) treat long prompts as an external environment, allowing programmatic examination and recursive self-calls]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: RLMs handle inputs up to 100x beyond context windows, outperform base LLMs and long-context scaffolds, with comparable or cheaper cost]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Dec-POMDP, CTDE, GRPO]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Dong Qiu, Duo Xu, Limengxi Yue"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," New England College, Northeastern University, University of Massachusetts Amherst"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24609",children:"https://arxiv.org/pdf/2512.24609"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A reinforcement learning-augmented LLM agent framework that formulates multi-agent collaboration as a Dec-POMDP and uses CTDE. 2. The introduction of Group Relative Policy Optimization (GRPO) for jointly optimizing agent policies with global training signals. 3. A simplified joint reward function that balances task quality, speed, and coordination cost."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/251d4cfbf0941a0b6ad2b2a8b7158ec06789c4a7a60653f447034ce562d8c91d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/251d4cfbf0941a0b6ad2b2a8b7158ec06789c4a7a60653f447034ce562d8c91d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of collaborative awareness in LLMs for multi-agent settings by proposing a framework that combines reinforcement learning with LLMs, using a Dec-POMDP formulation and CTDE. It introduces GRPO for policy optimization and a balanced reward function. The method significantly outperforms baselines in collaborative writing and coding tasks, demonstrating improved speed, consistency, and success rates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Reinforcement Learning-Augmented LLM Agents<br/>\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u7684LLM\u667a\u80fd\u4f53] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem<br/>LLMs lack collaborative awareness in multi-agent settings<br/>LLM\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u7f3a\u4e4f\u534f\u4f5c\u610f\u8bc6]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Dec-POMDP & CTDE framework with GRPO and a simplified joint reward<br/>\u57fa\u4e8eDec-POMDP\u548cCTDE\u7684\u6846\u67b6\uff0c\u4f7f\u7528GRPO\u548c\u7b80\u5316\u8054\u5408\u5956\u52b1]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results<br/>3x speedup, 98.7% writing consistency, 74.6% coding pass rate<br/>3\u500d\u901f\u5ea6\u63d0\u5347\uff0c98.7%\u5199\u4f5c\u4e00\u81f4\u6027\uff0c74.6%\u7f16\u7801\u901a\u8fc7\u7387]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent dialogue, role-based architecture, self-game mechanism, retrieval enhancement, proximal policy optimization]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zheyu Shi, Dong Qiu, Shanlong Yu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Brown University, New England College, Georgia Institute of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24613",children:"https://arxiv.org/pdf/2512.24613"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a three-level role division architecture (generation-verification-integration) for structured multi-agent collaboration in complex reasoning. 2. Introduced a self-game mechanism to expand multi-path reasoning trajectories and a retrieval enhancement module for dynamic external knowledge supplementation. 3. Designed a composite reward function and applied an improved proximal policy optimization strategy for collaborative training of the multi-agent system."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e250eb290183b556b4931328b4b20eb01ed043b916f7156301013ceb7995ab66_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e250eb290183b556b4931328b4b20eb01ed043b916f7156301013ceb7995ab66_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a group deliberation oriented multi-agent conversational model to enhance complex reasoning. The model employs a three-agent architecture for opinion generation, evidence verification, and consistency arbitration, augmented by a self-game mechanism and retrieval enhancement. Experiments show significant improvements in multi-hop reasoning accuracy and consistency over baseline models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Limitations of single LLMs in complex reasoning tasks]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Three-level role division, self-game mechanism, retrieval enhancement, composite reward & PPO training]\n    D[\u5173\u952e\u7ed3\u679c/Results: Improved multi-hop reasoning accuracy & consistency on HotpotQA, 2WikiMultihopQA, MeetingBank]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [hierarchical compression, compression-aware scaling law, decoupled \xb5P parametrization, concept space, adaptive semantic boundaries]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xingwei Qu, Shaowen Wang, Zihao Huang, Kai Hua, Fan Yin, Rui-Jie Zhu, Jundong Zhou, Qiyang Min, Zihao Wang, Yizhi Li, Tianyu Zhang, He Xing, Zheng Zhang, Yuxuan Song, Tianyu Zheng, Zhiyuan Zeng, Chenghua Lin, Ge Zhang, Wenhao Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ByteDance Seed, University of Manchester, Mila - Quebec AI Institute, Tsinghua University, M-A-P"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24617",children:"https://arxiv.org/pdf/2512.24617"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed Dynamic Large Concept Models (DLCM), a hierarchical language modeling framework that learns variable-length semantic concepts end-to-end and shifts computation from tokens to a compressed concept space for more efficient reasoning. 2. Introduced the first compression-aware scaling law that disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. 3. Developed a decoupled \xb5P parametrization for stable training of the heterogeneous architecture, supporting zero-shot hyperparameter transfer across model widths and compression regimes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dff9c61b225b5a86d535cfc752b13f390ae301473e649284a6815c3eaf80b24_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dff9c61b225b5a86d535cfc752b13f390ae301473e649284a6815c3eaf80b24_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the inefficiency of uniform token-level computation in LLMs by proposing Dynamic Large Concept Models (DLCM), which learns adaptive semantic concepts and reallocates compute to a higher-capacity reasoning backbone in a compressed concept space. This approach achieves a +2.69% average improvement across 12 zero-shot benchmarks under matched inference FLOPs."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs apply uniform computation to tokens, wasting capacity on predictable spans and under-allocating to critical transitions]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Hierarchical framework learns semantic boundaries, shifts computation to compressed concept space, introduces compression-aware scaling law and decoupled \xb5P parametrization]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: +2.69% average improvement on 12 zero-shot benchmarks under matched inference FLOPs with R=4 compression]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Chat-Driven Optimal Management for Virtual Network Services"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [intent-based networking, virtual network allocation, integer linear programming, Sentence-BERT, large language model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuya Miyaoka, Masaki Inoue, Kengo Urata, Shigeaki Harada"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Keio University, NTT Inc."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24614",children:"https://arxiv.org/pdf/2512.24614"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel two-stage chat-driven framework that integrates NLP-based intent extraction with optimization-based allocation for virtual network management. 2. Introduces and compares two intent extractors: a low-latency Sentence-BERT with SVM classifier and a high-accuracy LLM-based model. 3. Demonstrates the framework's ability to dynamically and feasibly update VM placement and routing in both single-user and multi-user settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dd7600e3aadf99d8f0d2549d3d65d3c00bce80acbf6105aef79f0c8a797c126_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dd7600e3aadf99d8f0d2549d3d65d3c00bce80acbf6105aef79f0c8a797c126_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of conventional intent-based networking, which cannot guarantee feasible configurations, by proposing a chat-driven framework. The framework uses an NLP Interpreter to extract user intent and an optimization-based Optimizer to compute feasible VM placement and routing. The results show that combining NLP with optimization enables safe, interpretable, and user-friendly network management, with an LLM-based extractor offering higher accuracy and a Sentence-BERT/SVM extractor providing lower latency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Chat-Driven Optimal Management for Virtual Network Services] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Conventional IBN cannot guarantee configuration feasibility] --\x3e P1[\u4f20\u7edfIBN\u65b9\u6cd5/Traditional IBN Methods]\n    P1 --\x3e P2[\u4f9d\u8d56\u7edf\u8ba1\u8bed\u8a00\u6a21\u578b/Rely on statistical language models]\n    P2 --\x3e P3[\u65e0\u6cd5\u4fdd\u8bc1\u53ef\u884c\u6027/Cannot guarantee feasibility]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Two-stage NLP + Optimization Framework] --\x3e M1[\u9636\u6bb51: \u89e3\u91ca\u5668/Stage 1: Interpreter]\n    M1 --\x3e M2[\u63d0\u53d6\u7528\u6237\u610f\u56fe/Extract user intent from chat]\n    M2 --\x3e M3[\u4f7f\u7528NLP\u6a21\u578b/Use NLP models (Sentence-BERT+SVM or LLM)]\n    Method --\x3e M4[\u9636\u6bb52: \u4f18\u5316\u5668/Stage 2: Optimizer]\n    M4 --\x3e M5[\u8ba1\u7b97\u53ef\u884c\u914d\u7f6e/Compute feasible configuration]\n    M5 --\x3e M6[\u4f7f\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212/Use Integer Linear Programming]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u52a8\u6001\u66f4\u65b0VM\u653e\u7f6e\u548c\u8def\u7531/Dynamically updates VM placement & routing]\n    R1 --\x3e R2[\u4fdd\u6301\u53ef\u884c\u6027/Preserves feasibility]\n    Results --\x3e R3[LLM\u63d0\u53d6\u5668: \u9ad8\u7cbe\u5ea6/LLM Extractor: High accuracy with few samples]\n    Results --\x3e R4[Sentence-BERT+SVM: \u4f4e\u5ef6\u8fdf/Sentence-BERT+SVM: Low latency for real-time]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [LLM agent framework, automated agent generation, hybrid policy optimization, in-context optimization, reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"}),' Tencent (inferred from "TencentCloudADP" in GitHub URL)']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24615",children:"https://arxiv.org/pdf/2512.24615"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/TencentCloudADP/youtu-agent",children:"https://github.com/TencentCloudADP/youtu-agent"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. A modular LLM agent framework (Youtu-Agent) with a structured configuration system for decoupling components and enabling automated synthesis. 2. Two agent generation paradigms: Workflow mode for standard tasks and Meta-Agent mode for complex tasks, capable of auto-generating tools and prompts. 3. A hybrid policy optimization system combining an in-context learning "Agent Practice" module and a scalable reinforcement learning "Agent RL" module for continuous agent evolution.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0414a5769d966ffb5a9f4428d4a182e5095ba0b107862d50c8224788df0caa46_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0414a5769d966ffb5a9f4428d4a182e5095ba0b107862d50c8224788df0caa46_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Youtu-Agent, a framework to automate the generation and continuous optimization of LLM agents, addressing high configuration costs and static capabilities. It introduces structured configuration, automated generation paradigms, and a hybrid optimization system combining in-context learning and reinforcement learning. Experiments show state-of-the-art performance on several benchmarks and significant improvements in agent capabilities through automated synthesis and optimization."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Youtu-Agent] --\x3e B[\u6838\u5fc3\u95ee\u9898 / Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5 / Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c / Results]\n    B --\x3e B1[\u9ad8\u914d\u7f6e\u6210\u672c / High Configuration Cost]\n    B --\x3e B2[\u9759\u6001\u80fd\u529b / Static Capabilities]\n    C --\x3e C1[\u7ed3\u6784\u5316\u914d\u7f6e\u7cfb\u7edf / Structured Configuration System]\n    C --\x3e C2[\u81ea\u52a8\u5316\u751f\u6210 / Automated Generation]\n    C --\x3e C21[\u5de5\u4f5c\u6d41\u6a21\u5f0f / Workflow Mode]\n    C --\x3e C22[\u5143\u667a\u80fd\u4f53\u6a21\u5f0f / Meta-Agent Mode]\n    C --\x3e C3[\u6df7\u5408\u7b56\u7565\u4f18\u5316 / Hybrid Policy Optimization]\n    C --\x3e C31[\u667a\u80fd\u4f53\u5b9e\u8df5 / Agent Practice]\n    C --\x3e C32[\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60 / Agent RL]\n    D --\x3e D1[SOTA\u6027\u80fd / SOTA Performance]\n    D --\x3e D2[\u9ad8\u5de5\u5177\u5408\u6210\u7387 / High Tool Synthesis Rate]\n    D --\x3e D3[\u80fd\u529b\u663e\u8457\u63d0\u5347 / Significant Capability Improvement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [personalized federated learning, prompt learning, traffic prediction, non-IID data, hyper-parameter tuning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zijian Zhao, Yitong Shang, Sen Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Hong Kong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24625",children:"https://arxiv.org/pdf/2512.24625"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/RS2002/AutoFed",children:"https://github.com/RS2002/AutoFed"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AutoFed, a novel Personalized Federated Learning (PFL) framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. 2. Introduces a federated representor with a client-aligned adapter to distill local data into a compact, globally shared prompt matrix, inspired by prompt learning. 3. Demonstrates through extensive experiments that AutoFed consistently achieves superior performance across diverse real-world traffic prediction scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e572784e0dff554ff14fce989febaa7869bdfb488d60b6fd86ebd7e98cdf0bf7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e572784e0dff554ff14fce989febaa7869bdfb488d60b6fd86ebd7e98cdf0bf7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes AutoFed, a manual-free Personalized Federated Learning framework for traffic prediction that uses a client-aligned adapter to generate a shared prompt matrix, enabling knowledge sharing while preserving local specificity. Experiments on real-world datasets show that AutoFed achieves superior performance without requiring manual hyper-parameter tuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u5b64\u5c9b\u4e0e\u9690\u79c1\u95ee\u9898 / Data Silos & Privacy]\n    B --\x3e B2[\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e / Non-IID Data]\n    B --\x3e B3[\u624b\u52a8\u8d85\u53c2\u6570\u8c03\u4f18 / Manual Hyper-parameter Tuning]\n    C --\x3e C1[\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60 / Personalized Federated Learning (PFL)]\n    C --\x3e C2[\u63d0\u793a\u5b66\u4e60 / Prompt Learning]\n    C --\x3e C3[\u8054\u90a6\u8868\u5f81\u5668\u4e0e\u5ba2\u6237\u7aef\u5bf9\u9f50\u9002\u914d\u5668 / Federated Representor & Client-Aligned Adapter]\n    D --\x3e D1[\u6027\u80fd\u4f18\u8d8a / Superior Performance]\n    D --\x3e D2[\u65e0\u9700\u624b\u52a8\u8c03\u53c2 / No Manual Tuning]\n    D --\x3e D3[\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1 / Validated on Real-world Datasets]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [medical audio classification], [hierarchical classification, acoustic biomarkers, mel-spectrograms, voice disorders, sustained vowels]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mohsen Annabestani, Samira Aghadoost, Anais Rameau, Olivier Elemento, Gloria Chia-Yi Chiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Weill Cornell Medicine"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24628",children:"https://arxiv.org/pdf/2512.24628"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel three-stage hierarchical machine learning framework for voice disorder classification that mirrors clinical triage workflows, integrating deep spectral features with interpretable acoustic biomarkers. 2. The proposed system outperforms flat multi-class classifiers and state-of-the-art pre-trained self-supervised audio models (HuBERT, HeAR) on the task of classifying benign laryngeal disorders from sustained vowels. 3. Demonstrates the potential of combining deep learning representations with clinically interpretable features to enhance transparency and alignment for scalable, non-invasive vocal health screening and monitoring."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a53018a32ff94f55161f7c3e6f57843d9d248636c6146e968b0832ca7fdb34b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a53018a32ff94f55161f7c3e6f57843d9d248636c6146e968b0832ca7fdb34b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a hierarchical AI framework to classify benign laryngeal voice disorders from short, sustained vowel recordings. The method uses a three-stage pipeline combining CNN-derived mel-spectrogram features with interpretable acoustic biomarkers, outperforming standard multi-class and pre-trained audio models. The results highlight the framework's potential as a scalable tool for early voice disorder screening and diagnostic triage."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u826f\u6027\u5589\u90e8\u55d3\u97f3\u75be\u75c5\u5206\u7c7b/Benign Laryngeal Voice Disorder Classification]\n    C --\x3e C1[\u4e09\u7ea7\u5206\u5c42\u673a\u5668\u5b66\u4e60\u6846\u67b6/Three-Stage Hierarchical ML Framework]\n    C1 --\x3e C1_1[\u9636\u6bb51: \u75c5\u7406\u7b5b\u67e5/Stage 1: Pathological Screening]\n    C1 --\x3e C1_2[\u9636\u6bb52: \u7c97\u7c92\u5ea6\u5206\u5c42/Stage 2: Coarse Stratification]\n    C1 --\x3e C1_3[\u9636\u6bb53: \u7ec6\u7c92\u5ea6\u5206\u7c7b/Stage 3: Fine-Grained Classification]\n    C1_1 --\x3e C1_1a[\u878d\u5408CNN\u6885\u5c14\u8c31\u7279\u5f81\u4e0e21\u79cd\u58f0\u5b66\u751f\u7269\u6807\u5fd7\u7269/Integrates CNN Mel-Spectrogram & 21 Acoustic Biomarkers]\n    D --\x3e D1[\u6027\u80fd\u4f18\u4e8e\u5e73\u9762\u591a\u7c7b\u5206\u7c7b\u5668\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b/Outperforms Flat Classifiers & Pre-trained Models (HuBERT, HeAR)]\n    D --\x3e D2[\u7ed3\u5408\u6df1\u5ea6\u8868\u5f81\u4e0e\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u589e\u5f3a\u4e34\u5e8a\u53ef\u64cd\u4f5c\u6027/Enhances Transparency & Clinical Alignment via Deep & Interpretable Features]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [se], [automated program repair], [large language models, dynamic analysis, iterative repair, execution-level information, Defects4J]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhili Huang, Ling Xu, Chao Liu, Weifeng Sun, Xu Zhang, Yan Lei, Meng Yan, Hongyu Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Chongqing University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24635",children:"https://arxiv.org/pdf/2512.24635"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes DynaFix, a novel APR method that iteratively leverages fine-grained, execution-level dynamic information (e.g., variable states, control-flow) to guide LLMs in patch generation. 2. Introduces an iterative repair loop where failed patches trigger re-execution to collect updated runtime feedback, mimicking human stepwise debugging. 3. Demonstrates significant effectiveness and efficiency improvements, repairing 186 bugs (10% more than SOTA) and reducing patch search space by 70% on Defects4J benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ca5f82c2ff7a5874dfaa7c320c9097716fe0d1514eca3eb69291b75f1a981d7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ca5f82c2ff7a5874dfaa7c320c9097716fe0d1514eca3eb69291b75f1a981d7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes DynaFix, an automated program repair method that iteratively uses execution-level dynamic information (like variable states) to guide large language models in generating patches. This approach mimics human debugging by refining patches based on runtime feedback from failed attempts. Evaluation on Defects4J shows it repairs more bugs and reduces the search space more effectively than existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709APR\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u5206\u6790\u6216\u7c97\u7c92\u5ea6\u53cd\u9988\uff0c\u96be\u4ee5\u6a21\u62df\u4eba\u7c7b\u9010\u6b65\u8c03\u8bd5/Existing APR relies on static or coarse feedback, failing to simulate stepwise debugging]\n    C --\x3e C1[\u8fed\u4ee3\u6355\u83b7\u6267\u884c\u7ea7\u52a8\u6001\u4fe1\u606f\uff08\u53d8\u91cf\u72b6\u6001\u3001\u63a7\u5236\u6d41\u7b49\uff09\u6307\u5bfcLLM\u751f\u6210\u8865\u4e01/Iteratively captures execution-level info (variable states, control flow) to guide LLM patch generation]\n    D --\x3e D1[\u4fee\u590dDefects4J\u4e2d186\u4e2abug\uff0c\u6027\u80fd\u63d0\u534710%/Repairs 186 bugs on Defects4J, 10% improvement over SOTA]\n    D --\x3e D2[\u5c06\u8865\u4e01\u641c\u7d22\u7a7a\u95f4\u51cf\u5c1170%/Reduces patch search space by 70%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [robot navigation], [hybrid motion planning, deep reinforcement learning, entity-aware reward, graph-based global planner, collision avoidance]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yury Kolomeytsev, Dmitry Golembiovsky"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Lomonosov Moscow State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24651",children:"https://arxiv.org/pdf/2512.24651"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes HMP-DRL, a hybrid framework integrating a graph-based global planner with a local DRL policy via checkpoints. 2. Introduces an entity-aware reward structure for the local planner to ensure social compliance by adjusting safety based on agent type. 3. Validates the method in a realistic simulation, showing superior performance in success rate, collision rate, and time to goal."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6963a6e6a0df2bf9e5857d6154c70386d9271eb85763359a237ce12c4881bec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes HMP-DRL, a hybrid motion planning framework that combines a graph-based global planner for long-range pathfinding with a local Deep Reinforcement Learning policy for reactive, socially-compliant navigation. The method uses checkpoints to integrate the global path and an entity-aware reward function to dynamically adjust to different moving agents. Experiments in realistic simulation show it outperforms other methods in key navigation metrics, enhancing safety and reliability in complex environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Hybrid Motion Planning with Deep Reinforcement Learning for Mobile Robot Navigation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4f20\u7edf\u56fe\u89c4\u5212\u5668\u7f3a\u4e4f\u53cd\u5e94\u6027/Traditional graph planners lack reactivity]\n    B --\x3e B2[\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587/DRL methods lack global context]\n    C --\x3e C1[\u6df7\u5408\u6846\u67b6HMP-DRL/Hybrid framework HMP-DRL]\n    C1 --\x3e C2[\u56fe\u89c4\u5212\u5668\u751f\u6210\u8def\u5f84/Graph planner generates path]\n    C1 --\x3e C3[\u5c40\u90e8DRL\u7b56\u7565\u4f7f\u7528\u68c0\u67e5\u70b9\u548c\u5b9e\u4f53\u611f\u77e5\u5956\u52b1/Local DRL policy uses checkpoints & entity-aware reward]\n    D --\x3e D1[\u66f4\u9ad8\u7684\u6210\u529f\u7387/Higher success rate]\n    D --\x3e D2[\u66f4\u4f4e\u7684\u78b0\u649e\u7387/Lower collision rate]\n    D --\x3e D3[\u66f4\u77ed\u7684\u5230\u8fbe\u65f6\u95f4/Shorter time to goal]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Do Large Language Models Know What They Are Capable Of?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [llm evaluation], [in-advance confidence, overconfidence, capability awareness, decision-making, agentic tasks]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Casey O. Barkan, Sid Black, Oliver Sourbut"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," RAND Corporation, UK AI Security Institute, The Future of Life Foundation"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24661",children:"https://arxiv.org/pdf/2512.24661"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Evaluates LLMs' in-advance confidence and its impact on decision-making in costly-failure scenarios, a less studied area compared to after-the-fact calibration. 2. Investigates how LLMs' confidence and overconfidence evolve during multi-step agentic tasks and with in-context failure experiences. 3. Demonstrates that while LLMs' decisions are rational given their self-estimates, their systematic overconfidence leads to poor task pursuit decisions, highlighting a lack of capability awareness."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c758274cef27c9ad79258c27a063b8420cef801a9f25ff7610a7c4c12509a926_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c758274cef27c9ad79258c27a063b8420cef801a9f25ff7610a7c4c12509a926_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether large language models (LLMs) can accurately predict their own success on tasks, especially when failure is costly. It evaluates their in-advance confidence, how it changes during multi-step tasks and with in-context failure, and its impact on decision-making. The main finding is that current LLMs are generally overconfident, which impairs their decision-making despite rational behavior based on their flawed self-assessments, indicating a lack of self-awareness of their capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Do Large Language Models Know What They Are Capable Of?] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u80fd\u5426\u9884\u6d4b\u81ea\u8eab\u4efb\u52a1\u6210\u529f\u7387?<br/>Can LLMs predict their task success?]\n    B --\x3e B2[\u5931\u8d25\u6210\u672c\u9ad8\u65f6\u5982\u4f55\u51b3\u7b56?<br/>How to decide when failure is costly?]\n    C --\x3e C1[\u8bc4\u4f30\u4e8b\u524d\u7f6e\u4fe1\u5ea6<br/>Evaluate in-advance confidence]\n    C --\x3e C2[\u5206\u6790\u591a\u6b65\u9aa4\u4efb\u52a1\u4e2d\u7684\u4fe1\u5fc3\u53d8\u5316<br/>Analyze confidence change in multi-step tasks]\n    C --\x3e C3[\u7814\u7a76\u4e0a\u4e0b\u6587\u5931\u8d25\u7ecf\u9a8c\u7684\u5f71\u54cd<br/>Study impact of in-context failure]\n    D --\x3e D1[LLMs\u666e\u904d\u8fc7\u5ea6\u81ea\u4fe1<br/>LLMs are generally overconfident]\n    D --\x3e D2[\u65b0/\u5927\u6a21\u578b\u5224\u522b\u529b\u672a\u663e\u8457\u63d0\u5347<br/>Newer/larger models don't have greater discriminatory power]\n    D --\x3e D3[\u90e8\u5206\u6a21\u578b\u80fd\u4ece\u5931\u8d25\u4e2d\u5b66\u4e60<br/>Some models learn from failure]\n    D --\x3e D4[\u51b3\u7b56\u7406\u6027\u4f46\u4f30\u8ba1\u8fc7\u4e8e\u4e50\u89c2<br/>Decisions rational but estimates overly optimistic]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Renormalization Group Guided Tensor Network Structure Search"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [tensor network structure search, renormalization group, multi-scale optimization, edge gates, node tension]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maolin Wang, Bowen Yu, Sheng Zhang, Linjie Mi, Wanyu Wang, Yiqi Wang, Pengyue Jia, Xuetao Wei, Zenglin Xu, Ruocheng Guo, Xiangyu Zhao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," City University of Hong Kong, National University of Defense Technology, Southern University of Science and Technology, Fudan University, Intuit AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24663",children:"https://arxiv.org/pdf/2512.24663"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Applied-Machine-Learning-Lab/RGTN",children:"https://github.com/Applied-Machine-Learning-Lab/RGTN"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RGTN, a physics-inspired framework that uses multi-scale renormalization group flows for continuous tensor network structure evolution, overcoming the limitations of fixed-scale, discrete search methods. 2. Introduces learnable edge gates for dynamic topology modification and intelligent proposals based on physical quantities like node tension and edge information flow to guide the search. 3. Demonstrates state-of-the-art performance, achieving superior compression ratios and running 4-600 times faster than existing methods on tasks like light field data and video completion."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9fdccc30b2aad8da00c1fdf132004ba3347f8992425dfb71406c3fa11d073c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9fdccc30b2aad8da00c1fdf132004ba3347f8992425dfb71406c3fa11d073c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of existing Tensor Network Structure Search (TN-SS) methods, which struggle with computational tractability and structure adaptivity. The authors propose RGTN, a novel framework guided by renormalization group theory, which enables multi-scale, continuous structure optimization. Experiments show RGTN achieves better compression and is significantly faster than prior methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Renormalization Group Guided Tensor Network Structure Search] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709TN-SS\u65b9\u6cd5\u5c40\u9650/Limitations of existing TN-SS]\n    P1 --\x3e P1_1[\u5355\u5c3a\u5ea6\u4f18\u5316/Single-scale optimization]\n    P1 --\x3e P1_2[\u79bb\u6563\u641c\u7d22\u7a7a\u95f4/Discrete search space]\n    P1 --\x3e P1_3[\u5206\u79bb\u7684\u7ed3\u6784-\u53c2\u6570\u4f18\u5316/Separated structure-parameter optimization]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[RGTN\u6846\u67b6/RGTN Framework]\n    M1 --\x3e M1_1[\u591a\u5c3a\u5ea6\u91cd\u6574\u5316\u7fa4\u6d41/Multi-scale RG flows]\n    M1 --\x3e M1_2[\u53ef\u5b66\u4e60\u8fb9\u95e8/Learnable edge gates]\n    M1 --\x3e M1_3[\u667a\u80fd\u63d0\u6848(\u8282\u70b9\u5f20\u529b, \u8fb9\u4fe1\u606f\u6d41)/Intelligent proposals (node tension, edge info flow)]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[SOTA\u538b\u7f29\u6bd4/State-of-the-art compression ratio]\n    Results --\x3e R2[4-600\u500d\u52a0\u901f/4-600x speedup]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [domain generalization], [multi-modal fusion, feature disentanglement, domain-invariant representation, cross-domain mixing, unseen working conditions]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pengcheng Xia, Yixiang Huang, Chengjin Qin, Chengliang Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24679",children:"https://arxiv.org/pdf/2512.24679"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/xiapc1996/MMDG",children:"https://github.com/xiapc1996/MMDG"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A dual disentanglement framework to separate modality-invariant/specific and domain-invariant/specific features. 2. A cross-domain mixed fusion strategy to augment data diversity by randomly mixing modality information across domains. 3. A triple-modal fusion mechanism to adaptively integrate heterogeneous multi-modal information."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afcd4bf3933b539ef0ff25f07453c8a5bf8bac90477ba90fdbe4c834d24627de_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afcd4bf3933b539ef0ff25f07453c8a5bf8bac90477ba90fdbe4c834d24627de_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a multi-modal fusion model with dual feature disentanglement to address the problem of fault diagnosis under unseen working conditions. The method decouples modality and domain features and uses cross-domain mixing to improve generalization. Experiments on motor fault diagnosis show it outperforms existing methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Multi-modal Cross-domain Mixed Fusion Model / \u591a\u6a21\u6001\u8de8\u57df\u6df7\u5408\u878d\u5408\u6a21\u578b"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u6027\u80fd\u4e0b\u964d\u5728\u672a\u89c1\u5de5\u51b5 / Performance decline under unseen conditions"]\n    Problem --\x3e P2["\u5355\u6a21\u6001\u4fe1\u606f\u5c40\u9650 / Single-modal limitation"]\n    Method --\x3e M1["\u53cc\u91cd\u89e3\u8026\u6846\u67b6 / Dual Disentanglement Framework"]\n    Method --\x3e M2["\u8de8\u57df\u6df7\u5408\u878d\u5408 / Cross-domain Mixed Fusion"]\n    Method --\x3e M3["\u4e09\u6a21\u6001\u878d\u5408 / Triple-modal Fusion"]\n    Results --\x3e R1["\u4f18\u4e8e\u5148\u8fdb\u65b9\u6cd5 / Outperforms advanced methods"]\n    Results --\x3e R2["\u6d88\u878d\u9a8c\u8bc1\u6709\u6548\u6027 / Ablation verifies effectiveness"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [VLA models, action chunking, trajectory smoothing, asynchronous inference, robot motion control]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yongsheng Zhao, Lei Zhao, Baoping Cheng, Gongxin Yao, Xuanzhang Wen, Han Gao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," China Mobile (Hangzhou) Information Technology Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24673",children:"https://arxiv.org/pdf/2512.24673"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes VLA-RAIL, a framework for asynchronous inference and motion control to enable smooth, continuous robot action execution. 2. Introduces a Trajectory Smoother using polynomial fitting to filter noise and jitter within an action chunk. 3. Designs a Chunk Fuser to ensure position, velocity, and acceleration continuity between successive action chunks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/886e2a128c843b55a605e8cbe2a7b174fc4b0e84225f1908b0b180891d09bdad_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/886e2a128c843b55a605e8cbe2a7b174fc4b0e84225f1908b0b180891d09bdad_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of motion jitter, stalling, and pauses when deploying Vision-Language-Action (VLA) models on robots due to sequential inference and execution. It proposes VLA-RAIL, a framework that decouples model inference from robot control via a Trajectory Smoother and Chunk Fuser. Experiments show it reduces jitter, increases speed, and improves task success rates for robotic manipulation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[VLA-RAIL: A Real-Time Asynchronous Inference Linker] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u5bfc\u81f4\u673a\u5668\u4eba\u52a8\u4f5c\u6296\u52a8\u3001\u5361\u987f/Existing methods cause jitter, stalling in robot actions]\n    C --\x3e C1[\u5f02\u6b65\u63a8\u7406\u4e0e\u8fd0\u52a8\u63a7\u5236/Asynchronous inference & motion control]\n    C1 --\x3e C2[\u8f68\u8ff9\u5e73\u6ed1\u5668/Trajectory Smoother]\n    C1 --\x3e C3[\u5757\u878d\u5408\u5668/Chunk Fuser]\n    D --\x3e D1[\u51cf\u5c11\u8fd0\u52a8\u6296\u52a8/Reduces motion jitter]\n    D --\x3e D2[\u63d0\u5347\u6267\u884c\u901f\u5ea6/Enhances execution speed]\n    D --\x3e D3[\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387/Improves task success rates]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [computational argumentation], [retrieval-augmented generation, argumentative memory, multi-turn debate, agentic framework, rhetorical grounding]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Maoyuan Li, Zhongsheng Wang, Haoyuan Li, Jiamou Liu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Auckland, Wuhan College of Communication"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24684",children:"https://arxiv.org/pdf/2512.24684"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://anonymous.4open.science/r/R-debater-E87F/",children:"https://anonymous.4open.science/r/R-debater-E87F/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes R-Debater, a novel agentic framework for multi-turn debate generation grounded in the concept of "argumentative memory" from rhetoric and memory studies. 2. Integrates a debate knowledge base for retrieving evidence and prior arguments with a role-based agent to ensure stance consistency and coherent multi-turn composition. 3. Demonstrates superior performance over strong LLM baselines in both single-turn and multi-turn debate tasks through automated metrics (InspireScore, Debatrix) and human evaluation with experienced debaters.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/987d8c7f9f1e27feb6f7eff24aacab0f5dd1eb3b83c76e27f254c97c97b4c0b3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/987d8c7f9f1e27feb6f7eff24aacab0f5dd1eb3b83c76e27f254c97c97b4c0b3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper presents R-Debater, a framework that generates multi-turn debates by retrieving and adapting arguments from a knowledge base ("argumentative memory") using a role-based agent. Evaluated on ORCHID debates, it outperforms LLM baselines in producing more consistent, evidence-grounded, and coherent debates across turns.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[R-Debater: Retrieval-Augmented Debate Generation] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs generate fluent but shallow, ungrounded debates with weak stance fidelity]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic framework with argumentative memory for retrieval & role-based utterance composition]\n    D[\u5173\u952e\u7ed3\u679c/Results: Higher scores than LLM baselines; more faithful, stance-aligned, coherent debates]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [physics-informed features, SHAP, Gradient Boosting Decision Trees, LLM reasoning, fault diagnosis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Songqi Zhou, Ruixue Liu, Boman Su, Jiazhou Wang, Yixing Wang, Benben Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24686",children:"https://arxiv.org/pdf/2512.24686"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes BatteryAgent, a hierarchical framework integrating physics-based features with LLM reasoning for interpretable battery fault diagnosis. 2. Introduces a "numerical-semantic" bridge using SHAP attributions and a knowledge base to generate comprehensive diagnostic reports with root cause analysis. 3. Demonstrates superior performance (AUROC 0.986) and extends binary detection to multi-type, interpretable diagnosis, shifting from passive detection to intelligent diagnosis.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3462edc6bdbdfb2b93fa0ef560df4483fbef65600fac566e9e76c08059dd4f31_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3462edc6bdbdfb2b93fa0ef560df4483fbef65600fac566e9e76c08059dd4f31_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes BatteryAgent, a framework that combines physics-informed features, Gradient Boosting Decision Trees with SHAP, and an LLM agent to diagnose lithium-ion battery faults. It achieves high accuracy (AUROC 0.986) and provides interpretable reports with root causes and maintenance suggestions, moving beyond simple binary classification."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u9ed1\u76d2\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027/Black-box models lack interpretability]\n    B --\x3e B2[\u4e8c\u5143\u5206\u7c7b\u65e0\u6cd5\u63d0\u4f9b\u6839\u56e0\u5206\u6790/Binary classification lacks root cause analysis]\n    C --\x3e C1[\u7269\u7406\u611f\u77e5\u5c42\u63d0\u53d6\u7279\u5f81/Physical Perception Layer extracts features]\n    C --\x3e C2[\u68c0\u6d4b\u5f52\u56e0\u5c42\u91cf\u5316\u8d21\u732e/Detection & Attribution Layer quantifies contributions]\n    C --\x3e C3[\u63a8\u7406\u8bca\u65ad\u5c42\u751f\u6210\u62a5\u544a/Reasoning & Diagnosis Layer generates reports]\n    D --\x3e D1[\u9ad8\u7cbe\u5ea6AUROC 0.986/High accuracy AUROC 0.986]\n    D --\x3e D2[\u7ea0\u6b63\u56f0\u96be\u6837\u672c/Misclassification correction on hard samples]\n    D --\x3e D3[\u5b9e\u73b0\u667a\u80fd\u8bca\u65ad/Enables intelligent diagnosis]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Nested Learning: The Illusion of Deep Learning Architectures"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [learning theory], [nested learning, in-context learning, continual learning, associative memory, self-modifying model]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, Vahab Mirrokni"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google Research (inferred from authors Ali Behrouz, Meisam Razaviyayn, Peilin Zhong, and Vahab Mirrokni, who are affiliated with Google)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24695",children:"https://arxiv.org/pdf/2512.24695"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Expressive Optimizers: Shows gradient-based optimizers are associative memory modules and proposes more expressive variants with deeper memory and learning rules. 2. Self-Modifying Learning Module: Presents a sequence model that learns to modify itself by learning its own update algorithm. 3. Continuum Memory System: Introduces a new memory formulation generalizing long/short-term memory, which is combined with the self-modifying model to create "Hope", a continual learning module.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aac4e338b76a10773a96b12a072d809a81c99a79e63d8b40927cb078da7b7fdb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aac4e338b76a10773a96b12a072d809a81c99a79e63d8b40927cb078da7b7fdb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper proposes a new learning paradigm called Nested Learning (NL), which frames machine learning models as nested optimization problems. This view explains the emergence of in-context learning and is used to design more expressive optimizers, a self-modifying model, and a new memory system, culminating in a continual learning module named "Hope" that shows promising results on various tasks.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Nested Learning: The Illusion of Deep Learning Architecture] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5982\u4f55\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u4e0e\u81ea\u6211\u6539\u8fdb/How to achieve continual learning and self-improvement]\n    C --\x3e C1[\u5d4c\u5957\u5b66\u4e60\u8303\u5f0f/Nested Learning Paradigm]\n    C --\x3e C2[\u8bbe\u8ba1\u8868\u8fbe\u6027\u4f18\u5316\u5668/Design Expressive Optimizers]\n    C --\x3e C3[\u81ea\u4fee\u6539\u5b66\u4e60\u6a21\u5757/Self-Modifying Learning Module]\n    C --\x3e C4[\u8fde\u7eed\u4f53\u8bb0\u5fc6\u7cfb\u7edf/Continuum Memory System]\n    D --\x3e D1[\u63d0\u51fa\u6301\u7eed\u5b66\u4e60\u6a21\u5757Hope/Propose continual learning module Hope]\n    D --\x3e D2[\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u5c55\u793a\u6f5c\u529b/Show potential on multiple tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-task learning], [multi-armed bandit, negative transfer, auxiliary task selection, multi-bandit framework, drug-target interaction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Andr\xe1s Millinghoffer, Andr\xe1s Formanek, Andr\xe1s Antos, P\xe9ter Antal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Budapest University of Technology and Economics, E-Group ICT Software Zrt., KU Leuven"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24708",children:"https://arxiv.org/pdf/2512.24708"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A three-stage method (BandiK) for efficient auxiliary task subset selection in multi-task learning, 2. Reduction of candidate auxiliary sets from exponential to linear complexity using pairwise transfer estimations, 3. A novel multi-bandit framework that exploits semi-overlapping arms across tasks to improve computational efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e49fedc6c9b07cd38435ef8daff0ba16207d6088f86e049c77cd192822bd2cf_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e49fedc6c9b07cd38435ef8daff0ba16207d6088f86e049c77cd192822bd2cf_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces BandiK, a three-stage method using multi-armed bandits to efficiently select beneficial auxiliary task subsets in multi-task learning, reducing computational cost by estimating pairwise transfers and leveraging a multi-bandit structure. It is validated on a drug-target interaction benchmark, showing scalable performance for complex multi-task scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u8d1f\u8fc1\u79fb\u548c\u8f85\u52a9\u4efb\u52a1\u9009\u62e9\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u4e0e\u590d\u6742\u6027]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u4e09\u9636\u6bb5\u591a\u81c2\u8001\u864e\u673a\u6846\u67b6\uff0c\u4f30\u8ba1\u4efb\u52a1\u95f4\u8f6c\u79fb\u3001\u6784\u5efa\u7ebf\u6027\u5019\u9009\u96c6\u3001\u5229\u7528\u534a\u91cd\u53e0\u81c2\u7684\u591a\u8001\u864e\u673a\u7ed3\u6784]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u836f\u7269-\u9776\u70b9\u76f8\u4e92\u4f5c\u7528\u57fa\u51c6\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u4efb\u52a1\u5206\u89e3]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Evolving, Not Training: Zero-Shot Reasoning Segmentation via Evolutionary Prompting"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [reasoning segmentation], [evolutionary prompting, zero-shot learning, visual arena, semantic mutation, heterogeneous arena]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kai Ye, Xiaotong You, Jianghang Lin, Jiayi Ji, Pingyang Dai, Liujuan Cao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Xiamen University, National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24702",children:"https://arxiv.org/pdf/2512.24702"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/AHideoKuzeA/Evol-SAM3",children:"https://github.com/AHideoKuzeA/Evol-SAM3"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. 2. Introduces a "Generate-Evaluate-Evolve" loop with a Visual Arena for reference-free fitness assessment and a Semantic Mutation operator for diversity and error correction. 3. Designs a Heterogeneous Arena module that integrates geometric priors with semantic reasoning for robust final selection.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b60e24e2f5e5668a6d7d977acfb32177365388575df74e72ccb5a8b3d4e7f7e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b60e24e2f5e5668a6d7d977acfb32177365388575df74e72ccb5a8b3d4e7f7e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitations of static, training-free methods for reasoning segmentation by proposing EVOL-SAM3, a zero-shot framework that uses an evolutionary prompting strategy to iteratively refine prompt hypotheses at inference time. The method outperforms both static baselines and fully supervised state-of-the-art methods on the ReasonSeg benchmark without any training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[EVOL-SAM3: \u96f6\u6837\u672c\u63a8\u7406\u5206\u5272\u7684\u8fdb\u5316\u63d0\u793a / EVOL-SAM3: Zero-Shot Reasoning Segmentation via Evolutionary Prompting] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898 / Problem] --\x3e B1[\u9759\u6001\u63a8\u7406\u8303\u5f0f / Static Inference Paradigm]\n    B1 --\x3e B2[\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3 / Insufficient Reasoning Depth]\n    B1 --\x3e B3[\u65e0\u6cd5\u81ea\u6211\u7ea0\u6b63 / Lack of Self-Correction]\n    C[\u4e3b\u8981\u65b9\u6cd5 / Method] --\x3e C1[\u8fdb\u5316\u641c\u7d22 / Evolutionary Search]\n    C1 --\x3e C2[\u751f\u6210-\u8bc4\u4f30-\u8fdb\u5316\u5faa\u73af / Generate-Evaluate-Evolve Loop]\n    C2 --\x3e C3[\u89c6\u89c9\u7ade\u6280\u573a / Visual Arena]\n    C2 --\x3e C4[\u8bed\u4e49\u7a81\u53d8 / Semantic Mutation]\n    C2 --\x3e C5[\u5f02\u6784\u7ade\u6280\u573a / Heterogeneous Arena]\n    D[\u5173\u952e\u7ed3\u679c / Results] --\x3e D1[\u8d85\u8d8a\u9759\u6001\u57fa\u7ebf / Outperforms Static Baselines]\n    D --\x3e D2[\u8d85\u8d8a\u5168\u76d1\u7763SOTA / Surpasses Fully Supervised SOTA]\n    D --\x3e D3[\u96f6\u6837\u672c\u8bbe\u7f6e / Zero-Shot Setting]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [latent semantic rule encoding, recurrent world model, language-guided latent classification, semantic risk detection, autonomous driving]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qian Cheng, Weitao Zhou, Cheng Jing, Nanshan Deng, Junze Wen, Zhaoyang Liu, Kun Jiang, Diange Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24712",children:"https://arxiv.org/pdf/2512.24712"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed LSRE, a framework that encodes sparse VLM judgments into decision boundaries within a recurrent world model's latent space for real-time semantic risk assessment. 2. Demonstrated that LSRE achieves detection accuracy comparable to a per-frame VLM baseline while enabling earlier hazard anticipation and operating at 10 Hz. 3. Showed that the learned latent classifier generalizes to rarely seen, semantically similar test cases, indicating its effectiveness for semantic safety monitoring."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7d95e05edf41980725845c43ad581e04cc0d1877fc56167a5c4d2c47f7e9516_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7d95e05edf41980725845c43ad581e04cc0d1877fc56167a5c4d2c47f7e9516_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of real-time semantic rule compliance in autonomous driving, where explicit encoding of complex social rules is difficult. It proposes LSRE, a framework that uses sparsely sampled VLM outputs to train a lightweight latent classifier within a recurrent world model, enabling efficient semantic risk detection. The method achieves accuracy comparable to a VLM baseline with much lower latency and better anticipation, showing promise for deployable semantic safety systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Real-time semantic rule compliance in autonomous driving is difficult to encode explicitly and VLM inference is too slow.)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: LSRE converts sparse VLM judgments into decision boundaries in a recurrent world model's latent space.)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Achieves VLM-comparable accuracy, earlier anticipation, 10 Hz operation, and generalization to unseen cases.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [robotic manipulation], [3D object flow, video generation, zero-shot manipulation, trajectory optimization, reinforcement learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Karthik Dharmarajan, Wenlong Huang, Jiajun Wu, Li Fei-Fei, Ruohan Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24766",children:"https://arxiv.org/pdf/2512.24766"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Dream2Flow, a framework that bridges video generation and robotic control using 3D object flow as an intermediate representation. 2. Demonstrates the ability to reconstruct 3D object motions from generated videos and formulate manipulation as object trajectory tracking, overcoming the embodiment gap. 3. Shows that the method enables zero-shot guidance from pre-trained video models to manipulate diverse object categories (rigid, articulated, deformable, granular) without task-specific demonstrations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c22839be4198942eb08182abe0606d486a3126572afb757ce865cb1b3a787721_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c22839be4198942eb08182abe0606d486a3126572afb757ce865cb1b3a787721_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Dream2Flow, a framework that uses 3D object flow extracted from videos generated by off-the-shelf models as an interface for robotic manipulation. It translates these generated motions into executable robot actions via trajectory optimization or reinforcement learning, enabling zero-shot manipulation of diverse objects in open-world settings. The results demonstrate 3D object flow as a general and scalable bridge between video generation models and robotic control."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Translating human-like motions from video models into low-level robot actions)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Use 3D object flow as intermediate representation, reconstruct motions from videos, track trajectories)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Enables zero-shot manipulation of diverse objects, bridges video generation to robot control)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [slate recommendation, generative recommendation, residual quantization, hierarchical planning, listwise preference alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yunsheng Pang, Zijian Liu, Yudong Li, Shaojie Zhu, Zijian Luo, Chenyun Yu, Sikai Wu, Shichen Shen, Cong Xu, Bin Wang, Kai Jiang, Hongyong Yu, Chengxiang Zhuo, Zang Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tencent, Sun Yat-sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24787",children:"https://arxiv.org/pdf/2512.24787"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed an auto-encoder with residual quantization and contrastive constraints for semantically structured item tokenization. 2. Introduced a hierarchical generation framework that decouples list-level planning from item-level decoding for efficient slate generation. 3. Designed a listwise preference alignment objective to directly optimize slate quality using implicit user feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df7bb0829f12a7ec59faf3d297069dfbce2bbcb60223c10f7e7a4162d6e7a4e0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df7bb0829f12a7ec59faf3d297069dfbce2bbcb60223c10f7e7a4162d6e7a4e0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes HiGR, an efficient generative framework for slate recommendation. It addresses the limitations of existing autoregressive methods by using hierarchical planning and a listwise alignment objective. Experiments on a commercial platform show HiGR significantly outperforms state-of-the-art methods in both offline quality and online metrics while being 5x faster at inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HiGR: Efficient Generative Slate Recommendation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u73b0\u6709\u81ea\u56de\u5f52\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u7ea0\u7f20\u548c\u4f4e\u6548\u89e3\u7801]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5206\u5c42\u89c4\u5212\u4e0e\u5217\u8868\u504f\u597d\u5bf9\u9f50]\n    C --\x3e D[\u8bed\u4e49\u7ed3\u6784\u5316ID / Semantically Structured IDs]\n    C --\x3e E[\u5206\u5c42\u751f\u6210 / Hierarchical Generation]\n    C --\x3e F[\u5217\u8868\u504f\u597d\u5bf9\u9f50 / Listwise Preference Alignment]\n    A --\x3e G[\u5173\u952e\u7ed3\u679c/Results: \u79bb\u7ebf\u8d28\u91cf\u63d0\u5347>10%, \u63a8\u7406\u52a0\u901f5\u500d, \u5728\u7ebf\u6307\u6807\u663e\u8457\u589e\u957f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] LeanCat: A Benchmark Suite for Formal Category Theory in Lean (Part I: 1-Categories)"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [theorem proving], [formal verification, category theory, benchmark, Lean, large language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rongge Xu, Hui Dai, Yiming Fu, Jiedong Jiang, Tianjiao Nie, Hongwei Wang, Junkai Wang, Holiverse Yang, Jiatong Yang, Zhi-Hao Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University, Southern University of Science and Technology, Westlake University, Xi'an Jiaotong-Liverpool University, The Chinese University of Hong Kong, Yanqi Lake Beijing Institute of Mathematical Sciences and Applications (BIMSA)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24796",children:"https://arxiv.org/pdf/2512.24796"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/sciencraft/LeanCat",children:"https://github.com/sciencraft/LeanCat"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces LeanCat, a benchmark for formal category theory in Lean, designed to stress-test abstraction and library-mediated reasoning. 2. Presents a curated dataset of 100 tasks with topic families and difficulty tiers, created via an LLM-assisted human grading process. 3. Demonstrates the benchmark's utility by evaluating models and the LeanBridge method, showing current AI capabilities and providing a checkpoint for tracking progress."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bb17bb33fa46697baca7f3b3a6262916453dd0a4bf5f92ff26cebdd7d681ffe_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bb17bb33fa46697baca7f3b3a6262916453dd0a4bf5f92ff26cebdd7d681ffe_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces LeanCat, a benchmark for formalizing category theory in Lean to better evaluate AI's ability for abstract, library-based reasoning in mathematics. It presents a curated set of 100 tasks and evaluates models, finding low success rates, especially on harder problems, while showing that retrieval-augmented methods like LeanBridge can improve performance. The benchmark serves as a compact checkpoint for tracking progress in research-level formal theorem proving."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LeanCat: A Benchmark Suite for Formal Category Theory in Lean] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>\u73b0\u6709\u57fa\u51c6\u672a\u80fd\u5145\u5206\u8861\u91cf\u62bd\u8c61\u548c\u57fa\u4e8e\u5e93\u7684\u63a8\u7406/Current benchmarks under-measure abstraction and library-mediated reasoning]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u4e3aLean\u521b\u5efa\u5f62\u5f0f\u5316\u8303\u7574\u8bba\u57fa\u51c6\uff0c\u5305\u542b100\u4e2a\u5206\u7ea7\u4efb\u52a1/Create a Lean benchmark for formal category theory with 100 graded tasks]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u6700\u4f73\u6a21\u578bpass@1\u4e3a8.25%\uff0c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u6709\u63d0\u5347/Best model pass@1 is 8.25%, retrieval-augmented methods show gains]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Practising responsibility: Ethics in NLP as a hands-on course"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [ethics in nlp], [ethics education, active learning, curriculum development, hands-on activities, learning by teaching]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Malvina Nissim, Viviana Patti, Beatrice Savoldi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Groningen, University of Turin, Fondazione Bruno Kessler"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24825",children:"https://arxiv.org/pdf/2512.24825"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduction of a dedicated course "Ethical Aspects in NLP" designed to integrate ethics into NLP education, 2. Development of a pedagogical approach based on active learning, interactive sessions, hands-on activities, and "learning by teaching" methods, 3. Creation and refinement of the course over four years, adapting it across different institutions, educational levels, and interdisciplinary backgrounds, yielding reusable teaching materials and student-made educational products.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8d866d1d641ab747e97be881ac0eec09fdae4762445938b33c32d5a452c3e5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8d866d1d641ab747e97be881ac0eec09fdae4762445938b33c32d5a452c3e5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the challenge of integrating ethical considerations into NLP education by proposing a hands-on course. The method employs active learning through interactive sessions, practical activities, and "learning by teaching". The main conclusion is that this approach successfully fosters critical thinking and produces reusable educational resources, providing a model for educators to incorporate social impact into curricula.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Practising responsibility: Ethics in NLP as a hands-on course") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("NLP\u7cfb\u7edf\u666e\u53ca/NLP systems pervasive")\n    Problem --\x3e P2("\u4f26\u7406\u6559\u80b2\u6311\u6218/Ethics education challenges")\n    Method --\x3e M1("\u4e3b\u52a8\u5b66\u4e60/Active learning")\n    Method --\x3e M2("\u5b9e\u8df5\u4e0e\u4e92\u52a8/Hands-on & interactive")\n    Method --\x3e M3("\u4ee5\u6559\u4fc3\u5b66/Learning by teaching")\n    Results --\x3e R1("\u8bfe\u7a0b\u4f18\u5316\u4e0e\u9002\u5e94/Course refined & adapted")\n    Results --\x3e R2("\u4ea7\u51fa\u53ef\u590d\u7528\u4ea7\u54c1/Reusable products created")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [human-robot interaction], [object rearrangement, human preference modeling, Monte Carlo Tree Search, psychological constructs, user study]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Emmanuel Fashae, Michael Burke, Leimin Tian, Lingheng Meng, Pamela Carreno-Medrano"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Monash University, CSIRO Robotics"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24829",children:"https://arxiv.org/pdf/2512.24829"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel, interpretable formulation of human object arrangement preferences based on four psychological constructs (spatial practicality, habitual convenience, semantic coherence, commonsense appropriateness). 2. Designs and validates a self-report questionnaire to capture these constructs through a 63-participant online study. 3. Demonstrates the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner to generate arrangements that align with human preferences."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0c9201484194f4f746f05eae7a288356c0e53c3a3a9d4683db5313924455a5a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0c9201484194f4f746f05eae7a288356c0e53c3a3a9d4683db5313924455a5a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of interpretability in robotic object rearrangement models by identifying four explicit psychological constructs that guide human organizational preferences. The authors designed a questionnaire to measure these constructs and integrated them into a Monte Carlo Tree Search planner. The results show that the planner, guided by these interpretable preferences, can generate arrangements closely matching those created by human participants."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Explaining Why Things Go Where They Go<br>\u89e3\u91ca\u7269\u54c1\u4e3a\u4f55\u5f52\u4f4d] --\x3e B(Problem: \u673a\u5668\u4eba\u91cd\u6392\u6a21\u578b\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027<br>Problem: Robotic rearrangement models lack interpretability)\n    A --\x3e C(Method: \u63d0\u51fa\u56db\u4e2a\u53ef\u89e3\u91ca\u504f\u597d\u6784\u5ff5\u4e0e\u95ee\u5377<br>Method: Four interpretable preference constructs & questionnaire)\n    A --\x3e D(Results: \u57fa\u4e8eMCTS\u7684\u89c4\u5212\u5668\u80fd\u751f\u6210\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u5e03\u5c40<br>Results: MCTS planner generates human-aligned arrangements)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] GenZ: Foundational models as latent variable generators within traditional statistical models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [hybrid statistical modeling], [latent variable model, generalized EM algorithm, semantic feature discovery, cold-start collaborative filtering, hedonic regression]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Marko Jojic, Nebojsa Jojic"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Arizona State University, Microsoft Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24834",children:"https://arxiv.org/pdf/2512.24834"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes GenZ, a hybrid model that integrates frozen foundational models as latent variable generators within traditional statistical models. 2. Introduces an iterative, generalized EM algorithm that jointly discovers interpretable semantic feature descriptors and optimizes statistical model parameters from dataset errors. 3. Demonstrates the method's effectiveness on real-world tasks, significantly outperforming pure LLM baselines and matching performance that requires extensive traditional data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11807fe38101f2230e94348a6c074eab9e6cece7f18336e076aa76c0c5604232_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11807fe38101f2230e94348a6c074eab9e6cece7f18336e076aa76c0c5604232_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes GenZ, a method that uses a frozen foundational model to generate latent semantic features within a statistical model, optimized via a generalized EM algorithm. It shows this hybrid approach significantly outperforms using the foundational model's general knowledge alone for house price prediction and matches traditional collaborative filtering performance for cold-start movie recommendations using only semantic descriptions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["GenZ: Foundational models as latent variable generators"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Foundational models lack dataset-specific patterns for prediction"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Hybrid model with generalized EM for joint semantic feature & statistical parameter optimization"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Outperforms GPT-5 on house prices; Matches CF with 4000 ratings using semantics"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [derivative-free optimisation, regret minimisation, multivariate mutual information, in-scene camera control, vision-language models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jason Armitage, Rico Sennnrich"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Zurich"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24826",children:"https://arxiv.org/pdf/2512.24826"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A new method that improves multivariate mutual information estimates using regret minimisation with derivative-free optimisation. 2. An algorithm enabling off-the-shelf 2D-trained cross-modal systems to adapt online to object occlusions and differentiate features in 3D scenes. 3. A pipeline that controls an in-scene camera to learn directly from noisy VLM outputs, improving performance on 3D multi-object scenes without pretraining or finetuning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66c8b5c775488157feb95c4650ebd70cf6bfc3b2373d13cfde2db9f88f119e8d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66c8b5c775488157feb95c4650ebd70cf6bfc3b2373d13cfde2db9f88f119e8d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the dimensional shift when 2D-trained vision-language models process 3D scenes. It proposes a method using derivative-free optimisation and regret minimisation to improve mutual information estimates and control an in-scene camera, allowing the system to adapt online and improve performance on cross-modal tasks for 3D multi-object scenes without additional training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("2D\u7cfb\u7edf\u5904\u74063D\u573a\u666f\u7684\u7ef4\u5ea6\u504f\u79fb/Dimensional shift for 2D systems on 3D scenes")\n    Problem --\x3e P2("\u9700\u8981\u5b66\u4e60\u76f8\u673a\u63a7\u5236\u6a21\u5757/Need to learn an in-scene camera control module")\n    Method --\x3e M1("\u57fa\u4e8e\u9057\u61be\u6700\u5c0f\u5316\u7684\u591a\u5143\u4e92\u4fe1\u606f\u4f30\u8ba1/Multivariate mutual information estimates via regret minimisation")\n    Method --\x3e M2("\u4f7f\u7528\u65e0\u5bfc\u6570\u4f18\u5316/Using derivative-free optimisation")\n    Results --\x3e R1("\u4f7f\u73b0\u6210\u76842D\u7cfb\u7edf\u80fd\u5728\u7ebf\u9002\u5e943D\u573a\u666f/Enables off-the-shelf 2D systems to adapt online to 3D scenes")\n    Results --\x3e R2("\u65e0\u9700\u9884\u8bad\u7ec3\u6216\u5fae\u8c03\u5373\u53ef\u63d0\u5347\u6027\u80fd/Improves performance without pretraining or finetuning")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [Privacy protections], [PrivacyBench, Retrieval-Augmented Generation (RAG), secret leakage, privacy-aware prompt, privacy-by-design]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Srija Mukhopadhyay, Sathwik Reddy, Shruthi Muthukumar, Jisun An, Ponnurangam Kumaraguru"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," International Institute of Information Technology Hyderabad, Indiana University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24848",children:"https://arxiv.org/pdf/2512.24848"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces PrivacyBench, a novel conversational benchmark with socially grounded datasets containing embedded secrets for evaluating privacy in AI assistants. 2. Provides a multi-turn conversational evaluation framework to measure secret preservation capabilities of personalized AI systems. 3. Empirically demonstrates that current RAG-based assistants leak secrets in up to 26.56% of interactions and identifies a critical architectural flaw where the retrieval mechanism is a single point of failure for privacy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7685e487e221610623a5fd5b2084368051b6218a6804a6749e97cc93aef26acb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7685e487e221610623a5fd5b2084368051b6218a6804a6749e97cc93aef26acb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces PrivacyBench, a benchmark to evaluate privacy leakage in personalized AI agents that access a user's digital footprint. Testing shows RAG-based assistants leak secrets frequently, and while privacy-aware prompts help, the fundamental architecture is unsafe, highlighting the need for structural, privacy-by-design solutions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: Personalized AI agents risk exposing sensitive user data from their digital footprint.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Introduce PrivacyBench benchmark with datasets containing secrets and multi-turn conversational evaluation.]\n    D[\u5173\u952e\u7ed3\u679c/Results: RAG assistants leak secrets; privacy prompts partially mitigate; need for privacy-by-design safeguards.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A study on constraint extraction and exception exclusion in care worker scheduling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [constraint learning], [constraint extraction, exception exclusion, constraint programming, shift scheduling, care worker scheduling]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Koki Suenaga, Tomohiro Furuta, Satoshi Ono"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kagoshima University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24853",children:"https://arxiv.org/pdf/2512.24853"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),"  1. Proposes a method using constraint templates to automatically extract facility-specific scheduling constraints from interview data, reducing the need for manual specification. 2. Introduces a novel mechanism to identify and exclude exceptional constraints from the extraction process, improving the quality of the learned constraints. 3. Demonstrates the effectiveness of the approach by successfully generating schedules that satisfy all hard constraints and reduce soft constraint violations in care worker scheduling."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e005f244d37b26b715bffe3d3edce37668aa27d5541ef7201258ae5746901d94_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e005f244d37b26b715bffe3d3edce37668aa27d5541ef7201258ae5746901d94_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of automatically generating work schedules for long-term care facilities, where constraints vary widely. It proposes a method that uses customizable constraint templates to extract relevant rules from manager interviews while excluding exceptional cases. Experiments show the method successfully creates schedules that meet all hard constraints and reduces soft constraint violations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A Study on Constraint Extraction and Exception Exclusion in Care Worker Scheduling] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u8bbe\u65bd\u6761\u4ef6\u5404\u5f02\uff0c\u9700\u4eba\u5de5\u8bbf\u8c08\u5b9a\u4e49\u7ea6\u675f/Facility-specific constraints require manual interviews]\n    C --\x3e C1[\u4f7f\u7528\u7ea6\u675f\u6a21\u677f\u63d0\u53d6\u7ec4\u5408/Use constraint templates to extract combinations]\n    C --\x3e C2[\u5f15\u5165\u4f8b\u5916\u7ea6\u675f\u6392\u9664\u673a\u5236/Incorporate mechanism to exclude exceptional constraints]\n    D --\x3e D1[\u6ee1\u8db3\u6240\u6709\u786c\u7ea6\u675f/Satisfied all hard constraints]\n    D --\x3e D2[\u51cf\u5c11\u8f6f\u7ea6\u675f\u8fdd\u89c4/Reduced soft constraint violations]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Big AI is accelerating the metacrisis: What can we do?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [ethics & society], [metacrisis, language engineers, human flourishing, planetary boundaries, technofeudalism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Steven Bird"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Charles Darwin University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24863",children:"https://arxiv.org/pdf/2512.24863"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Identifies and critiques the role of "Big AI" and language engineers in accelerating converging global crises (ecological, meaning, language). 2. Highlights the ethical conflict between professional obligations (e.g., ACL Code of Ethics) and the harms caused by current NLP/AI development practices. 3. Proposes a paradigm shift for NLP, advocating for a future centered on human flourishing and amplifying social networks rather than scaling through large, polluting models.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper argues that the current trajectory of "Big AI," particularly in NLP, is accelerating a global metacrisis. It critiques the field\'s focus on scalability and value-neutral technology development, which benefits powerful interests at the expense of the public good and the planet. The paper concludes by urgently calling for an alternative, life-affirming future for NLP centered on human flourishing.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Big AI is accelerating the metacrisis: What can we do?] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Big AI\u52a0\u901f\u751f\u6001\u3001\u610f\u4e49\u548c\u8bed\u8a00\u5371\u673a/Big AI accelerates ecological, meaning, and language crises]\n    B --\x3e B2[\u8bed\u8a00\u5de5\u7a0b\u5e08\u7684\u4f26\u7406\u56f0\u5883/Ethical dilemma of language engineers]\n    C --\x3e C1[\u6279\u5224\u5f53\u524d\u53ef\u6269\u5c55\u6027\u53d9\u4e8b/Critique current scalability narrative]\n    C --\x3e C2[\u547c\u5401\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848/Call to explore alternatives]\n    D --\x3e D1[\u9700\u8981\u4ee5\u4eba\u7c7b\u7e41\u8363\u4e3a\u4e2d\u5fc3\u7684\u672a\u6765/NLP future must center human flourishing]\n    D --\x3e D2[\u5229\u7528\u96c6\u4f53\u667a\u6167\u8bbe\u8ba1\u751f\u547d\u80af\u5b9a\u7684NLP/Design life-affirming NLP with collective intelligence]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [llm evaluation], [benchmark, knowledge statements, dynamic composition, data contamination, multi-knowledge assessment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yiming Liang, Yizhi Li, Yantao Du, Ge Zhang, Jiayi Zhou, Yuchen Wu, Yinzhu Piao, Denghui Cao, Tong Sun, Ziniu Li, Li Du, Bo Lei, Jiaheng Liu, Chenghua Lin, Zhaoxiang Zhang, Wenhao Huang, Jiajun Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Chinese Academy of Sciences, Chinese Academy of Sciences, Bytedance, Nanjing University, M-A-P, BAAI, The University of Manchester"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24867",children:"https://arxiv.org/pdf/2512.24867"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://encyclo-k.github.io",children:"https://encyclo-k.github.io"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel statement-based benchmark (Encyclo-K) that uses knowledge statements as the fundamental curation unit instead of pre-defined questions., 2. Introduces a dynamic evaluation method where questions are composed by randomly sampling multiple statements at test time, mitigating data contamination and enabling periodic refresh., 3. Demonstrates a scalable, low-cost annotation process that requires only formatting verification, not domain expertise, while enabling comprehensive multi-knowledge assessment per question."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bf5e4785262ae916ad666afc0e0e212833641ae7597f48f69f148b35cfc4807b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bf5e4785262ae916ad666afc0e0e212833641ae7597f48f69f148b35cfc4807b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Encyclo-K, a new benchmark for evaluating LLMs that constructs questions by dynamically combining multiple knowledge statements extracted from textbooks at test time. This approach addresses key limitations of existing benchmarks, such as data contamination and single-point assessment. Experiments show it poses a significant challenge to state-of-the-art models, with top accuracy at only 62.07%, validating its effectiveness for assessing comprehensive, multi-statement understanding."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027/Limitations of Existing Benchmarks]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u57fa\u4e8e\u77e5\u8bc6\u9648\u8ff0\u7684\u52a8\u6001\u7ec4\u5408/Dynamic Composition from Knowledge Statements]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u5f3a\u533a\u5206\u6027\uff0c\u6a21\u578b\u8868\u73b0\u68af\u5ea6\u5206\u5e03/Strong Discriminative Power, Gradient Performance]\n    B --\x3e B1[\u6570\u636e\u6c61\u67d3/Data Contamination]\n    B --\x3e B2[\u5355\u77e5\u8bc6\u70b9\u8bc4\u4f30/Single-Knowledge Assessment]\n    B --\x3e B3[\u9ad8\u6807\u6ce8\u6210\u672c/High Annotation Cost]\n    C --\x3e C1[\u4ece\u6743\u5a01\u6559\u6750\u63d0\u53d6\u9648\u8ff0/Extract Statements from Textbooks]\n    C --\x3e C2[\u6d4b\u8bd5\u65f6\u968f\u673a\u7ec4\u5408/Compose Questions at Test Time]\n    D --\x3e D1[GPT-5.1\u51c6\u786e\u738762.07%/GPT-5.1 Accuracy 62.07%]\n    D --\x3e D2[\u63a8\u7406\u6a21\u578b16.04%-62.07%/Reasoning Models 16.04%-62.07%]\n    D --\x3e D3[\u804a\u5929\u6a21\u578b9.71%-50.40%/Chat Models 9.71%-50.40%]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Agentic Learning Ecosystem (ALE), Interaction-based Policy Alignment (IPA), Terminal Bench Pro, post-training, trajectory generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Weixun Wang, XiaoXiao Xu, Wanhe An, Fangwen Dai, Wei Gao, Yancheng He, Ju Huang, Qiang Ji, Hanqi Jin, Xiaoyang Li, Yang Li, Zhongwen Li, Shirong Lin, Jiashun Liu, Zenan Liu, Tao Luo, Dilxat Muhtar, Yuanbin Qu, Jiaqiang Shi, Qinghui Sun, Yingshui Tan, Hao Tang, Runze Wang, Yi Wang, Zhaoguo Wang, Yanan Wu, Shaopan Xiong, Binchen Xu, Xander Xu, Yuchi Xu, Qipeng Zhang, Xixia Zhang, Haizhou Zhao, Jie Zhao, Shuaibing Zhao, Baihui Zheng, Jianhui Zheng, Suhang Zheng, Yanni Zhu, Mengze Cai, Kerui Cao, Xitong Chen, Yue Dai, Lifan Du, Tao Feng, Tao He, Jin Hu, Yijie Hu, Ziyu Jiang, Cheng Li, Xiang Li, Jing Liang, Chonghuan Liu, ZhenDong Liu, Haodong Mi, Yanhu Mo, Junjia Ni, Shixin Pei, Jingyu Shen, XiaoShuai Song, Cecilia Wang, Chaofan Wang, Kangyu Wang, Pei Wang, Tao Wang, Wei Wang, Ke Xiao, Mingyu Xu, Tiange Xu, Nan Ya, Siran Yang, Jianan Ye, Yaxing Zang, Duo Zhang, Junbo Zhang, Boren Zheng, Wanxi Deng, Ling Pan, Lin Qu, Wenbo Su, Jiamang Wang, Wei Wang, Hu Wei, Minggang Wu, Cheng Yu, Bing Zhao, Zhicheng Zheng, Bo Zheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ROCK & ROLL & IFLOW & DT Joint Team (Inferred from the author list and likely represents a collaboration, but no specific university or company is named. The domain is unclear from the provided text.)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24873",children:"https://arxiv.org/pdf/2512.24873"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces the Agentic Learning Ecosystem (ALE), an end-to-end infrastructure for developing agent LLMs, comprising the ROLL post-training framework, the ROCK sandbox manager, and the iFlow CLI agent framework. 2. Proposes a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks to improve long-horizon training stability. 3. Releases the ROME agent model, trained on over one million trajectories, and introduces the Terminal Bench Pro benchmark with improved scale and contamination control for rigorous evaluation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9408c7a8de1b2fe7261d28a9d7eb1d3df3afe81fc17a03cc9b2c09e332ac8782_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9408c7a8de1b2fe7261d28a9d7eb1d3df3afe81fc17a03cc9b2c09e332ac8782_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of a principled, end-to-end ecosystem for developing agentic LLMs by introducing the Agentic Learning Ecosystem (ALE). ALE streamlines the agent development pipeline, and the authors use it to build and release the ROME agent model, which demonstrates strong performance on benchmarks, validating the effectiveness of their infrastructure."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Let It Flow: Agentic Crafting on Rock and Roll<br/>\u6784\u5efaROME\u6a21\u578b\u4e8e\u5f00\u653e\u667a\u80fd\u4f53\u5b66\u4e60\u751f\u6001\u4e2d] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br/>Open-source community lacks a principled, end-to-end ecosystem for agent LLM development.] --\x3e B1[\u963b\u788d/Block<br/>Hinders practical development and production adoption of agents.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br/>Introduce Agentic Learning Ecosystem (ALE)] --\x3e C1[\u7ec4\u4ef6/Components<br/>ROLL (post-training), ROCK (sandbox), iFlow CLI (agent framework)]\n    C --\x3e C2[\u6a21\u578b/Model<br/>Release ROME agent trained on 1M+ trajectories]\n    C --\x3e C3[\u7b97\u6cd5/Algorithm<br/>Propose Interaction-based Policy Alignment (IPA)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br/>ROME achieves strong benchmark performance.] --\x3e D1[\u57fa\u51c6/Benchmarks<br/>24.72% on Terminal-Bench 2.0, 57.40% on SWE-bench Verified]\n    D --\x3e D2[\u65b0\u57fa\u51c6/New Benchmark<br/>Introduce Terminal Bench Pro for rigorous evaluation.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [3D object detection], [semi-automated annotation, human-in-the-loop, 3D object detection, data anonymization, domain adaptation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Andrii Gamalii, Daniel G\xf3rniak, Robert Nowak, Bart\u0142omiej Olber, Krystian Radlak, Jakub Winter"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Warsaw University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24896",children:"https://arxiv.org/pdf/2512.24896"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A semi-automated annotation pipeline that combines AI-generated initial annotations with human verification to reduce cost and time. 2. A system architecture supporting iterative model retraining and incorporating data anonymization and domain adaptation techniques. 3. A methodology and toolset that accelerates the creation of a large-scale, multimodal autonomous driving dataset tailored to Polish road conditions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/575844a7a43a73f8b8d00aa31dfa90a80dbb02b7129fa4cb48b23a397afe6e78_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/575844a7a43a73f8b8d00aa31dfa90a80dbb02b7129fa4cb48b23a397afe6e78_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the costly and time-consuming problem of manually annotating large-scale, multimodal datasets for autonomous vehicles. It proposes a semi-automated, human-in-the-loop annotation pipeline that uses 3D object detection to generate initial labels, enabling iterative retraining and incorporating anonymization and adaptation techniques. The developed solution significantly reduces annotation time while ensuring high-quality, consistent labels, directly supporting the creation of a Polish-specific autonomous driving dataset."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Manual annotation of multimodal AV datasets is costly and time-consuming."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: A semi-automated, human-in-the-loop pipeline using 3D object detection for initial annotations."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Substantial time savings and consistent, high-quality annotations."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] mHC: Manifold-Constrained Hyper-Connections"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [Hyper-Connections, residual connection, identity mapping, manifold constraint, training stability]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhenda Xie, Yixuan Wei, Huanqi Cao, Chenggang Zhao, Chengqi Deng, Jiashi Li, Damai Dai, Huazuo Gao, Jiang Chang, Liang Zhao, Shangyan Zhou, Zhean Xu, Zhengyan Zhang, Wangding Zeng, Shengding Hu, Yuqing Wang, Jingyang Yuan, Lean Wang, Wenfeng Liang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," DeepSeek-AI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24880",children:"https://arxiv.org/pdf/2512.24880"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Manifold-Constrained Hyper-Connections (mHC), a framework that projects the residual connection space onto a specific manifold to restore the identity mapping property compromised by Hyper-Connections (HC). 2. Incorporates rigorous infrastructure optimization to address the memory access overhead and ensure training efficiency. 3. Demonstrates that mHC enables effective large-scale training with tangible performance improvements and superior scalability, offering a flexible and practical extension of HC."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7219c6945df5dfb5231231a93ccf8e3cf155e38527f2c4071501eaae05a8b7ac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7219c6945df5dfb5231231a93ccf8e3cf155e38527f2c4071501eaae05a8b7ac_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that Hyper-Connections (HC), while improving performance, lose the identity mapping property of standard residual connections, leading to training instability and memory overhead. To solve this, the authors propose Manifold-Constrained Hyper-Connections (mHC), which projects HC's connection space onto a manifold to restore identity mapping and includes infrastructure optimizations. Empirical results show mHC is effective for scalable training, offering better performance and stability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[mHC: Manifold-Constrained Hyper-Connections] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1["HC \u7834\u574f\u4e86\u6052\u7b49\u6620\u5c04\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a/HC compromises identity mapping, causing instability"]\n    B --\x3e B2["HC \u5e26\u6765\u5185\u5b58\u5f00\u9500/HC incurs memory overhead"]\n    C --\x3e C1["\u5c06\u6b8b\u5dee\u8fde\u63a5\u7a7a\u95f4\u6295\u5f71\u5230\u7279\u5b9a\u6d41\u5f62/Project residual space onto a manifold"]\n    C --\x3e C2["\u6062\u590d\u6052\u7b49\u6620\u5c04\u5c5e\u6027/Restore identity mapping property"]\n    C --\x3e C3["\u7ed3\u5408\u57fa\u7840\u8bbe\u65bd\u4f18\u5316/Incorporate infrastructure optimization"]\n    D --\x3e D1["\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u6709\u6548\u8bad\u7ec3/Enables effective training at scale"]\n    D --\x3e D2["\u63d0\u4f9b\u6027\u80fd\u6539\u8fdb\u548c\u53ef\u6269\u5c55\u6027/Offers performance improvements & scalability"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AI-Driven Cloud Resource Optimization for Multi-Cluster Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [cluster infrastructure], [multi-cluster systems, resource optimization, predictive learning, policy-aware decision-making, cross-cluster telemetry]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vinoth Punniyamoorthy, Akash Kumar Agarwal, Bikesh Kumar, Abhirup Mazumder, Kabilan Kannan, Sumit Saha"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," IEEE (affiliations indicate authors are IEEE Senior Members, with industry affiliations from Albertsons and East West Bank, USA)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24914",children:"https://arxiv.org/pdf/2512.24914"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An AI-driven framework for adaptive resource optimization across multi-cluster cloud systems, moving beyond reactive, cluster-centric approaches. 2. Integration of predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management. 3. A prototype demonstrating improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02143e20715d24c6ab11a29c3710ca28e3f39c48ce36f9862a254d3564252726_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02143e20715d24c6ab11a29c3710ca28e3f39c48ce36f9862a254d3564252726_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an AI-driven framework to address the problem of inefficient and reactive resource management in multi-cluster cloud environments. The method uses predictive learning and policy-aware decision-making on cross-cluster telemetry to proactively optimize resource allocation for performance, cost, and reliability. The results show the framework improves resource efficiency and system stability compared to traditional approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AI-Driven Cloud Resource Optimization for Multi-Cluster Environments] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u65b9\u6cd5\u53cd\u5e94\u5f0f\u4e14\u96c6\u7fa4\u4e2d\u5fc3\u5316 / Existing approaches are reactive and cluster-centric]\n    B --\x3e B2[\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u4f4e\u6548\u548c\u5ef6\u8fdf\u9002\u5e94 / Causes inefficient resource utilization and delayed adaptation]\n    C --\x3e C1[AI\u9a71\u52a8\u6846\u67b6\u96c6\u6210\u9884\u6d4b\u5b66\u4e60 / AI-driven framework integrates predictive learning]\n    C --\x3e C2[\u7b56\u7565\u611f\u77e5\u51b3\u7b56\u4e0e\u6301\u7eed\u53cd\u9988 / Policy-aware decision-making and continuous feedback]\n    C --\x3e C3[\u5206\u6790\u8de8\u96c6\u7fa4\u9065\u6d4b\u6570\u636e / Analyzes cross-cluster telemetry]\n    D --\x3e D1[\u63d0\u9ad8\u8d44\u6e90\u6548\u7387 / Improved resource efficiency]\n    D --\x3e D2[\u66f4\u5feb\u7a33\u5b9a\u4e8e\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8 / Faster stabilization during workload fluctuations]\n    D --\x3e D3[\u51cf\u5c11\u6027\u80fd\u53d8\u5f02 / Reduced performance variability]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Iterative Deployment Improves Planning Skills in LLMs"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [iterative deployment, implicit reward, data curation, planning, fine-tuning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Augusto B. Corr\xeaa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, Andr\xe9 G. Pereira, Yarin Gal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Oxford, AI Sequrity Company, UFRGS"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24940",children:"https://arxiv.org/pdf/2512.24940"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that iterative deployment and fine-tuning on curated user data significantly improves LLM planning skills, including emergent generalization to longer plans. 2. Provides a theoretical analysis showing iterative deployment effectively implements an outer-loop reinforcement learning process with an implicit reward function. 3. Highlights the AI safety implications of this implicit training regime and positions it as an alternative to explicit RL training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper shows that repeatedly deploying LLMs and fine-tuning them on curated data from previous deployments significantly improves their planning capabilities. This process is analyzed as an implicit form of reinforcement learning, which raises safety concerns due to the undefined reward function and offers an alternative training paradigm based on data curation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Iterative Deployment Improves Planning Skills in LLMs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u89c4\u5212\u80fd\u529b/LLM Planning Skills]\n    C --\x3e C1[\u8fed\u4ee3\u90e8\u7f72\u4e0e\u5fae\u8c03/Iterative Deployment & Fine-tuning]\n    C1 --\x3e C2[\u7528\u6237\u6570\u636e\u7b5b\u9009/User Data Curation]\n    D --\x3e D1[\u89c4\u5212\u80fd\u529b\u63d0\u5347/Improved Planning Skills]\n    D --\x3e D2[\u53d1\u73b0\u9690\u5f0fRL/Discovering Implicit RL]\n    D2 --\x3e D3[AI\u5b89\u5168\u5f71\u54cd/AI Safety Implications]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [information retrieval], [relevance assessment, benchmark, long-tail, visual salience, e-commerce]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chenji Lu, Zhuo Chen, Hui Zhao, Zhenyi Wang, Pengjie Wang, Jian Xu, Bo Zheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Taobao & Tmall Group of Alibaba"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24943",children:"https://arxiv.org/pdf/2512.24943"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RAIR, a comprehensive Chinese benchmark for e-commerce relevance assessment derived from real-world scenarios. 2. Establishes a standardized evaluation framework with universal rules to address the lack of standardized metrics. 3. Introduces a dataset with three specialized subsets (general, long-tail hard, visual salience) to evaluate fundamental, challenging, and multimodal capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes RAIR, a rule-aware benchmark for e-commerce search relevance assessment, to address the lack of complex and standardized evaluation datasets. It introduces a comprehensive dataset with three subsets to test different model capabilities. Experiments on 14 models show RAIR is challenging, with GPT-5 performing best, and it serves as a new industry benchmark."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RAIR: \u4e00\u4e2a\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u76f8\u5173\u6027\u8bc4\u4f30\u7684\u89c4\u5219\u611f\u77e5\u57fa\u51c6 / RAIR: A Rule-Aware Benchmark for E-commerce Relevance Assessment]\n    A --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u590d\u6742\u6027\uff0c\u7f3a\u5c11\u6807\u51c6\u5316\u8bc4\u4f30 / Existing benchmarks lack complexity and standardized evaluation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u5305\u542b\u901a\u7528\u3001\u957f\u5c3e\u3001\u89c6\u89c9\u663e\u8457\u6027\u5b50\u96c6\u7684\u57fa\u51c6\u548c\u89c4\u5219\u6846\u67b6 / Propose benchmark with general, long-tail, visual-salience subsets and rule framework]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5bf914\u4e2a\u6a21\u578b\u6784\u6210\u6311\u6218\uff0cGPT-5\u8868\u73b0\u6700\u4f73\uff0c\u53ef\u4f5c\u4e3a\u884c\u4e1a\u57fa\u51c6 / Presents challenge to 14 models, GPT-5 performs best, serves as industry benchmark]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [Lyapunov certificates, exponential stability, multi-step learning, actor-critic, maximum entropy RL]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yongwei Zhang, Yuanzhe Xing, Quan Quan, Zhikun She"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beihang University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24955",children:"https://arxiv.org/pdf/2512.24955"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework (MSACL) that integrates exponential stability theory with maximum entropy RL via multi-step Lyapunov certificate learning, using off-policy data to learn certificates that satisfy theoretical stability conditions. 2. Introduces Exponential Stability Labels (ESL) and a \u03bb-weighted aggregation mechanism to effectively balance the bias-variance trade-off in multi-step learning. 3. Guides policy optimization with a stability-aware advantage function to ensure the learned policy promotes rapid Lyapunov descent, achieving provable stability and robustness under simple rewards."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea102a46402567fc13871b6bc5f72e6c07e79e6ee87e8349aee1c18c8fc9627e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes MSACL, a model-free reinforcement learning framework that ensures provable exponential stability by learning Lyapunov certificates from multi-step data and guiding policy optimization with a stability-aware advantage. It demonstrates superior performance over baseline and state-of-the-art Lyapunov-based RL methods across six benchmarks, achieving rapid convergence and robustness with simple rewards. The work establishes a link between Lyapunov theory and actor-critic frameworks for verifiably safe control."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Provable Stability in Model-Free RL / \u6a21\u578b\u65e0\u5173RL\u7684\u53ef\u8bc1\u660e\u7a33\u5b9a\u6027]\n    C --\x3e C1[Multi-Step Lyapunov Certificate Learning / \u591a\u6b65\u674e\u96c5\u666e\u8bfa\u592b\u8bc1\u4e66\u5b66\u4e60]\n    C --\x3e C2[Stability-Aware Advantage Function / \u7a33\u5b9a\u6027\u611f\u77e5\u4f18\u52bf\u51fd\u6570]\n    D --\x3e D1[Superiority over SOTA / \u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5]\n    D --\x3e D2[Exponential Stability & Robustness / \u6307\u6570\u7a33\u5b9a\u6027\u4e0e\u9c81\u68d2\u6027]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [multi-armed bandits], [semi-overlapping multi-bandit, best arm identification, sequential support network learning, GapE algorithm, sample complexity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Andr\xe1s Antos, Andr\xe1s Millinghoffer, P\xe9ter Antal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Budapest University of Technology and Economics, E-Group ICT Software Zrt."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24959",children:"https://arxiv.org/pdf/2512.24959"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a new pure-exploration model called the semi-overlapping multi-bandit (SOMMAB) for Sequential Support Network Learning (SSNL)., 2. Develops a generalized GapE algorithm for the SOMMAB setting., 3. Derives new exponential error bounds that improve the best-known constant in the exponent and scale linearly with the degree of overlap, showing sample complexity gains from shared evaluations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1ccf2e1312507d052da8a3c6c2b6fb042432d3f13e5efa2572b5d2cd1dff292_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1ccf2e1312507d052da8a3c6c2b6fb042432d3f13e5efa2572b5d2cd1dff292_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a new framework called Sequential Support Network Learning (SSNL) and models it as a semi-overlapping multi-bandit (SOMMAB) problem, where a single evaluation provides feedback to multiple bandits. The authors develop a generalized GapE algorithm for SOMMABs and prove new, improved error bounds that demonstrate significant sample-complexity reductions due to structural overlap."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: Selecting beneficial partners via shared, asymmetric evaluations"] --\x3e P1["\u95ee\u9898\u9886\u57df/Application Domains: MTL, ATL, FL, MAS"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: SOMMAB model & generalized GapE algorithm"] --\x3e M1["\u6a21\u578b/Model: Semi-overlapping multi-bandit"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: Improved error bounds & sample complexity gains"] --\x3e R1["\u7406\u8bba\u4fdd\u8bc1/Theoretical: Exponential bounds scale with overlap"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AMAP Agentic Planning Technical Report"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [tool-integrated reasoning, spatio-temporal understanding, cascaded training, hierarchical data curation, stable tool environment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yulan Hu, Xiangwen Zhang, Sheng Ouyang, Hao Yi, Lu Xu, Qinglin Lang, Lide Tan, Xiang Cheng, Tianchen Ye, Zhicong Li, Ge Chen, Wenjin Yang, Zheng Pan, Shaopan Xiong, Siran Yang, Ju Huang, Yan Zhang, Jiamang Wang, Yong Liu, Yinfeng Huang, Tucheng Lin, Xin Li, Ning Guo"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Alibaba (AMAP AI Agent LLM Team)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24957",children:"https://arxiv.org/pdf/2512.24957"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A stable tool environment supporting over ten domain-specific tools for asynchronous rollout and training. 2. A hierarchical data curation framework that filters high-quality queries with a 1:10,000 ratio, emphasizing diversity and difficulty. 3. A cascaded training recipe involving a seed SFT stage to measure query difficulty, a second SFT stage on high-certainty data, and an RL stage on low-certainty data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b6f557a1e8b6dbdc7fc3030b4817b52b9eae922a5f44ccb37d965540ecf2229_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b6f557a1e8b6dbdc7fc3030b4817b52b9eae922a5f44ccb37d965540ecf2229_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces STAgent, an agentic LLM specialized for spatio-temporal reasoning tasks like itinerary planning. It is empowered by a stable tool environment, a hierarchical data curation framework, and a cascaded training recipe. The model, initialized from Qwen3-30B-A3B, shows strong performance on TravelBench while maintaining general capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AMAP Agentic Planning Technical Report] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u7f3a\u4e4f\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u65f6\u7a7a\u63a8\u7406\u4efb\u52a1\u7684\u5de5\u5177\u96c6\u6210\u65b9\u6848/Lack of TIR solutions for real-world spatio-temporal reasoning]\n    C --\x3e C1[STAgent: \u4e13\u7528\u4e8e\u65f6\u7a7a\u7406\u89e3\u7684\u667a\u80fd\u4f53\u6a21\u578b/STAgent: Agentic LLM for spatio-temporal understanding]\n    C --\x3e C2[\u7a33\u5b9a\u5de5\u5177\u73af\u5883/Stable Tool Environment]\n    C --\x3e C3[\u5206\u5c42\u6570\u636e\u7ba1\u7406\u6846\u67b6/Hierarchical Data Curation Framework]\n    C --\x3e C4[\u7ea7\u8054\u8bad\u7ec3\u65b9\u6848/Cascaded Training Recipe]\n    D --\x3e D1[\u5728TravelBench\u4e0a\u8868\u73b0\u4f18\u5f02/Promising performance on TravelBench]\n    D --\x3e D2[\u4fdd\u6301\u4e86\u5e7f\u6cdb\u7684\u901a\u7528\u80fd\u529b/Maintains general capabilities across benchmarks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video restoration], [diffusion model, film restoration, high-resolution video, patch-wise training, global-local frequency module]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rongji Xun, Junjie Yuan, Zhongjie Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tongji University, Shanghai Film Restoration Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24946",children:"https://arxiv.org/pdf/2512.24946"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://anonymous.4open.science/r/HaineiFRDM",children:"https://anonymous.4open.science/r/HaineiFRDM"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed HaineiFRDM, a film restoration framework leveraging diffusion models for content understanding to restore indistinguishable film defects. 2. Introduced a patch-wise training/testing strategy with a position-aware Global Prompt and Frame Fusion Module and a global-local frequency module to enable high-resolution restoration on a single 24GB GPU and ensure texture consistency. 3. Constructed a new film restoration dataset containing restored real-degraded films and realistic synthetic data."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c49ddd01a0523d32c1f20822a4a1d270659f5454212011a90e04a39fe796d1ab_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c49ddd01a0523d32c1f20822a4a1d270659f5454212011a90e04a39fe796d1ab_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes HaineiFRDM, a diffusion model-based framework for restoring high-resolution, real-world films. It addresses limitations of existing open-source methods by using a patch-wise strategy and novel modules to handle high-resolution videos efficiently and introduces a new dataset. Experiments show the model outperforms existing open-source methods in defect restoration."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HaineiFRDM: Explore Diffusion to Restore High-resolution Real-World Films] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5f00\u6e90\u65b9\u6cd5\u6027\u80fd\u6709\u9650/Open-source methods have limited performance]\n    B --\x3e B2[\u9ad8\u5206\u8fa8\u7387\u7535\u5f71\u672a\u63a2\u7d22/High-resolution films unexplored]\n    C --\x3e C1[\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4fee\u590d\u6846\u67b6/Diffusion-based restoration framework]\n    C --\x3e C2[\u5206\u5757\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u7b56\u7565/Patch-wise training & testing]\n    C --\x3e C3[\u5168\u5c40-\u5c40\u90e8\u9891\u7387\u6a21\u5757/Global-local frequency module]\n    C --\x3e C4[\u6784\u5efa\u65b0\u6570\u636e\u96c6/Construct new dataset]\n    D --\x3e D1[\u7f3a\u9677\u4fee\u590d\u80fd\u529b\u4f18\u8d8a/Superior defect restoration ability]\n    D --\x3e D2[\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5c06\u5f00\u6e90/Code & dataset to be released]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.strong,{children:["[arXiv260101] ShowUI-",(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"\u03c0"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"\u03c0"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"\u03c0"})]})})]}),": Flow-based Generative Models as GUI Dexterous Hands"]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [human-computer interaction], [flow-based generative model, GUI automation, continuous trajectory prediction, unified discrete-continuous actions, ScreenDrag benchmark]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Siyuan Hu, Kevin Qinghong Lin, Mike Zheng Shou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Show Lab, National University of Singapore"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24965",children:"https://arxiv.org/pdf/2512.24965"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/showlab/showui-pi",children:"https://github.com/showlab/showui-pi"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed ShowUI-\u03c0, the first flow-based generative model for GUI dexterous manipulation, unifying discrete clicks and continuous drags in a shared model. 2. Introduced a flow-based action generation method for drag modeling, predicting incremental cursor adjustments from continuous visual observations. 3. Created ScreenDrag, a benchmark with 20K drag trajectories across five domains and comprehensive evaluation protocols to assess GUI agents' drag capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6391f609bd9b67bc717f5e3756501bf8f4dedd5a207352ff5b4f02bc902207_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6391f609bd9b67bc717f5e3756501bf8f4dedd5a207352ff5b4f02bc902207_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of existing GUI agents that only perform discrete clicks, lacking the ability for continuous, closed-loop drag interactions. The authors propose ShowUI-\u03c0, a flow-based generative model that unifies discrete and continuous actions and generates smooth drag trajectories from visual observations. Experiments show ShowUI-\u03c0 outperforms proprietary GUI agents on the new ScreenDrag benchmark, demonstrating effective dexterous control for GUI automation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[ShowUI-\u03c0: Flow-based Generative Models as GUI Dexterous Hands] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Existing GUI agents only support discrete clicks, lacking continuous drag capability for closed-loop trajectories]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Flow-based generative model with unified discrete-continuous actions and incremental trajectory prediction]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Outperforms proprietary agents on ScreenDrag benchmark (score 26.98), demonstrating effective dexterous control]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Evaluating the Impact of Compression Techniques on the Robustness of CNNs under Natural Corruptions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [model compression (quantization/pruning)], [quantization, pruning, weight clustering, robustness, multiobjective assessment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Itallo Patrick Castro Alves Da Silva, Emanuel Adler Medeiros Pereira, Erick de Andrade Barboza, Baldoino Fonseca dos Santos Neto, Marcio de Medeiros Ribeiro"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Federal University of Alagoas, Federal University of Rio Grande do Norte"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24971",children:"https://arxiv.org/pdf/2512.24971"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a comprehensive evaluation of individual and combined compression techniques (quantization, pruning, weight clustering) on CNNs for robustness under natural corruptions. 2. Demonstrated that certain compression strategies can preserve or even improve model robustness, especially on complex architectures. 3. Utilized multiobjective assessment to identify optimal compression configurations that balance robustness, accuracy, and compression ratio for real-world deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e8640f8930863d5573a7df0bb7287b8800d92c67a60523b6b0dab2eb044c58bb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e8640f8930863d5573a7df0bb7287b8800d92c67a60523b6b0dab2eb044c58bb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates how compression techniques like quantization, pruning, and weight clustering affect the robustness of CNNs (ResNet-50, VGG-19, MobileNetV2) against natural image corruptions on CIFAR-10-C/100-C. It finds that specific compression strategies, particularly when combined, can maintain or enhance robustness, with multiobjective analysis revealing the best trade-offs for efficient and robust model deployment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Evaluating the Impact of Compression Techniques on CNNs under Natural Corruptions] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u538b\u7f29\u6a21\u578b\u5728\u81ea\u7136\u635f\u574f\u4e0b\u7684\u9c81\u68d2\u6027/Robustness of compressed models under natural corruptions]\n    C --\x3e C1[\u8bc4\u4f30\u91cf\u5316\u3001\u526a\u679d\u3001\u6743\u91cd\u805a\u7c7b\u6280\u672f/Evaluate quantization, pruning, weight clustering]\n    C --\x3e C2[\u4f7f\u7528CIFAR-10/100-C\u6570\u636e\u96c6/Use CIFAR-10/100-C datasets]\n    C --\x3e C3[\u591a\u76ee\u6807\u8bc4\u4f30/Multiobjective assessment]\n    D --\x3e D1[\u7279\u5b9a\u7b56\u7565\u4fdd\u6301\u6216\u63d0\u5347\u9c81\u68d2\u6027/Certain strategies preserve or improve robustness]\n    D --\x3e D2[\u5b9a\u5236\u7ec4\u5408\u4ea7\u751f\u6709\u76ca\u7ed3\u679c/Customized combinations yield beneficial results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [embodied vision-language reasoning], [low-light vision, embodied question answering, vision-language models, image enhancement, benchmark]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yohan Park, Hyunwoo Ha, Wonjun Jo, Tae-Hyun Oh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), Pohang University of Science and Technology (POSTECH)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24985",children:"https://arxiv.org/pdf/2512.24985"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DarkEQA, the first benchmark for evaluating Embodied Question Answering (EQA) under multi-level, physics-based low-light conditions. 2. Features a physically faithful degradation pipeline that models illumination drop and sensor noise in linear RAW space, followed by an ISP-inspired renderer. 3. Systematically evaluates and reveals the limitations of state-of-the-art VLMs and the effectiveness of Low-Light Image Enhancement (LLIE) models as pre-processors in this challenging scenario."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f144c0ff2baabb069f605975462919cef76b3f54919a8c9db67dab0432973003_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f144c0ff2baabb069f605975462919cef76b3f54919a8c9db67dab0432973003_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper identifies a gap in evaluating Vision-Language Models (VLMs) for embodied agents under low-light conditions and proposes DarkEQA, a new benchmark that simulates realistic dark environments. The benchmark uses a physics-based image degradation model to test VLM robustness and the utility of image enhancement techniques. The evaluation reveals significant performance drops in VLMs under low-light, highlighting a critical area for improvement in robust embodied AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[DarkEQA: Benchmarking VLMs for EQA in Low-Light] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Existing EQA benchmarks overlook low-light conditions, a necessity for 24/7 robot operation.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes DarkEQA benchmark with physics-based low-light simulation in RAW space and ISP pipeline.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Evaluates VLMs & LLIE models, systematically revealing VLM limitations under low-light.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Classifying long legal documents using short random chunks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [document classification], [DeBERTa V3, LSTM, random chunks, Temporal, long document processing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Luis Adri\xe1n Cabrera-Diego"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Jus Mundi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24997",children:"https://arxiv.org/pdf/2512.24997"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel legal document classifier architecture combining DeBERTa V3 with an LSTM that processes only 48 randomly selected short chunks (max 128 tokens) per document, enabling efficient handling of long texts. 2. A robust deployment pipeline built using Temporal, a durable execution framework, ensuring reliable and fault-tolerant processing workflows. 3. Demonstrated effective performance on a multilingual legal document dataset with a weighted F-score of 0.898 and quantified processing efficiency (498 seconds per 100 files on CPU)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92192ce5f7c11c2d86da5e296a17a8e7ae1b0794ecb76a29cb686c4b5b4f5f12_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92192ce5f7c11c2d86da5e296a17a8e7ae1b0794ecb76a29cb686c4b5b4f5f12_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of classifying long legal documents by proposing a model that uses DeBERTa V3 and an LSTM to process only 48 randomly selected short text chunks per document. The method avoids the computational expense of processing full documents with Transformers and is deployed via a reliable Temporal-based pipeline. The system achieves a weighted F-score of 0.898 and processes 100 files in a median time of 498 seconds on CPU."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Classifying long legal documents using short random chunks] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Long legal documents are expensive/slow to process with full Transformers]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Classifier: DeBERTa V3 + LSTM on 48 random short chunks (128 tokens max)]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>Weighted F-score: 0.898, Median time: 498s per 100 files (CPU)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A Modal Logic for Possibilistic Reasoning with Fuzzy Formal Contexts"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [modal logic], [weighted modal logic, possibilistic reasoning, formal concept analysis, fuzzy formal contexts, rough set theory]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Prosenjit Howlader, Churn-Jung Liau"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Information Science, Academia Sinica"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24980",children:"https://arxiv.org/pdf/2512.24980"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel two-sort weighted modal logic with necessity and sufficiency operators for possibilistic reasoning in fuzzy formal contexts. 2. Provides a sound and complete axiomatization for the logic and its fragments with respect to fuzzy context models. 3. Shows the logic can represent generalized formal, object-oriented, and property-oriented concepts in fuzzy FCA and can be extended to multi-relational contexts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0eedb37864559f4df3443ff6f46099ca8b0528be3387a300ecd0f5068e2a25f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0eedb37864559f4df3443ff6f46099ca8b0528be3387a300ecd0f5068e2a25f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces a new two-sort weighted modal logic designed for possibilistic reasoning with fuzzy formal contexts, featuring necessity and sufficiency operators. It provides a sound and complete axiomatization for this logic and demonstrates its expressive power by showing it can represent key generalized concepts from Formal Concept Analysis (FCA) in the fuzzy setting. The work also indicates the logic's potential for extension to reasoning with multi-relational fuzzy contexts."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[\u8bba\u6587\u6807\u9898: A Modal Logic for Possibilistic Reasoning with Fuzzy Formal Contexts] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Reasoning with uncertainty in fuzzy formal contexts] --\x3e P1[\u6a21\u7cca\u5f62\u5f0f\u80cc\u666f\u4e2d\u7684\u53ef\u80fd\u6027\u63a8\u7406/Possibilistic reasoning in fuzzy formal contexts]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: A two-sort weighted modal logic] --\x3e M1[\u5f15\u5165\u4e24\u79cd\u52a0\u6743\u6a21\u6001\u7b97\u5b50/Introduces two weighted modal operators]\n    M1 --\x3e M1a[\u5fc5\u8981\u6027\u7b97\u5b50/Necessity (\u25a1)]\n    M1 --\x3e M1b[\u5145\u5206\u6027\u7b97\u5b50/Sufficiency (\u229f)]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u903b\u8f91\u662f\u53ef\u9760\u4e14\u5b8c\u5907\u7684/Logic is sound and complete]\n    Results --\x3e R2[\u53ef\u8868\u793aFCA\u4e2d\u7684\u5e7f\u4e49\u6982\u5ff5/Can represent generalized FCA concepts]\n    Results --\x3e R3[\u53ef\u6269\u5c55\u81f3\u591a\u5173\u7cfb\u6a21\u7cca\u80cc\u666f/Extensible to multi-relational contexts]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Modeling Language as a Sequence of Thoughts"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [language modeling], [recurrent transformer, thought gestalt, reversal curse, cross-attention, scaling efficiency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Nasim Borazjanizadeh, James McClelland"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Independent Researcher, Stanford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25026",children:"https://arxiv.org/pdf/2512.25026"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduced the Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels (tokens and sentence-level "thought" states). 2. Proposed a unified training scheme where token and sentence representations are generated with the same parameters and a single next-token objective, enabling gradient flow through memory. 3. Demonstrated improved data and parameter efficiency over GPT-2 and better performance on relational direction generalization (e.g., reversal curse).']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8e6d868bbc8b6b68328f1680dd184805a29e94d0e7b58137122aad5c0a6e9d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8e6d868bbc8b6b68328f1680dd184805a29e94d0e7b58137122aad5c0a6e9d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' The paper addresses the limitations of standard Transformers, which rely on surface-level token statistics and lack globally consistent representations. It proposes the Thought Gestalt model, a recurrent Transformer that generates tokens while cross-attending to a memory of prior sentence-level "thought" states, trained with a unified next-token objective. The model shows improved scaling efficiency and reduces errors on relational generalization tasks like the reversal curse.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Modeling Language as a Sequence of Thoughts") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("Transformer \u4f9d\u8d56\u8868\u5c42\u7edf\u8ba1/Transformers rely on surface-level statistics")\n    Problem --\x3e P2("\u7f3a\u4e4f\u5168\u5c40\u4e00\u81f4\u8868\u793a/Lack globally consistent representations")\n    Problem --\x3e P3("\u5bfc\u81f4\u9006\u8f6c\u8bc5\u5492\u7b49\u95ee\u9898/Leads to issues like reversal curse")\n    Method --\x3e M1("\u63d0\u51fa\u601d\u60f3\u5b8c\u5f62\u6a21\u578b/Propose Thought Gestalt (TG) model")\n    Method --\x3e M2("\u53cc\u5c42\u5efa\u6a21: Token + \u53e5\u5b50\u7ea7\u601d\u60f3/Two-level modeling: tokens & sentence-level thoughts")\n    Method --\x3e M3("\u5faa\u73afTransformer + \u8de8\u6ce8\u610f\u529b\u8bb0\u5fc6/Recurrent Transformer with cross-attention memory")\n    Results --\x3e R1("\u6bd4GPT-2\u66f4\u9ad8\u6548/More efficient than GPT-2")\n    Results --\x3e R2("\u51cf\u5c11\u9006\u8f6c\u8bc5\u5492\u9519\u8bef/Reduces reversal curse errors")\n    Results --\x3e R3("\u7edf\u4e00\u53c2\u6570\u4e0e\u76ee\u6807\u8bad\u7ec3/Unified parameter & objective training")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Generative Classifiers Avoid Shortcut Solutions"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [generative models], [generative classifiers, spurious correlations, distribution shift, diffusion models, autoregressive models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alexander C. Li, Ananya Kumar, Deepak Pathak"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, Stanford University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25034",children:"https://arxiv.org/pdf/2512.25034"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/alexlioralexli/generative-classifiers",children:"https://github.com/alexlioralexli/generative-classifiers"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Demonstrates that generative classifiers (using class-conditional generative models) inherently avoid shortcut learning by modeling all features, not just spurious ones. 2. Shows that generative classifiers achieve state-of-the-art performance on multiple image and text distribution shift benchmarks without specialized techniques. 3. Provides a theoretical analysis in a Gaussian toy setting to explain the inductive biases and data conditions favoring generative classifiers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f744eff83ad768a9dc5e431ef5b2d98baefe24c12d01fc980aa2fa92c3c21c65_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f744eff83ad768a9dc5e431ef5b2d98baefe24c12d01fc980aa2fa92c3c21c65_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of discriminative classifiers learning spurious shortcuts that fail under distribution shift. It proposes using generative classifiers, which model p(x|y), and finds they avoid shortcuts and achieve state-of-the-art robustness on standard benchmarks without needing specialized training tricks. The main conclusion is that generative classifiers offer a simple and effective alternative for building more robust models."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Generative Classifiers Avoid Shortcut Solutions] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Discriminative models learn spurious shortcuts<br>\u5224\u522b\u6a21\u578b\u5b66\u4e60\u865a\u5047\u6377\u5f84]\n    C --\x3e C1[Use class-conditional generative models<br>\u4f7f\u7528\u7c7b\u6761\u4ef6\u751f\u6210\u6a21\u578b]\n    C --\x3e C2[Model p(x|y) instead of p(y|x)<br>\u5efa\u6a21 p(x|y) \u800c\u975e p(y|x)]\n    D --\x3e D1[Avoid shortcuts & SOTA on distribution shift<br>\u907f\u514d\u6377\u5f84\u5e76\u5728\u5206\u5e03\u504f\u79fb\u4e0a\u8fbe\u5230SOTA]\n    D --\x3e D2[Simple training, no specialized techniques<br>\u8bad\u7ec3\u7b80\u5355\uff0c\u65e0\u9700\u4e13\u95e8\u6280\u672f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Large Language Model, Building Energy Management System, AI Agents, Human-Building Interaction, Context-aware]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Tianzhi He, Farrokh Jazizadeh"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Texas at San Antonio, Virginia Polytechnic Institute and State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25055",children:"https://arxiv.org/pdf/2512.25055"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a conceptual framework for LLM-based AI agents in BEMS, featuring a closed-loop system with perception, central control, and action modules. 2. Develops and benchmarks a prototype using real-world datasets and diverse metrics (latency, functionality, accuracy, cost-effectiveness), formalizing the assessment of such agents. 3. Demonstrates the framework's performance and generalizability, identifying strengths (e.g., high accuracy in device control) and areas for improvement (e.g., complex cost estimation)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d46efc47f789043b6987c8068e21aecb4ec53b645c2c1a61c1880ed06029103b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d46efc47f789043b6987c8068e21aecb4ec53b645c2c1a61c1880ed06029103b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a framework for LLM-based AI agents to manage energy in smart buildings through natural language. The agent uses a closed-loop system to analyze data and control devices, and its evaluation shows promising accuracy in tasks like device control but highlights challenges in complex cost estimation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Existing BEMS lack context-aware, natural language interaction for energy management"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Proposes a three-module LLM-based AI agent framework (perception, central control, action) for closed-loop management"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Prototype shows high accuracy in device control (86%) and memory tasks (97%), but lower accuracy in cost estimation (49%)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.strong,{children:["[arXiv260101] AdaGReS",":Adaptive"," Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG"]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [redundancy-aware selection, token-budgeted RAG, greedy selection, submodular optimization, adaptive calibration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chao Peng, Bin Wang, Zhilei Long, Jinfang Sheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Central South University, Yizhi Intelligent (YZInt)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25052",children:"https://arxiv.org/pdf/2512.25052"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AdaGReS, a redundancy-aware context selection framework that optimizes a set-level objective combining query relevance and intra-set redundancy penalties under a token-budget constraint. 2. Introduces a closed-form, instance-adaptive calibration method for the relevance-redundancy trade-off parameter, eliminating manual tuning and adapting to candidate-pool statistics and budget limits. 3. Provides a theoretical analysis showing the proposed objective exhibits \u03b5-approximate submodularity, yielding near-optimality guarantees for the greedy selection algorithm."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85c85942576679b5e5fe4c0066c0977620d02d122c659a34dfe900bfed59c445_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85c85942576679b5e5fe4c0066c0977620d02d122c659a34dfe900bfed59c445_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of redundant context in token-budgeted RAG systems, which wastes budget and degrades generation quality. It proposes AdaGReS, an adaptive greedy selection framework that scores and selects chunks by balancing relevance and redundancy, with a theoretically-backed near-optimal guarantee. Experiments on QA and biomedical datasets show it improves redundancy control and end-to-end answer quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AdaGReS: Adaptive Greedy Context Selection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Top-k\u68c0\u7d22\u8fd4\u56de\u5197\u4f59\u5757\uff0c\u6d6a\u8d39token\u9884\u7b97\u5e76\u964d\u4f4e\u751f\u6210\u8d28\u91cf/Top-k retrieval returns redundant chunks, wasting token budget and degrading generation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5197\u4f59\u611f\u77e5\u7684\u8d2a\u5a6a\u9009\u62e9\u6846\u67b6\uff0c\u7ed3\u5408\u76f8\u5173\u6027\u5f97\u5206\u4e0e\u5197\u4f59\u60e9\u7f5a\uff0c\u5e76\u8fdb\u884c\u81ea\u9002\u5e94\u53c2\u6570\u6821\u51c6/Redundancy-aware greedy selection framework with relevance-redundancy trade-off and adaptive calibration]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u5f00\u653e\u57dfQA\u548c\u751f\u7269\u533b\u5b66\u8bed\u6599\u4e0a\uff0c\u5197\u4f59\u63a7\u5236\u548c\u4e0a\u4e0b\u6587\u8d28\u91cf\u5f97\u5230\u6539\u5584\uff0c\u63d0\u5347\u4e86\u7aef\u5230\u7aef\u7b54\u6848\u8d28\u91cf/Improved redundancy control and context quality on open-domain QA and biomedical corpus, leading to better end-to-end answer quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [memory & caching], [heuristic synthesis, evolutionary search, instance-optimal, LLM code generation, cache eviction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Texas at Austin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25065",children:"https://arxiv.org/pdf/2512.25065"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Vulcan, a framework that recasts heuristic design as an automated search problem using LLMs to synthesize instance-optimal heuristics tailored to specific deployment contexts. 2. Introduces LLM-friendly, task-agnostic interfaces that separate policy and mechanism, making the synthesis tractable and enabling even small LLMs to generate correct code. 3. Demonstrates the framework's effectiveness by synthesizing heuristics for cache eviction and memory tiering that outperform state-of-the-art human-designed algorithms."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes Vulcan, a framework that uses LLM-driven evolutionary search to automatically synthesize instance-optimal system heuristics, tailored to specific workloads and hardware. It introduces task-agnostic interfaces to separate policy from mechanism, enabling efficient code generation. The synthesized heuristics for cache eviction and memory tiering were shown to outperform existing state-of-the-art algorithms."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: Manual heuristic design is slow and cannot adapt to changing hardware and workloads.]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: Use LLM-driven evolutionary search over task-agnostic interfaces to synthesize instance-optimal heuristics.]\n    Results[\u5173\u952e\u7ed3\u679c/Results: Synthesized heuristics outperform state-of-the-art algorithms in cache eviction and memory tiering.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Coordinated Humanoid Manipulation with Choice Policies"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [imitation learning], [humanoid robot, teleoperation, choice policy, multimodal behavior, whole-body coordination]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Haozhi Qi, Yen-Jen Wang, Toru Lin, Brent Yi, Yi Ma, Koushil Sreenath, Jitendra Malik"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," UC Berkeley"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25072",children:"https://arxiv.org/pdf/2512.25072"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://choice-policy.github.io",children:"https://choice-policy.github.io"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A modular teleoperation interface that decomposes humanoid control into intuitive submodules (e.g., hand-eye coordination, locomotion) for efficient, high-quality data collection. 2. The Choice Policy, a novel imitation learning architecture that generates multiple candidate actions and learns to score them, enabling fast inference and effective modeling of multimodal behaviors. 3. Empirical validation on real-world tasks (dishwasher loading, whiteboard wiping) showing superior performance over diffusion policies and behavior cloning, and highlighting the critical role of hand-eye coordination."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fc3a4a5fc6ec972fc1d7ab23cbd63d6c1c8efc8d326140cc34f70ea5a5cb65_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fc3a4a5fc6ec972fc1d7ab23cbd63d6c1c8efc8d326140cc34f70ea5a5cb65_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"}),' This paper tackles the challenge of achieving robust whole-body coordination for humanoid robots in unstructured environments. It proposes a system combining a modular teleoperation interface for data collection with a novel "Choice Policy" for imitation learning, which scores multiple candidate actions. Experiments on real-world tasks demonstrate that this approach outperforms baseline methods and that hand-eye coordination is crucial for success in long-horizon manipulation.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[Coordinated Humanoid Manipulation with Choice Policies] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1["\u5b9e\u73b0\u4eba\u5f62\u673a\u5668\u4eba\u5934\u3001\u624b\u3001\u817f\u7684\u9c81\u68d2\u5168\u8eab\u534f\u8c03/Robust whole-body coordination for humanoids"]\n    C --\x3e C1["\u6a21\u5757\u5316\u9065\u64cd\u4f5c\u63a5\u53e3/Modular teleoperation interface"]\n    C --\x3e C2["\u9009\u62e9\u7b56\u7565\uff1a\u751f\u6210\u5e76\u8bc4\u4f30\u5019\u9009\u52a8\u4f5c/Choice Policy: generate & score candidate actions"]\n    D --\x3e D1["\u5728\u6d17\u7897\u673a\u88c5\u8f7d\u3001\u767d\u677f\u64e6\u62ed\u4efb\u52a1\u4e0a\u8d85\u8d8a\u57fa\u7ebf/Outperforms baselines on dishwasher loading & whiteboard wiping"]\n    D --\x3e D2["\u624b\u773c\u534f\u8c03\u5bf9\u957f\u65f6\u57df\u4efb\u52a1\u81f3\u5173\u91cd\u8981/Hand-eye coordination is critical for long-horizon tasks"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [video generation], [video diffusion model, space-time disentanglement, temporal-warping training, camera-conditioning, generative rendering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Zhening Huang, Hyeonho Jeong, Xuelin Chen, Yulia Gryaditskaya, Tuanfeng Y. Wang, Joan Lasenby, Chun-Hao Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Cambridge, Adobe Research"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25075",children:"https://arxiv.org/pdf/2512.25075"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/zheninghuang/Space-Time-Pilot",children:"https://github.com/zheninghuang/Space-Time-Pilot"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced an animation time-embedding mechanism for explicit motion sequence control in video diffusion. 2. Proposed a temporal-warping training scheme to repurpose multi-view datasets for learning temporal variations. 3. Created the CamxTime synthetic dataset and an improved camera-conditioning mechanism for precise dual space-time control."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82552564f2c6cc5799df28c30493304ecd3600d22b5bcd81578cb3aaf6f15150_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82552564f2c6cc5799df28c30493304ecd3600d22b5bcd81578cb3aaf6f15150_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces SpaceTimePilot, a video diffusion model that independently controls camera viewpoint and motion sequence to re-render dynamic scenes from a monocular video. The method uses a novel time-embedding mechanism and a temporal-warping training strategy to achieve robust space-time disentanglement. Experiments show the model enables continuous exploration across space and time, outperforming prior work."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5982\u4f55\u4ece\u5355\u76ee\u89c6\u9891\u4e2d\u89e3\u8026\u7a7a\u95f4\u548c\u65f6\u95f4\u4ee5\u8fdb\u884c\u53ef\u63a7\u751f\u6210\u6e32\u67d3/How to disentangle space and time from a monocular video for controllable generative rendering]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5f15\u5165\u52a8\u753b\u65f6\u95f4\u5d4c\u5165\u673a\u5236\u548c\u65f6\u57df\u626d\u66f2\u8bad\u7ec3\u65b9\u6848/Introduce animation time-embedding and temporal-warping training scheme]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5b9e\u73b0\u9c81\u68d2\u7684\u65f6\u7a7a\u89e3\u8026\u4e0e\u8fde\u7eed\u53ef\u63a7\u6e32\u67d3/Achieve robust space-time disentanglement and continuous controllable rendering]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI using Physics-Informed Diffusion Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical imaging], [diffusion models, quantitative MRI, data consistency, physics-informed, multi-parametric mapping]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shishuai Wang, Florian Wiesinger, Noemi Sgambelluri, Carolin Pirkl, Stefan Klein, Juan A. Hernandez-Tamames, Dirk H.J. Poot"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Erasmus MC (Erasmus University Medical Center)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23726",children:"https://arxiv.org/pdf/2512.23726"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a diffusion model-based method (q3-MuPa) for quantitative MRI mapping that combines a deep generative model with a physics-based data consistency constraint., 2. Enables high-quality mapping from a fourfold-accelerated, nearly silent MRI scan (MuPa-ZTE), reducing acquisition time to ~1 minute., 3. Demonstrates successful training on synthetic data from digital phantoms alone, with strong generalization to real patient and phantom scans."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e081389f251cbbacaf7c704cd1a34c3a032b2173e63192833db976abd6541d5e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e081389f251cbbacaf7c704cd1a34c3a032b2173e63192833db976abd6541d5e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes q3-MuPa, a method that uses a physics-informed diffusion model to generate high-quality quantitative MRI maps (T1, T2, proton density) from accelerated, silent scans. The method integrates a denoising diffusion model with the MRI signal physics as a constraint during inference. It achieves accurate mapping from 1-minute scans and generalizes well to real data despite being trained only on synthetic phantoms."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Need for fast, quiet, and accurate quantitative MRI mapping)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Physics-informed diffusion model with data consistency)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: High-accuracy maps from 1-min scans, trained on synthetic data)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Leveraging Machine Learning for Early Detection of Lung Diseases"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [deep learning, convolutional neural networks, chest x-ray, disease classification, VGG16]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bahareh Rahmani, Harsha Reddy Bindela, Rama Kanth Reddy Gosula, Krishna Yedubati, Mohammad Amir Salari, Leslie Hinyard, Payam Norouzzadeh, Eli Snir, Martin Schoen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Saint Louis University, Washington University at Saint Louis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23757",children:"https://arxiv.org/pdf/2512.23757"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a diagnostic framework combining traditional image processing with advanced neural networks for lung disease detection. 2. Trains and validates multiple deep learning models (CNNs, VGG16, InceptionV3, EfficientNetB0) on chest x-rays for COVID-19, lung cancer, and pneumonia. 3. Demonstrates high accuracy, precision, recall, and F1 scores, highlighting the potential for real-world, non-invasive diagnostic applications in resource-limited settings."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d5eaabf315a0348dff119282fff830baf854bc7edaf57b6601b94745f8aa312_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d5eaabf315a0348dff119282fff830baf854bc7edaf57b6601b94745f8aa312_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes using deep learning models, including CNNs, VGG16, InceptionV3, and EfficientNetB0, to diagnose lung diseases like COVID-19, lung cancer, and pneumonia from chest x-rays. The method combines traditional image processing with neural networks to create a rapid, non-invasive diagnostic tool. The study concludes that these models achieve high performance metrics, showing reliability and potential for real-world healthcare applications, especially where radiologists are scarce."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Leveraging Machine Learning for Early Detection of Lung Diseases<br>\u5229\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u80ba\u90e8\u75be\u75c5\u65e9\u671f\u68c0\u6d4b] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Limited access to radiologists & resources<br>\u653e\u5c04\u79d1\u533b\u751f\u548c\u8d44\u6e90\u6709\u9650]\n    B --\x3e B2[Need for rapid, non-invasive diagnosis<br>\u9700\u8981\u5feb\u901f\u3001\u65e0\u521b\u8bca\u65ad]\n    C --\x3e C1[Combine image processing & neural networks<br>\u7ed3\u5408\u56fe\u50cf\u5904\u7406\u548c\u795e\u7ecf\u7f51\u7edc]\n    C --\x3e C2[Train models (CNN, VGG16, etc.) on chest X-rays<br>\u5728\u80f8\u90e8X\u5149\u7247\u4e0a\u8bad\u7ec3\u6a21\u578b]\n    D --\x3e D1[High accuracy, precision, recall, F1 scores<br>\u9ad8\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570]\n    D --\x3e D2[Potential for real-world diagnostic applications<br>\u5177\u6709\u5b9e\u9645\u8bca\u65ad\u5e94\u7528\u6f5c\u529b]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [quantum error mitigation, attention graph neural network, NISQ hardware, Burgers equation, zero-noise extrapolation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Seyed Mohamad Ali Tousi, Adib Bazgir, Yuwen Zhang, G. N. DeSouza"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23817",children:"https://arxiv.org/pdf/2512.23817"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A hybrid quantum-classical framework for solving the viscous Burgers equation on NISQ hardware, using the Cole-Hopf transformation and Trotterized quantum circuits. 2. The creation of a large parametric dataset of noisy, ZNE-corrected, hardware, and classical solutions with circuit metadata for data-driven error mitigation. 3. A novel attention-based graph neural network model that ingests circuit features and noisy outputs to predict error-mitigated solutions, outperforming ZNE alone."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57bb32110f5a354755f846f1b5a7ab41ac3fc4a701e97b9b25486f2bab0c72eb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57bb32110f5a354755f846f1b5a7ab41ac3fc4a701e97b9b25486f2bab0c72eb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a hybrid quantum-classical framework enhanced with a learned error mitigation model to solve the Burgers equation on noisy quantum hardware. The method uses an attention graph neural network trained on a dataset of noisy quantum simulations to predict corrected solutions. The results show the learned model consistently reduces errors beyond standard zero-noise extrapolation techniques."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5728\u542b\u566a\u58f0\u91cf\u5b50\u786c\u4ef6\u4e0a\u6c42\u89e3Burgers\u65b9\u7a0b/Solving Burgers Equation on Noisy Quantum Hardware]\n    C --\x3e C1[\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6846\u67b6\u4e0e\u6ce8\u610f\u529b\u56fe\u795e\u7ecf\u7f51\u7edc/Hybrid Quantum-Classical Framework with Attention GNN]\n    D --\x3e D1[\u5b66\u4e60\u6a21\u578b\u8d85\u8d8aZNE\uff0c\u51cf\u5c11\u91cf\u5b50-\u7ecf\u5178\u89e3\u5dee\u5f02/Learned Model Outperforms ZNE, Reduces Quantum-Classical Discrepancy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Autoregressive long-horizon prediction of plasma edge dynamics"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [surrogate modeling], [transformer, autoregressive prediction, plasma edge dynamics, surrogate model, long-horizon training]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hunor Csala, Sebastian De Pascuale, Paul Laiu, Jeremy Lore, Jae-Sun Park, Pei Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Oak Ridge National Laboratory"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23884",children:"https://arxiv.org/pdf/2512.23884"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a transformer-based, autoregressive surrogate model for fast, long-horizon prediction of 2D plasma edge state fields (electron temperature, density, radiated power). 2. Demonstrates that training with longer autoregressive horizons systematically improves model rollout stability and mitigates error accumulation, enabling stable predictions over hundreds to thousands of time steps. 3. Shows the surrogate model is orders of magnitude faster than the high-fidelity SOLPS-ITER simulator, enabling rapid parameter exploration for fusion device design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f71c9629a318094d2cde5d048b18c5b331d3a235097acfb1e70f8caf9d3c603_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f71c9629a318094d2cde5d048b18c5b331d3a235097acfb1e70f8caf9d3c603_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high computational cost of high-fidelity plasma edge simulations (SOLPS-ITER) by proposing a transformer-based autoregressive surrogate model. The model is trained on simulation data to predict key plasma state fields over long time horizons, and longer-horizon training is shown to improve prediction stability. The resulting surrogate is much faster than the original simulator, enabling rapid scenario exploration for fusion reactor design."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Autoregressive long-horizon prediction of plasma edge dynamics") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u9ad8\u4fdd\u771f\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8/High-fidelity simulation is computationally expensive")\n    Method --\x3e M1("\u57fa\u4e8eTransformer\u7684\u81ea\u56de\u5f52\u4ee3\u7406\u6a21\u578b/Transformer-based autoregressive surrogate model")\n    Method --\x3e M2("\u957f\u65f6\u57df\u8bad\u7ec3/Long-horizon training")\n    Results --\x3e R1("\u9884\u6d4b\u7a33\u5b9a\uff0c\u8bef\u5dee\u7d2f\u79ef\u51cf\u5c11/Stable prediction, reduced error accumulation")\n    Results --\x3e R2("\u901f\u5ea6\u6bd4\u539f\u6a21\u62df\u5feb\u6570\u4e2a\u6570\u91cf\u7ea7/Orders of magnitude faster than original simulator")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [remote sensing image analysis], [InSAR, Transformer, ground deformation forecasting, cross-site generalization, multimodal learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wendong Yao, Binhua Huang, Soumyabrata Dev"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," ADAPT SFI Research Centre, University College Dublin"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23906",children:"https://arxiv.org/pdf/2512.23906"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel multimodal patch-based Transformer architecture for InSAR-based ground deformation nowcasting, integrating displacement snapshots with static kinematic indicators and temporal encodings. 2. Demonstrated superior performance of the proposed model over baseline models (CNN-LSTM, STGCN) on a test tile in eastern Ireland, achieving high accuracy (RMSE=0.90mm, R\xb2=0.97). 3. Showcased strong cross-site generalization by training on one tile and applying the model without fine-tuning to five unseen European tiles, maintaining high performance (R\xb2\u22650.93) across diverse deformation patterns."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/36024dc5598b92b146557714c9e66eeb494b793bdcfaacb98b73cf6725cc8bfa_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of forecasting ground deformation from InSAR time series data. It proposes a multimodal Transformer model that combines recent displacement maps with kinematic indicators and temporal features to predict the next displacement epoch. The model achieves high accuracy and demonstrates strong generalization across different geographic sites in Europe without requiring retraining."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[\u8bba\u6587\u6807\u9898: A multimodal Transformer for InSAR-based ground deformation forecasting] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem: \u5982\u4f55\u5229\u7528\u5386\u53f2InSAR\u6570\u636e\u9884\u6d4b\u672a\u6765\u7684\u5730\u8868\u5f62\u53d8?] --\x3e P1[\u6311\u6218/Challenges: \u957f\u671f\u8d8b\u52bf\u3001\u5b63\u8282\u5468\u671f\u3001\u7a81\u53d8\u4e8b\u4ef6\u7684\u53e0\u52a0]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method: \u591a\u6a21\u6001Transformer] --\x3e M1[\u8f93\u5165/Inputs: \u8fd1\u671f\u5f62\u53d8\u56fe\u3001\u9759\u6001\u8fd0\u52a8\u5b66\u6307\u6807\u3001\u65f6\u95f4\u7f16\u7801]\n    Method --\x3e M2[\u4efb\u52a1/Task: \u5355\u6b65\u3001\u56fa\u5b9a\u95f4\u9694\u7684\u4e0b\u4e00\u65f6\u671f\u4e34\u8fd1\u9884\u62a5]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6027\u80fd/Performance: RMSE=0.90mm, R\xb2=0.97 (\u7231\u5c14\u5170\u6d4b\u8bd5\u96c6)]\n    Results --\x3e R2[\u6cdb\u5316/Generalization: \u8de8\u6b27\u6d325\u4e2a\u672a\u89c1\u533a\u57df\uff0cR\xb2\u22650.93]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Generative Video Compression: Towards 0.01% Compression Rate for Video Transmission"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [communication & networking], [generative video compression, task-oriented communication, AI Flow, compression-computation trade-off, Level C Shannon-Weaver]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xiangyu Chen, Jixiang Luo, Jingyu Xu, Fangqiu Yi, Chi Zhang, Xuelong Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Artificial Intelligence (TeleAI), China Telecom"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24300",children:"https://arxiv.org/pdf/2512.24300"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Generative Video Compression (GVC), a novel framework leveraging generative video models to achieve extreme compression rates as low as 0.02%, 2. Introduces a paradigm shift by trading computation for bandwidth, shifting the reconstruction burden to the receiver using generative priors, 3. Presents a practical compression-computation trade-off strategy for fast inference on consumer-grade GPUs, enabling deployment within the AI Flow framework for constrained environments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0223eada26a73d6b029f6d32188e4919884b4dea1b6854eeb80d3b61f3d6ac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0223eada26a73d6b029f6d32188e4919884b4dea1b6854eeb80d3b61f3d6ac_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Generative Video Compression (GVC), a framework that uses generative video models to achieve extreme compression rates by transmitting compact representations and reconstructing video at the receiver. It shifts the computational burden from transmission to inference and proposes a practical trade-off strategy for deployment. The work demonstrates a viable path for efficient video communication in bandwidth-constrained scenarios."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Generative Video Compression: Towards 0.01% Compression Rate for Video Transmission") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u80fd\u5426\u5b9e\u73b00.01%\u6781\u7aef\u538b\u7f29\u7387?/Achieve 0.01% extreme compression rate?")\n    Problem --\x3e P2("\u5982\u4f55\u6743\u8861\u8ba1\u7b97\u4e0e\u538b\u7f29?/Trade computation for compression?")\n    Problem --\x3e P3("\u662f\u5426\u5b9e\u7528\u53ef\u90e8\u7f72?/Practical and deployable?")\n    Method --\x3e M1("\u751f\u6210\u5f0f\u89c6\u9891\u538b\u7f29\u6846\u67b6/GVC Framework")\n    Method --\x3e M2("\u5229\u7528\u751f\u6210\u5148\u9a8c\u91cd\u5efa/Use generative priors for reconstruction")\n    Method --\x3e M3("\u538b\u7f29-\u8ba1\u7b97\u6743\u8861\u7b56\u7565/Compression-computation trade-off")\n    Results --\x3e R1("\u5b9e\u73b0~0.02%\u538b\u7f29\u7387/Achieved ~0.02% compression rate")\n    Results --\x3e R2("\u4e3aAI Flow\u6846\u67b6\u8d4b\u80fd/Enables AI Flow framework")\n    Results --\x3e R3("\u5f00\u8f9f\u9ad8\u6548\u89c6\u9891\u901a\u4fe1\u65b0\u8303\u5f0f/Opens new practical video communication paradigm")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Automated Classification of First-Trimester Fetal Heart Views Using Ultrasound-Specific Self-Supervised Learning"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image classification], [self-supervised learning, masked autoencoder, vision transformer, ultrasound foundation model, fetal echocardiography]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Youssef Megahed, Aylin Erman, Robin Ducharme, Mark C. Walker, Steven Hawken, Adrian D. C. Chan"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Carleton University, University of Ottawa, Ottawa Hospital Research Institute"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24492",children:"https://arxiv.org/pdf/2512.24492"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Evaluated a self-supervised ultrasound foundation model (USF-MAE) for the challenging task of first-trimester fetal heart view classification. 2. Demonstrated that ultrasound-specific pretraining on a large, unlabeled dataset yields more transferable representations than models pretrained on natural images (ImageNet) or standard supervised CNNs. 3. Showed robust performance without the need for aggressive image preprocessing or region-of-interest cropping, and improved discrimination of non-diagnostic frames."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f73d9d90b381ff2a6f244e15b64b3e24d9b28e8c2fbe78fa50c79ef8f58d1c66_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f73d9d90b381ff2a6f244e15b64b3e24d9b28e8c2fbe78fa50c79ef8f58d1c66_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of automated first-trimester fetal heart view classification in ultrasound by fine-tuning a self-supervised ultrasound foundation model (USF-MAE). The model, pretrained on over 370,000 unlabeled ultrasound images, outperformed supervised CNN baselines and a natural image-pretrained Vision Transformer, achieving over 90% accuracy. The results indicate that ultrasound-specific self-supervised pretraining enables more generalizable representations for early fetal cardiac imaging."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Automated Classification of First-Trimester Fetal Heart Views<br>\u65e9\u5b55\u671f\u80ce\u513f\u5fc3\u810f\u89c6\u56fe\u81ea\u52a8\u5206\u7c7b] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[Problem: Early detection of congenital heart disease is challenging<br>\u6838\u5fc3\u95ee\u9898: \u5148\u5929\u6027\u5fc3\u810f\u75c5\u65e9\u671f\u68c0\u6d4b\u56f0\u96be]\n    C[Method: Fine-tune USF-MAE, an ultrasound-specific self-supervised model<br>\u4e3b\u8981\u65b9\u6cd5: \u5fae\u8c03\u8d85\u58f0\u4e13\u7528\u81ea\u76d1\u7763\u6a21\u578bUSF-MAE]\n    D[Results: Achieved SOTA 90.57% accuracy, outperforming baselines<br>\u5173\u952e\u7ed3\u679c: \u8fbe\u523090.57%\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Generative AI-enhanced Sector-based Investment Portfolio Construction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [quantitative finance], [portfolio optimization, large language models, sector-based investment, Sharpe ratio, regime shift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alina Voronina, Oleksandr Romanko, Ruiwen Cao, Roy H. Kwon, Rafael Mendoza-Arriaga"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Ukrainian Catholic University, SS&C Algorithmics, University of Toronto, Hong Kong Polytechnic University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24526",children:"https://arxiv.org/pdf/2512.24526"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducts a multi-model, cross-provider evaluation of LLMs (OpenAI, Google, Anthropic, DeepSeek, xAI) for stock selection in quantitative portfolio construction. 2. Demonstrates a strong temporal dependence in LLM portfolio performance, showing outperformance in stable markets but underperformance in volatile periods. 3. Proposes and validates a hybrid framework that improves performance and consistency by combining LLM-based stock selection with classical portfolio optimization techniques."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76999779560abd5e04b9d83f5cf53223a1c444ffacf2142f6df9f0e236e87dd0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76999779560abd5e04b9d83f5cf53223a1c444ffacf2142f6df9f0e236e87dd0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates using LLMs from multiple providers to select and weight stocks for sector-based portfolios. The study finds that while LLM-weighted portfolios can outperform sector indices in stable markets, they struggle during volatile periods; however, combining LLM selection with traditional optimization improves outcomes. The results highlight the potential and current limitations of LLMs in investment management, advocating for hybrid AI-quantitative frameworks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Generative AI-enhanced Sector-based Investment Portfolio Construction] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: How can LLMs be applied to quantitative sector-based portfolio construction?]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: Prompt LLMs to select/weight stocks, combine with classical portfolio optimization, evaluate across stable and volatile periods.]\n    D[\u5173\u952e\u7ed3\u679c/Results: LLM performance is market-dependent; hybrid frameworks (LLM + optimization) improve performance and consistency.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image reconstruction], [disentangled representation, latent diffusion model, self-supervised learning, multidimensional MRI, zero-shot adaptation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ruiyang Zhao, Fan Lam"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24674",children:"https://arxiv.org/pdf/2512.24674"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A novel learned feature-based image representation that disentangles features like geometry and contrast into distinct latent spaces. 2. The integration of a latent diffusion model to impose stronger constraints on the disentangled feature spaces. 3. New reconstruction formulations and algorithms that combine the learned representation with zero-shot self-supervised learning adaptation and subspace modeling."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f858a20b731ce7ed66cd4e854bc6e6bdd5ae01548b1060d4814f643684ce73a0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f858a20b731ce7ed66cd4e854bc6e6bdd5ae01548b1060d4814f643684ce73a0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new method for reconstructing multidimensional MRI data by learning a disentangled image representation that separates features like geometry and contrast into distinct latent spaces, enhanced by a latent diffusion model. The approach integrates this representation with zero-shot self-supervised learning, enabling improved reconstruction without task-specific training. It demonstrates superior performance on accelerated T1 and T2 parameter mapping compared to state-of-the-art methods."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["An Adaptive, Disentangled Representation for Multidimensional MRI Reconstruction"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Limited data for task-specific training in multidimensional MRI reconstruction"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Disentangled representation + Latent diffusion model + Zero-shot self-supervised adaptation"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Improved performance on T1/T2 mapping without task-specific training"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] AstroReview: An LLM-driven Multi-Agent Framework for Telescope Proposal Peer Review and Refinement"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent framework, automated peer review, LLM-driven, reasoning traces, iterative refinement]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yutong Wang, Yunxiang Xiao, Yonglin Tian, Junyong Li, Jing Wang, Yisheng Lv"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24754",children:"https://arxiv.org/pdf/2512.24754"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. An open-source, multi-agent framework (AstroReview) that automates telescope proposal review in three structured stages (novelty/merit, feasibility/yield, meta-review/verification). 2. A design employing task isolation and explicit reasoning traces to curb LLM hallucinations and improve review transparency and auditability. 3. An "AstroReview in Action" module that demonstrates an iterative review-refinement loop, increasing proposal acceptance rates by 66% after two revision cycles.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74800e2a96855acce45d842bc6dfc7d6ea4c32d6def9f45717a69483ec603078_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74800e2a96855acce45d842bc6dfc7d6ea4c32d6def9f45717a69483ec603078_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents AstroReview, an LLM-driven multi-agent framework designed to automate and scale the peer review process for astronomical telescope proposals. The system operates in three stages to assess scientific merit, feasibility, and review reliability, using task isolation and reasoning traces to improve transparency. The results show it can identify accepted proposals with 87% accuracy and, through an iterative feedback loop, significantly improve the quality and acceptance rate of revised proposals."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AstroReview: An LLM-driven Multi-Agent Framework for Telescope Proposal Peer Review and Refinement] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u671b\u8fdc\u955c\u63d0\u6848\u8bc4\u5ba1\u6210\u4e3a\u74f6\u9888/Proposal review is a bottleneck]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u4e09\u9636\u6bb5\u591a\u667a\u80fd\u4f53\u6846\u67b6/Three-stage multi-agent framework]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 87%\u51c6\u786e\u7387\uff0c\u63a5\u53d7\u7387\u63d0\u534766%/87% accuracy, 66% acceptance rate increase]\n    B --\x3e B1[\u63d0\u6848\u91cf\u8d85\u8fc7\u53ef\u7528\u65f6\u95f4/Proposal volume > telescope time]\n    C --\x3e C1[\u65b0\u9896\u6027\u4e0e\u79d1\u5b66\u4ef7\u503c/Novelty & scientific merit]\n    C --\x3e C2[\u53ef\u884c\u6027\u4e0e\u9884\u671f\u4ea7\u51fa/Feasibility & expected yield]\n    C --\x3e C3[\u5143\u8bc4\u5ba1\u4e0e\u53ef\u9760\u6027\u9a8c\u8bc1/Meta-review & reliability verification]\n    D --\x3e D1[\u6b63\u786e\u8bc6\u522b\u5df2\u63a5\u53d7\u63d0\u6848/Correctly identifies accepted proposals]\n    D --\x3e D2[\u8fed\u4ee3\u53cd\u9988\u63d0\u5347\u63d0\u6848\u8d28\u91cf/Iterative feedback improves proposal quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] The Impact of LLMs on Online News Consumption and Production"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [ai economics], [staggered difference-in-differences, synthetic difference-in-differences, robots.txt]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hangcheng Zhao, Ron Berman"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Rutgers Business School, The Wharton School of the University of Pennsylvania"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24968",children:"https://arxiv.org/pdf/2512.24968"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Quantified a moderate decline in news publisher website traffic following the rise of generative AI. 2. Demonstrated that blocking GenAI bots via robots.txt can paradoxically reduce total and real consumer traffic for large publishers. 3. Provided empirical evidence that, contrary to predictions, LLMs have not yet reduced editorial hiring and have shifted publisher content strategy towards rich media and advertising."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7836df9e705d8a023a351c30d3595b1ff6e9614cf1d805218347987098aa3882_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7836df9e705d8a023a351c30d3595b1ff6e9614cf1d805218347987098aa3882_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper empirically investigates the impact of Large Language Models (LLMs) on online news publishers using high-frequency data and causal inference methods like difference-in-differences. It finds that blocking LLM crawlers reduces publisher traffic, LLMs have not yet replaced editorial jobs, and publishers are shifting to rich content and advertising tech. The results reveal unforeseen consequences of LLM adoption on the news ecosystem."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Impact of LLMs on Online News Consumption and Production] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u5982\u4f55\u5f71\u54cd\u65b0\u95fb\u751f\u4ea7\u4e0e\u6d88\u8d39/How LLMs affect news production and consumption]\n    C --\x3e C1[\u9ad8\u9891\u6570\u636e\u4e0e\u56e0\u679c\u63a8\u65ad/High-frequency data & Causal inference]\n    D --\x3e D1[\u6d41\u91cf\u4e0b\u964d/Traffic decline]\n    D --\x3e D2[\u5c4f\u853d\u722c\u866b\u53cd\u6548\u679c/Blocking bots backfires]\n    D --\x3e D3[\u7f16\u8f91\u5c97\u4f4d\u672a\u51cf\u5c11/Editorial jobs not reduced]\n    D --\x3e D4[\u5185\u5bb9\u8f6c\u5411\u5bcc\u5a92\u4f53/Shift to rich content]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [sequence learning], [formal language theory, symbolic sequences, benchmark suite, cognitive modeling, sequence processing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Barna Zajzon, Younes Bouhadjar, Maxime Fabre, Felix Schmidt, Noah Ostendorf, Emre Neftci, Abigail Morrison, Renato Duarte"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," J\xfclich Research Centre, RWTH Aachen University, University of Groningen, University of Coimbra"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24977",children:"https://arxiv.org/pdf/2512.24977"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces SymSeq, a tool for the rigorous generation and analysis of structured symbolic sequences. 2. Introduces SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks for evaluating AI systems. 3. Provides a unified, domain-agnostic framework (SymSeqBench) based on Formal Language Theory to standardize experiments across cognitive science and AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71331410faecaa464fb09419a580962b2cddad2a5e128910f8482dc81e965858_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71331410faecaa464fb09419a580962b2cddad2a5e128910f8482dc81e965858_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SymSeqBench, a unified software framework combining a symbolic sequence generator/analyzer (SymSeq) and a benchmark suite (SeqBench) for evaluating sequence learning. It is based on Formal Language Theory to provide a domain-agnostic, formal link between computation and cognition. The main conclusion is that this modular, open-source tool offers a versatile and standardized way to investigate sequential structure across diverse fields like psycholinguistics, cognitive psychology, and AI."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[SymSeqBench: \u7edf\u4e00\u6846\u67b6] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u8bc4\u4f30\u5e8f\u5217\u5b66\u4e60/Evaluating Sequence Learning]\n    Problem --\x3e P2[\u9886\u57df\u65e0\u5173\u7684\u8bc4\u4f30/Domain-Agnostic Evaluation]\n    Problem --\x3e P3[\u8fde\u63a5\u5f62\u5f0f\u7406\u8bba\u4e0e\u8ba4\u77e5/Linking Formal Theory & Cognition]\n    Method --\x3e M1[SymSeq: \u751f\u6210\u4e0e\u5206\u6790/SymSeq: Generation & Analysis]\n    Method --\x3e M2[SeqBench: \u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6/SeqBench: Benchmark Suite]\n    Method --\x3e M3[\u57fa\u4e8e\u5f62\u5f0f\u8bed\u8a00\u7406\u8bba/Based on Formal Language Theory]\n    Results --\x3e R1[\u8de8\u9886\u57df\u591a\u529f\u80fd/Versatile Across Domains]\n    Results --\x3e R2[\u6807\u51c6\u5316\u5b9e\u9a8c/Standardizes Experiments]\n    Results --\x3e R3[\u6a21\u5757\u5316\u5f00\u6e90\u5de5\u5177/Modular Open-Source Tool]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);