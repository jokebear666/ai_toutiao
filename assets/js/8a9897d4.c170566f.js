"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6601],{28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(96540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}},56822:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_PL/20251229-20260104","title":"20251229-20260104 (cs.PL)","description":"2025-12-29","source":"@site/docs/daily/cs_PL/20251229-20260104.md","sourceDirName":"daily/cs_PL","slug":"/daily/cspl/20251229-20260104","permalink":"/ai_toutiao/daily/cspl/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767243055000,"frontMatter":{"slug":"/daily/cspl/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.PL)","permalink":"/ai_toutiao/daily/cspl/20251222-20251228"},"next":{"title":"cs.RO","permalink":"/ai_toutiao/daily/csro"}}');var r=i(74848),t=i(28453);const a={slug:"/daily/cspl/20251229-20260104"},o="20251229-20260104 (cs.PL)",l={},c=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2},{value:"2026-01-01",id:"2026-01-01",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251229-20260104-cspl",children:"20251229-20260104 (cs.PL)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] AInsteinBench: Benchmarking Coding Agents on Scientific Repositories"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [software engineering], [benchmark, scientific computing, code generation, pull requests, test-driven verification]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," ByteDance Seed, Princeton University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21373",children:"https://arxiv.org/pdf/2512.21373"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/ByteDance-Seed/AInsteinBench",children:"https://github.com/ByteDance-Seed/AInsteinBench"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Can LLM agents operate as scientific computing development agents?]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: End-to-end evaluation using tasks from real scientific pull requests]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Measures ability beyond surface-level code generation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251229] Quantitative Verification of Omega-regular Properties in Probabilistic Programming"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [probabilistic programming and verification], [temporal posterior inference, omega-regular properties, stochastic barrier certificates, Rabin automata, quantitative verification]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Peixin Wang, Jianhao Bai, Min Zhang, C.-H. Luke Ong"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," East China Normal University, Nanyang Technological University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21596",children:"https://arxiv.org/pdf/2512.21596"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Temporal Posterior Inference (TPI), a new framework unifying probabilistic programming with temporal logic to compute posterior distributions over execution traces satisfying omega-regular properties. 2. Develops a novel method for computing rigorous upper and lower bounds on satisfaction probabilities by decomposing Rabin acceptance conditions and constructing sound stochastic barrier certificates. 3. Implements the approach in a prototype tool named TPInfer and demonstrates its effectiveness and efficiency on a suite of benchmarks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c111a01f9d5e96a85d9b5c62645dae0f5bb40053d723e34cb57dc7f31554dcda_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c111a01f9d5e96a85d9b5c62645dae0f5bb40053d723e34cb57dc7f31554dcda_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the limitation of standard probabilistic program inference, which fails to capture temporal behavior, by proposing Temporal Posterior Inference (TPI). TPI computes posterior distributions over program traces that satisfy omega-regular temporal specifications, using a method based on stochastic barrier certificates to provide quantitative verification bounds. The approach is implemented in the TPInfer tool and shown to be effective for inference over rich temporal properties."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Quantitative Verification of Omega-regular Properties in Probabilistic Programming") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u6807\u51c6\u540e\u9a8c\u63a8\u65ad\u7684\u5c40\u9650/Limitation of Standard Posterior Inference")\n    P1 --\x3e P2("\u65e0\u6cd5\u6355\u6349\u7a0b\u5e8f\u6267\u884c\u7684\u65f6\u95f4\u6f14\u5316/Fails to capture temporal evolution")\n    Method --\x3e M1("\u63d0\u51fa\u65f6\u95f4\u540e\u9a8c\u63a8\u65ad\u6846\u67b6/Propose Temporal Posterior Inference (TPI)")\n    M1 --\x3e M2("\u7edf\u4e00\u6982\u7387\u7f16\u7a0b\u4e0e\u65f6\u5e8f\u903b\u8f91/Unifies Probabilistic Programming & Temporal Logic")\n    M2 --\x3e M3("\u57fa\u4e8e\u968f\u673a\u5c4f\u969c\u8bc1\u4e66\u7684\u5b9a\u91cf\u9a8c\u8bc1\u65b9\u6cd5/Quantitative Verification via Stochastic Barrier Certificates")\n    Results --\x3e R1("\u5b9e\u73b0\u539f\u578b\u5de5\u5177 TPInfer/Implement Prototype Tool TPInfer")\n    Results --\x3e R2("\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u6709\u6548\u6027\u4e0e\u6548\u7387/Demonstrates Effectiveness & Efficiency on Benchmarks")'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [spatial dataflow, tile-based compilation, MLIR, on-chip network, hardware representation]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Wei Li, Zhenyu Bai, Heru Wang, Pranav Dangi, Zhiqiang Zhang, Cheng Tan, Huiying Lan, Weng-Fai Wong, Tulika Mitra"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," National University of Singapore, Arizona State University, Google, Lumai Ltd."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22168",children:"https://arxiv.org/pdf/2512.22168"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An end-to-end compiler framework (TL) that compiles tile-based programs (e.g., Triton kernels) onto spatial dataflow architectures, focusing on distributing tile instances across cores. 2. A novel hardware representation that captures interconnect topology, memory hierarchy, and compute capabilities to enable architecture-specific optimizations and support diverse targets. 3. A practical implementation built on the MLIR ecosystem, providing a generic entry point for different front-ends and an end point for different back-ends, demonstrated with performance gains over vendor libraries."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents TL, an end-to-end compiler framework that tackles the limited programmability of spatial dataflow accelerators by automatically mapping tile-based workloads across distributed cores to optimize data reuse and reduce communications. TL introduces a hardware-aware representation and is built on MLIR to support diverse targets. Experiments show it can match or exceed the performance of hand-tuned vendor libraries on kernels like GEMM and FlashAttention."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[TL: Automatic End-to-End Compiler] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Limited Programmability of Spatial Accelerators<br/>\u7a7a\u95f4\u52a0\u901f\u5668\u7684\u6709\u9650\u53ef\u7f16\u7a0b\u6027]\n    Problem --\x3e P2[Poor Performance of Naive Mappings<br/>\u6734\u7d20\u6620\u5c04\u6027\u80fd\u5dee]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[End-to-End Tile-Based Compiler Framework<br/>\u7aef\u5230\u7aef\u57fa\u4e8e\u5206\u5757\u7684\u7f16\u8bd1\u5668\u6846\u67b6]\n    Method --\x3e M2[Hardware Representation for Topology & Memory<br/>\u7528\u4e8e\u62d3\u6251\u548c\u5185\u5b58\u7684\u786c\u4ef6\u8868\u793a]\n    Method --\x3e M3[Built on MLIR Ecosystem<br/>\u57fa\u4e8eMLIR\u751f\u6001\u7cfb\u7edf\u6784\u5efa]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Performance on par with/vs Vendor Library (GEMM)<br/>\u6027\u80fd\u4e0e\u5382\u5546\u5e93\u76f8\u5f53/\u8d85\u8d8a(GEMM)]\n    Results --\x3e R2[Significant Speedup for FlashAttention<br/>FlashAttention\u663e\u8457\u52a0\u901f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [megakernel, kernel fusion, SM-level graph, software pipelining, CUDA]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, Tsinghua University, NVIDIA, University of Michigan, Purdue University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22219",children:"https://arxiv.org/pdf/2512.22219"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/mirage-project/mirage",children:"https://github.com/mirage-project/mirage"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces an SM-level graph representation for capturing fine-grained data dependencies across GPU streaming multiprocessors. 2. Develops a compiler and an in-kernel parallel runtime that automatically transforms multi-operator inference into a single, high-performance mega-kernel. 3. Enables previously infeasible GPU optimizations like cross-operator software pipelining and fine-grained kernel overlap, significantly reducing inference latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces Mirage Persistent Kernel (MPK), a compiler and runtime system that automatically fuses multiple GPU kernels for model inference into a single, optimized mega-kernel. It achieves this by using a novel SM-level graph representation and decentralized scheduling to enable fine-grained optimizations like software pipelining. Evaluation shows MPK reduces LLM inference latency by up to 1.7x, pushing performance close to hardware limits."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Mirage Persistent Kernel<br>\u5e7b\u5f71\u6301\u4e45\u5185\u6838] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Kernel-per-operator execution<br>limits GPU optimization<br>\u9010\u7b97\u5b50\u5185\u6838\u6267\u884c\u9650\u5236GPU\u4f18\u5316]\n    C --\x3e C1[SM-level graph &<br>mega-kernel runtime<br>SM\u7ea7\u56fe\u4e0e\u5de8\u578b\u5185\u6838\u8fd0\u884c\u65f6]\n    D --\x3e D1[Reduces inference latency<br>by up to 1.7x<br>\u63a8\u7406\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe1.7\u500d]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Symbolic Specification and Reasoning for Quantum Data and Operations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [other], [quantum programming languages & verification], [symbolic logic, formal verification, quantum computation, automated reasoning, SOL]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Mingsheng Ying"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Technology Sydney"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22383",children:"https://arxiv.org/pdf/2512.22383"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel logical framework called Symbolic Operator Logic (SOL) for symbolic specification of quantum data and operations., 2. Embeds classical first-order logic into SOL to enable reasoning about quantum properties modulo theories of classical data, leveraging existing classical verification tools., 3. Provides a conceptual foundation for formal verification and automated theorem proving of quantum computation in proof assistants like Lean and Coq."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d170e9ed692953b589cb0ca609b55da71b661300061784405cc0fe9e73f4c680_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d170e9ed692953b589cb0ca609b55da71b661300061784405cc0fe9e73f4c680_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of a formal theory for symbolic reasoning in quantum computing by introducing a general logical framework called Symbolic Operator Logic (SOL). The core method embeds classical first-order logic into a language of formal operators for quantum specifications, enabling automated reasoning by reusing classical verification tools. The authors conclude that SOL provides a foundational framework for the formal verification of quantum algorithms and programs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Symbolic Specification and Reasoning for Quantum Data and Operations"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>\u7f3a\u4e4f\u91cf\u5b50\u6570\u636e\u4e0e\u64cd\u4f5c\u7684\u5f62\u5f0f\u5316\u7b26\u53f7\u63a8\u7406\u7406\u8bba"] --\x3e P1["\u5bfc\u81f4\u7ed3\u679c/Consequence<br>\u9650\u5236\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u9a8c\u8bc1\u7684\u5b9e\u7528\u6027"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u63d0\u51fa\u7b26\u53f7\u7b97\u5b50\u903b\u8f91(SOL)\u6846\u67b6"] --\x3e M1["\u5173\u952e\u6280\u672f/Key Technique<br>\u5c06\u7ecf\u5178\u4e00\u9636\u903b\u8f91\u5d4c\u5165\u5f62\u5f0f\u7b97\u5b50\u8bed\u8a00"]\n    Method --\x3e M2["\u4f18\u52bf/Advantage<br>\u57fa\u4e8e\u7ecf\u5178\u6570\u636e\u7406\u8bba(\u5982\u5e03\u5c14\u4ee3\u6570)\u8fdb\u884c\u63a8\u7406"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>\u4e3a\u91cf\u5b50\u8ba1\u7b97\u5f62\u5f0f\u9a8c\u8bc1\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840"] --\x3e R1["\u5e94\u7528\u524d\u666f/Application<br>\u7528\u4e8eLean, Coq\u7b49\u8bc1\u660e\u52a9\u624b"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Eliminate Branches by Melding IR Instructions"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [branch elimination, if-conversion, instruction melding, sequence alignment, LLVM pass]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yuze Li, Srinivasan Ramachandra Sharma, Charitha Saumya, Ali R. Butt, Kirshanthan Sundararajah"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Virginia Tech, Intel Corporation"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22390",children:"https://arxiv.org/pdf/2512.22390"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MERIT, a novel compiler transformation that eliminates branches by aligning and melding similar operations from divergent paths at the IR level, differing from traditional if-conversion. 2. Adapts sequence alignment to discover merging opportunities and uses safe operand-level guarding to ensure correctness without hardware predication, overcoming limitations of speculation on architectures like x86. 3. Demonstrates effectiveness through an LLVM pass implementation, achieving a geometric mean speedup of 10.9% and up to 32x peak improvement over hardware branch prediction on 102 benchmark programs."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b6ca42fd8300cb0b345dbbb72918ff7cecfcb6403ae9595873d4e5ffdc15ac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b6ca42fd8300cb0b345dbbb72918ff7cecfcb6403ae9595873d4e5ffdc15ac_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the performance penalty from branch mispredictions by introducing MERIT, a compiler transformation that eliminates branches by aligning and melding similar instructions from divergent paths at the IR level. It uses sequence alignment to find merging opportunities and operand guarding for safety, avoiding the pitfalls of traditional if-conversion. Implemented in LLVM, MERIT achieves significant speedups, demonstrating its effectiveness in reducing branch overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Eliminate Branches by Melding IR Instructions] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Branch mispredictions cause performance loss; traditional if-conversion has limitations]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: MERIT - melds similar IR instructions from divergent paths using sequence alignment & operand guarding]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 10.9% mean speedup, up to 32x peak improvement, reduced instruction overhead]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] A Bounded Game Semantics Checker for Precise Smart Contract Analysis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [smart contract security], [game semantics, bounded model checking, Yul, reentrancy, trace enumeration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vasileios Koutavas, Yu-Yang Lin, Nikos Tzevelekos"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Trinity College Dublin, Lero - the Science Foundation Ireland Research Centre for Software, Queen Mary University of London"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22417",children:"https://arxiv.org/pdf/2512.22417"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a precise, bounded-complete vulnerability detection method for smart contracts based on game semantics, which models contract-environment interactions to reduce reasoning about external contracts to trace enumeration., 2. Implements the approach in YulToolkit, a tool for the Yul intermediate language that avoids over-approximation by exploring only feasible interactions and supports instrumentation for tractable analysis., 3. Demonstrates the tool's effectiveness by successfully detecting known vulnerabilities (e.g., reentrancy) in real-world incidents like The DAO and benchmark contracts, with no false positives within the analysis bounds."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d265d01c22405ca441e39696a7690570d06e75e375e5f9138e9d8f0d3b02e5c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d265d01c22405ca441e39696a7690570d06e75e375e5f9138e9d8f0d3b02e5c_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a new approach for precise smart contract vulnerability detection using bounded game semantics. The method, implemented in the YulToolkit, models computation as contract-environment interactions to explore all feasible traces within bounds, avoiding false positives. Evaluation on real-world incidents shows it effectively detects complex vulnerabilities like reentrancy."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["A Bounded Game Semantics Checker for Precise Smart Contract Analysis"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Smart contract vulnerabilities lead to significant financial losses; existing tools suffer from false positives, false negatives, or scalability issues."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Bounded game semantics modeling; YulToolkit implementation for Yul; Feasible trace enumeration with instrumentation."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Detects known vulnerabilities (e.g., in The DAO) precisely; No false positives within bounds; Effective for hard-to-detect bugs like reentrancy."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Compiling Gradual Types with Evidence"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [gradual typing], [evidence-based semantics, monotonic references, structural types]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jos\xe9 Luis Romero, Crist\xf3bal Isla, Mat\xedas Toro, \xc9ric Tanter"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," PLEIAD Lab, Computer Science Department (DCC), University of Chile"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22684",children:"https://arxiv.org/pdf/2512.22684"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Designed and implemented GrEv, an evidence-based compiler for gradual typing, demonstrating its viability for efficient implementation. 2. Bridged the gap between the formal Abstracting Gradual Typing (AGT) semantics and a practical compiler, identifying novel monotonic semantics. 3. Showed through empirical evaluation that the evidence-based approach can be competitive with and sometimes faster than coercion-based approaches, while offering more stable performance across the static-dynamic spectrum."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb574126eb37250ba1fbd02c5000fce4a412197f9e248e6204ab7c46a65c386d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb574126eb37250ba1fbd02c5000fce4a412197f9e248e6204ab7c46a65c386d_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of efficiently implementing sound gradual typing for languages with structural types. It proposes GrEv, a compiler based on the evidence-based semantics from the Abstracting Gradual Typing methodology, and demonstrates that this approach can achieve performance competitive with or better than existing coercion-based compilers."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Compiling Gradual Types with Evidence"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Is evidence-based semantics viable for efficient gradual typing implementation?"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Design & implement GrEv compiler using evidence-based semantics"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>GrEv is competitive/faster than coercion-based, more stable performance"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Anka: A Domain-Specific Language for Reliable LLM Code Generation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Domain-Specific Language, Constrained Syntax, Code Generation, Data Transformation Pipeline, In-Context Learning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Saif Khalfan Saif Al Mazrouei"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Wisconsin-Madison"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23214",children:"https://arxiv.org/pdf/2512.23214"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Anka: A Domain-Specific Language for Reliable LLM Code Generation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs make systematic errors in complex multi-step code generation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Design Anka, a constrained DSL for data transformation pipelines]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: High parse success & task accuracy; Anka outperforms Python on multi-step tasks]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Verifying Asynchronous Hyperproperties in Reactive Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [formal verification], [asynchronous hyperproperties, HyperLTL, model checking, game semantics, observational determinism]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Raven Beutner, Bernd Finkbeiner"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," CISPA Helmholtz Center for Information Security"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23344",children:"https://arxiv.org/pdf/2512.23344"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel game-based approach for verifying arbitrary \u2200\u2217\u2203\u2217 formulas in Asynchronous HyperLTL (A-HLTL) in reactive systems. 2. Interprets verification as a game between a verifier and refuter, where a winning strategy provides witnesses for traces and asynchronous alignments for stutterings. 3. Identifies fragments for which the game-based interpretation is complete, providing a finite-state decision procedure, and contributes a prototype implementation with encouraging experimental results."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e321908ac7277c8c91e3b8e509efae3be66dbe7c391e613f19a6ca343db4f16_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e321908ac7277c8c91e3b8e509efae3be66dbe7c391e613f19a6ca343db4f16_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of model-checking asynchronous hyperproperties in reactive systems, which require comparing execution traces across different timesteps. It proposes a novel game-based verification method for a logic called Asynchronous HyperLTL (A-HLTL), interpreting the problem as a two-player game to find suitable trace stutterings. The approach provides a decision procedure for certain formula fragments and is supported by a prototype implementation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Verifying Asynchronous Hyperproperties in Reactive Systems] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u540c\u6b65HyperLTL\u65e0\u6cd5\u8868\u8fbe\u5f02\u6b65\u8d85\u5c5e\u6027/Synchronous HyperLTL cannot express asynchronous hyperproperties]\n    Problem --\x3e P2[\u73b0\u6709\u65b9\u6cd5\u9650\u5236\u4e8e\u53d7\u9650\u7247\u6bb5\u6216\u7ec8\u6b62\u7cfb\u7edf/Existing methods limited to restricted fragments or terminating systems]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u63d0\u51fa\u57fa\u4e8e\u6e38\u620f\u7684\u9a8c\u8bc1\u65b9\u6cd5/Propose a game-based verification approach]\n    Method --\x3e M2[\u9a8c\u8bc1\u8005\u4e0e\u53cd\u9a73\u8005\u7684\u53cc\u4eba\u6e38\u620f/Two-player game between verifier and refuter]\n    Method --\x3e M3[\u83b7\u80dc\u7b56\u7565\u5bf9\u5e94\u5b58\u5728\u91cf\u5316\u7684\u8bc1\u636e/Winning strategy corresponds to witnesses for existential quantification]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u4e3a\u2200\u2217\u2203\u2217 A-HLTL\u516c\u5f0f\u63d0\u4f9b\u65b9\u6cd5/Provides method for arbitrary \u2200\u2217\u2203\u2217 A-HLTL formulas]\n    Results --\x3e R2[\u8bc6\u522b\u5b8c\u5168\u6027\u7684\u7247\u6bb5/Identifies fragments for which the interpretation is complete]\n    Results --\x3e R3[\u539f\u578b\u5b9e\u73b0\u4e0e\u5b9e\u9a8c\u7ed3\u679c/Prototype implementation and experimental results]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Adaptable TeaStore: A Choreographic Approach"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [choreographic programming], [adaptable microservices, choreographic programming, AIOCJ, runtime adaptation, communication correctness]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Giuseppe De Palma, Saverio Giallorenzo, Ivan Lanese, Gianluigi Zavattaro"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Universit\xe0 di Bologna, INRIA"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23497",children:"https://arxiv.org/pdf/2512.23497"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"}),"  1. Presents an implementation of the Adaptable TeaStore reference model using the AIOCJ choreographic language. 2. Demonstrates that AIOCJ ensures by-construction correctness of communications (e.g., deadlock freedom) before, during, and after runtime adaptation. 3. Provides an analysis of the strengths and current limitations of the choreographic approach for adaptable cloud architectures, suggesting future refinements."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper models the Adaptable TeaStore, a reference model for adaptable microservice architectures, using the AIOCJ choreographic programming language. The approach ensures communication correctness by construction and supports dynamic runtime adaptation. The work showcases the paradigm's strengths, identifies its limitations, and suggests future directions to better align it with real-world cloud systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Adaptable TeaStore: A Choreographic Approach") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u9700\u8981\u53ef\u9002\u5e94\u7684\u5fae\u670d\u52a1\u67b6\u6784/Need for adaptable microservice architectures")\n    Method --\x3e M1("\u4f7f\u7528AIOCJ\u7f16\u6392\u8bed\u8a00/Use AIOCJ choreographic language")\n    Method --\x3e M2("\u786e\u4fdd\u901a\u4fe1\u6b63\u786e\u6027/Ensure communication correctness")\n    Results --\x3e R1("\u5c55\u793a\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u5c40\u9650/Showcase strengths and limitations")\n    Results --\x3e R2("\u63d0\u51fa\u672a\u6765\u6539\u8fdb\u65b9\u5411/Propose future refinements")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Fancy Some Chips for Your TeaStore? Modeling the Control of an Adaptable Discrete System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [modeling languages, control theory, distributed systems], [Chips, control theory, component-based modeling, Adaptable TeaStore, BIP]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Anna Gallone, Simon Bliudze, Sophie Cerf, Olga Kouchnarenko"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Universit\xe9 Marie et Louis Pasteur (FEMTO-ST), Univ. Lille (Inria, CNRS, CRIStAL)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23496",children:"https://arxiv.org/pdf/2512.23496"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/NwaitDev/Chips_Public",children:"https://github.com/NwaitDev/Chips_Public"}),", ",(0,r.jsx)(n.a,{href:"https://github.com/NwaitDev/TeaStore-Variation",children:"https://github.com/NwaitDev/TeaStore-Variation"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces Chips, a novel language for designing models of complex, intertwined systems by mixing control theory with general-purpose programming concepts. 2. Enables systematic design, modeling, and analysis of adaptable systems through functional block descriptions. 3. Demonstrates the language's application and utility using a variation of the Adaptable TeaStore as a concrete running example."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces Chips, a modeling language that combines control theory with programming concepts to facilitate the design and analysis of robust, component-based systems. The method is demonstrated on an Adaptable TeaStore application, showing how Chips can be used to systematically model complex, interacting entities like software, hardware, and services. The main conclusion is that Chips aids in ensuring system robustness and quality of service for web applications and cyber-physical systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[Fancy Some Chips for Your TeaStore?<br/>Modeling the Control of an Adaptable Discrete System] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br/>Web\u5e94\u7528\u9700\u7ba1\u7406\u590d\u6742\u3001\u76f8\u4e92\u4f9d\u8d56\u7684\u8d44\u6e90\u4ee5\u786e\u4fdd\u9c81\u68d2\u6027] --\x3e Problem_Detail[\u7cfb\u7edf\u590d\u6742/Complex System<br/>\u8f6f\u4ef6\u3001\u786c\u4ef6\u3001\u7f51\u7edc\u3001\u5fae\u670d\u52a1\u4ea4\u7ec7]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u63d0\u51faChips\u5efa\u6a21\u8bed\u8a00] --\x3e Method_Detail1[\u6df7\u5408\u6982\u5ff5/Mixed Concepts<br/>\u63a7\u5236\u7406\u8bba + \u901a\u7528\u7f16\u7a0b\u8bed\u8a00]\n    Method --\x3e Method_Detail2[\u529f\u80fd\u5757\u63cf\u8ff0/Functional Blocks<br/>\u751f\u6210\u9c81\u68d2\u7684\u7ec4\u4ef6\u6a21\u578b]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br/>\u7cfb\u7edf\u5316\u8bbe\u8ba1\u3001\u5efa\u6a21\u4e0e\u5206\u6790] --\x3e Results_Detail[\u6848\u4f8b\u6f14\u793a/Case Study<br/>\u4f7f\u7528Adaptable TeaStore\u53d8\u4f53\u9a8c\u8bc1]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [dynamic deadlock prediction], [lock sets, critical sections, partial order relations, false positives, false negatives]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Martin Sulzmann"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Karlsruhe University of Applied Sciences"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23552",children:"https://arxiv.org/pdf/2512.23552"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a novel trace-based characterization of critical sections that can span multiple threads, correcting the standard per-thread model., 2. Proposes a sound approximation of the multi-thread critical section concept using partial order relations, enabling an improved lock set construction., 3. Integrates the improved lock set construction into an extended SPDOffline deadlock predictor, reducing both false positives and false negatives without impacting performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies that standard per-thread lock set analysis for deadlock prediction is flawed because it ignores locks acquired across thread boundaries, leading to inaccurate results. To solve this, the authors propose a new model of multi-thread critical sections and a sound approximation method using partial order relations to construct more precise lock sets. This approach, integrated into an extended predictor, reduces false positives and false negatives while maintaining performance."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6807\u51c6\u6bcf\u7ebf\u7a0b\u9501\u96c6\u5206\u6790\u5ffd\u7565\u8de8\u7ebf\u7a0b\u9501/Standard per-thread lock sets ignore cross-thread locks]\n    B1 --\x3e B2[\u5bfc\u81f4\u5047\u9633\u6027\u548c\u5047\u9634\u6027/Leads to false positives and false negatives]\n    C --\x3e C1[\u63d0\u51fa\u57fa\u4e8e\u8f68\u8ff9\u7684\u591a\u7ebf\u7a0b\u4e34\u754c\u533a\u6982\u5ff5/Propose trace-based multi-thread critical sections]\n    C1 --\x3e C2[\u4f7f\u7528\u504f\u5e8f\u5173\u7cfb\u8fdb\u884c\u53ef\u9760\u8fd1\u4f3c/Use partial order relations for sound approximation]\n    C2 --\x3e C3[\u6539\u8fdb\u9501\u96c6\u6784\u9020/Improved lock set construction]\n    D --\x3e D1[\u51cf\u5c11\u5047\u9633\u6027\u548c\u5047\u9634\u6027/Reduces false positives and false negatives]\n    D1 --\x3e D2[\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd/Performance not affected]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251230] Automating the Analysis of Parsing Algorithms (and other Dynamic Programs)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [nlp], [program analysis], [declarative programming, dynamic programming, static analysis, complexity analysis, Dyna]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Tim Vieira, Ryan Cotterell, Jason Eisner"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Johns Hopkins University, ETH Z\xfcrich"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23665",children:"https://arxiv.org/pdf/2512.23665"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/timvieira/dyna-pi",children:"https://github.com/timvieira/dyna-pi"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed a system for the automated static analysis of declarative programs, specifically those written in the Dyna language for dynamic programming. 2. Successfully applied the system to infer types, identify dead/redundant code, and derive parametric runtime and space complexity bounds for NLP algorithms. 3. Demonstrated the system's utility by correctly analyzing and tightening the known complexity bounds of existing NLP parsing algorithms (e.g., from O(n\u2077) to O(n\u2076))."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a554685bfd3ae13d5c3add707df8b528c44420979de28bdc7b5ff913d70b027_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a554685bfd3ae13d5c3add707df8b528c44420979de28bdc7b5ff913d70b027_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper develops an automated system for analyzing declarative programs, particularly dynamic programs used in NLP. The system helps programmers by statically inferring types, complexity bounds, and identifying code issues. The authors demonstrate its effectiveness by applying it to several NLP algorithms, where it successfully infers correct properties and even improves upon previously published complexity analyses."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("Automating the Analysis of Parsing Algorithms") --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: Manual analysis of dynamic programs is tedious and error-prone."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: Develop a system for automated static analysis of declarative (Dyna) programs."]\n    Results["\u5173\u952e\u7ed3\u679c/Results: System infers types, complexity bounds, and finds dead code; validates on NLP algorithms."]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2026-01-01",children:"2026-01-01"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Enforcing Temporal Constraints for LLM Agents"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [temporal constraints, SMT solving, constrained generation, formal verification, LLM agents]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Adharsh Kamath, Sishen Zhang, Calvin Xu, Shubham Ugare, Gagandeep Singh, Sasa Misailovic"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Illinois at Urbana-Champaign, Meta"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23738",children:"https://arxiv.org/pdf/2512.23738"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/structuredllm/agent-c",children:"https://github.com/structuredllm/agent-c"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel framework (Agent-C) providing runtime guarantees for LLM agents to adhere to formal temporal safety properties., 2. A domain-specific language for expressing temporal properties, which are translated to first-order logic and verified via SMT solving during token generation., 3. Demonstration of perfect safety (100% conformance) and improved task utility across real-world applications and multiple LLMs, outperforming state-of-the-art guardrails."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a978adfab8b202d7b971f6b65f8d005235baabb93f5540985ad131638c67354_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a978adfab8b202d7b971f6b65f8d005235baabb93f5540985ad131638c67354_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of LLM agents violating temporal safety policies, such as accessing data before authentication. It proposes Agent-C, a framework that uses a domain-specific language, formal logic translation, and SMT solving to enforce constraints during token generation, ensuring compliant actions. The evaluation shows Agent-C achieves 100% safety conformance and improves task utility compared to existing methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Enforcing Temporal Constraints for LLM Agents] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u62a4\u680f\u65e0\u6cd5\u4fdd\u8bc1\u65f6\u95f4\u5b89\u5168\u7b56\u7565/Existing guardrails fail to enforce temporal safety policies]\n    C --\x3e C1[\u63d0\u51faAgent-C\u6846\u67b6/Propose Agent-C framework]\n    C1 --\x3e C2[\u4f7f\u7528DSL\u548cSMT\u6c42\u89e3\u8fdb\u884c\u8fd0\u884c\u65f6\u9a8c\u8bc1/Use DSL & SMT solving for runtime verification]\n    C2 --\x3e C3[\u91c7\u7528\u7ea6\u675f\u751f\u6210\u786e\u4fdd\u5408\u89c4/Achieve compliance via constrained generation]\n    D --\x3e D1[100%\u5b89\u5168\u6027\uff0c0%\u5371\u5bb3/100% safety, 0% harm]\n    D --\x3e D2[\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u63d0\u9ad8\u4efb\u52a1\u6548\u7528/Improve task utility in real-world applications]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Towards representation agnostic probabilistic programming"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [compiler & ir], [factor abstraction, probabilistic programming, hybrid models, representation-agnostic, factor graphs]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Ole Fenske, Maximilian Popko, Sebastian Bader, Thomas Kirste"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Institute for Visual and Analytic Computing, University of Rostock"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23740",children:"https://arxiv.org/pdf/2512.23740"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a factor abstraction with five fundamental operations as a universal interface for manipulating probabilistic factors. 2. Enables representation-agnostic probabilistic programming, allowing the mixing of different distribution representations (e.g., discrete tables, Gaussians, samples) within a single framework. 3. Facilitates practical inference in complex hybrid (mixed discrete-continuous) models that current toolkits cannot adequately handle."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97ac8ba28932b58d58cfedc5a8c2d53a706dd206b4f545e3d26852fb3ee19d75_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97ac8ba28932b58d58cfedc5a8c2d53a706dd206b4f545e3d26852fb3ee19d75_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the tight coupling between model representations and inference algorithms in current probabilistic programming tools, which limits flexibility. It proposes a factor abstraction with a set of core operations to create a representation-agnostic interface. This allows users to mix various distribution representations, enabling inference in complex hybrid models previously difficult to express."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Towards representation agnostic probabilistic programming] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[PPLs\u8026\u5408\u8868\u793a\u4e0e\u63a8\u7406\u7b97\u6cd5/PPLs couple representations & inference]\n    B --\x3e B2[\u963b\u788d\u6df7\u5408\u6a21\u578b\u5b9e\u9a8c/Prevents hybrid model experimentation]\n    C --\x3e C1[\u5f15\u5165\u56e0\u5b50\u62bd\u8c61/Introduce factor abstraction]\n    C --\x3e C2[\u5b9a\u4e49\u4e94\u4e2a\u57fa\u672c\u64cd\u4f5c/Define five fundamental operations]\n    C --\x3e C3[\u521b\u5efa\u901a\u7528\u63a5\u53e3/Create universal interface]\n    D --\x3e D1[\u5b9e\u73b0\u8868\u793a\u65e0\u5173\u7f16\u7a0b/Enable representation-agnostic programming]\n    D --\x3e D2[\u652f\u6301\u6df7\u5408\u8868\u793a/Support mixing representations]\n    D --\x3e D3[\u5904\u7406\u590d\u6742\u6df7\u5408\u6a21\u578b/Handle complex hybrid models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python with Partitioning and Parallel Execution"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [memory management], [garbage collection, concurrent mark-and-sweep, memory fragmentation, parallel execution, zone-based architecture]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abdulla M"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Could not be determined from the provided content."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23768",children:"https://arxiv.org/pdf/2512.23768"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/Abdullahlab-n/VGC-for-arxiv",children:"https://github.com/Abdullahlab-n/VGC-for-arxiv"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces a dual-layer (Active and Passive) garbage collector architecture to separate compile-time and runtime memory management responsibilities., 2. Proposes a concurrent mark-and-sweep strategy for the Active VGC to reduce pause times in parallel workloads., 3. Employs predictive memory mapping and cache-aligned allocation in the Passive VGC to minimize fragmentation and reduce total memory usage."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0edb6409b92db2ec79f95ff72421bf0148b259c4251b261594c32563a128cb85_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0edb6409b92db2ec79f95ff72421bf0148b259c4251b261594c32563a128cb85_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes VGC, a novel garbage collector for Python designed to overcome performance bottlenecks like the GIL and fragmentation. It uses a dual-layer architecture with a runtime concurrent collector and a compile-time allocator to reduce pause times and memory usage. The results show significant improvements in performance and scalability for parallel applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    Root[VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[Python GC Bottlenecks: GIL, Pauses, Fragmentation]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Dual-Layer Architecture / \u53cc\u5c42\u67b6\u6784]\n    M1 --\x3e M1_1[Active VGC: Runtime Concurrent Mark-and-Sweep / \u8fd0\u884c\u65f6\u5e76\u53d1\u6807\u8bb0\u6e05\u9664]\n    M1 --\x3e M1_2[Passive VGC: Compile-Time Predictive Allocation / \u7f16\u8bd1\u65f6\u9884\u6d4b\u6027\u5206\u914d]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[Reduced Pause Times (up to 30%) / \u964d\u4f4e\u6682\u505c\u65f6\u95f4]\n    Results --\x3e R2[Reduced Memory Usage (up to 25%) / \u964d\u4f4e\u5185\u5b58\u4f7f\u7528]\n    Results --\x3e R3[Improved Scalability for Parallel Apps / \u63d0\u5347\u5e76\u884c\u5e94\u7528\u53ef\u6269\u5c55\u6027]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [speculative decoding, tree-based decoding, latency optimization, compiler-friendly execution, static runtime]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yue Guan, Changming Yu, Shihan Fang, Weiming Hu, Zaifeng Pan, Zheng Wang, Zihan Liu, Yangjie Zhou, Yufei Ding, Minyi Guo, Jingwen Leng"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shanghai Jiao Tong University, Shanghai Qizhi Institute, University of California, San Diego"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23858",children:"https://arxiv.org/pdf/2512.23858"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces an equal-growth tree structure for speculative decoding that is compatible with static graph compilers. 2. Proposes a latency-aware optimization objective for draft selection, moving beyond simple average accepted length. 3. Designs a stage-based scheduling mechanism to reduce runtime overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13cf851f76b89c86dd0ecc981628839d1ca0ba1772a6b9b893ec9677720b6be0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13cf851f76b89c86dd0ecc981628839d1ca0ba1772a6b9b893ec9677720b6be0_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper identifies a performance mismatch between dynamic speculative decoding algorithms and static runtime systems. It proposes Yggdrasil, a co-designed system that uses a context-aware tree drafting structure and compiler-friendly execution to achieve latency-optimal speculative decoding. The system supports unmodified LLMs and achieves up to 3.98x speedup over state-of-the-art baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Mismatch between dynamic speculation and static runtime assumptions leads to suboptimal performance]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Co-designed system with context-aware tree drafting and compiler-friendly execution]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Up to 3.98x speedup over SOTA baselines, supports unmodified LLMs]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260101] State Space Estimation for DPOR-based Model Checkers"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [se], [model checking], [DPOR, Mazurkiewicz trace, Monte Carlo estimation, state space estimation, stochastic enumeration]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," A. R. Balasubramanian, Mohammad Hossein Khoshechin Jorshari, Rupak Majumdar, Umang Mathur, Minjian Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Max Planck Institute for Software Systems (MPI-SWS), National University of Singapore, University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23996",children:"https://arxiv.org/pdf/2512.23996"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proved the #P-hardness and inapproximability of counting Mazurkiewicz trace-equivalence classes for concurrent programs, establishing the theoretical difficulty of the problem. 2. Introduced a poly-time unbiased Monte Carlo estimator by converting an optimal DPOR algorithm into a bounded tree and applying Knuth's estimator with stochastic enumeration for variance control. 3. Implemented and evaluated the estimator in the JMC model checker, demonstrating its practical effectiveness in providing stable estimates for large state spaces (10^5\u201310^6 classes) with modest computational budgets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f877162e9490ceb5356ddbd67ad74f3fbb0e6eefb7872252a112f618f8723e92_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f877162e9490ceb5356ddbd67ad74f3fbb0e6eefb7872252a112f618f8723e92_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of estimating the number of distinct behaviors (Mazurkiewicz trace-equivalence classes) in bounded concurrent programs to predict model checking runtime and progress. It proposes a Monte Carlo method that transforms a stateless optimal DPOR algorithm into an unbiased estimator, using Knuth's estimator and stochastic enumeration to control variance. The implemented estimator provides stable, practical estimates for large state spaces, offering the first provable poly-time unbiased solution for this important resource allocation problem."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[State Space Estimation for DPOR-based Model Checkers] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f30\u8ba1\u5e76\u53d1\u7a0b\u5e8f\u7684\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f/Estimate # of trace-equivalence classes]\n    B --\x3e B2[\u9884\u6d4b\u6a21\u578b\u68c0\u67e5\u6210\u672c\u4e0e\u8fdb\u5ea6/Predict model-checking cost & progress]\n    C --\x3e C1[\u5c06DPOR\u7b97\u6cd5\u8f6c\u4e3a\u65e0\u504f\u4f30\u8ba1\u5668/Convert DPOR to unbiased estimator]\n    C --\x3e C2[\u5e94\u7528Knuth\u4f30\u8ba1\u5668\u4e0e\u968f\u673a\u679a\u4e3e/Apply Knuth's estimator & stochastic enumeration]\n    D --\x3e D1[\u7406\u8bba: \u9996\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u65e0\u504f\u4f30\u8ba1\u5668/Theoretical: first poly-time unbiased estimator]\n    D --\x3e D2[\u5b9e\u8df5: \u5728JMC\u4e2d\u5b9e\u73b0, \u4f30\u8ba1\u7a33\u5b9a/ Practical: implemented in JMC, stable estimates]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);