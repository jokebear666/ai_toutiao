"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4610],{2827:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_IR/20251222-20251228","title":"20251222-20251228 (cs.IR)","description":"2025-12-22","source":"@site/docs/daily/cs_IR/20251222-20251228.md","sourceDirName":"daily/cs_IR","slug":"/daily/csir/20251222-20251228","permalink":"/ai_toutiao/daily/csir/20251222-20251228","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1766462881000,"frontMatter":{"slug":"/daily/csir/20251222-20251228"},"sidebar":"tutorialSidebar","previous":{"title":"20251215-20251221 (cs.IR)","permalink":"/ai_toutiao/daily/cs_IR/20251215-20251221"},"next":{"title":"cs.IT","permalink":"/ai_toutiao/daily/csit"}}');var r=i(4848),t=i(8453);const a={slug:"/daily/csir/20251222-20251228"},o="20251222-20251228 (cs.IR)",l={},c=[{value:"2025-12-22",id:"2025-12-22",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251222-20251228-csir",children:"20251222-20251228 (cs.IR)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-22",children:"2025-12-22"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] V-Agent: An Interactive Video Search System Using Vision-Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision-language model, fine-tuning, retrieval vector, re-ranking, multi-agent system]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," NC AI, Kakao, Korea Advanced Institute of Science and Technology (KAIST)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16925",children:"https://arxiv.org/pdf/2512.16925"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," V-Agent is a multi-agent video search system that fine-tunes a vision-language model with a small video preference dataset and enhances it with a retrieval vector to embed video frames and audio transcriptions into a shared multimodal space. It uses three agents\u2014routing, search, and chat\u2014to refine searches and interact with users, achieving state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [search engine audit, semantic alignment, topical annotation, trajectory analysis]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Erica Coppolillo, Simone Mungari"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Calabria, ICAR-CNR, University of Southern California"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17027",children:"https://arxiv.org/pdf/2512.17027"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper conducts a comparative audit of search engine recommendations on Wikipedia and Grokipedia by analyzing over 70,000 results from nearly 10,000 neutral English word queries. It finds that both platforms frequently generate weakly related or unexpected results from innocuous queries, though their recommendation sets often differ substantially in topical distribution and exploration trajectories."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] ABE-CLIP: Training-Free Attribute Binding Enhancement for Compositional Image-Text Matching"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [CLIP, semantic refinement mechanism, local token-patch alignment, attribute-object binding, compositional image-text matching]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Qi Zhang, Yuxu Chen, Lei Deng, Lili Shen"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Sichuan University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17178",children:"https://arxiv.org/pdf/2512.17178"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea9a6c4b5b64bc9b1ed96212005ee492c3fd2ae615fc413250d7a6ef7c3bc712_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea9a6c4b5b64bc9b1ed96212005ee492c3fd2ae615fc413250d7a6ef7c3bc712_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ABE-CLIP, a training-free method to enhance attribute-object binding in CLIP models. It uses a semantic refinement mechanism to improve text token embeddings and a local token-patch alignment strategy to compute image-text similarity. Experiments show the method significantly improves compositional matching performance, even surpassing some trained approaches."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [residual connection, score regularization, manifold mixup]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Saeed Ebrahimi, Weijie Jiang, Jaewon Yang, Olafur Gudmundsson, Yucheng Tu, Huizhong Duan"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Pinterest"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17277",children:"https://arxiv.org/pdf/2512.17277"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f351bf91dbfa3f8f187d67a36cb3c88f1014690a13606c70e860bd376621c71f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f351bf91dbfa3f8f187d67a36cb3c88f1014690a13606c70e860bd376621c71f_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes a cost-efficient strategy to improve cold-start recommendations by introducing lightweight techniques: a residual connection for non-historical features, a score regularization term, and manifold mixup for data sparsity. These methods collectively increased fresh content engagement by 10% without harming overall engagement or cost, and have been deployed at Pinterest."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] A Systematic Reproducibility Study of BSARec for Sequential Recommendation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [sequential recommendation], [BSARec, Transformer, Fourier transform, discrete wavelet transform, padding strategies, frequency rescaling]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy, Yuanna Liu"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Amsterdam"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17442",children:"https://arxiv.org/pdf/2512.17442"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper reproduces and evaluates BSARec, a sequential recommendation method that enhances Transformer encoders with a frequency layer using Fourier transforms to capture high-frequency signals. The study finds that BSARec outperforms other methods on some datasets, but digital signal processing techniques like discrete wavelet transform offer only marginal improvements over Fourier transforms, and non-constant padding significantly boosts performance while constant padding hinders high-frequency signal capture."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [marketing personalisation], [randomised controlled trial, agentic messaging, rule-based campaign, causal inference, contextual bandits]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Olivier Jeunen, Schaun Wheeler"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," aampe"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17462",children:"https://arxiv.org/pdf/2512.17462"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates an agentic messaging approach for customer communication, comparing it against a traditional rule-based system in a financial service application via a randomized controlled trial. The results show that the agentic system reduced unsubscribe events by 21% and encouraged earlier tax filing, demonstrating its effectiveness in improving user engagement and retention."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [recommendation systems], [causal deconfounding, LightGCN, Unbiased Asymmetric Co-purchase Relationship (UACR), counterfactual exposure, BPR loss]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jingmao Zhang, Zhiting Zhao, Yunqi Lin, Jianghong Ma, Tianjun Wei, Haijun Zhang, Xiaofeng Zhang"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Harbin Institute of Technology (Shenzhen), Nanyang Technological University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17733",children:"https://arxiv.org/pdf/2512.17733"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes Cadence, a plug-and-play framework built on LightGCN that uses causal deconfounding to compute unbiased item-item relationships and counterfactual exposure simulation to enhance recommendation diversity. The method constructs a deconfounded directed item graph and identifies diverse, causally relevant items a user has not interacted with. Experiments show it outperforms state-of-the-art models in both diversity and accuracy."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Knowledge Mining, Digital Preservation, Semantic Web, Data Integration, Dual-Stream Architecture]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Binh Vu"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," FernUniversit\xe4t in Hagen"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17795",children:"https://arxiv.org/pdf/2512.17795"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes the Intelligent Knowledge Mining Framework (IKMF), a conceptual dual-stream architecture that combines a horizontal AI-driven mining process with a parallel trustworthy archiving stream. It aims to bridge the gap between dynamic analysis and long-term preservation, transforming static data repositories into living, actionable knowledge ecosystems."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);