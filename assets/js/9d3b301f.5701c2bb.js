"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4055],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}},59360:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_MA/20260105-20260111","title":"20260105-20260111 (cs.MA)","description":"2026-01-05","source":"@site/docs/daily/cs_MA/20260105-20260111.md","sourceDirName":"daily/cs_MA","slug":"/daily/csma/20260105-20260111","permalink":"/ai_toutiao/daily/csma/20260105-20260111","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{"slug":"/daily/csma/20260105-20260111"},"sidebar":"tutorialSidebar","previous":{"title":"20251229-20260104 (cs.MA)","permalink":"/ai_toutiao/daily/csma/20251229-20260104"},"next":{"title":"cs.MM","permalink":"/ai_toutiao/daily/csmm"}}');var r=i(74848),a=i(28453);const t={slug:"/daily/csma/20260105-20260111"},o="20260105-20260111 (cs.MA)",l={},c=[{value:"2026-01-05",id:"2026-01-05",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20260105-20260111-csma",children:"20260105-20260111 (cs.MA)"})}),"\n",(0,r.jsx)(n.h2,{id:"2026-01-05",children:"2026-01-05"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] \u03bcACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [formal calculus, resource-constrained communication, semantic compression, multi-agent systems, consensus]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Arnab Mallick, Indraveni Chebolu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Center for Development of Advanced Computing (C-DAC), Hyderabad"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00219",children:"https://arxiv.org/pdf/2601.00219"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A formal Resource-Constrained Agent Communication (RCAC) model for reasoning about expressiveness vs. resource trade-offs. 2. A proof that a minimal four-verb basis {PING, TELL, ASK, OBSERVE} is complete for encoding finite-state FIPA protocols under constraints. 3. A semantic compression theory establishing tight information-theoretic bounds on message complexity and showing the protocol can implement consensus under partial synchrony."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/576ee220ff5d9e07ae8e367107aed97b22132ae73d9984e8ae5aa51b0d947780_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/576ee220ff5d9e07ae8e367107aed97b22132ae73d9984e8ae5aa51b0d947780_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes \u03bcACP, a formal calculus for agent communication designed to operate under severe resource constraints like those in edge and IoT environments. It proves that a minimal set of four communication verbs is sufficient to encode expressive protocols and establishes theoretical bounds on message complexity, achieving low latency in simulations. The main contribution is a unified framework that reconciles semantic richness with provable efficiency for resource-constrained multi-agent systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root("\u03bcACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication")\n    Root --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u4f20\u7edfACL\u534f\u8bae\u8d44\u6e90\u6d88\u8017\u5927/Traditional ACLs are resource-intensive")\n    Problem --\x3e P2("\u8f7b\u91cf\u7ea7IoT\u534f\u8bae\u7f3a\u4e4f\u8868\u8fbe\u6027/Lightweight IoT protocols lack expressiveness")\n    Method --\x3e M1("\u5f62\u5f0f\u5316RCAC\u6a21\u578b/Formal RCAC Model")\n    Method --\x3e M2("\u6700\u5c0f\u56db\u52a8\u8bcd\u57fa\u7840\u96c6/Minimal 4-verb basis")\n    Method --\x3e M3("\u8bed\u4e49\u538b\u7f29\u7406\u8bba/Semantic Compression Theory")\n    Results --\x3e R1("\u7406\u8bba:\u6d88\u606f\u590d\u6742\u5ea6\u6709\u754c/Theoretical: Bounded message complexity")\n    Results --\x3e R2("\u5b9e\u8df5:\u5b9e\u73b0\u5171\u8bc6/Implementation: Achieves consensus")\n    Results --\x3e R3("\u9a8c\u8bc1:\u4f4e\u5ef6\u8fdf\u4e0e\u5b89\u5168\u6027/Verification: Low latency & safety")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sys], [wireless networking], [O-RAN, UAV, trajectory optimization, RIC, low-altitude economy]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Aly Sabri Abdalla, Vuk Marojevic"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Mississippi State University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00257",children:"https://arxiv.org/pdf/2601.00257"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes an O-RAN-enabled framework for intelligent orchestration of Low-Altitude Economy (LAE) operations, integrating disaggregated RAN architecture with AI-driven RAN Intelligent Controllers (RICs). 2. Presents a semantic-aware rApp and a reinforcement learning-enabled xApp for closed-loop, context-aware trajectory planning of UAV swarms. 3. Surveys available UAV testbeds for LAE research and identifies critical research challenges and standardization needs for future deployments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cae00fb3b22c64bae2b8ae14c12c3a5262a87f4a6954a5d6578c0a24172848_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cae00fb3b22c64bae2b8ae14c12c3a5262a87f4a6954a5d6578c0a24172848_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of orchestrating UAV missions in complex, signal-constrained environments for the Low-Altitude Economy (LAE). It proposes a novel framework that leverages the Open Radio Access Network (O-RAN) architecture, using AI-driven controllers (RICs) and specialized apps (rApp/xApp) for semantic-aware, real-time trajectory planning. The work concludes by evaluating the framework's feasibility and outlining future research and standardization directions for scalable LAE deployments."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem: Lack of real-time, resilient orchestration for UAVs in complex environments"] --\x3e P1["\u5b50\u95ee\u9898/Sub-Problem: Absence of AI-integrated, context-aware control for LAE"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method: O-RAN-enabled LAE framework with AI-driven RICs"] --\x3e M1["\u7ec4\u4ef6/Component: Semantic-aware rApp (terrain interpreter)"]\n    Method --\x3e M2["\u7ec4\u4ef6/Component: RL-enabled xApp (trajectory planner)"]\n    Results["\u5173\u952e\u7ed3\u679c/Results: Framework enables closed-loop, AI-optimized LAE operations"] --\x3e R1["\u8bc4\u4f30/Evaluation: Feasibility and performance analysis presented"]\n    Results --\x3e R2["\u5c55\u671b/Outlook: Research challenges and standardization needs surveyed"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [reinforcement learning], [self-evolving agent, hierarchical memory, protocol redesign]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Sixue Xing, Xuanye Xia, Kerui Wu, Meng Jiang, Jintai Chen, Tianfan Fu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Notre Dame, Georgia Institute of Technology, University of Massachusetts Amherst, Hong Kong University of Science and Technology (Guangzhou), Nanjing University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00290",children:"https://arxiv.org/pdf/2601.00290"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ClinicalReTrial, a self-evolving AI agent framework that moves beyond static trial outcome prediction to actionable protocol optimization. 2. Introduces a closed-loop, reward-driven optimization framework that integrates failure diagnosis, safety-aware modification, and candidate evaluation, using a prediction model as a simulation environment. 3. Designs a hierarchical memory mechanism to capture iteration-level feedback and distill transferable redesign patterns for efficient exploration."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b82407468d333ae862573b891f5a19251a04fd53b36b2e4e9e895ca08f9073_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b82407468d333ae862573b891f5a19251a04fd53b36b2e4e9e895ca08f9073_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ClinicalReTrial, a self-evolving AI agent framework that optimizes clinical trial protocols through iterative, reward-driven redesign. It uses an outcome prediction model as a simulation environment and a hierarchical memory for efficient exploration. Empirical results show the framework improves 83.3% of trial protocols with a mean success probability gain of 5.7%."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Clinical trial failure due to protocol design flaws, existing AI is reactive)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Self-evolving agent with closed-loop optimization, hierarchical memory, using prediction model as simulation)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Improves 83.3% of protocols, mean success probability gain of 5.7%)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Offline Multi-Agent Reinforcement Learning for 6G Communications: Fundamentals, Applications and Future Directions"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [offline reinforcement learning, conservative Q-learning, meta-learning, radio resource management, UAV networks]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Eslam Eldeeb, Hirley Alves"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Oulu"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00321",children:"https://arxiv.org/pdf/2601.00321"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel offline multi-agent reinforcement learning algorithm based on conservative Q-learning (CQL) for safe and efficient training in wireless networks., 2. Extends the offline MARL approach with meta-learning to enhance adaptability in dynamic environments., 3. Validates the proposed framework through practical use cases in radio resource management and UAV network applications."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cc964c00876ee81486a12f18505ed613255db0f942d692eb3a3d428f15d72c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cc964c00876ee81486a12f18505ed613255db0f942d692eb3a3d428f15d72c6_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the cost, safety, and scalability limitations of online multi-agent reinforcement learning (MARL) in complex 6G networks by proposing an offline MARL algorithm based on conservative Q-learning (CQL), enhanced with meta-learning for dynamic environments. The method is validated in wireless use cases like radio resource management and UAV networks. The work concludes that offline MARL is a promising direction for future wireless applications, highlighting its advantages and limitations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\nA[Offline Multi-Agent RL for 6G] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Online MARL faces cost, safety, scalability limits in 6G networks]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Novel offline MARL algorithm based on CQL + meta-learning]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Validated in RRM & UAV use cases; highlights advantages & future directions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [self-healing, distributed computing continuum, language model agents, multi-agent systems, fault tolerance]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lov\xe9n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Lule\xe5 University of Technology, Peking University, TU Wien"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00339",children:"https://arxiv.org/pdf/2601.00339"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Introduces ReCiSt, a novel bio-inspired framework that maps biological self-healing phases (Hemostasis, Inflammation, Proliferation, Remodeling) to computational layers (Containment, Diagnosis, Meta-Cognitive, Knowledge) for resilience in DCCS. 2. Proposes the use of Language Model (LM)-powered agents to autonomously interpret logs, diagnose faults, and reconfigure resources with minimal human intervention. 3. Demonstrates the framework's capability for self-healing within tens of seconds with low resource overhead (e.g., 10% CPU usage) through evaluation on public fault datasets."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes ReCiSt, a bio-inspired, agent-based framework that uses Language Model-powered agents to autonomously detect, diagnose, and recover from faults in Distributed Computing Continuum Systems. The framework is evaluated on public datasets, showing it can achieve self-healing in tens of seconds with minimal resource overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:'graph TB\n    Root["Bio-inspired Agentic Self-healing Framework<br>\u751f\u7269\u542f\u53d1\u7684\u667a\u80fd\u4f53\u81ea\u6108\u6846\u67b6"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>DCCS\u4e2d\u7684\u590d\u6742\u6027\u4e0e\u6545\u969c\u9891\u53d1<br>Complexity & Frequent Faults in DCCS"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>ReCiSt\u6846\u67b6: \u4eff\u751f\u56db\u5c42\u4e0eLM\u667a\u80fd\u4f53<br>ReCiSt Framework: Bio-inspired Layers & LM Agents"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results<br>\u6570\u5341\u79d2\u5185\u81ea\u6108\uff0c\u4f4eCPU\u5f00\u9500<br>Self-healing in tens of seconds, low CPU overhead"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Mapping Human Anti-collusion Mechanisms to Multi-agent AI"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent systems], [collusion, anti-collusion mechanisms, multi-agent AI, AI safety, game theory]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Jamiu Adekunle Idowu, Ahmed Almasoud, Ayman Alfahid"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University College London (UCL), Sahel AI, Prince Sultan University, Majmaah University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00360",children:"https://arxiv.org/pdf/2601.00360"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Developed a taxonomy of human anti-collusion mechanisms (e.g., sanctions, leniency, monitoring). 2. Mapped these human mechanisms to potential interventions for multi-agent AI systems. 3. Highlighted key open challenges in applying these mechanisms to AI, such as the attribution problem and adversarial adaptation."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ddbe564b87a89c6b0bfd47c15c01195109e5af5ff41994f193729c6ff841d80_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ddbe564b87a89c6b0bfd47c15c01195109e5af5ff41994f193729c6ff841d80_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the risk of collusion in autonomous multi-agent AI systems by proposing to adapt established human anti-collusion mechanisms. It develops a taxonomy of these mechanisms and maps them to potential AI interventions. The work concludes by identifying critical challenges for future research in this area, such as distinguishing beneficial cooperation from harmful collusion."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Mapping Human Anti-collusion Mechanisms to Multi-agent AI] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[AI\u4ee3\u7406\u51fa\u73b0\u5408\u8c0b/AI Agents Develop Collusion]\n    C --\x3e C1[\u5efa\u7acb\u4eba\u7c7b\u53cd\u5408\u8c0b\u673a\u5236\u5206\u7c7b\u6cd5/Develop Taxonomy of Human Anti-collusion Mechanisms]\n    C --\x3e C2[\u6620\u5c04\u5230AI\u7cfb\u7edf\u5e72\u9884\u63aa\u65bd/Map to Multi-agent AI Interventions]\n    D --\x3e D1[\u63d0\u51fa\u5b9e\u65bd\u65b9\u6cd5/Propose Implementation Approaches]\n    D --\x3e D2[\u8bc6\u522b\u5f00\u653e\u6311\u6218/Highlight Open Challenges]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv260105] Priority-Aware Multi-Robot Coverage Path Planning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-robot path planning], [coverage path planning, priority-weighted latency, lexicographic optimization, spanning-tree, Steiner-tree]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kanghoon Lee, Hyeonjun Kim, Jiachen Li, Jinkyoo Park"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Korea Advanced Institute of Science and Technology (KAIST), Korea Military Academy (KMA), University of California, Riverside (UCR)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2601.00580",children:"https://arxiv.org/pdf/2601.00580"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Formally defines the Priority-Aware Multi-Robot Coverage Path Planning (PA-MCPP) problem, introducing priority weights and a lexicographic objective to minimize priority-weighted latency and makespan. 2. Proposes a scalable two-phase framework combining greedy zone assignment with local search and Steiner-tree-guided residual coverage. 3. Demonstrates through experiments that the method significantly reduces priority-weighted latency compared to baselines while maintaining competitive makespan and scales well with the number of robots."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4091ae11f186a26844a6a1c27c13cf633fa92da4e6636d53275a7d839f775d9f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4091ae11f186a26844a6a1c27c13cf633fa92da4e6636d53275a7d839f775d9f_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of standard multi-robot coverage path planning, which treats all areas equally, by introducing a priority-aware version (PA-MCPP) where certain zones have higher urgency. The authors propose a two-phase method that first assigns and covers priority zones efficiently and then handles the remaining area. Experiments show their approach successfully reduces coverage delay for high-priority zones without significantly compromising the overall completion time."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TB\n    A[Priority-Aware Multi-Robot Coverage Path Planning] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u6807\u51c6MCPP\u5ffd\u89c6\u533a\u57df\u4f18\u5148\u7ea7/Standard MCPP ignores zone priority]\n    C --\x3e C1[\u4e24\u9636\u6bb5\u6846\u67b6: \u8d2a\u5fc3\u5206\u914d\u4e0e\u65af\u5766\u7eb3\u6811\u5f15\u5bfc\u8986\u76d6/Two-phase framework: greedy assignment & Steiner-tree-guided coverage]\n    D --\x3e D1[\u663e\u8457\u964d\u4f4e\u4f18\u5148\u7ea7\u52a0\u6743\u5ef6\u8fdf/Significantly reduces priority-weighted latency]\n    D --\x3e D2[\u4fdd\u6301\u6709\u7ade\u4e89\u529b\u7684\u5b8c\u5de5\u65f6\u95f4/Maintains competitive makespan]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);