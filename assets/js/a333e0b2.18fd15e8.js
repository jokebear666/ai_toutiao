"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4390],{4808:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_SE/20251222-20251228","title":"20251222-20251228 (cs.SE)","description":"2025-12-22","source":"@site/docs/daily/cs_SE/20251222-20251228.md","sourceDirName":"daily/cs_SE","slug":"/daily/csse/20251222-20251228","permalink":"/ai_toutiao/daily/csse/20251222-20251228","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1766487361000,"frontMatter":{"slug":"/daily/csse/20251222-20251228"},"sidebar":"tutorialSidebar","previous":{"title":"20251215-20251221 (cs.SE)","permalink":"/ai_toutiao/daily/cs_SE/20251215-20251221"},"next":{"title":"cs.SI","permalink":"/ai_toutiao/daily/cssi"}}');var r=i(4848),a=i(8453);const t={slug:"/daily/csse/20251222-20251228"},o="20251222-20251228 (cs.SE)",l={},c=[{value:"2025-12-22",id:"2025-12-22",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251222-20251228-csse",children:"20251222-20251228 (cs.SE)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-22",children:"2025-12-22"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [dense embedding retrieval, graph-based exploration, BM25, LLM-based reasoning, code localization]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shravan Chaudhari, Rahul Thomas Jacob, Mononito Goswami, Jiajun Cao, Shihab Rashid, Christian Bock"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Johns Hopkins University, AWS AI Labs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16956",children:"https://arxiv.org/pdf/2512.16956"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes SpIDER, a method that enhances dense retrieval for code localization by using graph-based exploration of a codebase to gather auxiliary context, which is then reasoned over by an LLM. This approach addresses the limitations of standard embedding methods that underutilize code structure. Empirical results show that SpIDER consistently improves retrieval performance across multiple programming languages."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [SWE-Bench++, automated benchmark generation, pull request harvesting, environment synthesis, test oracle extraction, hint-guided trajectory synthesis, fine-tuning]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Turing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17419",children:"https://arxiv.org/pdf/2512.17419"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [software defect prediction], [Explainable Boosting Machines, stratified interaction analysis, class imbalance, class overlap, irrelevant features, attribute noise, outliers]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Emmanuel Charleson Dapaah, Jens Grabowski"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of G\xf6ttingen"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17460",children:"https://arxiv.org/pdf/2512.17460"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper conducts a large-scale empirical study using Explainable Boosting Machines and stratified interaction analysis to examine five co-occurring data quality issues in software defect prediction across 374 datasets. It finds that co-occurrence is nearly universal, identifies tipping points for issues like class overlap and imbalance, and reveals context-dependent effects, concluding that no single model performs best under all conditions."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [multiple instance learning, AutoML, feature extraction, whole-slide images, benchmarking, computational pathology]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Siemen Brussee, Pieter A. Valkema, Jurre A. J. Weijer, Thom Doeleman, Anne M.R. Schrader, Jesper Kers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Leiden University Medical Center, Utrecht University Medical Center, Amsterdam University Medical Center"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17517",children:"https://arxiv.org/pdf/2512.17517"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces PathBench-MIL, an automated machine learning and benchmarking framework designed for Multiple Instance Learning in histopathology. It automates the entire pipeline from preprocessing to model aggregation, enabling standardized and reproducible evaluation of various models and feature extractors on whole-slide image datasets. The main conclusion is that this open-source framework facilitates rapid experimentation and standardization in computational pathology research."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] LLM-based Behaviour Driven Development for Hardware Design"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [Behavior Driven Development (BDD), Large Language Models (LLMs), hardware design, test and verification, natural language processing, Electronic Design Automation (EDA)]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Rolf Drechsler, Qian Liu"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Bremen, DFKI"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17814",children:"https://arxiv.org/pdf/2512.17814"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the use of Large Language Models (LLMs) to automate the generation of behavioral scenarios from textual specifications for Behavior Driven Development (BDD) in hardware design. The core method involves applying LLM-based techniques to interpret specifications and produce high-level behavioral descriptions. The main conclusion is that LLMs offer a promising opportunity to support and automate BDD workflows in hardware design, addressing the manual effort and complexity of current verification practices."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(6540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);