"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7138],{8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>o});var t=n(6540);const s={},a=t.createContext(s);function r(e){const i=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:i},e.children)}},9892:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"daily/cs_IT/20251222-20251228","title":"20251222-20251228 (cs.IT)","description":"2025-12-22","source":"@site/docs/daily/cs_IT/20251222-20251228.md","sourceDirName":"daily/cs_IT","slug":"/daily/csit/20251222-20251228","permalink":"/ai_toutiao/daily/csit/20251222-20251228","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1766487361000,"frontMatter":{"slug":"/daily/csit/20251222-20251228"},"sidebar":"tutorialSidebar","previous":{"title":"20251215-20251221 (cs.IT)","permalink":"/ai_toutiao/daily/cs_IT/20251215-20251221"},"next":{"title":"cs.LG","permalink":"/ai_toutiao/daily/cslg"}}');var s=n(4848),a=n(8453);const r={slug:"/daily/csit/20251222-20251228"},o="20251222-20251228 (cs.IT)",l={},c=[{value:"2025-12-22",id:"2025-12-22",level:2}];function d(e){const i={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"20251222-20251228-csit",children:"20251222-20251228 (cs.IT)"})}),"\n",(0,s.jsx)(i.h2,{id:"2025-12-22",children:"2025-12-22"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv251222] Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [ai], [algorithmic information theory], [Solomonoff induction, Bayesian Model Averaging, hypothesis ranking, systematic generalisation, uncertainty estimation]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Josh Barber, Rourke Young, Cameron Coombe, Will Browne"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," Queensland University of Technology, CSIRO"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2512.17145",children:"https://arxiv.org/pdf/2512.17145"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"thumbnail:"})," ",(0,s.jsx)(i.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper proposes a method that uses a Solomonoff-inspired scoring to weight hypotheses generated by a Large Language Model based on their simplicity and predictive fit. The method, applied to Mini-ARC tasks, produces uncertainty-aware predictions by spreading probability across multiple hypotheses, contrasting with Bayesian Model Averaging which tends to concentrate weight on a single candidate. The results highlight the value of algorithmic information-theoretic priors for robust, interpretable reasoning under uncertainty."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"[arXiv251222] Timely Information Updating for Mobile Devices Without and With ML Advice"})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"tags:"})," [sys], [online scheduling], [competitive online algorithm, age of information, consistency-robustness trade-off, ML-augmented algorithm, adversarial environment]"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"authors:"})," Yu-Pin Hsu, Yi-Hsuan Tseng"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"institution:"})," National Taipei University"]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"link:"})," ",(0,s.jsx)(i.a,{href:"https://arxiv.org/pdf/2512.17381",children:"https://arxiv.org/pdf/2512.17381"})]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Simple LLM Summary:"})," This paper proposes an online algorithm for a mobile device to decide when to send status updates to an access point, balancing information timeliness and update cost. The algorithm achieves an optimal competitive ratio against adversarial uncertainties and, when augmented with machine learning advice, attains an optimal consistency-robustness trade-off. The main conclusion is that an optimal competitive algorithm exhibits a threshold-like response to ML advice, either fully trusting or completely ignoring it."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);