"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9703],{25111:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_CY/20251229-20260104","title":"20251229-20260104 (cs.CY)","description":"2025-12-29","source":"@site/docs/daily/cs_CY/20251229-20260104.md","sourceDirName":"daily/cs_CY","slug":"/daily/cscy/20251229-20260104","permalink":"/ai_toutiao/daily/cscy/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767086937000,"frontMatter":{"slug":"/daily/cscy/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.CY)","permalink":"/ai_toutiao/daily/cscy/20251222-20251228"},"next":{"title":"cs.DB","permalink":"/ai_toutiao/daily/csdb"}}');var a=i(74848),r=i(28453);const t={slug:"/daily/cscy/20251229-20260104"},o="20251229-20260104 (cs.CY)",l={},d=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"20251229-20260104-cscy",children:"20251229-20260104 (cs.CY)"})}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] SENTINEL: A Multi-Modal Early Detection Framework for Emerging Cyber Threats using Telegram"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [cyber threat intelligence], [multi-modal fusion, large language models, graph neural networks, early detection, social media analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mohammad Hammas Saeed, Howie Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," George Washington University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21380",children:"https://arxiv.org/pdf/2512.21380"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes SENTINEL, a multi-modal framework for early cyber threat detection by aligning social media discussions with real-world attacks. 2. Combines language modeling (using LLMs) and network coordination analysis (using GNNs) to fuse textual and relational signals from platforms like Telegram. 3. Demonstrates the framework's effectiveness on a dataset of 365k messages from 16 Telegram channels, achieving an F1 score of 0.89 for threat alignment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3e47a235de6afcb4955afd774a9e4b3883efcafc7e4aaa97649575ef2fb34d0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3e47a235de6afcb4955afd774a9e4b3883efcafc7e4aaa97649575ef2fb34d0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents SENTINEL, a framework for the early detection of cyber threats by analyzing multi-modal signals from social media platforms like Telegram. It combines large language models for text understanding with graph neural networks to model user coordination, successfully aligning online discussions to real-world attacks. The evaluation on Telegram data shows the approach is effective, achieving a high F1 score of 0.89."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["SENTINEL: A Multi-Modal Early Detection Framework for Emerging Cyber Threats using Telegram"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Post-hoc detection of cyber attacks is reactive; need for proactive, early warning systems."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Multi-modal framework combining LLMs (language) and GNNs (coordination graphs) to analyze social media signals."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Achieves F1 of 0.89 aligning Telegram discussions to real-world cyber threats."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] ALETHEIA: Combating Social Media Influence Campaigns with Graph Neural Networks"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [social network security], [Graph Neural Networks, influence campaigns, temporal link prediction, troll detection, Reddit]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Mohammad Hammas Saeed, Isaiah J. King, Howie Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," George Washington University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21391",children:"https://arxiv.org/pdf/2512.21391"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes ALETHEIA, a system that formalizes the detection of malicious accounts in influence campaigns as a node classification and link prediction problem using a graph-based representation. 2. Demonstrates that a detection pipeline combining topological (graph) and linguistic features outperforms standard interaction and user features, achieving a 3.7% F1-score improvement. 3. Introduces a novel temporal link prediction mechanism for influence campaigns by stacking a GNN over an RNN to forecast future troll interactions (TTE/TUE) with high accuracy (96.6% AUC)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/473a865358e998c62938f17660edc395a7658bf360ef15e62ea79317e8734aec_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/473a865358e998c62938f17660edc395a7658bf360ef15e62ea79317e8734aec_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents ALETHEIA, a system that uses Graph Neural Networks (GNNs) to detect malicious accounts and predict their future interactions in social media influence campaigns. By modeling campaigns as graphs and combining structural and linguistic features, it improves detection performance and forecasts troll behavior with high accuracy. The results underscore the importance of leveraging network structure to combat coordinated malicious activity online."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[ALETHEIA: Combating Social Media Influence Campaigns with Graph Neural Networks] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Detecting and predicting malicious influence campaigns on social media]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Graph Neural Networks (GNNs) with topological & linguistic features, GNN+RNN for temporal link prediction]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 3.7% F1-score improvement in detection, 96.6% AUC for predicting future troll interactions]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [ai for education], [human-ai alignment, trustworthy ai, adaptive learning, educational technology, ai ethics]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hua Shen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," NYU Shanghai, New York University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21552",children:"https://arxiv.org/pdf/2512.21552"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Proposes the novel concept of "bidirectional human-AI alignment" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI\'s role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[\u8bba\u6587\u6807\u9898: Bidirectional Human-AI Alignment in Education] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: AI in education introduces risks to equity, privacy, and autonomy.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sec], [Data Provenance], [Data Provenance, Compliance Rating, Generative AI, Dataset Ethics, Transparency]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Matyas Bohacek, Ignacio Vilanova Echavarri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Stanford University, Imperial College London"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21775",children:"https://arxiv.org/pdf/2512.21775"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the Compliance Rating Scheme (CRS), a framework for evaluating dataset compliance with transparency, accountability, and security principles. 2. Develops and releases an open-source Python library that implements the CRS framework using data provenance technology. 3. Creates a tool that is both reactive (evaluating existing datasets) and proactive (guiding the responsible construction of new datasets)."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa33a1fedd52ef1c87e9bf7d9a25dad61aae942ba50660263862470b9b677745_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of ethical and legal oversight in the creation and sharing of datasets for Generative AI. It proposes the Compliance Rating Scheme (CRS) framework and an accompanying open-source library to assess and ensure dataset compliance with key principles. The work aims to improve traceability and accountability in the AI data supply chain."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u6570\u636e\u96c6\u521b\u5efa\u7f3a\u4e4f\u4f26\u7406\u4e0e\u6cd5\u5f8b\u76d1\u7763/Lack of ethical & legal oversight in dataset creation")\n    Problem --\x3e P2("\u6570\u636e\u6765\u6e90\u4e0e\u5408\u6cd5\u6027\u4fe1\u606f\u4e22\u5931/Loss of data origin & legitimacy info")\n    Method --\x3e M1("\u63d0\u51fa\u5408\u89c4\u8bc4\u7ea7\u65b9\u6848(CRS)\u6846\u67b6/Propose Compliance Rating Scheme (CRS) framework")\n    Method --\x3e M2("\u5f00\u53d1\u57fa\u4e8e\u6570\u636e\u6eaf\u6e90\u6280\u672f\u7684\u5f00\u6e90\u5e93/Develop open-source library using data provenance")\n    Results --\x3e R1("\u8bc4\u4f30\u73b0\u6709\u6570\u636e\u96c6\u7684\u5408\u89c4\u6027/Evaluate compliance of existing datasets")\n    Results --\x3e R2("\u6307\u5bfc\u8d1f\u8d23\u4efb\u7684\u65b0\u6570\u636e\u96c6\u6784\u5efa/Guide responsible construction of new datasets")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] On The Conceptualization and Societal Impact of Cross-Cultural Bias"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [bias and fairness], [cultural bias, literature survey, societal impact, harm evaluation, bias mitigation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Vitthal Bhandari"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Washington"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21809",children:"https://arxiv.org/pdf/2512.21809"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),"  1. Conducts a focused survey of 20 recent (2025) papers on cultural bias in NLP, identifying gaps in current research practices. 2. Critiques the literature for lacking concrete definitions of bias, failing to identify affected stakeholders, and inadequately evaluating the harms of biased systems. 3. Advocates for a future research agenda that emphasizes robust societal impact assessment, concrete bias conceptualization, and engagement with real-world stakeholders."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper surveys recent literature on cultural bias in NLP, finding that current research often fails to concretely define bias, engage with affected stakeholders, or thoroughly evaluate societal harms. The author proposes a set of observations to guide future work towards more robust and impactful assessments of cross-cultural bias in language technologies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\nRoot("On The Conceptualization and Societal Impact of Cross-Cultural Bias") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem: LLMs exhibit cross-cultural bias; research often avoids real-world stakeholder engagement.")\nRoot --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method: Survey and analyze 20 recent (2025) papers on cultural bias in NLP.")\nRoot --\x3e Results("\u5173\u952e\u7ed3\u679c/Results: Identifies gaps in bias definition, harm evaluation; advocates for robust societal impact assessment.")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Zhejiang University, University of California, Los Angeles, Palo Alto Networks"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21871",children:"https://arxiv.org/pdf/2512.21871"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/bluedream02/CopyGuard",children:"https://github.com/bluedream02/CopyGuard"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?"]\n    Root --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: LVLMs may infringe copyright when processing visual inputs"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Benchmark dataset & Tool-augmented defense framework"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Current LVLMs are deficient; Proposed framework reduces risk"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [AI Governance & Compliance], [lifecycle management, bias detection, differential privacy, federated learning, terminology drift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sunil Arora, John Hastings"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Dakota State University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22060",children:"https://arxiv.org/pdf/2512.22060"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework's practicality through a healthcare case study demonstrating detection of and response to terminology drift."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>NLP systems in sensitive domains face unaddressed security, privacy, and compliance risks."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>Proposes SC-NLP-LMF, a six-phase framework integrating standards (NIST, ISO, EU AI Act) and techniques (bias detection, differential privacy)."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Provides a practical lifecycle structure for secure, accountable NLP systems, validated via a healthcare case study."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Agent-based simulation of online social networks and disinformation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [agent-based simulation], [agent-based simulation, large language model, disinformation campaigns, synthetic social networks, behavioral automata]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Alejandro Buitrago L\xf3pez, Alberto Ortega Pastor, David Montoro Aguilera, Mario Fern\xe1ndez T\xe1rraga, Jes\xfas Verd\xfa Chac\xf3n, Javier Pastor-Galindo, Jos\xe9 A. Ruip\xe9rez-Valiente"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Murcia"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22082",children:"https://arxiv.org/pdf/2512.22082"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A simulation framework that models synthetic social networks using agents with demographic-based personality traits and finite-state behavioral automata for realistic and interpretable actions. 2. A generative module powered by an LLM to produce context-aware social media posts consistent with each agent's profile and memory. 3. A red module implementing DISARM-inspired workflows to orchestrate disinformation campaigns and a Mastodon-based visualization layer for real-time inspection and validation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a3415bee27d71926e7770fd596253ec973faaa85d1fcba853a047ff6d08bfe3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a3415bee27d71926e7770fd596253ec973faaa85d1fcba853a047ff6d08bfe3_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes an agent-based simulation framework to study online social networks and disinformation, addressing the limitations of platform opacity and data access. The framework uses LLM-powered agents with personality traits and behavioral automata to generate realistic content and simulate disinformation campaigns, with evaluation showing structural, behavioral, and linguistic realism. It provides a customizable and controllable environment for studying information dynamics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Agent-based simulation of online social networks and disinformation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u5e73\u53f0\u4e0d\u900f\u660e\u4e0e\u6570\u636e\u9650\u5236/Platform Opacity & Data Limits]\n    Problem --\x3e P2[\u73b0\u6709\u6a21\u62df\u7f3a\u4e4f\u771f\u5b9e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027/Existing Simulations Lack Realism & Explainability]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u57fa\u4e8e\u4ee3\u7406\u7684\u5408\u6210\u793e\u4ea4\u7f51\u7edc/Agent-based Synthetic Social Networks]\n    Method --\x3e M2[LLM\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u5185\u5bb9/LLM Generates Context-aware Content]\n    Method --\x3e M3[\u7ea2\u8272\u6a21\u5757\u6a21\u62df\u865a\u5047\u4fe1\u606f\u6d3b\u52a8/Red Module Simulates Disinformation Campaigns]\n    Method --\x3e M4[Mastodon\u53ef\u89c6\u5316\u5c42/Mastodon Visualization Layer]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u5c55\u793a\u7ed3\u6784\u3001\u884c\u4e3a\u3001\u8bed\u8a00\u771f\u5b9e\u6027/Demonstrates Structural, Behavioral, Linguistic Realism]\n    Results --\x3e R2[\u4e3a\u7814\u7a76\u4fe1\u606f\u52a8\u6001\u63d0\u4f9b\u53ef\u5b9a\u5236\u73af\u5883/Provides Customizable Environment for Studying Information Dynamics]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Pre-review to Peer review: Pitfalls of Automating Reviews using Large Language Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [peer review automation], [large language models, peer review, pre-review, citation prediction, review alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Akhil Pandey Akella, Harish Varma Siravuri, Shaurya Rohatgi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," AllSci Corp, Sunwater Capital, Kellogg School of Management (Northwestern University), Northern Illinois University, MBZUAI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22145",children:"https://arxiv.org/pdf/2512.22145"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a systematic evaluation of frontier open-weight LLMs for generating peer reviews, measuring alignment with human reviewers and correlation with post-publication metrics like citations and novelty. 2. Identified key pitfalls of LLMs as autonomous reviewers, including weak correlation with human scores (0.15), systematic overestimation bias (3-5 points), and uniformly high confidence scores despite errors. 3. Demonstrated the potential utility of LLMs as pre-review screening agents, as their generated reviews correlate more strongly with post-publication outcomes than with human reviewer scores, and released an open-source dataset (DLMRSD) to support further safety research."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff267a101523eaa0ec56d561e9fa2c165c73baa1b3016d38df1ed64dbc91dcf6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff267a101523eaa0ec56d561e9fa2c165c73baa1b3016d38df1ed64dbc91dcf6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates the use of large language models (LLMs) for automating academic peer review by comparing LLM-generated reviews against human reviewer scores and post-publication metrics. The study finds that while LLMs show weak alignment with human reviewers and exhibit overconfidence and bias, their reviews correlate better with future citation impact, suggesting they could serve as useful pre-review screening tools rather than fully autonomous reviewers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Pre-review to Peer Review: Pitfalls of Automating Reviews using Large Language Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLMs\u7528\u4e8e\u81ea\u52a8\u5316\u540c\u884c\u8bc4\u5ba1\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027/Safety & Reliability of Automating Peer Review with LLMs]\n    C --\x3e C1[\u4f7f\u7528\u524d\u6cbf\u5f00\u6e90LLMs\u751f\u6210\u8bc4\u5ba1\u5e76\u4e0e\u4eba\u7c7b\u8bc4\u5206\u53ca\u53d1\u8868\u540e\u6307\u6807\u5bf9\u6bd4/Using Frontier Open-Weight LLMs to Generate Reviews vs. Human Scores & Post-Publication Metrics]\n    D --\x3e D1[LLMs\u4e0e\u4eba\u7c7b\u8bc4\u5ba1\u5458\u5f31\u76f8\u5173\uff0c\u5b58\u5728\u9ad8\u4f30\u504f\u5dee\u4e0e\u8fc7\u5ea6\u81ea\u4fe1/Weak Correlation with Humans, Overestimation Bias, High Confidence]\n    D --\x3e D2[LLM\u8bc4\u5ba1\u4e0e\u53d1\u8868\u540e\u6307\u6807\u76f8\u5173\u6027\u66f4\u5f3a\uff0c\u9002\u5408\u9884\u5ba1\u7b5b\u67e5/LLM Reviews Correlate More with Post-Publication Metrics, Suitable for Pre-Review Screening]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AETAS: Analysis of Evolving Temporal Affect and Semantics for Legal History"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [semantic change detection], [diachronic embeddings, orthogonal Procrustes, lexical drift]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Qizhi Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," PingCAP, Data & AI-Innovation Lab"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22196",children:"https://arxiv.org/pdf/2512.22196"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A reproducible, expert-system style pipeline for quantifying and visualizing lexical drift in historical corpora. 2. A method coupling interpretable semantic trajectories with legally meaningful axes (e.g., mercy-versus-retribution). 3. The application of the pipeline to the Old Bailey Corpus, exposing the evolution of legal concepts like justice and crime alongside historical events."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df36f3ea25509e1c01d661a7893c2b940f15cfeb346560d105c4488a5fba4140_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df36f3ea25509e1c01d661a7893c2b940f15cfeb346560d105c4488a5fba4140_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents a reproducible pipeline for analyzing semantic drift in historical legal texts. The method involves training and aligning diachronic word embeddings to quantify and visualize lexical change. The analysis of the Old Bailey Corpus reveals how concepts of justice and crime evolved with penal reforms and societal debates."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[AETAS: Analysis of Evolving Temporal Affect and Semantics for Legal History] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1("\u6570\u5b57\u4eba\u6587\u4e2d\u8bed\u4e49\u53d8\u8fc1\u5206\u6790<br>Digital Humanities Semantic Shift Analysis")\n    C --\x3e C1("\u53ef\u590d\u73b0\u7684\u4e13\u5bb6\u7cfb\u7edf\u6d41\u7a0b<br>Reproducible Expert-System Pipeline")\n    C1 --\x3e C2("\u5206\u65f6\u6bb5\u8bcd\u5d4c\u5165\u4e0e\u5bf9\u9f50<br>Temporal Embeddings & Alignment")\n    C2 --\x3e C3("\u51e0\u4f55\u4f4d\u79fb\u4e0e\u90bb\u57df\u53d8\u5316\u5ea6\u91cf<br>Geometric & Neighborhood Metrics")\n    D --\x3e D1("\u53ef\u89c6\u5316\u6cd5\u5f8b\u6982\u5ff5\u6f14\u53d8<br>Visualizing Legal Concept Evolution")\n    D1 --\x3e D2("\u63ed\u793a\u4e0e\u5386\u53f2\u4e8b\u4ef6\u7684\u5173\u8054<br>Revealing Links to Historical Events")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical imaging], [algorithmic fairness, subgroup performance analysis, JustEFAB framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shaurya Gaur, Michel Vitale, Alessa Hering, Johan Kwisthout, Colin Jacobs, Lena Philipp, Fennie van der Graaf"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Radboud University Medical Center, Radboud University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22242",children:"https://arxiv.org/pdf/2512.22242"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a fairness evaluation of three lung cancer risk estimation models (Sybil, Venkadesh21, PanCan2b) using the JustEFAB framework to assess ethically significant biases. 2. Identified and quantified statistically significant performance disparities across demographic subgroups (e.g., gender, race) that were not explained by available clinical confounders. 3. Highlighted the critical need for monitoring and improving model fairness in lung cancer screening AI to ensure equitable clinical application."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/783ab81ef53ced6c68b136e7001be4ece45c131979c45d04a04c21084cbf9888_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/783ab81ef53ced6c68b136e7001be4ece45c131979c45d04a04c21084cbf9888_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study evaluates the fairness of AI models for lung cancer risk estimation from CT scans. Using the JustEFAB framework, it assessed performance disparities across demographic groups and found significant, unexplained biases in two deep learning models. The findings underscore the importance of algorithmic fairness in medical AI to ensure equitable screening outcomes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[Fairness Evaluation of Risk Estimation Models for Lung Cancer Screening<br/>\u80ba\u764c\u7b5b\u67e5\u98ce\u9669\u4f30\u8ba1\u6a21\u578b\u7684\u516c\u5e73\u6027\u8bc4\u4f30] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem<br/>AI\u80ba\u764c\u98ce\u9669\u6a21\u578b\u5728\u4e0d\u540c\u4eba\u53e3\u4e9a\u7ec4\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u662f\u5426\u516c\u5e73\uff1f<br/>Is AI lung cancer risk model performance fair across demographic subgroups?]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method<br/>\u4f7f\u7528JustEFAB\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u5728NLST\u9a8c\u8bc1\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02<br/>Evaluate model performance disparities on NLST validation set using JustEFAB framework]\n    Results[\u5173\u952e\u7ed3\u679c/Results<br/>\u53d1\u73b0Sybil\u548cVenkadesh21\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u3001\u65e0\u6cd5\u7528\u6df7\u6742\u56e0\u7d20\u89e3\u91ca\u7684\u6027\u80fd\u5dee\u5f02<br/>Found significant, unexplained performance disparities in Sybil and Venkadesh21 models]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Reddit Deplatforming and Toxicity Dynamics on Generalist Voat Communities"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [social network analysis], [deplatforming, toxicity detection, dynamic reputation modeling, network analysis, migration regimes]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Aleksandar Toma\u0161evi\u0107, Ana Vrani\u0107, Aleksandra Alori\u0107, Marija Mitrovi\u0107 Dankulov"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Institute of Physics Belgrade, University of Belgrade"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22348",children:"https://arxiv.org/pdf/2512.22348"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),'  1. Identifies and characterizes two distinct regimes ("Hostile Takeover" and "Toxic Equilibrium") of how deplatformed users transform receiving communities on alternative platforms. 2. Demonstrates that community transformation is driven by peripheral dynamics and volume, not by newcomers capturing central network positions. 3. Shows that the structure of the migrating community (loose vs. cohesive) determines whether they disperse into generalist spaces or form dedicated enclaves.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ecb07715a5eebfede95c0e808d5c2d61c5453c8fb7fa8b8c2b8260b568fa2f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ecb07715a5eebfede95c0e808d5c2d61c5453c8fb7fa8b8c2b8260b568fa2f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper studies how Reddit deplatforming affects the communities on the alternative platform Voat. Using network analysis, toxicity detection, and dynamic reputation modeling, it finds that migration leads to increased toxicity through distinct phases and that platforms have a narrow window to intervene before toxic norms become entrenched."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Reddit Deplatforming and Toxicity Dynamics on Generalist Voat Communities] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem);\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method);\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results);\n    B --\x3e B1[\u66ff\u4ee3\u5e73\u53f0\u63a5\u6536\u88ab\u7981\u7528\u6237\u7684\u5f71\u54cd/Impact on alternative platforms receiving banned users];\n    C --\x3e C1[\u7f51\u7edc\u5206\u6790/Network Analysis];\n    C --\x3e C2[\u6bd2\u6027\u68c0\u6d4b/Toxicity Detection];\n    C --\x3e C3[\u52a8\u6001\u58f0\u8a89\u5efa\u6a21/Dynamic Reputation Modeling];\n    D --\x3e D1[\u654c\u5bf9\u63a5\u7ba1\u9636\u6bb5/Hostile Takeover Phase (2015-2018)];\n    D --\x3e D2[\u6bd2\u6027\u5e73\u8861\u9636\u6bb5/Toxic Equilibrium Phase (2018-2020)];\n    D --\x3e D3[\u5916\u56f4\u52a8\u6001\u9a71\u52a8\u8f6c\u53d8/Peripheral Dynamics Drive Change];"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [human-ai interaction], [boundary objects, relational mediation, marginalized clients, therapeutic systems, dynamic framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiatao Quan, Ziyue Li, Tian Qi Zhu, Yuxuan Li, Baoying Wang, Wanda Pratt, Nan Gao"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Washington, The Hong Kong Polytechnic University, Nankai University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22462",children:"https://arxiv.org/pdf/2512.22462"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Identifies enduring relational challenges in psychotherapy for marginalized clients, such as trust-building and self-disclosure burdens. 2. Proposes the Dynamic Boundary Mediation Framework, which re-conceptualizes LLMs as adaptive boundary objects. 3. Delineates three specific forms of mediation (Epistemic, Relational, Contextual) to address knowledge gaps, power asymmetries, and therapy-life discontinuities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8695c76e0392473389276989f78ab825dab06f2e38bdd785d2418d8ca9a1d80_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8695c76e0392473389276989f78ab825dab06f2e38bdd785d2418d8ca9a1d80_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper argues that current framings of LLMs in mental health overlook their potential to mediate complex therapeutic relationships. Based on interviews with therapists and marginalized clients in China, the authors propose the Dynamic Boundary Mediation Framework, which positions LLM chatbots as adaptive boundary objects to bridge knowledge, power, and contextual gaps. This offers a pathway for designing AI systems that more effectively and accountably support therapeutic relationships for marginalized users."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results"]\n    Problem --\x3e P1["\u73b0\u6709\u89c6\u89d2\u7684\u5c40\u9650/Current Framing Limitations"]\n    Problem --\x3e P2["\u8fb9\u7f18\u5316\u5ba2\u6237\u7684\u5173\u7cfb\u6311\u6218/Relational Challenges for Marginalized Clients"]\n    Method --\x3e M1["\u52a8\u6001\u8fb9\u754c\u8c03\u89e3\u6846\u67b6/Dynamic Boundary Mediation Framework"]\n    Method --\x3e M2["\u4f5c\u4e3a\u8fb9\u754c\u5bf9\u8c61\u7684LLM/LLMs as Boundary Objects"]\n    Results --\x3e R1["\u4e09\u79cd\u8c03\u89e3\u5f62\u5f0f/Three Forms of Mediation"]\n    Results --\x3e R2["\u5173\u7cfb\u95ee\u8d23\u7684AI\u7cfb\u7edf/Relationally Accountable AI Systems"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Urban Food Self-Production in the Perspective of Social Learning Theory: Empowering Self-Sustainability"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [social computing], [urban agriculture, hydroponics, qualitative study, social learning theory, sustainable food production]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ewa Duda, Adamina Korwin-Szymanowska"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Uniwersytet \u0141\xf3dzki, Uniwersytet Warszawski (University of \u0141\xf3d\u017a, University of Warsaw)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22594",children:"https://arxiv.org/pdf/2512.22594"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a qualitative study on resident participation in an innovative urban hydroponic farming project. 2. Identified key motivations and experiences of urban residents engaging in community-based food self-production. 3. Provided insights for urban educators and policymakers on fostering sustainable food initiatives through social learning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e23a23f4c52bbdc6c863186ff1aad1ec49304917fba3f15168891df1f7d6b610_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e23a23f4c52bbdc6c863186ff1aad1ec49304917fba3f15168891df1f7d6b610_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates urban residents' participation in a community hydroponic farming project in Poland. Using purposive sampling and in-depth interviews, the study explores the motivations, experiences, and educational pathways of participants. The findings highlight the role of social learning in empowering urban self-sustainability and offer guidance for stakeholders in urban education and development."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Urban Food Self-Production in the Perspective of Social Learning Theory: Empowering Self-Sustainability] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[Urban food security & climate change/\u57ce\u5e02\u7cae\u98df\u5b89\u5168\u4e0e\u6c14\u5019\u53d8\u5316]\n    C --\x3e C1[Qualitative study: interviews/\u5b9a\u6027\u7814\u7a76\uff1a\u8bbf\u8c08]\n    C --\x3e C2[Two communities in Poland/\u6ce2\u5170\u7684\u4e24\u4e2a\u793e\u533a]\n    C --\x3e C3[Hydroponic cabinets in flats/\u516c\u5bd3\u4e2d\u7684\u6c34\u57f9\u67dc]\n    D --\x3e D1[Understand resident motivations/\u7406\u89e3\u5c45\u6c11\u52a8\u673a]\n    D --\x3e D2[Outline farming experiences/\u6982\u8ff0\u79cd\u690d\u7ecf\u9a8c]\n    D --\x3e D3[Relevance for urban educators/\u5bf9\u57ce\u5e02\u6559\u80b2\u8005\u7684\u610f\u4e49]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Mitigating Social Desirability Bias in Random Silicon Sampling"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [llm evaluation], [silicon sampling, social desirability bias, prompt engineering, jensen-shannon divergence, american national election study]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Sashank Chapala, Maksym Mironov, Songgaojun Deng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Eindhoven University of Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22725",children:"https://arxiv.org/pdf/2512.22725"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Replicates and confirms the presence of persistent Social Desirability Bias (SDB) in LLM-based silicon sampling. 2. Proposes and systematically evaluates four psychologically grounded prompt-based methods (reformulated, reverse-coded, priming, preamble) for mitigating SDB. 3. Demonstrates that reformulated prompts (neutral, third-person phrasing) are the most effective method for improving alignment between silicon and human survey response distributions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e514b34cb5fd24baebc22116c45f73b1898e7c713905a13d372408df0900782b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e514b34cb5fd24baebc22116c45f73b1898e7c713905a13d372408df0900782b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how to reduce Social Desirability Bias in LLM-generated survey responses (silicon sampling). It tests four prompt-based mitigation methods and finds that reformulating questions into neutral, third-person phrasing most effectively aligns the LLM outputs with real human data from the American National Election Study."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Mitigating Social Desirability Bias in Random Silicon Sampling] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLM\u7845\u91c7\u6837\u5b58\u5728\u793e\u4f1a\u671f\u671b\u504f\u5dee/Social Desirability Bias in Silicon Sampling]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u6d4b\u8bd5\u56db\u79cd\u57fa\u4e8e\u63d0\u793a\u7684\u7f13\u89e3\u65b9\u6cd5/Test Four Prompt-based Mitigation Methods]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u91cd\u6784\u63d0\u793a\u6700\u6709\u6548\uff0c\u6539\u5584\u4e0e\u4eba\u7c7b\u6570\u636e\u5bf9\u9f50/Reformulated Prompts Most Effective, Improve Alignment]\n    C --\x3e C1[\u91cd\u6784/Reformulated]\n    C --\x3e C2[\u53cd\u5411\u7f16\u7801/Reverse-coded]\n    C --\x3e C3[\u542f\u52a8/Priming]\n    C --\x3e C4[\u5e8f\u8a00/Preamble]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Ungraded Assignments in Introductory Computing: A Report"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [computing education], [ungraded assignments, formative feedback, student engagement, mixed-methods, introductory computing]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yehya Sleiman Tellawi, Abhishek K. Umrawal"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Illinois Urbana-Champaign"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23004",children:"https://arxiv.org/pdf/2512.23004"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Developed and administered new optional ungraded assignments for a large introductory computer engineering course (ECE 120). 2. Employed a mixed-methods approach (surveys, interviews, performance analysis) to assess the impact of ungraded assignments on learning. 3. Found a positive relationship between participation in ungraded assignments and overall course performance, suggesting they appeal to high-achievers or support better outcomes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03fe0f743f635ea37a635da0020b8df696d9ae620a38ea5dd83dd57902fd7911_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03fe0f743f635ea37a635da0020b8df696d9ae620a38ea5dd83dd57902fd7911_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the effects of optional ungraded assignments in an introductory computing course. The authors developed such assignments and used surveys, interviews, and performance data to evaluate their impact. The main finding is a positive correlation between completing ungraded work and higher course grades, indicating potential benefits for student engagement and learning."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Ungraded Assignments in Introductory Computing: A Report] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1(\u8bc4\u4f30\u538b\u529b\u4e0e\u5185\u5728\u52a8\u673a/Grade pressure vs. intrinsic motivation)\n    C --\x3e C1(\u5f00\u53d1\u5e76\u5b9e\u65bd\u672a\u8bc4\u5206\u4f5c\u4e1a/Develop & administer ungraded assignments)\n    C --\x3e C2(\u6df7\u5408\u65b9\u6cd5\u8bc4\u4f30/Mixed-methods evaluation)\n    D --\x3e D1(\u53c2\u4e0e\u5ea6\u4e0e\u6210\u7ee9\u6b63\u76f8\u5173/Participation correlates with performance)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Inteligencia Artificial y Empleo: perspectiva Territorial y de G\xe9nero"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [labor economics, computational social science], [AI exposure index, sector-based analysis, territorial disaggregation, gender gap, CNAE incidence matrix]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Antoni Mestre, Xavier Naya, Manoli Albert, Vicente Pelechano"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universitat de Val\xe8ncia (inferred from author names and Spanish context)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23059",children:"https://arxiv.org/pdf/2512.23059"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),"  1. Proposes a novel methodological framework for estimating AI exposure using sector-based data (CNAE classification) instead of occupation-based approaches, addressing limitations in the Spanish context. 2. Constructs an AI CNAE incidence matrix and applies it to provincial employment data (2021-2023) to provide a territorial and gender-disaggregated assessment of AI's potential impact. 3. Reveals stable structural patterns of AI exposure, identifying higher exposure in metropolitan/service regions and a consistent gender gap where female employment is more exposed across all territories."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/562053897ffb2e59883167293942d4f1e524304623f8d2e91e0026105669c93d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/562053897ffb2e59883167293942d4f1e524304623f8d2e91e0026105669c93d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a sector-based methodological framework to estimate the potential exposure of employment to AI in Spain, addressing the limitations of occupation-centered approaches. By applying an AI CNAE incidence matrix to provincial employment data from 2021-2023, it provides a territorial and gender-disaggregated assessment. The results show higher AI exposure in metropolitan and service-oriented regions and a consistent gender gap, with female employment being more exposed across all territories, offering a structural perspective for policy planning rather than predicting job displacement."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Inteligencia Artificial y Empleo: perspectiva Territorial y de G\xe9nero] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>AI\u5bf9\u52b3\u52a8\u529b\u5e02\u573a\u7684\u4e0d\u5747\u8861\u5f71\u54cd<br>Uneven AI impact on labor markets]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>\u6784\u5efa\u884c\u4e1aAI\u66b4\u9732\u77e9\u9635<br>Construct sector-based AI exposure matrix]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>\u5927\u90fd\u5e02\u533a\u66b4\u9732\u66f4\u9ad8, \u5b58\u5728\u6027\u522b\u5dee\u8ddd<br>Higher exposure in metro areas, consistent gender gap]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Identifying Barriers Hindering the Acceptance of Generative AI as a Work Associate, measured with the new AGAWA scale"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [human-ai interaction], [AGAWA scale, technology acceptance, generative AI, workplace, moral dilemmas]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," \u0141ukasz Sikorski, Albert \u0141ukasik, Jacek Matulewski, Arkadiusz Gut"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nicolaus Copernicus University in Toru\u0144"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23373",children:"https://arxiv.org/pdf/2512.23373"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed the AGAWA scale, a concise 4-item tool for measuring attitudes toward generative AI as a coworker, 2. Investigated key factors (concerns, human-like characteristics, sense of human uniqueness) influencing acceptance of generative AI in the workplace, 3. Confirmed the relationship between affective/moral dimensions of trust and attitudes toward generative AI at work."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae604f8d4d4b73f323c396a472bef59c496be69f1ebbd75e34c80cb0805f530_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae604f8d4d4b73f323c396a472bef59c496be69f1ebbd75e34c80cb0805f530_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces the AGAWA scale, a brief measurement tool based on TAM and UTAUT models, to study barriers to accepting generative AI as a work associate. The study found that positive attitudes toward AI coworkers are negatively correlated with concerns about interaction, human-like AI traits, and a sense of human superiority. The results highlight the link between trust dimensions and workplace AI acceptance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Identifying Barriers to Generative AI Acceptance / \u8bc6\u522b\u751f\u6210\u5f0fAI\u63a5\u53d7\u7684\u969c\u788d"] --\x3e Problem["Core Problem: Student attitudes affect future workplace AI adoption / \u6838\u5fc3\u95ee\u9898: \u5b66\u751f\u6001\u5ea6\u5f71\u54cd\u672a\u6765\u5de5\u4f5c\u573a\u6240AI\u91c7\u7528"]\n    Root --\x3e Method["Method: Propose AGAWA scale (4-item tool) / \u65b9\u6cd5: \u63d0\u51faAGAWA\u91cf\u8868(4\u9879\u5de5\u5177)"]\n    Root --\x3e Results["Results: Positive attitudes linked to reduced concerns, human-likeness, and superiority beliefs / \u7ed3\u679c: \u79ef\u6781\u6001\u5ea6\u4e0e\u51cf\u5c11\u7684\u62c5\u5fe7\u3001\u62df\u4eba\u7279\u6027\u548c\u4f18\u8d8a\u611f\u4fe1\u5ff5\u76f8\u5173"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [scientometrics], [gender diversity, team roles, author contribution statements, threshold regression, citation impact]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yi Zhao, Yongjun Zhu, Donghun Kim, Yuzhuo Wang, Heng Zhang, Chao Lu, Chengzhi Zhang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Anhui University, Yonsei University, Nanjing University, Central China Normal University, Hohai University, Nanjing University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23429",children:"https://arxiv.org/pdf/2512.23429"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a team roles perspective by classifying authors into leadership and support roles using contribution statements, moving beyond aggregate diversity measures. 2. Discovered a non-linear (inverted U-shape) relationship between gender diversity and team impact for both leadership and support groups. 3. Revealed the moderating effect of team size, showing that the impact of leadership-group gender diversity shifts from negative to positive as team size increases, while support-group diversity remains consistently positive."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8e0d6494840d098b4c65bf9f6eb6b4b27a82bd62024c95c0f60db9e5b8fa31f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8e0d6494840d098b4c65bf9f6eb6b4b27a82bd62024c95c0f60db9e5b8fa31f_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This study investigates how gender diversity within specific team roles (leadership vs. support) affects scientific team impact, measured by citations. By analyzing over 130,000 PLOS papers and using contribution statements to define roles, the authors employed multivariable and threshold regression. They found the relationship is an inverted U-shape, identified high-impact team compositions, and showed that team size significantly moderates the effect of leadership diversity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[The Effect of Gender Diversity on Scientific Team Impact<br>\u6027\u522b\u591a\u6837\u6027\u5bf9\u79d1\u7814\u56e2\u961f\u5f71\u54cd\u529b\u7684\u5f71\u54cd] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem<br>Inconsistent findings on gender diversity's effect,<br>lack of role-differentiated analysis.<br>\u6027\u522b\u591a\u6837\u6027\u5f71\u54cd\u7ed3\u8bba\u4e0d\u4e00\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u56e2\u961f\u89d2\u8272\u7684\u5206\u6790]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Analyzed 130k+ PLOS papers, used contribution<br>statements for role classification (leadership/support),<br>applied multivariable & threshold regression.<br>\u5206\u679013\u4e07+PLOS\u8bba\u6587\uff0c\u5229\u7528\u8d21\u732e\u58f0\u660e\u8fdb\u884c\u89d2\u8272\u5206\u7c7b\uff0c\u5e94\u7528\u591a\u5143\u53ca\u9608\u503c\u56de\u5f52]\n    D[\u5173\u952e\u7ed3\u679c/Results<br>1. Inverted U-shape relationship.<br>2. All-female leadership + all-male support yields high impact.<br>3. Team size moderates leadership diversity effect.<br>1. \u5012U\u578b\u5173\u7cfb\u3002<br>2. \u5168\u5973\u6027\u9886\u5bfc+\u5168\u7537\u6027\u652f\u6301\u7684\u56e2\u961f\u5f71\u54cd\u529b\u66f4\u9ad8\u3002<br>3. \u56e2\u961f\u89c4\u6a21\u8c03\u8282\u9886\u5bfc\u7ec4\u591a\u6837\u6027\u6548\u5e94\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Can AI Recognize Its Own Reflection? Self-Detection Performance of LLMs in Computing Education"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [academic integrity detection], [Large Language Models, AI-generated text detection, deceptive prompts, computing education, self-detection]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Christopher Burger, Karmece Talley, Christina Trotter"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The University of Mississippi, Rust College"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23587",children:"https://arxiv.org/pdf/2512.23587"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Evaluates the self-detection performance of three prominent LLMs (GPT-4, Claude, Gemini) in computing-specific contexts. 2. Tests detection under both standard and deceptive prompt conditions where models are instructed to evade detection. 3. Reveals significant instability in detection, showing high error rates for human-written work and susceptibility to simple prompt alterations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e1ff7ce7b5924fdb6e21130ee87b352dc8c7613c8706c156c27ac0e31017f8b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e1ff7ce7b5924fdb6e21130ee87b352dc8c7613c8706c156c27ac0e31017f8b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper evaluates the ability of LLMs (GPT-4, Claude, Gemini) to detect AI-generated text in computing education. It tests them under standard and deceptive prompt conditions, finding that while default AI text is easily identified, models struggle with human-written work and are highly fooled by deceptive prompts, making them unreliable for high-stakes academic judgments."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Can AI Recognize Its Own Reflection? Self-Detection Performance of LLMs in Computing Education] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: LLMs challenge academic integrity in computing education]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Evaluate GPT-4, Claude, Gemini on AI-generated text detection with standard/deceptive prompts]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Models unstable; high error on human text; easily fooled by deceptive prompts; unreliable for misconduct judgments]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] AI tutoring can safely and effectively support students: An exploratory RCT in UK classrooms"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [educational ai], [generative AI, fine-tuning, randomized controlled trial, Socratic questioning, pedagogical instruction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," LearnLM Team Google, Eedi, Albert Wang, Aliya Rysbek, Andrea Huber, Anjali Nambiar, Anna Kenolty, Ben Caulfield, Beth Lilley-Draper, Bibi Groot, Brian Veprek, Chelsea Burdett, Claire Willis, Craig Barton, Digory Smith, George Mu, Harriet Walters, Irina Jurenka, Iris Hulls, James Stalley-Moores, Jonathan Caton, Julia Wilkowski, Kaiz Alarakyia, Kevin R. McKee, Liam McCafferty, Lucy Dalton, Markus Kunesch, Pauline Malubay, Rachel Kidson, Rich Wells, Sam Wheeler, Sara Wiltberger, Shakir Mohamed, Simon Woodhead, Vasco Braz\xe3o"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google, Eedi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23633",children:"https://arxiv.org/pdf/2512.23633"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted a rigorous, in-classroom exploratory RCT to evaluate the safety and efficacy of a generative AI tutor (LearnLM) in a real educational setting. 2. Demonstrated that a pedagogically fine-tuned AI model can reliably draft instructional content, with human tutors approving 76.4% of its messages with minimal or no edits. 3. Showed that AI-supported tutoring led to student performance at least equivalent to human-only tutoring, with a significant 5.5 percentage point improvement in solving novel problems on subsequent topics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b430e7c78534d660126208f226397ed95756e540bade56276301199a0114bc76_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b430e7c78534d660126208f226397ed95756e540bade56276301199a0114bc76_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates whether generative AI can scale effective one-to-one tutoring. The authors integrated LearnLM, a pedagogically fine-tuned AI model, into a math tutoring platform and conducted a randomized controlled trial where human tutors supervised its outputs. The results show that LearnLM was a reliable tutor, and students using it performed as well as or better than those with human tutors alone, suggesting AI can deliver effective, individualized learning support at scale."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[AI Tutoring RCT in UK Classrooms] --\x3e Problem[\u6838\u5fc3\u95ee\u9898/Problem]\n    Root --\x3e Method[\u4e3b\u8981\u65b9\u6cd5/Method]\n    Root --\x3e Results[\u5173\u952e\u7ed3\u679c/Results]\n    Problem --\x3e P1[\u4e2a\u6027\u5316\u8f85\u5bfc\u6210\u672c\u9ad8/High cost of 1-to-1 tutoring]\n    Problem --\x3e P2[AI\u8f85\u5bfc\u7684\u6709\u6548\u6027\u4e0e\u5b89\u5168\u6027\u672a\u77e5/Unproven efficacy & safety of AI tutoring]\n    Method --\x3e M1[\u6574\u5408LearnLM\u6a21\u578b/Integrate LearnLM (pedagogically fine-tuned AI)]\n    Method --\x3e M2[\u5728Eedi\u5e73\u53f0\u8fdb\u884cRCT/Conduct RCT on Eedi platform]\n    Method --\x3e M3[\u4e13\u5bb6\u5bfc\u5e08\u76d1\u7763\u8f93\u51fa/Human tutors supervise AI drafts]\n    Results --\x3e R1[76.4%\u6d88\u606f\u88ab\u76f4\u63a5\u6279\u51c6/76.4% messages approved with minimal edits]\n    Results --\x3e R2[\u5b66\u751f\u8868\u73b0\u76f8\u5f53\u6216\u66f4\u597d/Student performance equal or better]\n    Results --\x3e R3[\u89e3\u51b3\u65b0\u95ee\u9898\u80fd\u529b\u63d0\u53475.5%/5.5% improvement on novel problems]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);