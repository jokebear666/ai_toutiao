"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9404],{25526:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"daily/cs_AR/20251229-20260104","title":"20251229-20260104 (cs.AR)","description":"2025-12-29","source":"@site/docs/daily/cs_AR/20251229-20260104.md","sourceDirName":"daily/cs_AR","slug":"/daily/csar/20251229-20260104","permalink":"/ai_toutiao/daily/csar/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767100119000,"frontMatter":{"slug":"/daily/csar/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.AR)","permalink":"/ai_toutiao/daily/csar/20251222-20251228"},"next":{"title":"cs.CC","permalink":"/ai_toutiao/daily/cscc"}}');var s=i(74848),a=i(28453);const t={slug:"/daily/csar/20251229-20260104"},o="20251229-20260104 (cs.AR)",l={},c=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"20251229-20260104-csar",children:"20251229-20260104 (cs.AR)"})}),"\n",(0,s.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251229] Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [sec], [side-channel analysis], [RISC-V, CVA6, Correlation Power Analysis (CPA), RTL simulation, power side-channel]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Behnam Farnaghinejad, Antonio Porsia, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo, Ernesto Sanchez"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Politecnico di Torino"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21362",children:"https://arxiv.org/pdf/2512.21362"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Presents the first side-channel vulnerability evaluation of the CVA6 RISC-V processor core. 2. Demonstrates the application of the VeriSide RTL-level power profiling framework for efficient power trace extraction without waveform files. 3. Shows that Correlation Power Analysis (CPA) on the CVA6 during software-based AES encryption enables key recovery, highlighting the need for early-stage RTL security assessments."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper analyzes the power side-channel vulnerability of the CVA6 RISC-V core using the VeriSide RTL simulation framework. By applying Correlation Power Analysis (CPA) to power traces during software AES execution, the authors successfully recover the secret key. The findings demonstrate significant leakage in the CVA6 design, emphasizing the importance of pre-silicon RTL-level security evaluation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    A[Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u73b0\u4ee3RISC-V\u5904\u7406\u5668\u9700\u8981\u6297\u4fa7\u4fe1\u9053\u653b\u51fb\u80fd\u529b / Modern RISC-V processors require resilience to side-channel attacks]\n    C --\x3e C1[\u4f7f\u7528VeriSide\u6846\u67b6\u5728RTL\u7ea7\u8fdb\u884c\u529f\u8017\u5206\u6790 / Use VeriSide framework for RTL-level power analysis]\n    C --\x3e C2[\u5bf9\u8f6f\u4ef6AES\u6267\u884c\u8fdb\u884c\u76f8\u5173\u6027\u529f\u8017\u5206\u6790(CPA) / Perform Correlation Power Analysis (CPA) on software AES execution]\n    D --\x3e D1[CVA6\u8bbe\u8ba1\u5b58\u5728\u663e\u8457\u6cc4\u6f0f / CVA6 design exhibits significant leakage]\n    D --\x3e D2[\u6210\u529f\u6062\u590dAES\u5bc6\u94a5 / Successful AES key recovery]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251229] Online Learning Extreme Learning Machine with Low-Complexity Predictive Plasticity Rule and FPGA Implementation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [predictive plasticity rule, extreme learning machine, FPGA implementation, online learning, low-complexity training]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Zhenya Zang, Xingda Li, David Day Uei Li"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," University of Strathclyde"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21777",children:"https://arxiv.org/pdf/2512.21777"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a simplified, biologically inspired predictive local learning rule that eliminates global backpropagation and membrane integration, using sparse, binary-driven vector additions triggered only by prediction errors. 2. Integrated this rule into an Extreme Learning Machine (ELM), replacing the conventional matrix inversion, thereby reducing training complexity from O(M^3) to O(M) for M hidden nodes. 3. Demonstrated an FPGA implementation showing significant reductions in computational and memory requirements, highlighting its potential for energy-efficient online learning on low-cost edge devices."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fd9efea1b6faa314e48c1a0c90ad6c7bf79112ed59bfb1db6f14146d142848_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fd9efea1b6faa314e48c1a0c90ad6c7bf79112ed59bfb1db6f14146d142848_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a low-complexity online learning method by integrating a simplified predictive plasticity rule into an Extreme Learning Machine (ELM), which reduces training complexity from cubic to linear order. The approach is implemented on FPGA, showing reduced computational and memory needs while maintaining comparable accuracy. The work demonstrates strong potential for enabling efficient online learning on resource-constrained edge devices."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TB\n    Root["Online Learning ELM with Low-Complexity Predictive Plasticity Rule and FPGA Implementation<br/>\u5728\u7ebf\u5b66\u4e60ELM\u4e0e\u4f4e\u590d\u6742\u5ea6\u9884\u6d4b\u53ef\u5851\u6027\u89c4\u5219\u53caFPGA\u5b9e\u73b0"]\n    Root --\x3e Problem["Problem: High complexity of online learning for edge devices<br/>\u95ee\u9898\uff1a\u9762\u5411\u8fb9\u7f18\u8bbe\u5907\u7684\u5728\u7ebf\u5b66\u4e60\u590d\u6742\u5ea6\u9ad8"]\n    Root --\x3e Method["Method: Simplified predictive plasticity rule + ELM<br/>\u65b9\u6cd5\uff1a\u7b80\u5316\u7684\u9884\u6d4b\u53ef\u5851\u6027\u89c4\u5219 + ELM"]\n    Root --\x3e Results["Results: O(M) training, FPGA implementation, low resource use<br/>\u7ed3\u679c\uff1aO(M)\u8bad\u7ec3\uff0cFPGA\u5b9e\u73b0\uff0c\u4f4e\u8d44\u6e90\u6d88\u8017"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Uppsala University"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22066",children:"https://arxiv.org/pdf/2512.22066"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TB\n    Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>LLM\u63a8\u7406\u80fd\u8017\u9ad8\uff0cPrefill\u4e0eDecode\u9636\u6bb5\u74f6\u9888\u4e0d\u540c"] --\x3e Problem_Sub1["SRAM\u5927\u5c0f\u4e0e\u9891\u7387\u5982\u4f55\u5f71\u54cd\u80fd\u6548\uff1f"]\n    Problem --\x3e Problem_Sub2["\u5185\u5b58\u5e26\u5bbd\u5982\u4f55\u9650\u5236\u6027\u80fd\uff1f"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>\u7ed3\u5408OpenRAM, LLMCompass, ScaleSIM\u7684\u6a21\u62df\u65b9\u6cd5"] --\x3e Method_Sub1["\u80fd\u8017\u5efa\u6a21/Energy Modeling"]\n    Method --\x3e Method_Sub2["\u5ef6\u8fdf\u6a21\u62df/Latency Simulation"]\n    Method --\x3e Method_Sub3["\u64cd\u4f5c\u5f3a\u5ea6\u5206\u6790/Operational Intensity"]\n    Results["\u5173\u952e\u7ed3\u679c/Results"] --\x3e Results_Sub1["\u603b\u80fd\u8017\u4e3b\u8981\u7531SRAM\u5927\u5c0f\u51b3\u5b9a<br>\u5927\u7f13\u5b58\u589e\u52a0\u9759\u6001\u80fd\u8017"]\n    Results --\x3e Results_Sub2["\u9ad8\u9891\u53ef\u964d\u4f4e\u603b\u80fd\u8017<br>\uff08\u51cf\u5c11\u9759\u6001\u80fd\u8017\uff09"]\n    Results --\x3e Results_Sub3["\u6700\u4f18\u914d\u7f6e\uff1a\u9ad8\u9891(1200-1400MHz) + \u5c0f\u7f13\u5b58(32-64KB)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [RFET, stochastic computing, SCNN, stochastic number generator, accelerator]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Sheng Lu, Qianhou Qu, Sungyong Jung, Qilian Liang, Chenyun Pan"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"}),' University of Texas at Arlington (inferred from IEEE affiliation and author "Qilian Liang, Fellow, IEEE" known association)']}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22131",children:"https://arxiv.org/pdf/2512.22131"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel SCNN architecture leveraging Reconfigurable Field-Effect Transistors (RFETs) for device-level reconfigurability. 2. Designs highly efficient and compact core modules (e.g., SNGs, APCs) enabled by RFET technology. 3. Develops and evaluates a dedicated RFET-based SCNN accelerator, showing significant improvements in area, latency, and energy over a FinFET baseline."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the high resource consumption of Stochastic Computing Neural Networks (SCNNs) by proposing a novel accelerator architecture based on Reconfigurable Field-Effect Transistors (RFETs). The inherent reconfigurability of RFETs enables the design of compact and efficient core components like stochastic number generators. Experimental results demonstrate that the proposed RFET-based accelerator achieves substantial reductions in area, latency, and energy consumption compared to a FinFET-based design at the same technology node."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    A[An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: SCNN\u8d44\u6e90\u6d88\u8017\u9ad8/High SCNN Resource Usage]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: \u57fa\u4e8eRFET\u7684\u67b6\u6784/RFET-Based Architecture]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u9762\u79ef\u3001\u5ef6\u8fdf\u3001\u80fd\u8017\u964d\u4f4e/Reduced Area, Latency, Energy]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [FPGA, HLS, Point Cloud, Model Compression, Fixed-Point]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," National University of Sciences and Technology (Pakistan), RPTU Kaiserslautern-Landau (Germany)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22139",children:"https://arxiv.org/pdf/2512.22139"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"code:"})," ",(0,s.jsx)(n.a,{href:"https://github.com/dll-ncai/HLS4PC",children:"https://github.com/dll-ncai/HLS4PC"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposed HLS4PC, a parameterizable HLS framework for accelerating point-based 3D point cloud models on FPGA. 2. Introduced PointMLP-Lite, a 4x less complex model variant created via hardware-aware compression techniques (URS, quantization, pruning, fusion). 3. Demonstrated FPGA acceleration achieving 3.56x higher throughput than prior work and outperforming GPU/CPU implementations."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of real-time 3D point cloud processing by proposing HLS4PC, a parameterizable FPGA acceleration framework. The method combines algorithmic optimizations and hardware-aware model compression to create an efficient fixed-point implementation, which significantly outperforms previous accelerators and GPU/CPU baselines in throughput."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    Root[HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[GPU under-utilization due to sparse, unstructured point cloud data]\n    P1 --\x3e P2[High memory/computation demand hinders real-time performance]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[Parameterizable HLS framework for FPGA]\n    M1 --\x3e M2[Hardware-aware compression: URS, quantization, pruning, fusion]\n    M2 --\x3e M3[Creates PointMLP-Lite model]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[PointMLP-Lite: 4x less complex, ~2% accuracy drop]\n    R1 --\x3e R2[3.56x higher throughput vs. prior work]\n    R2 --\x3e R3[2.3x (GPU) and 22x (CPU) higher throughput]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [analog circuit design, multi-agent framework, stratified memory, simulation-grounded feedback, self-evolving]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Zining Wang, Jian Gao, Weimin Fu, Xiaolong Guo, Xuan Zhang"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Northeastern University, Kansas State University"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22435",children:"https://arxiv.org/pdf/2512.22435"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AnalogSAGE, an open-source self-evolving multi-agent framework for analog circuit design that coordinates three-stage agent explorations through four stratified memory layers, enabling iterative refinement with simulation-grounded feedback. 2. Introduces a stratified context mechanism to selectively preserve stage-relevant information, enhancing long-horizon reasoning and reliability under stringent specifications. 3. Demonstrates significant improvements in pass rates and search space reduction through a benchmark of ten operational amplifier design problems using the open-source SKY130 PDK and ngspice."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf0a7cad048acb4f93f29281281d9e76543f81e5aa1dd6e183e005cda30a7c56_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf0a7cad048acb4f93f29281281d9e76543f81e5aa1dd6e183e005cda30a7c56_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of automating analog circuit design, which traditionally relies heavily on human intuition, by introducing AnalogSAGE, a self-evolving multi-agent framework with stratified memory and simulation-grounded feedback. This approach enables iterative refinement across topology selection, refinement, and parameter optimization stages. Evaluations show it achieves a 10x overall pass rate and 4x reduction in parameter search space compared to existing methods, enhancing reliability and autonomy in analog design automation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    A[AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[Analog circuit design is knowledge-intensive and relies on human intuition]\n    B --\x3e B2[Existing LLM-based methods lack feedback and generalization]\n    C --\x3e C1[Self-evolving multi-agent framework]\n    C --\x3e C2[Three-stage agent explorations with stratified memory]\n    C --\x3e C3[Iterative refinement via simulation-grounded feedback]\n    D --\x3e D1[10x overall pass rate improvement]\n    D --\x3e D2[48x Pass@1 improvement]\n    D --\x3e D3[4x reduction in parameter search space]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [on-device ai], [activation function, hardware accelerator, taylor series, energy efficiency, edge inference]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Soham Pramanik, Vimal William, Arnab Raha, Debayan Das, Amitava Mukherjee, Janet L. Paluh"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Jadavpur University, SandLogic Technologies, Intel Corporation, Indian Institute of Science, Amrita University, SUNY Polytechnic Institute"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23062",children:"https://arxiv.org/pdf/2512.23062"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposes TYTAN, a Taylor-series based Generalized Non-linear Approximation Engine (G-NAE) for accelerating non-linear activation functions in deep learning. 2. Integrates a re-configurable hardware design with a specialized algorithm to dynamically estimate approximations, aiming for minimal accuracy deviation. 3. Demonstrates significant performance gains and efficiency improvements, including ~2x performance, ~56% power reduction, and ~35x lower area compared to a baseline NVDLA implementation."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes TYTAN, a hardware-software co-designed engine that uses Taylor series approximations to accelerate non-linear activation functions for energy-efficient AI inference at the edge. The system dynamically configures the approximation to maintain accuracy. Evaluations show it achieves high frequency operation (>950 MHz) with substantial improvements in performance, power, and area compared to a standard accelerator."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    A[TYTAN: Taylor-series based Non-Linear Activation Engine] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Edge AI inference requires acceleration and energy efficiency, limited by high-power operations like activation functions.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Proposes a Generalized Non-linear Approximation Engine (G-NAE) using Taylor series and re-configurable hardware with a dynamic approximation algorithm.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: >950 MHz operation, ~2x performance, ~56% power reduction, ~35x lower area vs. NVDLA baseline.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Meta Platforms"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23236",children:"https://arxiv.org/pdf/2512.23236"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system's effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    A[KernelEvolve: Scaling Agentic Kernel Coding] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[DLRM\u8bad\u7ec3/\u63a8\u7406\u6548\u7387<br/>DLRM Training/Inference Efficiency]\n    B --\x3e B2[\u6a21\u578b\u3001\u5185\u6838\u3001\u786c\u4ef6\u5f02\u6784\u6027<br/>Model, Kernel, Hardware Heterogeneity]\n    C --\x3e C1[\u667a\u80fd\u5185\u6838\u7f16\u7801\u6846\u67b6<br/>Agentic Kernel Coding Framework]\n    C --\x3e C2[\u591a\u62bd\u8c61\u5c42: Triton, CuTe DSL<br/>Multi-Abstraction: Triton, CuTe DSL]\n    C --\x3e C3[\u56fe\u641c\u7d22\u4e0e\u68c0\u7d22\u589e\u5f3a\u63d0\u793a<br/>Graph Search & Retrieval-Augmented Prompt]\n    D --\x3e D1[100%\u6b63\u786e\u7387, 17\u500d\u52a0\u901f<br/>100% Correctness, 17x Speedup]\n    D --\x3e D2[\u5f00\u53d1\u65f6\u95f4: \u6570\u5468->\u6570\u5c0f\u65f6<br/>Dev Time: Weeks->Hours]\n    D --\x3e D3[\u964d\u4f4e\u65b0\u786c\u4ef6\u7f16\u7a0b\u58c1\u5792<br/>Reduces New Hardware Programmability Barrier]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"[arXiv251230] Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"tags:"})," [other], [digital signal processing, computer arithmetic, high-performance computing], [energy-efficient computing, integer-friendly approximation, conflict-free memory access, fast Fourier transform, fast Schur algorithm]"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"authors:"})," Sergey Salishev"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"institution:"})," Saint Petersburg State University"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"link:"})," ",(0,s.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22676",children:"https://arxiv.org/pdf/2512.22676"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"contributions:"})," 1. A power/energy consumption model for clocked CMOS logic to select optimal parallelism. 2. Integer-friendly approximation methods for elementary functions using constrained piecewise-polynomials to reduce lookup-table size. 3. Provably conflict-free data placement and execution order schemes for mixed-radix streaming FFT on multi-bank/single-port memories."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"thumbnail:"})," ",(0,s.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp"})]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Simple LLM Summary:"})," This thesis develops signal-processing algorithms and implementation schemes under constraints of minimal parallelism and memory space to improve energy efficiency. It proposes a power model, approximation methods, and conflict-free memory access schemes for FFT and fast Schur algorithms. The results provide constructive theorems and design trade-offs for building efficient specialized accelerators."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TB\n    Root["Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space<br>\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u5728\u6700\u5c0f\u5e76\u884c\u5ea6\u548c\u5185\u5b58\u7a7a\u95f4\u7ea6\u675f\u4e0b\u7684\u7efc\u5408"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Improving energy efficiency of low-power computing hardware<br>\u63d0\u9ad8\u4f4e\u529f\u8017\u8ba1\u7b97\u786c\u4ef6\u7684\u80fd\u6548"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>1. Power/energy model for CMOS logic<br>CMOS\u903b\u8f91\u529f\u8017/\u80fd\u8017\u6a21\u578b<br>2. Integer-friendly function approximation<br>\u6574\u6570\u53cb\u597d\u51fd\u6570\u8fd1\u4f3c<br>3. Conflict-free FFT schedules<br>\u65e0\u51b2\u7a81FFT\u8c03\u5ea6<br>4. Parallelism/memory analysis for fast Schur algorithm<br>\u5feb\u901fSchur\u7b97\u6cd5\u7684\u5e76\u884c\u5ea6/\u5185\u5b58\u5206\u6790"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Constructive theorems, schedules, and design trade-offs for efficient specialized accelerators<br>\u4e3a\u9ad8\u6548\u4e13\u7528\u52a0\u901f\u5668\u63d0\u4f9b\u6784\u9020\u6027\u5b9a\u7406\u3001\u8c03\u5ea6\u65b9\u6848\u548c\u8bbe\u8ba1\u6743\u8861"]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var r=i(96540);const s={},a=r.createContext(s);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);