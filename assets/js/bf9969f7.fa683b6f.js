"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[27],{28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(96540);const r={},s=i.createContext(r);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}},44637:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"daily/cs_AR/20251215-20251221","title":"20251215-20251221 (cs.AR)","description":"2025-12-19","source":"@site/docs/daily/cs_AR/20251215-20251221.md","sourceDirName":"daily/cs_AR","slug":"/daily/cs_AR/20251215-20251221","permalink":"/ai_toutiao/daily/cs_AR/20251215-20251221","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767086937000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"cs.AR","permalink":"/ai_toutiao/category/csar"},"next":{"title":"20251222-20251228 (cs.AR)","permalink":"/ai_toutiao/daily/csar/20251222-20251228"}}');var r=t(74848),s=t(28453);const a={},o="20251215-20251221 (cs.AR)",c={},l=[{value:"2025-12-19",id:"2025-12-19",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251215-20251221-csar",children:"20251215-20251221 (cs.AR)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-19",children:"2025-12-19"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"[arXiv251219] AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [AI Engine (AIE), GEMV, quantization, on-chip data movement, graph placement and search, low-latency inference, fused bias addition and ReLU]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Dimitrios Danopoulos, Enrico Lupi, Chang Sun, Sebastian Dittmeier, Michael Kagan, Vladimir Loncar, Maurizio Pierini"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," European Organization for Nuclear Research (CERN), Institute of Physics Belgrade, Heidelberg University"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.15946",children:"https://arxiv.org/pdf/2512.15946"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents AIE4ML, an end-to-end framework that automatically compiles neural networks into optimized firmware for AMD's AI Engine-ML accelerators. It achieves high efficiency through a structured parallelization method that scales across the 2D fabric and uses a novel graph placement algorithm for on-chip execution. The framework delivers GPU-class throughput with microsecond latency, making it suitable for ultra-low-latency applications like particle physics trigger systems."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);