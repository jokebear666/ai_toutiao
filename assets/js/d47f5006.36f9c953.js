"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[601],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(96540);const a={},r=s.createContext(a);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(r.Provider,{value:n},e.children)}},77737:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"daily/cs_IR/20251229-20260104","title":"20251229-20260104 (cs.IR)","description":"2025-12-29","source":"@site/docs/daily/cs_IR/20251229-20260104.md","sourceDirName":"daily/cs_IR","slug":"/daily/csir/20251229-20260104","permalink":"/ai_toutiao/daily/csir/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767583031000,"frontMatter":{"slug":"/daily/csir/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.IR)","permalink":"/ai_toutiao/daily/csir/20251222-20251228"},"next":{"title":"20260105-20260111 (cs.IR)","permalink":"/ai_toutiao/daily/csir/20260105-20260111"}}');var a=i(74848),r=i(28453);const t={slug:"/daily/csir/20251229-20260104"},o="20251229-20260104 (cs.IR)",l={},d=[{value:"2025-12-29",id:"2025-12-29",level:2},{value:"2025-12-30",id:"2025-12-30",level:2},{value:"2026-01-01",id:"2026-01-01",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"20251229-20260104-csir",children:"20251229-20260104 (cs.IR)"})}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Dynamic Cooperative Strategies in Search Engine Advertising Market: With and Without Retail Competition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [e-commerce, digital marketing], [search engine advertising, cooperative advertising, differential games, quality score, retail competition]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huiran Li, Qiucheng Li, Baozhu Feng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Customs College, Anhui University of Finance and Economics"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21501",children:"https://arxiv.org/pdf/2512.21501"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel dynamic cooperative advertising optimization model for the SEA market that incorporates direct manufacturer advertising and retailer subsidies. 2. Analyzes two distinct scenarios (with and without retail competition) and provides feasible equilibrium solutions for optimal policies. 3. Investigates the impact of key factors like dynamic quality scores, gross margin, and competitor market share through numerical experiments and sensitivity analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e8e39e4b762e4f21704f8b0ceb833bc4aaedafa4ea17a006a39e667b238fb9a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e8e39e4b762e4f21704f8b0ceb833bc4aaedafa4ea17a006a39e667b238fb9a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper models cooperative advertising strategies in the search engine advertising (SEA) market using a differential game framework over a finite time horizon. It proposes an optimization model where a manufacturer can advertise directly and subsidize a retailer, analyzing scenarios with and without a competing independent retailer. The study provides equilibrium solutions and numerical insights, concluding that retail competition significantly impacts the optimal cooperative strategy and overall channel performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Dynamic Cooperative Strategies in Search Engine Advertising Market<br/>\u52a8\u6001\u5408\u4f5c\u7b56\u7565\u5728\u641c\u7d22\u5f15\u64ce\u5e7f\u544a\u5e02\u573a"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Intense retail competition & need for channel coordination in SEA"] --\x3e P1["\u5b50\u95ee\u9898/Sub-Problem<br/>Optimal cooperative advertising with/without retail competition"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Dynamic cooperative advertising model using differential games"] --\x3e M1["\u6a21\u578b\u7279\u5f81/Model Features<br/>Finite time horizon, dynamic quality score"]\n    Method --\x3e M2["\u573a\u666f/Scenarios<br/>Scenario I: One manufacturer, one retailer<br/>Scenario II: Alliance vs. independent retailer"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Equilibrium solutions & numerical analysis"] --\x3e R1["\u53d1\u73b0/Findings<br/>Impact of quality score, gross margin, competitor share"]\n    Results --\x3e R2["\u7ed3\u8bba/Conclusion<br/>Retail competition affects optimal strategy & channel performance"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Selective LLM-Guided Regularization for Enhancing Recommendation Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [selective regularization, knowledge distillation, cold-start, long-tail, gating mechanism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shanglin Yang, Zhan Shi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sichuan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21526",children:"https://arxiv.org/pdf/2512.21526"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a selective LLM-guided regularization framework (S-LLMR) that activates LLM supervision only when a gating mechanism predicts the LLM to be reliable, addressing the issue of inaccurate global distillation. 2. Introduces a trainable gating mechanism informed by user history length, item popularity, and model uncertainty to dynamically decide when to apply LLM-based pairwise ranking supervision. 3. Demonstrates through experiments that the method improves overall accuracy and yields substantial gains in cold-start and long-tail recommendation scenarios, outperforming global distillation baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of leveraging large language models (LLMs) for recommendation without suffering from their high cost and unreliability in certain scenarios. It proposes Selective LLM-Guided Regularization (S-LLMR), a model-agnostic framework that uses a gating mechanism to selectively apply LLM-based supervision only when the LLM is predicted to be reliable. Experiments show this approach improves recommendation accuracy, especially for cold-start users and long-tail items, outperforming methods that uniformly distill LLM knowledge."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Selective LLM-Guided Regularization<br>\u9009\u62e9\u6027LLM\u5f15\u5bfc\u6b63\u5219\u5316] --\x3e B(Problem/\u6838\u5fc3\u95ee\u9898<br>LLMs as standalone recommenders are costly/unreliable;<br>Global distillation forces imitation of inaccurate LLM guidance.)\n    A --\x3e C(Method/\u4e3b\u8981\u65b9\u6cd5<br>Selective LLM-Guided Regularization (S-LLMR):<br>Trainable gating mechanism activates LLM supervision only when reliable.)\n    A --\x3e D(Results/\u5173\u952e\u7ed3\u679c<br>Improves overall accuracy;<br>Substantial gains in cold-start & long-tail regimes.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CEMG: Collaborative-Enhanced Multimodal Generative Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [multimodal fusion, generative recommendation, large language model, collaborative filtering, residual quantization vae]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuzhen Lin, Hongyi Chen, Xuanjing Chen, Shaowen Wang, Ivonne Xu, Dongming Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, University of California, Los Angeles, Columbia University, University of Illinois Urbana-Champaign, University of Chicago, Rice University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21543",children:"https://arxiv.org/pdf/2512.21543"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework (CEMG) that deeply integrates collaborative signals to guide multimodal feature fusion, addressing superficial integration. 2. Introduces a Unified Modality Tokenization stage using a Residual Quantization VAE to convert fused multimodal representations into discrete semantic codes. 3. Fine-tunes a large language model to autoregressively generate item codes for end-to-end generative recommendation, demonstrating superior performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/267ab80cc75bcfd70f9642eece8f5665f85619909a397396158a72d2bb42b941_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/267ab80cc75bcfd70f9642eece8f5665f85619909a397396158a72d2bb42b941_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes CEMG, a novel generative recommendation framework that addresses superficial collaborative signal integration and decoupled multimodal fusion. It uses collaborative signals to guide multimodal feature fusion, tokenizes the fused representation into discrete codes using an RQ-VAE, and fine-tunes an LLM to generate these codes. Experiments show CEMG significantly outperforms state-of-the-art baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[CEMG: Collaborative-Enhanced Multimodal Generative Recommendation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u6d45\u5c42\u534f\u540c\u4fe1\u53f7\u96c6\u6210/Superficial collaborative signal integration]\n    Problem --\x3e P2[\u89e3\u8026\u7684\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408/Decoupled multimodal feature fusion]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u591a\u6a21\u6001\u878d\u5408\u5c42/Multimodal Fusion Layer]\n    M1 --\x3e M1_Detail[\u534f\u540c\u4fe1\u53f7\u5f15\u5bfc\u878d\u5408/Collaborative signal-guided fusion]\n    Method --\x3e M2[\u7edf\u4e00\u6a21\u6001\u6807\u8bb0\u5316/Unified Modality Tokenization]\n    M2 --\x3e M2_Detail[\u4f7f\u7528RQ-VAE/Using RQ-VAE]\n    Method --\x3e M3[\u7aef\u5230\u7aef\u751f\u6210\u63a8\u8350/End-to-End Generative Recommendation]\n    M3 --\x3e M3_Detail[\u5fae\u8c03LLM\u751f\u6210\u4ee3\u7801/Fine-tune LLM to generate codes]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf/Significantly outperforms baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [item-to-item recommendation, data-centric, long-tail items, data augmentation, data filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yinfu Feng, Yanjing Wu, Rong Xiao, Xiaoyi Zen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21595",children:"https://arxiv.org/pdf/2512.21595"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLM-I2I, a data-centric framework that leverages Large Language Models to enhance I2I recommendation models without altering their architecture. 2. Introduces an LLM-based data generator to synthesize user-item interactions, specifically targeting long-tail items to alleviate data sparsity. 3. Designs an LLM-based data discriminator to filter out noisy interactions from both real and synthetic data, improving overall data quality for training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses data sparsity and noise problems in Item-to-Item (I2I) recommendation systems by proposing LLM-I2I, a data-centric framework that uses an LLM to generate synthetic interactions for long-tail items and filter noisy data. The refined data is then used to train existing I2I models. Experimental results on industrial and academic datasets show significant improvements in recommendation accuracy, especially for long-tail items, and deployment on a large e-commerce platform led to measurable gains in recall and gross merchandise value."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u7a00\u758f\u4e0e\u566a\u58f0/Data Sparsity & Noise]\n    C --\x3e C1[LLM\u6570\u636e\u751f\u6210\u5668/LLM-based Data Generator]\n    C --\x3e C2[LLM\u6570\u636e\u5224\u522b\u5668/LLM-based Data Discriminator]\n    C1 --\x3e C3[\u5408\u6210\u4ea4\u4e92\u6570\u636e/Synthesize Interaction Data]\n    C2 --\x3e C4[\u8fc7\u6ee4\u566a\u58f0\u6570\u636e/Filter Noisy Data]\n    C3 & C4 --\x3e C5[\u878d\u5408\u6570\u636e\u8bad\u7ec3I2I\u6a21\u578b/Fuse Data to Train I2I Model]\n    D --\x3e D1[\u63d0\u5347\u63a8\u8350\u51c6\u786e\u7387/Improves Recommendation Accuracy]\n    D --\x3e D2[\u63d0\u5347\u957f\u5c3e\u7269\u54c1\u6027\u80fd/Better for Long-tail Items]\n    D --\x3e D3[\u7ebf\u4e0a\u6307\u6807\u63d0\u5347/Online Metric Improvements (RN+6.02%, GMV+1.22%)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] KG20C & KG20C-QA: Scholarly Knowledge Graph Benchmarks for Link Prediction and Question Answering"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [db], [knowledge graph], [knowledge graph embedding, question answering, scholarly data, benchmark dataset, link prediction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hung-Nghiep Tran, Atsuhiro Takasu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Information Technology, Vietnam National University, Ho Chi Minh City; National Institute of Informatics, The Graduate University for Advanced Studies, SOKENDAI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21799",children:"https://arxiv.org/pdf/2512.21799"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/tranhungnghiep/KG20C/",children:"https://github.com/tranhungnghiep/KG20C/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides the first formal, peer-reviewed description and documentation of the KG20C scholarly knowledge graph, a high-quality benchmark constructed from the Microsoft Academic Graph. 2. Introduces KG20C-QA, a new benchmark dataset for question answering on scholarly data, built by converting KG20C triples into natural language question-answer pairs. 3. Establishes reproducible evaluation protocols, benchmarks standard knowledge graph embedding methods on KG20C-QA, and analyzes performance across different relation types."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6a0acbf8722d77d366a3d6b93104d40b8d9c7d53e5a9c94bd36138fd5ab3107_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6a0acbf8722d77d366a3d6b93104d40b8d9c7d53e5a9c94bd36138fd5ab3107_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper formally introduces KG20C and KG20C-QA, two curated benchmark datasets for scholarly knowledge graphs. KG20C is a cleaned and structured knowledge graph from academic metadata, while KG20C-QA provides a question-answering benchmark derived from it. The authors benchmark standard models on the new QA dataset and release the resources to support future research in scholarly data reasoning and QA."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["KG20C & KG20C-QA: \u5b66\u672f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6<br/>KG20C & KG20C-QA: Scholarly KG Benchmarks"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u7f3a\u4e4f\u5b66\u672f\u9886\u57df\u7684\u6807\u51c6\u5316\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6<br/>Lack of Standardized KG Benchmarks for Scholarly Domain"]\n    Method["\u4eceMAG\u6784\u5efa\u9ad8\u8d28\u91cf\u5b66\u672f\u77e5\u8bc6\u56fe\u8c31KG20C<br/>Construct High-Quality Scholarly KG KG20C from MAG"] --\x3e SubMethod1["\u5b9a\u4e49QA\u6a21\u677f\uff0c\u751f\u6210KG20C-QA\u6570\u636e\u96c6<br/>Define QA Templates to Create KG20C-QA Dataset"]\n    Results["\u53d1\u5e03\u6b63\u5f0f\u6587\u6863\u5316\u7684\u53ef\u91cd\u7528\u57fa\u51c6\u8d44\u6e90<br/>Release Formally Documented, Reusable Benchmark Resources"] --\x3e SubResult1["\u5728KG20C-QA\u4e0a\u8bc4\u4f30\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5<br/>Evaluate KG Embedding Methods on KG20C-QA"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Frozen LVLMs for Micro-Video Recommendation: A Systematic Study of Feature Extraction and Fusion"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [frozen large video language models, micro-video recommendation, feature fusion, intermediate hidden states, dual feature fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huatuan Sun, Yunshan Ma, Changguang Wu, Yanxin Zhang, Pengfei Wang, Xiaoyu Du"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University of Science and Technology, Singapore Management University, University of Wisconsin-Madison, GienTech Technology Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21863",children:"https://arxiv.org/pdf/2512.21863"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted the first systematic empirical study on integrating frozen LVLMs into micro-video recommendation, evaluating feature extraction paradigms (captions vs. hidden states) and integration strategies (replacement vs. fusion) with ID embeddings. 2. Derived three key principles: intermediate hidden states outperform captions, ID embeddings are irreplaceable (fusion > replacement), and the effectiveness of hidden states varies across layers. 3. Proposed the Dual Feature Fusion (DFF) Framework, a lightweight plug-and-play method that adaptively fuses multi-layer LVLM representations with ID embeddings, achieving state-of-the-art performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6963682bbae94363e4d55953d0681db3b9e674fbd82bcf7d3d2a179f4ea6f73e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6963682bbae94363e4d55953d0681db3b9e674fbd82bcf7d3d2a179f4ea6f73e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper systematically studies how to best integrate frozen Large Video-Language Models (LVLMs) as feature extractors for micro-video recommendation. It finds that using intermediate decoder hidden states and fusing them with item ID embeddings is superior to using generated captions or replacing IDs. Based on these insights, the authors propose the Dual Feature Fusion (DFF) framework, which achieves state-of-the-art results on benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Frozen LVLMs for Micro-Video Recommendation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("LVLM\u96c6\u6210\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30/Lack of systematic evaluation for LVLM integration")\n    Method --\x3e M1("\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76/Systematic empirical study")\n    Method --\x3e M2("\u63d0\u51faDFF\u6846\u67b6/Propose DFF Framework")\n    M1 --\x3e M1a("\u6bd4\u8f83\u7279\u5f81\u63d0\u53d6\u8303\u5f0f/Compare feature extraction paradigms")\n    M1 --\x3e M1b("\u6bd4\u8f83ID\u96c6\u6210\u7b56\u7565/Compare ID integration strategies")\n    M2 --\x3e M2a("\u81ea\u9002\u5e94\u878d\u5408\u591a\u5c42\u7279\u5f81/Adaptively fuse multi-layer features")\n    M2 --\x3e M2b("\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528/Lightweight plug-and-play")\n    Results --\x3e R1("\u4e2d\u95f4\u9690\u85cf\u6001\u4f18\u4e8e\u63cf\u8ff0/Intermediate hidden states > captions")\n    Results --\x3e R2("ID\u5d4c\u5165\u4e0d\u53ef\u66ff\u4ee3/Fusion > replacement")\n    Results --\x3e R3("DFF\u5b9e\u73b0SOTA\u6027\u80fd/DFF achieves SOTA performance")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] AutoPP: Towards Automated Product Poster Generation and Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image generation], [product poster generation, click-through rate optimization, isolated direct preference optimization, AutoPP1M dataset, unified design module]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiahao Fan, Yuxin Qin, Wei Feng, Yanyin Chen, Yaoyu Li, Ao Ma, Yixiu Li, Li Zhuang, Haoyi Bian, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," JD.COM"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21921",children:"https://arxiv.org/pdf/2512.21921"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/JD-GenX/AutoPP",children:"https://github.com/JD-GenX/AutoPP"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An automated pipeline (AutoPP) for end-to-end product poster generation and optimization, requiring only basic product information as input. 2. A novel optimization method that uses systematic element replacement and Isolated Direct Preference Optimization (IDPO) to attribute CTR gains to specific poster elements. 3. The creation and release of AutoPP1M, the largest dataset for product poster generation and optimization, containing one million posters and user feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f18700c508d46682b8040947d4af38f1b6c821d269a8518370be8bf9c574fe71_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f18700c508d46682b8040947d4af38f1b6c821d269a8518370be8bf9c574fe71_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces AutoPP, an automated pipeline that generates product posters from basic product information and then optimizes them for higher Click-Through Rate (CTR) using online feedback and a novel Isolated Direct Preference Optimization technique. It is supported by a large-scale dataset, AutoPP1M. Experiments show that AutoPP achieves state-of-the-art performance in both offline and online evaluations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AutoPP: Towards Automated Product Poster Generation and Optimization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4eba\u5de5\u5236\u4f5c\u4e0e\u4f18\u5316\u6d77\u62a5\u8017\u65f6\u8017\u529b/Manual poster creation and optimization is laborious]\n    C --\x3e C1[\u81ea\u52a8\u5316\u751f\u6210\u4e0e\u4f18\u5316\u7ba1\u9053/Automated generation and optimization pipeline]\n    C1 --\x3e C1_1[\u751f\u6210\u5668: \u7edf\u4e00\u8bbe\u8ba1\u6a21\u5757\u4e0e\u5143\u7d20\u6e32\u67d3/Generator: Unified design & element rendering]\n    C1 --\x3e C1_2[\u4f18\u5316\u5668: \u5143\u7d20\u66ff\u6362\u4e0eIDPO/Optimizer: Element replacement & IDPO]\n    C --\x3e C2[\u6570\u636e\u96c6: AutoPP1M/Dataset: AutoPP1M]\n    D --\x3e D1[\u79bb\u7ebf\u548c\u5728\u7ebfSOTA\u7ed3\u679c/Offline and online SOTA results]\n    D --\x3e D2[\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u516c\u5f00/Code & dataset released]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-30",children:"2025-12-30"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] IANEC: Digital Forensic Investigation of Contemporary Writers' Archives"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [sys], [digital forensics], [digital forensics, file fingerprinting, FUSE, OS virtualization, document classification]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Emmanuel Giguet"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Universit\xe9 Caen Normandie, ENSICAEN, CNRS, Normandie Univ, GREYC UMR 6072"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22167",children:"https://arxiv.org/pdf/2512.22167"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Development of a method to separate system/application files from user files using fingerprint databases for archival analysis, 2. Creation of tools for reading files on Mac partitions and virtualizing operating systems to emulate original computing environments, 3. Implementation of semantic analysis techniques for automatic text classification, image analysis, and detection of sensitive content (e.g., hate speech) in digital archives."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a4c37c326ec3830119685f14996db61a1f1efdecaefecd64e96244e26e9512b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a4c37c326ec3830119685f14996db61a1f1efdecaefecd64e96244e26e9512b_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The IANEC project develops digital forensic tools to automate the analysis of born-digital archives from contemporary writers. The proposed method combines technical file system analysis (e.g., fingerprinting, virtualization) with semantic document analysis (e.g., text/image classification). The main conclusion is that these tools are essential for the effective extraction, processing, and description of native digital archival corpora in cultural heritage institutions."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["IANEC: Digital Forensic Investigation of Contemporary Writers\' Archives"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: Born-digital archives are prevalent but difficult to analyze manually."]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Develop digital forensic tools for technical and semantic analysis of archives."]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: Automated tools are essential for processing and describing digital archival corpora."]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection], [hallucination detection, retrieval-augmented verification, contradiction graph, Paraphrased Hallucination Consistency Score (PHCS), materials science]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Bhanu Prakash Vangala, Sajid Mahmud, Pawan Neupane, Joel Selvaraj, Jianlin Cheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Missouri"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22396",children:"https://arxiv.org/pdf/2512.22396"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces HalluMatData, a benchmark dataset for evaluating hallucination detection in AI-generated materials science content. 2. Proposes HalluMatDetector, a multi-stage hallucination detection framework integrating intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment. 3. Introduces the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2d61ec50b266277e33c913c31df1946cc27990dbacfbd8d5b4979a627f3fa00_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2d61ec50b266277e33c913c31df1946cc27990dbacfbd8d5b4979a627f3fa00_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of factual hallucinations in LLM-generated materials science content. It proposes HalluMatDetector, a multi-stage verification framework that combines intrinsic checks, retrieval, and contradiction analysis to detect and mitigate errors. The method reduces hallucination rates by 30% compared to standard LLM outputs and introduces a new metric (PHCS) for evaluating response consistency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content"] --\x3e Problem["\u6838\u5fc3\u95ee\u9898/Problem: LLM Hallucinations in Scientific Content"]\n    Root --\x3e Method["\u4e3b\u8981\u65b9\u6cd5/Method: Multi-Stage Verification Framework (HalluMatDetector)"]\n    Root --\x3e Results["\u5173\u952e\u7ed3\u679c/Results: 30% Hallucination Reduction & New Metric (PHCS)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] OxygenREC: An Instruction-Following Generative Framework for E-commerce Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [Fast-Slow Thinking, Instruction-Guided Retrieval (IGR), Soft Adaptive Group Clip Policy Optimization (SA-GCPO)]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Xuegang Hao, Ming Zhang, Alex Li, Xiangyu Qian, Zhi Ma, Yanlong Zang, Shijie Yang, Zhongxuan Han, Xiaolong Ma, Jinguang Liu, Zhen Li, Zhida Jiang, Shusheng Wang, Ning Tang, Yanchen Qiao, Chenxiang Yang, Chen Sun, Jincheng Yuan, Chunhua Peng, Heng Hu, Peijun Yang, Baopeng Yuan, Caiyun Qiu, Zhaolong Xing, Haofei Yuan, Haipeng Zhang, Yuzhang Guo, Weijie Ding, Jiahua Gao, Hao Huang, Zhen Chen, Tongxuan Liu, Pinghua Gong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," JD.com"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22386",children:"https://arxiv.org/pdf/2512.22386"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces a Fast-Slow Thinking architecture for recommendation, using a near-line LLM for reasoning instruction synthesis and a high-efficiency encoder-decoder for real-time generation. 2. Proposes a semantic alignment mechanism with Instruction-Guided Retrieval (IGR) and Query-to-Item (Q2I) loss to ensure reasoning instructions effectively enhance recommendation generation. 3. Solves multi-scenario scalability by transforming scenario info into controllable instructions and using unified reward mapping with SA-GCPO, enabling a "train-once-deploy-everywhere" paradigm.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84cd56a9ce98d2f47d6f8e5216ecf9532042bab98fe47926131d2df6f68cded7_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84cd56a9ce98d2f47d6f8e5216ecf9532042bab98fe47926131d2df6f68cded7_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes OxygenREC, an industrial e-commerce recommendation system that addresses the limitations of existing generative methods in deep reasoning and multi-scenario scalability. It employs a Fast-Slow Thinking architecture, semantic alignment via instruction-guided retrieval, and a unified policy optimization method to achieve efficient, scalable, and reasoning-capable recommendations, leading to significant business metric improvements."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[OxygenREC: An Instruction-Following Generative Framework for E-commerce Recommendation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u4f20\u7edf\u63a8\u8350\u7cfb\u7edf\u95ee\u9898 / Traditional RS Issues]\n    B1 --\x3e B2[\u591a\u9636\u6bb5\u76ee\u6807\u4e0d\u4e00\u81f4 / Inconsistent Multi-stage Objectives]\n    B1 --\x3e B3[\u751f\u6210\u5f0f\u63a8\u8350\u7f3a\u4e4f\u6df1\u5ea6\u63a8\u7406 / GR Lacks Deep Reasoning]\n    B1 --\x3e B4[\u591a\u573a\u666f\u53ef\u6269\u5c55\u6027\u74f6\u9888 / Multi-scenario Scalability Bottleneck]\n    C --\x3e C1[\u5feb\u6162\u601d\u8003\u67b6\u6784 / Fast-Slow Thinking Architecture]\n    C1 --\x3e C2[\u6162\u601d\u8003: \u8fd1\u7ebfLLM\u751f\u6210\u63a8\u7406\u6307\u4ee4 / Slow: Near-line LLM for Reasoning Instructions]\n    C1 --\x3e C3[\u5feb\u601d\u8003: \u9ad8\u6548\u7f16\u89e3\u7801\u5668\u5b9e\u65f6\u751f\u6210 / Fast: Efficient Encoder-Decoder for Real-time Gen]\n    C --\x3e C4[\u8bed\u4e49\u5bf9\u9f50\u673a\u5236 / Semantic Alignment Mechanism]\n    C4 --\x3e C5[\u6307\u4ee4\u5f15\u5bfc\u68c0\u7d22(IGR) / Instruction-Guided Retrieval (IGR)]\n    C4 --\x3e C6[\u67e5\u8be2\u5230\u7269\u54c1(Q2I)\u635f\u5931 / Query-to-Item (Q2I) Loss]\n    C --\x3e C7[\u591a\u573a\u666f\u53ef\u6269\u5c55\u6027\u65b9\u6848 / Multi-scenario Scalability Solution]\n    C7 --\x3e C8[\u573a\u666f\u4fe1\u606f\u8f6c\u4e3a\u53ef\u63a7\u6307\u4ee4 / Transform Scenario Info to Controllable Instructions]\n    C7 --\x3e C9[\u7edf\u4e00\u5956\u52b1\u6620\u5c04\u4e0eSA-GCPO / Unified Reward Mapping & SA-GCPO]\n    D --\x3e D1[\u5b9e\u73b0"\u4e00\u6b21\u8bad\u7ec3\uff0c\u5904\u5904\u90e8\u7f72" / Achieves "Train-once-deploy-everywhere"]\n    D --\x3e D2[\u663e\u8457\u63d0\u5347GMV\u548c\u8ba2\u5355\u91cf / Significant GMV & Order Volume Increase]\n    D --\x3e D3[\u5c55\u793a\u8de8\u573a\u666f\u7684\u7075\u6d3b\u6027\u4e0e\u53ef\u6269\u5c55\u6027 / Demonstrates Flexibility & Scalability Across Scenarios]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Hallucination Detection and Evaluation of Large Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [hallucination detection], [HHEM, KnowHalu, segment-based retrieval, factual consistency, CDF analysis]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chenggong Zhang, Haopeng Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of California, Los Angeles"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22416",children:"https://arxiv.org/pdf/2512.22416"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Integrated the lightweight Hughes Hallucination Evaluation Model (HHEM) to significantly reduce computational cost and time for hallucination detection compared to multi-stage methods like KnowHalu. 2. Introduced a segment-based retrieval technique to improve the detection of localized hallucinations in summarization tasks, addressing a key limitation of HHEM. 3. Conducted a comparative CDF analysis revealing that larger LLMs (7B-9B parameters) exhibit fewer hallucinations, while intermediate-sized models show higher instability."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a208bbdfd47e46de589a2306cd9e02976448bce48e5e81a002adcb6f30ec224d_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a208bbdfd47e46de589a2306cd9e02976448bce48e5e81a002adcb6f30ec224d_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of efficiently detecting hallucinations in Large Language Models. It proposes integrating the lightweight HHEM framework and a segment-based retrieval method, which together reduce evaluation time dramatically while maintaining high accuracy. The study concludes that larger models are generally more reliable and highlights the need for efficient yet robust evaluation frameworks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Hallucination Detection and Evaluation of Large Language Model] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[LLM\u5e7b\u89c9\u635f\u5bb3\u53ef\u4fe1\u5ea6/LLM Hallucinations Undermine Trust]\n    C --\x3e C1[\u96c6\u6210\u8f7b\u91cf\u7ea7HHEM\u6846\u67b6/Integrate Lightweight HHEM Framework]\n    C --\x3e C2[\u5f15\u5165\u5206\u6bb5\u68c0\u7d22\u6280\u672f/Introduce Segment-based Retrieval]\n    D --\x3e D1[\u6548\u7387\u63d0\u5347: 8\u5c0f\u65f6->10\u5206\u949f/Efficiency Gain: 8hrs->10mins]\n    D --\x3e D2[\u6700\u9ad8\u51c6\u786e\u7387: 82.2%/Best Accuracy: 82.2%]\n    D --\x3e D3[\u5927\u6a21\u578b\u5e7b\u89c9\u66f4\u5c11/Larger Models Hallucinate Less]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [hierarchical filtering, two-pass generation, citation verification, query formulation, model cascade]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Cattalyya Nuengsigkapian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Google"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22442",children:"https://arxiv.org/pdf/2512.22442"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a hierarchical content filtering pipeline to replace standard vector similarity search, improving context precision. 2. Introduces a model cascade strategy using a cost-efficient model (Gemini 2.5 Flash) for filtering and a powerful model (Gemini 2.5 Pro) for final generation. 3. Demonstrates significant performance gains on the MMU-RAGent benchmark and a custom dataset for post-cutoff knowledge."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper presents HiFi-RAG, a system designed to improve open-domain RAG by addressing irrelevant retrieved information. The method uses a multi-stage pipeline with hierarchical filtering and a two-pass generation strategy employing different LLMs for efficiency and quality. The system won a NeurIPS 2025 competition and showed substantial improvements over baselines in evaluation metrics."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HiFi-RAG] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u5f00\u653e\u57dfRAG\u4e2d\u7684\u65e0\u5173\u4fe1\u606f\u4e0e\u610f\u56fe\u5bf9\u9f50/Open-domain RAG faces irrelevant info & intent misalignment]\n    C --\x3e C1[\u5206\u5c42\u8fc7\u6ee4\u4e0e\u4e24\u9636\u6bb5\u751f\u6210/Hierarchical Filtering & Two-Pass Generation]\n    C1 --\x3e C2[\u4f7f\u7528Gemini Flash\u8fdb\u884c\u8fc7\u6ee4/Use Gemini Flash for filtering]\n    C1 --\x3e C3[\u4f7f\u7528Gemini Pro\u8fdb\u884c\u751f\u6210/Use Gemini Pro for generation]\n    D --\x3e D1[\u5728MMU-RAGent\u4e0a\u8d85\u8d8a\u57fa\u7ebf/Outperforms baseline on MMU-RAGent]\n    D --\x3e D2[\u5728\u81ea\u5b9a\u4e49\u6d4b\u8bd5\u96c6\u4e0a\u663e\u8457\u63d0\u5347/Substantial gains on custom test set]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] A Real-Time System to Populate FRA Form 57 from News"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [information extraction], [vision language model, grouped question answering, form parsing, key information extraction, evaluation dataset]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chansong Lim, Haz Sameen Shahgir, Yue Dong, Jia Chen, Evangelos E. Papalexakis"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of California, Riverside"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22457",children:"https://arxiv.org/pdf/2512.22457"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. A pipeline that converts visually irregular and semantically dense forms (FRA Form 57) into a structured JSON schema using a vision language model with sample aggregation. 2. A grouped question answering approach that follows the form layout's intent to reduce ambiguity when extracting information from noisy news text. 3. The creation of an evaluation dataset by aligning scraped news articles with official FRA records and annotating retrievable information."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c8eb0e51c216144ca3ec858a84acec0a075178e373a291f789325439e91bcaa5_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c8eb0e51c216144ca3ec858a84acec0a075178e373a291f789325439e91bcaa5_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of providing timely situational awareness for railway incidents by automatically populating the official FRA Form 57 from news articles. The proposed method uses a vision language model to understand the complex form structure and a grouped question-answering technique to extract relevant information from noisy text. The system is evaluated on a newly created dataset and shows improved accuracy and coverage in information retrieval compared to alternatives."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[A Real-Time System to Populate FRA Form 57 from News] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u5b98\u65b9\u62a5\u544a\u5ef6\u8fdf/Official report latency]\n    B --\x3e B2[\u65b0\u95fb\u4fe1\u606f\u566a\u58f0/Noisy news information]\n    B --\x3e B3[\u8868\u683c\u7ed3\u6784\u590d\u6742/Complex form structure]\n    C --\x3e C1[VLM\u8868\u683c\u89e3\u6790/VLM form parsing]\n    C --\x3e C2[\u5206\u7ec4\u95ee\u7b54/Grouped QA]\n    C --\x3e C3[\u6784\u5efa\u8bc4\u4f30\u96c6/Build evaluation dataset]\n    D --\x3e D1[\u8bc4\u4f30\u7cfb\u7edf/System evaluation]\n    D --\x3e D2[\u4fe1\u606f\u68c0\u7d22\u51c6\u786e\u7387/IR accuracy]\n    D --\x3e D3[\u4fe1\u606f\u8986\u76d6\u5ea6/Information coverage]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] DICE: Discrete Interpretable Comparative Evaluation with Probabilistic Scoring for Retrieval-Augmented Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [probabilistic scoring, Swiss-system tournament, explainable evaluation, evidence-coupled framework, ranking fidelity]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shiyan Liu, Jian Ma, Rui Qu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Huazhong University of Science and Technology"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22629",children:"https://arxiv.org/pdf/2512.22629"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduces DICE, a two-stage, evidence-coupled framework for explainable and robust RAG evaluation using probabilistic {A, B, Tie} scoring. 2. Employs a Swiss-system tournament to reduce computational complexity from O(N\xb2) to O(N log N) for efficient multi-system comparisons. 3. Demonstrates high agreement (85.7%) with human experts on a Chinese financial QA dataset, outperforming existing LLM-based metrics like RAGAS."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6045a90fb152ced5737d976a17be84cd02b0a0396b4dd9cb385e9ba4d9063de6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6045a90fb152ced5737d976a17be84cd02b0a0396b4dd9cb385e9ba4d9063de6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the lack of interpretability and efficiency in evaluating Retrieval-Augmented Generation (RAG) systems. It proposes DICE, a framework that uses probabilistic scoring and a Swiss-system tournament to provide transparent, confidence-aware judgments while reducing computational cost. The method shows strong agreement with human experts, establishing it as an explainable and efficient paradigm for trustworthy RAG assessment."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[DICE: Discrete Interpretable Comparative Evaluation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u73b0\u6709\u6307\u6807\u95ee\u9898/Existing Metrics Issues]\n    P1 --\x3e P1_1[\u53ef\u89e3\u91ca\u6027\u6709\u9650/Limited Interpretability]\n    P1 --\x3e P1_2[\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0d\u8db3/Inadequate Uncertainty Quantification]\n    P1 --\x3e P1_3[\u8ba1\u7b97\u6548\u7387\u4f4e/Computational Inefficiency]\n\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u4e24\u9636\u6bb5\u8bc1\u636e\u8026\u5408\u6846\u67b6/Two-Stage Evidence-Coupled Framework]\n    M1 --\x3e M1_1[\u6982\u7387{A,B,Tie}\u8bc4\u5206/Probabilistic Scoring]\n    M1 --\x3e M1_2[\u53ef\u89e3\u91ca\u63a8\u7406\u75d5\u8ff9/Interpretable Reasoning Traces]\n    Method --\x3e M2[\u745e\u58eb\u5236\u9526\u6807\u8d5b/Swiss-System Tournament]\n    M2 --\x3e M2_1[\u964d\u4f4e\u590d\u6742\u5ea6/Reduces O(N\xb2) to O(N log N)]\n\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u6548\u7387\u63d0\u5347/Efficiency Gain]\n    R1 --\x3e R1_1[\u8ba1\u7b97\u91cf\u51cf\u5c1142.9%/42.9% Reduction]\n    Results --\x3e R2[\u8bc4\u4f30\u6709\u6548\u6027/Evaluation Validity]\n    R2 --\x3e R2_1[\u4e0e\u4e13\u5bb685.7%\u4e00\u81f4/85.7% Human Agreement]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [out-of-core, approximate nearest neighbor search, I/O orchestration, vector search, SSD]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chengying Huan, Lizheng Chen, Zhengyi Yang, Shaonan Ma, Rong Gu, Renjie Yao, Zhibin Wang, Mingxing Zhang, Fang Xi, Jie Tao, Gang Zhang, Guihai Chen, Chen Tian"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University, University of New South Wales, AISoft (QiyuanLab), Tsinghua University, China Mobile (Suzhou) Software Technology Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.22838",children:"https://arxiv.org/pdf/2512.22838"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. Introduces a heterogeneous local index selection per cluster via offline auto-profiling to match varying cluster scales. 2. Maintains a query-aware in-memory navigation graph that adapts to skewed query workloads for efficient routing. 3. Applies multi-level pruning with geometric bounds to filter clusters and vectors before issuing SSD reads, preventing "fetch-to-discard" overhead.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdb94f456d7410c515c5dcba047400662a1afb3a011cd9a57efd9526c5cc408_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdb94f456d7410c515c5dcba047400662a1afb3a011cd9a57efd9526c5cc408_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper presents OrchANN, a new out-of-core approximate nearest neighbor search engine designed for billion-scale vector search where data resides on SSD. It addresses performance degradation under skewed data distributions by unifying I/O governance through adaptive navigation and multi-level pruning. OrchANN significantly outperforms existing systems in queries per second and latency while reducing SSD accesses, without sacrificing accuracy."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("OrchANN: A Unified I/O Orchestration Framework for Skewed Out-of-Core Vector Search") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("\u5927\u89c4\u6a21ANNS\u662f\u5916\u5b58\u95ee\u9898/Large-scale ANNS is an out-of-core problem")\n    Problem --\x3e P2("\u73b0\u6709\u7cfb\u7edf\u5728\u503e\u659c\u6570\u636e\u4e0b\u5931\u6548/Existing systems break down under skewed data")\n    Method --\x3e M1("\u5f02\u6784\u672c\u5730\u7d22\u5f15/Heterogeneous local index per cluster")\n    Method --\x3e M2("\u67e5\u8be2\u611f\u77e5\u5bfc\u822a\u56fe/Query-aware in-memory navigation graph")\n    Method --\x3e M3("\u591a\u7ea7\u526a\u679d/Multi-level pruning with geometric bounds")\n    Results --\x3e R1("\u66f4\u9ad8\u7684QPS\u548c\u66f4\u4f4e\u5ef6\u8fdf/Higher QPS and lower latency")\n    Results --\x3e R2("\u51cf\u5c11SSD\u8bbf\u95ee/Reduced SSD accesses")\n    Results --\x3e R3("\u4fdd\u6301\u51c6\u786e\u6027/Maintains accuracy")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [adversarial robustness], [randomized smoothing, certified robustness, neural ranking models, adversarial attacks, retrieval-augmented generation]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiawei Liu, Zhuo Chen, Rui Zhu, Miaokun Chen, Yuyang Gong, Wei Lu, Xiaofeng Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Wuhan University, Yale University, Nanyang Technological University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23307",children:"https://arxiv.org/pdf/2512.23307"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RobustMask, a novel defense combining pretrained language models' context-prediction with a randomized masking-based smoothing mechanism to protect neural ranking models. 2. Provides a theoretical proof for RobustMask's certified top-K robustness against character-, word-, and phrase-level adversarial perturbations. 3. Demonstrates through extensive experiments that RobustMask can certify over 20% of candidate documents within the top-10 ranking against perturbations affecting up to 30% of content."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92efd69f112646f719a80cc74cecc9d34018b0607ad1f827ed960e54e754af07_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92efd69f112646f719a80cc74cecc9d34018b0607ad1f827ed960e54e754af07_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the vulnerability of neural ranking models to adversarial attacks that manipulate retrieval results. It proposes RobustMask, a defense method that uses randomized masking and smoothing to provide certified robustness. The results show it can effectively certify a significant portion of top-ranking documents against substantial content perturbations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Neural ranking models are vulnerable to adversarial manipulations that poison retrieval results.]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Combines PLM context-prediction with randomized masking-based smoothing.]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Certifies >20% of top-10 docs against perturbations affecting up to 30% content.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [medical image analysis], [Scalable Residual Feature Aggregation (SRFA), Hybrid Metaheuristic Optimization (HHO-BA), Vision Transformer (ViT) with EfficientNet-B3]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Janani Annur Thiruvengadam, Kiran Mayee Nabigaru, Anusha Kovi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Amazon.com Services LLC"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23597",children:"https://arxiv.org/pdf/2512.23597"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a Scalable Residual Feature Aggregation (SRFA) framework integrating MAGRes-UNet for segmentation and DenseNet-121 for hierarchical feature extraction. 2. Introduces a hybrid HHO-BA metaheuristic feature selection strategy to refine the optimal feature subset. 3. Develops a novel hybrid classifier combining Vision Transformer (ViT) and EfficientNet-B3, fine-tuned using a dual SSA-GWO optimization mechanism for robust classification."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/236616ac709d85c1958734582dc8a1182b385106ea696a4ffc79796016e70db9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/236616ac709d85c1958734582dc8a1182b385106ea696a4ffc79796016e70db9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of early pancreatic neoplasm detection in multimodal CT imaging by proposing a Scalable Residual Feature Aggregation (SRFA) framework. The method combines advanced segmentation, feature extraction with residual storage, hybrid metaheuristic feature selection, and a novel ViT-EfficientNet-B3 classifier optimized with SSA and GWO. The proposed system achieves high performance (96.23% accuracy), demonstrating significant improvement over traditional and contemporary models for robust early detection."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging] --\x3e B\n    A --\x3e C\n    A --\x3e D\n    B[\u6838\u5fc3\u95ee\u9898/Problem: \u80f0\u817a\u80bf\u7624\u65e9\u671f\u68c0\u6d4b\u56f0\u96be/Early pancreatic neoplasm detection is difficult due to subtle, low-contrast lesions and high patient variability in CT scans.]\n    C[\u4e3b\u8981\u65b9\u6cd5/Method: SRFA\u6846\u67b6\u6574\u5408MAGRes-UNet\u5206\u5272\u3001DenseNet-121\u7279\u5f81\u63d0\u53d6\u3001HHO-BA\u7279\u5f81\u9009\u62e9\u3001ViT-EfficientNet-B3\u6df7\u5408\u5206\u7c7b\u5668\uff0c\u5e76\u4f7f\u7528SSA-GWO\u4f18\u5316/SRFA framework integrates MAGRes-UNet segmentation, DenseNet-121 feature extraction, HHO-BA feature selection, ViT-EfficientNet-B3 hybrid classifier, optimized with SSA-GWO.]\n    D[\u5173\u952e\u7ed3\u679c/Results: \u6a21\u578b\u8fbe\u523096.23%\u51c6\u786e\u7387\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCNN\u548c\u5f53\u524d\u57fa\u4e8eTransformer\u7684\u6a21\u578b/Model achieves 96.23% accuracy, significantly outperforming traditional CNNs and contemporary transformer-based models.]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251230] Nested Browser-Use Learning for Agentic Information Seeking"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [information-seeking agents, browser interaction, ReAct-style agents, nested framework]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tongyi Lab, Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23647",children:"https://arxiv.org/pdf/2512.23647"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Alibaba-NLP/DeepResearch",children:"https://github.com/Alibaba-NLP/DeepResearch"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a minimal and complete browser-action framework for agents, 2. Introduces a nested structure to decouple interaction control from page exploration, 3. Demonstrates improved performance on deep information-seeking benchmarks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the limitation of current information-seeking agents, which rely on simple API calls and cannot perform real browsing. It proposes NestBrowse, a framework that uses a nested structure to enable fine-grained browser control for agents, simplifying reasoning and improving performance on deep search tasks."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Nested Browser-Use Learning for Agentic Information Seeking<br>\u9762\u5411\u667a\u80fd\u4fe1\u606f\u641c\u7d22\u7684\u5d4c\u5957\u6d4f\u89c8\u5668\u4f7f\u7528\u5b66\u4e60"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br>Agents lack real browsing, limited to APIs."]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br>NestBrowse: nested browser-action framework."]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br>Better performance on deep IS benchmarks."]'}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"2026-01-01",children:"2026-01-01"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Deletion Considered Harmful"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [Personal Information Management], [deletion, filing, retrieval success, user behaviour, knowledge workers]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Paul Englefield, Russell Beale"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Birmingham"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23907",children:"https://arxiv.org/pdf/2512.23907"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An empirical study revealing that deletion is consistently under-adopted compared to other Personal Information Management (PIM) tactics like Filing, Coverage, Ontology, and Timeliness. 2. Statistical evidence demonstrating that the practice of deletion is detrimental to retrieval success and user satisfaction, challenging the intuitive belief that decluttering is beneficial. 3. A detailed analysis and clustering of user behaviors that provides insights into the relationship between deletion and other information management strategies."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/344b922727ad08c44db409e5d258a91eb23a5dd268f6314fc4a64df943271db6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/344b922727ad08c44db409e5d258a91eb23a5dd268f6314fc4a64df943271db6_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper investigates the effectiveness of deletion as a Personal Information Management (PIM) tactic through a study of 51 knowledge workers using questionnaires and interviews. The study finds that deletion is less commonly used than other tactics and, contrary to common belief, empirical data shows it harms retrieval success and satisfaction. The authors conclude that deletion has adverse effects on information management outcomes."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Deletion Considered Harmful] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Is deletion helpful for managing information overload?]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Study of 51 knowledge workers via questionnaires & interviews]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Deletion is under-adopted and detrimental to retrieval]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [agentic AI, recommendation system, KYC (Know Your Customer), nDCG, multi-stage architecture]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junjie H. Xu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Hechu Tech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.23961",children:"https://arxiv.org/pdf/2512.23961"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel agentic AI-based recommendation system specifically designed for integrating KYC (Know Your Customer) processes. 2. Conducts a comparative performance evaluation across five distinct content verticals (Ad, News, Gossip, Sharing, Tech) using the nDCG metric. 3. Synthesizes experimental data with industry benchmarks to provide engineering insights for building large-scale agentic recommendation systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e7c4d7572522a69f7c0db05b6553014273403aa44576ea9c0de823750c5368_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e7c4d7572522a69f7c0db05b6553014273403aa44576ea9c0de823750c5368_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a new recommendation system that uses agentic AI to incorporate KYC (Know Your Customer) information. It evaluates the system's performance across five different content types and compares it against standard benchmarks. The study concludes by providing practical insights for engineering large-scale agentic recommendation systems based on the experimental results."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[An Comparative Analysis about KYC on a Recommendation System Toward Agentic Recommendation System] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Transition from passive ranking to agentic AI in RecSys]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Agentic AI for KYC, evaluated across 5 content verticals using nDCG@k]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Performance comparison of 4 KYC usage groups, insights for large-scale engineering]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] High-dimensional Regret Minimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [db], [interactive query processing], [regret minimization, high-dimensional data, interactive query, skyline query, top-k query]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Junyu Liao, Ashwin Lall, Mitsunori Ogihara, Raymond Wong"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," The Hong Kong University of Science and Technology, Denison University, University of Miami"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24078",children:"https://arxiv.org/pdf/2512.24078"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed FHDR (Fast High-Dimensional Reduction), a novel framework for scalable interactive regret minimization. 2. Achieved significant efficiency, requiring less than 0.01s and fewer than 30 rounds of user interaction. 3. Demonstrated performance improvements of at least an order of magnitude in execution time and several orders of magnitude in interaction rounds compared to prior work."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc5adec19be3a80d0a53d2ec741bc611e59f7e2c74dd78fd4952eec991a81e0e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc5adec19be3a80d0a53d2ec741bc611e59f7e2c74dd78fd4952eec991a81e0e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the scalability challenge of interactive regret minimization queries in high-dimensional databases, where existing methods are too slow or require excessive user feedback. The authors propose the FHDR framework, which drastically reduces both computation time and the number of required user interactions. Experiments show FHDR establishes a new state-of-the-art, outperforming previous algorithms by orders of magnitude."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[High-dimensional Regret Minimization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u73b0\u6709\u4ea4\u4e92\u5f0f\u7b97\u6cd5\u65e0\u6cd5\u6269\u5c55\u5230\u9ad8\u7ef4\u6570\u636e\u96c6 / Existing interactive algorithms fail to scale to high-dimensional datasets]\n    B --\x3e B2[\u7528\u6237\u4ea4\u4e92\u8f6e\u6570\u8fc7\u591a\uff08\u5e38\u8d851000\u8f6e\uff09/ Excessive user interactions (often >1000 rounds)]\n    C --\x3e C1[\u63d0\u51faFHDR\u6846\u67b6 / Propose FHDR (Fast High-Dimensional Reduction) framework]\n    D --\x3e D1[\u4ea4\u4e92\u8f6e\u6570\u5c11\u4e8e30\u8f6e / Fewer than 30 rounds of interaction]\n    D --\x3e D2[\u5904\u7406\u65f6\u95f4\u5c0f\u4e8e0.01\u79d2 / Takes less than 0.01s]\n    D --\x3e D3[\u6027\u80fd\u63d0\u5347\u6570\u4e2a\u6570\u91cf\u7ea7 / Outperforms prior work by orders of magnitude]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] CogRec: A Cognitive Recommender Agent Fusing Large Language Models and Soar for Explainable Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [cognitive architecture, Soar, large language models, explainable recommendation, online learning]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiaxin Hu, Tao Wang, Bingsan Yang, Hongrun Wang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sun Yat-Sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24113",children:"https://arxiv.org/pdf/2512.24113"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes CogRec, a novel cognitive recommender agent that synergizes the strengths of Large Language Models (LLMs) and the Soar cognitive architecture. 2. Introduces a learning paradigm where Soar's symbolic reasoning is initialized and dynamically augmented by an LLM via chunking, enabling robust online learning. 3. Demonstrates that the agent provides highly interpretable rationales and shows advantages in accuracy, explainability, and addressing the long-tail problem on public datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6840c5950eff3f651f3ba24036f583190638dc59f4b4c5d9c32d2ca2079cb860_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6840c5950eff3f651f3ba24036f583190638dc59f4b4c5d9c32d2ca2079cb860_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes CogRec, a cognitive recommender agent that fuses Large Language Models (LLMs) with the Soar cognitive architecture to address the black-box nature and limited online learning of LLMs. The agent uses Soar for structured reasoning and dynamically queries an LLM to generate new symbolic rules when needed, enabling continuous knowledge evolution. Evaluations show CogRec improves recommendation accuracy, explainability, and performance on long-tail items."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[CogRec: A Cognitive Recommender Agent] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLMs: \u9ed1\u76d2, \u5e7b\u89c9, \u96be\u5728\u7ebf\u5b66\u4e60/LLMs: Black-Box, Hallucination, Limited Online Learning]\n    B --\x3e B2[\u8ba4\u77e5\u67b6\u6784: \u77e5\u8bc6\u83b7\u53d6\u56f0\u96be/Cognitive Architectures: Laborious Knowledge Acquisition]\n    C --\x3e C1[\u878d\u5408LLM\u4e0eSoar/Fuse LLM and Soar]\n    C --\x3e C2[\u611f\u77e5-\u8ba4\u77e5-\u884c\u52a8\u5faa\u73af/PCA Cycle]\n    C --\x3e C3[LLM\u521d\u59cb\u5316\u4e0e\u52a8\u6001\u67e5\u8be2/LLM for Initialization & Dynamic Query]\n    C --\x3e C4[Soar\u7ec4\u5757\u5316\u5728\u7ebf\u5b66\u4e60/Soar Chunking for Online Learning]\n    D --\x3e D1[\u63d0\u5347\u63a8\u8350\u51c6\u786e\u6027/Improved Recommendation Accuracy]\n    D --\x3e D2[\u589e\u5f3a\u53ef\u89e3\u91ca\u6027/Enhanced Explainability]\n    D --\x3e D3[\u6709\u6548\u5904\u7406\u957f\u5c3e\u95ee\u9898/Effective Long-Tail Handling]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] Time-Aware Adaptive Side Information Fusion for Sequential Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [sequential recommendation], [side information fusion, temporal dynamics, adaptive filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jie Luo, Wenyu Zhang, Xinming Zhang, Yuan Fang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China, Singapore Management University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24246",children:"https://arxiv.org/pdf/2512.24246"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/jluo00/TASIF",children:"https://github.com/jluo00/TASIF"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"}),' 1. A plug-and-play time span partitioning mechanism to capture global temporal patterns. 2. An adaptive frequency filter that uses a learnable gate to denoise feature sequences. 3. An efficient adaptive side information fusion layer with a "guide-not-mix" architecture for deep interaction without mixing attributes into item embeddings.']}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a11c0b345833a0a377b18e0217b0b567071b00be6a8e2b525f74cb65d753c493_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a11c0b345833a0a377b18e0217b0b567071b00be6a8e2b525f74cb65d753c493_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes the TASIF framework to address challenges in sequential recommendation, including overlooking temporal dynamics, vulnerability to noise, and high computational cost. It introduces three components: time span partitioning, an adaptive frequency filter, and an efficient fusion layer. Experiments show TASIF outperforms state-of-the-art baselines while maintaining training efficiency."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\nA[Time-Aware Adaptive Side Information Fusion for Sequential Recommendation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\nB --\x3e B1[\u5ffd\u7565\u7ec6\u7c92\u5ea6\u65f6\u95f4\u52a8\u6001/Ignore fine-grained temporal dynamics]\nB --\x3e B2[\u5e8f\u5217\u566a\u58f0\u654f\u611f/Vulnerable to sequence noise]\nB --\x3e B3[\u878d\u5408\u67b6\u6784\u8ba1\u7b97\u6602\u8d35/Computationally expensive fusion]\nC --\x3e C1[\u65f6\u95f4\u8de8\u5ea6\u5212\u5206/Time span partitioning]\nC --\x3e C2[\u81ea\u9002\u5e94\u9891\u7387\u6ee4\u6ce2/Adaptive frequency filter]\nC --\x3e C3[\u9ad8\u6548\u81ea\u9002\u5e94\u878d\u5408/Efficient adaptive fusion layer]\nD --\x3e D1[\u6027\u80fd\u663e\u8457\u63d0\u5347/Significantly outperforms baselines]\nD --\x3e D2[\u8bad\u7ec3\u6548\u7387\u9ad8/Maintains training efficiency]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [corpus poisoning, dense retriever, retrieval-stage defense, document partitioning, token masking]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Pankayaraj Pathmanathan, Michael-Andrei Panaitescu-Liess, Cho-Yu Jason Chiang, Furong Huang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Maryland College Park, Capital One, Peraton Labs"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24268",children:"https://arxiv.org/pdf/2512.24268"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed RAGPart, a defense leveraging the training dynamics of dense retrievers and document partitioning to mitigate poisoned documents. 2. Proposed RAGMask, a defense that identifies suspicious tokens by analyzing similarity shifts under targeted token masking. 3. Introduced an interpretable attack to stress-test the proposed defenses and evaluated them across multiple benchmarks, poisoning strategies, and retrievers."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eed99fde057eefd1431417b1d512eaa39807473cb3d4135031a0e9dae115d7a8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eed99fde057eefd1431417b1d512eaa39807473cb3d4135031a0e9dae115d7a8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the vulnerability of Retrieval-Augmented Generation (RAG) systems to corpus poisoning attacks, where adversaries inject malicious documents to manipulate outputs. It proposes two lightweight, retrieval-stage defenses, RAGPart and RAGMask, which operate directly on the retriever without modifying the generation model. The defenses were shown to consistently reduce attack success rates while maintaining utility under benign conditions, highlighting the potential of retrieval-stage approaches for robust RAG."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RAGPart & RAGMask: Retrieval-Stage Defenses Against Corpus Poisoning] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: RAG\u7cfb\u7edf\u6613\u53d7\u8bed\u6599\u5e93\u6295\u6bd2\u653b\u51fb/RAG vulnerable to corpus poisoning attacks]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u4e24\u79cd\u68c0\u7d22\u9636\u6bb5\u9632\u5fa1/Propose two retrieval-stage defenses]\n    C --\x3e D[RAGPart: \u5229\u7528\u7a20\u5bc6\u68c0\u7d22\u5668\u8bad\u7ec3\u52a8\u6001\u4e0e\u6587\u6863\u5206\u533a/Leverages dense retriever training dynamics & document partitioning]\n    C --\x3e E[RAGMask: \u57fa\u4e8e\u76ee\u6807\u4ee4\u724c\u63a9\u7801\u7684\u76f8\u4f3c\u6027\u504f\u79fb\u8bc6\u522b\u53ef\u7591\u4ee4\u724c/Identifies suspicious tokens via similarity shifts under targeted token masking]\n    A --\x3e F[\u5173\u952e\u7ed3\u679c/Results: \u5728\u591a\u79cd\u8bbe\u7f6e\u4e0b\u6301\u7eed\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4fdd\u6301\u826f\u6027\u6548\u7528/Consistently reduces attack success rates across settings, preserves benign utility]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MaRCA: Multi-Agent Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Multi-Agent Reinforcement Learning, Centralized Training with Decentralized Execution (CTDE), Model Predictive Control (MPC), Dynamic Computation Allocation, Recommender Systems]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Wan Jiang, Xinyi Zang, Yudong Zhao, Yusi Zou, Yunfei Lu, Junbo Tong, Yang Liu, Ming Li, Jiani Shi, Xin Yang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," JD.com, Tsinghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24325",children:"https://arxiv.org/pdf/2512.24325"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MaRCA, a multi-agent reinforcement learning framework that models recommender system stages as cooperative agents for end-to-end computation resource allocation. 2. Introduces an AutoBucket TestBench for accurate computation cost estimation in large-scale systems. 3. Designs a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5648d9986b292c2db26fc1ddb4325c3fc0f14c6516ddecf792ceaf524e365c4_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenge of dynamic computation allocation in large-scale, multi-stage recommender systems under resource constraints. It proposes MaRCA, a multi-agent reinforcement learning framework that uses Centralized Training with Decentralized Execution (CTDE) and integrates a Model Predictive Control-based balancer to optimize revenue. The system was deployed on a major e-commerce platform, handling hundreds of billions of daily requests and achieving a 16.67% revenue uplift using existing resources."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MaRCA: Multi-Agent RL for Dynamic Computation Allocation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u5927\u89c4\u6a21\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6d41\u91cf\u89c4\u6a21\u589e\u957f\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u9636\u6bb5\u95f4\u4f9d\u8d56\uff0c\u9650\u5236\u5168\u5c40\u6700\u4f18\u6027\u3002]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51faMaRCA\u6846\u67b6\uff0c\u5c06\u63a8\u8350\u7cfb\u7edf\u9636\u6bb5\u5efa\u6a21\u4e3a\u5408\u4f5c\u667a\u80fd\u4f53\uff0c\u4f7f\u7528CTDE\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5f15\u5165AutoBucket TestBench\u548c\u57fa\u4e8eMPC\u7684\u6536\u76ca-\u6210\u672c\u5e73\u8861\u5668\u3002]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u9886\u5148\u7684\u5168\u7403\u7535\u5546\u5e73\u53f0\u5e7f\u544a\u7ba1\u7ebf\u4e2d\u7aef\u5230\u7aef\u90e8\u7f72\uff0c\u6bcf\u65e5\u5904\u7406\u6570\u5343\u4ebf\u5e7f\u544a\u8bf7\u6c42\uff0c\u4f7f\u7528\u73b0\u6709\u8ba1\u7b97\u8d44\u6e90\u5b9e\u73b016.67%\u7684\u6536\u76ca\u63d0\u5347\u3002]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] On the Factual Consistency of Text-based Explainable Recommendation Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [explainable recommendation], [factual consistency, large language models, natural language inference, statement-level evaluation, explainable recommendation models]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Ben Kabongo, Vincent Guigue"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sorbonne University, CNRS, ISIR, AgroParisTech"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24366",children:"https://arxiv.org/pdf/2512.24366"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/BenKabongo25/factual_explainable_recommendation",children:"https://github.com/BenKabongo25/factual_explainable_recommendation"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Introduced a comprehensive framework for evaluating the factual consistency of text-based explainable recommendation models. 2. Proposed a prompting-based pipeline using LLMs to extract atomic explanatory statements from reviews to construct a factual ground truth benchmark. 3. Designed statement-level alignment metrics combining LLM- and NLI-based approaches to assess factual consistency and relevance of generated explanations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9c76b5ee4016c79058d120bfc7c050ef62a7ce8fc6f0623fe422173e38e2f33_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9c76b5ee4016c79058d120bfc7c050ef62a7ce8fc6f0623fe422173e38e2f33_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of factual inconsistency in text-based explainable recommendation models. The authors propose a new evaluation framework that uses LLMs to extract factual statements from reviews as ground truth and combines LLM- and NLI-based metrics to assess explanation quality. Their experiments on six state-of-the-art models reveal a critical gap where models achieve high semantic similarity but alarmingly low factual consistency, highlighting the need for factuality-aware evaluation."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    A[On the Factual Consistency of Text-based Explainable Recommendation Models] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1["\u89e3\u91ca\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u662f\u5426\u53ef\u9760?<br/>Are explanations factually consistent?"]\n    C --\x3e C1["LLM\u63d0\u793a\u7ba1\u9053\u6784\u5efa\u4e8b\u5b9e\u57fa\u51c6<br/>LLM-prompting pipeline for factual ground truth"]\n    C --\x3e C2["\u8bed\u53e5\u7ea7\u5bf9\u9f50\u8bc4\u4f30\u6307\u6807<br/>Statement-level alignment metrics (LLM+NLI)"]\n    D --\x3e D1["\u9ad8\u8bed\u4e49\u76f8\u4f3c\u6027<br/>High semantic similarity (BERTScore F1: 0.81-0.90)"]\n    D --\x3e D2["\u4f4e\u4e8b\u5b9e\u4e00\u81f4\u6027<br/>Low factual consistency (Precision: 4.38%-32.88%)"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [nlp], [coreference resolution], [incremental clustering, dual-threshold constraint, memory-efficient, lightweight transformer, cache management]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kangyang Luo, Shuzheng Si, Yuzhuo Bai, Cheng Gao, Zhitong Wang, Cheng Huang, Yingli Shen, Yufeng Han, Wenhao Li, Cunliang Kong, Maosong Sun"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tsinghua University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24711",children:"https://arxiv.org/pdf/2512.24711"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MEIC-DT, a novel dual-threshold, memory-efficient incremental clustering approach for long-text coreference resolution. 2. Introduces a Statistics-Aware Eviction Strategy (SAES) for intelligent cache management within a predefined memory budget. 3. Presents an Internal Regularization Policy (IRP) to strategically condense clusters by selecting the most representative mentions, preserving semantic integrity."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34337ad38d20be1dae6a4c4cc881ccab3fb447fa75e8bee3e7a838015b008cbb_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34337ad38d20be1dae6a4c4cc881ccab3fb447fa75e8bee3e7a838015b008cbb_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of balancing efficiency and performance in incremental clustering for long-text coreference resolution. It proposes MEIC-DT, a memory-efficient method featuring a dual-threshold constraint mechanism, a statistics-aware eviction strategy, and an internal regularization policy. Experiments show MEIC-DT achieves competitive performance under strict memory constraints."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Balancing efficiency and performance in incremental clustering for long texts]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Dual-threshold constraint, Statistics-Aware Eviction Strategy (SAES), Internal Regularization Policy (IRP)]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Achieves highly competitive coreference performance under stringent memory constraints]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [federated learning], [federated recommendation, item cold-start, diffusion model, modality-guided generation, privacy guarantee]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Kang Fu, Honglei Zhang, Xuechao Zou, Yidong Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Beijing Jiaotong University, Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, China"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24715",children:"https://arxiv.org/pdf/2512.24715"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes MDiffFR, a novel generation-based modality-guided diffusion method for generating embeddings for cold-start items in Federated Recommendations, moving beyond the fixed attribute-to-embedding mapping paradigm. 2. Introduces the use of a pre-trained modality encoder to extract features as conditional signals to guide the reverse denoising process of the diffusion model, aligning item semantics. 3. Provides theoretical analysis demonstrating that the proposed method offers stronger privacy guarantees compared to existing mapping-based approaches."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0043abb7859816bbc8cd02d819ea36ea1dcb659896ddccf82fe3a147387a46e8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0043abb7859816bbc8cd02d819ea36ea1dcb659896ddccf82fe3a147387a46e8_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the challenging item cold-start problem in Federated Recommendation (FR) by proposing MDiffFR, a method that uses a modality-guided diffusion model on the server to generate item embeddings. The generated embeddings are distributed to clients for inference, leveraging modality features to guide the generation process and improve alignment. Experiments on four real datasets show that MDiffFR outperforms existing baselines and provides stronger privacy guarantees."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c/Results)\n    B --\x3e B1[\u8054\u90a6\u63a8\u8350\u4e2d\u7684\u9879\u76ee\u51b7\u542f\u52a8\u95ee\u9898 / Item Cold-Start in Federated Recommendation]\n    B --\x3e B2[\u4e25\u683c\u9690\u79c1\u9650\u5236\u5bfc\u81f4\u8868\u793a\u5b66\u4e60\u56f0\u96be / Strict Privacy Constraints Hinder Representation Learning]\n    C --\x3e C1[\u670d\u52a1\u5668\u7aef\u4f7f\u7528\u5b9a\u5236\u6269\u6563\u6a21\u578b\u751f\u6210\u5d4c\u5165 / Use Tailored Diffusion Model on Server to Generate Embeddings]\n    C --\x3e C2[\u9884\u8bad\u7ec3\u6a21\u6001\u7f16\u7801\u5668\u63d0\u4f9b\u6761\u4ef6\u4fe1\u53f7 / Pre-trained Modality Encoder Provides Conditional Signals]\n    D --\x3e D1[\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u57fa\u7ebf / Outperforms Baselines on Four Real Datasets]\n    D --\x3e D2[\u63d0\u4f9b\u66f4\u5f3a\u7684\u9690\u79c1\u4fdd\u8bc1 / Provides Stronger Privacy Guarantees]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] OpenOneRec Technical Report"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm training], [generative recommendation, foundation model, co-pretraining, RecIF-Bench, catastrophic forgetting]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Guorui Zhou, Honghui Bao, Jiaming Huang, Jiaxin Deng, Jinghao Zhang, Junda She, Kuo Cai, Lejian Ren, Lu Ren, Qiang Luo, Qianqian Wang, Qigen Hu, Rongzhou Zhang, Ruiming Tang, Shiyao Wang, Wuchao Li, Xiangyu Wu, Xinchen Luo, Xingmei Wang, Yifei Hu, Yunfan Wu, Zhanyu Liu, Zhiyang Zhang, Zixing Zhang, Bo Chen, Bin Wen, Chaoyi Ma, Chengru Song, Chenglong Chu, Defu Lian, Fan Yang, Feng Jiang, Hongtao Cheng, Huanjie Wang, Kun Gai, Pengfei Zheng, Qiang Wang, Rui Huang, Siyang Mao, Tingting Gao, Wei Yuan, Yan Wang, Yang Zhou, Yi Su, Zexuan Cheng, Zhixin Ling, Ziming Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Kuaishou"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24762",children:"https://arxiv.org/pdf/2512.24762"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/Kuaishou-OneRec/OpenOneRec",children:"https://github.com/Kuaishou-OneRec/OpenOneRec"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1) Proposed RecIF-Bench, a holistic benchmark with 8 tasks for evaluating integrated recommendation capabilities, and released a large open training dataset. 2) Open-sourced a comprehensive training pipeline (data processing, co-pretraining, post-training) to ensure reproducibility and demonstrated predictable scaling of recommendation capabilities while mitigating catastrophic forgetting. 3) Released the OneRec-Foundation model family (1.7B and 8B), achieving new SOTA on RecIF-Bench and showing strong cross-domain transferability with a 26.8% average improvement on the Amazon benchmark."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/479a2e2d3cfe6c5155f120df18d59b7783da83d3d0ced554b30ba633be6d5b8c_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/479a2e2d3cfe6c5155f120df18d59b7783da83d3d0ced554b30ba633be6d5b8c_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the gap between current generative recommendation models and general intelligence by introducing an open foundation model and benchmark. The proposed method involves co-pretraining and post-training a large model on a massive dataset, resulting in the OneRec-Foundation models which achieve state-of-the-art performance on recommendation tasks while retaining general knowledge, demonstrating a step towards more intelligent recommender systems."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[OpenOneRec Technical Report] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u63a8\u8350\u7cfb\u7edf\u4e0e\u901a\u7528\u667a\u80fd\u5b58\u5728\u5dee\u8ddd/Gap between RecSys and General Intelligence]\n    B --\x3e B2[\u7f3a\u4e4f\u7efc\u5408\u8bc4\u4f30\u57fa\u51c6/Lack of Holistic Benchmark]\n    C --\x3e C1[\u63d0\u51faRecIF-Bench\u4e0e\u5f00\u6e90\u6570\u636e/Propose RecIF-Bench & Open Data]\n    C --\x3e C2[\u5f00\u6e90\u5b8c\u6574\u8bad\u7ec3\u6846\u67b6/Open-source Full Training Pipeline]\n    C --\x3e C3[\u53d1\u5e03OneRec-Foundation\u6a21\u578b/Release OneRec-Foundation Models]\n    D --\x3e D1[\u5728RecIF-Bench\u4e0a\u5b9e\u73b0SOTA/Achieve SOTA on RecIF-Bench]\n    D --\x3e D2[\u5728Amazon\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u5347/Substantial Improvement on Amazon Benchmark]\n    D --\x3e D3[\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8/Mitigate Catastrophic Forgetting]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] HiGR: Efficient Generative Slate Recommendation via Hierarchical Planning and Multi-Objective Preference Alignment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [slate recommendation, generative recommendation, residual quantization, hierarchical planning, listwise preference alignment]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yunsheng Pang, Zijian Liu, Yudong Li, Shaojie Zhu, Zijian Luo, Chenyun Yu, Sikai Wu, Shichen Shen, Cong Xu, Bin Wang, Kai Jiang, Hongyong Yu, Chengxiang Zhuo, Zang Li"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Tencent, Sun Yat-sen University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24787",children:"https://arxiv.org/pdf/2512.24787"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposed an auto-encoder with residual quantization and contrastive constraints for semantically structured item tokenization. 2. Introduced a hierarchical generation framework that decouples list-level planning from item-level decoding for efficient slate generation. 3. Designed a listwise preference alignment objective to directly optimize slate quality using implicit user feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df7bb0829f12a7ec59faf3d297069dfbce2bbcb60223c10f7e7a4162d6e7a4e0_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df7bb0829f12a7ec59faf3d297069dfbce2bbcb60223c10f7e7a4162d6e7a4e0_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes HiGR, an efficient generative framework for slate recommendation. It addresses the limitations of existing autoregressive methods by using hierarchical planning and a listwise alignment objective. Experiments on a commercial platform show HiGR significantly outperforms state-of-the-art methods in both offline quality and online metrics while being 5x faster at inference."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[HiGR: Efficient Generative Slate Recommendation] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u73b0\u6709\u81ea\u56de\u5f52\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u7ea0\u7f20\u548c\u4f4e\u6548\u89e3\u7801]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5206\u5c42\u89c4\u5212\u4e0e\u5217\u8868\u504f\u597d\u5bf9\u9f50]\n    C --\x3e D[\u8bed\u4e49\u7ed3\u6784\u5316ID / Semantically Structured IDs]\n    C --\x3e E[\u5206\u5c42\u751f\u6210 / Hierarchical Generation]\n    C --\x3e F[\u5217\u8868\u504f\u597d\u5bf9\u9f50 / Listwise Preference Alignment]\n    A --\x3e G[\u5173\u952e\u7ed3\u679c/Results: \u79bb\u7ebf\u8d28\u91cf\u63d0\u5347>10%, \u63a8\u7406\u52a0\u901f5\u500d, \u5728\u7ebf\u6307\u6807\u663e\u8457\u589e\u957f]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv260101] RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [information retrieval], [relevance assessment, benchmark, long-tail, visual salience, e-commerce]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chenji Lu, Zhuo Chen, Hui Zhao, Zhenyi Wang, Pengjie Wang, Jian Xu, Bo Zheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Taobao & Tmall Group of Alibaba"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.24943",children:"https://arxiv.org/pdf/2512.24943"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes RAIR, a comprehensive Chinese benchmark for e-commerce relevance assessment derived from real-world scenarios. 2. Establishes a standardized evaluation framework with universal rules to address the lack of standardized metrics. 3. Introduces a dataset with three specialized subsets (general, long-tail hard, visual salience) to evaluate fundamental, challenging, and multimodal capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes RAIR, a rule-aware benchmark for e-commerce search relevance assessment, to address the lack of complex and standardized evaluation datasets. It introduces a comprehensive dataset with three subsets to test different model capabilities. Experiments on 14 models show RAIR is challenging, with GPT-5 performing best, and it serves as a new industry benchmark."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[RAIR: \u4e00\u4e2a\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u76f8\u5173\u6027\u8bc4\u4f30\u7684\u89c4\u5219\u611f\u77e5\u57fa\u51c6 / RAIR: A Rule-Aware Benchmark for E-commerce Relevance Assessment]\n    A --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: \u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u590d\u6742\u6027\uff0c\u7f3a\u5c11\u6807\u51c6\u5316\u8bc4\u4f30 / Existing benchmarks lack complexity and standardized evaluation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u63d0\u51fa\u5305\u542b\u901a\u7528\u3001\u957f\u5c3e\u3001\u89c6\u89c9\u663e\u8457\u6027\u5b50\u96c6\u7684\u57fa\u51c6\u548c\u89c4\u5219\u6846\u67b6 / Propose benchmark with general, long-tail, visual-salience subsets and rule framework]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5bf914\u4e2a\u6a21\u578b\u6784\u6210\u6311\u6218\uff0cGPT-5\u8868\u73b0\u6700\u4f73\uff0c\u53ef\u4f5c\u4e3a\u884c\u4e1a\u57fa\u51c6 / Presents challenge to 14 models, GPT-5 performs best, serves as industry benchmark]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsxs)(n.strong,{children:["[arXiv260101] AdaGReS",":Adaptive"," Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG"]})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [rag (retrieval-augmented generation)], [redundancy-aware selection, token-budgeted RAG, greedy selection, submodular optimization, adaptive calibration]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Chao Peng, Bin Wang, Zhilei Long, Jinfang Sheng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Central South University, Yizhi Intelligent (YZInt)"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.25052",children:"https://arxiv.org/pdf/2512.25052"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AdaGReS, a redundancy-aware context selection framework that optimizes a set-level objective combining query relevance and intra-set redundancy penalties under a token-budget constraint. 2. Introduces a closed-form, instance-adaptive calibration method for the relevance-redundancy trade-off parameter, eliminating manual tuning and adapting to candidate-pool statistics and budget limits. 3. Provides a theoretical analysis showing the proposed objective exhibits \u03b5-approximate submodularity, yielding near-optimality guarantees for the greedy selection algorithm."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85c85942576679b5e5fe4c0066c0977620d02d122c659a34dfe900bfed59c445_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85c85942576679b5e5fe4c0066c0977620d02d122c659a34dfe900bfed59c445_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of redundant context in token-budgeted RAG systems, which wastes budget and degrades generation quality. It proposes AdaGReS, an adaptive greedy selection framework that scores and selects chunks by balancing relevance and redundancy, with a theoretically-backed near-optimal guarantee. Experiments on QA and biomedical datasets show it improves redundancy control and end-to-end answer quality."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AdaGReS: Adaptive Greedy Context Selection] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Top-k\u68c0\u7d22\u8fd4\u56de\u5197\u4f59\u5757\uff0c\u6d6a\u8d39token\u9884\u7b97\u5e76\u964d\u4f4e\u751f\u6210\u8d28\u91cf/Top-k retrieval returns redundant chunks, wasting token budget and degrading generation]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: \u5197\u4f59\u611f\u77e5\u7684\u8d2a\u5a6a\u9009\u62e9\u6846\u67b6\uff0c\u7ed3\u5408\u76f8\u5173\u6027\u5f97\u5206\u4e0e\u5197\u4f59\u60e9\u7f5a\uff0c\u5e76\u8fdb\u884c\u81ea\u9002\u5e94\u53c2\u6570\u6821\u51c6/Redundancy-aware greedy selection framework with relevance-redundancy trade-off and adaptive calibration]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: \u5728\u5f00\u653e\u57dfQA\u548c\u751f\u7269\u533b\u5b66\u8bed\u6599\u4e0a\uff0c\u5197\u4f59\u63a7\u5236\u548c\u4e0a\u4e0b\u6587\u8d28\u91cf\u5f97\u5230\u6539\u5584\uff0c\u63d0\u5347\u4e86\u7aef\u5230\u7aef\u7b54\u6848\u8d28\u91cf/Improved redundancy control and context quality on open-domain QA and biomedical corpus, leading to better end-to-end answer quality]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}}}]);