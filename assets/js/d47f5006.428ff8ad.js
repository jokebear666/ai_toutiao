"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[601],{7737:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"daily/cs_IR/20251229-20260104","title":"20251229-20260104 (cs.IR)","description":"2025-12-29","source":"@site/docs/daily/cs_IR/20251229-20260104.md","sourceDirName":"daily/cs_IR","slug":"/daily/csir/20251229-20260104","permalink":"/ai_toutiao/daily/csir/20251229-20260104","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767007855000,"frontMatter":{"slug":"/daily/csir/20251229-20260104"},"sidebar":"tutorialSidebar","previous":{"title":"20251222-20251228 (cs.IR)","permalink":"/ai_toutiao/daily/csir/20251222-20251228"},"next":{"title":"cs.IT","permalink":"/ai_toutiao/daily/csit"}}');var a=i(4848),s=i(8453);const r={slug:"/daily/csir/20251229-20260104"},o="20251229-20260104 (cs.IR)",d={},l=[{value:"2025-12-29",id:"2025-12-29",level:2}];function c(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"20251229-20260104-csir",children:"20251229-20260104 (cs.IR)"})}),"\n",(0,a.jsx)(n.h2,{id:"2025-12-29",children:"2025-12-29"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Dynamic Cooperative Strategies in Search Engine Advertising Market: With and Without Retail Competition"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [other], [e-commerce, digital marketing], [search engine advertising, cooperative advertising, differential games, quality score, retail competition]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huiran Li, Qiucheng Li, Baozhu Feng"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Shanghai Customs College, Anhui University of Finance and Economics"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21501",children:"https://arxiv.org/pdf/2512.21501"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel dynamic cooperative advertising optimization model for the SEA market that incorporates direct manufacturer advertising and retailer subsidies. 2. Analyzes two distinct scenarios (with and without retail competition) and provides feasible equilibrium solutions for optimal policies. 3. Investigates the impact of key factors like dynamic quality scores, gross margin, and competitor market share through numerical experiments and sensitivity analysis."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e8e39e4b762e4f21704f8b0ceb833bc4aaedafa4ea17a006a39e667b238fb9a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e8e39e4b762e4f21704f8b0ceb833bc4aaedafa4ea17a006a39e667b238fb9a_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper models cooperative advertising strategies in the search engine advertising (SEA) market using a differential game framework over a finite time horizon. It proposes an optimization model where a manufacturer can advertise directly and subsidize a retailer, analyzing scenarios with and without a competing independent retailer. The study provides equilibrium solutions and numerical insights, concluding that retail competition significantly impacts the optimal cooperative strategy and overall channel performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["Dynamic Cooperative Strategies in Search Engine Advertising Market<br/>\u52a8\u6001\u5408\u4f5c\u7b56\u7565\u5728\u641c\u7d22\u5f15\u64ce\u5e7f\u544a\u5e02\u573a"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u6838\u5fc3\u95ee\u9898/Problem<br/>Intense retail competition & need for channel coordination in SEA"] --\x3e P1["\u5b50\u95ee\u9898/Sub-Problem<br/>Optimal cooperative advertising with/without retail competition"]\n    Method["\u4e3b\u8981\u65b9\u6cd5/Method<br/>Dynamic cooperative advertising model using differential games"] --\x3e M1["\u6a21\u578b\u7279\u5f81/Model Features<br/>Finite time horizon, dynamic quality score"]\n    Method --\x3e M2["\u573a\u666f/Scenarios<br/>Scenario I: One manufacturer, one retailer<br/>Scenario II: Alliance vs. independent retailer"]\n    Results["\u5173\u952e\u7ed3\u679c/Results<br/>Equilibrium solutions & numerical analysis"] --\x3e R1["\u53d1\u73b0/Findings<br/>Impact of quality score, gross margin, competitor share"]\n    Results --\x3e R2["\u7ed3\u8bba/Conclusion<br/>Retail competition affects optimal strategy & channel performance"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Selective LLM-Guided Regularization for Enhancing Recommendation Models"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [selective regularization, knowledge distillation, cold-start, long-tail, gating mechanism]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Shanglin Yang, Zhan Shi"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Sichuan University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21526",children:"https://arxiv.org/pdf/2512.21526"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a selective LLM-guided regularization framework (S-LLMR) that activates LLM supervision only when a gating mechanism predicts the LLM to be reliable, addressing the issue of inaccurate global distillation. 2. Introduces a trainable gating mechanism informed by user history length, item popularity, and model uncertainty to dynamically decide when to apply LLM-based pairwise ranking supervision. 3. Demonstrates through experiments that the method improves overall accuracy and yields substantial gains in cold-start and long-tail recommendation scenarios, outperforming global distillation baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76336a3d123794e83843c14c4b799afd0817948ee9dfeb2f6f19ce776f183796_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of leveraging large language models (LLMs) for recommendation without suffering from their high cost and unreliability in certain scenarios. It proposes Selective LLM-Guided Regularization (S-LLMR), a model-agnostic framework that uses a gating mechanism to selectively apply LLM-based supervision only when the LLM is predicted to be reliable. Experiments show this approach improves recommendation accuracy, especially for cold-start users and long-tail items, outperforming methods that uniformly distill LLM knowledge."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[Selective LLM-Guided Regularization<br>\u9009\u62e9\u6027LLM\u5f15\u5bfc\u6b63\u5219\u5316] --\x3e B(Problem/\u6838\u5fc3\u95ee\u9898<br>LLMs as standalone recommenders are costly/unreliable;<br>Global distillation forces imitation of inaccurate LLM guidance.)\n    A --\x3e C(Method/\u4e3b\u8981\u65b9\u6cd5<br>Selective LLM-Guided Regularization (S-LLMR):<br>Trainable gating mechanism activates LLM supervision only when reliable.)\n    A --\x3e D(Results/\u5173\u952e\u7ed3\u679c<br>Improves overall accuracy;<br>Substantial gains in cold-start & long-tail regimes.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] CEMG: Collaborative-Enhanced Multimodal Generative Recommendation"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [multimodal fusion, generative recommendation, large language model, collaborative filtering, residual quantization vae]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yuzhen Lin, Hongyi Chen, Xuanjing Chen, Shaowen Wang, Ivonne Xu, Dongming Jiang"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Carnegie Mellon University, University of California, Los Angeles, Columbia University, University of Illinois Urbana-Champaign, University of Chicago, Rice University"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21543",children:"https://arxiv.org/pdf/2512.21543"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel framework (CEMG) that deeply integrates collaborative signals to guide multimodal feature fusion, addressing superficial integration. 2. Introduces a Unified Modality Tokenization stage using a Residual Quantization VAE to convert fused multimodal representations into discrete semantic codes. 3. Fine-tunes a large language model to autoregressively generate item codes for end-to-end generative recommendation, demonstrating superior performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/267ab80cc75bcfd70f9642eece8f5665f85619909a397396158a72d2bb42b941_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/267ab80cc75bcfd70f9642eece8f5665f85619909a397396158a72d2bb42b941_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes CEMG, a novel generative recommendation framework that addresses superficial collaborative signal integration and decoupled multimodal fusion. It uses collaborative signals to guide multimodal feature fusion, tokenizes the fused representation into discrete codes using an RQ-VAE, and fine-tunes an LLM to generate these codes. Experiments show CEMG significantly outperforms state-of-the-art baselines."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    Root[CEMG: Collaborative-Enhanced Multimodal Generative Recommendation] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem[\u6838\u5fc3\u95ee\u9898/Problem] --\x3e P1[\u6d45\u5c42\u534f\u540c\u4fe1\u53f7\u96c6\u6210/Superficial collaborative signal integration]\n    Problem --\x3e P2[\u89e3\u8026\u7684\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408/Decoupled multimodal feature fusion]\n    Method[\u4e3b\u8981\u65b9\u6cd5/Method] --\x3e M1[\u591a\u6a21\u6001\u878d\u5408\u5c42/Multimodal Fusion Layer]\n    M1 --\x3e M1_Detail[\u534f\u540c\u4fe1\u53f7\u5f15\u5bfc\u878d\u5408/Collaborative signal-guided fusion]\n    Method --\x3e M2[\u7edf\u4e00\u6a21\u6001\u6807\u8bb0\u5316/Unified Modality Tokenization]\n    M2 --\x3e M2_Detail[\u4f7f\u7528RQ-VAE/Using RQ-VAE]\n    Method --\x3e M3[\u7aef\u5230\u7aef\u751f\u6210\u63a8\u8350/End-to-End Generative Recommendation]\n    M3 --\x3e M3_Detail[\u5fae\u8c03LLM\u751f\u6210\u4ee3\u7801/Fine-tune LLM to generate codes]\n    Results[\u5173\u952e\u7ed3\u679c/Results] --\x3e R1[\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf/Significantly outperforms baselines]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [item-to-item recommendation, data-centric, long-tail items, data augmentation, data filtering]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Yinfu Feng, Yanjing Wu, Rong Xiao, Xiaoyi Zen"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Alibaba Group"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21595",children:"https://arxiv.org/pdf/2512.21595"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Proposes LLM-I2I, a data-centric framework that leverages Large Language Models to enhance I2I recommendation models without altering their architecture. 2. Introduces an LLM-based data generator to synthesize user-item interactions, specifically targeting long-tail items to alleviate data sparsity. 3. Designs an LLM-based data discriminator to filter out noisy interactions from both real and synthetic data, improving overall data quality for training."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cb08ea9b26b612493e4d48e7db88c46a869c2050c94d47b75488adcaf6ddfa9_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses data sparsity and noise problems in Item-to-Item (I2I) recommendation systems by proposing LLM-I2I, a data-centric framework that uses an LLM to generate synthetic interactions for long-tail items and filter noisy data. The refined data is then used to train existing I2I models. Experimental results on industrial and academic datasets show significant improvements in recommendation accuracy, especially for long-tail items, and deployment on a large e-commerce platform led to measurable gains in recall and gross merchandise value."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[LLM-I2I: Boost Your Small Item2Item Recommendation Model with Large Language Model] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u6570\u636e\u7a00\u758f\u4e0e\u566a\u58f0/Data Sparsity & Noise]\n    C --\x3e C1[LLM\u6570\u636e\u751f\u6210\u5668/LLM-based Data Generator]\n    C --\x3e C2[LLM\u6570\u636e\u5224\u522b\u5668/LLM-based Data Discriminator]\n    C1 --\x3e C3[\u5408\u6210\u4ea4\u4e92\u6570\u636e/Synthesize Interaction Data]\n    C2 --\x3e C4[\u8fc7\u6ee4\u566a\u58f0\u6570\u636e/Filter Noisy Data]\n    C3 & C4 --\x3e C5[\u878d\u5408\u6570\u636e\u8bad\u7ec3I2I\u6a21\u578b/Fuse Data to Train I2I Model]\n    D --\x3e D1[\u63d0\u5347\u63a8\u8350\u51c6\u786e\u7387/Improves Recommendation Accuracy]\n    D --\x3e D2[\u63d0\u5347\u957f\u5c3e\u7269\u54c1\u6027\u80fd/Better for Long-tail Items]\n    D --\x3e D3[\u7ebf\u4e0a\u6307\u6807\u63d0\u5347/Online Metric Improvements (RN+6.02%, GMV+1.22%)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] KG20C & KG20C-QA: Scholarly Knowledge Graph Benchmarks for Link Prediction and Question Answering"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [db], [knowledge graph], [knowledge graph embedding, question answering, scholarly data, benchmark dataset, link prediction]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Hung-Nghiep Tran, Atsuhiro Takasu"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," University of Information Technology, Vietnam National University, Ho Chi Minh City; National Institute of Informatics, The Graduate University for Advanced Studies, SOKENDAI"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21799",children:"https://arxiv.org/pdf/2512.21799"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/tranhungnghiep/KG20C/",children:"https://github.com/tranhungnghiep/KG20C/"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Provides the first formal, peer-reviewed description and documentation of the KG20C scholarly knowledge graph, a high-quality benchmark constructed from the Microsoft Academic Graph. 2. Introduces KG20C-QA, a new benchmark dataset for question answering on scholarly data, built by converting KG20C triples into natural language question-answer pairs. 3. Establishes reproducible evaluation protocols, benchmarks standard knowledge graph embedding methods on KG20C-QA, and analyzes performance across different relation types."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6a0acbf8722d77d366a3d6b93104d40b8d9c7d53e5a9c94bd36138fd5ab3107_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6a0acbf8722d77d366a3d6b93104d40b8d9c7d53e5a9c94bd36138fd5ab3107_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper formally introduces KG20C and KG20C-QA, two curated benchmark datasets for scholarly knowledge graphs. KG20C is a cleaned and structured knowledge graph from academic metadata, while KG20C-QA provides a question-answering benchmark derived from it. The authors benchmark standard models on the new QA dataset and release the resources to support future research in scholarly data reasoning and QA."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root["KG20C & KG20C-QA: \u5b66\u672f\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6<br/>KG20C & KG20C-QA: Scholarly KG Benchmarks"] --\x3e Problem\n    Root --\x3e Method\n    Root --\x3e Results\n    Problem["\u7f3a\u4e4f\u5b66\u672f\u9886\u57df\u7684\u6807\u51c6\u5316\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6<br/>Lack of Standardized KG Benchmarks for Scholarly Domain"]\n    Method["\u4eceMAG\u6784\u5efa\u9ad8\u8d28\u91cf\u5b66\u672f\u77e5\u8bc6\u56fe\u8c31KG20C<br/>Construct High-Quality Scholarly KG KG20C from MAG"] --\x3e SubMethod1["\u5b9a\u4e49QA\u6a21\u677f\uff0c\u751f\u6210KG20C-QA\u6570\u636e\u96c6<br/>Define QA Templates to Create KG20C-QA Dataset"]\n    Results["\u53d1\u5e03\u6b63\u5f0f\u6587\u6863\u5316\u7684\u53ef\u91cd\u7528\u57fa\u51c6\u8d44\u6e90<br/>Release Formally Documented, Reusable Benchmark Resources"] --\x3e SubResult1["\u5728KG20C-QA\u4e0a\u8bc4\u4f30\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5<br/>Evaluate KG Embedding Methods on KG20C-QA"]'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] Frozen LVLMs for Micro-Video Recommendation: A Systematic Study of Feature Extraction and Fusion"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [ai], [recommender systems], [frozen large video language models, micro-video recommendation, feature fusion, intermediate hidden states, dual feature fusion]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Huatuan Sun, Yunshan Ma, Changguang Wu, Yanxin Zhang, Pengfei Wang, Xiaoyu Du"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," Nanjing University of Science and Technology, Singapore Management University, University of Wisconsin-Madison, GienTech Technology Co., Ltd."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21863",children:"https://arxiv.org/pdf/2512.21863"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. Conducted the first systematic empirical study on integrating frozen LVLMs into micro-video recommendation, evaluating feature extraction paradigms (captions vs. hidden states) and integration strategies (replacement vs. fusion) with ID embeddings. 2. Derived three key principles: intermediate hidden states outperform captions, ID embeddings are irreplaceable (fusion > replacement), and the effectiveness of hidden states varies across layers. 3. Proposed the Dual Feature Fusion (DFF) Framework, a lightweight plug-and-play method that adaptively fuses multi-layer LVLM representations with ID embeddings, achieving state-of-the-art performance."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6963682bbae94363e4d55953d0681db3b9e674fbd82bcf7d3d2a179f4ea6f73e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6963682bbae94363e4d55953d0681db3b9e674fbd82bcf7d3d2a179f4ea6f73e_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper systematically studies how to best integrate frozen Large Video-Language Models (LVLMs) as feature extractors for micro-video recommendation. It finds that using intermediate decoder hidden states and fusing them with item ID embeddings is superior to using generated captions or replacing IDs. Based on these insights, the authors propose the Dual Feature Fusion (DFF) framework, which achieves state-of-the-art results on benchmark datasets."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:'graph TB\n    Root("Frozen LVLMs for Micro-Video Recommendation") --\x3e Problem("\u6838\u5fc3\u95ee\u9898/Problem")\n    Root --\x3e Method("\u4e3b\u8981\u65b9\u6cd5/Method")\n    Root --\x3e Results("\u5173\u952e\u7ed3\u679c/Results")\n    Problem --\x3e P1("LVLM\u96c6\u6210\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30/Lack of systematic evaluation for LVLM integration")\n    Method --\x3e M1("\u7cfb\u7edf\u5b9e\u8bc1\u7814\u7a76/Systematic empirical study")\n    Method --\x3e M2("\u63d0\u51faDFF\u6846\u67b6/Propose DFF Framework")\n    M1 --\x3e M1a("\u6bd4\u8f83\u7279\u5f81\u63d0\u53d6\u8303\u5f0f/Compare feature extraction paradigms")\n    M1 --\x3e M1b("\u6bd4\u8f83ID\u96c6\u6210\u7b56\u7565/Compare ID integration strategies")\n    M2 --\x3e M2a("\u81ea\u9002\u5e94\u878d\u5408\u591a\u5c42\u7279\u5f81/Adaptively fuse multi-layer features")\n    M2 --\x3e M2b("\u8f7b\u91cf\u7ea7\u5373\u63d2\u5373\u7528/Lightweight plug-and-play")\n    Results --\x3e R1("\u4e2d\u95f4\u9690\u85cf\u6001\u4f18\u4e8e\u63cf\u8ff0/Intermediate hidden states > captions")\n    Results --\x3e R2("ID\u5d4c\u5165\u4e0d\u53ef\u66ff\u4ee3/Fusion > replacement")\n    Results --\x3e R3("DFF\u5b9e\u73b0SOTA\u6027\u80fd/DFF achieves SOTA performance")'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"[arXiv251229] AutoPP: Towards Automated Product Poster Generation and Optimization"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"tags:"})," [cv], [image generation], [product poster generation, click-through rate optimization, isolated direct preference optimization, AutoPP1M dataset, unified design module]"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"authors:"})," Jiahao Fan, Yuxin Qin, Wei Feng, Yanyin Chen, Yaoyu Li, Ao Ma, Yixiu Li, Li Zhuang, Haoyi Bian, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"institution:"})," JD.COM"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"link:"})," ",(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21921",children:"https://arxiv.org/pdf/2512.21921"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"code:"})," ",(0,a.jsx)(n.a,{href:"https://github.com/JD-GenX/AutoPP",children:"https://github.com/JD-GenX/AutoPP"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"contributions:"})," 1. An automated pipeline (AutoPP) for end-to-end product poster generation and optimization, requiring only basic product information as input. 2. A novel optimization method that uses systematic element replacement and Isolated Direct Preference Optimization (IDPO) to attribute CTR gains to specific poster elements. 3. The creation and release of AutoPP1M, the largest dataset for product poster generation and optimization, containing one million posters and user feedback."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"thumbnail:"})," ",(0,a.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f18700c508d46682b8040947d4af38f1b6c821d269a8518370be8bf9c574fe71_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f18700c508d46682b8040947d4af38f1b6c821d269a8518370be8bf9c574fe71_w640_q70.webp"})]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces AutoPP, an automated pipeline that generates product posters from basic product information and then optimizes them for higher Click-Through Rate (CTR) using online feedback and a novel Isolated Direct Preference Optimization technique. It is supported by a large-scale dataset, AutoPP1M. Experiments show that AutoPP achieves state-of-the-art performance in both offline and online evaluations."]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,a.jsx)(n.mermaid,{value:"graph TB\n    A[AutoPP: Towards Automated Product Poster Generation and Optimization] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[\u4eba\u5de5\u5236\u4f5c\u4e0e\u4f18\u5316\u6d77\u62a5\u8017\u65f6\u8017\u529b/Manual poster creation and optimization is laborious]\n    C --\x3e C1[\u81ea\u52a8\u5316\u751f\u6210\u4e0e\u4f18\u5316\u7ba1\u9053/Automated generation and optimization pipeline]\n    C1 --\x3e C1_1[\u751f\u6210\u5668: \u7edf\u4e00\u8bbe\u8ba1\u6a21\u5757\u4e0e\u5143\u7d20\u6e32\u67d3/Generator: Unified design & element rendering]\n    C1 --\x3e C1_2[\u4f18\u5316\u5668: \u5143\u7d20\u66ff\u6362\u4e0eIDPO/Optimizer: Element replacement & IDPO]\n    C --\x3e C2[\u6570\u636e\u96c6: AutoPP1M/Dataset: AutoPP1M]\n    D --\x3e D1[\u79bb\u7ebf\u548c\u5728\u7ebfSOTA\u7ed3\u679c/Offline and online SOTA results]\n    D --\x3e D2[\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u516c\u5f00/Code & dataset released]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var t=i(6540);const a={},s=t.createContext(a);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);