"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2493],{28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var s=i(96540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}},93271:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"daily/cs_MA/20251222-20251228","title":"20251222-20251228 (cs.MA)","description":"2025-12-22","source":"@site/docs/daily/cs_MA/20251222-20251228.md","sourceDirName":"daily/cs_MA","slug":"/daily/csma/20251222-20251228","permalink":"/ai_toutiao/daily/csma/20251222-20251228","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1767087759000,"frontMatter":{"slug":"/daily/csma/20251222-20251228"},"sidebar":"tutorialSidebar","previous":{"title":"20251215-20251221 (cs.MA)","permalink":"/ai_toutiao/daily/cs_MA/20251215-20251221"},"next":{"title":"20251229-20260104 (cs.MA)","permalink":"/ai_toutiao/daily/csma/20251229-20260104"}}');var r=i(74848),a=i(28453);const t={slug:"/daily/csma/20251222-20251228"},l="20251222-20251228 (cs.MA)",d={},c=[{value:"2025-12-22",id:"2025-12-22",level:2},{value:"2025-12-23",id:"2025-12-23",level:2},{value:"2025-12-24",id:"2025-12-24",level:2},{value:"2025-12-25",id:"2025-12-25",level:2}];function o(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"20251222-20251228-csma",children:"20251222-20251228 (cs.MA)"})}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-22",children:"2025-12-22"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] V-Agent: An Interactive Video Search System Using Vision-Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [multi-modal inference], [vision-language model, fine-tuning, retrieval vector, re-ranking, multi-agent system]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," NC AI, Kakao, Korea Advanced Institute of Science and Technology (KAIST)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16925",children:"https://arxiv.org/pdf/2512.16925"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," V-Agent is a multi-agent video search system that fine-tunes a vision-language model with a small video preference dataset and enhances it with a retrieval vector to embed video frames and audio transcriptions into a shared multimodal space. It uses three agents\u2014routing, search, and chat\u2014to refine searches and interact with users, achieving state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] PAACE: A Plan-Aware Automated Agent Context Engineering Framework"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [context engineering, plan-aware compression, next-k-task relevance, instruction co-refinement, function-preserving compression, synthetic data generation, knowledge distillation]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Kamer Ali Yuksel"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," aiXplain Inc"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.16970",children:"https://arxiv.org/pdf/2512.16970"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [multi-agent system, transactional analysis, ego states, information retrieval, vector stores, ablation test]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Monika Zamojska, Jaros\u0142aw A. Chudziak"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Warsaw University of Technology"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17060",children:"https://arxiv.org/pdf/2512.17060"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a multi-agent system architecture that integrates Transactional Analysis theory, dividing each agent into Parent, Adult, and Child ego states, and enhances their responses with contextual information retrieval from vector stores. The system is evaluated through ablation tests in a simulated dialogue scenario. The results show that this psychologically grounded structure improves the realism of LLM-based agent behavior."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [others], [differentiable simulation, graph neural network, SE(3)-equivariance, attention mechanism, 3D Zernike polynomials, shape-matching loss, implicit differentiation, bilevel optimization]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Seong Ho Pahng, Guoye Guan, Benjamin Fefferman, Sahand Hormoz"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Harvard University, Harvard Medical School, Dana-Farber Cancer Institute, Broad Institute of MIT and Harvard"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17129",children:"https://arxiv.org/pdf/2512.17129"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper introduces DiffeoMorph, a differentiable framework that uses an attention-based SE(3)-equivariant graph neural network to train agents to collectively morph into target 3D shapes. It employs a novel shape-matching loss based on 3D Zernike polynomials and uses implicit differentiation to handle a bilevel optimization problem for rotation alignment. The method successfully generates complex shapes from simple ellipsoids using minimal spatial cues."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251222] Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [llm inference], [audit agents, attestation protocols, constrained reasoning, cryptographic attestation, symbolic methods, benchmark suite, verifiability]"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Abhivansh Gupta"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Indian Institute of Technology, Roorkee"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17259",children:"https://arxiv.org/pdf/2512.17259"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a Verifiability-First architecture for LLM-based agents, integrating runtime attestations, lightweight audit agents for continuous verification, and challenge-response protocols for high-risk operations. It introduces the OPERA benchmark to evaluate the detectability and speed of remediation for misaligned behavior, shifting the focus from measuring the propensity for misalignment to ensuring reliable detection and control."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-23",children:"2025-12-23"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Boris Kriuk, Logic Ng"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17914",children:"https://arxiv.org/pdf/2512.17914"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d4fd665329b7eb837ca00f1091de17f8b4c1eb920670c43995680ca539562ae_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d4fd665329b7eb837ca00f1091de17f8b4c1eb920670c43995680ca539562ae_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Matthieu Mastio, Paul Saves, Benoit Gaudou, Nicolas Verstaevel"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.17979",children:"https://arxiv.org/pdf/2512.17979"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Boxuan Wang, Zhuoyun Li, Xiaowei Huang, Yi Dong"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18094",children:"https://arxiv.org/pdf/2512.18094"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18126",children:"https://arxiv.org/pdf/2512.18126"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] On Swarm Leader Identification using Probing Policies"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Stergios E. Bachoumas, Panagiotis Artemiadis"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18146",children:"https://arxiv.org/pdf/2512.18146"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," On Swarm Leader Identification using Probing Policies"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Snowveil: A Framework for Decentralised Preference Discovery"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Grammateia Kotsialou"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18444",children:"https://arxiv.org/pdf/2512.18444"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Snowveil: A Framework for Decentralised Preference Discovery"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Xavier Rafael-Palou, Jose Munuera, Ana Jimenez-Pastor, Richard Osuala, Karim Lekadir, Oliver Diaz"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18450",children:"https://arxiv.org/pdf/2512.18450"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18470",children:"https://arxiv.org/pdf/2512.18470"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] ShibuyaSocial: Multi-scale Model of Pedestrian Flows in Scramble Crossing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Akihiro Sakurai, Naoya Kajio, Ko Yamamoto"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18550",children:"https://arxiv.org/pdf/2512.18550"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/843027a88605f9f8d1080240849a486d0714182a2284ffc1375f8f6f116c1c39_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/843027a88605f9f8d1080240849a486d0714182a2284ffc1375f8f6f116c1c39_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," ShibuyaSocial: Multi-scale Model of Pedestrian Flows in Scramble Crossing"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Saad Alqithami"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18561",children:"https://arxiv.org/pdf/2512.18561"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18616",children:"https://arxiv.org/pdf/2512.18616"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18622",children:"https://arxiv.org/pdf/2512.18622"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Junjun Pan, Yixin Liu, Rui Miao, Kaize Ding, Yu Zheng, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, Shirui Pan"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18733",children:"https://arxiv.org/pdf/2512.18733"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] MemEvolve: Meta-Evolution of Agent Memory Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Guibin Zhang, Haotian Ren, Chong Zhan, Zhenhong Zhou, Junhao Wang, He Zhu, Wangchunshu Zhou, Shuicheng Yan"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18746",children:"https://arxiv.org/pdf/2512.18746"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bcb0edebf98e4279185979654fe8f92c41ebcbd3b45786b67e305d7a65d04f6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bcb0edebf98e4279185979654fe8f92c41ebcbd3b45786b67e305d7a65d04f6_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," MemEvolve: Meta-Evolution of Agent Memory Systems"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251223] Quantifying the Lifelong Impact of Resilience Interventions via Agent-Based LLM Simulation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Vivienne L'Ecuyer Ming"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.18803",children:"https://arxiv.org/pdf/2512.18803"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbb9912dc64ced0a3542815309f1cfd619aff6ad7759e8db7f3222089c75b40e_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbb9912dc64ced0a3542815309f1cfd619aff6ad7759e8db7f3222089c75b40e_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Quantifying the Lifelong Impact of Resilience Interventions via Agent-Based LLM Simulation"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-24",children:"2025-12-24"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.19707",children:"https://arxiv.org/pdf/2512.19707"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] Learning to Design City-scale Transit Routes"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Bibek Poudel, Weizi Li"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.19767",children:"https://arxiv.org/pdf/2512.19767"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Learning to Design City-scale Transit Routes"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] A Multi-Agent Retrieval-Augmented Framework for Work-in-Progress Predictio"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yousef Mehrdad Bibalan, Behrouz Far, Mohammad Moshirpour, Bahareh Ghiyasian"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.19841",children:"https://arxiv.org/pdf/2512.19841"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45f978e53da563dbc9e748ff49d537fb4e3d35d7c8fd9c552b19ad53eb6c0c42_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45f978e53da563dbc9e748ff49d537fb4e3d35d7c8fd9c552b19ad53eb6c0c42_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," A Multi-Agent Retrieval-Augmented Framework for Work-in-Progress Predictio"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] Chain-of-Anomaly Thoughts with Large Vision-Language Models"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Pedro Domingos, Jo\xe3o Pereira, Vasco Lopes, Jo\xe3o Neves, David Semedo"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20417",children:"https://arxiv.org/pdf/2512.20417"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e26e3aba92227ff2a24c227033ffa15e8e191cf437a0a97c819748f4dfb7c94_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e26e3aba92227ff2a24c227033ffa15e8e191cf437a0a97c819748f4dfb7c94_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," Chain-of-Anomaly Thoughts with Large Vision-Language Models"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Marco Aruta, Francesco Improta, Vadim Malvone, Aniello Murano"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20457",children:"https://arxiv.org/pdf/2512.20457"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/664463f9c309b65554e570fddf642935c026241a76429b252415a066c09c87df_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/664463f9c309b65554e570fddf642935c026241a76429b252415a066c09c87df_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251224] LongVideoAgent: Multi-Agent Reasoning with Long Videos"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," TBD"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20618",children:"https://arxiv.org/pdf/2512.20618"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," LongVideoAgent: Multi-Agent Reasoning with Long Videos"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2025-12-25",children:"2025-12-25"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] Reflection-Driven Self-Optimization 6G Agentic AI RAN via Simulation-in-the-Loop Workflows"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [agentic AI, simulation-in-the-loop, reflection-driven optimization, autonomous RAN, 6G networks]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yunhao Hu, Xinchen Lyu, Chenshan Ren, Keda Chen, Qimei Cui, Xiaofeng Tao"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing University of Posts and Telecommunications, Minzu University of China"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20640",children:"https://arxiv.org/pdf/2512.20640"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes the first reflection-driven self-optimization framework that integrates agentic AI with high-fidelity network simulation in a closed-loop architecture for 6G RAN., 2. Introduces a system orchestrating four specialized agents (scenario, solver, simulation, reflector) to create a self-correcting system capable of escaping local optima and recognizing implicit user intent., 3. Demonstrates significant performance improvements through extensive experiments, including higher throughput, improved QoS satisfaction, and reduced resource utilization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3381ce41a28a862e29b4ca28a7f2754986518a545ddbd678c6fe9aacc79a7adc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3381ce41a28a862e29b4ca28a7f2754986518a545ddbd678c6fe9aacc79a7adc_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the lack of empirical validation and self-improvement in current agentic AI frameworks for 6G Radio Access Networks (RAN). It proposes a novel reflection-driven self-optimization framework that integrates agentic AI with high-fidelity network simulation in a closed-loop workflow. The framework demonstrates substantial performance gains over non-agentic approaches, including higher throughput, better QoS satisfaction, and more efficient resource utilization."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\nA[Reflection-Driven Self-Optimization 6G Agentic AI RAN via Simulation-in-the-Loop Workflows] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Current agentic AI lacks empirical validation & self-improvement for 6G RAN]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Reflection-driven framework with 4 agents & simulation-in-the-loop]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 17.1% higher throughput, 67% improved QoS, 25% reduced resource use]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent systems], [Differentiable Price Mechanism, Dominant Strategy Incentive Compatibility, VCG-equivalent incentive, Dec-POMDPs, Bayesian Incentive Compatibility]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Stefano Grassi"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," None (No affiliation or email domain provided in the given content)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20688",children:"https://arxiv.org/pdf/2512.20688"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Mechanism-Based Intelligence (MBI), a new paradigm framing intelligence as emergent from the coordination of multiple agents. 2. Introduces the Differentiable Price Mechanism (DPM), which computes exact loss gradients as incentive signals to guarantee Dominant Strategy Incentive Compatibility and convergence. 3. Demonstrates a framework that scales linearly with the number of agents, bypassing Dec-POMDP complexity and showing significant empirical speedup over model-free RL."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfdd6bb51cf65ab558a1d13cbaf0fbdda25f9c06c58be3e201a62b231f808da4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfdd6bb51cf65ab558a1d13cbaf0fbdda25f9c06c58be3e201a62b231f808da4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the fragility of multi-agent systems in coordinating private information and aligning incentives. It proposes Mechanism-Based Intelligence (MBI) and its core Differentiable Price Mechanism (DPM), which uses differentiable incentives to align agent actions with global objectives. The method guarantees incentive compatibility, scales efficiently, and is shown to be much faster than standard reinforcement learning approaches."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\nA[Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Hayekian Information Problem & Hurwiczian Incentive Problem]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Differentiable Price Mechanism (DPM) & Bayesian Extension]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results: DSIC/BIC Guarantee, Linear Scaling, 50x Faster than Model-Free RL]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs with Inconsistent Beliefs and Limited Communication"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [ai], [multi-agent reinforcement learning], [Dec-POMDP, belief inconsistency, limited communication, action consistency, multi-agent planning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Moshe Rafaeli Shimron, Vadim Indelman"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Technion - Israel Institute of Technology"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20778",children:"https://arxiv.org/pdf/2512.20778"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. A novel decentralized framework for optimal joint action selection that explicitly accounts for belief inconsistencies among agents. 2. Provides probabilistic guarantees for both action consistency and performance relative to a fully-communicating baseline. 3. Introduces a mechanism to selectively trigger communication only when necessary and addresses the decision of whether to share data after action selection to improve inference."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4538ed8602d7a249e385e29bfc0423ed3f6682a9ac338c82e10822f10bd96df8_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4538ed8602d7a249e385e29bfc0423ed3f6682a9ac338c82e10822f10bd96df8_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the problem of multi-agent decision-making under uncertainty when agents have inconsistent beliefs due to limited communication. It proposes a new decentralized framework for Dec-POMDPs that provides performance and action consistency guarantees while minimizing communication. Simulation results demonstrate that the approach outperforms existing state-of-the-art algorithms."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\nA[Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs] --\x3e B(\u6838\u5fc3\u95ee\u9898/Problem: Belief Inconsistency & Limited Communication)\nA --\x3e C(\u4e3b\u8981\u65b9\u6cd5/Method: Novel Decentralized Framework with Guarantees)\nA --\x3e D(\u5173\u952e\u7ed3\u679c/Results: Outperforms SOTA Algorithms)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["[arXiv251225] MAR",":Multi-Agent"," Reflexion Improves Reasoning Abilities in LLMs"]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent reflection, reasoning improvement, self-correction, episodic memory, iterative refinement]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Onat Ozer, Grace Wu, Yuchen Wang, Daniel Dosti, Honghao Zhang, Vivi De La Rue"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Michigan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20845",children:"https://arxiv.org/pdf/2512.20845"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies systematic shortcomings in the single-agent Reflexion framework, such as repeated reasoning errors and confirmation bias, through detailed replication and analysis. 2. Proposes Multi-Agent Reflexion (MAR), a structured multi-agent extension that incorporates diverse reasoning personas and a judge model to synthesize critiques into unified reflections. 3. Demonstrates that MAR improves performance over Reflexion on HotPotQA and HumanEval benchmarks, reducing stagnation and enhancing reasoning reliability."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6022c55272f43b40b16d9e6f722483682ba159634bd04eb55be130ec83c86fe4_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6022c55272f43b40b16d9e6f722483682ba159634bd04eb55be130ec83c86fe4_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper addresses the problem of reasoning error repetition and limited corrective feedback in single-agent LLM self-reflection frameworks like Reflexion. It proposes Multi-Agent Reflexion (MAR), which uses multiple agents with diverse personas to generate critiques and a judge to synthesize them, leading to more diverse and effective reflections. The method shows improved accuracy on HotPotQA and HumanEval benchmarks compared to the single-agent approach."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[MAR: Multi-Agent Reflexion] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Single-agent self-reflection leads to repeated errors and confirmation bias]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Multi-agent system with diverse personas and a judge model for critique synthesis]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: Improved accuracy on HotPotQA (47% EM) and HumanEval (82.7% pass@1)]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [cv], [visual reasoning], [visual programming, spatial reasoning, tool induction, transductive learning, 3D scene understanding]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Stanford University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20934",children:"https://arxiv.org/pdf/2512.20934"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://transductive-visualprogram.github.io/",children:"https://transductive-visualprogram.github.io/"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes Transductive Visual Programming (TVP), a novel framework that builds new tools from experiential solutions rather than speculative induction., 2. Introduces a closed-loop system with an evolving Tool Library and an Example Library, enabling self-improvement through experience., 3. Demonstrates state-of-the-art performance on spatial reasoning benchmarks and shows that transductively learned tools are used more frequently and generalize better."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the challenge of spatial reasoning in 3D scenes by proposing Transductive Visual Programming (TVP), a framework that learns reusable higher-level tools by abstracting patterns from its own successful solutions. This experience-driven approach outperforms existing methods and GPT-4o on benchmarks, showing more effective tool discovery and strong generalization to unseen tasks."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[Transductive Visual Programming] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem<br>Spatial reasoning is challenging for VLMs]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Build tools from experience, not speculation]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results<br>SOTA performance, better tool reuse & generalization]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] DAO-Agent: Zero Knowledge-Verified Incentives for Decentralized Multi-Agent Coordination"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [Zero-Knowledge Proofs, Shapley Value, Decentralized Autonomous Organizations, Multi-Agent Systems, Blockchain]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Yihan Xia, Taotao Wang, Wenxin Xu, Shengli Zhang"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Shenzhen University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20973",children:"https://arxiv.org/pdf/2512.20973"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. An on-chain DAO governance mechanism for transparent coordination and immutable logging. 2. A ZKP mechanism for off-chain Shapley-based contribution measurement. 3. A hybrid on-chain/off-chain architecture for verifying ZKP-validated contributions with minimal on-chain overhead."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ff4955d8d9489107cba57cf8d1124252e3fa945a32495d363fb58496f2f40bc_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ff4955d8d9489107cba57cf8d1124252e3fa945a32495d363fb58496f2f40bc_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper proposes DAO-Agent, a framework that uses a hybrid on-chain/off-chain architecture with Zero-Knowledge Proofs (ZKP) and DAO governance to enable auditable and fair incentive distribution for LLM-based multi-agent systems in trustless environments while preserving privacy. It achieves up to 99.9% reduction in on-chain verification costs compared to naive on-chain methods, providing a scalable solution for decentralized agent coordination."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\nA[DAO-Agent] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem<br>Trustless multi-agent coordination<br>needs auditability & fairness<br>but faces high on-chain cost & privacy risk]\nA --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method<br>Hybrid On-chain/Off-chain Architecture<br>On-chain DAO for governance<br>Off-chain ZKP for Shapley value]\nA --\x3e D[\u5173\u952e\u7ed3\u679c/Results<br>99.9% gas cost reduction<br>Constant-time verification<br>Scalable foundation]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [LangChain, Hyperledger Fabric, MCP (Model Context Protocol), permissioned blockchain, multi-agent system]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Salman Jan, Hassan Ali Razzaqi, Ali Akarma, Mohammad Riyaz Belgaum"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Arab Open University-Bahrain, Islamic University of Madinah"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20985",children:"https://arxiv.org/pdf/2512.20985"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposed a novel architecture integrating a LangChain-based multi-agent system with a permissioned blockchain for monitoring and auditing agentic AI actions. 2. Introduced a framework linking the perception-reasoning-action cycle to a blockchain governance layer for input verification, action evaluation, and outcome logging. 3. Demonstrated the framework's applicability and performance through experiments in smart inventory management, traffic-signal control, and healthcare monitoring."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b6daf67b596733e755359a781c7506180a1c98a12a8eab70c8fd627d718b47_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b6daf67b596733e755359a781c7506180a1c98a12a8eab70c8fd627d718b47_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper proposes a blockchain-monitored architecture for agentic AI systems to address trust and oversight concerns. The method integrates a LangChain multi-agent system with a Hyperledger Fabric blockchain to create an auditable perception-reasoning-action pipeline. The results show the framework effectively prevents unauthorized actions, provides full decision traceability, and maintains acceptable operational latency."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[\u8bba\u6587\u6807\u9898 / Paper Title<br>A Blockchain-Monitored Agentic AI Architecture] --\x3e B(\u6838\u5fc3\u95ee\u9898 / Problem<br>Agentic AI\u7f3a\u4e4f\u4fe1\u4efb\u4e0e\u5ba1\u8ba1 / Lack of Trust & Auditability)\n    A --\x3e C(\u4e3b\u8981\u65b9\u6cd5 / Method<br>\u533a\u5757\u94fe\u76d1\u63a7\u7684LangChain\u591a\u667a\u80fd\u4f53\u67b6\u6784 / Blockchain-Monitored LangChain Multi-Agent Architecture)\n    A --\x3e D(\u5173\u952e\u7ed3\u679c / Results<br>\u6709\u6548\u5b89\u5168\u9a8c\u8bc1\u4e0e\u53ef\u8ffd\u6eaf\u6027 / Effective Security Verification & Traceability)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] FinAgent: An Agentic AI Framework Integrating Personal Finance and Nutrition Planning"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [multi-agent architecture, substitution graph, price-aware optimization]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Toqeer Ali Syed, Abdulaziz Alshahrani, Ali Ullah, Ali Akarma, Sohail Khan, Muhammad Nauman, Salman Jan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Islamic University of Madinah, Effat University, Arab Open University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.20991",children:"https://arxiv.org/pdf/2512.20991"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes a novel agentic AI framework that integrates personal finance management with real-time diet optimization, addressing a gap in current tools. 2. Implements a modular multi-agent architecture with specialized agents (budgeting, nutrition, price monitoring, health personalization) that share a knowledge base and use a substitution graph for cost-effective meal planning. 3. Demonstrates through a case study simulation significant cost reduction (12-18%) and high nutrient adequacy (>95%) while maintaining robustness to market price fluctuations."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc1ddd8fc13f7437534fa058d5e3879ce0f82c07898d64ccb7548f0932948a8a_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc1ddd8fc13f7437534fa058d5e3879ce0f82c07898d64ccb7548f0932948a8a_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces FinAgent, an agentic AI framework that combines personal finance and real-time price data to generate nutritionally adequate meal plans at minimal cost. It uses a modular multi-agent system and a substitution graph to dynamically adapt to budget constraints and market changes. The system was validated in a simulation, showing significant cost savings and high nutritional adequacy, aligning with sustainable development goals."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[FinAgent] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: Limited budgets & nutritional demands with fluctuating food prices]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Price-aware agentic AI with multi-agent architecture & substitution graph]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: 12-18% cost reduction, >95% nutrient adequacy, robust to price changes]"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsxs)(n.strong,{children:["[arXiv251225] CoTDeceptor",":Adversarial"," Code Obfuscation Against CoT-Enhanced LLM Code Agents"]})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [sec], [software supply chain security], [adversarial obfuscation, chain-of-thought reasoning, LLM code agents, vulnerability detection, code poisoning]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Haoyang Li, Mingjin Li, Jinxin Zuo, Siqi Li, Xiao Li, Hao Wu, Yueming Lu, Xiaochuan He"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," Beijing University of Posts and Telecommunications, Institute of Information Engineering, Chinese Academy of Sciences, National Key Lab for Novel Software Technology, Nanjing University"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21250",children:"https://arxiv.org/pdf/2512.21250"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"code:"})," ",(0,r.jsx)(n.a,{href:"https://github.com/hiki9712/CoT-Code-Obfuscation",children:"https://github.com/hiki9712/CoT-Code-Obfuscation"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Identifies systematic weaknesses in the reasoning chains and semantic abstraction processes of CoT-enhanced LLM vulnerability detectors that can be exploited for evasion. 2. Proposes CoTDeceptor, the first adversarial code obfuscation framework designed to target and disrupt CoT-driven detection logic in LLMs. 3. Demonstrates superior evasion performance, with CoTDeceptor bypassing detection in 14 out of 15 vulnerability categories, significantly outperforming prior methods."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cefe211bbeb3689b53fe3c942123a9b959d545c2e5ca843e46619fd06066843b_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cefe211bbeb3689b53fe3c942123a9b959d545c2e5ca843e46619fd06066843b_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," This paper introduces CoTDeceptor, an adversarial code obfuscation framework that exploits weaknesses in Chain-of-Thought (CoT) reasoning used by LLM-based vulnerability detectors. It autonomously constructs multi-stage obfuscation strategies to embed malicious logic and evade detection. The results show it successfully bypasses most vulnerability categories, highlighting significant risks to software supply chain security and the need for more robust LLM-powered security systems."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[CoTDeceptor] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem: CoT-Enhanced LLM Detectors Have Exploitable Weaknesses];\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method: Adversarial Multi-Stage Code Obfuscation Framework];\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results: High Evasion Rate (14/15 Categories), Supply Chain Risk];"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"[arXiv251225] A Plan Reuse Mechanism for LLM-Driven Agent"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"tags:"})," [mlsys], [agent system], [plan reuse, semantic cache, intent classification, LLM-driven agent, latency reduction]"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"authors:"})," Guopeng Li, Ruiqi Wu, Haisheng Tan"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"institution:"})," University of Science and Technology of China"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"link:"})," ",(0,r.jsx)(n.a,{href:"https://arxiv.org/pdf/2512.21309",children:"https://arxiv.org/pdf/2512.21309"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"contributions:"})," 1. Proposes AgentReuse, a plan reuse mechanism for LLM-driven agents to reduce latency by reusing previously generated plans for similar requests. 2. Introduces an approach using intent classification and semantic analysis to accurately evaluate request similarity, overcoming challenges from diverse natural language expressions. 3. Demonstrates high effectiveness through real-world experiments, showing a 93% plan reuse rate and a 93.12% latency reduction compared to non-reuse baselines."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"thumbnail:"})," ",(0,r.jsx)(n.a,{href:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7df94c0cf5ebebedbde6da5050e515454a6b8b17388ca392a472240c8b1ec80_w640_q70.webp",children:"https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7df94c0cf5ebebedbde6da5050e515454a6b8b17388ca392a472240c8b1ec80_w640_q70.webp"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simple LLM Summary:"})," The paper addresses the high latency in LLM-driven agents caused by plan generation. It proposes AgentReuse, a mechanism that reuses plans for similar requests by evaluating semantic similarity through intent classification. Experiments show it significantly reduces latency while maintaining high accuracy in plan reuse."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mindmap:"})}),"\n",(0,r.jsx)(n.mermaid,{value:"graph LR\n    A[A Plan Reuse Mechanism for LLM-Driven Agent<br>LLM\u9a71\u52a8Agent\u7684\u8ba1\u5212\u91cd\u7528\u673a\u5236] --\x3e B[\u6838\u5fc3\u95ee\u9898/Problem]\n    A --\x3e C[\u4e3b\u8981\u65b9\u6cd5/Method]\n    A --\x3e D[\u5173\u952e\u7ed3\u679c/Results]\n    B --\x3e B1[LLM\u751f\u6210\u8ba1\u5212\u5ef6\u8fdf\u9ad8<br>High LLM Plan Generation Latency]\n    B --\x3e B2[\u8bf7\u6c42\u76f8\u4f3c\u6027\u96be\u5b9a\u4e49<br>Hard to Define Request Similarity]\n    C --\x3e C1[AgentReuse\u673a\u5236<br>AgentReuse Mechanism]\n    C1 --\x3e C2[\u610f\u56fe\u5206\u7c7b\u8bc4\u4f30\u8bed\u4e49\u76f8\u4f3c\u6027<br>Intent Classification for Semantic Similarity]\n    C1 --\x3e C3[\u91cd\u7528\u5386\u53f2\u8ba1\u5212<br>Reuse Historical Plans]\n    D --\x3e D1[93%\u6709\u6548\u91cd\u7528\u7387<br>93% Effective Reuse Rate]\n    D --\x3e D2[93.12%\u5ef6\u8fdf\u964d\u4f4e<br>93.12% Latency Reduction]"}),"\n"]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}}}]);