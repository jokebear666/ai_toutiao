<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251215-20251221" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251215-20251221 | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/20251215-20251221"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251215-20251221 | AI头条"><meta data-rh="true" name="description" content="2025-12-15"><meta data-rh="true" property="og:description" content="2025-12-15"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/20251215-20251221"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251215-20251221" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251215-20251221" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"20251215-20251221","item":"https://jokebear666.github.io/ai_toutiao/daily/20251215-20251221"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.cc04cc53.css">
<script src="/ai_toutiao/assets/js/runtime~main.25ffb784.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.d71a22b2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads"><div class="content-main"><div class="content-inner"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251215-20251221</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251215-20251221</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-15">2025-12-15<a href="#2025-12-15" class="hash-link" aria-label="Direct link to 2025-12-15" title="Direct link to 2025-12-15" translate="no">​</a></h2>
<p><strong>cs.DC total: 15</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251215] Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed network algorithms], [multi-packet messaging, pruning, closeness centrality, decentralized computation, message efficiency]</li>
<li class=""><strong>authors:</strong> Patrick D. Manya, Eugene M. Mbuyi, Gothy T. Ngoie, Jordan F. Masakuna</li>
<li class=""><strong>institution:</strong> University of Kinshasa</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11512" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11512</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper enhances a distributed pruning method for closeness centrality by using multi-packet messaging to batch data into larger blocks. This reduces the number of exchanged messages and improves communication efficiency, particularly for large networks, with a manageable trade-off in local memory overhead.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Seamless Transitions: A Comprehensive Review of Live Migration Technologies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [virtualization], [live migration, container migration, virtual machine migration, migration techniques, migration units, infrastructure characteristics]</li>
<li class=""><strong>authors:</strong> Sima Attar-Khorasani, Lincoln Sherpa, Matthias Lieber, Siavash Ghiasvand</li>
<li class=""><strong>institution:</strong> TUD Dresden University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10979" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10979</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper provides a comprehensive review of live migration technologies, focusing on container-based and virtual machine-based approaches. It analyzes migration techniques, units, and infrastructure, concluding that practical challenges and resource demands can sometimes outweigh the benefits, making implementation difficult to justify.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] An Efficient Approach for Energy Conservation in Cloud Computing Environment</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [cloud computing], [task scheduling, resource utilization, fitness value, multi-criteria energy-efficient task scheduling (MCEETS), MaxUtil]</li>
<li class=""><strong>authors:</strong> Sohan Kumar Pande, Sanjaya Kumar Panda, Preeti Ranjan Sahu</li>
<li class=""><strong>institution:</strong> Not specified</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10974" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10974</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a multi-criteria energy-efficient task scheduling (MCEETS) algorithm for cloud computing, which uses a fitness value based on CPU, disk, I/O utilization, and task processing time to improve resource utilization. Simulation results show that the proposed algorithm consumes less energy than the existing MaxUtil algorithm.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [dynamic scheduling, multi-objective scheduling, hybrid priority scheduler, predictive backfill, smart batch, fragmentation reduction, job starvation, GPU utilization]</li>
<li class=""><strong>authors:</strong> Akhmadillo Mamirov</li>
<li class=""><strong>institution:</strong> The College of Wooster</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10980</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces three dynamic multi-objective schedulers (Hybrid Priority, Predictive Backfill, and Smart Batch) designed to reduce fragmentation and starvation in GPU clusters. Through simulation, these schedulers significantly outperform static baselines in utilization, throughput, and fairness, demonstrating that adaptive scheduling can meaningfully improve GPU efficiency in heterogeneous AI clusters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] An LLVM-Based Optimization Pipeline for SPDZ</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [secure multiparty computation], [LLVM, SPDZ, secret sharing, batching, GPU kernels, non-blocking scheduler]</li>
<li class=""><strong>authors:</strong> Tianye Dai, Hammurabi Mendes, Heuichan Lim</li>
<li class=""><strong>institution:</strong> Davidson College</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11112" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11112</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an LLVM-based compiler pipeline for the SPDZ MPC protocol, which uses C with privacy annotations and LLVM IR to automatically batch operations and a runtime scheduler to overlap communication and computation, including GPU kernel mapping. The evaluation shows significant speedups over MP-SPDZ, indicating that leveraging LLVM with protocol-aware scheduling is effective for extracting parallelism without sacrificing usability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Dora: QoE-Aware Hybrid Parallelism for Distributed Edge AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [hybrid parallelism, data parallelism, pipeline parallelism, model partitioning, network scheduling, runtime adaptation]</li>
<li class=""><strong>authors:</strong> Jianli Jin, Ziyang Lin, Qianli Dong, Yi Chen, Jayanth Srinivasa, Myungjin Lee, Zhaowei Tan, Fan Lai</li>
<li class=""><strong>institution:</strong> UIUC, Northwestern University, University of California, Riverside, Cisco Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10990" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10990</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dora is a framework that uses heterogeneity-aware model partitioning, contention-aware network scheduling, and a runtime adapter to achieve QoE-aware hybrid parallelism for distributed edge AI. It demonstrates significant improvements in execution speed and energy efficiency while maintaining quality of experience under dynamic runtime conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [GPU-native compilation, parallel traditional compilation, neural compilation, sequence-to-sequence translation, probabilistic verification, hybrid architecture, in-VRAM iteration]</li>
<li class=""><strong>authors:</strong> Adilet Metinov, Gulida M. Kudakeeva, Gulnara D. Kabaeva</li>
<li class=""><strong>institution:</strong> Institute of Information Technology, Kyrgyz State Technical University named after I. Razzakov</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11200" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11200</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper establishes theoretical foundations for three GPU-native compilation approaches—parallel traditional, neural, and hybrid—to eliminate CPU-GPU data transfers during code iteration cycles. It demonstrates that these methods can achieve 10-100x speedups by keeping compilation and execution entirely in GPU memory. The main conclusion is that GPU-native compilation offers a path to drastically reduce latency and energy consumption in AI code generation systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [cluster scheduling, disaggregated architecture, co-execution group, two-tier scheduling, round-robin, warm-start context switching]</li>
<li class=""><strong>authors:</strong> Tianyuan Wu, Lunxi Cao, Yining Wei, Wei Gao, Yuheng Zhao, Dakai An, Shaopan Xiong, Zhiqiang Lv, Ju Huang, Siran Yang, Yinghao Yu, Jiamang Wang, Lin Qu, Wei Wang</li>
<li class=""><strong>institution:</strong> Hong Kong University of Science and Technology, UIUC, Alibaba Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11306" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11306</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces RollMux, a cluster scheduling framework that improves efficiency in disaggregated RL post-training by multiplexing jobs to utilize idle phases. Its core method involves a two-tier scheduler and a co-execution group abstraction to orchestrate cross-cluster execution. The evaluation shows RollMux significantly improves cost efficiency over standard disaggregated and co-located baselines while maintaining service-level objectives.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical federated learning, aggregated federated learning, continual federated learning, decentralized aggregation, gossip-based protocols]</li>
<li class=""><strong>authors:</strong> Sumit Chongder</li>
<li class=""><strong>institution:</strong> Maharashtra Institute of Technology - Art, Design and Technology University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10987" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10987</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an evaluation framework to compare centralized and decentralized aggregation algorithms in federated learning systems. It finds that decentralized methods (Aggregated and Continual Federated Learning) outperform centralized Hierarchical Federated Learning in metrics like precision and recall on standard datasets, highlighting the advantages of distributed computation and aggregation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Agentic Operator Generation for ML ASICs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [GPU kernels], [Triton, ATen kernels, PyTorch OpInfo, JIT compilation, large language models, agentic AI, kernel generation]</li>
<li class=""><strong>authors:</strong> Alec M. Hammond, Aram Markosyan, Aman Dontula, Simon Mahns, Zacharias Fisches, Dmitrii Pedchenko, Keyur Muzumdar, Natacha Supper, Mark Saroufim, Joe Isaacson, Laura Wang, Warren Hunt, Kaustubh Gondkar, Roman Levenstein, Gabriel Synnaeve, Richard Li, Jacob Kahn, Ajit Mathews</li>
<li class=""><strong>institution:</strong> Meta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.10977" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.10977</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents TritorX, an agentic AI system that uses large language models combined with a custom linter, JIT compilation, and a PyTorch OpInfo test harness to automatically generate functionally correct Triton ATen kernels for ML accelerators like MTIA. The system prioritizes broad operator coverage over performance for a limited set, successfully generating kernels for 481 unique operators that pass over 20,000 tests. This approach enables the rapid overnight generation of complete PyTorch ATen backends for new accelerator platforms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [runtime parallelization, branch-aware memory management, adaptive scheduling, DAG partitioning, buffer reuse, heterogeneous inference]</li>
<li class=""><strong>authors:</strong> Chong Tang, Hao Dai, Jagmohan Chauhan</li>
<li class=""><strong>institution:</strong> University of Southampton, University College London</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11532" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11532</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Parallax is a framework that accelerates mobile DNN inference by partitioning the computation graph to expose parallelism and using branch-aware memory management with adaptive scheduling to handle operator fallbacks. It reduces latency by up to 46% and energy consumption by up to 30% compared to state-of-the-art frameworks, while controlling memory overhead, without requiring model refactoring.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [continuous learning, camera grouping, GPU allocation, transmission control, cross-camera correlation]</li>
<li class=""><strong>authors:</strong> Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste</li>
<li class=""><strong>institution:</strong> Carnegie Mellon University, Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11727" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11727</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ECCO is a video analytics framework that improves resource efficiency by grouping cameras with similar data drift patterns to share retrained models. It uses a dynamic grouping algorithm, GPU allocator, and transmission controller to reduce compute and communication costs. The system increases retraining accuracy by 6.7%-18.1% or supports 3.3x more cameras at the same accuracy compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Stateless Snowflake: A Cloud-Agnostic Distributed ID Generator Using Network-Derived Identity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [distributed systems], [Snowflake algorithm, network-derived identity, private IPv4 address, bit-allocation scheme (1-41-16-6), stateless microservices, container orchestration]</li>
<li class=""><strong>authors:</strong> Manideep Reddy Chinthareddy</li>
<li class=""><strong>institution:</strong> Independent researcher (based on email domain)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11643" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11643</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a stateless, cloud-agnostic distributed ID generator that eliminates the need for explicit worker IDs by deriving node uniqueness from a container&#x27;s private IPv4 address. It introduces a modified bit-allocation scheme to incorporate this network-derived entropy while preserving monotonicity. The method demonstrates performance comparable to traditional stateful generators while offering improved scalability and operational simplicity in containerized environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] FirecREST v2: lessons learned from redesigning an API for scalable HPC resource access</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [HPC resource access], [RESTful API, performance testing, proxy-based APIs, I/O bottlenecks, architectural redesign, security, authorization]</li>
<li class=""><strong>authors:</strong> Elia Palme, Juan Pablo Dorsch, Ali Khosravi, Giovanni Pizzi, Francesco Pagnamenta, Andrea Ceriani, Eirini Koutsaniti, Rafael Sarmiento, Ivano Bonesana, Alejandro Dabin</li>
<li class=""><strong>institution:</strong> CSCS – Swiss National Supercomputing Centre, PSI Center for Scientific Computing, Theory, and Data</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11634" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11634</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents FirecREST v2, a redesigned RESTful API for programmatic access to HPC resources, focusing on integrating enhanced security and high throughput. Through systematic performance testing, the authors identified and addressed bottlenecks in proxy-based APIs, achieving a ~100x performance improvement. The key conclusion is that a ground-up architectural redesign was necessary to meet growing user demands for scalable and secure HPC resource access.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251215] Hypergraph based Multi-Party Payment Channel</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [blockchain scalability], [hypergraph, payment channel networks, multi-party channels, off-chain scaling, DAG updates]</li>
<li class=""><strong>authors:</strong> Ayush Nainwal, Atharva Kamble, Nitin Awathare</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology, Jodhpur; Indian Institute of Technology, Bombay</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.11775" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.11775</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Hypergraph-based Multi-Party Payment Channels (H-MPCs), a new off-chain construction that replaces traditional bilateral channels with collectively funded hyperedges to enable leaderless, concurrent payments. This design addresses liquidity fragmentation and channel depletion in existing payment networks. An implementation demonstrates a high transaction success rate of approximately 94%, highlighting the robustness of the approach.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 16</strong></p>
<ul>
<li class="">[arXiv251215] Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning <a href="https://arxiv.org/pdf/2512.11179" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Motif-2-12.7B-Reasoning: A Practitioner&#x27;s Guide to RL Training Recipes <a href="https://arxiv.org/pdf/2512.11463" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Rethinking Expert Trajectory Utilization in LLM Post-training <a href="https://arxiv.org/pdf/2512.11470" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] In-Context Multi-Objective Optimization <a href="https://arxiv.org/pdf/2512.11114" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents <a href="https://arxiv.org/pdf/2512.11277" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits <a href="https://arxiv.org/pdf/2512.11345" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance <a href="https://arxiv.org/pdf/2512.11421" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control <a href="https://arxiv.org/pdf/2512.11247" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Three methods, one problem: Classical and AI approaches to no-three-in-line <a href="https://arxiv.org/pdf/2512.11469" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound <a href="https://arxiv.org/pdf/2512.11169" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation <a href="https://arxiv.org/pdf/2512.11270" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning <a href="https://arxiv.org/pdf/2512.11342" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization <a href="https://arxiv.org/pdf/2512.11391" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry <a href="https://arxiv.org/pdf/2512.11558" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Agile Flight Emerges from Multi-Agent Competitive Racing <a href="https://arxiv.org/pdf/2512.11781" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Marti-5: A Mathematical Model of &quot;Self in the World&quot; as a First Step Toward Self-Awareness <a href="https://arxiv.org/pdf/2512.10985" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 6</strong></p>
<ul>
<li class="">[arXiv251215] A Scalable Multi-GPU Framework for Encrypted Large-Model Inference <a href="https://arxiv.org/pdf/2512.11269" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling <a href="https://arxiv.org/pdf/2512.11187" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee <a href="https://arxiv.org/pdf/2512.11127" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise <a href="https://arxiv.org/pdf/2512.11282" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning <a href="https://arxiv.org/pdf/2512.11342" target="_blank" rel="noopener noreferrer" class="">link</a></li>
<li class="">[arXiv251215] Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration <a href="https://arxiv.org/pdf/2512.11587" target="_blank" rel="noopener noreferrer" class="">link</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-18">2025-12-18<a href="#2025-12-18" class="hash-link" aria-label="Direct link to 2025-12-18" title="Direct link to 2025-12-18" translate="no">​</a></h2>
<p><strong>cs.DC total: 3</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251218] Privacy-Preserving Feature Valuation in Vertical Federated Learning Using Shapley-CMI and PSI Permutation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Shapley-CMI, Private Set Intersection, Conditional Mutual Information, Vertical Federated Learning, data valuation]</li>
<li class=""><strong>authors:</strong> Unai Laskurain, Aitor Aguirre-Ortuzar, Urko Zurutuza</li>
<li class=""><strong>institution:</strong> Mondragon Unibertsitatea</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14767" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14767</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a privacy-preserving method for evaluating feature contributions in Vertical Federated Learning (VFL) using Shapley-CMI and a Private Set Intersection (PSI) server to compute encrypted intersection sizes without sharing raw data. The system enables secure and fair data valuation before model training. Initial experiments confirm the approach&#x27;s correctness and privacy, demonstrating its viability for secure feature contribution estimation in VFL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [8-bit training, activation checkpointing, offloading, copy-engine collectives, dynamic tensor-level scaling, ZeRO-1]</li>
<li class=""><strong>authors:</strong> Erik Schultheis, Dan Alistarh</li>
<li class=""><strong>institution:</strong> IST Austria</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15306" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15306</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLMQ is an end-to-end CUDA/C++ framework that enables efficient 8-bit pretraining and fine-tuning of medium-sized language models on consumer GPUs by employing optimizations like activation checkpointing, offloading, and copy-engine based collectives to overcome memory and communication bottlenecks. It demonstrates that models up to 32B parameters can be trained on affordable hardware like a 4xRTX 4090 workstation while maintaining high FLOP utilization, rivaling the efficiency of production systems on more expensive cloud-grade GPUs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Dynamic Rebatching for Efficient Early-Exit Inference with DREX</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [early-exit, dynamic rebatching, copy-free buffer, SLA-aware scheduler, KV cache, state-copying]</li>
<li class=""><strong>authors:</strong> Xuting Liu, Daniel Alexander, Siva Kesava Reddy Kakarla, Behnaz Arzani, Vincent Liu</li>
<li class=""><strong>institution:</strong> University of Pennsylvania, Microsoft Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15705" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15705</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Dynamic Rebatching and the DREX system to efficiently batch requests in Early-Exit LLMs, where tokens can exit at different layers. DREX dynamically reorganizes batches at exit points using a copy-free buffer and a predictive scheduler, improving throughput by 2-12% while eliminating involuntary exits and preserving output quality.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251218] A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [Latent Class Reinforcement Learning (LCRL), Variational Bayes, Bayesian estimation, discrete choice models]</li>
<li class=""><strong>authors:</strong> Georges Sfeir, Stephane Hess, Thomas O. Hancock, Filipe Rodrigues, Jamal Amani Rad, Michiel Bliemer, Matthew Beck, Fayyaz Khan</li>
<li class=""><strong>institution:</strong> University of Leeds, Technical University of Denmark, University of Sydney, Al Yamamah University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14713" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14713</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Latent Class Reinforcement Learning (LCRL) model, estimated using Variational Bayes, to capture how travelers adapt their preferences through experience. The application to a driving simulator dataset reveals three distinct behavioral classes, showing heterogeneity in how individuals balance exploration and exploitation in their travel decisions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [Quantum Decision Transformer, Quantum-Inspired Attention, Quantum Feedforward Networks, entanglement, interference, offline reinforcement learning, Decision Transformer]</li>
<li class=""><strong>authors:</strong> Abraham Itzhak Weinberg</li>
<li class=""><strong>institution:</strong> AI-WEINBERG, AI Experts</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14726</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Quantum Decision Transformer (QDT), a novel architecture that integrates quantum-inspired attention with entanglement and quantum feedforward networks with interference to improve offline reinforcement learning. It demonstrates a dramatic performance improvement over standard Decision Transformers and shows that the synergy between its quantum-inspired components is crucial for its success.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [machine learning theory], [Bregman projection, entropy reservoir, information geometry, model collapse, self-referential learning]</li>
<li class=""><strong>authors:</strong> Jingwei Chen</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14879" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14879</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Entropy-Reservoir Bregman Projection (ERBP) framework, which models self-referential learning as a stochastic Bregman projection sequence in distribution space. It shows that injecting an entropy reservoir stabilizes the dynamics and prevents model collapse, unifying various empirical fixes into a single quantitative design rule.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Puzzle Curriculum GRPO for Vision-Centric Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [PC-GRPO, RL with Verifiable Rewards, self-supervised puzzle environments, difficulty-aware curriculum, reasoning-answer consistency]</li>
<li class=""><strong>authors:</strong> Ahmadreza Jeddi, Hakki Can Karaimer, Hue Nguyen, Zhongling Wang, Ke Zhao, Javad Rajabi, Ran Zhang, Raghav Goyal, Babak Taati, Radek Grzeszczuk</li>
<li class=""><strong>institution:</strong> Samsung Electronics, University of Toronto, Vector Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14944" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14944</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Puzzle Curriculum GRPO (PC-GRPO), a supervision-free reinforcement learning method that uses self-supervised puzzle environments and a difficulty-aware curriculum to improve visual reasoning in vision language models. It enhances reasoning quality, training stability, and downstream accuracy without relying on annotations or external verifiers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [adaptive partitioning, model-based algorithm, diffusion processes, regret bounds, zooming dimension]</li>
<li class=""><strong>authors:</strong> Hanqing Jin, Renyuan Xu, Yanzhao Yang</li>
<li class=""><strong>institution:</strong> University of Oxford, Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14991" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14991</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a model-based reinforcement learning algorithm that adaptively partitions the state-action space for controlled diffusion processes with unbounded continuous states. It refines partitions based on estimation bias versus statistical confidence, achieving regret bounds that extend to unbounded domains. The approach is validated through numerical experiments, including high-dimensional portfolio selection.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Spectral Representation-based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [spectral representations, spectral decomposition, transition operator, partially observable MDPs, model-free, model-based]</li>
<li class=""><strong>authors:</strong> Chenxiao Gao, Haotian Sun, Na Li, Dale Schuurmans, Bo Dai</li>
<li class=""><strong>institution:</strong> Georgia Tech, Harvard University, Google DeepMind, University of Alberta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15036" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15036</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces spectral representations, derived from the spectral decomposition of the transition operator, as a framework for reinforcement learning to address issues like theoretical ambiguity and optimization instability. It shows how to construct these representations for different system structures and extends the approach to partially observable environments. The proposed algorithms achieve performance comparable to or better than state-of-the-art methods on over 20 challenging control tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [cognitive-inspired elastic reasoning, markov decision process, reinforcement learning, chain-of-thought, tool-assisted reasoning]</li>
<li class=""><strong>authors:</strong> Jinwu Hu, Dongjin Yang, Langyu Bian, Zhiquan Wen, Yufeng Wang, Yaofo Chen, Bin Xiao, Yuanqing Li, Mingkui Tan</li>
<li class=""><strong>institution:</strong> South China University of Technology, Pazhou Laboratory, Peng Cheng Laboratory, Chongqing University of Posts and Telecommunications</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15089" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15089</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes CogER, a framework that dynamically selects reasoning strategies for LLMs based on query complexity, modeled as a Markov Decision Process and trained with reinforcement learning. It introduces Cognitive Tool-Assisted Reasoning for autonomous tool use within reasoning chains. Experiments show CogER outperforms state-of-the-art methods, improving exact match scores by at least 13% on in-domain and 8% on out-of-domain tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Automatic Reward Shaping from Multi-Objective Human Heuristics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reward shaping, multi-objective optimization, bi-level optimization, stochastic exploration]</li>
<li class=""><strong>authors:</strong> Yuqing Xie, Jiayu Chen, Wenhao Tang, Ya Zhang, Chao Yu, Yu Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15120" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15120</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MORSE, a framework that automatically combines multiple human-designed heuristic rewards into a unified reward function using bi-level optimization with stochastic exploration. It effectively balances conflicting objectives in robotic tasks, achieving performance comparable to manually tuned rewards in MuJoCo and Isaac Sim environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [BEV-grounding, Chain-of-Thought, reinforcement learning, determinantal point process, keyframe selection, spatial reward, pose querying]</li>
<li class=""><strong>authors:</strong> Jiaxu Wan, Xu Wang, Mengwei Xie, Hang Zhang, Mu Xu, Yang Han, Hong Zhang, Ding Yuan, Yifan Yang</li>
<li class=""><strong>institution:</strong> BUAA (Beihang University)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15160" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15160</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EagleVision introduces a dual-stage framework for spatial reasoning, combining a macro perception stage for selecting keyframes and a micro verification stage that uses BEV-grounded pose querying and reinforcement learning. It achieves state-of-the-art performance on VSI-Bench, demonstrating strong and generalizable spatial understanding.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [reinforcement learning with verifiable rewards, progressive prefix-token policy optimization, beginning lock-in effect, prefix optimization, continuation accumulated reward]</li>
<li class=""><strong>authors:</strong> Yiliu Sun, Zicheng Zhao, Yang Wei, Yanfang Zhang, Chen Gong</li>
<li class=""><strong>institution:</strong> Nanjing University of Science and Technology, North University of China, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15274" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15274</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Progressive Prefix-token Policy Optimization (PPPO), a reinforcement learning method that focuses on optimizing the initial prefix tokens of an LLM&#x27;s reasoning output, based on the identified Beginning Lock-in Effect. It introduces strategies like Progressive Prefix Retention and Continuation Accumulated Reward to improve training efficiency. The method achieves significant accuracy improvements on reasoning tasks while using far fewer training tokens compared to standard approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [formal methods], [reinforcement learning, graph neural networks, labeled transition system, exploration policy]</li>
<li class=""><strong>authors:</strong> Toshihide Ubukata, Enhong Mu, Takuto Yamauchi, Mingyue Zhang, Jialong Li, Kenji Tei</li>
<li class=""><strong>institution:</strong> Waseda University, Southwest University, Institute of Science Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15295" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15295</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces GCRL, a method that enhances reinforcement learning for controller synthesis by integrating Graph Neural Networks to encode exploration history into a graph for broader context. It demonstrates superior learning efficiency and generalization compared to state-of-the-art methods in most benchmark domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [bayesian reinforcement learning, epistemic uncertainty, minimax-optimal regret, sample complexity, infinite-horizon MDPs]</li>
<li class=""><strong>authors:</strong> Jianfei Ma, Wee Sun Lee</li>
<li class=""><strong>institution:</strong> National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15405" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15405</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes EUBRL, a Bayesian reinforcement learning algorithm that uses epistemic uncertainty to guide exploration and reduce per-step regret. It provides theoretical guarantees for regret and sample complexity and demonstrates superior sample efficiency and scalability in sparse-reward, long-horizon tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [feature model-based reinforcement learning, actor-critic, Dyna-Q, model-based RL, model-free RL, multi-task control]</li>
<li class=""><strong>authors:</strong> Quanxi Zhou, Wencan Mao, Manabu Tsukada, John C.S. Lui, Yusheng Ji</li>
<li class=""><strong>institution:</strong> The University of Tokyo, National Institute of Informatics, The Chinese University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15430" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15430</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FM-EAC, a feature model-based enhanced actor-critic algorithm that integrates planning, acting, and learning for multi-task control. It combines model-based and model-free reinforcement learning to improve generalizability across tasks. Simulations show it outperforms state-of-the-art methods in urban and agricultural applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Double Horizon Model-Based Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [model-based reinforcement learning, policy optimization, distribution rollout, training rollout, double horizon]</li>
<li class=""><strong>authors:</strong> Akihiro Kubo, Paavo Parmas, Shin Ishii</li>
<li class=""><strong>institution:</strong> Advanced Telecommunications Research Institute, Kyoto University, The University of Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15439</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Double Horizon Model-Based Policy Optimization (DHMBPO), a method that separates the model rollout process into a long &quot;distribution rollout&quot; to mitigate distribution shift and a short &quot;training rollout&quot; for stable gradient estimation. This approach balances model bias and gradient variance. The method demonstrates superior sample efficiency and runtime compared to existing MBRL methods on continuous-control benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [language models], [autoregressive models, energy-based models, soft Bellman equation, maximum entropy reinforcement learning, distillation]</li>
<li class=""><strong>authors:</strong> Mathieu Blondel, Michael E. Sander, Germain Vivier-Ardisson, Tianlin Liu, Vincent Roulet</li>
<li class=""><strong>institution:</strong> Google DeepMind</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15605</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper establishes a formal bijection between autoregressive language models (ARMs) and energy-based models (EBMs) in function space, showing this equivalence corresponds to a special case of the soft Bellman equation in maximum entropy RL. It demonstrates the equivalence of their supervised learning and provides theoretical error bounds for distilling an EBM into an ARM. The results explain how ARMs, despite being trained on next-token prediction, can implicitly perform lookahead planning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reasoning and self-critique], [stepwise think-critique, reinforcement learning, self-critique, chain of thought, process reward models]</li>
<li class=""><strong>authors:</strong> Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan LU</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China, Microsoft Research Asia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15662" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15662</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single large language model, trained using a hybrid reinforcement learning objective. Experiments on mathematical reasoning benchmarks show that STC enhances critical thinking capabilities and produces more interpretable reasoning traces.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [gradient-guided reinforcement learning, G2RL, PPO, KL control, final-layer sensitivity]</li>
<li class=""><strong>authors:</strong> Zhenwen Liang, Sidi Lu, Wenhao Yu, Kishan Panaganti, Yujun Zhou, Haitao Mi, Dong Yu</li>
<li class=""><strong>institution:</strong> Tencent AI Lab, University of Notre Dame</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15687</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces G2RL, a gradient-guided reinforcement learning framework that uses the model&#x27;s own gradient directions to guide exploration, rather than external heuristics like entropy bonuses. It shows that G2RL improves reasoning performance across multiple benchmarks by encouraging diverse and orthogonal update directions. The results indicate that a policy&#x27;s internal update geometry provides a more effective basis for exploration in LLM reinforcement learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical deep reinforcement learning, double deep Q-network, constrained soft actor-critic, Lagrangian multipliers, centralized training and decentralized execution]</li>
<li class=""><strong>authors:</strong> Jiayang Wan, Ke He, Yafei Wang, Fan Liu, Wenjin Wang, Shi Jin</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories, University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15119" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15119</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a two-level hierarchical deep reinforcement learning framework for joint link selection and trajectory optimization in UAV mobility management within SAGIN. The method uses a top-level DDQN for discrete link selection and a lower-level constrained SAC with Lagrangian multipliers for continuous trajectory optimization under QoS constraints. Simulation results show the proposed scheme outperforms benchmarks in throughput, link switching frequency, and QoS satisfaction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, deep learning surrogate model, digital twin, autonomous control, pressure control]</li>
<li class=""><strong>authors:</strong> Guillermo Rodriguez-Llorente, Galo Gallardo, Rodrigo Morant Navascués, Nikita Khvatkin Petrovsky, Anderson Sabogal, Roberto Gómez-Espinosa Martín</li>
<li class=""><strong>institution:</strong> HI Iberia, Universidad Carlos III de Madrid, IFMIF-DONES Spain</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15521" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15521</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a fully data-driven approach for autonomous pressure control in a particle accelerator prototype. It uses a deep learning surrogate model as a digital twin to emulate system dynamics and trains a deep reinforcement learning agent within this simulation. The agent successfully learns a control policy to maintain pressure within strict operational limits, advancing intelligent autonomous control for next-generation accelerator facilities.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 8</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251218] A Roadmap for Applying Graph Neural Networks to Numerical Data: Insights from Cementitious Materials</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [graph neural network, k-nearest neighbor, random forest, hyperparameter optimization, feature selection]</li>
<li class=""><strong>authors:</strong> Mahmuda Sharmin, Taihao Han, Jie Huang, Narayanan Neithalath, Gaurav Sant, Aditya Kumar</li>
<li class=""><strong>institution:</strong> Missouri University of Science and Technology, Arizona State University, University of California, Los Angeles</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14855" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14855</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method for applying Graph Neural Networks (GNNs) to numerical data in cementitious materials research by converting tabular data into graph representations using the k-nearest neighbor approach. The study systematically optimizes model hyperparameters and feature selection, finding that the GNN&#x27;s performance is comparable to a benchmark random forest model. The work establishes a foundational roadmap for transitioning to advanced, multi-modal, and physics-informed AI architectures for material design.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [neural network activation functions], [Fourier Analysis Network, Dual-Activation Layer, sine activation, gradient analysis, dying-ReLU problem]</li>
<li class=""><strong>authors:</strong> Sam Jeong, Hae Yong Kim</li>
<li class=""><strong>institution:</strong> University of São Paulo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14873" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14873</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper analyzes the mechanism of the Fourier Analysis Network (FAN) and finds its benefit stems from the sine function&#x27;s non-zero derivative near zero, which mitigates vanishing gradients and the dying-ReLU problem. Based on this insight, the authors propose a new Dual-Activation Layer (DAL) that accelerates convergence and achieves equal or higher accuracy than conventional activations in evaluated tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] PIP<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> Net: Physics-informed Partition Penalty Deep Operator Network</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific machine learning], [operator learning, DeepONet, partition-of-unity, physics-informed neural networks, regularization, Burgers equation, Allen-Cahn equation]</li>
<li class=""><strong>authors:</strong> Hongjin Mi, Huiqiang Lun, Changhong Mou, Yeyu Zhang</li>
<li class=""><strong>institution:</strong> Shanghai University of Finance and Economics, York University, Utah State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15086</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes PIP² Net, a physics-informed operator learning network that introduces a simplified partition penalty based on partition-of-unity methods to regularize and stabilize trunk-network features in DeepONet. The method is evaluated on nonlinear PDEs like Burgers and Allen-Cahn equations, where it consistently outperforms baseline models in prediction accuracy and robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computational catalysis], [deep generative model, periodic Brownian-bridge, equivariant graph neural network, DFT relaxation, adsorption energy, outlier detection]</li>
<li class=""><strong>authors:</strong> Songze Huo, Xiao-Ming Cao</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15228" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15228</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces DBCata, a deep generative model that combines a periodic Brownian-bridge framework with an equivariant graph neural network to directly generate equilibrium adsorption structures from unrelaxed ones, bypassing explicit energy or force calculations. It achieves high-fidelity geometry generation and improves DFT accuracy, enabling accelerated high-throughput screening for catalysts like those in the oxygen reduction reaction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [long-context fine-tuning, sequential bucketed strategy, tool-integrated reasoning, multi-mode supervision, dataset distillation]</li>
<li class=""><strong>authors:</strong> Wei Du, Shubham Toshniwal, Branislav Kisacanin, Sadegh Mahdavi, Ivan Moshkov, George Armstrong, Stephen Ge, Edgar Minasyan, Feng Chen, Igor Gitman</li>
<li class=""><strong>institution:</strong> NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15489" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15489</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Nemotron-Math, a large-scale mathematical reasoning dataset generated using the multi-mode capabilities of gpt-oss-120b, featuring diverse reasoning styles and Python tool integration. The authors also propose a sequential bucketed strategy to accelerate long-context fine-tuning. The dataset enables state-of-the-art performance on mathematical benchmarks, achieving 100% accuracy on AIME 2024/2025 with tool-integrated reasoning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Restless Multi-Process Multi-Armed Bandits with Applications to Self-Driving Microscopies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [decision theory], [restless multi-armed bandits, Whittle index, Markov chains, Thompson Sampling, Bayesian UCB, epsilon-Greedy]</li>
<li class=""><strong>authors:</strong> Jaume Anguera Peris, Songtao Cheng, Hanzhao Zhang, Wei Ouyang, Joakim Jaldén</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, SciLifeLab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14930" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14930</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Restless Multi-Process Multi-Armed Bandit (RMPMAB) framework, which models experimental regions as ensembles of Markov chains to capture biological heterogeneity. It derives closed-form expressions for process behavior and designs scalable Whittle index policies. The method significantly outperforms existing bandit algorithms in simulations and live-cell imaging, capturing more biological events and reducing regret, demonstrating its potential for autonomous smart microscopy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep reinforcement learning, deep learning surrogate model, digital twin, autonomous control, pressure control]</li>
<li class=""><strong>authors:</strong> Guillermo Rodriguez-Llorente, Galo Gallardo, Rodrigo Morant Navascués, Nikita Khvatkin Petrovsky, Anderson Sabogal, Roberto Gómez-Espinosa Martín</li>
<li class=""><strong>institution:</strong> HI Iberia, Universidad Carlos III de Madrid, IFMIF-DONES Spain</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15521" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15521</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a fully data-driven approach for autonomous pressure control in a particle accelerator prototype. It uses a deep learning surrogate model as a digital twin to emulate system dynamics and trains a deep reinforcement learning agent within this simulation. The agent successfully learns a control policy to maintain pressure within strict operational limits, advancing intelligent autonomous control for next-generation accelerator facilities.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Photonics-Enhanced Graph Convolutional Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [photonic positional embeddings, graph convolutional networks, synthetic frequency lattices, intensity correlation matrices, hybrid photonic-electronic workflow]</li>
<li class=""><strong>authors:</strong> Yuan Wang, Oleksandr Kyriienko</li>
<li class=""><strong>institution:</strong> University of Sheffield</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15549" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15549</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid workflow that enhances Graph Convolutional Networks (GCNs) by using photonic positional embeddings derived from simulating light propagation on synthetic frequency lattices that match the input graph structure. The method generates internode intensity correlation matrices to provide global structural information to the GCN. The results show that these photonic embeddings outperform baseline Laplacian-based embeddings on molecular graph benchmarks, improving regression and classification performance, and support the potential for optical acceleration in graph machine learning.</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-18T07:21:37.000Z" itemprop="dateModified">Dec 18, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/20251208-20251214"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251208-20251214</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-15" class="table-of-contents__link toc-highlight">2025-12-15</a></li><li><a href="#2025-12-18" class="table-of-contents__link toc-highlight">2025-12-18</a></li></ul></div></div></div></div></div><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div>
</body>
</html>