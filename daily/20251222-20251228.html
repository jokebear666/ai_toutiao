<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251222-20251228" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251222-20251228 | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/20251222-20251228"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251222-20251228 | AI头条"><meta data-rh="true" name="description" content="2025-12-22"><meta data-rh="true" property="og:description" content="2025-12-22"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/20251222-20251228"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251222-20251228" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251222-20251228" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"20251222-20251228","item":"https://jokebear666.github.io/ai_toutiao/daily/20251222-20251228"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.84a25bac.css">
<script src="/ai_toutiao/assets/js/runtime~main.36d5e77f.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.e61b1501.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251222-20251228</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251222-20251228</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-22">2025-12-22<a href="#2025-12-22" class="hash-link" aria-label="Direct link to 2025-12-22" title="Direct link to 2025-12-22" translate="no">​</a></h2>
<p><strong>cs.DC total: 4</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251222] Dion2: A Simple Method to Shrink Matrix in Muon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Muon optimizer, orthonormalization, matrix shrinking, sampling, Newton-Schulz iterations, FSDP2]</li>
<li class=""><strong>authors:</strong> Kwangjun Ahn, Noah Amsel, John Langford</li>
<li class=""><strong>institution:</strong> Microsoft Research, AI Frontiers, NYU</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16928</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Dion2, a simple method to reduce the computational cost of the Muon optimizer by sampling a fraction of rows or columns for orthonormalization at each iteration. This sparsifies the update, lowering computation and communication overhead. The method maintains update quality close to full Muon while improving scalability, as shown in training benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated learning, byzantine-robust aggregation, privacy-preserving, dimensionality reduction, secure multi-party computation, adaptive tuning]</li>
<li class=""><strong>authors:</strong> Baolei Zhang, Minghong Fang, Zhuqing Liu, Biao Yi, Peizhao Zhou, Yuan Wang, Tong Li, Zheli Liu</li>
<li class=""><strong>institution:</strong> Nankai University, University of Louisville, University of North Texas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ABBR, a practical framework for federated learning that combines Byzantine-robust aggregation with privacy-preserving techniques. Its core method uses dimensionality reduction to speed up private computations and an adaptive tuning strategy to minimize the impact of malicious models. The framework is shown to run significantly faster with minimal overhead while maintaining strong Byzantine resilience.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adaptive graph pruning, Spatio-Temporal Graph Neural Networks (ST-GNNs), Sudden Event Prediction Accuracy (SEPA), online semi-decentralized training, Federated Learning (FL), Gossip Learning]</li>
<li class=""><strong>authors:</strong> Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas</li>
<li class=""><strong>institution:</strong> University of Zagreb, Faculty of Electrical Engineering and Computing; RISE Research Institutes of Sweden; KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an adaptive graph pruning algorithm for Spatio-Temporal Graph Neural Networks (ST-GNNs) to reduce communication overhead in online semi-decentralized traffic prediction systems. It also introduces a novel evaluation metric, SEPA, to measure responsiveness to sudden traffic events. The method maintains prediction accuracy while significantly lowering communication costs across different decentralized learning settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [GPU-internal scheduling, resource sharing, collaborative multi-GPU video decoding, logically decoupled execution, FlashCodec, UnifiedServe]</li>
<li class=""><strong>authors:</strong> Lingxiao Zhao, Haoran Zhou, Yuezhi Che, Dazhao Cheng</li>
<li class=""><strong>institution:</strong> Wuhan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17574" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17574</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65d961bcef453cdff273d0991a97111419acf476f8d34e21f66dbd356156dfa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65d961bcef453cdff273d0991a97111419acf476f8d34e21f66dbd356156dfa7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlashCodec and UnifiedServe, a framework that optimizes multimodal large language model (MLLM) serving by accelerating video decoding and enabling resource sharing across the vision and text stages. This approach reduces latency and eliminates inter-stage blocking, leading to significantly higher throughput and better SLO adherence compared to existing systems.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 25</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251222] Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [Proximal Policy Optimization (PPO), Group Relative Policy Optimization (GRPO), turn-level MDP, advantage estimation, multi-turn RL]</li>
<li class=""><strong>authors:</strong> Junbo Li, Peng Zhou, Rui Meng, Meet P. Vadera, Lihong Li, Yang Li</li>
<li class=""><strong>institution:</strong> The University of Texas at Austin, Amazon</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17008" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17008</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Turn-PPO, a reinforcement learning method that applies Proximal Policy Optimization at the turn level instead of the token level for training LLM agents in multi-turn tasks. It demonstrates that this approach is more robust and effective than the commonly used GRPO method, particularly for long-horizon reasoning scenarios, as validated on the WebShop and Sokoban datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific ai evaluation], [Practical Inquiry Model (PIM), SGI-Bench, Test-Time Reinforcement Learning (TTRL), retrieval-augmented novelty, agent-based evaluation]</li>
<li class=""><strong>authors:</strong> Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu</li>
<li class=""><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [gradient boosting, DQN, ensemble learning, Bellman residual, non-stationary environments]</li>
<li class=""><strong>authors:</strong> Chang-Hwan Lee, Chanseung Lee</li>
<li class=""><strong>institution:</strong> Florida Atlantic University, Morrow Company</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17034</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes GB-DQN, a method that uses gradient boosting to create an ensemble of Q-networks, where each new network learns the residual error of the current ensemble to adapt to non-stationary environments. Experiments show that GB-DQN achieves faster recovery and greater robustness compared to standard DQN and other baselines in tasks with changing dynamics.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge graph question answering], [reinforcement learning, subgraph selection, graph pruning, llm fine-tuning, relation-centric reasoning]</li>
<li class=""><strong>authors:</strong> Yinxu Tang, Chengsong Huang, Jiaxin Huang, William Yeoh</li>
<li class=""><strong>institution:</strong> Washington University in St. Louis</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces UniRel-R1, a framework for relation-centric knowledge graph question answering that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The method is designed to identify compact and informative subgraph answers by rewarding specific relations and lower-degree entities. Experiments show it outperforms baselines in connectivity and reward and generalizes well to unseen entities and relations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Value Under Ignorance in Universal Artificial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [AIXI, Choquet integrals, imprecise probability theory, semimeasure loss, utility functions]</li>
<li class=""><strong>authors:</strong> Cole Wyeth, Marcus Hutter</li>
<li class=""><strong>institution:</strong> University of Waterloo, Google DeepMind, Australian National University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17086</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper generalizes the AIXI reinforcement learning agent to handle a wider class of utility functions, confronting the ambiguity of finite history predictions by interpreting belief distributions as imprecise probabilities. It explores computing expected utilities using Choquet integrals from imprecise probability theory and investigates their computability. The authors show that the standard recursive value function is a special case, but the most general utilities under a &quot;death interpretation&quot; cannot be characterized by these integrals.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, model predictive control, MPPI, hierarchical planning, adaptive sampling]</li>
<li class=""><strong>authors:</strong> Toshiaki Hori, Jonathan DeCastro, Deepak Gopinath, Avinash Balachandran, Guy Rosman</li>
<li class=""><strong>institution:</strong> Toyota Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17091</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that fuses reinforcement learning and model-predictive control (MPC) into an adaptive hierarchical framework. It uses RL actions to guide the MPPI sampler and adaptively aggregates MPPI samples to improve value estimation, leading to more robust and sample-efficient policies. The approach demonstrates improved data efficiency, performance, and convergence speed in domains like race driving and Lunar Lander.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Reinforcement Learning for Self-Improving Agent with Skill Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [reinforcement learning, skill library, sequential rollout, skill-integrated reward, GRPO, self-improving agent]</li>
<li class=""><strong>authors:</strong> Jiongxiao Wang, Qiaojing Yan, Yawei Wang, Yijun Tian, Soumya Smruti Mishra, Zhichao Xu, Megha Gandhi, Panpan Xu, Lin Lee Cheong</li>
<li class=""><strong>institution:</strong> University of Wisconsin–Madison, AWS Agentic AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17102" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17102</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SAGE, a reinforcement learning framework that enhances LLM-based agents by integrating a skill library through sequential rollouts and a skill-integrated reward. This approach enables agents to accumulate and reuse skills across tasks for continual self-improvement. Experiments show SAGE improves task completion accuracy while significantly reducing interaction steps and token usage compared to existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [interactive reinforcement learning, multi-teacher learning, Q-learning, teacher selection, concept drift]</li>
<li class=""><strong>authors:</strong> Maher Mesto, Francisco Cruz</li>
<li class=""><strong>institution:</strong> University of New South Wales, Universidad Central de Chile</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17180</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a multi-teacher interactive reinforcement learning framework where agents can select advice from teachers with different reward structures. The core finding is that agents exhibit a strong conservative bias, overwhelmingly preferring low-reward but consistent teachers over high-reward ones, which challenges traditional reward-maximization assumptions in RL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [reinforcement learning, fine-tuning, retrieval-augmented generation, multi-modal large language models, explainable AI]</li>
<li class=""><strong>authors:</strong> Shengwei Zhao, Jingwen Yao, Sitong Wei, Linhai Xu, Yuying Liu, Dong Zhang, Zhiqiang Tian, Shaoyi Du</li>
<li class=""><strong>institution:</strong> Xi’an Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17194" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17194</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MMRAG-RFT, a two-stage reinforcement fine-tuning framework for explainable multi-modal retrieval-augmented generation. The method uses rule-based and reasoning-based reinforcement learning to filter documents and jointly optimize ranking and answer generation, achieving state-of-the-art results on benchmark datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [latent modulation, variational autoencoder, reinforcement learning, supervised fine-tuning, reasoning strategies, controllable exploration]</li>
<li class=""><strong>authors:</strong> Rujiao Long, Yang Li, Xingyao Zhang, Weixun Wang, Tianqianjin Lin, Xi Zhao, Yuchi Xu, Wenbo Su, Junchi Yan, Bo Zheng</li>
<li class=""><strong>institution:</strong> Alibaba Group, Shanghai Jiao Tong University, Zhejiang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bfcb7d02fac2a6f117f80403719551786b6b7722d6b86bf1338ef9e18ddda6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bfcb7d02fac2a6f117f80403719551786b6b7722d6b86bf1338ef9e18ddda6b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Reasoning Palette, a framework that uses a latent variable from a VAE to modulate a model&#x27;s reasoning trajectory via prepended token prefixes, enabling diverse strategic exploration. It shows that this approach improves exploration efficiency in RL training and leads to consistent performance gains over standard methods on reasoning benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] CheXPO-v2: Preference Optimization for Chest X-ray VLMs with Knowledge Graph Consistency</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [reinforcement learning, group relative policy optimization, knowledge graph consistency, entity-relation matching, process supervision, hard-example mining]</li>
<li class=""><strong>authors:</strong> Xiao Liang, Yuxuan An, Di Wang, Jiawei Hu, Zhicheng Jiao, Bin Jing, Quan Wang</li>
<li class=""><strong>institution:</strong> Xidian University, Brown University, Capital Medical University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17213" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17213</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c86c0e9aa8fe8870d86c5f63baf1ccd89856e7434ece25e03ba384660733fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c86c0e9aa8fe8870d86c5f63baf1ccd89856e7434ece25e03ba384660733fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CheXPO-v2, an alignment framework that uses a Knowledge Graph Consistency Reward for process supervision to reduce hallucinations in medical VLMs. It parses reasoning into structured triplets to penalize incoherent logic, outperforming prior methods on benchmarks with high data efficiency. The approach achieves state-of-the-art accuracy on MIMIC-CXR-VQA using only 5k samples.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning When to Look: A Disentangled Curriculum for Strategic Perception in Multimodal Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [curriculum learning, supervised fine-tuning, reinforcement learning, perception-grounded chain-of-thought, pivotal perception reward]</li>
<li class=""><strong>authors:</strong> Siqi Yang, Zilve Gao, Haibo Qiu, Fanfan Liu, Peng Shi, Zhixiong Zeng, Qingmin Liao, Lin Ma</li>
<li class=""><strong>institution:</strong> Meituan, Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17227" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17227</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68b925dc42674866f1a5d50b8321678a682bbb13a5906e16c5013dcca31b9aea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68b925dc42674866f1a5d50b8321678a682bbb13a5906e16c5013dcca31b9aea_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a two-stage curriculum framework to address visual forgetting in multimodal reasoning. It first builds an abstract reasoning backbone using text-only data and then uses reinforcement learning with a novel reward to teach the model a strategic policy for when to perceive visual information. This approach transforms the model into a more strategic and visually grounded reasoner.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Theoretical Analysis of State Similarity Between Markov Decision Processes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [bisimulation metric, generalized bisimulation metric, Markov decision process, policy transfer, state aggregation, sampling-based estimation]</li>
<li class=""><strong>authors:</strong> Zhenyu Tao, Wei Xu, Xiaohu You</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17265" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17265</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a Generalized Bisimulation Metric (GBSM) to measure state similarity between different Markov Decision Processes, establishing its fundamental mathematical properties. The authors leverage GBSM to theoretically analyze tasks like policy transfer and state aggregation, obtaining tighter performance bounds than previous methods. Numerical results validate the effectiveness of GBSM for multi-MDP scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Understanding Generalization in Role-Playing Models via Information Theory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [natural language processing], [information theory, mutual information, reinforcement learning, distribution shift, role-playing models]</li>
<li class=""><strong>authors:</strong> Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li</li>
<li class=""><strong>institution:</strong> Wuhan University, Tongyi Lab, Zhongguancun Academy</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17270" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17270</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language models, turn-based battle system, strategic decision-making, content generation, procedural generation, adaptive difficulty]</li>
<li class=""><strong>authors:</strong> Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> Birla Institute of Technology and Science, Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17308" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17308</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a turn-based Pokémon battle system where LLMs act as agents, making tactical decisions based on a structured battle state without domain-specific training. The core method involves evaluating LLMs on strategic reasoning and their ability to generate novel game content. The main conclusion is that LLMs can function as dynamic game opponents and designers, offering a practical alternative to reinforcement learning for strategic games.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Xiaomi MiMo-VL-Miloco Technical Report</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [supervised fine-tuning, reinforcement learning, Group Relative Policy Optimization, chain-of-thought supervision, token-budget-aware reasoning, quantization]</li>
<li class=""><strong>authors:</strong> Jiaze Li, Jingyang Chen, Yuxun Qu, Jianzhong Ju, Zhenbo Luo, Jian Luan, Shijie Xu, Zhenru Lin, Junyou Zhu, Boshen Xu, Wenhui Tan, Pei Fu</li>
<li class=""><strong>institution:</strong> Xiaomi</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17436</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5131a57d5cef340803d1dd4e55e39db8e4fc7a8b7925e87579be976c079279c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5131a57d5cef340803d1dd4e55e39db8e4fc7a8b7925e87579be976c079279c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MiMo-VL-Miloco-7B, a vision-language model specialized for smart-home understanding, built via a two-stage training pipeline combining supervised fine-tuning and reinforcement learning. The model achieves leading performance on home-scenario tasks like gesture recognition and also shows gains on general multimodal and language reasoning benchmarks. The authors conclude that targeted home-scenario training enhances activity understanding and can improve text-only reasoning with minimal trade-offs on other tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reinforcement learning, independent proximal policy optimization, agent-based modeling, electricity markets, capacity markets, contracts for difference]</li>
<li class=""><strong>authors:</strong> Javier Gonzalez-Ruiz, Carlos Rodriguez-Pardo, Iacopo Savelli, Alice Di Bella, Massimo Tavoni</li>
<li class=""><strong>institution:</strong> Politecnico di Milano, CMCC Foundation - Euro-Mediterranean Center on Climate Change, RFF-CMCC European Institute on Economics and the Environment, Bocconi University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17444</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent reinforcement learning framework, using independent proximal policy optimization, to model investment decisions by generation companies in long-term electricity markets. The model is applied to a stylized Italian electricity system to test various market designs and policy scenarios. The results demonstrate that market design is critical for achieving decarbonization targets while mitigating price volatility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning Safe Autonomous Driving Policies Using Predictive Safety Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [safe reinforcement learning], [safe reinforcement learning, predictive safety representations, constrained markov decision processes, waymo open motion dataset, nuplan, srpl]</li>
<li class=""><strong>authors:</strong> Mahesh Keswani, Raunak Bhattacharyya</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Delhi</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17586</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40dd4c52ca67a3f1ecc6ec7068de338a3616940aa4e51935c5ce5f30430ebbfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40dd4c52ca67a3f1ecc6ec7068de338a3616940aa4e51935c5ce5f30430ebbfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the Safety Representations for Safer Policy Learning (SRPL) framework, which augments SafeRL agents with a predictive model of future constraint violations to improve the safety-performance trade-off in autonomous driving. Experiments on real-world datasets (Waymo Open Motion Dataset and NuPlan) show that SRPL can lead to statistically significant improvements in success rate and cost reduction, and enhances robustness to noise and generalization in cross-dataset evaluation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SCOPE: Sequential Causal Optimization of Process Interventions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [prescriptive process monitoring], [backward induction, causal learning, reinforcement learning, sequential decision-making]</li>
<li class=""><strong>authors:</strong> Jakob De Moor, Hans Weytjens, Johannes De Smedt, Jochen De Weerdt</li>
<li class=""><strong>institution:</strong> KU Leuven, Technical University of Munich (TUM)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17629" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17629</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SCOPE, a prescriptive process monitoring approach that uses backward induction and causal learning to recommend aligned sequences of interventions for optimizing key performance indicators. It directly leverages observational data without needing process approximations for reinforcement learning. Experiments show SCOPE outperforms existing techniques in optimizing KPIs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Trust-Region Adaptive Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [post-training], [Trust-Region Adaptive Policy Optimization, Trust-Region SFT, forward KL divergence, reverse KL, adaptive prefix-selection, supervised fine-tuning, reinforcement learning]</li>
<li class=""><strong>authors:</strong> Mingyu Su, Jian Guan, Yuxian Gu, Minlie Huang, Hongning Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Ant Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17636" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17636</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces TRAPO, a hybrid framework that interleaves supervised fine-tuning and reinforcement learning within each training instance to unify expert supervision and self-exploration. It stabilizes training with Trust-Region SFT and an adaptive prefix-selection mechanism. Experiments on mathematical reasoning benchmarks show TRAPO outperforms standard pipelines and state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] About Time: Model-free Reinforcement Learning with Timed Reward Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [timed reward machines, tabular Q-learning, timed automata, counterfactual-imagining]</li>
<li class=""><strong>authors:</strong> Anirban Majumdar, Ritam Raha, Rajarshi Roy, David Parker, Marta Kwiatkowska</li>
<li class=""><strong>institution:</strong> Tata Institute of Fundamental Research, Max Planck Institute for Software Systems, University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17637" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17637</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes timed reward machines (TRMs), an extension of reward machines that incorporates timing constraints into the reward specification for reinforcement learning. The authors develop model-free RL algorithms, specifically using tabular Q-learning integrated with abstractions of timed automata and counterfactual-imagining heuristics, to learn optimal policies. The experimental results show that their approach successfully learns policies that achieve high rewards while satisfying the specified timing constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [energy-based models, gradient-based refinement, hindsight goal relabeling, latent-space planning]</li>
<li class=""><strong>authors:</strong> Carlos Vélez García, Miguel Cazorla, Jorge Pomares</li>
<li class=""><strong>institution:</strong> INESCOP, University of Alicante</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17846" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17846</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Planning as Descent (PaD), a method for offline goal-conditioned reinforcement learning that learns an energy function over latent trajectories and performs planning via gradient-based refinement in this energy landscape. It achieves state-of-the-art 95% success on cube manipulation tasks, demonstrating that verification-driven trajectory synthesis outperforms direct policy learning, especially when trained on noisy data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [ViPR, ViPR-Eureka, ViPR-RL, behavior cloning, VLM-in-the-loop Parallel Refinement, LLM-guided contact sampling, sim-to-real transfer, GPU simulation]</li>
<li class=""><strong>authors:</strong> Ran Gong, Xiaohan Zhang, Jinghuan Shang, Maria Vittoria Minniti, Jigarkumar Patel, Valerio Pepe, Riedana Yan, Ahmet Gundogdu, Ivan Kapelyukh, Ali Abbas, Xiaoqiang Yan, Harsh Patel, Laura Herlant, Karl Schmeckpeper</li>
<li class=""><strong>institution:</strong> Robotics and AI Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17853" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17853</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AnyTask, an automated framework that uses massively parallel GPU simulation and foundation models to generate diverse robot manipulation tasks and expert demonstration data. It introduces three agents (ViPR, ViPR-Eureka, ViPR-RL) for synthesizing demonstrations, which are used to train behavior cloning policies. These policies achieve a 44% average success rate when deployed directly on real robot hardware for various manipulation tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [imitation learning, distributionally robust control, layered control architecture, Taylor Series Imitation Learning (TaSIL), L1-Distributionally Robust Adaptive Control (L1-DRAC), certifiable autonomy]</li>
<li class=""><strong>authors:</strong> Aditya Gahlawat, Ahmed Aboudonia, Sandeep Banik, Naira Hovakimyan, Nikolai Matni, Aaron D. Ames, Gioele Zardini, Alberto Speranzon</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, University of Pennsylvania, California Institute of Technology, Massachusetts Institute of Technology, Lockheed Martin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17899" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17899</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Distributionally Robust Imitation Policy (DRIP) architecture, a layered control framework that integrates Taylor Series Imitation Learning (TaSIL) and L1-Distributionally Robust Adaptive Control (L1-DRAC) to address different sources of distribution shift. The main conclusion is that this integration enables the design of certifiable autonomy pipelines by guaranteeing performance certificates for the entire control system, combining learning-based components with model-based decision-making.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] HydroGym: A Reinforcement Learning Platform for Fluid Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [reinforcement learning, flow control, differentiable solvers, transfer learning, benchmark platform]</li>
<li class=""><strong>authors:</strong> Christian Lagemann, Sajeda Mokbel, Miro Gondrum, Mario Rüttgers, Jared Callaham, Ludger Paehler, Samuel Ahnert, Nicholas Zolman, Kai Lagemann, Nikolaus Adams, Matthias Meinke, Wolfgang Schröder, Jean-Christophe Loiseau, Esther Lagemann, Steven L. Brunton</li>
<li class=""><strong>institution:</strong> University of Washington, RWTH Aachen University, Inha University, Technical University of Munich, German Center for Neurodegenerative Diseases, Arts et Métiers Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17534" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17534</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HydroGym, a reinforcement learning platform designed for fluid dynamics control, featuring both non-differentiable and differentiable solvers to improve sample efficiency. The platform includes 42 validated environments and demonstrates that RL agents can discover robust control principles, achieving significant drag reduction and efficient adaptation to new conditions via transfer learning.</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 10</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, model predictive control, MPPI, hierarchical planning, adaptive sampling]</li>
<li class=""><strong>authors:</strong> Toshiaki Hori, Jonathan DeCastro, Deepak Gopinath, Avinash Balachandran, Guy Rosman</li>
<li class=""><strong>institution:</strong> Toyota Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17091</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that fuses reinforcement learning and model-predictive control (MPC) into an adaptive hierarchical framework. It uses RL actions to guide the MPPI sampler and adaptively aggregates MPPI samples to improve value estimation, leading to more robust and sample-efficient policies. The approach demonstrates improved data efficiency, performance, and convergence speed in domains like race driving and Lunar Lander.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep unrolled model, Restormer, learned coil sensitivity map estimator, sampling-aware weighted data consistency, universal conditioning, progressive cascade expansion training]</li>
<li class=""><strong>authors:</strong> Puyang Wang, Pengfei Guo, Keyi Chai, Jinyuan Zhou, Daguang Xu, Shanshan Jiang</li>
<li class=""><strong>institution:</strong> Johns Hopkins University, NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17137" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17137</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SDUM, a scalable deep unrolled model for universal MRI reconstruction that integrates a Restormer-based reconstructor, learned coil sensitivity estimation, and sampling-aware data consistency. It demonstrates predictable performance scaling with model depth and achieves state-of-the-art results across diverse clinical MRI protocols without task-specific fine-tuning. The work establishes a practical framework for a single, universally applicable reconstruction model in clinical environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [evaluation framework], [LLM-as-a-Judge, regression, MetricBank, retrieval, human feedback correlation]</li>
<li class=""><strong>authors:</strong> Michael J. Ryan, Yanzhe Zhang, Amol Salunkhe, Yi Chu, Di Xu, Diyi Yang</li>
<li class=""><strong>institution:</strong> Stanford University, American Express</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17267" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17267</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AutoMetrics, a framework that synthesizes evaluation metrics by combining retrieved metrics from a curated bank with automatically generated LLM-as-a-Judge criteria, composed via regression to maximize correlation with human feedback. It demonstrates that AutoMetrics significantly improves correlation with human judgments over standard LLM-as-a-Judge approaches while requiring minimal human feedback data. The method can serve as an effective proxy reward for optimizing AI applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Kolmogorov-Arnold Networks (KANs), multilayer perceptron networks (MLPs), Physics-informed Neural Networks, nonlocal consistency loss, integro-differential equations (IDEs), fractional PDEs]</li>
<li class=""><strong>authors:</strong> Farinaz Mostajeran, Aruzhan Tleubek, Salah A Faroughi</li>
<li class=""><strong>institution:</strong> University of Utah</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MINPO, a unified neural framework that learns nonlocal operators and their inverses using KANs or MLPs to solve integro-differential equations. It enforces coherence between the learned operator and solution via a nonlocal consistency loss. The method is shown to be accurate and robust across diverse kernel types and dimensionalities, generalizing beyond problem-specific formulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [speech processing], [voice activity detection, vision transformer, MFCC, Gammatone filter bank cepstral coefficients, dataset augmentation, out-of-distribution evaluation]</li>
<li class=""><strong>authors:</strong> Ioannis Stylianou, Achintya kr. Sarkar, Nauman Dawalatabad, James Glass, Zheng-Hua Tan</li>
<li class=""><strong>institution:</strong> Aalborg University, Pioneer Centre for AI, IIIT SriCity, Zoom Communications Inc., Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17281" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17281</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LibriVAD, a scalable open dataset for voice activity detection (VAD) created by augmenting LibriSpeech with diverse noise sources. It benchmarks several feature-model combinations and proposes using a Vision Transformer (ViT) architecture for VAD. The main conclusion is that ViT with MFCC features outperforms established models across various conditions, and scaling the dataset size and balancing its silence-to-speech ratio consistently improves out-of-distribution generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memristive architecture, minion recurrent unit, weighted-bit streaming, experience replay, mixed-signal accelerator, on-chip continual learning]</li>
<li class=""><strong>authors:</strong> Abdullah M. Zyarah, Dhireesha Kudithipudi</li>
<li class=""><strong>institution:</strong> University of Texas at San Antonio, University of Baghdad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17299</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces M2RU, a mixed-signal hardware architecture that implements the Minion Recurrent Unit for efficient on-chip continual learning at the edge. It uses weighted-bit streaming and experience replay to enable energy-efficient temporal processing and stable adaptation. The results show significant energy efficiency improvements and a long operational lifetime, establishing M2RU as a scalable platform for edge-level temporal intelligence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ProCache: Constraint-Aware Feature Caching with Selective Computation for Diffusion Transformer Acceleration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [feature caching, selective computation, constraint-aware scheduling, temporal redundancy, activation schedule]</li>
<li class=""><strong>authors:</strong> Fanpu Cao, Yaofo Chen, Zeng You, Wei Luo, Cen Chen</li>
<li class=""><strong>institution:</strong> South China University of Technology, South China Agricultural University, Pazhou Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17298</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af7870aa86d8ec0f40bf8ee51c36b05d76a3b23aeb26f3f88d6835a77ed1a314_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af7870aa86d8ec0f40bf8ee51c36b05d76a3b23aeb26f3f88d6835a77ed1a314_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes ProCache, a training-free framework to accelerate Diffusion Transformers (DiTs) by using dynamic feature caching. It introduces a constraint-aware caching pattern search to create non-uniform activation schedules and a selective computation module to mitigate error accumulation. Experiments show ProCache achieves significant speedups with minimal quality loss, outperforming prior caching methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [democratic systems], [fair voting methods, cumulative voting, equal shares, proportional representation, participatory budgeting, AI voting assistance]</li>
<li class=""><strong>authors:</strong> Evangelos Pournaras</li>
<li class=""><strong>institution:</strong> University of Leeds</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17461" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17461</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes that combining expressive ballot formats like cumulative voting with proportional aggregation methods like equal shares constitutes a &quot;fair voting method.&quot; It concludes that such methods enhance democratic legitimacy, accelerate impactful outcomes in areas like welfare and education, and serve as a safeguard against biases in emerging AI-assisted voting scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bitbox: Behavioral Imaging Toolbox for Computational Analysis of Behavior from Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [computational behavioral measurement, video analysis, facial expression, head movement, body action, open-source toolkit, modularity, interpretability]</li>
<li class=""><strong>authors:</strong> Evangelos Sariyanidi, Gokul Nair, Lisa Yankowitz, Casey J. Zampella, Mohan Kashyap Pargi, Aashvi Manakiwala, Maya McNealis, John D. Herrington, Jeffrey Cohn, Robert T. Schultz, Birkan Tunc</li>
<li class=""><strong>institution:</strong> The Children&#x27;s Hospital of Philadelphia, University of Pennsylvania, University of Pittsburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17655" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17655</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Bitbox, an open-source behavioral imaging toolbox that provides a standardized interface for extracting high-level behavioral measurements from video using multiple face, head, and body processors. It is designed to bridge the translational gap by making advanced computational analysis accessible to behavioral and clinical researchers without requiring engineering expertise. The authors conclude that Bitbox will accelerate the integration of computational behavioral measurement into behavioral, clinical, and mental health research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Generative Multi-Objective Bayesian Optimization with Scalable Batch Evaluations for Sample-Efficient De Novo Molecular Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [molecular design], [Bayesian optimization, generative models, multi-objective optimization, acquisition function, qPMHI, Monte Carlo sampling]</li>
<li class=""><strong>authors:</strong> Madhav R. Muthyala, Farshud Sorourifar, Tianhong Tan, You Peng, Joel A. Paulson</li>
<li class=""><strong>institution:</strong> University of Wisconsin–Madison, The Ohio State University, The Dow Chemical Company</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17659" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17659</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a &quot;generate-then-optimize&quot; framework for de novo molecular design, which uses a generative model to create candidate molecules and a novel acquisition function called qPMHI to efficiently select batches for evaluation. The method demonstrates significant improvements over existing approaches in sample efficiency and performance, as shown in benchmarks and a case study on designing organic cathode materials for batteries.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-23">2025-12-23<a href="#2025-12-23" class="hash-link" aria-label="Direct link to 2025-12-23" title="Direct link to 2025-12-23" translate="no">​</a></h2>
<p><strong>cs.DC total: 21</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251223] Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nihir Chadderwala</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17913" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17913</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QAISim: A Toolkit for Modeling and Simulation of AI in Quantum Cloud Computing Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Irwindeep Singh, Sukhpal Singh Gill, Jinzhao Sun, Jan Mol</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17918" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17918</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ffe2289ec69b8a1b313e066cc4c4de736d5becc210f22958bfd52daff8ff5e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ffe2289ec69b8a1b313e066cc4c4de736d5becc210f22958bfd52daff8ff5e6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QAISim: A Toolkit for Modeling and Simulation of AI in Quantum Cloud Computing Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Allison Li, Kristjan Greenewald, Thomas Parnell, Navid Azizan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17910</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Xu, Ayan Banerjee, Midhat Urooj, Sandeep K.S. Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fast Online Digital Twinning on FPGA for Mission Critical Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Xu, Ayan Banerjee, Sandeep K. S. Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17942" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17942</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16ee82367ac1a35aebfd7c95c003a129158965297946e5c0f25e447a72aa119c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16ee82367ac1a35aebfd7c95c003a129158965297946e5c0f25e447a72aa119c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fast Online Digital Twinning on FPGA for Mission Critical Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ACE-Sync: An Adaptive Cloud-Edge Synchronization Framework for Communication-Efficient Large-Scale Distributed Model Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yi Yang, Ziyu Lin, Liesheng Wei</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18127" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18127</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0b4f1e094718ec73523430923a11d6db1ca267faf57d9dfeb12c670c753f795_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0b4f1e094718ec73523430923a11d6db1ca267faf57d9dfeb12c670c753f795_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ACE-Sync: An Adaptive Cloud-Edge Synchronization Framework for Communication-Efficient Large-Scale Distributed Model Training</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Constrained Cuts, Flows, and Lattice-Linearity</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Robert Streit, Vijay K. Garg</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18141" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18141</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4988963d0df9feb5d6d93950c8695a282967332a6a2d340e258ed92a056f4c86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4988963d0df9feb5d6d93950c8695a282967332a6a2d340e258ed92a056f4c86_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Constrained Cuts, Flows, and Lattice-Linearity</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dongha Yoon, Younghoon Min, Hoshik Kim, Sam H. Noh, Jongryool Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18194" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18194</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf126804dfba85c7a794b9b5687408dce6800961fba23c8342730d926fc068da_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf126804dfba85c7a794b9b5687408dce6800961fba23c8342730d926fc068da_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eren Caglar, Amirkia Rafiei Oskooei, Mehmet Kutanoglu, Mustafa Keles, Mehmet S. Aktas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18318" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18318</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faster Vertex Cover Algorithms on GPUs with Component-Aware Parallel Branching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hussein Amro, Basel Fakhri, Amer E. Mouawad, Izzat El Hajj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18334</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b31bc47ecb1dc74e237f8d5df239958727df951c6edb1120b903f3fd7b5c55be_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b31bc47ecb1dc74e237f8d5df239958727df951c6edb1120b903f3fd7b5c55be_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faster Vertex Cover Algorithms on GPUs with Component-Aware Parallel Branching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Snowveil: A Framework for Decentralised Preference Discovery</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Grammateia Kotsialou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18444</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Snowveil: A Framework for Decentralised Preference Discovery</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Liu, Yuhao Hu, Ruiting Zhou, Baochun Li, Ne Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18674" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18674</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Real-Time Digital Twin for Adaptive Scheduling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yihe Zhang, Yash Kurkure, Yiheng Tao, Michael E. Papka, Zhiling Lan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18894" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18894</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/228b6575bd24119fca42b0b1a9ba6a42e15166f06d7d2264d4bc894aff71d4ed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/228b6575bd24119fca42b0b1a9ba6a42e15166f06d7d2264d4bc894aff71d4ed_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Real-Time Digital Twin for Adaptive Scheduling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QoS-Aware Load Balancing in the Computing Continuum via Multi-Player Bandits</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ivan Čilić, Ivana Podnar Žarko, Pantelis Frangoudis, Schahram Dustdar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18915" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18915</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9dc5e7bd9261487c82b2942a0f628fd37b770391416336515d537b8d9c7608d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9dc5e7bd9261487c82b2942a0f628fd37b770391416336515d537b8d9c7608d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoS-Aware Load Balancing in the Computing Continuum via Multi-Player Bandits</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Timely Parameter Updating in Over-the-Air Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiaqi Zhu, Zhongyuan Zhao, Xiao Li, Ruihao Du, Shi Jin, Howard H.Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19103" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19103</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fc52e9cecab5d074f9763764f769e7c7bd5aaa186ce1d747f2bbd3fa2caf41_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fc52e9cecab5d074f9763764f769e7c7bd5aaa186ce1d747f2bbd3fa2caf41_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Timely Parameter Updating in Over-the-Air Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Murtaza Rangwala, Richard O. Sinnott, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19131</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5ab0acf932ea7b2d42fac6b935c509aaf0582fb4879eb9fae7e0fe0a8e7f766_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5ab0acf932ea7b2d42fac6b935c509aaf0582fb4879eb9fae7e0fe0a8e7f766_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yitao Yuan, Chenqi Zhao, Bohan Zhao, Zane Cao, Yongchao He, Wenfei Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19179" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19179</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a06667660cf3663082a8dcc7b41e7338eae070225a51b761512a3dfc2c89548_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a06667660cf3663082a8dcc7b41e7338eae070225a51b761512a3dfc2c89548_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> L4: Low-Latency and Load-Balanced LLM Serving via Length-Aware Scheduling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Simulations between Strongly Sublinear MPC and Node-Capacitated Clique</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Philipp Schneider, Julian Werthmann</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19326" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19326</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8644a50509dfa5e351f02bea3451463ff322106a9319b73a700313df6f2ab2a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8644a50509dfa5e351f02bea3451463ff322106a9319b73a700313df6f2ab2a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simulations between Strongly Sublinear MPC and Node-Capacitated Clique</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kiril Dichev, Filip Pawlowski, Albert-Jan Yzelman</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19342" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19342</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2babd04ddf70f201df2fa1a003998a91a1e266029f2a3a118314f226a7ce88f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2babd04ddf70f201df2fa1a003998a91a1e266029f2a3a118314f226a7ce88f0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> George Karfakis, Faraz Tahmasebi, Binglu Chen, Lime Yao, Saptarshi Mitra, Tianyue Pan, Hyoukjun Kwon, Puneet Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19606" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19606</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ba70ec7306532ca1c35d62f262fda2524e63fa17cc3a261b1800c846a6c06b2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ba70ec7306532ca1c35d62f262fda2524e63fa17cc3a261b1800c846a6c06b2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] EuroHPC SPACE CoE: Redesigning Scalable Parallel Astrophysical Codes for Exascale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nitin Shukla, Alessandro Romeo, Caterina Caravita, Lubomir Riha, Ondrej Vysocky, Petr Strakos, Milan Jaros, João Barbosa, Radim Vavrik, Andrea Mignone, Marco Rossazza, Stefano Truzzi, Vittoria Berta, Iacopo Colonnelli, Doriana Medić, Elisabetta Boella, Daniele Gregori, Eva Sciacca, Luca Tornatore, Giuliano Taffoni, Pranab J. Deka, Fabio Bacchini, Rostislav-Paul Wilhelm, Georgios Doulis, Khalil Pierre, Luciano Rezzolla, Tine Colman, Benoît Commerçon, Othman Bouizi, Matthieu Kuhn, Erwan Raffin, Marc Sergent, Robert Wissing, Guillermo Marin, Klaus Dolag, Geray S. Karademir, Gino Perna, Marisa Zanotti, Sebastian Trujillo-Gomez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18883" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18883</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/858132a58cba05e698ccaa1c8a830fb0c87d0b8772070099bf19455acf265c4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/858132a58cba05e698ccaa1c8a830fb0c87d0b8772070099bf19455acf265c4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EuroHPC SPACE CoE: Redesigning Scalable Parallel Astrophysical Codes for Exascale</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 59</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251223] Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lihui Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17912" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17912</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Karthik Prabhakar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17943" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17943</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SuperFlow: Training Flow Matching Models with RL on the Fly</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kaijie Chen, Zhiyang Xu, Ying Shen, Zihao Lin, Yuguang Yao, Lifu Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17951" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17951</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/948003a9b36edb891b1eea74cedf1aaab2c086c912b2c476bae0259abbca38e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/948003a9b36edb891b1eea74cedf1aaab2c086c912b2c476bae0259abbca38e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SuperFlow: Training Flow Matching Models with RL on the Fly</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthieu Mastio, Paul Saves, Benoit Gaudou, Nicolas Verstaevel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17979" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17979</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Autonomous Navigation in Endovascular Interventions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tudor Jianu, Anh Nguyen, Sebastiano Fichera, Pierre Berthet-Rayne</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18081" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18081</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f911d278f0ab6bda3ee8c65e700063ac44b97c8d600de90a9982d9c8c3b33f81_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f911d278f0ab6bda3ee8c65e700063ac44b97c8d600de90a9982d9c8c3b33f81_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Autonomous Navigation in Endovascular Interventions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cristiano da Costa Cunha, Wei Liu, Tim French, Ajmal Mian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Swarm Leader Identification using Probing Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stergios E. Bachoumas, Panagiotis Artemiadis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18146" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18146</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Swarm Leader Identification using Probing Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Deng, Yijia Li, Renrui Zhang, Peijun Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18189" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18189</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Stable and Efficient Single-Rollout RL for Multimodal Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Stable and Efficient Single-Rollout RL for Multimodal Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Harsh Rathva, Ojas Srivastava, Pruthwik Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18309</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18336</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Monitoring Monitorability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Monitoring Monitorability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Universality of Transformer Architectures; How Much Attention Is Enough?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Amirreza Abbasi, Mohsen Hooshmand</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18445" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18445</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e732525ad7eeb9bd777c68adaa24b4e1209e8441252397e0784b8ce41a3a00d7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e732525ad7eeb9bd777c68adaa24b4e1209e8441252397e0784b8ce41a3a00d7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Universality of Transformer Architectures; How Much Attention Is Enough?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Robots Say No: The Empathic Ethical Disobedience Benchmark</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dmytro Kuzmenko, Nadiya Shvai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18474" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18474</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/083ac27bf9c1ba565d26a4c6417b20f994336e4ffb3cb410b3b93d3ef36fb6aa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/083ac27bf9c1ba565d26a4c6417b20f994336e4ffb3cb410b3b93d3ef36fb6aa_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Robots Say No: The Empathic Ethical Disobedience Benchmark</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scaling up Stability: Reinforcement Learning for Distributed Control of Networked Systems in the Space of Stabilizing Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Cao, Luca Furieri</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18540" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18540</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43fe9d2dae8cd7dd8a3ae293cabf5bd434385dd8877da1630a601a47c5dc1a7f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43fe9d2dae8cd7dd8a3ae293cabf5bd434385dd8877da1630a601a47c5dc1a7f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling up Stability: Reinforcement Learning for Distributed Control of Networked Systems in the Space of Stabilizing Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Training Superintelligent Software Agents through Self-Play SWE-RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18552</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Training Superintelligent Software Agents through Self-Play SWE-RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Distributionally Robust Multi-Agent Reinforcement Learning for Intelligent Traffic Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuwei Pei, Joran Borger, Arda Kosay, Muhammed O. Sayin, Saeed Ahmed</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18558" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18558</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c1324b0e30f974791cfbd8d505d68abcbf0e5d1e0c030b0e526accb5fbb97de_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c1324b0e30f974791cfbd8d505d68abcbf0e5d1e0c030b0e526accb5fbb97de_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Distributionally Robust Multi-Agent Reinforcement Learning for Intelligent Traffic Control</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Chen, Sihan Cheng, Can Gurkan, Ryan Lay, Moez Salahuddin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18564" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18564</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wencan Mao, Quanxi Zhou, Tomas Couso Coddou, Manabu Tsukada, Yunling Liu, Yusheng Ji</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18604" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18604</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18623" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18623</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18622" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18622</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Offline Reinforcement Learning for End-to-End Autonomous Driving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chihiro Noguchi, Takaki Yamamoto</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18662" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18662</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48070c89f8318c57738214d175fd04c9e38d7e43e2838b599453ae0e31d8c27f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48070c89f8318c57738214d175fd04c9e38d7e43e2838b599453ae0e31d8c27f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Reinforcement Learning for End-to-End Autonomous Driving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xue Yang, Michael Schukat, Junlin Lu, Patrick Mannion, Karl Mason, Enda Howley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18670" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18670</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Theoretical Lens for RL-Tuned Language Models via Energy-Based Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiquan Tan, Yinrong Hong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18730</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726f00d4aa0c339e8cdaf688c05c28499bf469ac19b055e49f249d532aa40b2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726f00d4aa0c339e8cdaf688c05c28499bf469ac19b055e49f249d532aa40b2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Theoretical Lens for RL-Tuned Language Models via Energy-Based Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Gaussian-Mixture-Model Q-Functions for Policy Iteration in Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh Vu, Konstantinos Slavakis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18763" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18763</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19f67ca81a26c636db40a8c5fd0bedfcf549bc2e97dbcd90530ca1de4a7f861_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19f67ca81a26c636db40a8c5fd0bedfcf549bc2e97dbcd90530ca1de4a7f861_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gaussian-Mixture-Model Q-Functions for Policy Iteration in Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kaican Li, Lewei Yao, Jiannan Wu, Tiezheng Yu, Jierun Chen, Haoli Bai, Lu Hou, Lanqing Hong, Wei Zhang, Nevin L. Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18745</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MaskFocus: Focusing Policy Optimization on Critical Steps for Masked Image Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Guohui Zhang, Hu Yu, Xiaoxiao Ma, Yaning Pan, Hang Xu, Feng Zhao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18766" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18766</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e30d5e631331f72f5d3daa88862f5f4de5bcba185997003c4eb4c2df4ba695e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e30d5e631331f72f5d3daa88862f5f4de5bcba185997003c4eb4c2df4ba695e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MaskFocus: Focusing Policy Optimization on Critical Steps for Masked Image Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Word to World: Can Large Language Models be Implicit Text-based World Models?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, Mengdi Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18832" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18832</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7359ba2b2edde0aa35db68272c398f7be194a19334cd0996c3e220c7df0b0c05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7359ba2b2edde0aa35db68272c398f7be194a19334cd0996c3e220c7df0b0c05_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Word to World: Can Large Language Models be Implicit Text-based World Models?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] InDRiVE: Reward-Free World-Model Pretraining for Autonomous Driving via Latent Disagreement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Feeza Khan Khanzada, Jaerock Kwon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18850" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18850</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6819b32f0d91763f868ca298c9e844896fa38b755e6a9bf4eed0851e5ae3cbf1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6819b32f0d91763f868ca298c9e844896fa38b755e6a9bf4eed0851e5ae3cbf1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> InDRiVE: Reward-Free World-Model Pretraining for Autonomous Driving via Latent Disagreement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Gao, Zhikun Xu, Xiao Ye, Ben Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18857</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shaomu Tan, Ryosuke Mitani, Ritvik Choudhary, Qiyu Wu, Toshiyuki Sekiya, Christof Monz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18906" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18906</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fe48c6335a2271e131697f68ce5e1bd4c38bb02d11e569ba97f897ef4100cd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fe48c6335a2271e131697f68ce5e1bd4c38bb02d11e569ba97f897ef4100cd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Framework for Deploying Learning-based Quadruped Loco-Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yadong Liu, Jianwei Liu, He Liang, Dimitrios Kanoulas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18938" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18938</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed6b45b02a235e7607255d7b5204abe59d049aea04c8c4caa01b35f1f4f309d9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed6b45b02a235e7607255d7b5204abe59d049aea04c8c4caa01b35f1f4f309d9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Framework for Deploying Learning-based Quadruped Loco-Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debamita Ghosh, George K. Atia, Yue Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18957</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f848ae68e82b8a23f061ffdf3e4e75811fcab48a03fe5070cce95c8a38a027b7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f848ae68e82b8a23f061ffdf3e4e75811fcab48a03fe5070cce95c8a38a027b7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhi Wang, Linan Yue, Min-Ling Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjie Zhao, Xue Yu, Yongzhi Qi, Hao Hu, Jianshen Zhang, Yingzheng Ma, Shuyu Han, Wei Qi, Zuo-Jun Max Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19001" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19001</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peiqing Lu, Yuan Zhang, Haoyun Zhang, Jiasen Zheng, Kejian Tong, Wenjun Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19093" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19093</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengyu Chen, Tao Ouyang, Ke Luo, Weijie Hong, Xu Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19083" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19083</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92e42fabfcde19e98a2f6371e650103f1dd9895fac5630cbb65993eda35b116a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92e42fabfcde19e98a2f6371e650103f1dd9895fac5630cbb65993eda35b116a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihan Lin, Xiaohan Wang, Hexiong Yang, Jiajun Chai, Jie Cao, Guojun Yin, Wei Lin, Ran He</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19126" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19126</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea562f5265303d30f48412af8f0c2c84f8e98bc5e8f45118efe7f417df403e8d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea562f5265303d30f48412af8f0c2c84f8e98bc5e8f45118efe7f417df403e8d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengxuan Yang, Ben Lu, Zhongpu Xia, Chao Han, Yinfeng Gao, Teng Zhang, Kun Zhan, XianPeng Lang, Yupeng Zheng, Qichao Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19133" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19133</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95928df29dd1d6db8d9cc4946cd472f8722d19286d4bfa47dd919093172f5948_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95928df29dd1d6db8d9cc4946cd472f8722d19286d4bfa47dd919093172f5948_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> WorldRFT: Latent World Model Planning with Reinforcement Fine-Tuning for Autonomous Driving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] RMLer: Synthesizing Novel Objects across Diverse Categories via Reinforcement Mixing Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jun Li, Zikun Chen, Haibo Chen, Shuo Chen, Jian Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19300" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19300</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4417f7bedbf213cebde42bcbbe520cb32e68e60eec8444be79b07344e3b47020_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4417f7bedbf213cebde42bcbbe520cb32e68e60eec8444be79b07344e3b47020_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RMLer: Synthesizing Novel Objects across Diverse Categories via Reinforcement Mixing Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Bridging Semantics and Geometry: A Decoupled LVLM-SAM Framework for Reasoning Segmentation in Remote Sensing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xu Zhang, Junyao Ge, Yang Zheng, Kaitai Guo, Jimin Liang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19302" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19302</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bd6cba707b6fa3a38c669135a7bae69d4a297f430743568b2ec5258f28c554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bd6cba707b6fa3a38c669135a7bae69d4a297f430743568b2ec5258f28c554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bridging Semantics and Geometry: A Decoupled LVLM-SAM Framework for Reasoning Segmentation in Remote Sensing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning-Assisted Multi-Operator Variable Neighborhood Search for Urban Cable Routing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wei Liu, Tao Zhang, Chenhui Lin, Kaiwen Li, Rui Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19321" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19321</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3d94e7990bf940cb4e587f12cfcbb0d8438eef591b7db89e5a77d7daec8f35d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c3d94e7990bf940cb4e587f12cfcbb0d8438eef591b7db89e5a77d7daec8f35d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning-Assisted Multi-Operator Variable Neighborhood Search for Urban Cable Routing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing PLS of Indoor IRS-VLC Systems for Colluding and Non-Colluding Eavesdroppers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rashid Iqbal, Ahmed Zoha, Salama Ikki, Muhammad Ali Imran, Hanaa Abumarshoud</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19339" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19339</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/851f695ae948a59a83b4e4a7e1c623d8507df46c587ff957f421fe69eb4b5b05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/851f695ae948a59a83b4e4a7e1c623d8507df46c587ff957f421fe69eb4b5b05_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing PLS of Indoor IRS-VLC Systems for Colluding and Non-Colluding Eavesdroppers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] First-Order Representation Languages for Goal-Conditioned RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19355" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19355</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> First-Order Representation Languages for Goal-Conditioned RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning General Policies with Policy Gradient Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Blai Bonet, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19366</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning General Policies with Policy Gradient Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Isshaan Singh, Divyansh Chawla, Anshu Garg, Shivin Mangal, Pallavi Gupta, Khushi Agarwal, Nimrat Singh Khalsa, Nandan Patel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19361" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19361</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afec297ffe8c1a2ba4e79439bf065a0920537f7decb882056013d6e7740f8e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afec297ffe8c1a2ba4e79439bf065a0920537f7decb882056013d6e7740f8e9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CodeSimpleQA: Scaling Factuality in Code Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Yang, Wei Zhang, Yizhi Li, Shawn Guo, Haowen Wang, Aishan Liu, Ge Zhang, Zili Wang, Zhoujun Li, Xianglong Liu, Weifeng Lv</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19424" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19424</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91e94588098b016a931e564501e220f391d8186f55b4c39b93da715a899afb11_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91e94588098b016a931e564501e220f391d8186f55b4c39b93da715a899afb11_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeSimpleQA: Scaling Factuality in Code Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Bo Yin, Yaochu Jin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19516</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yinhuai Wang, Runyi Yu, Hok Wai Tsui, Xiaoyi Lin, Hui Zhang, Qihan Zhao, Ke Fan, Miao Li, Jie Song, Jingbo Wang, Qifeng Chen, Ping Tan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19583" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19583</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50064ac2ceaf4f963ab285d471e35de23cbb546a9b072cfb14bd945c6439276e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50064ac2ceaf4f963ab285d471e35de23cbb546a9b072cfb14bd945c6439276e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19673</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19691" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19691</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sheryl Chen, Tony Wang, Kyle Feinstein</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17929" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17929</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Yang, Chiyuan Wang, Andreas Schaab, Benjamin Moll</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18892</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haishan Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19104" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19104</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1de9f54709e8dfd7512b0bf65bde1fbf69bbf9510338a82e721bb9ab43307b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1de9f54709e8dfd7512b0bf65bde1fbf69bbf9510338a82e721bb9ab43307b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 34</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251223] Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Farida Mohsen, Ali Safa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17958</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Joshua Gibson, Kapil Dhakal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18034</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Accelerating End-to-End PDF to Markdown Conversion Through Assisted Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Changxu Duan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18122" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18122</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58612e72a18b314f91299b4a4f61d1fb3eaebfbccaa97bca668eb194568e1396_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58612e72a18b314f91299b4a4f61d1fb3eaebfbccaa97bca668eb194568e1396_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Accelerating End-to-End PDF to Markdown Conversion Through Assisted Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nuntipat Narkthong, Xiaolin Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18132" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18132</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5249dae70a6ea951da7229a4606840eb6080d2d0b091828439fd7dc722b3fe4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5249dae70a6ea951da7229a4606840eb6080d2d0b091828439fd7dc722b3fe4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PermuteV: A Performant Side-channel-Resistant RISC-V Core Securing Edge AI Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PIM-FW: Hardware-Software Co-Design of All-pairs Shortest Paths in DRAM</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tsung-Han Lu, Zheyu Li, Minxuan Zhou, Tajana Rosing</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18158" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18158</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c0e2dda9beb3cd09d48e66d5bd1e2e0d25dcf0ff68f729ae40eea17980532c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c0e2dda9beb3cd09d48e66d5bd1e2e0d25dcf0ff68f729ae40eea17980532c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PIM-FW: Hardware-Software Co-Design of All-pairs Shortest Paths in DRAM</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Building UI/UX Dataset for Dark Pattern Detection and YOLOv12x-based Real-Time Object Recognition Detection System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Se-Young Jang, Su-Yeon Yoon, Jae-Woong Jung, Dong-Hun Lee, Seong-Hun Choi, Soo-Kyung Jun, Yu-Bin Kim, Young-Seon Ju, Kyounggon Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18269" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18269</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/367924eac7293dd60fe2ea42c0f8cc5f30a08d5958f71c4e9e1a77afcf26f521_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/367924eac7293dd60fe2ea42c0f8cc5f30a08d5958f71c4e9e1a77afcf26f521_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Building UI/UX Dataset for Dark Pattern Detection and YOLOv12x-based Real-Time Object Recognition Detection System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Efficient Agents: A Co-Design of Inference Architecture and System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Weizhe Lin, Hui-Ling Zhen, Shuai Yang, Xian Wang, Renxi Liu, Hanting Chen, Wangze Zhang, Chuansai Zhou, Yiming Li, Chen Chen, Xing Li, Zhiyuan Yang, Xiaosong Li, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan, Yunhe Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18337" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18337</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7ed4e66482149eeb38c88b95b26442424c5cb783935dd1d2ae998dcbe934a3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7ed4e66482149eeb38c88b95b26442424c5cb783935dd1d2ae998dcbe934a3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Efficient Agents: A Co-Design of Inference Architecture and System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wonseok Choi, Hyunah Yu, Jongmin Kim, Hyesung Ji, Jaiyoung Park, Jung Ho Ahn</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18345" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18345</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e4c078425f57860f1303fe0449ae500adae2d4acf07294f16f8ed22a154bad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e4c078425f57860f1303fe0449ae500adae2d4acf07294f16f8ed22a154bad_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Weight Transformations in Bit-Sliced Crossbar Arrays for Fault Tolerant Computing-in-Memory: Design Techniques and Evaluation Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akul Malhotra, Sumeet Kumar Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18459" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18459</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97e8d699ae3dc2331ca317ecfd53fe4db9ae0d861417dcb1143bdade9d3ecfa0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97e8d699ae3dc2331ca317ecfd53fe4db9ae0d861417dcb1143bdade9d3ecfa0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Weight Transformations in Bit-Sliced Crossbar Arrays for Fault Tolerant Computing-in-Memory: Design Techniques and Evaluation Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SoK: Understanding (New) Security Issues Across AI4Code Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qilong Wu, Taoran Li, Tianyang Zhou, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18456" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18456</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SoK: Understanding (New) Security Issues Across AI4Code Use Cases</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Overcoming Spectral Bias via Cross-Attention</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiaodong Feng, Tao Tang, Xiaoliang Wan, Tao Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18586</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41a27de306c0dce8a093c2cb1cd83c5b2a1515e2b795e63c3f3140fda5f27898_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41a27de306c0dce8a093c2cb1cd83c5b2a1515e2b795e63c3f3140fda5f27898_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Overcoming Spectral Bias via Cross-Attention</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yifan Zhao, Xinglong Yu, Yi Sun, Honglin Kuang, Jun Han</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18589" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18589</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1feca70dc6f2a05e35a48f6366ccdcc1accb232952639d7388e6316ca2ff652_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1feca70dc6f2a05e35a48f6366ccdcc1accb232952639d7388e6316ca2ff652_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DNA-HHE: Dual-mode Near-network Accelerator for Hybrid Homomorphic Encryption on the Edge</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wencan Mao, Quanxi Zhou, Tomas Couso Coddou, Manabu Tsukada, Yunling Liu, Yusheng Ji</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18604" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18604</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SimpleCall: A Lightweight Image Restoration Agent in Label-Free Environments with MLLM Perceptual Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jianglin Lu, Yuanwei Wu, Ziyi Zhao, Hongcheng Wang, Felix Jimenez, Abrar Majeedi, Yun Fu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18599" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18599</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/196c51c23a0210e0d5f61fa9aa109b4c1b71673440779c2559e8762b7020daf5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/196c51c23a0210e0d5f61fa9aa109b4c1b71673440779c2559e8762b7020daf5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SimpleCall: A Lightweight Image Restoration Agent in Label-Free Environments with MLLM Perceptual Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pierre Colombo, Malik Boudiaf, Allyn Sweet, Michael Desa, Hongxi Wang, Kevin Candra, Syméon del Marmol</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18658" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18658</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99cb2c0d15c54813fefddf4670e9d0dc5b70cdc79ff9a13a7d5fb4f3a38f7143_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99cb2c0d15c54813fefddf4670e9d0dc5b70cdc79ff9a13a7d5fb4f3a38f7143_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xue Yang, Michael Schukat, Junlin Lu, Patrick Mannion, Karl Mason, Enda Howley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18670" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18670</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Thorsten Hellert, Nikolay Agladze, Alex Giovannone, Jan Jug, Frank Mayet, Mark Sherwin, Antonin Sulc, Chris Tennant</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18779" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18779</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4811b7a6317b8d33b2f92f5249b3e215e280fef25b4d76030d5495c78a7d02f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4811b7a6317b8d33b2f92f5249b3e215e280fef25b4d76030d5495c78a7d02f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generative Modeling through Spectral Analysis of Koopman Operator</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuanchao Xu, Fengyi Li, Masahiro Fujisawa, Youssef Marzouk, Isao Ishikawa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18837" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18837</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3838b816a163dddae4907465cfe37d64e1f909b2317422f86a8a2c6ad7e98898_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3838b816a163dddae4907465cfe37d64e1f909b2317422f86a8a2c6ad7e98898_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative Modeling through Spectral Analysis of Koopman Operator</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generalized Chebyshev acceleration on the unit disc</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nurgül Gökgöz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18848" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18848</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f63d665dcf2ac69573f3e985999d052f51eac8e7aa11582ea4d1a0234129824_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f63d665dcf2ac69573f3e985999d052f51eac8e7aa11582ea4d1a0234129824_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generalized Chebyshev acceleration on the unit disc</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Delta-LLaVA: Base-then-Specialize Alignment for Token-Efficient Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mohamad Zamini, Diksha Shukla</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18910</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82dc1b903fe39645cfdac67e793b8aaf7d0b36f43bd3088781f3ec68c702dafb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82dc1b903fe39645cfdac67e793b8aaf7d0b36f43bd3088781f3ec68c702dafb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Delta-LLaVA: Base-then-Specialize Alignment for Token-Efficient Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Merging of Kolmogorov-Arnold networks trained on disjoint datasets</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Andrew Polar, Michael Poluektov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18921" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18921</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e53714df09977ebe2db3d05959d679946262bcbddc4ea0acb1d3d3511f211611_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e53714df09977ebe2db3d05959d679946262bcbddc4ea0acb1d3d3511f211611_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Merging of Kolmogorov-Arnold networks trained on disjoint datasets</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Mamba-Based Modality Disentanglement Network for Multi-Contrast MRI Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Weiyi Lyu, Xinming Fang, Jun Wang, Jun Shi, Guixu Zhang, Juncheng Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19095" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19095</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/660b7ce425295dabbd643561507450b5b391330b19646c8c466147c1770bdf63_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/660b7ce425295dabbd643561507450b5b391330b19646c8c466147c1770bdf63_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mamba-Based Modality Disentanglement Network for Multi-Contrast MRI Reconstruction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards a collaborative digital platform for railway infrastructure projects</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pierre Jehel, Pierre-Étienne Gautier, Judicaël Dehotin, Flavien Viguier</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19169" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19169</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3874b7105990b7eea9564e4b1e9114f5f53c8e95ba6b7ddfc4422d6b9542ed5a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3874b7105990b7eea9564e4b1e9114f5f53c8e95ba6b7ddfc4422d6b9542ed5a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards a collaborative digital platform for railway infrastructure projects</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Phase-space entropy at acquisition reflects downstream learnability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiu-Cheng Wang, Jun-Jie Zhanga, Nan Cheng, Long-Gang Pang, Taijiao Du, Deyu Meng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19223" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19223</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6f7f5d98244f4027de001e9a63b027e02247bcd25714fdcf9483af34b3cbf0c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6f7f5d98244f4027de001e9a63b027e02247bcd25714fdcf9483af34b3cbf0c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Phase-space entropy at acquisition reflects downstream learnability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vision-Aided Relative State Estimation for Approach and Landing on a Moving Platform with Inertial Measurements</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tarek Bouazza, Alessandro Melis, Soulaimane Berkane, Robert Mahony, Tarek Hamel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d513f5a88f2a529f413e52c4a1f8a346c5bbe6ab056bc09090ccb37d3041a044_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d513f5a88f2a529f413e52c4a1f8a346c5bbe6ab056bc09090ccb37d3041a044_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vision-Aided Relative State Estimation for Approach and Landing on a Moving Platform with Inertial Measurements</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Binary Neural Network Implementation for Handwritten Digit Recognition on FPGA</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Emir Devlet Ertörer, Cem Ünsalan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19304" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19304</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f352565f0530b4ee02ed15da3cf6f6c724c3dee282c3ce8dcec4f2bb7a8bed00_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f352565f0530b4ee02ed15da3cf6f6c724c3dee282c3ce8dcec4f2bb7a8bed00_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Binary Neural Network Implementation for Handwritten Digit Recognition on FPGA</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongwei Fan, Hang Dai, Jiyao Zhang, Jinzhou Li, Qiyang Yan, Yujie Zhao, Mingju Gao, Jinghang Wu, Hao Tang, Hao Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19390" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19390</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf1e9d4003951dba668a306d606416b006b75689695b9667afa58a3ba76ea89_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf1e9d4003951dba668a306d606416b006b75689695b9667afa58a3ba76ea89_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] D2Pruner: Debiased Importance and Structural Diversity for MLLM Token Pruning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Evelyn Zhang, Fufu Yu, Aoqi Wu, Zichen Wen, Ke Yan, Shouhong Ding, Biqing Qi, Linfeng Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19443" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19443</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b276a091b11e8296a53fd51f1160b3e57aa375c543150f9b00e1f03505b59fa1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b276a091b11e8296a53fd51f1160b3e57aa375c543150f9b00e1f03505b59fa1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> D2Pruner: Debiased Importance and Structural Diversity for MLLM Token Pruning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Gauss-Newton-Induced Structure-Exploiting Algorithm for Differentiable Optimal Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuankun Chen, Zifei Nie, Xun Gong, Yunfeng Hu, Hong Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19447" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19447</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74ef4be4d92e46d4eb48894c23b5b114f6542e056ba7735882b575a70ef70317_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74ef4be4d92e46d4eb48894c23b5b114f6542e056ba7735882b575a70ef70317_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Gauss-Newton-Induced Structure-Exploiting Algorithm for Differentiable Optimal Control</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Agentic Framework for Autonomous Materials Computation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zeyu Xia, Jinzhe Ma, Congjie Zheng, Shufei Zhang, Yuqiang Li, Hang Su, P. Hu, Changshui Zhang, Xingao Gong, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Mao Su</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19458" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19458</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Agentic Framework for Autonomous Materials Computation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19526</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Muhammad Osama Imran, Roshni Lulla, Rodney Sappington</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17989" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17989</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evolutionary Cooperation with Game Transitions via Markov Decision Chain in Networked Population</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chaoyang Luo, Yuji Zhang, Minyu Feng, Attila Szolnoki</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18972" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18972</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af9b1c10d4d6654d591148d5bf2617a4e1b09646e5af8cfba3db0476ae3943b4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af9b1c10d4d6654d591148d5bf2617a4e1b09646e5af8cfba3db0476ae3943b4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evolutionary Cooperation with Game Transitions via Markov Decision Chain in Networked Population</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-24">2025-12-24<a href="#2025-12-24" class="hash-link" aria-label="Direct link to 2025-12-24" title="Direct link to 2025-12-24" translate="no">​</a></h2>
<p><strong>cs.DC total: 15</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251224] Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Tarizzo, Mohammad Kazemi, Deniz Gündüz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19777" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19777</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Holoscope: Open and Lightweight Distributed Telescope &amp; Honeypot Platform</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Andrea Sordello, Marco Mellia, Idilio Drago, Rodolfo Valentim, Francesco Musumeci, Massimo Tornatore, Federico Cerutti, Martino Trevisan, Alessio Botta, Willen Borges Coelho</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19842" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19842</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e888d5285a786a3c767579c7eaaca0375fc971ad3a2fb2064daa28b1f1f886b9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e888d5285a786a3c767579c7eaaca0375fc971ad3a2fb2064daa28b1f1f886b9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Holoscope: Open and Lightweight Distributed Telescope &amp; Honeypot Platform</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] An Adaptive Distributed Stencil Abstraction for GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aditya Bhosale, Laxmikant Kale</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19851" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19851</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c440cc2cd05a524e05f6d514a65e60b4224e6fad90cc6a9250733b6134c5563a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c440cc2cd05a524e05f6d514a65e60b4224e6fad90cc6a9250733b6134c5563a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Adaptive Distributed Stencil Abstraction for GPUs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UCCL-EP: Portable Expert-Parallel Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19849</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UCCL-EP: Portable Expert-Parallel Communication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengchao Han, Xi Huang, Yi Fang, Guojun Han</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19972" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19972</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68a57a4b48fd01d2fd3b5670a8a2ba0afbbd643b8ddcf8604e3c9fdeb4782d83_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68a57a4b48fd01d2fd3b5670a8a2ba0afbbd643b8ddcf8604e3c9fdeb4782d83_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Scaling Point-based Differentiable Rendering for Large-scale Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hexu Zhao, Xiaoteng Liu, Xiwen Min, Jianhao Huang, Youming Deng, Yanfei Li, Ang Li, Jinyang Li, Aurojit Panda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20017" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20017</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ce1e013da49adc5236a2b8d6111015f3c345c5b5d1cd6d9c9375d46d54a5c3d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ce1e013da49adc5236a2b8d6111015f3c345c5b5d1cd6d9c9375d46d54a5c3d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Point-based Differentiable Rendering for Large-scale Reconstruction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yaojian Chen, Si-Qiu Gong, Lin Gan, Yanfei Liu, An Yang, Yinuo Wang, Chao-yang Lu, Guangwen Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20064" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20064</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/daf5920f62b1d9628f22f64fd603d044ea22b1d4cbcf93ff65d5699edb214a6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/daf5920f62b1d9628f22f64fd603d044ea22b1d4cbcf93ff65d5699edb214a6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Population Protocols Revisited: Parity and Beyond</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Leszek Gąsieniec, Tytus Grodzicki, Tomasz Jurdziński, Jakub Kowalski, Grzegorz Stachowiak</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20163" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20163</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8aad104fc51d7c782bd987b120b6adc44b9209ecea22bf9d780ac0054be6ece3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8aad104fc51d7c782bd987b120b6adc44b9209ecea22bf9d780ac0054be6ece3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Population Protocols Revisited: Parity and Beyond</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chen Zhuang, Lingqi Zhang, Benjamin Brock, Du Wu, Peng Chen, Toshio Endo, Satoshi Matsuoka, Mohamed Wahib</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20178" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20178</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/340dca9738b4b1930a1331103d9fe185151f34d58d7be73cc31d211665f20128_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/340dca9738b4b1930a1331103d9fe185151f34d58d7be73cc31d211665f20128_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reaching Agreement Among Reasoning LLM Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chaoyi Ruan, Yiliang Wang, Ziji Shi, Jialin Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20184" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20184</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/300a553c72ebfc0b096f1fc824a5f548ba652ad4ed3a63bd7596ea2c6fa4c4a9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/300a553c72ebfc0b096f1fc824a5f548ba652ad4ed3a63bd7596ea2c6fa4c4a9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reaching Agreement Among Reasoning LLM Agents</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yinan Ni, Xiao Yang, Yuqi Tang, Zhimin Qiu, Chen Wang, Tingzhou Yuan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20210" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20210</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbb6bb6b2735659dd1638f766c8c42f1c8f809b00b87f15a65d394ddfae14463_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbb6bb6b2735659dd1638f766c8c42f1c8f809b00b87f15a65d394ddfae14463_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20363" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20363</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mohammad Walid Charrwi, Zaid Hussain</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20394" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20394</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b39d3fd875a1d18d18c3b4c5a175ce223ca72ea88ffe8906fbefdd667cb5178_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b39d3fd875a1d18d18c3b4c5a175ce223ca72ea88ffe8906fbefdd667cb5178_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] WOC: Dual-Path Weighted Object Consensus Made Efficient</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tanisha Fonseca, Gengrui Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20485" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20485</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5815c48f85f174b306c1a113a0f90bbdad3e1dbaf0212a44c24b093feff6ff3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5815c48f85f174b306c1a113a0f90bbdad3e1dbaf0212a44c24b093feff6ff3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> WOC: Dual-Path Weighted Object Consensus Made Efficient</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Pan, Zhuofu Chen, Ravi Netravali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 31</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251224] Holographic MIMO Empowered NOMA-ISAC for 6G: Rate-Splitting Enhanced Near-Field Modeling, Multi-Objective Optimization, and Statistical Performance Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumita Majhi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19699" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19699</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2183a3ab117ce8aa35a27ef5ef1f90999864af516e6e9184883dd8c000154d9c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2183a3ab117ce8aa35a27ef5ef1f90999864af516e6e9184883dd8c000154d9c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Holographic MIMO Empowered NOMA-ISAC for 6G: Rate-Splitting Enhanced Near-Field Modeling, Multi-Objective Optimization, and Statistical Performance Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19696" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19696</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19717</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Tiny, On-Device Decision Makers with the MiniConv Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carlos Purves</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19726</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tiny, On-Device Decision Makers with the MiniConv Library</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Hard Negative Sample-Augmented DPO Post-Training for Small Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haocheng Lu, Minjun Zhu, Henry Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19728" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19728</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c371de45b1b11fd08dee5a184a8d1c0b7de0a0ff5ecd8c96c44e8fddf3eabedc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c371de45b1b11fd08dee5a184a8d1c0b7de0a0ff5ecd8c96c44e8fddf3eabedc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Hard Negative Sample-Augmented DPO Post-Training for Small Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wilson Fung, Lu Guo, Drake Hilliard, Alessandro Casadei, Raj Ratan, Sreyoshi Bhaduri, Adi Surve, Nikhil Agarwal, Rohit Malshe, Pavan Mullapudi, Hungjen Wang, Saurabh Doodhwala, Ankush Pole, Arkajit Rakshit</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19738" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19738</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa995500ed323b0099b96191763cdf14300972d797c5bdf631faa22d483ef8d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa995500ed323b0099b96191763cdf14300972d797c5bdf631faa22d483ef8d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learning to Design City-scale Transit Routes</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bibek Poudel, Weizi Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19767" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19767</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning to Design City-scale Transit Routes</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] An Optimal Policy for Learning Controllable Dynamics by Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peter N. Loxley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Optimal Policy for Learning Controllable Dynamics by Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Scaling Reinforcement Learning for Content Moderation with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Reinforcement Learning for Content Moderation with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chaithra, Kamesh Kadimisetty, Biju R Mohan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20082</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, Lifeng Shang, Jeff Z. Pan, Yuxin Jiang, Kam-Fai Wong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20092</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f21f9409d7ddcd534ada400fa2d7b093de0f8e8672067e512129d84ead74883_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f21f9409d7ddcd534ada400fa2d7b093de0f8e8672067e512129d84ead74883_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Information-directed sampling for bandits: a primer</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Annika Hirling, Giorgio Nicoletti, Antonio Celani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20096</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bda193cb418441da95d0440f5f59e93b002d7bab9c57780520c427e9d3126c5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bda193cb418441da95d0440f5f59e93b002d7bab9c57780520c427e9d3126c5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Information-directed sampling for bandits: a primer</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20111" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20111</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuanhao Chen, Qi Liu, Pengbin Chen, Zhongjian Qiao, Yanjie Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20115" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20115</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5c5ab959b1aabba8373388341144fb9d59c759f4a45a536ba853663551ebb84_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5c5ab959b1aabba8373388341144fb9d59c759f4a45a536ba853663551ebb84_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multi-hop Reasoning via Early Knowledge Alignment</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20144" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20144</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d88b182b244d4a4ceb1d9822c08a4a4d748f40278f40b510b9dc474ab390f2c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d88b182b244d4a4ceb1d9822c08a4a4d748f40278f40b510b9dc474ab390f2c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-hop Reasoning via Early Knowledge Alignment</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dan Chen, Heye Huang, Tiantian Chen, Zheng Li, Yongji Li, Yuhui Xu, Sikai Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20179" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20179</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba879d80c9d58b4f8d7942ebda77c8c4b993bb9018f484a08adfe360eb40c02c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba879d80c9d58b4f8d7942ebda77c8c4b993bb9018f484a08adfe360eb40c02c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FaithLens: Detecting and Explaining Faithfulness Hallucination</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20182" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20182</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FaithLens: Detecting and Explaining Faithfulness Hallucination</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Offline Safe Policy Optimization From Heterogeneous Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ze Gong, Pradeep Varakantham, Akshat Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20173" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20173</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Safe Policy Optimization From Heterogeneous Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Edge-Served Congestion Control for Wireless Multipath Transmission with a Transformer Agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Liang Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20186" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20186</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16b93be39f0376f25deb8cc4fbada1a95fee8a407d89b5267be07145e8a1b9e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/16b93be39f0376f25deb8cc4fbada1a95fee8a407d89b5267be07145e8a1b9e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Edge-Served Congestion Control for Wireless Multipath Transmission with a Transformer Agent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Joint Design of Embedded Index Coding and Beamforming for MIMO-based Distributed Computing via Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Heekang Song, Wan Choi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20201" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20201</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cef2c0107d65c30e332cf8fcbb67cfa02aecf72c8313c8aa9f6eed48502a4093_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cef2c0107d65c30e332cf8fcbb67cfa02aecf72c8313c8aa9f6eed48502a4093_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Joint Design of Embedded Index Coding and Beamforming for MIMO-based Distributed Computing via Multi-Agent Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kausthubh Manda, Raghuram Bharadwaj Diddigi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20220" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20220</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96bb0ad288cee461b985922b13e1446ef6b03b8ee1b5f20f1e908e0e81174e2b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96bb0ad288cee461b985922b13e1446ef6b03b8ee1b5f20f1e908e0e81174e2b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Divya Vijay, Vignesh Ethiraj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20312</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Identifying Appropriately-Sized Services with Deep Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20381" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20381</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Appropriately-Sized Services with Deep Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Recurrent Off-Policy Deep Reinforcement Learning Doesn&#x27;t Have to be Slow</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tyler Clark, Christine Evers, Jonathon Hare</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20513" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20513</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfed8377a526fc8b1686b7063bcf7aa6afc36205aa596ab393544501923d4a4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfed8377a526fc8b1686b7063bcf7aa6afc36205aa596ab393544501923d4a4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Recurrent Off-Policy Deep Reinforcement Learning Doesn&#x27;t Have to be Slow</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Performative Policy Gradient: Optimality in Performative Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Performative Policy Gradient: Optimality in Performative Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20589" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20589</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LongVideoAgent: Multi-Agent Reasoning with Long Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LongVideoAgent: Multi-Agent Reasoning with Long Videos</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 22</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251224] Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vasileios C. Pezoulas, Nikolaos S. Tachos, Eleni Georga, Kostas Marias, Manolis Tsiknakis, Dimitrios I. Fotiadis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19718" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19718</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/690024688881d156d3131447c4b795c922984c2e3732a32a3b139b183a1be23e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/690024688881d156d3131447c4b795c922984c2e3732a32a3b139b183a1be23e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] High-Performance Self-Supervised Learning by Joint Training of Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kosuke Ukita, Tsuyoshi Okita</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19729" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19729</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> High-Performance Self-Supervised Learning by Joint Training of Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] EdgeFlex-Transformer: Transformer Inference for Edge Devices</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shoaib Mohammad, Guanqun Song, Ting Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19741" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19741</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a472c5a3779ea5b970e030fee19030719f5db1d085d239de2dc5df41dffd7439_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a472c5a3779ea5b970e030fee19030719f5db1d085d239de2dc5df41dffd7439_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EdgeFlex-Transformer: Transformer Inference for Edge Devices</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ilsun Chang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19750" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19750</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22261640471da63aebf047b2045859846dac3cc2b34448b820a7154bc31cfb4f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22261640471da63aebf047b2045859846dac3cc2b34448b820a7154bc31cfb4f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Risk-Aware GPU-Assisted Cardinality Estimation for Cost-Based Query Optimizers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19799" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19799</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kian Godhwani, David Benrimoh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20022" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20022</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd553d2c8dfa3e24074d8dc0752a5348a2dc9e7e83526071de4a16c28bb018b6_w640_q70.png" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd553d2c8dfa3e24074d8dc0752a5348a2dc9e7e83526071de4a16c28bb018b6_w640_q70.png</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-Assisted Abstract Screening with OLIVER: Evaluating Calibration and Single-Model vs. Actor-Critic Configurations in Literature Reviews</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] VSA<!-- -->:Visual-Structural<!-- --> Alignment for UI-to-Code</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xian Wu, Ming Zhang, Zhiyu Fang, Fei Li, Bin Wang, Yong Jiang, Hao Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20034</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96d552b0d871e15200119995d18b2c4223e07f8d868c7cc4caaa9ee14883b636_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96d552b0d871e15200119995d18b2c4223e07f8d868c7cc4caaa9ee14883b636_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VSA<!-- -->:Visual-Structural<!-- --> Alignment for UI-to-Code</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingue Park, Jisung Hwang, Seungwoo Yoo, Kyeongmin Yeo, Minhyuk Sung</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20063" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20063</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1f331573ffd5fdda741a1d0056236e66fefa140bd0c2b8c4b173e3519544061_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1f331573ffd5fdda741a1d0056236e66fefa140bd0c2b8c4b173e3519544061_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Huizheng Wang, Taiquan Wei, Hongbin Wang, Zichuan Wang, Xinru Tang, Zhiheng Yue, Shaojun Wei, Yang Hu, Shouyi Yin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20198" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20198</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e2bc2f765accf0fbb24e05e708bd3a2b62c961a86def9137c9976aa8b753f85_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e2bc2f765accf0fbb24e05e708bd3a2b62c961a86def9137c9976aa8b753f85_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TongSIM: A General Platform for Simulating Intelligent Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Sun, Kunlun Wu, Chuanjian Fu, Zeming Song, Langyong Shi, Zihe Xue, Bohan Jing, Ying Yang, Xiaomeng Gao, Aijia Li, Tianyu Guo, Huiying Li, Xueyuan Yang, Rongkai Liu, Xinyi He, Yuxi Wang, Yue Li, Mingyuan Liu, Yujie Lu, Hongzhao Xie, Shiyun Zhao, Bo Dai, Wei Wang, Tao Yuan, Song-Chun Zhu, Yujia Peng, Zhenliang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TongSIM: A General Platform for Simulating Intelligent Machines</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DeepONet-accelerated Bayesian inversion for moving boundary problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marco A. Iglesias, Michael. E. Causon, Mikhail Y. Matveev, Andreas Endruweit, Michael .V. Tretyakov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20268" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20268</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cca57b0bdfa7635748d75eae61d7af10d528a81997788a87eb9ab2703231769b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cca57b0bdfa7635748d75eae61d7af10d528a81997788a87eb9ab2703231769b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DeepONet-accelerated Bayesian inversion for moving boundary problems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Ferroelectric FET-based Logic-in-Memory Encoder for Hyperdimensional Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Arka Chakraborty, Franz Müller, Thomas Kämpfe, Shubham Sahay</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20302" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20302</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6feea0ba4ef2950fd67ff0b965cd0f25df3de85c5b2c14b3b86666f9afc997e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6feea0ba4ef2950fd67ff0b965cd0f25df3de85c5b2c14b3b86666f9afc997e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Ferroelectric FET-based Logic-in-Memory Encoder for Hyperdimensional Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mrinmay Sen, Subhrajit Nag</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20329" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20329</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f60b7e61ea92d36b52de81bc3df02c7af567b1cd9eb4626ad016c3ce36765e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f60b7e61ea92d36b52de81bc3df02c7af567b1cd9eb4626ad016c3ce36765e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Emilia Majerz, Witold Dzwinel, Jacek Kitowski</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20346" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20346</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d6aa7726e909753c196217ccc3bdf17d07a9339b0fc1d35361587823848df71_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d6aa7726e909753c196217ccc3bdf17d07a9339b0fc1d35361587823848df71_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SmartSplat: Feature-Smart Gaussians for Scalable Compression of Ultra-High-Resolution Images</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linfei Li, Lin Zhang, Zhong Wang, Ying Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20377" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20377</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06dc77546a31f168b83f87c8efbfe002590b29ab252385b482db477a74d615ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06dc77546a31f168b83f87c8efbfe002590b29ab252385b482db477a74d615ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SmartSplat: Feature-Smart Gaussians for Scalable Compression of Ultra-High-Resolution Images</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kanchon Gharami, Sanjiv Kumar Sarkar, Yongxin Liu, Shafika Showkat Moni</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20405" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20405</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594ed7491abb39e62fd7b3759310d809c622b7da530d48b7e61a79c247aa8e25_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594ed7491abb39e62fd7b3759310d809c622b7da530d48b7e61a79c247aa8e25_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ChatGPT: Excellent Paper! Accept It. Editor: Imposter Found! Review Rejected</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20469" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20469</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> He Zhu, Zheng Liu, Xingyang Li, Anbang Wu, Jieru Zhao, Fangxin Liu, Yiming Gan, Jingwen Leng, Yu Feng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20495</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1ba8a7f58cc0b9807b31889823cb7497448ae885dece28021d7b9eda1828c58_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1ba8a7f58cc0b9807b31889823cb7497448ae885dece28021d7b9eda1828c58_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alexandros Christoforos, Chadbourne Davis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20604" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20604</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/740b7502b49c1387c998a9fd8b95bff7878c9c8ecb80d21efccf1c64db303459_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/740b7502b49c1387c998a9fd8b95bff7878c9c8ecb80d21efccf1c64db303459_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QMBench: A Research Level Benchmark for Quantum Materials Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanzhen Wang, Yiyang Jiang, Diana Golovanova, Kamal Das, Hyeonhu Bae, Yufei Zhao, Huu-Thong Le, Abhinava Chatterjee, Yunzhe Liu, Chao-Xing Liu, Felipe H. da Jornada, Binghai Yan, Xiao-Liang Qi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19753" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19753</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QMBench: A Research Level Benchmark for Quantum Materials Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Towards a point-to-point CV-QKD system: Implementation challenges and perspectives</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Davi Juvêncio Gomes de Sousa, Nelson Alves Ferreira Neto, Christiano M. S. Nascimento, Lucas Q. Galvão, Mauro Queiroz Nooblath Neto, Micael Andrade Dias, Cássio de Castro Silva, Braian Pinheiro da Silva, Alexandre B. Tacla, Valéria Loureiro da Silva</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19834" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19834</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa7fbf5acad2dd0ae547f58bc198ca67d3b36ccc31ad024285f0358a08cb6c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa7fbf5acad2dd0ae547f58bc198ca67d3b36ccc31ad024285f0358a08cb6c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards a point-to-point CV-QKD system: Implementation challenges and perspectives</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mebin Jose, Jisha Francis, Sudheesh Kumar Kattumannil</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20305" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20305</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f5766a6c4e9984e1a7c6234a1bf0776e7a9fad9ef648cc4ca17ad3ba035698_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f5766a6c4e9984e1a7c6234a1bf0776e7a9fad9ef648cc4ca17ad3ba035698_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-25T03:58:05.000Z" itemprop="dateModified">Dec 25, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/20251215-20251221"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251215-20251221</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-22" class="table-of-contents__link toc-highlight">2025-12-22</a></li><li><a href="#2025-12-23" class="table-of-contents__link toc-highlight">2025-12-23</a></li><li><a href="#2025-12-24" class="table-of-contents__link toc-highlight">2025-12-24</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251222/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>