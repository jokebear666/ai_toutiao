<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251229-20260104" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251229-20260104 | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251229-20260104 | AI头条"><meta data-rh="true" name="description" content="2025-12-29"><meta data-rh="true" property="og:description" content="2025-12-29"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"20251229-20260104","item":"https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.38d649e8.css">
<script src="/ai_toutiao/assets/js/runtime~main.ded78d19.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.e580b2b9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251229-20260104</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251229-20260104</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-29">2025-12-29<a href="#2025-12-29" class="hash-link" aria-label="Direct link to 2025-12-29" title="Direct link to 2025-12-29" translate="no">​</a></h2>
<p><strong>cs.DC total: 16</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda</p>
</li>
<li class="">
<p><strong>institution:</strong> Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21340" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21340</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Lukić, Franck Cappello</p>
</li>
<li class="">
<p><strong>institution:</strong> University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21433" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21433</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Demystifying ARM SME to Optimize General Matrix Multiplications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [ARM SME, GEMM, cache-aware partitioning, micro-kernels, on-the-fly transposition]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong</p>
</li>
<li class="">
<p><strong>institution:</strong> College of Computer Science and Technology, National University of Defense Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21473" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21473</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic characterization of the ARM SME architecture that derives optimization guidelines for GEMM. 2. The design and implementation of MpGEMM, an open-source library featuring cache-aware partitioning and efficient data packing with on-the-fly transposition. 3. Specialized micro-kernels that fully utilize SME&#x27;s multi-vector loads and all available tile registers to maximize performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underutilization of ARM&#x27;s Scalable Matrix Extension (SME) hardware for large-scale General Matrix Multiplication (GEMM). It proposes MpGEMM, an open-source library that optimizes GEMM through cache-aware partitioning, efficient data packing, and specialized micro-kernels tailored for SME. Evaluations on an Apple M4 Pro show MpGEMM achieves a 1.23x speedup over the vendor-optimized Apple Accelerate library.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21487" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21487</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Canaan Inc.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21571" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21571</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/kendryte/nncase" target="_blank" rel="noopener noreferrer" class="">https://github.com/kendryte/nncase</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a &quot;compile once, adapt everywhere&quot; capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]</p>
</li>
<li class="">
<p><strong>authors:</strong> Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science and Technology of China (USTC), Hefei University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21615" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21615</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [real-time systems], [lock-free, fault-tolerance, resource sharing, multicore, worst-case response time analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> University of York, Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21701</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [vision transformer, cloud-device collaboration, dynamic scheduling, patch-level importance, weighted ensembling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, Tsinghua University, Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21730</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A collaboration-aware importance scorer that identifies critical regions at the patch level for selective processing. 2. A dynamic scheduler that adaptively adjusts patch transmission quality to balance latency and accuracy under changing network conditions. 3. A weighted ensembler that fuses edge and cloud inference results to improve overall accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Hyperion, a cloud-device collaborative framework designed to enable low-latency inference on Ultra-HD video using off-the-shelf vision transformers. It tackles computational and transmission bottlenecks by selectively processing critical patches, dynamically adjusting transmission quality, and fusing results. Experiments show Hyperion improves frame processing rate by up to 1.61x and accuracy by up to 20.2% compared to baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]</p>
</li>
<li class="">
<p><strong>authors:</strong> Krishna Chaitanya Sunkara, Rambabu Konakanchi</p>
</li>
<li class="">
<p><strong>institution:</strong> Oracle, Charles Schwab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21801" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21801</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Probabilistic LSTM forecasting validated within ±30-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] LIME<!-- -->:Accelerating<!-- --> Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [collaborative inference, pipeline parallelism, model offloading, memory adaptation, edge computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Shandong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21835" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21835</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LIME, a collaborative system for lossless LLM inference across multiple memory-constrained edge devices under limited bandwidth. 2. Employs an interleaved pipeline parallelism with model offloading to dynamically balance computation and communication. 3. Introduces a fine-grained offline allocation scheduler and an online memory adaptation strategy to optimize resource usage and minimize inference latency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes LIME, a system that enables lossless, collaborative LLM inference on multiple memory-constrained edge devices by using interleaved pipeline parallelism and model offloading, along with offline scheduling and online memory adaptation. Experiments on four Nvidia Jetson devices with LLaMA3.3-70B show that LIME achieves significant speedups over baselines without accuracy loss.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tingyang Sun, Ting He, Bo Ji, Parimal Parag</p>
</li>
<li class="">
<p><strong>institution:</strong> Pennsylvania State University, Virginia Tech, Indian Institute of Science</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21884" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21884</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] BLEST: Blazingly Efficient BFS using Tensor Cores</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [BFS, Tensor Cores, SpMSpV, Graph Reordering, Kernel Fusion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deniz Elbek, Kamer Kaya</p>
</li>
<li class="">
<p><strong>institution:</strong> Sabanci University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21967" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21967</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Giuseppe De Palma, Saverio Giallorenzo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22054" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22054</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [communication &amp; networking], [Mixture-of-Experts, expert parallelism, data shuffling, transformation-communication fusion, collective communication]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Infinigence AI, University of Southern California, Zhongguancun Academy, Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22036" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22036</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies the root cause of inefficiency in MoE data shuffling as the misalignment between expert-major and device-major data layouts, requiring disaggregated transformation and communication. 2. Proposes FUSCO, a communication library that fuses data transformation and communication operations into a single, efficient pipeline to eliminate redundant data movement. 3. Introduces lightweight planning and load-balancing mechanisms to eliminate redundant communication and disperse traffic, further optimizing the shuffling process.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the performance bottleneck of distributed data shuffling in Mixture-of-Experts (MoE) model training and inference. It proposes FUSCO, a communication library that fuses data transformation and communication to align expert-major and device-major data layouts efficiently. Evaluations show FUSCO achieves significant speedups over existing libraries like NCCL and DeepEP, reducing both training and inference latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [federated fine-tuning, connection failures, adaptive aggregation, data heterogeneity, convergence guarantee]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang</p>
</li>
<li class="">
<p><strong>institution:</strong> The affiliations include IEEE members, suggesting multiple institutions. Based on common patterns, likely institutions include The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen) and/or other Chinese universities/tech institutes, given authors like Tsung-Hui Chang and Tony Q. S. Quek are affiliated with such institutions.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22035" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22035</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FedAuto, a novel Federated Fine-Tuning framework that mitigates the combined effects of unreliable connections and data heterogeneity via adaptive aggregation, requiring no prior knowledge of network conditions. 2. Establishes a rigorous, per-round convergence guarantee for FedAuto that holds for each individual realization, removing common assumptions on failure probabilities or client selection. 3. Demonstrates through extensive experiments that FedAuto outperforms state-of-the-art baselines under diverse failure scenarios for both full and partial-parameter fine-tuning (e.g., LoRA).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the performance degradation of Federated Fine-Tuning (FFT) in real-world networks with unreliable connections and heterogeneous data. It proposes FedAuto, a framework that uses adaptive aggregation to handle these issues without prior network knowledge or infrastructure changes. Experiments show FedAuto consistently outperforms existing methods and provides stronger theoretical convergence guarantees.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois at Urbana-Champaign, IBM Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22113" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22113</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 17</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Santhosh Kumar Ravindran</p>
</li>
<li class="">
<p><strong>institution:</strong> Microsoft Corporation</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21351" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21351</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as &quot;genomes&quot; that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]</p>
</li>
<li class="">
<p><strong>authors:</strong> Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21395" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21395</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng</p>
</li>
<li class="">
<p><strong>institution:</strong> Illinois Institute of Technology, California State University, San Bernardino</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21412</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington, University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21446" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21446</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards &quot;diffusion supremacy&quot; over autoregressive models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21514" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21514</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Generative Actor Critic</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21527</a></p>
</li>
<li class="">
<p><strong>code:</strong> github.com/qayqaq/Generative-Actor-Critic</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Harbin Institute of Technology, Shenzhen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21540" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21540</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Towards Learning-Based Formula 1 Race Strategies</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [mixed-integer nonlinear programming, reinforcement learning, energy allocation, tire wear, pit stop]</p>
</li>
<li class="">
<p><strong>authors:</strong> Giona Fieni, Joschua Wüthrich, Marc-Philippe Neumann, Mohammad M. Moradi, Christopher H. Onder</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute for Dynamic Systems and Control, ETH Zürich</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21570</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a comprehensive race scenario model for Formula 1 that jointly accounts for energy allocation, tire wear, and pit stop timing using lap time maps and a dynamic tire wear model. 2. Develops and solves the strategy optimization problem using a Mixed-Integer Nonlinear Program (MINLP) to handle the integer decisions of pit stops. 3. Implements a complementary Reinforcement Learning (RL) framework trained on the same scenario, providing a fast-inference solution suitable for real-time human decision support during races.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes two complementary frameworks to optimize Formula 1 race strategies by jointly managing energy, tire wear, and pit stops. It uses a Mixed-Integer Nonlinear Program for optimal offline planning and a Reinforcement Learning agent for fast, real-time inference. The RL agent achieves suboptimality of only about 5 seconds in a 1.5-hour race, demonstrating its potential for real-time strategic assistance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xin Liu, Haoran Li, Dongbin Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21586</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Renmin University of China, The Chinese University of Hong Kong, Ant Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21625" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21625</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maximilian Weichart</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Regensburg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21648" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21648</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Max-We/inverse-rpo" target="_blank" rel="noopener noreferrer" class="">https://github.com/Max-We/inverse-rpo</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [communication &amp; networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin</p>
</li>
<li class="">
<p><strong>institution:</strong> Kyung Hee University, Ghent University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21717</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> National Taiwan Normal University, Wells Fargo Bank</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21819" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21819</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&amp;P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&amp;P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark&#x27;s 7.09%, demonstrating its effectiveness in dynamic financial environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville</p>
</li>
<li class="">
<p><strong>institution:</strong> Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21852" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21852</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]</p>
</li>
<li class="">
<p><strong>authors:</strong> KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21919" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21919</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [forward-backward MDP, multi-objective reinforcement learning, orthogonal multipoint multicast, wireless caching, latency optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohsen Amidzadeh</p>
</li>
<li class="">
<p><strong>institution:</strong> Aalto University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21954</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel forward-backward Markov decision process (FB-MDP) model that captures both the forward dynamics of user preferences and the backward dynamics of latency in a cache-aided multicast network. 2. Proposes a forward-backward multi-objective reinforcement learning (FB-MORL) algorithm to optimize for expected latency, outage probability, and resource consumption simultaneously. 3. Demonstrates through simulation that the proposed FB-MORL algorithm can find a promising dynamic cache policy for latency-optimal streaming.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of optimizing streaming latency in a cellular network with cache-enabled base stations using multicast. The authors propose a novel forward-backward reinforcement learning framework that models the network&#x27;s temporal dynamics as a multi-objective Markov decision process. Simulation results show their method is effective in finding a dynamic cache policy that reduces latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [communication &amp; networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]</p>
</li>
<li class="">
<p><strong>authors:</strong> Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers</p>
</li>
<li class="">
<p><strong>institution:</strong> Delft University of Technology, Telefónica Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22022" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22022</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&amp;C), encryption weaknesses, radio-frequency (RF) links]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mark Ballard, Guanqun Song, Ting Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> The Ohio State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21367</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&amp;C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington, University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21446" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21446</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards &quot;diffusion supremacy&quot; over autoregressive models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21452</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi</p>
</li>
<li class="">
<p><strong>institution:</strong> Technical University of Darmstadt</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21524" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21524</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a &quot;digital twin&quot;. 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinru Wen, Weizhong Lin, Xuan Xiao</p>
</li>
<li class="">
<p><strong>institution:</strong> JCI (inferred from email domain <code>jci.edu.cn</code>)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21544" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21544</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University, University of California, Riverside</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21563" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21563</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework&#x27;s capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework&#x27;s applicability to various data distributions and algorithms beyond ISTA/FISTA.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maximilian Weichart</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Regensburg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21648" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21648</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Max-We/inverse-rpo" target="_blank" rel="noopener noreferrer" class="">https://github.com/Max-We/inverse-rpo</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis</p>
</li>
<li class="">
<p><strong>institution:</strong> Purdue University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21757" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21757</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&amp;R model]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21766" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21766</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&amp;Resource (A/R/A&amp;R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&amp;R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Evgeny Alves Limarenko, Anastasiia Studenikina</p>
</li>
<li class="">
<p><strong>institution:</strong> Moscow Institute of Physics and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21769</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [speculative decoding, draft tree, inference acceleration, autoregressive image generation, dynamic tree structure]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Southeast University, Institute of Automation Chinese Academy of Sciences, Singapore Management University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21857</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Haodong-Lei-Ray/ADT-Tree" target="_blank" rel="noopener noreferrer" class="">https://github.com/Haodong-Lei-Ray/ADT-Tree</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified the key obstacle of applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to spatially varying token prediction difficulty. 2. Proposed ADT-Tree, an adjacency-adaptive dynamic draft tree that dynamically adjusts tree depth and width based on adjacent token states and prior acceptance rates. 3. Demonstrated significant speedups (over 3x) on benchmarks and seamless integration with relaxed sampling methods for further acceleration.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow inference of visual autoregressive models by proposing ADT-Tree, a dynamic draft tree method that adapts its structure to image region complexity. It achieves over 3x speedup on standard benchmarks and can be combined with other sampling techniques for additional gains.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Soochow University, Meituan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21911</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong</p>
</li>
<li class="">
<p><strong>institution:</strong> Southern University of Science and Technology, Microsoft Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21925</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm&#x27;s consistent advantage over purely online or offline baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21970</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://shengliangd.github.io/StereoVLA-Webpage" target="_blank" rel="noopener noreferrer" class="">https://shengliangd.github.io/StereoVLA-Webpage</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar</p>
</li>
<li class="">
<p><strong>institution:</strong> National School of Artificial Intelligence (ENSIA)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22007</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22065" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22065</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://streamavatar.github.io" target="_blank" rel="noopener noreferrer" class="">https://streamavatar.github.io</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras</p>
</li>
<li class="">
<p><strong>institution:</strong> Uppsala University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22066</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Yume-1.5: A Text-Controlled Interactive World Generation Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [interactive world generation, long-video generation, attention distillation, context compression, text-controlled generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai AI Laboratory, Fudan University, Shanghai Innovation Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22096</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/stdstu12/YUME" target="_blank" rel="noopener noreferrer" class="">https://github.com/stdstu12/YUME</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A long-video generation framework integrating unified context compression with linear attention. 2. A real-time streaming acceleration strategy using bidirectional attention distillation and an enhanced text embedding scheme. 3. A text-controlled method for generating world events.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Yume-1.5, a framework to address challenges in generating interactive, explorable worlds using diffusion models, such as large model size and slow inference. The method introduces a novel architecture combining context compression, attention distillation, and text-based event control to enable real-time, keyboard-controlled world generation from text or images. The work concludes with a public codebase demonstrating the feasibility of text-controlled interactive world creation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Imperial College London, Fudan University, Xiamen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21652" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21652</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-29T06:08:20.000Z" itemprop="dateModified">Dec 29, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/20251222-20251228"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251222-20251228</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-29" class="table-of-contents__link toc-highlight">2025-12-29</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>