<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/20251229-20260104" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251229-20260104 | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251229-20260104 | AI头条"><meta data-rh="true" name="description" content="2025-12-29"><meta data-rh="true" property="og:description" content="2025-12-29"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"20251229-20260104","item":"https://jokebear666.github.io/ai_toutiao/daily/20251229-20260104"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.647bd1ff.css">
<script src="/ai_toutiao/assets/js/runtime~main.500c5cf3.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.1e3609bc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251229-20260104</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251229-20260104</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-29">2025-12-29<a href="#2025-12-29" class="hash-link" aria-label="Direct link to 2025-12-29" title="Direct link to 2025-12-29" translate="no">​</a></h2>
<p><strong>cs.DC total: 16</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda</p>
</li>
<li class="">
<p><strong>institution:</strong> Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21340" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21340</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Lukić, Franck Cappello</p>
</li>
<li class="">
<p><strong>institution:</strong> University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21433" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21433</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Demystifying ARM SME to Optimize General Matrix Multiplications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [ARM SME, GEMM, cache-aware partitioning, micro-kernels, on-the-fly transposition]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong</p>
</li>
<li class="">
<p><strong>institution:</strong> College of Computer Science and Technology, National University of Defense Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21473" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21473</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic characterization of the ARM SME architecture that derives optimization guidelines for GEMM. 2. The design and implementation of MpGEMM, an open-source library featuring cache-aware partitioning and efficient data packing with on-the-fly transposition. 3. Specialized micro-kernels that fully utilize SME&#x27;s multi-vector loads and all available tile registers to maximize performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underutilization of ARM&#x27;s Scalable Matrix Extension (SME) hardware for large-scale General Matrix Multiplication (GEMM). It proposes MpGEMM, an open-source library that optimizes GEMM through cache-aware partitioning, efficient data packing, and specialized micro-kernels tailored for SME. Evaluations on an Apple M4 Pro show MpGEMM achieves a 1.23x speedup over the vendor-optimized Apple Accelerate library.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21487" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21487</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Canaan Inc.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21571" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21571</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/kendryte/nncase" target="_blank" rel="noopener noreferrer" class="">https://github.com/kendryte/nncase</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a &quot;compile once, adapt everywhere&quot; capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]</p>
</li>
<li class="">
<p><strong>authors:</strong> Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science and Technology of China (USTC), Hefei University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21615" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21615</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [real-time systems], [lock-free, fault-tolerance, resource sharing, multicore, worst-case response time analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> University of York, Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21701</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [vision transformer, cloud-device collaboration, dynamic scheduling, patch-level importance, weighted ensembling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, Tsinghua University, Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21730</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A collaboration-aware importance scorer that identifies critical regions at the patch level for selective processing. 2. A dynamic scheduler that adaptively adjusts patch transmission quality to balance latency and accuracy under changing network conditions. 3. A weighted ensembler that fuses edge and cloud inference results to improve overall accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Hyperion, a cloud-device collaborative framework designed to enable low-latency inference on Ultra-HD video using off-the-shelf vision transformers. It tackles computational and transmission bottlenecks by selectively processing critical patches, dynamically adjusting transmission quality, and fusing results. Experiments show Hyperion improves frame processing rate by up to 1.61x and accuracy by up to 20.2% compared to baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]</p>
</li>
<li class="">
<p><strong>authors:</strong> Krishna Chaitanya Sunkara, Rambabu Konakanchi</p>
</li>
<li class="">
<p><strong>institution:</strong> Oracle, Charles Schwab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21801" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21801</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Probabilistic LSTM forecasting validated within ±30-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] LIME<!-- -->:Accelerating<!-- --> Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [collaborative inference, pipeline parallelism, model offloading, memory adaptation, edge computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Shandong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21835" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21835</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LIME, a collaborative system for lossless LLM inference across multiple memory-constrained edge devices under limited bandwidth. 2. Employs an interleaved pipeline parallelism with model offloading to dynamically balance computation and communication. 3. Introduces a fine-grained offline allocation scheduler and an online memory adaptation strategy to optimize resource usage and minimize inference latency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes LIME, a system that enables lossless, collaborative LLM inference on multiple memory-constrained edge devices by using interleaved pipeline parallelism and model offloading, along with offline scheduling and online memory adaptation. Experiments on four Nvidia Jetson devices with LLaMA3.3-70B show that LIME achieves significant speedups over baselines without accuracy loss.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tingyang Sun, Ting He, Bo Ji, Parimal Parag</p>
</li>
<li class="">
<p><strong>institution:</strong> Pennsylvania State University, Virginia Tech, Indian Institute of Science</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21884" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21884</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] BLEST: Blazingly Efficient BFS using Tensor Cores</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [BFS, Tensor Cores, SpMSpV, Graph Reordering, Kernel Fusion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deniz Elbek, Kamer Kaya</p>
</li>
<li class="">
<p><strong>institution:</strong> Sabanci University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21967" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21967</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Giuseppe De Palma, Saverio Giallorenzo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22054" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22054</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [communication &amp; networking], [Mixture-of-Experts, expert parallelism, data shuffling, transformation-communication fusion, collective communication]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Infinigence AI, University of Southern California, Zhongguancun Academy, Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22036" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22036</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies the root cause of inefficiency in MoE data shuffling as the misalignment between expert-major and device-major data layouts, requiring disaggregated transformation and communication. 2. Proposes FUSCO, a communication library that fuses data transformation and communication operations into a single, efficient pipeline to eliminate redundant data movement. 3. Introduces lightweight planning and load-balancing mechanisms to eliminate redundant communication and disperse traffic, further optimizing the shuffling process.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the performance bottleneck of distributed data shuffling in Mixture-of-Experts (MoE) model training and inference. It proposes FUSCO, a communication library that fuses data transformation and communication to align expert-major and device-major data layouts efficiently. Evaluations show FUSCO achieves significant speedups over existing libraries like NCCL and DeepEP, reducing both training and inference latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [federated fine-tuning, connection failures, adaptive aggregation, data heterogeneity, convergence guarantee]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang</p>
</li>
<li class="">
<p><strong>institution:</strong> The affiliations include IEEE members, suggesting multiple institutions. Based on common patterns, likely institutions include The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen) and/or other Chinese universities/tech institutes, given authors like Tsung-Hui Chang and Tony Q. S. Quek are affiliated with such institutions.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22035" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22035</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FedAuto, a novel Federated Fine-Tuning framework that mitigates the combined effects of unreliable connections and data heterogeneity via adaptive aggregation, requiring no prior knowledge of network conditions. 2. Establishes a rigorous, per-round convergence guarantee for FedAuto that holds for each individual realization, removing common assumptions on failure probabilities or client selection. 3. Demonstrates through extensive experiments that FedAuto outperforms state-of-the-art baselines under diverse failure scenarios for both full and partial-parameter fine-tuning (e.g., LoRA).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the performance degradation of Federated Fine-Tuning (FFT) in real-world networks with unreliable connections and heterogeneous data. It proposes FedAuto, a framework that uses adaptive aggregation to handle these issues without prior network knowledge or infrastructure changes. Experiments show FedAuto consistently outperforms existing methods and provides stronger theoretical convergence guarantees.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois at Urbana-Champaign, IBM Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22113" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22113</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 17</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Santhosh Kumar Ravindran</p>
</li>
<li class="">
<p><strong>institution:</strong> Microsoft Corporation</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21351" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21351</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as &quot;genomes&quot; that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]</p>
</li>
<li class="">
<p><strong>authors:</strong> Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21395" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21395</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng</p>
</li>
<li class="">
<p><strong>institution:</strong> Illinois Institute of Technology, California State University, San Bernardino</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21412</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington, University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21446" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21446</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards &quot;diffusion supremacy&quot; over autoregressive models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21514" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21514</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Generative Actor Critic</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21527</a></p>
</li>
<li class="">
<p><strong>code:</strong> github.com/qayqaq/Generative-Actor-Critic</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Harbin Institute of Technology, Shenzhen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21540" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21540</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Towards Learning-Based Formula 1 Race Strategies</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [mixed-integer nonlinear programming, reinforcement learning, energy allocation, tire wear, pit stop]</p>
</li>
<li class="">
<p><strong>authors:</strong> Giona Fieni, Joschua Wüthrich, Marc-Philippe Neumann, Mohammad M. Moradi, Christopher H. Onder</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute for Dynamic Systems and Control, ETH Zürich</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21570</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a comprehensive race scenario model for Formula 1 that jointly accounts for energy allocation, tire wear, and pit stop timing using lap time maps and a dynamic tire wear model. 2. Develops and solves the strategy optimization problem using a Mixed-Integer Nonlinear Program (MINLP) to handle the integer decisions of pit stops. 3. Implements a complementary Reinforcement Learning (RL) framework trained on the same scenario, providing a fast-inference solution suitable for real-time human decision support during races.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes two complementary frameworks to optimize Formula 1 race strategies by jointly managing energy, tire wear, and pit stops. It uses a Mixed-Integer Nonlinear Program for optimal offline planning and a Reinforcement Learning agent for fast, real-time inference. The RL agent achieves suboptimality of only about 5 seconds in a 1.5-hour race, demonstrating its potential for real-time strategic assistance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xin Liu, Haoran Li, Dongbin Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21586</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Renmin University of China, The Chinese University of Hong Kong, Ant Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21625" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21625</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maximilian Weichart</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Regensburg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21648" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21648</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Max-We/inverse-rpo" target="_blank" rel="noopener noreferrer" class="">https://github.com/Max-We/inverse-rpo</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [communication &amp; networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin</p>
</li>
<li class="">
<p><strong>institution:</strong> Kyung Hee University, Ghent University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21717</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> National Taiwan Normal University, Wells Fargo Bank</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21819" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21819</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&amp;P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&amp;P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark&#x27;s 7.09%, demonstrating its effectiveness in dynamic financial environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville</p>
</li>
<li class="">
<p><strong>institution:</strong> Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21852" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21852</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]</p>
</li>
<li class="">
<p><strong>authors:</strong> KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21919" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21919</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [forward-backward MDP, multi-objective reinforcement learning, orthogonal multipoint multicast, wireless caching, latency optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohsen Amidzadeh</p>
</li>
<li class="">
<p><strong>institution:</strong> Aalto University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21954</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel forward-backward Markov decision process (FB-MDP) model that captures both the forward dynamics of user preferences and the backward dynamics of latency in a cache-aided multicast network. 2. Proposes a forward-backward multi-objective reinforcement learning (FB-MORL) algorithm to optimize for expected latency, outage probability, and resource consumption simultaneously. 3. Demonstrates through simulation that the proposed FB-MORL algorithm can find a promising dynamic cache policy for latency-optimal streaming.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of optimizing streaming latency in a cellular network with cache-enabled base stations using multicast. The authors propose a novel forward-backward reinforcement learning framework that models the network&#x27;s temporal dynamics as a multi-objective Markov decision process. Simulation results show their method is effective in finding a dynamic cache policy that reduces latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [communication &amp; networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]</p>
</li>
<li class="">
<p><strong>authors:</strong> Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers</p>
</li>
<li class="">
<p><strong>institution:</strong> Delft University of Technology, Telefónica Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22022" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22022</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 19</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&amp;C), encryption weaknesses, radio-frequency (RF) links]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mark Ballard, Guanqun Song, Ting Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> The Ohio State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21367</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&amp;C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington, University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21446" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21446</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards &quot;diffusion supremacy&quot; over autoregressive models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21452</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi</p>
</li>
<li class="">
<p><strong>institution:</strong> Technical University of Darmstadt</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21524" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21524</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a &quot;digital twin&quot;. 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinru Wen, Weizhong Lin, Xuan Xiao</p>
</li>
<li class="">
<p><strong>institution:</strong> JCI (inferred from email domain <code>jci.edu.cn</code>)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21544" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21544</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University, University of California, Riverside</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21563" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21563</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework&#x27;s capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework&#x27;s applicability to various data distributions and algorithms beyond ISTA/FISTA.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maximilian Weichart</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Regensburg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21648" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21648</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Max-We/inverse-rpo" target="_blank" rel="noopener noreferrer" class="">https://github.com/Max-We/inverse-rpo</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis</p>
</li>
<li class="">
<p><strong>institution:</strong> Purdue University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21757" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21757</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&amp;R model]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21766" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21766</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&amp;Resource (A/R/A&amp;R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&amp;R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Evgeny Alves Limarenko, Anastasiia Studenikina</p>
</li>
<li class="">
<p><strong>institution:</strong> Moscow Institute of Physics and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21769</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [speculative decoding, draft tree, inference acceleration, autoregressive image generation, dynamic tree structure]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Southeast University, Institute of Automation Chinese Academy of Sciences, Singapore Management University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21857</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Haodong-Lei-Ray/ADT-Tree" target="_blank" rel="noopener noreferrer" class="">https://github.com/Haodong-Lei-Ray/ADT-Tree</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified the key obstacle of applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to spatially varying token prediction difficulty. 2. Proposed ADT-Tree, an adjacency-adaptive dynamic draft tree that dynamically adjusts tree depth and width based on adjacent token states and prior acceptance rates. 3. Demonstrated significant speedups (over 3x) on benchmarks and seamless integration with relaxed sampling methods for further acceleration.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow inference of visual autoregressive models by proposing ADT-Tree, a dynamic draft tree method that adapts its structure to image region complexity. It achieves over 3x speedup on standard benchmarks and can be combined with other sampling techniques for additional gains.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Soochow University, Meituan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21911</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong</p>
</li>
<li class="">
<p><strong>institution:</strong> Southern University of Science and Technology, Microsoft Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21925</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm&#x27;s consistent advantage over purely online or offline baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21970</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://shengliangd.github.io/StereoVLA-Webpage" target="_blank" rel="noopener noreferrer" class="">https://shengliangd.github.io/StereoVLA-Webpage</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar</p>
</li>
<li class="">
<p><strong>institution:</strong> National School of Artificial Intelligence (ENSIA)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22007</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22065" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22065</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://streamavatar.github.io" target="_blank" rel="noopener noreferrer" class="">https://streamavatar.github.io</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras</p>
</li>
<li class="">
<p><strong>institution:</strong> Uppsala University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22066</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Yume-1.5: A Text-Controlled Interactive World Generation Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [interactive world generation, long-video generation, attention distillation, context compression, text-controlled generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai AI Laboratory, Fudan University, Shanghai Innovation Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22096</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/stdstu12/YUME" target="_blank" rel="noopener noreferrer" class="">https://github.com/stdstu12/YUME</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A long-video generation framework integrating unified context compression with linear attention. 2. A real-time streaming acceleration strategy using bidirectional attention distillation and an enhanced text embedding scheme. 3. A text-controlled method for generating world events.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Yume-1.5, a framework to address challenges in generating interactive, explorable worlds using diffusion models, such as large model size and slow inference. The method introduces a novel architecture combining context compression, attention distillation, and text-based event control to enable real-time, keyboard-controlled world generation from text or images. The work concludes with a public codebase demonstrating the feasibility of text-controlled interactive world creation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Imperial College London, Fudan University, Xiamen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21652" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21652</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-30">2025-12-30<a href="#2025-12-30" class="hash-link" aria-label="Direct link to 2025-12-30" title="Direct link to 2025-12-30" translate="no">​</a></h2>
<p><strong>cs.DC total: 42</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251230] GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [GPU Virtualization, Benchmarking, Multi-tenancy, CUDA, Performance Isolation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jithin VG, Ditto PS</p>
</li>
<li class="">
<p><strong>institution:</strong> Bud Ecosystem Inc</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22125</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/BudEcosystem/GPU-Virt-Bench" target="_blank" rel="noopener noreferrer" class="">https://github.com/BudEcosystem/GPU-Virt-Bench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed GPU-Virt-Bench, a comprehensive benchmarking framework with 56 metrics across 10 categories for evaluating software-based GPU virtualization systems. 2. Enabled systematic comparison between software virtualization approaches (e.g., HAMi-core, BUD-FCSP) and ideal hardware-based MIG behavior. 3. Demonstrated the framework&#x27;s utility by revealing critical performance characteristics for production deployment decisions in multi-tenant environments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a1c9f2d4dfba1fc452a424ad0f1298f01afe6d95dfd39dd2ff3f0c1bac9430c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of standardized evaluation for software-based GPU virtualization systems, which are needed for efficient GPU sharing in AI/LLM workloads. The authors propose GPU-Virt-Bench, a comprehensive benchmarking framework that measures performance across multiple critical dimensions. The framework provides actionable insights for practitioners by comparing software solutions against hardware-based baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SoDA: An Efficient Interaction Paradigm for the Agentic Web</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Sovereign Digital Avatar, Intent-Permission Handshake, orthogonal decoupling, A2A protocols, dual-factor adaptive routing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, Shanghai Innovation Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22135</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of &quot;data as a persistent asset, model as a transient tool&quot;. 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SlimEdge: Lightweight Distributed DNN Deployment on Constrained Hardware</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [Structured Pruning, Multi-Objective Optimization, Edge Inference, MVCNN, View-Adaptive Compression]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mahadev Sunil Kumar, Arnab Raha, Debayan Das, Gopakumar G, Amitava Mukherjee</p>
</li>
<li class="">
<p><strong>institution:</strong> Accenture PLC, Intel Corporation, Indian Institute of Science, Amrita Vishwa Vidyapeetham, Birla Institute of Technology and Science</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22136" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22136</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a framework for lightweight DNN deployment that integrates structured pruning with multi-objective optimization to meet heterogeneous hardware constraints. 2. Demonstrates the framework on MVCNN by quantifying the contribution of individual views to accuracy for view-adaptive pruning budget allocation. 3. Shows experimentally that the compressed models meet user-specified accuracy and memory bounds while achieving 1.2x to 5.0x inference speedup across diverse hardware.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7687c3e58bfa2b22573745dffb608fb7c36a0c339dd9216829f78a284f51e662_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7687c3e58bfa2b22573745dffb608fb7c36a0c339dd9216829f78a284f51e662_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of deploying large DNNs on resource-constrained edge devices. It proposes SlimEdge, a method that combines structured pruning and multi-objective optimization to compress models like MVCNN while preserving task performance. The results show that this approach successfully meets specified accuracy and memory constraints while significantly reducing inference latency on various edge hardware platforms.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [edge-cloud collaboration, task decomposition, adaptive routing, parallel execution, token-efficient inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiangwen Dong, Jiayu Li, Wanyu Lin</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong Polytechnic University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22137" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22137</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes HybridFlow, a resource-adaptive inference framework for collaborative reasoning between edge and cloud LLMs. 2. Introduces a two-stage method involving dynamic task decomposition for parallel execution and a learned router for resource-aware subtask assignment. 3. Demonstrates effectiveness in reducing end-to-end inference time and token usage while maintaining accuracy on multiple reasoning benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a14e12f757065eef8f857ead7c55331977412b8a4d1ba64499c5c1457d797284_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a14e12f757065eef8f857ead7c55331977412b8a4d1ba64499c5c1457d797284_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenges of high latency and token cost for LLM inference on edge devices by proposing HybridFlow, a framework that dynamically decomposes queries into parallel subtasks and adaptively routes them between edge and cloud models. The method reduces inference time and token consumption while preserving competitive accuracy, as validated on several reasoning benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HLS4PC: A Parametrizable Framework For Accelerating Point-Based 3D Point Cloud Models on FPGA</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [FPGA, HLS, Point Cloud, Model Compression, Fixed-Point]</p>
</li>
<li class="">
<p><strong>authors:</strong> Amur Saqib Pal, Muhammad Mohsin Ghaffar, Faisal Shafait, Christian Weis, Norbert Wehn</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Sciences and Technology (Pakistan), RPTU Kaiserslautern-Landau (Germany)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22139" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22139</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/dll-ncai/HLS4PC" target="_blank" rel="noopener noreferrer" class="">https://github.com/dll-ncai/HLS4PC</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed HLS4PC, a parameterizable HLS framework for accelerating point-based 3D point cloud models on FPGA. 2. Introduced PointMLP-Lite, a 4x less complex model variant created via hardware-aware compression techniques (URS, quantization, pruning, fusion). 3. Demonstrated FPGA acceleration achieving 3.56x higher throughput than prior work and outperforming GPU/CPU implementations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21433bfda0767bbdfcee46f13fb3acd9373d13bb741d87a755643767c9ad74f9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of real-time 3D point cloud processing by proposing HLS4PC, a parameterizable FPGA acceleration framework. The method combines algorithmic optimizations and hardware-aware model compression to create an efficient fixed-point implementation, which significantly outperforms previous accelerators and GPU/CPU baselines in throughput.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] On Harnessing Idle Compute at the Edge for Foundation Model Training</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [edge computing, tensor parallelism, parameter server, device heterogeneity, fault-tolerance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Leyang Xue, Meghana Madhyastha, Myungjin Lee, Amos Storkey, Randal Burns, Mahesh K. Marina</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Edinburgh, Johns Hopkins University, Cisco Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22142" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22142</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel selective hybrid tensor parallelism method to finely partition training operations for edge devices. 2. A parameter server-centric training framework to cope with device memory limits and avoid communication bottlenecks. 3. A cost optimization model to guide device selection and workload distribution, effectively handling device heterogeneity and churn.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fefe0f72fa70ae7be2cad54f15e74f96fd08cc506630060214e298521278148_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of decentralized foundation model training on edge devices, which is hindered by memory limits, communication overhead, and device heterogeneity. It proposes Cleave, a new paradigm that uses selective hybrid tensor parallelism and a parameter server framework to partition training efficiently. The evaluation shows Cleave matches cloud-based training performance, scales to thousands of devices, and handles failures with much faster recovery than prior methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [hpc], [gpu kernels], [Minimal Executable Program (MEP), Automatic Error Repair, Performance Pattern Inheritance, iterative optimization, cross-platform]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ruifan Chu, Anbang Wang, Xiuxiu Bai, Shuai Liu, Xiaoshe Dong</p>
</li>
<li class="">
<p><strong>institution:</strong> School of Software Engineering, Xi’an Jiaotong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22147" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22147</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an end-to-end LLM framework that optimizes GPU kernels by constructing Minimal Executable Programs (MEPs) to avoid expensive full application builds and executions. 2. Introduces Automatic Error Repair and Performance Pattern Inheritance to automatically fix faults and reuse effective optimization strategies, reducing search cost. 3. Demonstrates cross-platform portability and effectiveness on NVIDIA GPUs and the Haiguang DCU platform, achieving significant speedups over direct LLM optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fd593bd3569f30bdbf11d361054f51142863fb91e592b76bc4eb2f600850c5e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high cost of full builds for GPU kernel optimization in large HPC applications by proposing an LLM framework that uses Minimal Executable Programs (MEPs) for iterative optimization. The method integrates automatic error repair and performance pattern inheritance to maintain correctness and reuse strategies. It achieves substantial speedups across different hardware platforms without requiring full-source dependencies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [serverless computing, GPU resource allocation, workload scheduling, multi-agent systems, collaborative reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Guilin Zhang, Wulan Guo, Ziqi Tan</p>
</li>
<li class="">
<p><strong>institution:</strong> George Washington University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22149" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22149</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An adaptive GPU resource allocation framework for multi-agent systems in serverless environments that dynamically adjusts resources based on workload characteristics, agent priorities, and minimum requirements. 2. An O(N) complexity algorithm for real-time adaptation, enabling millisecond-scale reallocation to handle dynamic workload fluctuations. 3. A comprehensive evaluation demonstrating the framework&#x27;s superiority over static and round-robin strategies, achieving 85% latency reduction while maintaining throughput and improving GPU utilization and cost-efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fe7e30427c00e4689f161fb9912d4d11cc091ed6dd1dae3c4ea2c5805084e3b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes an adaptive GPU resource allocation framework to address the challenge of efficiently deploying heterogeneous multi-agent AI systems on serverless platforms. The method dynamically allocates resources using a real-time algorithm to handle varying computational demands and workload fluctuations. The results show it significantly reduces latency compared to baseline schedulers while maintaining throughput, offering a cost-effective solution for serverless multi-agent deployment.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] TL: Automatic End-to-End Compiler of Tile-Based Languages for Spatial Dataflow Architectures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [spatial dataflow, tile-based compilation, MLIR, on-chip network, hardware representation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wei Li, Zhenyu Bai, Heru Wang, Pranav Dangi, Zhiqiang Zhang, Cheng Tan, Huiying Lan, Weng-Fai Wong, Tulika Mitra</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Singapore, Arizona State University, Google, Lumai Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22168" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22168</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An end-to-end compiler framework (TL) that compiles tile-based programs (e.g., Triton kernels) onto spatial dataflow architectures, focusing on distributing tile instances across cores. 2. A novel hardware representation that captures interconnect topology, memory hierarchy, and compute capabilities to enable architecture-specific optimizations and support diverse targets. 3. A practical implementation built on the MLIR ecosystem, providing a generic entry point for different front-ends and an end point for different back-ends, demonstrated with performance gains over vendor libraries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cce8d87d1dd357c986e9809985cc87b6430fd568820f39521500addb34e7eef7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents TL, an end-to-end compiler framework that tackles the limited programmability of spatial dataflow accelerators by automatically mapping tile-based workloads across distributed cores to optimize data reuse and reduce communications. TL introduces a hardware-aware representation and is built on MLIR to support diverse targets. Experiments show it can match or exceed the performance of hand-tuned vendor libraries on kernels like GEMM and FlashAttention.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] BitFlipScope: Scalable Fault Localization and Recovery for Bit-Flip Corruptions in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [fault-tolerance], [bit-flip faults, fault localization, transformer reliability, residual-path perturbation, loss-sensitivity profiling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Muhammad Zeeshan Karamat, Sadman Saif, Christiana Chamon Garcia</p>
</li>
<li class="">
<p><strong>institution:</strong> Virginia Tech</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22174" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22174</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces BitFlipScope, a scalable software framework for localizing bit-flip corruptions in transformer-based LLMs under two deployment scenarios (with and without a clean reference model). 2. Proposes differential analysis for fault localization when a reference model is available and residual-path perturbation/loss-sensitivity profiling for localization when no reference exists. 3. Enables lightweight performance recovery for corrupted models without requiring costly fine-tuning or full retraining.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e931785a8ed1d0dca51ed3c75265de72147ccd6e3d68df21de1c7cad78a1d912_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces BitFlipScope, a framework for localizing and recovering from bit-flip corruptions in LLMs. It uses differential analysis with a reference model or perturbation-based profiling without one to identify fault-affected regions, enabling targeted recovery without full retraining. The work aims to improve fault resilience for LLMs in hardware-prone and adversarial environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AiiDAlab: on the route to accelerate science</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [hpc], [scientific workflow management], [AiiDAlab, AiiDA, provenance tracking, FAIR principles, web-based interface]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aliaksandr V.Yakutovich, Jusong Yu, Daniel Hollas, Edan Bainglass, Corsin Battaglia, Miki Bonacci, Lucas Fernandez Vilanova, Stephan Henne, Anders Kaestner, Michel Kenzelmann, Graham Kimbell, Jakob Lass, Fabio Lopes, Daniel G. Mazzone, Andres Ortega-Guerrero, Xing Wang, Nicola Marzari, Carlo A. Pignedoli, Giovanni Pizzi</p>
</li>
<li class="">
<p><strong>institution:</strong> Empa, Paul Scherrer Institute, École Polytechnique Fédérale de Lausanne, University of Bristol</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22173" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22173</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Development of the AiiDAlab platform, a web-based interface that simplifies access to and execution of complex computational workflows on supercomputers, lowering the barrier to entry for non-experts. 2. Maturation and expansion of the platform from its origins in computational materials science to support diverse scientific disciplines including quantum chemistry, atmospheric modeling, and experimental data analysis. 3. Integration with electronic laboratory notebooks (ELNs) and emphasis on automatic provenance tracking via AiiDA to enforce reproducibility and adherence to FAIR principles for generating Open Research Data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffb3ec2c93f3c0a0b3a1f69f46586695b4825664dea8e67ccbdf005064367c46_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffb3ec2c93f3c0a0b3a1f69f46586695b4825664dea8e67ccbdf005064367c46_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents AiiDAlab, a web-based platform designed to simplify the execution of complex computational workflows on supercomputers. It abstracts away technical details, provides an intuitive interface, and automatically tracks simulation provenance to ensure reproducibility. The platform has evolved to accelerate scientific discovery across multiple disciplines by allowing researchers to focus on their science rather than computational challenges.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] iOS as Acceleration</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [distributed pipeline parallelism, mobile acceleration, iOS, memory constraints, thermal throttling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alexander K. Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent High School Researcher (No institutional affiliation inferred)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22180</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel proof-of-concept system using distributed pipeline parallelism to harness iOS devices as computational accelerators for local ML tasks. 2. Demonstrates the system&#x27;s effectiveness in accelerating modest model training (e.g., ResNet-34) and agentic LRM tool-usage, achieving a 44% decrease in training time in a specific setup. 3. Explores the unique potential of ubiquitous mobile devices with powerful processors and sensors (e.g., LiDAR, GPS) as cost-effective resources for embodied agentic AI and local compute, discussing practical use-cases and limitations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2533767e76bdf97e302af13359b973b06a9948269cc9017131b6e880553cb6b9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the barrier of expensive compute for local machine learning by proposing a system that uses distributed pipeline parallelism to leverage underutilized iOS phones as accelerators. The method partitions model weights to circumvent mobile memory limits, successfully accelerating tasks like training ResNet-34. The work concludes that commonplace mobile devices have significant potential to contribute to ML, especially for local, cost-sensitive, or sensor-driven applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] MatKV: Trading Compute for Flash Storage in LLM Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, key-value cache, flash storage, prefill optimization, power efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kun-Woo Shin, Jay H. Park, Moonwook Oh, Yohan Jo, Jaeyoung Do, Sang-Won Lee</p>
</li>
<li class="">
<p><strong>institution:</strong> Seoul National University, Samsung Electronics</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22195" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22195</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/kunwooshin/MatKV" target="_blank" rel="noopener noreferrer" class="">https://github.com/kunwooshin/MatKV</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MatKV, a scheme to precompute and materialize KV vectors of RAG documents in flash storage to avoid recomputation during inference. 2. Demonstrates that MatKV reduces inference time and power consumption by half for RAG workloads with minimal accuracy impact. 3. Shows MatKV enables additional optimizations like overlapping KV loading with decoding and enabling the use of low-end GPUs for decoding.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d47111ab2d615579a09c00ff5a99f391f035b974cc23e324cddfbabf4d23cec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high compute and energy cost of the prefill phase in RAG-based LLM inference. It proposes MatKV, which precomputes and stores key-value vectors of documents in flash storage for reuse, trading compute for storage. Experiments show this approach halves inference time and power consumption while maintaining accuracy and enabling further hardware optimizations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [hpc], [computational fluid dynamics], [GPU porting, unified memory, memory pool manager, OpenFOAM, scalability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Simone Bnà, Giuseppe Giaquinto, Ettore Fadiga, Tommaso Zanelli, Francesco Bottau</p>
</li>
<li class="">
<p><strong>institution:</strong> Cineca Supercomputing Centre, Università degli Studi di Napoli Federico II</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22215</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents SPUMA, a full GPU porting of OpenFOAM targeting both NVIDIA and AMD GPUs. 2. Implements a portable programming model with a memory pool manager leveraging unified memory for efficient GPU utilization. 3. Demonstrates significant performance and energy efficiency gains through extensive testing on pre-exascale clusters, showing up to 82% energy reduction compared to CPU simulations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ea486a67026343b5f3c7d85db1ef1ff1202af04d0bd147ef25d9dc29565e2b1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of GPU programmability for open-source CFD by introducing SPUMA, a portable GPU port of OpenFOAM that uses a memory pool manager with unified memory. The method was tested on LUMI and Leonardo clusters, showing strong scalability up to 65% efficiency and weak scalability up to 85%, while reducing energy consumption by up to 82% compared to CPU-based simulations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [megakernel, kernel fusion, SM-level graph, software pipelining, CUDA]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinhao Cheng, Zhihao Zhang, Yu Zhou, Jianan Ji, Jinchen Jiang, Zepeng Zhao, Ziruo Xiao, Zihao Ye, Yingyi Huang, Ruihang Lai, Hongyi Jin, Bohan Hou, Mengdi Wu, Yixin Dong, Anthony Yip, Zihao Ye, Songting Wang, Wenqin Yang, Xupeng Miao, Tianqi Chen, Zhihao Jia</p>
</li>
<li class="">
<p><strong>institution:</strong> Carnegie Mellon University, Tsinghua University, NVIDIA, University of Michigan, Purdue University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22219" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22219</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/mirage-project/mirage" target="_blank" rel="noopener noreferrer" class="">https://github.com/mirage-project/mirage</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces an SM-level graph representation for capturing fine-grained data dependencies across GPU streaming multiprocessors. 2. Develops a compiler and an in-kernel parallel runtime that automatically transforms multi-operator inference into a single, high-performance mega-kernel. 3. Enables previously infeasible GPU optimizations like cross-operator software pipelining and fine-grained kernel overlap, significantly reducing inference latency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f886cd06ce6c0f773c062fa38aae0fa982d862cc66ef54da9fbbfd6cf62dd86a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces Mirage Persistent Kernel (MPK), a compiler and runtime system that automatically fuses multiple GPU kernels for model inference into a single, optimized mega-kernel. It achieves this by using a novel SM-level graph representation and decentralized scheduling to enable fine-grained optimizations like software pipelining. Evaluation shows MPK reduces LLM inference latency by up to 1.7x, pushing performance close to hardware limits.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Scalable Cloud-Native Architectures for Intelligent PMU Data Processing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [cluster infrastructure], [cloud-native, distributed stream processing, containerized microservices, elastic resource orchestration, edge-cloud hybrid]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nachiappan Chockalingam, Akshay Deshpande, Lokesh Butra, Ram Sekhar Bodala, Nitin Saksena, Adithya Parthasarathy, Balakrishna Pothineni, Akash Kumar Agarwal</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE, NTT Data, Amtrak, Albertsons Companies</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22231" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22231</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A comprehensive theoretical framework for AI-enhanced cloud-based PMU analytics. 2. Mathematical formulations for distributed machine learning optimized for PMU time-series data. 3. Analysis of edge-cloud hybrid architectures with integrated security and privacy considerations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59263c4210b1af52fedb9e9660a5117d937ac4a63d70c41f31a04dc3c553429f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a scalable cloud-native architecture to address the latency and scalability challenges of processing high-frequency data from Phasor Measurement Units (PMUs) in smart grids. The method integrates AI with edge and cloud computing, using distributed stream processing and containerized microservices for real-time analytics. The analysis shows the architecture can achieve sub-second response times while scaling to large deployments, providing a robust foundation for next-generation grid analytics.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Valori: A Deterministic Memory Substrate for AI Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [deterministic memory, fixed-point arithmetic, vector embeddings, approximate nearest neighbor search, state machine]</p>
</li>
<li class="">
<p><strong>authors:</strong> Varshith Gudur</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (Valori Kernel Project)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22280</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/varshith-Git/Valori-Kernel" target="_blank" rel="noopener noreferrer" class="">https://github.com/varshith-Git/Valori-Kernel</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and characterizes the fundamental non-determinism in AI memory systems caused by hardware-dependent floating-point arithmetic, which leads to divergent memory states and retrieval results. 2. Proposes Valori, a deterministic AI memory substrate that replaces floating-point operations with fixed-point arithmetic (Q16.16) and models memory as a replayable state machine. 3. Demonstrates that Valori guarantees bit-identical memory states, snapshots, and search results across different hardware platforms (e.g., x86 vs. ARM), establishing deterministic memory as a necessary primitive for trustworthy AI.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb7ed17a8a06e6a2b8760f08fa9345391995aee74a3542cacf55dd051b383f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies non-determinism in AI memory systems due to hardware-dependent floating-point arithmetic, which compromises replayability and auditability. It proposes Valori, a memory substrate using fixed-point arithmetic and a state machine model to guarantee bit-identical behavior across platforms. The work concludes that deterministic memory is essential for building trustworthy AI systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Cost-Aware Text-to-SQL: An Empirical Study of Cloud Compute Costs for LLM-Generated Queries</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Text-to-SQL, Cloud Cost Optimization, Query Efficiency, Large Language Models, Google BigQuery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Saurabh Deochake, Debajyoti Mukhopadhyay</p>
</li>
<li class="">
<p><strong>institution:</strong> SentinelOne, WIDiCoReL Research Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22364" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22364</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a cloud-native cost evaluation methodology for Text-to-SQL systems, measuring bytes processed, slot utilization, and estimated query cost on production infrastructure. 2. Conducted an empirical evaluation of six LLMs on Google BigQuery, demonstrating that reasoning models achieve significantly lower cloud compute costs while maintaining high correctness. 3. Quantified cost variance across models, identified prevalent inefficiency patterns (e.g., missing partition filters), and provided deployment guidelines for cost-sensitive environments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06f17566f5fb65cb73b79b0dbb64bde11c2f87d177f02865af7fc2d8910e3ac4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper studies the cloud compute costs of SQL queries generated by Large Language Models (LLMs) for Text-to-SQL tasks. By evaluating six state-of-the-art LLMs on Google BigQuery, it finds that reasoning models are more cost-efficient, processing far fewer bytes, and that execution time is a poor proxy for cloud cost. The work provides a new cost-focused evaluation methodology and guidelines for deploying cost-aware Text-to-SQL systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Efficient Multi-Model Orchestration for Self-Hosted Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Kubernetes, Helm, DistilBERT, scale-to-zero, hybrid routing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bhanu Prakash Vangala, Tanu Malik</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Missouri</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22402" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22402</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A unified Helm-based deployment system for self-hosted LLMs on Kubernetes, 2. An adaptive scale-to-zero automation mechanism for efficient GPU resource utilization, 3. A hybrid routing module combining keyword heuristics and a lightweight DistilBERT classifier to balance cost, latency, and accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14e9270400ac5f7fbf1ac4048cb82d9527c762106e232f9cd97653eb0ab3bdb4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces &quot;Pick and Spin,&quot; a framework for efficient orchestration of self-hosted large language models. It addresses challenges in GPU utilization and workload routing by integrating Kubernetes-based deployment, adaptive scaling, and a hybrid routing strategy. The system demonstrates significant improvements in success rate, latency, and cost compared to static deployments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, dynamic adaptation, multi-armed bandit, throughput optimization, latency reduction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rui Li, Zhaoning Zhang, Libo Zhang, Huaimin Wang, Xiang Fu, Zhiquan Lai</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Defense Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22420" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22420</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies the critical trade-off in speculative decoding: beneficial in memory-bound (low-load) scenarios but detrimental in compute-bound (high-load) scenarios due to verification overhead. 2. Proposes Nightjar, a novel learning-based algorithm that dynamically adapts the speculative length (or disables SD) based on real-time request load and batch size. 3. Demonstrates significant performance gains, achieving up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c6466394cd16e760ca78e05f13eba9852a284e7e8231b58de2c71fbee1e7b39_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the inefficiency of fixed-length speculative decoding in LLM serving, which fails to adapt to dynamic request loads. It proposes Nightjar, a learning-based algorithm that dynamically selects the optimal speculative length. Experiments show Nightjar significantly improves throughput and reduces latency compared to standard speculative decoding.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Role-Based Fault Tolerance System for LLM RL Post-Training</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [fault-tolerance], [role-based fault tolerance, RL post-training, UCX communication, warm standby, Effective Training Time Ratio (ETTR)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhenqian Chen, Baoquan Zhong, Xiang Li, Qing Dai, Xinkui Zhao, Miao Ye, Ren Cheng, Lufei Zhang, Jianwei Yin</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, State Key Laboratory of Mathematical Engineering and Advanced Computing</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22492" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22492</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a role-based fault isolation and recovery system (RobustRL) for RL post-training, enabling recovery of only the failed component (trainer, rollout) instead of restarting the entire task. 2. Introduces a role-aware monitoring mechanism to accurately detect failures and avoid false positives/delays specific to different RL roles. 3. Implements dynamic, UCX-based point-to-point communication to reconnect recovered roles and synchronize weights immediately, replacing static collective communication.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ceff77cfb9d0c7d7e763916b77716ee6534c3aa3d54d41253fef6ea4d9a86ec0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the lack of fault tolerance for RL post-training of LLMs, which interleaves training and inference workloads. It proposes RobustRL, a system that isolates and recovers failed roles (e.g., trainer, rollout) individually using a Detect-Restart-Reconnect paradigm, instead of restarting the entire job. This approach significantly improves the Effective Training Time Ratio and reduces end-to-end training time compared to baseline methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Object Abstraction To Streamline Edge-Cloud-Native Application Development</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [serverless computing, edge computing], [Object-as-a-Service (OaaS), edge-cloud continuum, serverless, FaaS, declarative SLA]</p>
</li>
<li class="">
<p><strong>authors:</strong> Pawissanutt Lertpongrujikorn</p>
</li>
<li class="">
<p><strong>institution:</strong> University of North Texas</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22534" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22534</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed the Object-as-a-Service (OaaS) paradigm, unifying resource, state, and workflow management with the Oparaca prototype. 2. Extended OaaS to the edge-cloud continuum with OaaS-IoT/EdgeWeaver, improving performance and reducing code complexity. 3. Established an empirical methodology and commercialization pathway for cloud-native research grounded in practitioner needs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fcd35442b8b6cfbc12c61e295e970899c2bfb10184fe06c88745b8fbf0137055_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fcd35442b8b6cfbc12c61e295e970899c2bfb10184fe06c88745b8fbf0137055_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This dissertation addresses the complexity and fragmentation in serverless and cloud-native development by proposing the Object-as-a-Service (OaaS) paradigm. It introduces a unified abstraction for resources, state, and workflows, and extends it to the edge-cloud continuum, demonstrating improved developer productivity and system performance. The work concludes that OaaS effectively hides infrastructure complexity, allowing developers to focus on application logic.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [disaggregated infrastructure, hardware-affinity mapping, fine-grained asynchrony]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wei Gao, Yuheng Zhao, Tianyuan Wu, Shaopan Xiong, Weixun Wang, Dakai An, Lunxi Cao, Dilxat Muhtar, Zichen Liu, Haizhou Zhao, Ju Huang, Siran Yang, Yongbin Li, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng, Wei Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> HKUST, Alibaba Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22560" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22560</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="">https://github.com/alibaba/ROLL</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A hardware-affinity workload mapping strategy that routes compute-bound and bandwidth-bound tasks to best-fit GPU devices. 2. A fine-grained asynchrony mechanism that manages execution at the trajectory level to mitigate resource bubbles and improve utilization. 3. A statefulness-aware computation design that offloads stateless components to serverless infrastructure for elastic scaling.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc8e408c613097b7b60bc32e41ec3137faa8dd94184658c8a802b65cbf57c593_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents RollArt, a distributed system designed to scale agentic reinforcement learning training on disaggregated infrastructure. It addresses the heterogeneity of agentic RL workloads by proposing three core techniques: hardware-affinity workload mapping, fine-grained asynchrony, and statefulness-aware computation. The system demonstrates significant improvements in training throughput, achieving 1.35-2.05x speedup over baselines, and scales to thousands of GPUs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [energy efficiency, dynamic voltage and frequency scaling (DVFS), GPU underutilization, visual token sequences, stage-level analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mona Moghadampanah, Adib Rezaei Shahmirzadi, Farhana Amin, Dimitrios S. Nikolopoulos</p>
</li>
<li class="">
<p><strong>institution:</strong> Virginia Tech</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22695" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22695</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides the first detailed, stage-level energy characterization of MLLM inference, identifying modality inflation as a key inefficiency. 2. Quantifies the significant energy overhead (17%-94%) of multimodal inference and reveals diverse bottlenecks (vision encoder vs. prefill) and GPU underutilization. 3. Demonstrates stage-wise DVFS as an effective optimization to reduce energy consumption with minimal performance impact.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f6dd42f6aa45e4d0992cdd9fa407ab5c4268e31f45ecafdc9b44861ceb445e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f6dd42f6aa45e4d0992cdd9fa407ab5c4268e31f45ecafdc9b44861ceb445e1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the energy inefficiency of multimodal large language model (MLLM) inference, termed &quot;modality inflation,&quot; where extra encoding stages and longer token sequences increase energy consumption. It provides a stage-level energy analysis on GPUs, quantifying overheads and identifying bottlenecks, and proposes stage-wise dynamic voltage and frequency scaling (DVFS) as an effective optimization to save energy with modest performance loss.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] OptiNIC: A Resilient and Tail-Optimal RDMA NIC for Distributed ML Workloads</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [communication &amp; networking], [RDMA, tail latency, collective communication, reliability, domain-specific transport]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ertza Warraich, Ali Imran, Annus Zulfiqar, Shay Vargaftik, Sonia Fahmy, Muhammad Shahbaz</p>
</li>
<li class="">
<p><strong>institution:</strong> Purdue University, Broadcom, University of Michigan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22743" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22743</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes OptiNIC, a domain-specific RDMA transport that eliminates retransmissions and in-order delivery from the NIC, shifting to a best-effort, out-of-order model. 2. Introduces adaptive timeouts to trigger forward progress in case of data loss or delay, decoupling completion signaling from complete data delivery. 3. Shifts loss recovery to the ML pipeline (e.g., via Hadamard Transform and Erasure Coding) while retaining standard congestion control, improving performance and resilience for distributed ML workloads.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3143921b3b275baf220b75c6f927e8a49b4fa31653bbd117324490a1b8f8da93_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3143921b3b275baf220b75c6f927e8a49b4fa31653bbd117324490a1b8f8da93_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies tail latency in collective communication as a major bottleneck for distributed ML. It proposes OptiNIC, a new RDMA transport that relaxes strict reliability guarantees based on ML&#x27;s tolerance for data loss, using adaptive timeouts and moving recovery to the application layer. Evaluation shows OptiNIC significantly improves time-to-accuracy, throughput, and tail latency while reducing hardware resource usage.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Two-Robot Computational Landscape: A Complete Characterization of Model Power in Minimal Mobile Robot Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [distributed computing], [autonomous mobile robots, Look-Compute-Move (LCM), computational power hierarchy, finite-state robots, robots with lights]</p>
</li>
<li class="">
<p><strong>authors:</strong> Naoki Kitamura, Yuichi Sudo, Koichi Wada</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Osaka, Hosei University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22770" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22770</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proves that under full synchrony, the FSTA (finite-state) and LUMI (robots with lights) models coincide for two robots, showing perfect synchrony can substitute for memory and communication at this minimal scale. 2. Shows that the FSTA and FCOM (finite-communication) models are orthogonal (bidirectionally incomparable), completing the landscape of incomparability. 3. Provides the first complete and exact characterization of the computational power hierarchy for two robots across all major models and schedulers using a novel simulation-free method.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddce34ada1bbaebc271a0c17bbc6cf8413606d2887ebd22bfe77cc4c0e90d34a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddce34ada1bbaebc271a0c17bbc6cf8413606d2887ebd22bfe77cc4c0e90d34a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper provides the first complete characterization of the computational power of two autonomous mobile robots across major models (OBLOT, FSTA, FCOM, LUMI) and schedulers. Using a novel simulation-free method, it reveals a landscape distinct from the general n-robot case, showing that perfect synchrony can substitute for memory and communication for two robots, and that FSTA and FCOM are orthogonal. This yields the first exact computational hierarchy for minimal robot systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Argus: Token Aware Distributed LLM Inference Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [token-aware offloading, Lyapunov optimization, length prediction, edge-cloud systems, distributed inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Panlong Wu, Yifei Zhong, Danyang Chen, Ting Wang, Fangxin Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen (CUHK-SZ)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22925</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A Length-Aware Semantics (LAS) module that predicts output token lengths for prompts using a fine-tuned language model with token-length-sensitive feature modulation. 2. A Lyapunov-guided Offloading Optimization (LOO) module that formulates long-term Quality-of-Experience optimization considering both LLM prefilling and decoding costs. 3. A novel Iterative Offloading Algorithm with Damping and Congestion Control (IODCC) to solve the resulting integer nonlinear programming problem under time-varying constraints.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e6bf58921ba8401e4cc5e40322f2ce1b65861ebe0ac5f35cfead3e0339c7f09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e6bf58921ba8401e4cc5e40322f2ce1b65861ebe0ac5f35cfead3e0339c7f09_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Argus, a token-aware distributed LLM inference framework for edge-cloud systems. It addresses inference time variability by predicting output token lengths and using Lyapunov optimization for efficient task offloading. Evaluations show Argus achieves robust and efficient performance in dynamic, heterogeneous environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [hpc], [uncertainty quantification], [stochastic Galerkin method, polynomial chaos expansion, domain decomposition, Neumann-Neumann preconditioner]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sudhi Sharma Padillath Vasudevan</p>
</li>
<li class="">
<p><strong>institution:</strong> Carleton University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23027</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Applies an intrusive stochastic Galerkin method with Polynomial Chaos Expansion to solve acoustic wave propagation in random media, transforming the stochastic PDE into a deterministic system. 2. Employs Domain Decomposition-based solvers to address the high computational cost associated with large-scale, high-dimensional stochastic systems. 3. Utilizes a conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner, demonstrating efficient scalability for the problem.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a4a9c029830a2f5bbff0493a205dfd33bea894daf2a861a9f131c15f02f4b9d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles the high computational cost of simulating acoustic wave propagation in two-dimensional random media. It proposes a method combining an intrusive stochastic Galerkin approach with Polynomial Chaos Expansion and a Domain Decomposition-based linear solver preconditioned with a two-level Neumann-Neumann method. The results show that this approach provides an efficiently scalable solution for the problem.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Viability and Performance of a Private LLM Server for SMBs: A Benchmark Analysis of Qwen3-30B on Consumer-Grade Hardware</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [quantization, mixture-of-experts, on-premise deployment, consumer-grade hardware, benchmark analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alex Khalil, Guillaume Heilles, Maria Parraga, Simon Heilles</p>
</li>
<li class="">
<p><strong>institution:</strong> UCLouvain, Universidad Espíritu Santo, DENEM Labs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23029" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23029</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A comprehensive benchmarking framework for evaluating both the intrinsic model capabilities and the server-side performance (latency, throughput, scalability) of a private LLM deployment. 2. A practical demonstration and performance analysis of deploying a quantized, large-scale (30B parameter) Mixture-of-Experts model (Qwen3) on next-generation consumer-grade hardware (NVIDIA RTX 5090). 3. Evidence that a carefully configured on-premises LLM server can achieve performance comparable to cloud services, offering SMBs a viable, cost-effective, and privacy-preserving alternative.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed34c10397ed5cae19c39a4a8e2a5a1f0fd64e2f76183b8ba093c74b9a79fe51_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the feasibility of deploying a private, high-performance LLM server for Small and Medium Businesses using consumer-grade hardware. It benchmarks a quantized Qwen3-30B model on an NVIDIA RTX 5090, evaluating both model capability and server performance under load. The results show that such an on-premises setup can achieve performance close to cloud services at a lower cost and with full data privacy.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Osmotic Learning: A Self-Supervised Paradigm for Decentralized Contextual Data Representation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [self-supervised learning, representation learning, distributed learning, decentralized clustering, contextual data]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mario Colosi, Reza Farahani, Maria Fazio, Radu Prodan, Massimo Villari</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Messina, University of Klagenfurt, University of Innsbruck</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23096</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Osmotic Learning (OSM-L), a novel self-supervised paradigm for learning from distributed data without raw data exchange. 2. Proposes an &quot;osmosis&quot; process that aligns local representations to converge to a dynamic equilibrium, capturing contextual patterns. 3. Demonstrates that OSM-L functions as a decentralized clustering mechanism, identifying correlated data groups during training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2b452fb94443ab9846af33524787f0bc6c709b6e90ae3be4e653738c6fe592b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Osmotic Learning (OSM-L), a self-supervised distributed learning paradigm that extracts higher-level latent knowledge from decentralized data sources without sharing raw data. It achieves this through an iterative &quot;osmosis&quot; process that aligns local representations to converge to a contextual equilibrium, also enabling decentralized clustering. Experimental results show OSM-L achieves high accuracy in local information alignment while preserving contextual integrity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] FairGFL: Privacy-Preserving Fairness-Aware Federated Learning with Overlapping Subgraphs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [graph federated learning, fairness, overlapping subgraphs, privacy-preserving, weighted aggregation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zihao Zhou, Shusen Yang, Fangyuan Zhao, Xuebin Ren</p>
</li>
<li class="">
<p><strong>institution:</strong> Xi&#x27;an Jiaotong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23235" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23235</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Uncover and theoretically analyze the unfairness issue in graph federated learning caused by imbalanced overlapping subgraphs across clients. 2. Propose FairGFL, a novel algorithm that uses a privacy-preserving estimation of overlapping ratios and an interpretable weighted aggregation approach to enhance cross-client fairness. 3. Improve the tradeoff between model utility and fairness by integrating a carefully crafted regularizer into the federated composite loss function.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c67614889dfdf1e0e6de4fd0bd950e8649eb4d988fb1661c29ef6c14b73bba25_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a fairness problem in graph federated learning when client subgraphs overlap in an imbalanced way. To solve this, it proposes FairGFL, a method that uses privacy-preserving overlap estimation and a fairness-aware regularizer to balance utility and fairness. Experiments show FairGFL outperforms baselines in both utility and fairness on benchmark datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Lyapunov Optimization, Deep Reinforcement Learning, Edge-Cloud Partitioning, Transformer Decomposition, Queue Stability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Innsbruck, Sharif University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23310" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23310</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a fine-grained, adaptive partitioning framework (Splitwise) that decomposes transformer layers into attention heads and feed-forward sub-blocks, enabling exponentially more partition choices than layer-wise schemes. 2. Introduces a hierarchical DRL policy guided by Lyapunov optimization to jointly optimize latency, energy, and accuracy while guaranteeing queue stability under stochastic workloads and variable bandwidth. 3. Ensures robustness through partition checkpoints with exponential backoff recovery for communication failures, validated on real edge devices with large models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/121b71aa214f4a7c1671c9df76bf67a9cd64f3cb9e74186606a380ce86f7634f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes Splitwise, a Lyapunov-assisted DRL framework for dynamically partitioning LLM inference between edge and cloud at a fine-grained sub-layer level. It aims to minimize latency and energy while maintaining accuracy under fluctuating network conditions. Experiments show Splitwise significantly reduces latency and energy consumption compared to existing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [cluster infrastructure], [Kubernetes, Autoscaling, AIOps, Service Level Objectives, Cost Optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE, East West Bank, NTT Data, Albertsons</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23415" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23415</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Local Rendezvous Hashing: Bounded Loads and Minimal Churn via Cache-Local Candidates</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [distributed systems], [consistent hashing, rendezvous hashing, load balancing, cache locality, minimal churn]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yongjie Guan</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23434" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23434</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Local Rendezvous Hashing (LRH), which restricts HRW selection to a cache-local window of C distinct neighboring physical nodes on a ring. 2. Proposes next-distinct offsets to enforce bounded distinct candidate enumeration in exactly C ring steps. 3. Demonstrates that under fixed-candidate liveness failover, LRH achieves 0% excess churn while maintaining high throughput and good load balance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40c222a782553ce278b2cbc43564ea8beed18effebd850b7b92ac28f04bda05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40c222a782553ce278b2cbc43564ea8beed18effebd850b7b92ac28f04bda05_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the trade-off between load balance and performance in consistent hashing for distributed systems. It proposes Local Rendezvous Hashing (LRH), a method that performs a Highest Random Weight selection within a small, cache-local window of nodes on a ring. LRH achieves near-optimal load balance with minimal key churn and significantly higher lookup throughput compared to multi-probe consistent hashing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [blockchain scalability], [Bitcoin, Layer-2, Proof-of-Stake, interoperability, SegWit]</p>
</li>
<li class="">
<p><strong>authors:</strong> Marko Vukolić, Orestis Alpos, Jakov Mitrovski, Themis Papameletiou, Nikola Ristić, Dionysis Zindros</p>
</li>
<li class="">
<p><strong>institution:</strong> Bitcoin Scaling Labs, Common Prefix</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23439</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Bitcoin-IPC, a protocol enabling permissionless creation of Proof-of-Stake Layer-2 subnets with stake denominated in Bitcoin (BTC). 2. Proposes a novel design embedded within Bitcoin&#x27;s SegWit mechanism, inspired by SWIFT messaging, for seamless cross-subnet value transfer routed through Bitcoin L1. 3. Achieves significant scalability improvements, reducing transaction cost by up to 23x and increasing throughput from 7 to over 160 tps without modifying Bitcoin L1.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses Bitcoin&#x27;s limited transaction throughput for use as a Medium of Exchange. It proposes Bitcoin-IPC, a protocol that creates a network of programmable Proof-of-Stake Layer-2 chains (subnets) that use Bitcoin for security and settlement. The design significantly increases transaction throughput and reduces cost without requiring changes to the Bitcoin base layer.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Decoupling Adaptive Control in TeaStore</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [self-adaptive systems], [self-adaptation, microservices, control loop, operator pattern, software architecture]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eddy Truyen</p>
</li>
<li class="">
<p><strong>institution:</strong> DistriNet, KU Leuven</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23495</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fancy Some Chips for Your TeaStore? Modeling the Control of an Adaptable Discrete System</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [modeling languages, control theory, distributed systems], [Chips, control theory, component-based modeling, Adaptable TeaStore, BIP]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anna Gallone, Simon Bliudze, Sophie Cerf, Olga Kouchnarenko</p>
</li>
<li class="">
<p><strong>institution:</strong> Université Marie et Louis Pasteur (FEMTO-ST), Univ. Lille (Inria, CNRS, CRIStAL)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23496" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23496</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/NwaitDev/Chips_Public" target="_blank" rel="noopener noreferrer" class="">https://github.com/NwaitDev/Chips_Public</a>, <a href="https://github.com/NwaitDev/TeaStore-Variation" target="_blank" rel="noopener noreferrer" class="">https://github.com/NwaitDev/TeaStore-Variation</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Chips, a novel language for designing models of complex, intertwined systems by mixing control theory with general-purpose programming concepts. 2. Enables systematic design, modeling, and analysis of adaptable systems through functional block descriptions. 3. Demonstrates the language&#x27;s application and utility using a variation of the Adaptable TeaStore as a concrete running example.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80812c1a02bcd560c40919556c5ed13e3adfb056050e40a68f66bb940765d6f7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Chips, a modeling language that combines control theory with programming concepts to facilitate the design and analysis of robust, component-based systems. The method is demonstrated on an Adaptable TeaStore application, showing how Chips can be used to systematically model complex, interacting entities like software, hardware, and services. The main conclusion is that Chips aids in ensuring system robustness and quality of service for web applications and cyber-physical systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Optimal Configuration of API Resources in Cloud Native Computing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [cloud computing], [Kubernetes, resource optimization, microservices, DevOps, Bayesian optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eddy Truyen, Wouter Joosen</p>
</li>
<li class="">
<p><strong>institution:</strong> DistriNet, KU Leuven</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23494" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23494</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Applies an existing black-box optimization framework to the largely unexplored problem of fine-tuning CPU and memory allocation during the DevOps Release phase, before deployment. 2. Empirically evaluates the framework using the TeaStore microservice application and provides a statistical comparison of different optimization algorithms, analyzing their trade-offs. 3. Provides practical guidance on when to use factor screening (for optimal configuration or algorithm comparison with a budget) versus pure Bayesian optimization (for finding a near-optimal configuration).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd4cec4e268968c920e0f358d7cea15fb1e4dc177e4b11b53180a3f5172ef65_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fd4cec4e268968c920e0f358d7cea15fb1e4dc177e4b11b53180a3f5172ef65_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper applies a black-box optimization framework to tune Kubernetes CPU and memory resource configurations for microservices during the DevOps Release phase, a problem often overlooked in favor of runtime autoscaling. The evaluation on the TeaStore application shows that factor screening is useful for finding the optimal configuration within a budget, but Bayesian optimization without screening is better for finding a near-optimal solution.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [autonomic computing], [MAPE-K loop, decentralized adaptation, event-driven, rule-based, microservices]</p>
</li>
<li class="">
<p><strong>authors:</strong> Brice Arléon Zemtsop Ndadji, Simon Bliudze, Clément Quinton</p>
</li>
<li class="">
<p><strong>institution:</strong> Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23499" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23499</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [digital signal processing, computer arithmetic, high-performance computing], [energy-efficient computing, integer-friendly approximation, conflict-free memory access, fast Fourier transform, fast Schur algorithm]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sergey Salishev</p>
</li>
<li class="">
<p><strong>institution:</strong> Saint Petersburg State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22676" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22676</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A power/energy consumption model for clocked CMOS logic to select optimal parallelism. 2. Integer-friendly approximation methods for elementary functions using constrained piecewise-polynomials to reduce lookup-table size. 3. Provably conflict-free data placement and execution order schemes for mixed-radix streaming FFT on multi-bank/single-port memories.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fe50589b6f9e67a8e1acb929b6cfc7dcaecddcc5c1837d218c89e297ca79994_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This thesis develops signal-processing algorithms and implementation schemes under constraints of minimal parallelism and memory space to improve energy efficiency. It proposes a power model, approximation methods, and conflict-free memory access schemes for FFT and fast Schur algorithms. The results provide constructive theorems and design trade-offs for building efficient specialized accelerators.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [quantum computing], [hidden subgroup problem, exact quantum algorithm, distributed quantum algorithm, amplitude amplification, Chinese Remainder Theorem]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ziyuan Dong, Xiang Fan, Tengxun Zhong, Daowen Qiu</p>
</li>
<li class="">
<p><strong>institution:</strong> Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22959" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22959</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new, more concise exact quantum algorithm for the finite Abelian hidden subgroup problem using amplitude amplification. 2. Introduces a distributed exact quantum algorithm for the same problem that reduces resource requirements and avoids quantum communication by leveraging the Chinese Remainder Theorem. 3. Develops a parallel exact classical algorithm with reduced query complexity, where the total queries across nodes do not exceed the centralized version under mild conditions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7feb61cf81eb163415a6709dd5e0b72019ffd85d693a4f2bc910ebd710ff58b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7feb61cf81eb163415a6709dd5e0b72019ffd85d693a4f2bc910ebd710ff58b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper revisits the finite Abelian hidden subgroup problem (AHSP). It proposes a new exact quantum algorithm, a distributed quantum algorithm that requires fewer resources and no quantum communication, and a parallel classical algorithm. The main conclusion is that these methods offer more concise, resource-efficient, and scalable solutions for solving the AHSP.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]</p>
</li>
<li class="">
<p><strong>authors:</strong> Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell</p>
</li>
<li class="">
<p><strong>institution:</strong> Åbo Akademi University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23071" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23071</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;reinforcement learning&quot; total: 50</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251230] Unbiased Visual Reasoning with Controlled Visual Inputs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal reasoning], [vision-language models, spurious correlations, information bottleneck, reinforcement learning, modular reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22183" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22183</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Learning Tennis Strategy Through Curriculum-Based Dueling Double Deep Q-Networks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Dueling Double Deep Q-Network, curriculum learning, tennis simulation, sequential decision-making, sports analytics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vishnu Mohan</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22186" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22186</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a custom tennis simulation environment that models hierarchical scoring, tactical decisions, fatigue, and opponent skill. 2. Integrated a Dueling Double Deep Q-Network (DDQN) with curriculum learning to enable stable and effective strategy learning in a long-horizon, stochastic domain. 3. Identified a key limitation of win-rate optimization, revealing a learned defensive bias and highlighting challenges in reward design for sports RL.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/543e2f9f07244abac63adfdbdefd7fccfefed9147b55aed87016c10657f91bae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a reinforcement learning framework using a Dueling Double Deep Q-Network trained with curriculum learning to optimize tennis strategy in a custom simulation. The method achieves high win rates and demonstrates stable convergence, but analysis reveals the learned policy is overly defensive, pointing to a fundamental issue with reward design in sports simulations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Physics-Informed Machine Learning for Transformer Condition Monitoring -- Part I: Basic Concepts, Neural Networks, and Variants</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [prognostics &amp; health management (phm)], [Neural Networks, Convolutional Neural Networks, Reinforcement Learning, Uncertainty Quantification, Physics-Informed Machine Learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jose I. Aizpurua</p>
</li>
<li class="">
<p><strong>institution:</strong> University of the Basque Country (UPV/EHU)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22190</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the application of Neural Networks (NNs) and their variants, specifically Convolutional Neural Networks (CNNs), for transformer condition monitoring using diverse data modalities. 2. Discusses the integration of NN concepts within the Reinforcement Learning (RL) paradigm for decision-making and control in transformer health management. 3. Provides perspectives on emerging research directions at the intersection of physics-informed machine learning and transformer Prognostics &amp; Health Management (PHM).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73f2611de029a059f651f47ffd6b707f684cdbc0c0f865e4c8568c2765f5fede_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of traditional, rule-based transformer condition monitoring by proposing the use of machine learning, particularly Neural Networks and their variants. It explores Convolutional Neural Networks for processing diverse sensor data and discusses Reinforcement Learning for control, concluding that physics-informed ML provides a powerful framework for more accurate diagnostics, prognostics, and decision-making in power transformer health management.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Emotion-Inspired Learning Signals (EILS): A Homeostatic Framework for Adaptive Autonomous Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [intrinsic motivation, homeostatic control, adaptive optimization, non-stationary learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dhruv Tiwari</p>
</li>
<li class="">
<p><strong>institution:</strong> Lovely Professional University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22200" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22200</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel framework, Emotion-Inspired Learning Signals (EILS), that models emotions as continuous, homeostatic appraisal signals (e.g., Curiosity, Stress, Confidence) for adaptive control. 2. Formalizes these signals as vector-valued internal states derived from interaction history to dynamically modulate the agent&#x27;s optimization landscape in real-time. 3. Hypothesizes that this closed-loop homeostatic regulation enables superior sample efficiency and adaptation to non-stationary environments compared to standard baselines like PPO.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a45d2a56af1becf3eaddb05dbaeff3cf5453d19d41771b6d8ce1c1a70d3825c2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies the fragility of standard AI agents that rely on static, external rewards in open-ended environments. It proposes the Emotion-Inspired Learning Signals (EILS) framework, which uses bio-inspired internal signals like curiosity and stress to dynamically control learning. The authors hypothesize this approach will lead to more robust, adaptive, and sample-efficient autonomous agents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, Shanghai Innovation Institute, OpenMoss Team</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22234" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22234</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/OpenMOSS/DiRL" target="_blank" rel="noopener noreferrer" class="">https://github.com/OpenMOSS/DiRL</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [knowledge distillation, reinforcement learning, vision-language models, progressive masking, offline RL]</p>
</li>
<li class="">
<p><strong>authors:</strong> Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma</p>
</li>
<li class="">
<p><strong>institution:</strong> NVIDIA</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22238" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22238</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Masters, a mask-progressive RL distillation framework that first masks non-dominant teacher weights to reduce complexity and then progressively restores them for stable student learning. 2. Introduces an offline RL stage with complementary accuracy and distillation rewards, leveraging pre-generated responses from masked teachers for efficient guidance. 3. Demonstrates that progressive teacher scaling (e.g., from 14B to 38B) yields smoother convergence and stronger generalization than one-shot distillation, providing a scalable path to efficient VLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72df4c6bab2069771a9955e5dac4af81d2f423474fdaf07bf9980aaea39edeaf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of distilling large vision-language models (VLMs) into compact ones by proposing Masters, a framework that uses progressive masking of the teacher model and offline reinforcement learning. This method enables stable knowledge transfer and efficient training, resulting in small VLMs that achieve strong performance, sometimes surpassing larger models, while being far more efficient for deployment.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhonghao Jiang, David Lo, Zhongxin Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Singapore Management University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22256" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22256</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/ZhonghaoJiang/Awesome-Issue-Solving" target="_blank" rel="noopener noreferrer" class="">https://github.com/ZhonghaoJiang/Awesome-Issue-Solving</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [video understanding], [agentic framework, temporal zoom, reinforcement learning, long video reasoning, multimodal large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yang Ding, Yizhen Zhang, Xin Lai, Ruihang Chu, Yujiu Yang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, The Chinese University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22315" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22315</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/zsgvivo/VideoZoomer" target="_blank" rel="noopener noreferrer" class="">https://github.com/zsgvivo/VideoZoomer</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes VideoZoomer, a novel agentic framework that enables MLLMs to dynamically control visual focus during reasoning for long videos. 2. Introduces a two-stage training strategy combining supervised fine-tuning on distilled trajectories with reinforcement learning to refine the agentic policy. 3. Demonstrates strong performance across long video benchmarks, surpassing open-source models and rivaling proprietary systems with superior efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab9b4b645f4fff1b4f548256b858cb41da2b35db78b1083f110e983d60c3547e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitation of Multimodal LLMs in understanding long videos due to context window constraints. It proposes VideoZoomer, an agentic framework that dynamically selects and zooms into key temporal moments for fine-grained evidence gathering, trained with a two-stage strategy. The resulting 7B model achieves state-of-the-art performance on long video reasoning benchmarks with high efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Tencent</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22322" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22322</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://huggingface.co/collections/yolay/smartsnap" target="_blank" rel="noopener noreferrer" class="">https://huggingface.co/collections/yolay/smartsnap</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Cyber-Physical Systems Security], [False Data Injection (FDI), Physics-Informed Neural Network (PINN), Multi-Agent Reinforcement Learning (MARL)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohammad Zakaria Haider, Amit Kumar Podder, Prabin Mali, Aranya Chakrabortty, Sumit Paudyal, Mohammad Ashiqur Rahman</p>
</li>
<li class="">
<p><strong>institution:</strong> Florida International University, North Carolina State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22381" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22381</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes PHANTOM, a physics-aware adversarial attack framework that integrates a federated learning-enabled PINN as a digital twin for accurate modeling of EV charging systems. 2. Develops a multi-agent RL environment using DQN and SAC to generate stealthy FDI attack strategies that bypass conventional detection. 3. Constructs a T&amp;D co-simulation platform to demonstrate the cascading, cross-boundary grid impacts (e.g., load imbalance, voltage instability) of the learned attacks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc4a49b77c0e517eadb20d321d77564888677d1f33b27adf452e13f7c0ffcb8c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes PHANTOM, a physics-aware adversarial attack framework against federated learning-coordinated EV charging management. It uses a PINN-based digital twin and multi-agent RL to generate stealthy false data injection attacks, which are shown through co-simulation to cause significant grid instability, highlighting the need for physics-aware cybersecurity in vehicle-grid integration.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [LoRA, Parameter-Efficient Fine-Tuning, Activation Function Annealing, Non-linear Adaptation, Model Merging]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai</p>
</li>
<li class="">
<p><strong>institution:</strong> Meituan, Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22455" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22455</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method&#x27;s effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] FinPercep-RM: A Fine-grained Reward Model and Co-evolutionary Curriculum for RL-based Real-world Super-Resolution</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [image super-resolution], [reinforcement learning from human feedback (RLHF), reward hacking, perceptual quality, curriculum learning, fine-grained assessment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yidi Liu, Zihao Fan, Jie Huang, Jie Xiao, Dong Li, Wenlong Zhang, Lei Bai, Xueyang Fu, Zheng-Jun Zha</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science and Technology of China, Shanghai AI Laboratory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22647" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22647</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a Fine-grained Perceptual Reward Model (FinPercep-RM) with an encoder-decoder architecture that outputs both a global quality score and a Perceptual Degradation Map to localize defects. 2. Introduces the FGR-30k dataset containing diverse and subtle distortions from real-world super-resolution models for training the reward model. 3. Designs a Co-evolutionary Curriculum Learning (CCL) mechanism that synchronizes the progressive training of the reward model and the ISR model to ensure stable training and suppress reward hacking.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1738fd28b1410f3f5c393bd5d70851ae8df2e1196df6379de62b5d7d48c736b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1738fd28b1410f3f5c393bd5d70851ae8df2e1196df6379de62b5d7d48c736b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of reward hacking in RLHF-based Image Super-Resolution, where traditional Image Quality Assessment models are insensitive to local distortions. The authors propose a fine-grained reward model (FinPercep-RM) and a co-evolutionary curriculum learning strategy to provide localized feedback and stabilize training. Experiments show the method improves both global quality and local realism in generated images.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [State-Dependent Riccati Equation (SDRE), Integral Reinforcement Learning (IRL), Algebraic Riccati Equation (ARE), Nonlinear Input-Affine Systems, Optimal Regulation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Arya Rashidinejad Meibodi, Mahbod Gholamali Sinaki, Khalil Alipour</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Tehran, K. N. Toosi University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22668" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22668</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a partially model-free method for solving the State-Dependent Riccati Equation (SDRE) for nonlinear system control, eliminating the need for explicit drift dynamics knowledge. 2. Integrates Integral Reinforcement Learning (IRL) to learn the optimal control policy at each system state by solving the Algebraic Riccati Equation (ARE) online. 3. Demonstrates through simulation on a second-order nonlinear system that the IRL-based approach achieves performance comparable to the classical, model-dependent SDRE method.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4e534b9bbeb92e0817df99e432bb5925d48ed82bbc2dcc8e61dbc7faff88ee3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4e534b9bbeb92e0817df99e432bb5925d48ed82bbc2dcc8e61dbc7faff88ee3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the optimal regulation of nonlinear input-affine systems. It proposes a novel method that combines the State-Dependent Riccati Equation (SDRE) framework with Integral Reinforcement Learning (IRL) to learn optimal control without requiring a complete system model. Simulation results show that this IRL-based approach can achieve performance similar to the traditional model-dependent SDRE technique.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Memento-II: Learning by Stateful Reflective Memory</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [stateful reflective decision process, episodic memory, policy iteration, continual learning, retrieval-augmented generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jun Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> University College London (UCL)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22716</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the Stateful Reflective Decision Process (SRDP), a formal theoretical framework that models continual learning in LLM agents as a two-stage read-write interaction with episodic memory, linking it to policy evaluation and improvement. 2. Provides a theoretical analysis showing that the reflective learning process induces an equivalent Markov Decision Process, enabling the use of classical dynamic programming and RL tools, and establishes convergence guarantees when instantiated with entropy-regularised policy iteration. 3. Unifies heuristic approaches like case-based reasoning and retrieval-augmented generation with principled reinforcement learning, offering a rigorous mathematical foundation for building memory-augmented agents capable of online adaptation without parameter updates.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e8cff3c4a9f9d7b57c397010c69f5ae95897e34df30b8e86c43079e22a76db_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a theoretical framework for continual learning in LLM agents that uses episodic memory and reflection instead of back-propagation. The core method formalizes learning as a Stateful Reflective Decision Process, where writing to memory is policy evaluation and reading from it is policy improvement. The main conclusion is that this framework provides a principled, convergent foundation for agents to self-improve through interaction without fine-tuning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Cyber Resilience in Next-Generation Networks: Threat Landscape, Theoretical Foundations, and Design Paradigms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [network security], [software-defined networking, network function virtualization, zero trust architecture, reinforcement learning, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Junaid Farooq, Quanyan Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Michigan-Dearborn, New York University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22721" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22721</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides an interdisciplinary survey and analysis of the evolving threat landscape for next-generation networks, including AI-driven threats. 2. Establishes rigorous definitions and evaluation frameworks for cyber resilience that extend beyond traditional robustness and fault-tolerance. 3. Delves into advanced design paradigms and practical strategies, such as zero trust architectures and AI-enabled autonomous network control, for building resilient systems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45ce5f50020bb828e3588c3731b7d026aa73f3b8a029ede8f411eb0dc5e35dad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45ce5f50020bb828e3588c3731b7d026aa73f3b8a029ede8f411eb0dc5e35dad_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This book examines the challenge of achieving cyber resilience in next-generation networks, which are characterized by technologies like SDN and NFV. It proposes a re-conceptualized framework for resilience and explores advanced design paradigms, including AI-driven methods, to enable adaptive and autonomous threat response. The main conclusion is that a fundamental redesign of resilience mechanisms is required to secure the evolving, heterogeneous network infrastructure.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [context folding, long-horizon RL, non-stationary observation, gradient dilution, selective segment training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiaqi Shao, Yufeng Miao, Wei Zhang, Bing Luo</p>
</li>
<li class="">
<p><strong>institution:</strong> Hong Kong University of Science and Technology, Duke Kunshan University, Microsoft AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22733</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/SHAO-Jiaqi757/FoldAct" target="_blank" rel="noopener noreferrer" class="">https://github.com/SHAO-Jiaqi757/FoldAct</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Separated loss computation for independent gradient signals on summary and action tokens to address gradient dilution. 2. Full context consistency loss to reduce distribution shift caused by policy-dependent observation changes. 3. Selective segment training to reduce computational cost by processing unique contexts efficiently.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebdb4b7ca8ea3a44c0e368eed5fbbebfc656b663cf280d1891abfbf823c742fa_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that treating context folding (history summarization) as a standard action in long-horizon RL for LLMs creates a non-stationary observation distribution, leading to training instability and inefficiency. It proposes FoldAct, a framework with three innovations—separated loss, consistency loss, and selective training—to stabilize training and improve efficiency. The method achieves stable training and a 5.19× speedup.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ReDiF: Reinforced Distillation for Few Step Diffusion</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [reinforcement learning, knowledge distillation, policy optimization, denoising paths, model agnostic]</p>
</li>
<li class="">
<p><strong>authors:</strong> Amirhossein Tighkhorshid, Zahra Dehghanian, Gholamali Aminian, Chengchun Shi, Hamid R. Rabiee</p>
</li>
<li class="">
<p><strong>institution:</strong> Sharif University of Technology, Alan Turing Institute, London School of Economics</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22802" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22802</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel reinforcement learning framework for distilling diffusion models, treating distillation as a policy optimization problem. 2. Introduces a reward signal based on alignment with teacher outputs, allowing the student model to explore multiple denoising paths and take longer, optimized steps. 3. Demonstrates a model-agnostic framework that achieves superior performance with fewer inference steps and computational resources compared to existing distillation techniques.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73d47eb5443f9f8848454e65825da3569c70d954239d9794e6cff086fa5bc17a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow sampling problem in diffusion models by proposing ReDiF, a reinforcement learning-based distillation framework. Instead of using fixed losses, it treats distillation as policy optimization, using a reward signal to guide the student to take longer, optimized steps. The method achieves better performance with fewer steps and is applicable to various diffusion models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22796" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22796</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method&#x27;s flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gaurav Chaudhary, Laxmidhar Behera</p>
</li>
<li class="">
<p><strong>institution:</strong> IIT Kanpur</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22824" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22824</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [reflective policy optimization, asymmetric clipping, sample efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cuiling Wu, Yaozhong Gan, Junliang Xing, Ying Fu</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Institute of Technology, QiYuan Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22832" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22832</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency. 2. Introduces an asymmetric clipping mechanism derived from KL divergence to dynamically adjust the clipping range for improved training stability. 3. Validates the proposed MARPO framework on complex multi-agent benchmarks, demonstrating superior performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4bb8bd99df87d3fa5d6dae0b3405e01825ac1c612b07fbdd5519ae2b33ce19_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes MARPO, a new multi-agent reinforcement learning method to address sample inefficiency. It introduces a reflection mechanism to use trajectory information and an asymmetric clipping mechanism for stable training. The method is shown to outperform existing approaches in standard multi-agent environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [automated environment synthesis, environment-level RL, agentic reinforcement learning, simulated user, policy optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tongyi Lab, Alibaba Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22857</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]</p>
</li>
<li class="">
<p><strong>authors:</strong> Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar</p>
</li>
<li class="">
<p><strong>institution:</strong> Northeastern University, Dwarkadas J. Sanghvi College of Engineering</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22860" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22860</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [Reinforcement Networks, directed acyclic graph (DAG), credit assignment, LevelEnv, hierarchical RL]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maksim Kryzhanovskiy, Svetlana Glazyrina, Roman Ischenko, Konstantin Vorontsov</p>
</li>
<li class="">
<p><strong>institution:</strong> Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22876" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22876</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the Reinforcement Networks framework, a general approach for collaborative MARL that organizes agents as vertices in a directed acyclic graph (DAG)., 2. Formalizes training and inference methods for the framework and connects it to the LevelEnv concept for reproducible construction and evaluation., 3. Demonstrates improved performance over standard MARL baselines and unifies hierarchical, modular, and graph-structured views of MARL.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b613175c92e9bdddfbd57ed84d044a5846b7b8148cca8ab0405e69847f66c33a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of end-to-end training for AI systems with multiple learnable components. It proposes Reinforcement Networks, a framework that organizes agents in a directed acyclic graph for flexible credit assignment and coordination in multi-agent reinforcement learning. The method shows improved performance over baselines and provides a principled foundation for designing complex multi-agent systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [hierarchical deep reinforcement learning, portfolio management, dynamic asset grouping, utility-based capital allocation, SHAP interpretability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaotian Ren, Nuerxiati Abudurexiti, Zhengyong Jiang, Angelos Stefanidis, Hongbin Liu, Jionglong Su</p>
</li>
<li class="">
<p><strong>institution:</strong> Not explicitly stated in provided content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22895" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22895</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a hierarchical DRL framework (SAMP-HDRL) that integrates dynamic asset grouping, upper-lower agent coordination, and a utility-based capital allocation mechanism for robust portfolio management. 2. Demonstrates superior performance through extensive backtests across multiple market regimes, showing consistent improvements in return and risk-adjusted metrics over traditional and DRL baselines. 3. Provides interpretability via SHAP analysis, revealing a complementary &quot;diversified + concentrated&quot; decision pattern across agent layers.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07244b408b9238d10b2d5561e0007db8732b1d4e9e79bda5477bef5db2dd385c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles portfolio optimization in non-stationary markets by proposing SAMP-HDRL, a hierarchical deep reinforcement learning framework that segments assets, coordinates global and local agents, and uses a utility-based capital allocator. The method outperforms numerous baselines in backtests, achieving higher returns and risk-adjusted ratios, and its decisions are made interpretable through SHAP analysis, revealing a combined diversified and concentrated investment strategy.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Q-learning, ensemble learning, satisficing, distillation, bounded rationality]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ünver Çiftçi</p>
</li>
<li class="">
<p><strong>institution:</strong> Tekirdağ Namık Kemal University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22910</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a two-phase framework (Sat-EnQ) that first trains an ensemble of lightweight Q-networks using a satisficing objective to limit early value growth and reduce variance. 2. Provides theoretical proof that the satisficing objective induces bounded updates and cannot increase target variance, with a corollary for substantial reduction. 3. Demonstrates empirical results including significant variance reduction, elimination of catastrophic failures, robustness to noise, and improved compute efficiency compared to baseline methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d12c2382ed5ee9e4da47d1775097d950b626f676e5d3552cd0ff19b6c385b2a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the instability of deep Q-learning, especially early in training, by introducing Sat-EnQ. This framework first trains a satisficing ensemble of weak Q-learners to produce stable, low-variance estimates, then distills and fine-tunes the ensemble. The method significantly improves training reliability, robustness, and computational efficiency compared to standard approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Heterogeneity in Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [heterogeneity, multi-agent reinforcement learning, parameter sharing, heterogeneity distance, dynamic algorithm]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tianyi Hu, Zhiqiang Pu, Yuan Wang, Tenghai Qiu, Min Chen, Xin Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22941</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Harry67Hu/HetDPS" target="_blank" rel="noopener noreferrer" class="">https://github.com/Harry67Hu/HetDPS</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a systematic categorization of heterogeneity in MARL into five types with mathematical definitions. 2. Defines a heterogeneity distance and introduces a practical method to quantify agent heterogeneity. 3. Designs a heterogeneity-based dynamic parameter sharing algorithm that demonstrates better interpretability and adaptability compared to baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de4448c413f180749bc7f2220bea2793dad9a358fb068164020bd7b0421e5b05_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of a rigorous definition and understanding of heterogeneity in multi-agent reinforcement learning (MARL). It proposes a methodology to define, quantify, and utilize heterogeneity, culminating in a dynamic parameter sharing algorithm. Experiments show this algorithm offers improved interpretability and adaptability over other parameter-sharing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] APO: Alpha-Divergence Preference Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning from human feedback (rlhf)], [alpha-divergence, preference optimization, mode collapse, anchored coordinates, gradient variance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wang Zixian</p>
</li>
<li class="">
<p><strong>institution:</strong> China Mobile Communications Group Shandong Co., Ltd. Tai’an Branch</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22953" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22953</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces APO, an anchored framework using Csiszár alpha-divergence to continuously interpolate between forward and reverse KL behavior for RLHF. 2. Derives unified gradient dynamics parameterized by alpha and analyzes gradient variance properties. 3. Proposes a practical reward-and-confidence-guarded alpha schedule to transition from mode-covering to mode-seeking behavior safely.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a407212dc95985ef8918d58e7c65f70fd3f6adf8764c95f85871cd1924b3528_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the trade-off between stable but under-exploitative mode-covering updates and high-reward but unstable mode-seeking updates in LLM alignment. It proposes APO, an anchored preference optimization framework that uses alpha-divergence to smoothly interpolate between these regimes via a guarded schedule. Experiments show APO achieves competitive performance while maintaining training stability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Diversity or Precision? A Deep Dive into Next Token Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [policy gradient, reward shaping, next-token prediction, exploration space, cross-entropy loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haoyuan Wu, Hai Wang, Jiajia Wu, Jinxiang Ou, Keyao Wang, Weile Chen, Zihao Zheng, Bei Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Tencent, The Chinese University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22955" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22955</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Reinterprets standard cross-entropy loss as a specific instance of policy gradient optimization in a single-step episode, bridging supervised learning and RL. 2. Proposes a generalized pre-training objective using on-policy RL principles and a novel reward-shaping strategy to balance diversity and precision in the token-output distribution. 3. Empirically finds that a precision-oriented prior, rather than a high-entropy one, creates a more favorable exploration space for subsequent RL, enhancing reasoning performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how the token-output distribution from pre-training shapes the exploration space for subsequent reinforcement learning (RL) in language models. It proposes a new pre-training method that frames next-token prediction as an RL problem, using a reward-shaping strategy to control distribution precision. The key finding is that a precision-focused prior, contrary to intuition, provides a better exploration foundation for RL than a high-entropy one.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [reinforcement learning, training-inference mismatch, vocabulary pruning, gradient estimation, numerical stability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> (Institutions not explicitly listed in provided content. Affiliation inference requires author list with affiliations or email domains, which are not present in the given text. Therefore, cannot be determined from the provided snippet.)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23087" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23087</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proves that the training-inference mismatch in LLM RL has an asymmetric effect, where the bound on log-probability mismatch scales with (1-p), making low-probability &quot;tail&quot; tokens the primary source of instability. 2. Proposes a novel method to stabilize RL training by dynamically pruning the vocabulary to exclude the extreme tail tokens, trading large, biased mismatches for a small, bounded optimization bias. 3. Provides both empirical demonstration of stable training and a theoretical bound on the optimization bias introduced by the proposed vocabulary pruning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83b750895381feb238b14991a4015088fa8d05eb24ab0374082f6c25fb3ddd7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a fundamental training-inference mismatch in LLM reinforcement learning caused by differing numerical precision between high-throughput inference and stable training systems. To address this, the authors propose dynamically pruning low-probability &quot;tail&quot; tokens from the vocabulary during RL optimization, which stabilizes training by replacing large, biased errors with a small, bounded bias. Both theoretical analysis and empirical results support the effectiveness of this method.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yingru Li, Ziniu Li, Jiacai Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Not explicitly stated in provided content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23097</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, vision-language model, supervised fine-tuning, generalization paradox, cross-dataset transferability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Armin Berger, Manuela Bergau, Helen Schneider, Saad Ahmad, Tom Anglim Lagones, Gianluca Brugnara, Martha Foltyn-Dumitru, Kai Schlamp, Philipp Vollmuth, Rafet Sifa</p>
</li>
<li class="">
<p><strong>institution:</strong> Fraunhofer IAIS, University of Bonn, Lamarr Institute, Department of Health Queensland, Griffith University, University Hospital Bonn</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23090" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23090</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced ChexReason, a resource-efficient vision-language model for medical imaging trained with an R1-style (SFT+GRPO) method using minimal data and compute. 2. Identified a fundamental tension where RL optimization (GRPO) improves in-distribution benchmark performance but significantly degrades cross-dataset generalization, a pattern also observed in high-resource models. 3. Discovered a generalization paradox where the SFT checkpoint uniquely improves cross-dataset performance, suggesting teacher-guided reasoning captures more institution-agnostic features than RL optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87b0b1a571aa28f5dd9685e96b13ff3420ed36b0e1d569fff8b1394d564751f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper investigates applying reinforcement learning (RL) to vision-language models for medical imaging, finding that while RL improves performance on the training benchmark, it harms the model&#x27;s ability to generalize to new datasets. The authors conclude that for clinical robustness, curated supervised fine-tuning may be more effective than aggressive RL optimization.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Evaluating Parameter Efficient Methods for RLVR</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Parameter-Efficient Fine-Tuning, Reinforcement Learning with Verifiable Rewards, LoRA, Spectral Collapse, Mathematical Reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qingyu Yin, Yulun Wu, Zhennan Shen, Sunbowen Li, Zhilin Wang, Yanshu Li, Chak Tou Leong, Jiale Kang, Jinjin Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, HKUST, WUST, USTC, Brown University, Hong Kong Polytechnic University, INSAIT</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23165" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23165</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first comprehensive evaluation of over 12 PEFT methods for RLVR, challenging the default use of standard LoRA. 2. Identified that structural PEFT variants (DoRA, AdaLoRA, MiSS) consistently outperform LoRA in this setting. 3. Discovered and explained the failure of SVD-informed initialization methods (e.g., PiSSA) due to a &quot;spectral collapse&quot; phenomenon and misalignment with RL optimization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87ad6f372a6a1a3b13e37f8468a6816e52a585402f7e4505a01391ffaed0621c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper systematically evaluates Parameter-Efficient Fine-Tuning (PEFT) methods for Reinforcement Learning with Verifiable Rewards (RLVR) on mathematical reasoning tasks. It finds that structural variants like DoRA outperform standard LoRA, while SVD-based methods fail due to spectral collapse, and extreme parameter reduction bottlenecks performance. The work provides a guide for selecting PEFT methods in RLVR.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Human-Oriented Cooperative Driving Approach: Integrating Driving Intention, State, and Conflict</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [cooperative driving, human-machine conflict, intention-aware planning, authority allocation, shared control]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qin Wang, Shanmin Pang, Jianwu Fang, Shengye Dong, Fuhao Liu, Jianru Xue, Chen Lv</p>
</li>
<li class="">
<p><strong>institution:</strong> Xi&#x27;an Jiaotong University, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23220" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23220</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/i-Qin/HOCD" target="_blank" rel="noopener noreferrer" class="">https://github.com/i-Qin/HOCD</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a Human-Oriented Cooperative Driving (HOCD) approach that minimizes human-machine conflict by prioritizing driver intention and state. 2. Designs an intention-aware trajectory planning method at the tactical level, using an intention consistency cost to align the trajectory with driver intention. 3. Develops a reinforcement learning-based control authority allocation strategy at the operational level to achieve consistency between driver state and authority allocation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d5e5ef9e0e93b645fd2997c604be86cc36eb4f1a7f88af7219f0cc6a908523b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d5e5ef9e0e93b645fd2997c604be86cc36eb4f1a7f88af7219f0cc6a908523b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a Human-Oriented Cooperative Driving (HOCD) approach to improve human-vehicle interaction by minimizing conflict. The method integrates intention-aware trajectory planning and a reinforcement learning-based authority allocation strategy. Simulation and human-in-the-loop experiments show the approach aligns with driver intention, ensures reasonable authority allocation, and enhances driving performance compared to other methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ViLaCD-R1: A Vision-Language Framework for Semantic Change Detection in Remote Sensing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [change detection], [vision-language model, remote sensing, semantic change detection, supervised fine-tuning, reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xingwei Ma, Shiyang Feng, Bo Zhang, Bin Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, Shanghai Artificial Intelligence Laboratory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23244" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23244</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ViLaCD-R1, a novel two-stage vision-language framework for semantic change detection in remote sensing, comprising a Multi-Image Reasoner (MIR) and a Mask-Guided Decoder (MGD). 2. Introduces a training strategy for the VLM using supervised fine-tuning (SFT) and reinforcement learning (RL) on block-level dual-temporal inference tasks to generate a coarse change mask. 3. Demonstrates that the framework significantly improves semantic change recognition and localization while suppressing non-semantic variations, achieving state-of-the-art performance on multiple benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5871856f6e1854dd58df304f783ce8ea57314887e0296e446d48afb30805307_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of existing remote sensing change detection methods, such as poor semantic understanding and inaccurate localization, by proposing ViLaCD-R1. This two-stage vision-language framework first uses a fine-tuned VLM to generate a coarse change mask from dual-temporal images, then refines it with a decoder to produce a precise change map. The method shows superior performance in recognizing true semantic changes and suppressing irrelevant variations across several benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [semantic communications, agentic AI, joint source-channel coding, knowledge base, LLM/LVM agents]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haixiao Gao, Mengying Sun, Ruichen Zhang, Yanhan Wang, Xiaodong Xu, Nan Ma, Dusit Niyato, Ping Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing University of Posts and Telecommunications, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23294" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23294</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a comprehensive review of agentic AI-enhanced semantic communications, categorizing studies by agent types (embedded, LLM/LVM, RL). 2. Proposes a unified agentic AI-enhanced SemCom framework with a closed-loop architecture spanning application, semantic, and cloud-edge collaboration layers. 3. Introduces and validates a case study (AKB-JSCC) using agentic knowledge bases for joint source-channel coding, demonstrating improved reconstruction quality.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c6cd44bc1697f7504257d222eee725293b69d3eb38f48ca78c0d8e06f828cc7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c6cd44bc1697f7504257d222eee725293b69d3eb38f48ca78c0d8e06f828cc7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper explores how agentic AI can enhance semantic communications for 6G networks. It proposes a unified framework and a specific method (AKB-JSCC) that uses LLM/LVM and RL agents to build knowledge bases for improved coding. Experimental results show the proposed method achieves higher information reconstruction quality under various channel conditions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [CAD code generation, multi-expert reinforcement learning, Chain-of-Thought, CADExpert benchmark, CADQuery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ke Niu, Haiyang Yu, Zhuofan Chen, Zhengtao Yao, Weitao Jia, Xiaodong Ge, Jingqun Tang, Benlei Cui, Bin Li, Xiangyang Xue</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, ByteDance Inc.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23333</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Heterogeneous Collaborative Multi-Expert Reinforcement Learning (CME-CAD) paradigm for generating precise and editable CAD models., 2. Introduces a two-stage training process: Multi-Expert Fine-Tuning (MEFT) and Multi-Expert Reinforcement Learning (MERL)., 3. Presents CADExpert, an open-source benchmark with 17,299 instances including orthographic projections, CoT processes, CADQuery code, and 3D models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/854c145ea4394c54526f3cfa5f5b5e6528680bb17418bfc2756a03817bea2de5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/854c145ea4394c54526f3cfa5f5b5e6528680bb17418bfc2756a03817bea2de5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of automating the generation of high-precision, editable CAD models from sketches, which existing methods struggle with. It proposes a new training paradigm called CME-CAD, which uses a two-stage process of Multi-Expert Fine-Tuning and Reinforcement Learning to collaboratively improve model performance. The approach aims to generate accurate, constraint-compatible CAD code and is supported by a new open-source benchmark called CADExpert.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AGRO-SQL: Agentic Group-Relative Optimization with High-Fidelity Data Synthesis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text-to-sql], [Reinforcement Learning, Data Synthesis, Policy Optimization, Semantic-Logic Alignment, Group Relative Policy Optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cehua Yang, Dongyu Xiao, Junming Lin, Yuyang Song, Hanxu Yan, Shawn Guo, Wei Zhang, Jian Yang, Mingjie Tang, Bryan Dai</p>
</li>
<li class="">
<p><strong>institution:</strong> Sichuan University, IQuest Research, Beihang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23366</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an iterative data factory for synthesizing high-quality, RL-ready Text-to-SQL data with strict semantic-logic verification. 2. Introduces a novel Agentic Reinforcement Learning framework featuring a Diversity-Aware Cold Start stage and Group Relative Policy Optimization (GRPO). 3. Demonstrates state-of-the-art performance on the BIRD and Spider benchmarks through the synergistic combination of data-centric and model-centric approaches.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6740c1fc529b82b509bd38c2a7b5fb405b969bc5c3e11e6e0b7690e7fa791c85_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenges of data scarcity and limited reasoning in Text-to-SQL systems. It proposes a holistic framework that combines a data-centric approach for synthesizing high-fidelity training data with a model-centric approach using a novel Agentic Reinforcement Learning method called Group Relative Policy Optimization. The method achieves state-of-the-art results on major benchmarks, showing the effectiveness of the synergistic approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] The World Is Bigger! A Computationally-Embedded Perspective on the Big World Hypothesis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [continual learning], [big world hypothesis, computationally-embedded agent, interactivity, partially observable Markov decision process, model-based reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alex Lewandowski, Adtiya A. Ramesh, Edan Meyer, Dale Schuurmans, Marlos C. Machado</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Alberta, Amii, The Swiss AI Lab IDSIA, USI &amp; SUPSI, Canada CIFAR AI Chair, Google DeepMind</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23419" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23419</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a computationally-embedded perspective, representing an agent as an automaton simulated within a universal computer, proving it&#x27;s equivalent to interacting with a POMDP over an infinite state-space. 2. Proposed a new objective called &quot;interactivity&quot; to measure an agent&#x27;s ability to continually adapt its behavior by learning new predictions. 3. Developed a model-based RL algorithm for interactivity-seeking and constructed a synthetic problem to evaluate continual learning, finding deep linear networks outperform nonlinear ones in sustaining interactivity as capacity scales.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1eff9d76987d2bc49a07c8de307183661687471b7fe4f21ca75040ba3e1de25a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a computationally-embedded perspective to formalize the &quot;big world hypothesis&quot; in continual learning, where an agent is modeled as an automaton within the environment. It introduces &quot;interactivity&quot; as a new objective and a corresponding model-based RL algorithm to seek it. The main finding is that, in their synthetic evaluation, deep linear networks sustain higher interactivity as capacity increases, whereas deep nonlinear networks struggle.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23457" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23457</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/zhangkc97/HiR" target="_blank" rel="noopener noreferrer" class="">https://github.com/zhangkc97/HiR</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao</p>
</li>
<li class="">
<p><strong>institution:</strong> Tencent Hunyuan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23464" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23464</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Tencent-Hunyuan/HY-Motion-1.0" target="_blank" rel="noopener noreferrer" class="">https://github.com/Tencent-Hunyuan/HY-Motion-1.0</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning from human feedback (RLHF)], [reward model, inductive bias, information bottleneck, mutual information, reward hacking]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang</p>
</li>
<li class="">
<p><strong>institution:</strong> Alibaba, The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23461" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23461</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Qwen-Applications/DIR" target="_blank" rel="noopener noreferrer" class="">https://github.com/Qwen-Applications/DIR</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DIR, a novel information-theoretic debiasing method for reward models that maximizes mutual information with human preference while minimizing it with biased attributes. 2. Theoretically justifies the method&#x27;s ability to handle complex, non-linear inductive biases, extending beyond simple linear correlation models. 3. Empirically demonstrates DIR&#x27;s effectiveness in mitigating three types of biases (length, sycophancy, format) and shows it enhances RLHF performance and generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/522f5bbb5a5776cd8df024fb1b24faf19bb1a1ea6e0408c7951f37bfd1657846_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of inductive biases in reward models (RMs) for RLHF, which can lead to overfitting and reward hacking. It proposes DIR, an information-theoretic debiasing method inspired by the information bottleneck that optimizes mutual information to reduce bias. Experiments show DIR effectively mitigates multiple biases and improves RLHF performance and generalization.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [software supply chain security], [agentic AI, reinforcement learning, large language model, blockchain security ledger, CI/CD]</p>
</li>
<li class="">
<p><strong>authors:</strong> Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani</p>
</li>
<li class="">
<p><strong>institution:</strong> Islamic University of Madinah, Arab Open University-Bahrain</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23480" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23480</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Hierarchical Decision Mamba Meets Agentic AI: A Novel Approach for RAN Slicing in 6G</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Hierarchical Decision Mamba, Agentic AI, RAN Slicing, LLM, Self-healing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md Arafat Habib, Medhat Elsayed, Majid Bavand, Pedro Enrique Iturria Rivera, Yigit Ozcan, Melike Erol-Kantarci</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Ottawa, Ericsson Inc.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23502" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23502</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the first Hierarchical Decision Mamba (HDM) architecture for Agentic AI-based network management, enabling low-latency control via state-space sequence modeling. 2. Introduces a self-corrective control mechanism for continuous adjustment of slice weights and priorities to ensure SLA compliance. 3. Presents a coordinated Agentic AI framework that jointly orchestrates inter-slice provisioning, intra-slice scheduling, and self-healing for adaptive RAN management, integrating a Hybrid RAG-based LLM for context-aware decision-making.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05a50b9e8619f08f976fca766d72a9c64a17b17a2ce198f899fb8e68a2fb9f94_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05a50b9e8619f08f976fca766d72a9c64a17b17a2ce198f899fb8e68a2fb9f94_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a novel Agentic AI framework for 6G RAN slicing, which uses a Large Language Model (LLM) to interpret operator intents and a Hierarchical Decision Mamba (HDM) controller to coordinate specialized agents for resource scheduling and self-healing. The method addresses the lack of natural language understanding and coordinated decision-making in existing approaches. The framework demonstrates improved performance over baselines in terms of throughput, cell-edge performance, and latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [computational pathology], [agentic multimodal model, evidence-seeking inference, reinforcement learning, whole-slide images, vision-language model]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengyi Hua, Jianfeng Wu, Tianle Shen, Kangzhe Hu, Zhongzhen Huang, Shujuan Ni, Zhihong Zhang, Yuan Li, Zhe Wang, Xiaofan Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, Fourth Military Medical University, University of Science and Technology of China, Fudan University, Nanjing Medical University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23545" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23545</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed PathFound, an agentic multimodal model that introduces an evidence-seeking inference paradigm for pathological diagnosis, moving beyond static, single-pass analysis. 2. Integrated pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to enable proactive information acquisition and multi-stage diagnosis refinement. 3. Demonstrated that the evidence-seeking strategy consistently improves diagnostic accuracy across models and that PathFound achieves state-of-the-art performance, showing strong potential for discovering subtle pathological details.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db008475f544af0752cf146b5b6ba57eaf58c0e376cb94807dd3df594fa09037_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes PathFound, an agentic multimodal model that mimics clinical workflows by actively seeking evidence for ambiguous pathological diagnoses through multi-turn interactions. It integrates visual foundation models, vision-language models, and reinforcement learning-based reasoning to refine its initial diagnosis. The method achieves state-of-the-art diagnostic accuracy and demonstrates the effectiveness of evidence-seeking workflows in computational pathology.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ThinkGen: Generalized Thinking for Visual Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [text-to-image generation], [Chain-of-Thought (CoT), Multimodal Large Language Model (MLLM), Diffusion Transformer (DiT), reinforcement learning, SepGRPO]</p>
</li>
<li class="">
<p><strong>authors:</strong> Siyu Jiao, Yiheng Lin, Yujie Zhong, Qi She, Wei Zhou, Xiaohan Lan, Zilong Huang, Fei Yu, Yingchen Yu, Yunqing Zhao, Yao Zhao, Yunchao Wei</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Jiaotong University, Bytedance</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23568" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23568</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/jiaosiyuu/ThinkGen" target="_blank" rel="noopener noreferrer" class="">https://github.com/jiaosiyuu/ThinkGen</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM&#x27;s CoT reasoning for various generation tasks. 2. Introduces a decoupled architecture using a pretrained MLLM to generate instructions and a DiT for image synthesis. 3. Proposes a separable GRPO-based training paradigm (SepGRPO) for alternating reinforcement learning between modules, enabling joint training across diverse datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8377ac1537eac2a0f36b9ae8883a51e957cbbeb6e49b280cc20b5c5080e11f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8377ac1537eac2a0f36b9ae8883a51e957cbbeb6e49b280cc20b5c5080e11f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces ThinkGen, a framework that integrates Chain-of-Thought reasoning from Multimodal LLMs with a Diffusion Transformer for visual generation. It uses a decoupled architecture and a novel separable reinforcement learning training method to generalize across diverse generation scenarios. Experiments show it achieves state-of-the-art performance on multiple benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ProGuard: Towards Proactive Multimodal Safeguard</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal safety], [proactive guard, out-of-distribution (OOD) detection, reinforcement learning (RL), multimodal safety taxonomy, synonym-bank reward]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaohan Yu, Lijun Li, Chenyang Si, Lu Sheng, Jing Shao</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory, Nanjing University, Beihang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23573</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://yushaohan.github.io/ProGuard" target="_blank" rel="noopener noreferrer" class="">https://yushaohan.github.io/ProGuard</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces ProGuard, a vision-language proactive guard model that identifies and describes out-of-distribution safety risks without requiring model adjustments. 2. Constructs a modality-balanced dataset of 87K samples with binary safety labels and hierarchical risk categories to mitigate modality bias. 3. Trains the model purely via reinforcement learning augmented with a synonym-bank-based similarity reward to enhance OOD risk inference and description.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ffca72668094b2c8095387a83d8b49cc465da7d2f333cac7db429f76193be61_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ffca72668094b2c8095387a83d8b49cc465da7d2f333cac7db429f76193be61_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes ProGuard, a proactive multimodal safeguard that uses reinforcement learning on a balanced dataset to detect and describe unseen safety risks. It achieves performance comparable to closed-source models on safety classification and significantly improves OOD risk detection and description by over 50%.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Le Cam Distortion: A Decision-Theoretic Framework for Robust Transfer Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [transfer learning], [Le Cam Distortion, Deficiency Distance, Directional Simulability, Unsupervised Domain Adaptation, Negative Transfer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deniz Akdemir</p>
</li>
<li class="">
<p><strong>institution:</strong> None (Institution not specified in provided content)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23617" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23617</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a decision-theoretic framework for robust transfer learning based on Le Cam&#x27;s theory, replacing symmetric invariance with directional simulability. 2. Introduces Le Cam Distortion, quantified by the Deficiency Distance, as a rigorous upper bound for transfer risk. 3. Demonstrates the framework&#x27;s effectiveness across diverse experiments (genomics, vision, RL), showing it prevents source degradation and catastrophic negative transfer where traditional methods fail.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bd736028263c7eaaaaecae78f0df59f633374608f59295b1185c8385eea1e5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a flaw in standard Unsupervised Domain Adaptation, which can cause harmful &quot;negative transfer&quot; by forcing invariance between unequally informative domains. It proposes a new framework based on Le Cam&#x27;s theory, using directional simulability and a metric called Le Cam Distortion to enable safe transfer without degrading the source domain. Experiments show this method successfully prevents information loss and catastrophic failure in safety-critical applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Process Reward Model, Policy-Invariant Reward Shaping, Multi-Perspective Reward Fusion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huajie Tan, Sixiang Chen, Yijie Xu, Zixiao Wang, Yuheng Ji, Cheng Chi, Yaoxu Lyu, Zhongxia Zhao, Xiansheng Chen, Peterson Co, Shaoxuan Xie, Guocai Yao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Beijing Academy of Artificial Intelligence</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23703" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23703</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://robo-dopamine.github.io" target="_blank" rel="noopener noreferrer" class="">https://robo-dopamine.github.io</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Dopamine-Reward, a method for learning a step-aware, general-purpose process reward model (GRM) from multi-view inputs to overcome perceptual limitations. 2. Proposes a theoretically-sound Policy-Invariant Reward Shaping method within the Dopamine-RL framework to enable efficient policy learning without altering the optimal policy. 3. Demonstrates high efficiency and generalization, where a one-shot adapted GRM enables policy learning to achieve 95% success with only 150 online rollouts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbdde8d7dea23f224b530580752926db8c72c9f5768172278573c890a3c6b0c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cbdde8d7dea23f224b530580752926db8c72c9f5768172278573c890a3c6b0c6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of designing effective reward functions for real-world robotic RL by introducing Robo-Dopamine. It proposes a general, step-aware reward model trained on a large dataset and a robust policy learning framework with theoretically-sound reward shaping. Experiments show the approach achieves state-of-the-art reward accuracy and significantly improves policy learning efficiency with strong generalization.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Training AI Co-Scientists Using Rubric Rewards</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23707</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [alpha screening, large language models, reinforcement learning, factor investing, economic reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zuoyou Jiang, Li Zhao, Rui Sun, Ruohan Sun, Zhongjian Li, Jing Li, Daxin Jiang, Zuo Bai, Cheng Hua</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, StepFun, FinStep</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23515" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23515</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/FinStep-AI/Alpha-R1" target="_blank" rel="noopener noreferrer" class="">https://github.com/FinStep-AI/Alpha-R1</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. 2. Introduces a method for LLMs to reason over factor logic and real-time news to evaluate alpha relevance under changing market conditions. 3. Demonstrates that the model consistently outperforms benchmarks and shows improved robustness to alpha decay across multiple asset pools.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d921912985e0858276fe1088914641df9c33c30f5de309733b2244c86c21e75e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of alpha decay in non-stationary financial markets by proposing Alpha-R1, a reasoning model trained with reinforcement learning. It uses a large language model to process factor logic and news, selectively activating factors based on contextual economic relevance. Empirical results show it outperforms benchmark strategies and is more robust to signal decay.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<p><strong>cs.AI/cs.LG contains &quot;accelerate&quot; total: 30</strong></p>
<ul>
<li class="">
<p><strong>[arXiv251230] An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [RFET, stochastic computing, SCNN, stochastic number generator, accelerator]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sheng Lu, Qianhou Qu, Sungyong Jung, Qilian Liang, Chenyun Pan</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Texas at Arlington (inferred from IEEE affiliation and author &quot;Qilian Liang, Fellow, IEEE&quot; known association)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22131</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel SCNN architecture leveraging Reconfigurable Field-Effect Transistors (RFETs) for device-level reconfigurability. 2. Designs highly efficient and compact core modules (e.g., SNGs, APCs) enabled by RFET technology. 3. Develops and evaluates a dedicated RFET-based SCNN accelerator, showing significant improvements in area, latency, and energy over a FinFET baseline.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d718d7962f59eda2ed3430de0579c28b976cb6dd1e7da5e6fb355787c2b15ee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high resource consumption of Stochastic Computing Neural Networks (SCNNs) by proposing a novel accelerator architecture based on Reconfigurable Field-Effect Transistors (RFETs). The inherent reconfigurability of RFETs enables the design of compact and efficient core components like stochastic number generators. Experimental results demonstrate that the proposed RFET-based accelerator achieves substantial reductions in area, latency, and energy consumption compared to a FinFET-based design at the same technology node.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HookMIL: Revisiting Context Modeling in Multiple Instance Learning for Computational Pathology</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [computational pathology], [Multiple Instance Learning, Hook Tokens, Linear Complexity, Multimodal Initialization, Hook Diversity Loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xitong Ling, Minxi Ouyang, Xiaoxiao Li, Jiawen Li, Ying Chen, Yuxuan Sun, Xinrui Chen, Tian Guan, Xiaoping Liu, Yonghong He</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Xiamen University, Westlake University, Wuhan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22188" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22188</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/lingxitong/HookMIL" target="_blank" rel="noopener noreferrer" class="">https://github.com/lingxitong/HookMIL</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes HookMIL, a context-aware MIL framework using learnable hook tokens for structured contextual aggregation with linear computational complexity. 2. Introduces a multimodal initialization strategy for hook tokens using visual, textual, and spatial priors to accelerate convergence and improve representation. 3. Presents a Hook Diversity Loss and a hook-to-hook communication mechanism to encourage token specialization and refine interactions while minimizing redundancy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/125d35cff1b2c94d5e736ab81d897743e3d0b37d50d5ba6ce441aa77f8bc620e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the loss of context in traditional MIL and the high computational cost of transformer-based MIL for whole-slide image analysis. It proposes HookMIL, a framework that uses learnable hook tokens for efficient, linear-complexity context modeling, enhanced by multimodal initialization and specialized loss functions. Experiments on four public datasets show that HookMIL achieves state-of-the-art performance with improved efficiency and interpretability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] DiRL: An Efficient Post-Training Framework for Diffusion Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Diffusion Language Models, FlexAttention, Group Relative Policy Optimization, LMDeploy, blockwise training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, Shanghai Innovation Institute, OpenMoss Team</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22234" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22234</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/OpenMOSS/DiRL" target="_blank" rel="noopener noreferrer" class="">https://github.com/OpenMOSS/DiRL</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DiRL, an efficient post-training framework for Diffusion Language Models (dLLMs) that integrates FlexAttention-accelerated blockwise training with LMDeploy-optimized inference. 2. Introduces DiPO, the first unbiased Group Relative Policy Optimization (GRPO) implementation specifically designed for dLLMs. 3. Demonstrates state-of-the-art math reasoning performance for dLLMs by training DiRL-8B-Instruct, surpassing comparable models like Qwen2.5 series on benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0ae2d009d9099214203b1dcca9a8b460cf0609d952e240f981b2689f247e17d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underdeveloped and inefficient post-training landscape for Diffusion Language Models (dLLMs). It proposes DiRL, an efficient framework combining accelerated training and optimized inference, and introduces DiPO, a tailored reinforcement learning method. The resulting model, DiRL-8B-Instruct, achieves state-of-the-art math performance among dLLMs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Graph Attention-based Adaptive Transfer Learning for Link Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [graph neural networks], [graph attention network, link prediction, transfer learning, graph transformer, contrastive loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huashen Lu, Wensheng Gan, Guoting Chen, Zhichao Huang, Philip S. Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Jinan University, Great Bay University, JD Technology, University of Illinois Chicago</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22252" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22252</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/DSI-Lab1/GAATNet" target="_blank" rel="noopener noreferrer" class="">https://github.com/DSI-Lab1/GAATNet</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes GAATNet, a novel graph attention adaptive transfer network combining pre-training and fine-tuning for cross-dataset knowledge transfer in link prediction. 2. Incorporates distant neighbor embeddings as biases in self-attention to capture global node features. 3. Introduces a lightweight self-adapter module during fine-tuning to improve training efficiency and generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9ea1091686509af1da226ce7553577b4005c5646524a5c6718473e451d3c39_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses challenges in link prediction on large-scale sparse graphs and cross-dataset transfer learning by proposing GAATNet, which integrates graph attention with adaptive transfer strategies. The method uses distant neighbor embeddings and a self-adapter module to enhance global feature capture and training efficiency. Experiments on seven datasets show state-of-the-art performance, offering a scalable solution for integrating GNNs with transfer learning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LuxIA: A Lightweight Unitary matriX-based Framework Built on an Iterative Algorithm for Photonic Neural Network Training</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [photonic neural networks, transfer matrix, Slicing method, back-propagation, simulation framework]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tzamn Melendez Carmona, Federico Marchesin, Marco P. Abrate, Peter Bienstman, Stefano Di Carlo, Alessandro Savino Senior</p>
</li>
<li class="">
<p><strong>institution:</strong> Politecnico di Torino, Ghent University - imec, University College London</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22264" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22264</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Slicing method, an efficient transfer matrix computation approach compatible with back-propagation for training Photonic Neural Networks (PNNs). 2. Introduces LuxIA, a unified simulation and training framework that integrates the Slicing method to enable scalable PNN training. 3. Demonstrates through experiments that LuxIA surpasses existing tools in speed and scalability for training large-scale PNNs on standard datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/362a4190a58349fa96aae555a8a4643a7fdd50b962ff88817d9c12e4678fbe98_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the scalability challenges in simulating and training large-scale Photonic Neural Networks (PNNs) by introducing the Slicing method for efficient transfer matrix computation. The method is integrated into the LuxIA framework, which significantly reduces memory usage and training time. Experimental results show LuxIA outperforms existing tools, enabling the exploration of larger and more complex photonic architectures.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] DBAW-PIKAN: Dynamic Balance Adaptive Weight Kolmogorov-Arnold Neural Network for Solving Partial Differential Equations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [scientific machine learning], [Physics-informed neural networks, Kolmogorov-Arnold networks, Adaptive weighting, B-splines, Partial differential equations]</p>
</li>
<li class="">
<p><strong>authors:</strong> Guokan Chen, Yao Xiao</p>
</li>
<li class="">
<p><strong>institution:</strong> Fujian University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22283" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22283</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DBAW-PIKAN, a novel architecture combining a Kolmogorov-Arnold Network (KAN) with learnable B-splines for enhanced function representation in solving PDEs., 2. Introduces an adaptive weighting strategy with a dynamic decay upper bound to mitigate gradient flow stiffness and spectral bias, addressing key failure modes of PINNs., 3. Demonstrates significant improvements in convergence speed and solution accuracy (at least an order of magnitude) on benchmarks like Klein-Gordon, Burgers, and Helmholtz equations without added computational cost.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb9e65232c0c340c6072237e2ad1388255462aafca80cf91d4b7f3054eb9fe8c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes DBAW-PIKAN, a novel neural network that integrates a Kolmogorov-Arnold architecture with an adaptive weighting strategy to overcome the stiffness and spectral bias challenges faced by Physics-Informed Neural Networks (PINNs) when solving multi-scale PDEs. The method accelerates convergence and improves solution accuracy by at least an order of magnitude on standard benchmarks without increasing computational complexity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]</p>
</li>
<li class="">
<p><strong>authors:</strong> You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Northwestern University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22307</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (&lt;0.1% for 7,168 key bits).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Missouri, SRI International</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22387</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Quantum Generative Models for Computational Fluid Dynamics: A First Exploration of Latent Space Learning in Lattice Boltzmann Simulations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [Quantum Generative Models, Computational Fluid Dynamics, Lattice Boltzmann Method, Vector Quantized Variational Autoencoder, Quantum Circuit Born Machine]</p>
</li>
<li class="">
<p><strong>authors:</strong> Achraf Hsain, Fouad Mohammed Abbou</p>
</li>
<li class="">
<p><strong>institution:</strong> Al Akhawayn University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22672" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22672</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A complete open-source pipeline bridging CFD simulation and quantum machine learning. 2. The first empirical study of quantum generative modeling on compressed latent representations of physics simulations. 3. A comparative analysis of quantum (QCBM, QGAN) and classical (LSTM) generative models for a physics-derived latent distribution.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6094a8215d7304400e5580e08cc0e81135106aaf9b51ef11b7f4c5d62734237e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper explores the application of quantum generative models to Computational Fluid Dynamics (CFD) data. The authors compress fluid simulation data into a discrete latent space using a VQ-VAE and then compare quantum (QCBM, QGAN) and classical (LSTM) models for generating samples from this distribution. Under their experimental conditions, the quantum models, particularly the QCBM, outperformed the classical baseline in generating samples closer to the true distribution.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [differential games], [Hamilton-Jacobi reachability, reach-avoid games, dimensionality decomposition, UAVs, tracking control]</p>
</li>
<li class="">
<p><strong>authors:</strong> Minh Bui, Simon Monckton, Mo Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Simon Fraser University, Defense Research &amp; Development Canada (DRDC)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22793" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22793</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel dimensionality reduction framework for 3D reach-avoid games by decomposing the problem into horizontal and vertical sub-games., 2. A Hamilton-Jacobi-based tracking control algorithm to reconstruct the solution from sub-games, guaranteeing capture and subsequent tracking of the attacker., 3. Theoretical proof of the conditions for maintaining capture guarantees and empirical validation in both numerical simulations and a physics simulator (Gazebo).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14da164894760eae683bf30139829cd77a6bbd67cf14fee19eb09a05cb31eff_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles the high-dimensional challenge of 3D reach-avoid differential games for UAVs by proposing a decomposition approach that splits the problem into horizontal and vertical sub-games, solves them using Hamilton-Jacobi reachability analysis, and uses a novel tracking control to reconstruct the solution. The method is proven to maintain optimality and capture guarantees, and its effectiveness is successfully demonstrated through simulations and a physics simulator for quadrotor capture.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [ODE solver, parallel gradient evaluation, reinforcement learning fine-tuning, low-latency sampling, Dirichlet policy]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Westlake University, University of Illinois Urbana-Champaign, Nanyang Technological University, Shanghai Jiao Tong University, University of Science and Technology of China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22796" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22796</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes EPD-Solver, a novel ODE solver that uses multiple parallel gradient evaluations per step to reduce truncation errors while maintaining low latency. 2. Introduces a two-stage optimization framework, including a parameter-efficient RL fine-tuning scheme that reformulates the solver as a stochastic Dirichlet policy to avoid reward hacking. 3. Demonstrates the method&#x27;s flexibility as a plugin (EPD-Plugin) to enhance existing ODE samplers and shows state-of-the-art performance in both unconditional and text-to-image generation benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2678a61b07c4f5b5cfdd2006673a05c8a4699c07dee6180c47750600496f796_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high sampling latency of diffusion models by proposing EPD-Solver, a novel ODE solver that incorporates parallel gradient evaluations to reduce errors without increasing latency. The method uses a two-stage optimization, including RL fine-tuning with a Dirichlet policy, and can be used as a plugin. Experiments show it achieves superior image quality at low step counts and improves human preference scores in text-to-image generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] TEACH: Temporal Variance-Driven Curriculum for Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [curriculum learning, goal-conditioned reinforcement learning, temporal variance, student-teacher paradigm, Q-function]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gaurav Chaudhary, Laxmidhar Behera</p>
</li>
<li class="">
<p><strong>institution:</strong> IIT Kanpur</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22824" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22824</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Student-Teacher learning paradigm with a Temporal Variance-Driven Curriculum for accelerating Goal-Conditioned RL. 2. Establishes a theoretical connection between the temporal variance of Q-values and policy evolution. 3. Demonstrates the algorithm-agnostic nature of the approach, showing consistent improvements across 11 robotic manipulation and maze navigation tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c410b802a9fdb44624e8bf6d607803fec918def24d7a3c81bf3fb12d7fb2e63_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the sample inefficiency of uniform goal selection in multi-goal reinforcement learning. It proposes a TEACH framework where a teacher module dynamically selects goals with the highest temporal variance in Q-values to create an adaptive curriculum. The method is shown to improve learning efficiency over state-of-the-art curriculum learning methods across diverse robotic tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] PreGME: Prescribed Performance Control of Aerial Manipulators based on Variable-Gain ESO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [robotics control], [aerial manipulator, prescribed performance control, variable-gain extended state observer, dynamic coupling, motion control]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mengyu Ji, Shiliang Guo, Zhengzhen Li, Jiahao Shen, Huazi Cao, Shiyu Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Westlake University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22957</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel prescribed performance motion control framework (PreGME) for aerial manipulators. 2. The use of variable-gain extended state observers (ESOs) for accurate real-time estimation of rapidly varying dynamic coupling. 3. A control strategy that generates a preset error trajectory to ensure tracking errors remain within a prescribed performance envelope for high-precision control.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f2803479d85cfb232ae59d1133082b1c37608a63bed7f68577a5675d15b2598_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f2803479d85cfb232ae59d1133082b1c37608a63bed7f68577a5675d15b2598_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes PreGME, a new control framework for aerial manipulators that combines variable-gain extended state observers to estimate dynamic coupling with prescribed performance control to constrain error trajectories. The method enables high-precision control even during aggressive arm motions. Experiments, including aerial mixology and cart-pulling, validate its effectiveness under significant dynamic disturbances.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Embodied Robot Manipulation in the Era of Foundation Models: Planning and Learning Perspectives</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [robotic manipulation], [robotic foundation models, high-level planning, low-level control, imitation learning, reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuanghao Bai, Wenxuan Song, Jiayi Chen, Yuheng Ji, Zhide Zhong, Jin Yang, Han Zhao, Wanqi Zhou, Zhe Li, Pengxiang Ding, Cheng Chi, Chang Xu, Xiaolong Zheng, Donglin Wang, Haoang Li, Shanghang Zhang, Badong Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Xi&#x27;an Jiaotong University, Hong Kong University of Science and Technology (Guangzhou), Chinese Academy of Sciences, Westlake University, Zhejiang University, University of Sydney, BAAI, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22983" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22983</a></p>
</li>
<li class="">
<p><strong>code:</strong> Awesome-Robotics-Manipulation</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a unified algorithmic abstraction for robot manipulation, organizing approaches into high-level planning and low-level control. 2. Extends classical task planning to include reasoning over language, code, motion, affordances, and 3D representations. 3. Introduces a training-paradigm-oriented taxonomy for learning-based control, categorizing methods by input modeling, latent representation learning, and policy learning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22135ed5ae9ef66789b2dbe7f9c4c6e6a9de91ca6dd4b2025e75cfd5d4a89d02_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22135ed5ae9ef66789b2dbe7f9c4c6e6a9de91ca6dd4b2025e75cfd5d4a89d02_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This survey paper organizes recent learning-based approaches to robot manipulation within a unified framework of high-level planning and low-level control. It extends task planning to include multimodal reasoning and proposes a new taxonomy for learning-based control. The analysis aims to clarify the design space and identifies key challenges like scalability and safety for future robotic foundation models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [activation function, hardware accelerator, taylor series, energy efficiency, edge inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Soham Pramanik, Vimal William, Arnab Raha, Debayan Das, Amitava Mukherjee, Janet L. Paluh</p>
</li>
<li class="">
<p><strong>institution:</strong> Jadavpur University, SandLogic Technologies, Intel Corporation, Indian Institute of Science, Amrita University, SUNY Polytechnic Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23062" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23062</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes TYTAN, a Taylor-series based Generalized Non-linear Approximation Engine (G-NAE) for accelerating non-linear activation functions in deep learning. 2. Integrates a re-configurable hardware design with a specialized algorithm to dynamically estimate approximations, aiming for minimal accuracy deviation. 3. Demonstrates significant performance gains and efficiency improvements, including ~2x performance, ~56% power reduction, and ~35x lower area compared to a baseline NVDLA implementation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/233e926fc1401824c658e53f6ee69cc2fa91152f36cad6ff674b919cf9a3aa0e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes TYTAN, a hardware-software co-designed engine that uses Taylor series approximations to accelerate non-linear activation functions for energy-efficient AI inference at the edge. The system dynamically configures the approximation to maintain accuracy. Evaluations show it achieves high frequency operation (&gt;950 MHz) with substantial improvements in performance, power, and area compared to a standard accelerator.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Zero Trust Architecture], [Zero Trust, Micro-Segmentation, Adaptive Identity, Security Automation, Financial Risk Modeling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Paulo Fernandes Biao</p>
</li>
<li class="">
<p><strong>institution:</strong> Biaotech.dev</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23124" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23124</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SecureBank, a financially-aware and context-adaptive Zero Trust architecture specifically for high-assurance banking systems. 2. Integrates novel components like Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro-Segmentation, and Impact-Driven Security Automation. 3. Provides experimental validation through Monte Carlo simulation using new metrics (TII, ITAL, SAE), showing improved attack handling and trust adaptation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces SecureBank, a Zero Trust architecture designed for banking systems that incorporates financial risk and context. It integrates components like adaptive identity scoring and impact-driven automation. Simulation results show it improves automated attack handling and identity trust adaptation while maintaining transactional integrity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [regression], [squeeze and excitation, channel attention, residual connections, multi-layer perceptron, penetration acceleration]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yankang Li, Changsheng Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanjing University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23131</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed SE-MLP, a novel MLP architecture integrating a channel attention mechanism for feature prediction. 2. Incorporated residual connections into the MLP framework to enhance model stability and performance. 3. Demonstrated the model&#x27;s superior accuracy, generalization, and engineering applicability for rapidly predicting penetration acceleration features.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dab35d2c00d22564e8f3e36c067728bb8b4d1bb60f2ed675bfe34288c07503a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes SE-MLP, a multi-layer perceptron model enhanced with squeeze-and-excitation channel attention and residual connections, to rapidly predict prior acceleration features for penetration signals. The model establishes a nonlinear mapping from physical parameters to acceleration features, outperforming baseline models like MLP, XGBoost, and Transformer in accuracy and stability. The results validate its feasibility and provide a practical basis for engineering applications in penetration fuse design.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [molecular language modeling], [HELM notation, DeBERTa, cyclic peptide, membrane permeability, peptide-protein interaction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Seungeon Lee, Takuto Koyama, Itsuki Maeda, Shigeyuki Matsumoto, Yasushi Okuno</p>
</li>
<li class="">
<p><strong>institution:</strong> Kyoto University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23175" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23175</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes HELM-BERT, the first encoder-based peptide language model trained on HELM notation, designed to capture hierarchical dependencies. 2. Pre-trains the model on a curated corpus of 39,079 chemically diverse linear and cyclic peptides. 3. Demonstrates superior performance over SMILES-based models in downstream tasks like cyclic peptide membrane permeability and peptide-protein interaction prediction.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c83ec939e21fe471473f433077555782bca673e92ad1bfd3578b0fe729e20446_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces HELM-BERT, a transformer model based on DeBERTa and trained on HELM notation to better represent therapeutic peptides. It shows that this approach significantly outperforms existing SMILES-based models in predicting key peptide properties, demonstrating the data-efficiency advantages of topology-aware representations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [agentic kernel coding, heterogeneous accelerators, retrieval-augmented prompt synthesis, graph-based search, Triton/CuTe DSL]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gang Liao, Hongsen Qin, Ying Wang, Alicia Golden, Michael Kuchnik, Yavuz Yetim, Jia Jiunn Ang, Chunli Fu, Yihan He, Samuel Hsia, Zewei Jiang, Dianshi Li, Uladzimir Pashkevich, Varna Puvvada, Feng Shi, Matt Steiner, Ruichao Xiao, Nathan Yan, Xiayu Yu, Zhou Fang, Abdul Zainul-Abedin, Ketan Singh, Hongtao Yu, Wenyuan Chi, Barney Huang, Sean Zhang, Noah Weller, Zach Marine, Wyatt Cook, Carole-Jean Wu, Gaoxiang Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta Platforms</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23236" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23236</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes KernelEvolve, an agentic framework that automates kernel generation and optimization for DLRMs across heterogeneous hardware (NVIDIA/AMD GPUs, Meta accelerators) by operating at multiple programming abstractions. 2. Introduces a kernel optimization process modeled as a graph-based search with dynamic adaptation to runtime context via retrieval-augmented prompt synthesis and a persistent hardware knowledge base. 3. Demonstrates the system&#x27;s effectiveness by achieving 100% correctness on benchmark suites and substantial performance speedups (up to 17x) in production, reducing development time from weeks to hours and lowering the programmability barrier for new AI hardware.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/641ba327ba0d01461cd8fabad9a237e7b6667ce170be08aa3e89e6624ada0d38_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents KernelEvolve, an agentic framework that automates the generation and optimization of compute kernels for deep learning recommendation models to address challenges posed by model, kernel, and hardware heterogeneity. The method uses a graph-based search process enhanced with retrieval-augmented prompts and operates across multiple programming abstractions. The system was validated on production models and benchmarks, showing significant performance improvements and reduced development time, effectively mitigating the programmability barrier for new AI accelerators.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [diffusion transformer, inference acceleration, caching, error minimization, dynamic programming]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tong Shao, Yusen Fu, Guoying Sun, Jingde Kong, Zhuotao Tian, Jingyong Su</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology, Shenzhen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23258" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23258</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes CEM, a novel plugin for optimizing caching strategies in DiT acceleration via cumulative error minimization. 2. Introduces a dynamic programming algorithm guided by a predefined error prior to adaptively minimize caching error. 3. Demonstrates the method&#x27;s model-agnostic nature, seamless integration into existing frameworks, and significant fidelity improvements across multiple models and tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2f0b193709fc539d32a8fa74b0405ea99491982cb3f280e0dd10ff89b6b0a3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b2f0b193709fc539d32a8fa74b0405ea99491982cb3f280e0dd10ff89b6b0a3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the slow inference of Diffusion Transformers (DiTs) by proposing CEM, a plug-and-play fidelity optimization plugin. CEM minimizes cumulative caching error via a dynamic programming algorithm, adapting to error variations during denoising. The method is training-free, model-agnostic, and significantly improves generation fidelity when integrated with existing acceleration techniques.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] PCR-ORB: Enhanced ORB-SLAM3 with Point Cloud Refinement Using Deep Learning-Based Dynamic Object Filtering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [visual SLAM], [ORB-SLAM3, YOLOv8, dynamic object filtering, point cloud refinement, CUDA acceleration]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sheng-Kai Chen, Jie-Yu Chao, Jr-Yu Chang, Po-Lien Wu, Po-Chiang Lin</p>
</li>
<li class="">
<p><strong>institution:</strong> Yuan Ze University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23318" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23318</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes PCR-ORB, an enhanced ORB-SLAM3 framework that integrates deep learning-based point cloud refinement to filter dynamic objects. 2. Implements a multi-stage filtering strategy combining semantic segmentation (YOLOv8), ground plane estimation, sky removal, edge filtering, and temporal consistency for robust dynamic object removal. 3. Achieves real-time performance through CUDA-accelerated processing and demonstrates significant accuracy improvements in specific dynamic sequences on the KITTI dataset.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e72d53f96b383c73428b67d24fbf2d4163ac5820be1bfed6f370c529922f919_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e72d53f96b383c73428b67d24fbf2d4163ac5820be1bfed6f370c529922f919_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces PCR-ORB, an enhanced visual SLAM system that improves ORB-SLAM3&#x27;s robustness in dynamic environments by integrating YOLOv8 for semantic segmentation and a multi-stage point cloud refinement process to filter moving objects. The method achieves real-time performance with CUDA acceleration. Evaluation on KITTI shows scenario-dependent effectiveness, with notable accuracy improvements in some sequences but mixed results overall.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [explainable ai (xai)], [inverse kinematics, shapley additive explanations (SHAP), InterpretML, obstacle avoidance, neural network]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sheng-Kai Chen, Yi-Ling Tsai, Chun-Chih Chang, Yan-Chen Chen, Po-Chiang Lin</p>
</li>
<li class="">
<p><strong>institution:</strong> Yuan Ze University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23312</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an explainability-centered workflow integrating SHapley Additive exPlanations (SHAP) with physics-based obstacle avoidance evaluation for neural inverse kinematics. 2. Introduces and trains two lightweight variants of IKNet (Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling) on a synthetic dataset. 3. Demonstrates through simulation that neural IK architectures with more balanced feature importance attribution tend to maintain wider safety margins without sacrificing accuracy, linking XAI insights to robotic safety.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ab3055f2df7d03d7972b536c04fab2618a41cdd21ee682cf0f1ab9c0c6610f6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study addresses the lack of transparency in neural network-based inverse kinematics (IK) solvers by proposing an explainable AI workflow. It integrates SHAP analysis with physics-based simulation to evaluate two new IKNet variants on obstacle avoidance tasks. The key finding is that architectures with more evenly distributed feature importance achieve better safety performance, showing how XAI can guide the development of trustworthy robotic manipulation systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HL-index: Fast Reachability Query in Hypergraphs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [db], [graph databases], [hypergraph, reachability query, s-reachability, HL-index, index construction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Peiting Xie, Xiangjun Zai, Yanping Wu, Xiaoyang Wang, Wenjie Zhang, Lu Qin</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of New South Wales, University of Technology Sydney</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23345" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23345</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the novel concept of s-reachability and the max-reachability query for hypergraphs, generalizing traditional reachability to model groupwise interactions. 2. Proposes the HL-index, a compact vertex-to-hyperedge index specifically designed to answer max-reachability queries efficiently. 3. Develops a fast covering relationship detection method and a lightweight neighbor-index to accelerate the construction of a minimal HL-index.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/319a455ca1c94672837d9f4e7ca6e0f1c6b652927ab50a3eaefdfd43f2b3cffc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of efficiently answering reachability queries in hypergraphs, which model complex group interactions. It proposes a new index structure called HL-index, along with optimization techniques for its construction, to solve the max-reachability query problem. Experiments on 20 datasets show the approach is efficient and scalable.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SoulX-LiveTalk Technical Report</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [Self-correcting Bidirectional Distillation, Multi-step Retrospective Self-Correction, hybrid sequence parallelism, Parallel VAE, kernel-level optimizations]</p>
</li>
<li class="">
<p><strong>authors:</strong> Le Shen, Qiao Qian, Tan Yu, Ke Zhou, Tianhang Yu, Yu Zhan, Zhenjie Wang, Ming Tao, Shunshun Yin, Siyuan Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Soul AI Lab, Donghua University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23379</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://soul-ailab.github.io/soulx-livetalk/" target="_blank" rel="noopener noreferrer" class="">https://soul-ailab.github.io/soulx-livetalk/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a Self-correcting Bidirectional Distillation strategy that retains bidirectional attention within video chunks to preserve spatiotemporal correlations and enhance visual fidelity. 2. Proposed a Multi-step Retrospective Self-Correction Mechanism to ensure stability during infinite generation by enabling autonomous recovery from accumulated errors. 3. Engineered a full-stack inference acceleration suite with hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations to achieve real-time performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d6b1bb994b3c3273da207d2f19494d99c1ff6bf6663f41b1d85b2f0c69b83bb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of deploying large diffusion models for real-time, audio-driven avatar generation by introducing SoulX-LiveTalk, a 14B-parameter framework. It employs a bidirectional distillation strategy and a self-correction mechanism to maintain high visual quality and stability, while a suite of inference optimizations enables sub-second latency and 32 FPS throughput, setting a new standard for interactive digital humans.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [gpu kernels], [kernel generation, multi-agent system, domain-specific languages (DSLs), performance tuning, Triton]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jinye Du, Quan Yuan, Zuyao Zhang, Yanzhi Yi, Jiahui Hu, Wangyi Chen, Yiyang Zhu, Qishui Zheng, Wenxiang Zou, Xiangyu Chang, Zuohe Zheng, Zichun Ye, Chao Liu, Shanni Li, Renwei Zhang, Yiping Deng, Xinwei Hu, Xuefeng Jin, Jie Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Huawei Technologies Co., Ltd., Hunan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23424" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23424</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed AKG kernel agent, a multi-agent framework that automates the generation, migration, and performance tuning of computational kernels for diverse hardware platforms. 2. Designed the system to support multiple Domain-Specific Languages (DSLs) like Triton, TileLang, CPP, and CUDA-C, enabling cross-platform portability and correctness. 3. Demonstrated the system&#x27;s effectiveness through evaluation on KernelBench, achieving an average 1.46x speedup over PyTorch Eager baselines on GPU and NPU backends.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40d5942348375e7b86203ab7a7420bba7105494296f349fdd48174b020a1527e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AKG kernel agent, a multi-agent framework that automates the development and optimization of high-performance computational kernels for modern AI workloads across diverse hardware. The system supports multiple DSLs for portability and uses LLMs for code generation and tuning. Evaluation shows it achieves a 1.46x average speedup over baseline implementations, effectively accelerating kernel development.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fuzzy-Logic and Deep Learning for Environmental Condition-Aware Road Surface Classification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [image classification], [convolutional neural networks, fuzzy logic, road surface classification, intelligent transport systems, data fusion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mustafa Demetgul, Sanja Lazarova Molnar</p>
</li>
<li class="">
<p><strong>institution:</strong> Karlsruhe Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23436</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a real-time system for road surface classification by fusing weather-conditional data and road condition data. 2. Compares the performance of multiple deep learning CNNs (AlexNet, LeNet, VGG, ResNet) on both image-based and acceleration-data-as-image classification tasks. 3. Introduces the use of fuzzy logic to classify road surfaces according to environmental factors like weather and time of day, using sensor data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d74437ab4a94c7ac8b2148bba4e1b6dd8d4706d55db8a2ae146a41ace94ef9f9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a real-time system for road surface condition monitoring. It employs deep learning CNNs to classify road types from images and acceleration data, achieving over 95% accuracy, and suggests using fuzzy logic to incorporate weather and time-of-day factors. The work aims to enhance vehicle safety and autonomous driving systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [motion generation], [flow matching, diffusion transformer (DiT), reinforcement learning from human feedback (RLHF)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao</p>
</li>
<li class="">
<p><strong>institution:</strong> Tencent Hunyuan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23464" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23464</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Tencent-Hunyuan/HY-Motion-1.0" target="_blank" rel="noopener noreferrer" class="">https://github.com/Tencent-Hunyuan/HY-Motion-1.0</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [hpc], [scientific computing], [kinetic-diffusion Monte Carlo, asymptotic-preserving, Boltzmann-BGK, error analysis, plasma simulation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhirui Tang, Julian Koellermeier, Emil Løvbak, Giovanni Samaey</p>
</li>
<li class="">
<p><strong>institution:</strong> KU Leuven, University of Groningen, Ghent University, Karlsruhe Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23580" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23580</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a comprehensive theoretical and numerical convergence analysis for the combined Kinetic-Diffusion Monte Carlo (KDMC) method and its associated fluid estimation scheme. 2. Proves theoretical upper bounds for the error of both the KDMC simulation and the fluid estimation technique. 3. Demonstrates through numerical experiments that the analyzed algorithm achieves lower error than a purely fluid-based method and significant speedup compared to a fully kinetic Monte Carlo reference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6302c36c316815b29f4097f7a2975625261d744e473d4e2098cfa440ddbd03df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6302c36c316815b29f4097f7a2975625261d744e473d4e2098cfa440ddbd03df_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes a combined Kinetic-Diffusion Monte Carlo (KDMC) method and fluid estimation scheme for simulating neutral particles in plasma edge physics, a computationally expensive problem for large fusion reactors. The work provides theoretical error bounds and numerical verification, showing the method is more accurate than fluid-based approaches and faster than fully kinetic Monte Carlo. The analysis confirms the effectiveness of this asymptotic-preserving approach for nuclear fusion applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Space AI: Leveraging Artificial Intelligence for Space to Improve Life on Earth</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [autonomous systems], [autonomous operations, mission planning, in-situ resource utilisation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ziyang Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22399" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22399</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes and defines &quot;Space AI&quot; as a unified interdisciplinary field at the intersection of AI and space science. 2. Consolidates historical and contemporary progress into a systematic four-context framework (AI on Earth, in Orbit, in Deep Space, for Multi-Planetary Life). 3. Identifies key application areas where AI advances can translate to societal benefits on Earth, such as in sensing, robotics, and trustworthy AI.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6ab175271eb74821199e8998bba499198a030f7f6b329c43a525f851b07aabe_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces &quot;Space AI&quot; as a new interdisciplinary field and proposes a systematic framework to organize its applications across four mission contexts, from Earth-based planning to multi-planetary life support. It argues that AI is critical for enabling autonomous and resilient space operations under extreme conditions, and that advances in this domain will also yield significant benefits for life on Earth.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [scheduling], [constraint programming, biased random-key genetic algorithm, makespan, exact delays, local search]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vítor A. Barbosa, Rafael A. Melo</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Computing, Universidade Federal da Bahia</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23150" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23150</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A Constraint Programming (CP) model for the single-machine coupled task scheduling problem with exact delays, utilizing well-established global constraints. 2. A novel Biased Random-Key Genetic Algorithm (BRKGA) that incorporates an efficient decoder, periodical restarts, shakes, and a local search algorithm for enhanced exploration. 3. An empirical evaluation demonstrating that the BRKGA provides high-quality solutions quickly, while the CP model with extended resources can find best-known solutions for a majority of benchmark instances.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f80cc4c12e23f8eb80b390efdd4a8b62ea37fb03c01008317951d1079c35c319_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the NP-hard single-machine coupled task scheduling problem with exact delays to minimize makespan. It proposes both a Constraint Programming model and a Biased Random-Key Genetic Algorithm (BRKGA) enhanced with local search and shake components. Computational results show the BRKGA finds good solutions quickly, while the CP model with more resources achieves state-of-the-art results on most benchmark instances.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-30T11:07:23.000Z" itemprop="dateModified">Dec 30, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/20251222-20251228"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251222-20251228</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/paper"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Paper</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-29" class="table-of-contents__link toc-highlight">2025-12-29</a></li><li><a href="#2025-12-30" class="table-of-contents__link toc-highlight">2025-12-30</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/20251229/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>