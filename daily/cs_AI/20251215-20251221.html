<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_AI/20251215-20251221" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251215-20251221 (cs.AI) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/cs_AI/20251215-20251221"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251215-20251221 (cs.AI) | AI头条"><meta data-rh="true" name="description" content="2025-12-18"><meta data-rh="true" property="og:description" content="2025-12-18"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/cs_AI/20251215-20251221"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cs_AI/20251215-20251221" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cs_AI/20251215-20251221" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.AI","item":"https://jokebear666.github.io/ai_toutiao/category/csai"},{"@type":"ListItem","position":3,"name":"20251215-20251221 (cs.AI)","item":"https://jokebear666.github.io/ai_toutiao/daily/cs_AI/20251215-20251221"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.cc04cc53.css">
<script src="/ai_toutiao/assets/js/runtime~main.25ffb784.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.d71a22b2.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/category/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Collapse sidebar category &#x27;cs.AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><span title="20251215-20251221 (cs.AI)" class="linkLabel_WmDU">20251215-20251221 (cs.AI)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads"><div class="content-main"><div class="content-inner"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/csai"><span>cs.AI</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251215-20251221 (cs.AI)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251215-20251221 (cs.AI)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-18">2025-12-18<a href="#2025-12-18" class="hash-link" aria-label="Direct link to 2025-12-18" title="Direct link to 2025-12-18" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251218] Promoting Fairness in Information Access within Social Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [social network analysis], [resistance distance, greedy algorithm, combinatorial optimization, NP-hard, linear-time algorithm]</li>
<li class=""><strong>authors:</strong> Changan Liu, Xiaotian Zhou, Ahad N. Zehmakan, Zhongzhi Zhang</li>
<li class=""><strong>institution:</strong> Fudan University, Australian National University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14711</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a method to enhance fairness in information access within social networks by adding new connections, formulated as an optimization problem using resistance distance. The main technical contribution is a linear-time algorithm that reduces the complexity of a greedy approach, enabling accurate solutions for large networks with millions of nodes.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Autonomous Source Knowledge Selection in Multi-Domain Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [domain adaptation], [multi-domain adaptation, density-driven selection, pseudo-label enhancement, feature alignment, self-supervision]</li>
<li class=""><strong>authors:</strong> Keqiuyin Li, Jie Lu, Hua Zuo, Guangquan Zhang</li>
<li class=""><strong>institution:</strong> University of Technology Sydney</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14710" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14710</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes AutoS, a method for unsupervised multi-domain adaptation that autonomously selects relevant source samples and models via a density-driven strategy and uses a pre-trained multimodal model to enhance pseudo-labels for self-supervision. Experiments show the method effectively improves transfer performance by focusing on the most transferable knowledge from multiple source domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Improving Underwater Acoustic Classification Through Learnable Gabor Filter Convolution and Attention Mechanisms</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [learnable Gabor filters, ResNeXt, squeeze-and-excitation attention, spectrograms, deep learning]</li>
<li class=""><strong>authors:</strong> Lucas Cesar Ferreira Domingos, Russell Brinkworth, Paulo Eduardo Santos, Karl Sammut</li>
<li class=""><strong>institution:</strong> Flinders University, PrioriAnalytica</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14714" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14714</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes GSE ResNeXt, a deep learning model that integrates learnable Gabor filter convolutions with a ResNeXt backbone and squeeze-and-excitation attention mechanisms for underwater acoustic target classification. The model demonstrates improved classification accuracy and a 28% reduction in training time compared to baseline models, highlighting the effectiveness of combining adaptive signal processing with attention for better generalization in data-limited scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Tourists Profiling by Interest Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [data mining], [graph models, community detection, geo-located data, social network analysis, digital traces]</li>
<li class=""><strong>authors:</strong> Sonia Djebali, Quentin Gabot, Guillaume Guerard</li>
<li class=""><strong>institution:</strong> Léonard De Vinci, Research Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14704" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14704</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that uses both qualitative and quantitative analysis of digital traces from social networks to profile tourists. It employs graph models and community detection techniques to analyze geo-located data and understand tourist behavior dynamics within attraction networks. The main conclusion is that this combined approach provides a deeper understanding of tourist interests and movement patterns compared to purely quantitative studies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [neural architecture search, large language models, image captioning, prompt engineering, CNN encoder, LSTM, GRU, Transformer, BLEU-4]</li>
<li class=""><strong>authors:</strong> Krunal Jesani, Dmitry Ignatov, Radu Timofte</li>
<li class=""><strong>institution:</strong> University of Würzburg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14706" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14706</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents NN-Caption, a pipeline that uses a large language model (LLM) to automatically generate runnable image-captioning model architectures by composing CNN encoders and sequence decoders under a strict API. The method successfully produced dozens of models, with over half training successfully, demonstrating the promise of LLM-guided neural architecture search while highlighting challenges like code hallucinations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [neural-symbolic AI], [Vector Symbolic Architecture, self-attention, binding, unbinding, residual streams, hyperdimensional computing, chain-of-thought]</li>
<li class=""><strong>authors:</strong> Sahil Rajesh Dhayalkar</li>
<li class=""><strong>institution:</strong> Arizona State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14709</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper interprets transformer self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA), where attention performs soft binding/unbinding of roles and fillers. It uses this perspective to explain the models&#x27; reasoning capabilities and brittleness, and proposes VSA-inspired architectural modifications to improve logical reliability. The core conclusion is that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and robust reasoning systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [Mixture-of-Experts (MoE), Hierarchical Gated Attention Network, CatBoost meta-learner, multimodal fusion, deep fusion, expert stacking, Quad-Modal Ensemble]</li>
<li class=""><strong>authors:</strong> Ryan Cartularo</li>
<li class=""><strong>institution:</strong> The University of Texas at Austin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14712" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14712</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper compares two multimodal AI architectures for sepsis prediction and antibiotic selection: a complex end-to-end deep fusion model (SepsisFusionFormer) and a leaner, context-aware Mixture-of-Experts stacking model (SepsisLateFusion). The main conclusion is that for this high-stakes, data-sparse clinical domain, the interpretable expert stacking approach, which treats modalities as orthogonal experts and uses a CatBoost meta-learner, significantly outperformed the deep fusion model, achieving state-of-the-art predictive performance and enabling a prescriptive window for intervention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [bit-level fault injection, gradient-based sensitivity estimation, differentiable fault analysis, semantic steering, SBERT embeddings, perplexity scoring]</li>
<li class=""><strong>authors:</strong> Zafaryab Haider, Md Hafizur Rahman, Shane Moeykens, Vijay Devabhaktuni, Prabuddha Chakraborty</li>
<li class=""><strong>institution:</strong> University of Maine, Illinois State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14715" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14715</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces BLADE, a differentiable fault analysis framework that uses gradient-based sensitivity estimation to identify and flip specific bits in a quantized vision-language model&#x27;s weights, steering its generated captions to change semantic meaning while preserving grammatical fluency. It concludes that semantic drift from low-level bit flips is predictable and controllable, revealing vulnerabilities in generative AI systems and opening pathways for robustness testing and adversarial defense.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Hybrid Attribution Priors for Explainable and Robust Model Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [explainable ai], [class-aware attribution prior, explanation-guided learning, attribution priors, small language models, model interpretability]</li>
<li class=""><strong>authors:</strong> Zhuoran Zhang, Feng Zhang, Shangyuan Li, Yang Shi, Yuanxing Zhang, Wei Chen, Tengjiao Wang, Kam-Fai Wong</li>
<li class=""><strong>institution:</strong> Peking University, Kling Team, CUHK</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14719" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14719</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Class-Aware Attribution Prior (CAP) framework and its hybrid variant, CAP Hybrid, to generate more discriminative attribution priors for training small language models. By aligning a model&#x27;s self-attribution with these enriched priors, the method encourages the learning of diverse, decision-relevant features. Experiments show the approach consistently enhances both model interpretability and robustness across various data settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [time series forecasting], [spectral entropy, dependency evaluator, signed graph constructor, context spatial extractor, channel independence, channel dependence]</li>
<li class=""><strong>authors:</strong> Feng Xiong, Zongxia Xie, Yanru Sun, Haoyu Wang, Jianhong Lin</li>
<li class=""><strong>institution:</strong> Tianjin University, Fudan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14718" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14718</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes SEED, a framework for multivariate time series forecasting that uses spectral entropy to evaluate and model spatial-temporal dependencies. It introduces components like a Dependency Evaluator and a Signed Graph Constructor to adaptively balance modeling strategies and preserve negative correlations. Experiments on 12 datasets show SEED achieves state-of-the-art performance, demonstrating its effectiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Generative Urban Flow Modeling: From Geometry to Airflow with Graph Diffusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [graph neural network, diffusion model, generative modeling, unstructured meshes, urban flow simulation, score-based diffusion]</li>
<li class=""><strong>authors:</strong> Francisco Giral, Álvaro Manzano, Ignacio Gómez, Petros Koumoutsakos, Soledad Le Clainche</li>
<li class=""><strong>institution:</strong> Universidad Politécnica de Madrid, Harvard University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14725" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14725</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a generative diffusion framework that combines a hierarchical graph neural network with score-based diffusion modeling to synthesize steady-state urban wind fields from geometry data on unstructured meshes. The model generalizes to unseen geometries, accurately capturing key flow structures like wakes and recirculation zones, and provides uncertainty-aware predictions. This work represents a step towards foundation models for the built environment, enabling rapid evaluation of urban design decisions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical attention transformers, curriculum learning, groebner bases, polynomial systems, computational cost analysis]</li>
<li class=""><strong>authors:</strong> Mohamed Malhou, Ludovic Perret, Kristin Lauter</li>
<li class=""><strong>institution:</strong> Meta Superintelligence Labs (FAIR), Sorbonne Université, CNRS, LIP6, EPITA, EPITA Research Lab (LRE)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces HATSolver, a method that improves upon prior transformer-based approaches by using Hierarchical Attention Transformers (HATs) to compute Gröbner bases for solving systems of multivariate polynomial equations. The HAT architecture incorporates a tree-structured inductive bias to model hierarchical data relationships, achieving significant computational savings over flat attention models. Combined with curriculum learning, the method can solve much larger problem instances than previous work.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [Quantum Decision Transformer, Quantum-Inspired Attention, Quantum Feedforward Networks, entanglement, interference, offline reinforcement learning, Decision Transformer]</li>
<li class=""><strong>authors:</strong> Abraham Itzhak Weinberg</li>
<li class=""><strong>institution:</strong> AI-WEINBERG, AI Experts</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14726</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Quantum Decision Transformer (QDT), a novel architecture that integrates quantum-inspired attention with entanglement and quantum feedforward networks with interference to improve offline reinforcement learning. It demonstrates a dramatic performance improvement over standard Decision Transformers and shows that the synergy between its quantum-inspired components is crucial for its success.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SoMe: A Realistic Benchmark for LLM-based Social Media Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [SoMe benchmark, social media agents, LLM-based agents, agent tools, task evaluation, quantitative analysis, qualitative analysis]</li>
<li class=""><strong>authors:</strong> Dizhan Xue, Jing Cui, Shengsheng Qian, Chuanrui Hu, Changsheng Xu</li>
<li class=""><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tianjin University of Technology; Nanjing University of Posts and Telecommunications; Peng Cheng Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14720</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SoMe, a comprehensive benchmark for evaluating LLM-based social media agents across diverse tasks using real social media data and agent tools. The evaluation shows that current LLMs, both closed and open-source, perform unsatisfactorily on these realistic social media agent tasks. SoMe serves as a challenging testbed to advance future social media agent development.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical machine learning], [conformal prediction, uncertainty quantification, finite sample theory, calibration]</li>
<li class=""><strong>authors:</strong> Klaus-Rudolf Kladny, Bernhard Schölkopf, Lisa Koch, Christian F. Baumgartner, Michael Muehlebach</li>
<li class=""><strong>institution:</strong> Max Planck Institute for Intelligent Systems, University of Bern, University of Tübingen, University of Lucerne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14727" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14727</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper critically examines conformal prediction, a method for providing statistically guaranteed uncertainty estimates from machine learning models using a calibration dataset. It argues that while the theoretical guarantees hold for any calibration set size, the practical utility of these guarantees is highly dependent on having a sufficiently large calibration sample. This critique is particularly relevant for medical applications where data is often scarce, and the authors support their argument with an empirical demonstration on a medical image classification task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [planner-executor framework, large language models (LLMs), vision-language models (VLMs), segmentation models, image processing]</li>
<li class=""><strong>authors:</strong> Idan Tankel, Nir Mazor, Rafi Brada, Christina LeBedis, Guy ben-Yosef</li>
<li class=""><strong>institution:</strong> GE Healthcare Technology and Innovation Center, Boston Medical Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14732</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework that uses a planner-executor approach, where an LLM planner generates Python scripts to automate the detection and reporting of incidental findings in abdominal CT scans, and an executor runs these scripts using VLMs and segmentation models. The method is fully automatic and end-to-end. The results show that this framework outperforms pure VLM-based approaches in accuracy and efficiency for managing incidental findings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Semantic Geometry for policy-constrained interpretation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [semantic interpretation], [geometric framework, spherical convex regions, constrained optimization, policy constraints, information theory, Bayesian inference, sheaf-theoretic semantics]</li>
<li class=""><strong>authors:</strong> Nikit Phadke</li>
<li class=""><strong>institution:</strong> Independent researcher (based on gmail address)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14731" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14731</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a geometric framework for semantic interpretation where meaning is represented as directions on a unit sphere and policy constraints are applied as explicit priors. This approach separates evidence processing from policy rules, enabling provable prevention of hallucinated commitments. Empirical validation on financial data shows zero hallucinated approvals, demonstrating the method&#x27;s effectiveness in high-stakes, policy-constrained domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Zero-Knowledge Audit for Internet of Agents: Privacy-Preserving Communication Verification with Model Context Protocol</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [zero-knowledge proof, Model Context Protocol, privacy-preserving audit, Circom, mutual auditing]</li>
<li class=""><strong>authors:</strong> Guanlin Jing, Huayi Qi</li>
<li class=""><strong>institution:</strong> Beijing University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14737</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a framework that integrates zero-knowledge proofs with the Model Context Protocol (MCP) to enable verifiable, privacy-preserving audits of agent communications without revealing message content. It achieves mutual auditing for compliance and billing while maintaining data authenticity and privacy with negligible latency overhead. The authors implement the system, claiming it is the first to offer such verifiable mutual auditing for agent communications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Quantum-Augmented AI/ML for O-RAN: Hierarchical Threat Detection with Synergistic Intelligence and Interpretability (Technical Report)</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [quantum machine learning, hybrid quantum computing, amplitude encoding, entanglement encoding, hierarchical threat detection, anomaly detection, intrusion confirmation, multiattack classification, deep neural networks, ensemble classifiers]</li>
<li class=""><strong>authors:</strong> Tan Le, Van Le, Sachin Shetty</li>
<li class=""><strong>institution:</strong> Hampton University, Virginia Polytechnic Institute and State University, Old Dominion University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14742" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14742</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hierarchical cybersecurity framework for Open Radio Access Networks (O-RAN) that integrates hybrid quantum computing and machine learning. The method uses quantum-inspired feature encodings (amplitude- and entanglement-based) with deep and ensemble classifiers for anomaly detection, intrusion confirmation, and multiattack classification. The framework demonstrates near-perfect accuracy, high recall, and strong interpretability, indicating readiness for scalable deployment in O-RAN environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Persistent Backdoor Attacks under Continual Fine-Tuning of LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [backdoor attack, continual fine-tuning, gradient alignment, P-Trojan, persistence]</li>
<li class=""><strong>authors:</strong> Jing Cui, Yufei Han, Jianbin Jiao, Junge Zhang</li>
<li class=""><strong>institution:</strong> University of Chinese Academy of Sciences, INRIA, Institute of Automation, Chinese Academy of Sciences</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14741" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14741</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes P-Trojan, a backdoor attack method that optimizes for persistence by aligning poisoned gradients with clean task gradients on token embeddings during model poisoning. Experiments show it maintains over 99% backdoor persistence across continual fine-tuning updates on models like Qwen2.5 and LLaMA3 without harming clean-task accuracy. This highlights the need for stronger defenses and persistence-aware evaluation in real-world LLM adaptation pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Factor(U,T): Controlling Untrusted AI by Monitoring their Plans</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [ai safety], [factored cognition, control protocols, task decomposition, untrusted decomposer, monitoring, BigCodeBench, AUROC]</li>
<li class=""><strong>authors:</strong> Edward Lue Chee Lip, Anthony Channg, Diana Kim, Aaron Sandoval, Kevin Zhu</li>
<li class=""><strong>institution:</strong> Algoverse AI Research, Colorado State University, Orange Coast College</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14745</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Factor(U,T), a protocol where an untrusted, potentially malicious AI model decomposes a complex task into subtasks, which are then implemented by trusted models. It finds that monitoring only the natural language decomposition plans is ineffective for detecting attacks, whereas monitoring the concrete code solutions of the subtasks provides strong safety and discrimination. The main conclusion is that implementation-context monitoring is crucial for safety when using untrusted models for task decomposition.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] CODE ACROSTIC: Robust Watermarking for Code Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [watermarking, cue list, low-entropy, high-entropy, comment removal attack]</li>
<li class=""><strong>authors:</strong> Li Lin, Siyuan Xin, Yang Cao, Xiaochun Cao</li>
<li class=""><strong>institution:</strong> Institute of Science Tokyo, Shanghai University, Sun Yat-sen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14753" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14753</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a robust watermarking method for LLM-generated code that uses a Cue List to distinguish between low and high-entropy parts of the code for targeted watermark injection. It addresses the vulnerability of existing methods to comment removal attacks. The evaluation shows the method achieves higher detectability and usability compared to state-of-the-art techniques.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Cyberswarm: a novel swarm intelligence algorithm inspired by cyber community dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [recommendation systems], [swarm intelligence, dynamic hypergraph, centrality-based feature extraction, Node2Vec embeddings, message-passing mechanisms, hierarchical graph modeling]</li>
<li class=""><strong>authors:</strong> Abdelsadeq Elfergany, Ammar Adl, Mohammed Kayed</li>
<li class=""><strong>institution:</strong> Not specified in provided text</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14752" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14752</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Cyberswarm, a general-purpose swarm intelligence algorithm for recommendation systems that models user preferences and community influences using a dynamic hypergraph structure with techniques like Node2Vec and message-passing. Experimental results show it outperforms baseline methods on metrics like HR, MRR, and NDCG across various tasks. The work demonstrates the effectiveness of integrating swarm intelligence with network dynamics for adaptive and precise recommendations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] One Leak Away: How Pretrained Model Exposure Amplifies Jailbreak Risks in Finetuned LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [jailbreak attack, adversarial prompt, representation-level probing, linear separability, Probe-Guided Projection (PGP), transferability, finetuning, pretrained model]</li>
<li class=""><strong>authors:</strong> Yixin Tan, Zhe Yu, Jun Sakuma</li>
<li class=""><strong>institution:</strong> Institute of Science Tokyo, Riken AIP</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14751" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14751</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates how jailbreak vulnerabilities transfer from pretrained to finetuned LLMs. It introduces the Probe-Guided Projection (PGP) attack, which uses representation-level probing to guide adversarial prompt optimization for better transferability. The main conclusion is that the pretrain-finetune paradigm inherently amplifies security risks, as vulnerabilities encoded in the pretrained model&#x27;s representations are inherited by its finetuned variants.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Revisiting the Reliability of Language Models in Instruction-Following</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [llm evaluation], [instruction-following, reliability, data augmentation, benchmark, IFEval++, reliable@k]</li>
<li class=""><strong>authors:</strong> Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu</li>
<li class=""><strong>institution:</strong> Tsinghua University, Ant Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14754" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14754</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate &quot;cousin prompts&quot; for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] CAPE: Capability Achievement via Policy Execution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [capability engineering, policy execution, specification language, verification, DPO, contextual objectivity, verification-fidelity scaling]</li>
<li class=""><strong>authors:</strong> David Ball</li>
<li class=""><strong>institution:</strong> Superficial Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14761" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14761</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces CAPE, a protocol for Capability Engineering that implements a Specify-&gt;Verify-&gt;Correct-&gt;Train loop to convert requirements into executable specifications and train models to satisfy them by default. It demonstrates that CAPE reduces policy violation rates by 81% compared to DPO and significantly lowers costs and development timelines by using reusable specifications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Guided Discrete Diffusion for Constraint Satisfaction Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [generative models], [discrete diffusion, unsupervised learning, constraint satisfaction, sudoku]</li>
<li class=""><strong>authors:</strong> Justin Jung</li>
<li class=""><strong>institution:</strong> unknown</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14765" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14765</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an unsupervised discrete diffusion model to learn the distribution of Sudoku puzzles, aiming to capture their structural patterns. The method avoids the need for supervised datasets and directly handles the discrete nature of the constraint satisfaction problem. The authors demonstrate its capability to solve Sudoku puzzles without supervision.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Workflows vs Agents for Code Translation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Model Context Protocol (MCP), syntax repair, code translation, MATLAB-to-HDL, agentic framework, conditional retrieval]</li>
<li class=""><strong>authors:</strong> Henry Gray, Tom Yotam, Octavian Udrea</li>
<li class=""><strong>institution:</strong> Code Metal</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14762" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14762</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper compares two LLM-driven methods for syntax repair in a MATLAB-to-hardware-description-language translation pipeline: a fixed expert-designed workflow and a more autonomous agentic approach using the Model Context Protocol (MCP). The agentic approach, which dynamically selects tools, was more effective at resolving syntax errors, especially for small and mid-sized models, leading to significant downstream improvements in simulation success rates.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [self-reflection, cross-model verification, dual-assessment, uncertainty estimation, selective prediction, hallucination mitigation]</li>
<li class=""><strong>authors:</strong> Xixian Wu, Yang Ou, Pengchao Tian, Zian Yang, Jielei Zhang, Peiyi Li, Longwen Gao</li>
<li class=""><strong>institution:</strong> Bilibili Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14770" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14770</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes DAVR, a framework that enhances VQA reliability by combining a model&#x27;s self-assessment of its answer confidence with cross-verification using external models to reduce hallucinations. It achieved top results in a reliability challenge, demonstrating its effectiveness in improving the trustworthiness of vision-language model responses.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge graph reasoning], [GR-Agent, adaptive graph reasoning, incomplete knowledge graphs, agent environment interaction, reasoning paths]</li>
<li class=""><strong>authors:</strong> Dongzhuoran Zhou, Yuqicheng Zhu, Xiaxia Wang, Hongkuan Zhou, Jiaoyan Chen, Steffen Staab, Yuan He, Evgeny Kharlamov</li>
<li class=""><strong>institution:</strong> University of Oslo, Bosch Center for AI, University of Stuttgart, University of Oxford, Amazon, The University of Manchester, University of Southampton</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14766" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14766</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces GR-Agent, an adaptive graph reasoning agent that formalizes knowledge graph question answering as agent-environment interaction to handle incomplete knowledge graphs by using graph reasoning tools and memory of evidence. It demonstrates that existing methods degrade under incompleteness, while GR-Agent outperforms non-training baselines and matches training-based methods in both complete and incomplete settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Privacy-Preserving Feature Valuation in Vertical Federated Learning Using Shapley-CMI and PSI Permutation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Shapley-CMI, Private Set Intersection, Conditional Mutual Information, Vertical Federated Learning, data valuation]</li>
<li class=""><strong>authors:</strong> Unai Laskurain, Aitor Aguirre-Ortuzar, Urko Zurutuza</li>
<li class=""><strong>institution:</strong> Mondragon Unibertsitatea</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14767" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14767</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a privacy-preserving method for evaluating feature contributions in Vertical Federated Learning (VFL) using Shapley-CMI and a Private Set Intersection (PSI) server to compute encrypted intersection sizes without sharing raw data. The system enables secure and fair data valuation before model training. Initial experiments confirm the approach&#x27;s correctness and privacy, demonstrating its viability for secure feature contribution estimation in VFL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Incentives or Ontology? A Structural Rebuttal to OpenAI&#x27;s Hallucination Thesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [large language models], [transformer architecture, structural hallucination, Licensing Oracle, hybrid systems, statistical ontology]</li>
<li class=""><strong>authors:</strong> Richard Ackermann, Simeon Emanuilov</li>
<li class=""><strong>institution:</strong> RA Software, Sofia University “St. Kliment Ohridski”</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14801" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14801</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper argues that hallucination in LLMs is an architectural inevitability of transformers, which model token co-occurrence rather than the world, and demonstrates through a Licensing Oracle that external truth-validation modules are required for reliable abstention. It concludes that hallucination is a structural property, not a correctable incentive problem, necessitating hybrid systems to separate linguistic fluency from epistemic responsibility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Retrieval-Augmented Generation (RAG), Graph RAG, knowledge injection, error taxonomy, Terraform, IaC-Eval benchmark]</li>
<li class=""><strong>authors:</strong> Roman Nekrasov, Stefano Fossati, Indika Kumara, Damian Andrew Tamburri, Willem-Jan van den Heuvel</li>
<li class=""><strong>institution:</strong> Jheronimus Academy of Data Science, Tilburg University, Eindhoven University of Technology, University of Sannio</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14792" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14792</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates improving Large Language Model (LLM) generation of Infrastructure as Code (IaC) by injecting structured configuration knowledge using techniques from naive to Graph RAG. The study finds that while knowledge injection significantly boosts technical correctness, LLMs still struggle with nuanced user intent, revealing a &quot;Correctness-Congruence Gap&quot; where they are better coders than architects.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Sharing State Between Prompts and Programs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [natural language programming, shared program state, natural function interface, interoperability, Nightjar]</li>
<li class=""><strong>authors:</strong> Ellie Y. Cheng, Logan Weber, Tian Jin, Michael Carbin</li>
<li class=""><strong>institution:</strong> MIT CSAIL</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14805" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14805</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a programming abstraction called &quot;shared program state&quot; to enable seamless interoperability between natural language code (prompts) and formal program code (e.g., Python). It implements this abstraction in the Nightjar system, allowing natural code to directly read and write program variables. The results show that Nightjar programs can achieve higher task accuracy (+4-19%) and reduce lines of code by 39.6% on average, though with a runtime overhead of 0.4-4.3x compared to manual implementations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Let the Barbarians In: How AI Can Accelerate Systems Performance Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [AI-Driven Research for Systems (ADRS), OpenEvolve, GEPA, ShinkaEvolve, multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling]</li>
<li class=""><strong>authors:</strong> Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Shubham Agarwal, Mert Cemri, Bowen Wang, Alexander Krentsel, Tian Xia, Jongseok Park, Shuo Yang, Jeff Chen, Lakshya Agrawal, Ashwin Naren, Shulu Li, Ruiying Ma, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica</li>
<li class=""><strong>institution:</strong> UC Berkeley</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14806" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14806</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AI-Driven Research for Systems (ADRS), a method using AI to automate the generation, evaluation, and refinement of performance-optimizing algorithms for computer systems. Through case studies with frameworks like OpenEvolve, it demonstrates that ADRS can produce solutions matching or surpassing human-designed state-of-the-art. The work outlines best practices for applying ADRS and discusses its potential to shift researcher effort toward problem formulation and strategic oversight.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [multi-agent system, secure communication layer, ontology-aligned messaging, MITRE ATT&amp;CK, Lightweight Random Forest]</li>
<li class=""><strong>authors:</strong> Arth Bhardwaj, Sia Godika, Yuvam Loonker</li>
<li class=""><strong>institution:</strong> Saint Francis High School, Massachusetts Institute of Technology, JBCN International School</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14846" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14846</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes MALCDF, a real-time cyber defense framework where four specialized LLM agents (Detection, Intelligence, Response, Analysis) collaborate via a secure communication layer. It demonstrates that this multi-agent approach with encrypted, ontology-aligned messaging outperforms a lightweight ML baseline and a single-LLM setup in detection accuracy and F1-score on a test stream. The conclusion is that coordinating simple LLM agents improves practical, real-time cyber defense.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Penetration Testing of Agentic AI: A Comparative Security Analysis Across Models and Frameworks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [penetration testing, prompt injection, agentic ai, autogen, crewai, ssrf, sql injection]</li>
<li class=""><strong>authors:</strong> Viet K. Nguyen, Mohammad I. Husain</li>
<li class=""><strong>institution:</strong> Cal Poly Pomona</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14860" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14860</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts systematic penetration testing on agentic AI systems, comparing five LLM models across two frameworks using 13 attack scenarios. It finds significant security vulnerabilities, with over half of malicious prompts succeeding, and identifies novel defensive patterns like &quot;hallucinated compliance&quot;.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] A Roadmap for Applying Graph Neural Networks to Numerical Data: Insights from Cementitious Materials</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [graph neural network, k-nearest neighbor, random forest, hyperparameter optimization, feature selection]</li>
<li class=""><strong>authors:</strong> Mahmuda Sharmin, Taihao Han, Jie Huang, Narayanan Neithalath, Gaurav Sant, Aditya Kumar</li>
<li class=""><strong>institution:</strong> Missouri University of Science and Technology, Arizona State University, University of California, Los Angeles</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14855" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14855</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method for applying Graph Neural Networks (GNNs) to numerical data in cementitious materials research by converting tabular data into graph representations using the k-nearest neighbor approach. The study systematically optimizes model hyperparameters and feature selection, finding that the GNN&#x27;s performance is comparable to a benchmark random forest model. The work establishes a foundational roadmap for transitioning to advanced, multi-modal, and physics-informed AI architectures for material design.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [machine learning theory], [Bregman projection, entropy reservoir, information geometry, model collapse, self-referential learning]</li>
<li class=""><strong>authors:</strong> Jingwei Chen</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14879" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14879</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Entropy-Reservoir Bregman Projection (ERBP) framework, which models self-referential learning as a stochastic Bregman projection sequence in distribution space. It shows that injecting an entropy reservoir stabilizes the dynamics and prevents model collapse, unifying various empirical fixes into a single quantitative design rule.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [online learning], [weighted average, exponential weighted moving average, online linear regression, pseudo-inverse, coefficient of determination]</li>
<li class=""><strong>authors:</strong> Mohammad Abu-Shaira, Alejandro Rodriguez, Greg Speegle, Victor Sheng, Ishfaq Ahmad</li>
<li class=""><strong>institution:</strong> Baylor University, Texas Tech University, University of Texas at Arlington</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14892</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces OLR-WA, a novel multivariate online linear regression model based on a weighted average approach. It demonstrates rapid convergence and performance comparable to batch regression, while uniquely handling both temporal drift and confidence-based data scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language models, knowledge graphs, viewpoint classification, fine-tuning, wikidata, semantic enrichment]</li>
<li class=""><strong>authors:</strong> Massimiliano Fadda, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino</li>
<li class=""><strong>institution:</strong> University of Cagliari, The Open University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14887" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14887</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper improves a pipeline for analyzing political viewpoints in news by fine-tuning Large Language Models for classification and enriching claim representations with semantic actor descriptions from Wikidata. The integrated approach, evaluated on UK immigration debate data, shows that combining fine-tuned LLMs with knowledge graph context yields the best performance, particularly with models capable of processing long inputs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, structured drug knowledge, pharmacy question-answering, external knowledge integration]</li>
<li class=""><strong>authors:</strong> Houman Kazemzadeh, Kiarash Mokhtari Dizaji, Seyed Reza Tavakoli, Farbod Davoodi, MohammadReza KarimiNejad, Parham Abed Azad, Ali Sabzi, Armin Khosravi, Siavash Ahmadi, Mohammad Hossein Rohban, Glolamali Aminian, Tahereh Javaheri</li>
<li class=""><strong>institution:</strong> Tehran University of Medical Sciences, Sharif University of Technology, Amir Kabir University of Technology, Missouri University of Science and Technology, The Alan Turing Institute, Boston University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14896" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14896</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces DrugRAG, a three-step retrieval-augmented generation pipeline that integrates external structured drug knowledge into LLM prompts to improve accuracy on pharmacy QA tasks. It demonstrates that this external method enhances performance across multiple models without modifying their architecture, providing a practical approach for evidence-based AI in pharmacy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers&#x27; Enquiries Globally</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reasoning, chain-of-responsibility, modular architecture, governance mechanisms, multilingual interactions, real-time tools]</li>
<li class=""><strong>authors:</strong> Nadine Angela Cantonjos, Arpita Biswas</li>
<li class=""><strong>institution:</strong> Rutgers University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14910</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents AgroAskAI, a multi-agent AI framework designed to support smallholder farmers with climate adaptation queries. It uses a modular, role-specialized architecture coordinated via a chain-of-responsibility approach, integrating real-time data and multilingual support. The experimental results show that this system delivers more actionable and grounded outputs for agricultural decision support.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [imitation learning], [on-policy expert corrections, DAgger, covariate shift, rejection sampling, supervised fine-tuning, multi-turn agents]</li>
<li class=""><strong>authors:</strong> Niklas Lauffer, Xiang Deng, Srivatsa Kundurthy, Brad Kenstler, Jeff Da</li>
<li class=""><strong>institution:</strong> UC Berkeley, Cornell University, Scale AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14895" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14895</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel data generation method called on-policy expert corrections (OECs) to address covariate shift in imitation learning for multi-turn language model agents. The method generates partially on-policy data by starting rollouts with a student model and switching to an expert model mid-trajectory. Experiments on software engineering tasks show OECs yield a 13-14% improvement over traditional imitation learning, demonstrating the need to combine expert demonstrations with on-policy data for effective agent training.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [LoRA, dataset translation, visual question answering, instruction tuning, parameter-efficient fine-tuning]</li>
<li class=""><strong>authors:</strong> George-Andrei Dima, Dumitru-Clementin Cercel</li>
<li class=""><strong>institution:</strong> National University of Science and Technology POLITEHNICA Bucharest</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14926" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14926</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a parameter-efficient method for adapting vision-language models to Romanian by translating the Flickr30k dataset and generating QA pairs, then fine-tuning models like LLaMA, LLaVA, and Qwen2 using LoRA. The results show significant improvements in Romanian visual QA and image captioning, with the Qwen2-VL-RoVQA model achieving the best performance and reduced grammatical errors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Improving Pre-trained Segmentation Models using Post-Processing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [adaptive post-processing, glioma segmentation, brain MRI, BraTS challenge, resource-aware AI]</li>
<li class=""><strong>authors:</strong> Abhijeet Parida, Daniel Capellán-Martín, Zhifan Jiang, Nishad Kulkarni, Krithika Iyer, Austin Tapp, Syed Muhammad Anwar, María J. Ledesma-Carbayo, Marius George Linguraru</li>
<li class=""><strong>institution:</strong> Children&#x27;s National Hospital, Universidad Politécnica de Madrid, George Washington University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14937" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14937</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes adaptive post-processing techniques to refine the segmentation outputs of large-scale pre-trained models for brain tumor (glioma) segmentation in MRI, addressing systematic errors like false positives. The method was validated in BraTS 2025 challenges, showing significant metric improvements. The work advocates for a shift from complex model architectures to efficient, clinically aligned post-processing for more precise and sustainable medical image analysis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [diffusion transformer, video VAE, sliding window mechanism, motion-frame context, latent noise injection, MLLM director]</li>
<li class=""><strong>authors:</strong> Zhenzhi Wang, Jian Wang, Ke Ma, Dahua Lin, Bing Zhou</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Snap Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14938" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14938</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces TalkVerse, a large-scale open dataset for audio-driven video generation, and a reproducible 5B Diffusion Transformer baseline model. The model uses a video VAE with a high downsampling ratio and a sliding window mechanism to enable minute-long video generation with low drift and lower inference cost. The main conclusion is that this open resource and efficient model democratize research in this field by enabling fair comparisons and reducing computational barriers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV-cache management, lossy compression, adaptive eviction, utility function, multi-tier storage]</li>
<li class=""><strong>authors:</strong> Shaoting Feng, Yuhan Liu, Hanchen Li, Xiaokun Chen, Samuel Shen, Kuntai Du, Zhuohan Gu, Rui Zhang, Yuyang Huang, Yihua Cheng, Jiayi Yao, Qizheng Zhang, Ganesh Ananthanarayanan, Junchen Jiang</li>
<li class=""><strong>institution:</strong> University of Chicago, UC Berkeley, Tensormesh, Inc., MIT, UC Santa Cruz, Stanford, Microsoft</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14946" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14946</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EVICPRESS is a KV-cache management system that jointly optimizes lossy compression and adaptive eviction across multiple storage tiers using a unified utility function. It improves LLM inference efficiency by maximizing fast-tier cache hit rates while preserving generation quality through context-aware compression. Evaluations show it achieves up to 2.19x faster time-to-first-token at equivalent quality compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Prompt Repetition Improves Non-Reasoning LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prompt repetition, causal language model, attention mechanism, non-reasoning tasks]</li>
<li class=""><strong>authors:</strong> Yaniv Leviathan, Matan Kalman, Yossi Matias</li>
<li class=""><strong>institution:</strong> Google Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14982" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14982</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a simple method of repeating the input prompt to improve the performance of LLMs on non-reasoning tasks. This technique allows all prompt tokens to attend to each other within the causal attention mechanism, addressing order sensitivity. The authors demonstrate that this method boosts accuracy for models like Gemini, GPT, Claude, and Deepseek without increasing output length or latency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [multimodal reasoning, chain-of-thought prompting, ablation studies, occlusion-based interpretability, benchmark evaluation, modality fusion]</li>
<li class=""><strong>authors:</strong> Yiming Cui, Xin Yao, Yuxuan Qin, Xin Li, Shijin Wang, Guoping Hu</li>
<li class=""><strong>institution:</strong> State Key Laboratory of Cognitive Intelligence, iFLYTEK AI Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14989" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14989</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates 40 multimodal large language models on a benchmark of chemistry Olympiad questions requiring visual and textual reasoning. The core method involves using chain-of-thought prompting and interpretability techniques like ablation and occlusion. The main conclusion is that current models struggle with modality fusion, but chain-of-thought improves both accuracy and visual grounding, revealing critical limitations in scientific reasoning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Where is the Watermark? Interpretable Watermark Detection at the Block Level</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [image watermarking], [discrete wavelet transform, block-wise embedding, detection maps, post-hoc watermarking]</li>
<li class=""><strong>authors:</strong> Maria Bulychev, Neil G. Marchant, Benjamin I. P. Rubinstein</li>
<li class=""><strong>institution:</strong> University of Melbourne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14994" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14994</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an interpretable, post-hoc image watermarking method that embeds signals in the discrete wavelet transform domain using a statistical block-wise strategy. It generates detection maps to show which specific regions of an image are watermarked or altered. The method maintains strong robustness against common image transformations and high imperceptibility while providing more interpretable detection than prior approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [bug reproduction, LLM, iterative generate-validate-refine, agentic AI]</li>
<li class=""><strong>authors:</strong> Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh</li>
<li class=""><strong>institution:</strong> Dalhousie University, Polytechnique Montreal</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14990" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14990</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents RepGen, an automated approach that uses an LLM-based intelligent agent to reproduce deep learning bugs by constructing a learning-enhanced context and employing an iterative generate-validate-refine mechanism. It achieves an 80.19% reproduction rate on real-world bugs, significantly outperforming the state-of-the-art, and a developer study confirms it improves success rates and reduces time and cognitive load for bug reproduction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Beyond Proximity: A Keypoint-Trajectory Framework for Classifying Affiliative and Agonistic Social Networks in Dairy Cattle</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [YOLOv11, ByteTrack, ZebraPose, support vector machine, keypoint trajectories, pose estimation]</li>
<li class=""><strong>authors:</strong> Sibi Parivendan, Kashfia Sailunaz, Suresh Neethirajan</li>
<li class=""><strong>institution:</strong> Dalhousie University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14998" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14998</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a computer vision framework that uses pose estimation and keypoint trajectories to classify social interactions in dairy cattle, moving beyond simple proximity measures. The method integrates object detection, tracking, and a support vector machine to distinguish affiliative from agonistic behaviors with 77.51% accuracy. The results demonstrate improved behavioral discrimination and establish a proof-of-concept for automated, interaction-aware social network analysis in precision livestock farming.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [Process Reward Model (PRM), Chain-of-Function, meta-learning, label correction, bi-level optimization, test-time scaling, LiveCodeBench]</li>
<li class=""><strong>authors:</strong> Ruiyi Zhang, Peijia Qin, Qi Cao, Pengtao Xie</li>
<li class=""><strong>institution:</strong> University of California, San Diego</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15000" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15000</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes DreamPRM-Code, a process reward model for coding that treats functions as reasoning steps using a Chain-of-Function strategy and employs a meta-learning-based label correction mechanism to refine noisy intermediate training labels. It achieves state-of-the-art performance on LiveCodeBench, surpassing OpenAI o4-mini.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Evaluating the Capability of Video Question Generation for Expert Knowledge Elicitation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [video question generation], [video question generation, question-to-answer retrieval, EgoExoAsk dataset, expert knowledge elicitation]</li>
<li class=""><strong>authors:</strong> Huaying Zhang, Atsushi Hashimoto, Tosho Hirasawa</li>
<li class=""><strong>institution:</strong> OMRON SINIC X Corp., Hokkaido University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15006" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15006</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a retrieval-based evaluation protocol for video question generation (VQG) models, focusing on their ability to elicit expert knowledge. The method uses a question-to-answer retriever trained on a novel dataset, EgoExoAsk, to simulate expert communication. The main conclusion is that this metric effectively aligns with VQG settings, as models with richer context are evaluated better, validating the proposed framework.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [llm evaluation], [geometric stability framework, invariant transformations, accuracy-stability paradox]</li>
<li class=""><strong>authors:</strong> Xidan Song, Weiqi Wang, Ruifeng Cao, Qingya Hu</li>
<li class=""><strong>institution:</strong> Wuhan Donghu University, University of Manchester</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15033" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15033</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Geometric Stability Framework to evaluate LLMs in chess by testing their consistency under board transformations like rotation and mirroring. It finds an Accuracy-Stability Paradox, where models like GPT-5.1 achieve high standard accuracy but fail catastrophically under geometric perturbations, indicating a reliance on pattern matching rather than robust spatial reasoning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Epistemic diversity across language models mitigates knowledge collapse</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [model collapse, epistemic diversity, AI ecosystem, self-training, distributed training]</li>
<li class=""><strong>authors:</strong> Damian Hodel, Jevin D. West</li>
<li class=""><strong>institution:</strong> University of Washington</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15011" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15011</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper investigates whether diversity across language models (an &quot;AI ecosystem&quot;) can mitigate performance decay from training on model-generated data. It segments training data across multiple models and evaluates performance over self-training iterations. The main conclusion is that increased epistemic diversity mitigates knowledge collapse, but only up to an optimal level, with too few or too many models leading to poor performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Spectral Representation-based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [spectral representations, spectral decomposition, transition operator, partially observable MDPs, model-free, model-based]</li>
<li class=""><strong>authors:</strong> Chenxiao Gao, Haotian Sun, Na Li, Dale Schuurmans, Bo Dai</li>
<li class=""><strong>institution:</strong> Georgia Tech, Harvard University, Google DeepMind, University of Alberta</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15036" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15036</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces spectral representations, derived from the spectral decomposition of the transition operator, as a framework for reinforcement learning to address issues like theoretical ambiguity and optimization instability. It shows how to construct these representations for different system structures and extends the approach to partially observable environments. The proposed algorithms achieve performance comparable to or better than state-of-the-art methods on over 20 challenging control tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] LADY: Linear Attention for Autonomous Driving Efficiency without Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [linear attention, cross-modal interaction, end-to-end autonomous driving, constant-time complexity, generative model]</li>
<li class=""><strong>authors:</strong> Jihao Huang, Xi Xia, Zhiyuan Li, Tianle Liu, Jingke Wang, Junbo Chen, Tengju Ye</li>
<li class=""><strong>institution:</strong> Udeer AI, Zhejiang University, Yuanshi Intelligence</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15038" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15038</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes LADY, a fully linear attention-based generative model for end-to-end autonomous driving that replaces transformers with efficient linear attention mechanisms. It introduces a lightweight linear cross-attention for effective multi-modal fusion and achieves constant computational and memory costs for long-range temporal context. Experiments show state-of-the-art planning performance with significantly reduced cost, and the model is successfully deployed on edge devices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [agentic AI, integrated sensing and communication (ISAC), generative AI (GenAI), deep reinforcement learning (DRL), perception-reasoning-action loop]</li>
<li class=""><strong>authors:</strong> Wenwen Xie, Geng Sun, Ruichen Zhang, Xuejie Liu, Yinqiu Liu, Jiacheng Wang, Dusit Niyato, Ping Zhang</li>
<li class=""><strong>institution:</strong> Jilin University, Nanyang Technological University, Beijing University of Posts and Telecommunications</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15044" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15044</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel agentic AI framework for optimizing Integrated Sensing and Communication (ISAC) systems, leveraging continuous perception-reasoning-action loops and generative AI. The case study demonstrates that this framework can enhance ISAC performance in dynamic wireless environments. The work concludes that agentic AI is a promising solution for enabling intelligent and autonomous operation in future 6G networks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [embodied navigation], [3D scene graphs, hierarchical traversable graphs, movable obstacles, path planning, scene understanding]</li>
<li class=""><strong>authors:</strong> Yunheng Wang, Yixiao Feng, Yuetong Fang, Shuning Zhang, Tan Jing, Jian Li, Xiangrui Jiang, Renjing Xu</li>
<li class=""><strong>institution:</strong> The Hong Kong University of Science and Technology (Guangzhou)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15047" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15047</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes HERO, a framework for building Hierarchical Traversable 3D Scene Graphs that model movable obstacles as pathways by capturing their interactivity and semantics. This redefinition of traversability allows for more efficient navigation planning in obstructed environments. The results show HERO significantly reduces path length in partially obstructed scenes and increases success rate in fully obstructed ones compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [Meta-Prompting Protocol, Adversarial Trinity, DSPy, TextGrad, textual gradients, semantic computation graph]</li>
<li class=""><strong>authors:</strong> Fanzhe Fu</li>
<li class=""><strong>institution:</strong> Zhejiang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15053</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic &quot;Observable Software Engineering&quot; for probabilistic models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Tracking spatial temporal details in ultrasound long video via wavelet analysis and memory bank</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical image segmentation], [wavelet analysis, memory bank, encoder-decoder, cross-attention, high-frequency feature fusion]</li>
<li class=""><strong>authors:</strong> Chenxiao Zhang, Runshi Zhang, Junchen Wang</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text. Affiliation inference is not possible from the author names alone without email domains or explicit institutional mentions.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15066</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a network combining wavelet analysis and a memory bank to segment objects in long ultrasound videos. The method uses memory-based wavelet convolution and high-frequency-aware feature fusion to capture fine details and track objects over time. It demonstrates improved segmentation accuracy, particularly for small nodules, on several ultrasound datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [conditional diffusion model, probabilistic forecasting, residual U-Net, cross-attention, uncertainty quantification, imputation-based sampling]</li>
<li class=""><strong>authors:</strong> Zijiang Yan, Yixiang Huang, Jianhua Pei, Hina Tabassum, Luca Chiaraviglio</li>
<li class=""><strong>institution:</strong> York University, Huazhong University of Science and Technology, University of Rome Tor Vergata</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15067" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15067</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces EMFusion, a conditional diffusion-based probabilistic forecasting framework that uses a residual U-Net with cross-attention to integrate contextual factors for frequency-selective EMF level prediction. It treats forecasting as an inpainting task to handle irregular data and provides explicit uncertainty estimates. The results show that EMFusion significantly outperforms baseline models in key forecasting metrics.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [neuron-level intervention, expertise-weighted soft suppression, MM-TOXIC-QA, white-box detoxification, SGM*]</li>
<li class=""><strong>authors:</strong> Hongbo Wang, MaungMaung AprilPyone, Isao Echizen</li>
<li class=""><strong>institution:</strong> The University of Tokyo, National Institute of Informatics</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15052" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15052</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SGM, a neuron-level intervention method that selectively recalibrates toxic expert neurons in multimodal large language models (MLLMs) using expertise-weighted soft suppression to reduce harmful outputs. Experiments show SGM significantly cuts toxicity rates from 48.2% to 2.5% while preserving model fluency and reasoning, and it can be combined with other methods for stronger safety.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [retrieval-augmented generation], [conformal prediction, semantic similarity, natural language inference, hallucination detection, text embeddings]</li>
<li class=""><strong>authors:</strong> Debu Sinha</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15068" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15068</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper applies conformal prediction to provide statistical guarantees for hallucination detection in RAG systems, rigorously evaluating embedding-based methods. It finds that while these methods work on synthetic data, they fail on real benchmarks due to the &quot;semantic illusion,&quot; where plausible hallucinations remain semantically similar to source documents. The study concludes that embedding-based detection is insufficient for production, as reasoning-based methods like GPT-4 as a judge perform significantly better.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] PMMD: A pose-guided multi-view multi-modal diffusion for person generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [diffusion training], [diffusion framework, multimodal encoder, ResCVA module, cross modal fusion, pose-guided generation]</li>
<li class=""><strong>authors:</strong> Ziyu Shang, Haoran Liu, Rongchao Zhang, Zhiqian Wei, Tongtong Feng</li>
<li class=""><strong>institution:</strong> Harbin Institute of Technology, Shenzhen, City University of Hong Kong, Peking University, Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15069" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15069</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PMMD is a pose-guided multi-view multimodal diffusion framework that synthesizes photorealistic person images by jointly modeling visual views, pose features, and text prompts. It introduces a ResCVA module for local detail enhancement and a cross-modal fusion module to integrate image semantics with text. Experiments show PMMD outperforms baselines in consistency, detail preservation, and controllability on the DeepFashion MultiModal dataset.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Quantifying Return on Security Controls in LLM Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation (RAG), Monte Carlo simulation, loss exceedance curves, Laplace&#x27;s Rule of Succession, adversarial probing, Garak, attribute-based access control (ABAC), named entity recognition (NER) redaction, NeMo Guardrails]</li>
<li class=""><strong>authors:</strong> Richard Helder Moulton, Austin O&#x27;Brien, John D. Hastings</li>
<li class=""><strong>institution:</strong> Dakota State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15081" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15081</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a framework to quantify the financial return on security controls for LLM systems by simulating attacks on a RAG service, estimating attack success probabilities, and modeling potential losses with Monte Carlo methods. The main conclusion is that controls like ABAC and NER redaction significantly reduce expected financial losses and offer high return-on-control, whereas NeMo Guardrails provides minimal benefit in the tested scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [cognitive-inspired elastic reasoning, markov decision process, reinforcement learning, chain-of-thought, tool-assisted reasoning]</li>
<li class=""><strong>authors:</strong> Jinwu Hu, Dongjin Yang, Langyu Bian, Zhiquan Wen, Yufeng Wang, Yaofo Chen, Bin Xiao, Yuanqing Li, Mingkui Tan</li>
<li class=""><strong>institution:</strong> South China University of Technology, Pazhou Laboratory, Peng Cheng Laboratory, Chongqing University of Posts and Telecommunications</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15089" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15089</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes CogER, a framework that dynamically selects reasoning strategies for LLMs based on query complexity, modeled as a Markov Decision Process and trained with reinforcement learning. It introduces Cognitive Tool-Assisted Reasoning for autonomous tool use within reasoning chains. Experiments show CogER outperforms state-of-the-art methods, improving exact match scores by at least 13% on in-domain and 8% on out-of-domain tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Feature-Centric Unsupervised Node Representation Learning Without Homophily Assumption</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [graph representation learning], [graph convolution, unsupervised learning, node embeddings, homophily, non-homophilic graphs, intra-class similarity, inter-class separability]</li>
<li class=""><strong>authors:</strong> Sunwoo Kim, Soo Yong Lee, Kyungho Kim, Hyunjin Hwang, Jaemin Yoo, Kijung Shin</li>
<li class=""><strong>institution:</strong> KAIST (Korea Advanced Institute of Science and Technology)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15112" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15112</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FUEL, an unsupervised node representation learning method that adaptively adjusts the degree of graph convolution usage to enhance intra-class similarity and inter-class separability in the embedding space, using node feature clusters as proxy classes. It demonstrates state-of-the-art performance across diverse homophily levels in graphs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequence modeling], [attention, state space models, unified framework, interaction rank gap, head-count theorem, gradient highway]</li>
<li class=""><strong>authors:</strong> Ali Ghodsi</li>
<li class=""><strong>institution:</strong> University of Waterloo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15115" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15115</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a unified theoretical framework that connects attention mechanisms and state space models through an input-dependent interaction operator. It proves that representing a linear SSM requires a number of attention heads equal to the subspace dimension of its lag operators, and reveals a trade-off between the algebraic expressivity of the model and its ability to propagate gradients over long sequences.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [time series imputation], [diffusion model, Fourier transform, attention mechanism, gated convolution, frequency-domain modeling]</li>
<li class=""><strong>authors:</strong> Runze Li, Hanchen Wang, Wenjie Zhang, Binghao Li, Yu Zhang, Xuemin Lin, Ying Zhang</li>
<li class=""><strong>institution:</strong> University of New South Wales, University of Technology Sydney, Shanghai Jiao Tong University, Zhejiang Gongshang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15116" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15116</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FADTI is a diffusion-based framework for multivariate time series imputation that integrates a learnable Fourier Bias Projection module with self-attention and gated convolution to inject frequency-domain inductive bias. It outperforms state-of-the-art methods across multiple benchmarks, especially under high missing rates, by adaptively encoding both stationary and non-stationary patterns.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] I am here for you&quot;: How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [human-computer interaction], [conversational AI, relational style, transparent style, anthropomorphism, emotional reliance, online experiment, adolescent psychology]</li>
<li class=""><strong>authors:</strong> Pilyoung Kim, Yun Xie, Sujin Yang</li>
<li class=""><strong>institution:</strong> University of Denver, Ewha Womans University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15117" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15117</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper uses a preregistered online experiment with adolescent-parent dyads to compare how relational versus transparent conversational styles in AI chatbots affect adolescents&#x27; perceptions. It finds that a relational style increases anthropomorphism, trust, and emotional closeness, and is especially preferred by socially and emotionally vulnerable adolescents, highlighting a design consideration for youth AI safety.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Automatic Reward Shaping from Multi-Objective Human Heuristics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reward shaping, multi-objective optimization, bi-level optimization, stochastic exploration]</li>
<li class=""><strong>authors:</strong> Yuqing Xie, Jiayu Chen, Wenhao Tang, Ya Zhang, Chao Yu, Yu Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15120" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15120</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MORSE, a framework that automatically combines multiple human-designed heuristic rewards into a unified reward function using bi-level optimization with stochastic exploration. It effectively balances conflicting objectives in robotic tasks, achieving performance comparable to manually tuned rewards in MuJoCo and Isaac Sim environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] HD-Prot: A Protein Language Model for Joint Sequence-Structure Modeling with Continuous Structure Tokens</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [hybrid diffusion, continuous tokens, joint sequence-structure modeling, absorbing diffusion process, categorical prediction, continuous diffusion]</li>
<li class=""><strong>authors:</strong> Yi Zhou, Haohao Qu, Yunqing Liu, Shanru Lin, Le Song, Wenqi Fan</li>
<li class=""><strong>institution:</strong> The Hong Kong Polytechnic University, BioGen AI, Mohamed bin Zayed University of Artificial Intelligence</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15133" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15133</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes HD-Prot, a hybrid diffusion protein language model that integrates continuous structural tokens with discrete sequence tokens for joint modeling. It uses a unified absorbing diffusion process to handle both modalities, performing categorical prediction for sequences and continuous diffusion for structures. The model achieves competitive performance in tasks like co-generation and structure prediction, demonstrating the viability of combining categorical and continuous distributions in a unified architecture.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretability], [sparse autoencoders, sparse probes, concept disentanglement, steering experiments, multi-concept evaluation]</li>
<li class=""><strong>authors:</strong> Aaron Mueller, Andrew Lee, Shruti Joshi, Ekdeep Singh Lubana, Dhanya Sridhar, Patrik Reizinger</li>
<li class=""><strong>institution:</strong> Boston University, Harvard University, Mila – Quebec AI Institute, Goodfire, University of Tübingen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15134" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15134</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a multi-concept evaluation framework to test whether interpretability methods like sparse autoencoders and sparse probes recover disentangled and independently manipulable concept representations. It finds that features often correspond to single concepts, but concepts are distributed across many features, and steering one feature typically affects multiple concepts, indicating a lack of true independence. The results highlight that correlational metrics are insufficient for proving disentanglement and underscore the need for compositional evaluations in interpretability research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Offline Multi-Task Multi-Objective Data-Driven Evolutionary Algorithm with Language Surrogate Model and Implicit Q-Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [surrogate modeling, large language model, sequence-to-sequence modeling, offline training, reinforcement learning fine-tuning, implicit q-learning, multi-task multi-objective optimization]</li>
<li class=""><strong>authors:</strong> Xian-Rong Zhang, Yue-Jiao Gong, Zeyuan Ma, Jun Zhang</li>
<li class=""><strong>institution:</strong> South China University of Technology, Nankai University, Hanyang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15149" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15149</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Q-MetaSur, a plug-and-play surrogate modeling scheme that uses a Large Language Model as a sequence-to-sequence surrogate for offline multi-task multi-objective optimization, trained with a two-stage strategy combining supervised tuning and RL fine-tuning. The method demonstrates superior objective approximation accuracy and helps evolutionary algorithms achieve better convergence and Pareto optimality on benchmark problems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [MCP (Model Context Protocol), safety benchmark, multi-turn evaluation, multi-server workflows, attack taxonomy, agentic systems]</li>
<li class=""><strong>authors:</strong> Xuanjun Zong, Zhiqi Shen, Lei Wang, Yunshi Lan, Chao Yang</li>
<li class=""><strong>institution:</strong> East China Normal University, National University of Singapore, Singapore Management University, Shanghai AI Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15163" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15163</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MCP-SafetyBench, a benchmark built on real Model Context Protocol servers to evaluate the safety of LLMs operating as agents across tools and services. It systematically tests models on multi-step, multi-server tasks across five domains, revealing significant safety vulnerabilities that escalate with task complexity. The results highlight the urgent need for improved defenses in real-world LLM agent deployments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] DEER: Draft with Diffusion, Verify with Autoregressive Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, diffusion large language model, parallel decoding, draft-verify scheme, two-stage training, single-step decoding]</li>
<li class=""><strong>authors:</strong> Zicong Cheng, Guo-Wei Yang, Jia Li, Zhijie Deng, Meng-Hao Guo, Shi-Min Hu</li>
<li class=""><strong>institution:</strong> Tsinghua University, Proxseer Inc, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15176" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15176</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces DEER, a speculative decoding framework that uses a diffusion large language model (dLLM) as a parallel drafter to generate candidate tokens, which are then verified by a target autoregressive model. The method overcomes the sequential bottleneck and trust collapse of traditional AR drafters through a two-stage training pipeline and single-step decoding. Experiments show DEER achieves significantly longer draft acceptance and higher speedups (e.g., 5.54x) compared to prior methods like EAGLE-3.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Governing rapid technological change: Policy Delphi on the future of European AI governance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [policy analysis], [Policy Delphi, anticipatory governance, future-proof regulation, AI Act]</li>
<li class=""><strong>authors:</strong> Atte Ojanen, Johannes Anttila, Thilo H. K. Thelitz, Anna Bjork</li>
<li class=""><strong>institution:</strong> Demos Helsinki, University of Turku</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15196" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15196</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses a two-round Policy Delphi method with European experts to study the future of AI governance. It finds a consensus that effective regulation depends more on practical implementation and enforcement than on technical specifics, and identifies a gap between desirable policy directions (like citizen participation) and their perceived feasibility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [discrete optimization], [relaxed decision diagrams, variable ordering, clustering, branch-and-bound, maximum weighted independent set]</li>
<li class=""><strong>authors:</strong> Mohsen Nafar, Michael Römer, Lin Xie</li>
<li class=""><strong>institution:</strong> Brandenburg University of Technology, Bielefeld University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15198" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15198</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a clustering-based framework to improve variable ordering for relaxed decision diagrams, aiming to reduce the computational overhead of dynamic ordering heuristics. The framework partitions variables into clusters and applies two strategies, Cluster-to-Cluster and Pick-and-Sort, to guide the ordering process. The method, evaluated on the Maximum Weighted Independent Set Problem, consistently reduces computational costs compared to standard baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge-aware question answering], [knowledge graph, chain-of-thought, few-shot in-context learning, relation-driven adaptive hop-count selection, path guidance]</li>
<li class=""><strong>authors:</strong> Chao Zhang, Minghan Li, Tianrui Lv, Guodong Zhou</li>
<li class=""><strong>institution:</strong> Soochow University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15219" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15219</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes RFKG-CoT, a method that enhances knowledge-aware question answering by dynamically selecting reasoning steps in a knowledge graph based on relations and using few-shot examples to guide large language models in understanding reasoning paths. It improves answer accuracy over previous methods by making the integration of knowledge graph evidence more adaptive and guided. Experiments show significant accuracy gains on multiple benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Yes-MT&#x27;s Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [fine-tuning, LoRA, zero-shot prompting, few-shot prompting, supervised fine-tuning, transformer models]</li>
<li class=""><strong>authors:</strong> Yash Bhaskar, Parameswari Krishnamurthy</li>
<li class=""><strong>institution:</strong> IIIT Hyderabad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15226" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15226</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper explores various methods for low-resource Indic language translation, including fine-tuning models like mT5 and IndicBart, using LoRA with IndicTrans2 and Llama 3, and prompting LLMs like Llama 3 and Mixtral. The results highlight the challenges of data scarcity and demonstrate the potential of fine-tuned large language models for these translation tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Procedural Knowledge Base, Dynamic Workflow Adjustment, Evolutionary Memory Module, Large Language Model, Reflexion baseline]</li>
<li class=""><strong>authors:</strong> Zhengchao Chen, Haoran Wang, Jing Yao, Pedram Ghamisi, Jun Zhou, Peter M. Atkinson, Bing Zhang</li>
<li class=""><strong>institution:</strong> Chinese Academy of Sciences, University of Chinese Academy of Sciences, Helmholtz-Zentrum Dresden-Rossendorf, Lancaster University, Griffith University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15231" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15231</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces CangLing-KnowFlow, a unified intelligent agent framework for remote sensing that integrates a Procedural Knowledge Base, Dynamic Workflow Adjustment, and an Evolutionary Memory Module to plan, adapt, and learn from complex tasks. The framework was evaluated on a novel benchmark and outperformed a baseline method, demonstrating its potential as a robust and scalable automated solution for Earth observation challenges.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [Cross-Modal Alignment Consistency (CMAC-MMD), vision-language model (VLM), intersectional fairness, diagnostic certainty, True Positive Rate (TPR), Area Under the Curve (AUC)]</li>
<li class=""><strong>authors:</strong> Yupeng Zhang, Adam G. Dunn, Usman Naseem, Jinman Kim</li>
<li class=""><strong>institution:</strong> The University of Sydney, Macquarie University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15249" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15249</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a training framework called Cross-Modal Alignment Consistency (CMAC-MMD) to reduce intersectional bias in vision-language models for medical diagnosis by standardizing diagnostic certainty across patient subgroups. The method improves both fairness, by reducing the gap in missed diagnoses, and overall accuracy, as demonstrated on skin lesion and glaucoma screening tasks. It provides a scalable approach for equitable clinical AI without requiring sensitive demographic data during inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [self-supervised pretraining, dual-masking strategy, embedding concatenation, foundational models, CBraMod encoder]</li>
<li class=""><strong>authors:</strong> Youssef Ghallab, Omar Iraqy, Mohamed Kandil, Mohamed Ashraf, Saadeldine Eletter, Morougue Ghazal, Ayman Khalafallah, Nagwa El-Makky</li>
<li class=""><strong>institution:</strong> Alexandria University, Mohamed bin Zayed University of Artificial Intelligence</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15250" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15250</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method for multi-modal physiological signal analysis by adapting a self-supervised foundational model (CBraMod) for ECG and EEG, using a dual-masking strategy for ECG, and fusing the modalities via simple embedding concatenation. The approach achieves near state-of-the-art performance in emotion recognition, demonstrating that well-designed foundational encoders with straightforward fusion can effectively leverage limited multi-modal data. The results highlight the potential of foundation-model approaches for scalable and label-efficient solutions in healthcare and affective computing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [3D Gaussian Splatting, progressive three-stage training, geometric safety correction, onboard deployment optimization]</li>
<li class=""><strong>authors:</strong> Yuze Wu, Mo Zhu, Xingxing Li, Yuheng Du, Yuxin Fan, Wenjun Li, Xin Zhou, Fei Gao</li>
<li class=""><strong>institution:</strong> Zhejiang University, Differential Robotics</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15258" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15258</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes VLA-AN, an efficient onboard Vision-Language-Action framework for drone navigation. Its core method uses a high-fidelity dataset built with 3D Gaussian Splatting and a three-stage training pipeline, coupled with a lightweight safety-corrected action module. The conclusion is that the framework achieves robust real-time performance and high navigation success rates, providing a practical solution for autonomous aerial robots.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [reinforcement learning with verifiable rewards, progressive prefix-token policy optimization, beginning lock-in effect, prefix optimization, continuation accumulated reward]</li>
<li class=""><strong>authors:</strong> Yiliu Sun, Zicheng Zhao, Yang Wei, Yanfang Zhang, Chen Gong</li>
<li class=""><strong>institution:</strong> Nanjing University of Science and Technology, North University of China, Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15274" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15274</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Progressive Prefix-token Policy Optimization (PPPO), a reinforcement learning method that focuses on optimizing the initial prefix tokens of an LLM&#x27;s reasoning output, based on the identified Beginning Lock-in Effect. It introduces strategies like Progressive Prefix Retention and Continuation Accumulated Reward to improve training efficiency. The method achieves significant accuracy improvements on reasoning tasks while using far fewer training tokens compared to standard approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [formal methods], [reinforcement learning, graph neural networks, labeled transition system, exploration policy]</li>
<li class=""><strong>authors:</strong> Toshihide Ubukata, Enhong Mu, Takuto Yamauchi, Mingyue Zhang, Jialong Li, Kenji Tei</li>
<li class=""><strong>institution:</strong> Waseda University, Southwest University, Institute of Science Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15295" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15295</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces GCRL, a method that enhances reinforcement learning for controller synthesis by integrating Graph Neural Networks to encode exploration history into a graph for broader context. It demonstrates superior learning efficiency and generalization compared to state-of-the-art methods in most benchmark domains.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Quantum Neural Networks (QNNs), Quantum Support Vector Machines (QSVMs), Variational Quantum Circuits (VQCs), Quantum Generative Adversarial Networks (QGANs)]</li>
<li class=""><strong>authors:</strong> Siva Sai, Ishika Goyal, Shubham Sharma, Sri Harshita Manuri, Vinay Chamola, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> The University of Melbourne, Birla Institute of Technology and Science, Pilani, APPCAIR</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15286" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15286</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This survey paper explores Quantum Machine Learning (QML) techniques, including QNNs, QSVMs, VQCs, and QGANs, for cybersecurity applications like intrusion detection and malware classification. It concludes that QML offers potential advantages for processing high-dimensional data and enhancing security in areas like cloud computing, but also discusses current limitations and future research directions needed to address them.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Graph Pattern-based Association Rules Evaluated Under No-repeated-anything Semantics in the Graph Transactional Setting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [graph mining], [graph pattern-based association rules, no-repeated-anything semantics, confidence, lift, leverage, conviction]</li>
<li class=""><strong>authors:</strong> Basil Ell</li>
<li class=""><strong>institution:</strong> Bielefeld University, University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15308" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15308</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Graph Pattern-based Association Rules (GPARs) for analyzing directed labeled multigraphs like RDF graphs. It evaluates these rules under a &quot;no-repeated-anything&quot; semantics to better account for graph topology and defines probabilistic metrics like confidence and lift. The framework is shown to extend beyond existing formalisms for graph data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [multimodal reasoning, perception-cognition gap, calculation-conceptualization discrepancy, process hallucination, OCR, AI-resistant questions]</li>
<li class=""><strong>authors:</strong> Seok-Hyun Ga, Chun-Yen Chang</li>
<li class=""><strong>institution:</strong> Institute for Research Excellence in Learning Sciences, National Taiwan Normal University, Seoul National University, Universitas Negeri Malang</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15298</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study evaluates the multimodal scientific reasoning of LLMs like GPT-4o and Gemini on the Korean CSAT Earth Science I exam under different input conditions. It finds that models suffer from fundamental cognitive flaws, such as a perception-cognition gap and calculation-conceptualization discrepancy, even with optimized inputs. The paper concludes by suggesting these vulnerabilities can be exploited to design AI-resistant assessment questions to ensure academic integrity.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific information extraction], [zero-shot prompting, few-shot prompting, event-specific prompting, reflection-based prompting, in-context learning, event extraction, argument extraction]</li>
<li class=""><strong>authors:</strong> Charan Prakash Rathore, Saumi Ray, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> Birla Institute of Technology and Science, Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15312</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates six state-of-the-art LLMs using four prompting strategies (zero-shot, few-shot, event-specific, reflection-based) for extracting structured event and argument information from zeolite synthesis procedures. It finds that while LLMs achieve strong performance on high-level event classification, they show modest results on fine-grained parameter extraction, with advanced prompting offering minimal gains over zero-shot approaches. The conclusion is that precise scientific information extraction requires domain-adapted models, as current LLMs have fundamental limitations in capturing synthesis-specific nuances.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Automated Motion Artifact Check for MRI (AutoMAC-MRI): An Interpretable Framework for Motion Artifact Detection and Severity Assessment</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical imaging], [supervised contrastive learning, affinity scores, interpretable grading]</li>
<li class=""><strong>authors:</strong> Antony Jerald, Dattesh Shanbhag, Sudhanya Chatterjee</li>
<li class=""><strong>institution:</strong> GE HealthCare</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15315" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15315</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AutoMAC-MRI, an interpretable framework that uses supervised contrastive learning to detect and grade motion artifacts in MRI images. It computes grade-specific affinity scores to quantify an image&#x27;s proximity to each motion severity level, making the grading process transparent. The method was validated on over 5,000 expert-annotated brain MRI slices and shows potential for reducing unnecessary rescans and improving workflow efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Quantum-Inspired Rogue Variable Modeling (QRVM), Human-in-the-Loop Decoherence, Collective Cognitive Inference, proof of concept, VUCA]</li>
<li class=""><strong>authors:</strong> Agnieszka Bienkowska, Jacek Malecki, Alexander Mathiesen-Ohman, Katarzyna Tworek</li>
<li class=""><strong>institution:</strong> Not explicitly stated in provided text</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15325" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15325</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a proof of concept for the LAIZA human-AI symbiotic system, which uses a quantum-inspired cognitive mechanism to detect &quot;rogue variables&quot; and manage ambiguity by preserving interpretive plurality and activating structured human clarification. The main conclusion is that this approach enables proactive scenario-based preparation and decisive action in VUCA environments, reframing ambiguity as a key construct for organizational resilience.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Vision-based module for accurately reading linear scales in a laboratory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [vision-based models, object detection, image classification, instance segmentation, feature extraction, orientation correction]</li>
<li class=""><strong>authors:</strong> Parvesh Saini, Soumyadipta Maiti, Beena Rai</li>
<li class=""><strong>institution:</strong> TCS Research, Tata Consultancy Services Limited</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15327" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15327</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a vision-based module that mimics a human-inspired approach to read measurements from linear scales, such as on syringes and measuring cylinders, by correcting orientation, isolating the scale region, and extracting features like markers and digits. The system&#x27;s readings were compared against human-read values and showed accurate correspondence, demonstrating its potential for laboratory automation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [crowdsourcing, user study, extended reality, conversational agents, privacy, technology acceptance model]</li>
<li class=""><strong>authors:</strong> Efe Bozkir, Enkelejda Kasneci</li>
<li class=""><strong>institution:</strong> Technical University of Munich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15343" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15343</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducted a large-scale crowdsourcing study with 1036 participants to explore user acceptance and concerns regarding LLM-powered conversational agents in Extended Reality (XR). The study found that while users generally accept these technologies, they express significant concerns about security, privacy, social implications, and trust, with location data being the most sensitive. The results highlight the importance of practitioner transparency and that familiarity with generative AI increases acceptance, while prior XR device ownership is linked to lower acceptance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [phase adjustment, three-axis independent alignment, single-axis reference alignment, deep learning, vibration signals, predictive maintenance]</li>
<li class=""><strong>authors:</strong> Hiroyoshi Nagahama, Katsufumi Inoue, Masayoshi Todorokihara, Michifumi Yoshioka</li>
<li class=""><strong>institution:</strong> Osaka Metropolitan University, Seiko Epson Corp.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15344</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces two phase-aware preprocessing strategies—three-axis independent and single-axis reference phase adjustment—to handle random phase variations in multi-axis vibration data for fault diagnosis. The methods are evaluated using a new rotor dataset and six deep learning models, showing consistent performance improvements, with the single-axis reference approach achieving up to 96.2% accuracy by preserving spatial phase relationships. The findings demonstrate that these phase alignment strategies are practical and scalable enhancements for predictive maintenance systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Adversarial versification in portuguese as a jailbreak operator in LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [adversarial versification, poetry jailbreak, guardrail vulnerabilities, semiotic-formal variation, latent region displacement]</li>
<li class=""><strong>authors:</strong> Joao Queiroz</li>
<li class=""><strong>institution:</strong> Federal University of Juiz de Fora</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15353" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15353</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper investigates using versification, or rewriting prompts as poetry, as a method to bypass safety guardrails in aligned large language models. It concludes that this structural adversarial technique exploits a model&#x27;s over-reliance on surface patterns, causing significant safety failures, and highlights a critical research gap for Portuguese due to its linguistic complexity.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Image Complexity-Aware Adaptive Retrieval for Efficient Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [adaptive computation, early exit, dual-path training, image complexity classification, ConvNeXt-IC]</li>
<li class=""><strong>authors:</strong> Mikel Williams-Lekuona, Georgina Cosma</li>
<li class=""><strong>institution:</strong> Loughborough University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15372" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15372</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ICAR, an adaptive retrieval method that reduces computation for simple images in vision-language models by using early exits, while maintaining cross-modal alignment through dual-path training. It also introduces ConvNeXt-IC, a classifier for image complexity to decide the compute depth. The method achieves a 20% practical speedup with minimal performance loss, enabling more efficient scaling of vision-language systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Emotion Recognition in Signers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [cross-lingual transfer, temporal segment selection, hand motion features, textual emotion recognition, facial expression analysis]</li>
<li class=""><strong>authors:</strong> Kotaro Funakoshi, Yaoxiong Zhu</li>
<li class=""><strong>institution:</strong> Institute of Science Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15376" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15376</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a new dataset for emotion recognition in Japanese Sign Language and addresses the challenges of overlapping grammatical/affective expressions and data scarcity using cross-lingual transfer from textual emotion recognition in spoken language. The authors demonstrate that selecting specific temporal segments and incorporating hand motion features significantly improves emotion recognition performance in signers, establishing a stronger baseline than spoken language LLMs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SCOPE: Prompt Evolution for Enhancing Agent Effectiveness</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [prompt evolution, online optimization, dual-stream mechanism, perspective-driven exploration, execution trace analysis, HLE benchmark]</li>
<li class=""><strong>authors:</strong> Zehua Pei, Hui-Ling Zhen, Shixiong Kai, Sinno Jialin Pan, Yunhe Wang, Mingxuan Yuan, Bei Yu</li>
<li class=""><strong>institution:</strong> The Chinese University of Hong Kong, Noah&#x27;s Ark Lab, Huawei</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15374" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15374</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SCOPE, a method that frames context management for LLM agents as an online optimization problem, using a Dual-Stream mechanism and Perspective-Driven Exploration to automatically evolve the agent&#x27;s prompt from execution traces. It significantly improves agent effectiveness by balancing tactical error correction with strategic guideline evolution. Experiments on the HLE benchmark show that SCOPE increases task success rates from 14.23% to 38.64% without human intervention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [spatial reasoning], [retrieval-augmented generation, qualitative spatial relations, graph-based reasoning]</li>
<li class=""><strong>authors:</strong> Reinhard Moratz, Niklas Daute, James Ondieki, Markus Kattenbeck, Mario Krajina, Ioannis Giannopoulos</li>
<li class=""><strong>institution:</strong> University of Münster</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15388" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15388</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses Retrieval-Augmented Generation (RAG) with qualitative spatial representations to improve LLM-generated pedestrian route instructions. It finds that incorporating structured spatial data reduces hallucinations and errors, encouraging further integration for navigation and smart city applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] SMART: Semantic Matching Contrastive Learning for Partially View-Aligned Clustering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [multi-view clustering], [contrastive learning, distribution alignment, semantic graph, partially view-aligned clustering]</li>
<li class=""><strong>authors:</strong> Liang Peng, Yixuan Ye, Cheng Liu, Hangjun Che, Fei Wang, Zhiwen Yu, Si Wu, Hau-San Wong</li>
<li class=""><strong>institution:</strong> Shantou University, Huaqiao University, Southwest University, South China University of Technology, City University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15396" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15396</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SMART, a model for partially view-aligned clustering that uses view distribution alignment and semantic matching contrastive learning to handle misaligned multi-view data. It aligns cross-view covariance matrices to reduce distribution shifts and leverages a semantic graph to guide contrastive learning, improving clustering performance. Experiments on eight datasets show that SMART outperforms existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [feature model-based reinforcement learning, actor-critic, Dyna-Q, model-based RL, model-free RL, multi-task control]</li>
<li class=""><strong>authors:</strong> Quanxi Zhou, Wencan Mao, Manabu Tsukada, John C.S. Lui, Yusheng Ji</li>
<li class=""><strong>institution:</strong> The University of Tokyo, National Institute of Informatics, The Chinese University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15430" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15430</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FM-EAC, a feature model-based enhanced actor-critic algorithm that integrates planning, acting, and learning for multi-task control. It combines model-based and model-free reinforcement learning to improve generalizability across tasks. Simulations show it outperforms state-of-the-art methods in urban and agricultural applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [game AI], [outer-learning, bootstrapping, self-playing, perfect feature hash, statistical information, self-learning]</li>
<li class=""><strong>authors:</strong> Stefan Edelkamp</li>
<li class=""><strong>institution:</strong> Charles University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15435" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15435</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a bootstrapping outer-learning framework that expands a database of human expert games with millions of self-playing AI games to generate improved statistics for decision-making in trick-taking card games. It implements perfect feature hash functions for compacted tables to create a self-improving game engine. The case study in Skat demonstrates that this automated approach can effectively support various early-game decisions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Double Horizon Model-Based Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [model-based reinforcement learning, policy optimization, distribution rollout, training rollout, double horizon]</li>
<li class=""><strong>authors:</strong> Akihiro Kubo, Paavo Parmas, Shin Ishii</li>
<li class=""><strong>institution:</strong> Advanced Telecommunications Research Institute, Kyoto University, The University of Tokyo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15439</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Double Horizon Model-Based Policy Optimization (DHMBPO), a method that separates the model rollout process into a long &quot;distribution rollout&quot; to mitigate distribution shift and a short &quot;training rollout&quot; for stable gradient estimation. This approach balances model bias and gradient variance. The method demonstrates superior sample efficiency and runtime compared to existing MBRL methods on continuous-control benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Intent-Driven UAM Rescheduling</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scheduling optimization], [Mixed Integer Linear Programming (MILP), Answer Set Programming (ASP), three-valued logic, decision tree, Resource-Constrained Project Scheduling Problem (RCPSP)]</li>
<li class=""><strong>authors:</strong> Jeongseok Kim, Kangjin Kim</li>
<li class=""><strong>institution:</strong> Cleverplant, Chodang University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15462</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an intent-driven rescheduling system for Urban Air Mobility (UAM) that combines Answer Set Programming (ASP) with Mixed Integer Linear Programming (MILP) to handle ambiguous human requests. It uses a three-valued logic and a decision tree to interpret vague user intents for transparent schedule adjustments. The main conclusion is that this integrated framework provides a robust, explainable, and adaptive structure for UAM scheduling.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] On Assessing the Relevance of Code Reviews Authored by Generative Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [multi-subjective ranking, code review generation, ChatGPT, human evaluation, CodeReview StackExchange]</li>
<li class=""><strong>authors:</strong> Robert Heumüller, Frank Ortmeier</li>
<li class=""><strong>institution:</strong> Otto von Guericke University Magdeburg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15466" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15466</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-subjective ranking method to evaluate AI-generated code review comments, comparing ChatGPT outputs against top human responses from CodeReview StackExchange. The results show that ChatGPT&#x27;s comments were ranked significantly better than human-authored ones, even outperforming accepted answers. The method aims to provide a more meaningful assessment of generative AI in code review while highlighting risks of unchecked integration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [membership inference, semantically equivalent code transformation, variable renaming, causal analysis, code obfuscation]</li>
<li class=""><strong>authors:</strong> Hua Yang, Alejandro Velasco, Thanh Le-Cong, Md Nazmul Haque, Bowen Xu, Denys Poshyvanyk</li>
<li class=""><strong>institution:</strong> North Carolina State University, William &amp; Mary, The University of Melbourne</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15468" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15468</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates how semantically equivalent code transformations, such as variable renaming, can be used to evade membership inference detection in large language models for code. It finds that these transformations, especially RenameVariable, can significantly reduce the success of membership inference attacks without substantially harming model performance. The results reveal a critical vulnerability in license compliance enforcement for code LLMs, showing that transformation-based obfuscation can weaken detection of unauthorized code usage.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [long-context fine-tuning, sequential bucketed strategy, tool-integrated reasoning, multi-mode supervision, dataset distillation]</li>
<li class=""><strong>authors:</strong> Wei Du, Shubham Toshniwal, Branislav Kisacanin, Sadegh Mahdavi, Ivan Moshkov, George Armstrong, Stephen Ge, Edgar Minasyan, Feng Chen, Igor Gitman</li>
<li class=""><strong>institution:</strong> NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15489" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15489</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Nemotron-Math, a large-scale mathematical reasoning dataset generated using the multi-mode capabilities of gpt-oss-120b, featuring diverse reasoning styles and Python tool integration. The authors also propose a sequential bucketed strategy to accelerate long-context fine-tuning. The dataset enables state-of-the-art performance on mathematical benchmarks, achieving 100% accuracy on AIME 2024/2025 with tool-integrated reasoning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Attention in Motion: Secure Platooning via Transformer-based Misbehavior Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [transformer, multi-head self-attention, positional encoding, precision-focused loss, edge deployment, TensorFlow Lite, ONNX, TensorRT]</li>
<li class=""><strong>authors:</strong> Konstantinos Kalogiannis, Ahmed Mohamed Hussain, Hexu Li, Panos Papadimitratos</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, Lenovo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15503</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes AIMformer, a transformer-based framework for real-time misbehavior detection in vehicular platoons. It uses multi-head self-attention to capture spatiotemporal dependencies and a precision-focused loss to minimize false positives. The method demonstrates high performance and achieves sub-millisecond inference latency, making it suitable for deployment on resource-constrained edge platforms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Soft Geometric Inductive Bias for Object Centric Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [geometric deep learning], [geometric algebra neural networks, soft geometric inductive bias, equivariance, object-centric world models, autoregressive training, long-horizon rollouts]</li>
<li class=""><strong>authors:</strong> Hampus Linander, Conor Heins, Alexander Tschantz, Marco Perin, Christopher Buckley</li>
<li class=""><strong>institution:</strong> VERSES AI, University of Sussex</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15493" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15493</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using object-centric world models built with geometric algebra neural networks to provide a soft geometric inductive bias for learning physical dynamics. The method is evaluated on 2D rigid body simulations and shows that this soft bias leads to better long-horizon prediction fidelity compared to non-equivariant baselines, effectively balancing between strict symmetry constraints and unstructured learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] BERT and CNN integrated Neural Collaborative Filtering for Recommender Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [neural collaborative filtering, BERT, CNN, hybrid recommendation system, deep learning]</li>
<li class=""><strong>authors:</strong> Abdullah Al Munem, Sumona Yeasmin, Mohammad Rezwanul Huq</li>
<li class=""><strong>institution:</strong> East West University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15526</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid neural collaborative filtering (NCF) model that integrates BERT and CNN to process categorical and image data for recommendations. The model was trained on a MovieLens dataset and outperformed baseline NCF and BERT-based NCF models. The results show that incorporating both categorical and image data can improve recommendation system performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] A Conditioned UNet for Music Source Separation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [conditioned UNet, music source separation, QSCNet, Sparse Compressed Network, Bandsplit RNN, Banquet, MoisesDb]</li>
<li class=""><strong>authors:</strong> Ken O&#x27;Hanlon, Basil Woods, Lin Wang, Mark Sandler</li>
<li class=""><strong>institution:</strong> Queen Mary University of London, AudioStrip Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15532" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15532</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes QSCNet, a novel conditioned UNet architecture for music source separation that uses an audio query to specify the target stem, eliminating the need for a predefined instrument vocabulary. The method integrates conditioning elements into a Sparse Compressed Network and is shown to outperform the prior Banquet model by over 1dB SNR on certain tasks while using fewer than half the parameters.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] A Decision-Theoretic Approach for Managing Misalignment</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [decision theory], [value alignment, delegation, decision-theoretic framework, epistemic accuracy, reach, universal delegation, context-specific delegation]</li>
<li class=""><strong>authors:</strong> Daniel A. Herrmann, Abinav Chari, Isabelle Qian, Sree Sharvesh, B. A. Levinstein</li>
<li class=""><strong>institution:</strong> University of North Carolina at Chapel Hill, Georgia Institute of Technology, University of California, Berkeley, Amrita Vishwa Vidyapeetham, University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15584" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15584</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a formal, decision-theoretic framework to analyze when to delegate decisions to an AI agent by balancing its value alignment, epistemic accuracy, and reach. It concludes that universal delegation requires near-perfect alignment, but context-specific delegation can be optimal even with significant misalignment if the agent&#x27;s superior accuracy or expanded reach offers a net benefit.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Evaluating Large Language Models in Scientific Discovery</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific discovery evaluation], [scenario-grounded benchmark, two-phase evaluation, hypothesis generation, experiment design, result interpretation]</li>
<li class=""><strong>authors:</strong> Zhangde Song, Jieyu Lu, Yuanqi Du, Botao Yu, Thomas M. Pruyn, Yue Huang, Kehan Guo, Xiuzhe Luo, Yuanhao Qu, Yi Qu, Yinkai Wang, Haorui Wang, Jeff Guo, Jingru Gan, Parshin Shojaee, Di Luo, Andres M Bran, Gen Li, Qiyuan Zhao, Shao-Xiong Lennon Luo, Yuxuan Zhang, Xiang Zou, Wanru Zhao, Yifan F. Zhang, Wucheng Zhang, Shunan Zheng, Saiyang Zhang, Sartaaj Takrim Khan, Mahyar Rajabi-Kochi, Samantha Paradi-Maropakis, Tony Baltoiu, Fengyu Xie, Tianyang Chen, Kexin Huang, Weiliang Luo, Meijing Fang, Xin Yang, Lixue Cheng, Jiajun He, Soha Hassoun, Xiangliang Zhang, Wei Wang, Chandan K. Reddy, Chao Zhang, Zhiling Zheng, Mengdi Wang, Le Cong, Carla P. Gomes, Chang-Yu Hsieh, Aditya Nandy, Philippe Schwaller, Heather J. Kulik, Haojun Jia, Huan Sun, Seyed Mohamad Moosavi, Chenru Duan</li>
<li class=""><strong>institution:</strong> Deep Principle, Cornell University, The Ohio State University, University of Toronto, University of Notre Dame, QuEra Computing Inc., Stanford University, Harvard Law School, Tufts University, Georgia Institute of Technology, Ecole Polytechnique Federale de Lausanne, University of California, Los Angeles, Virginia Tech, Tsinghua University, Princeton University, Harvard University, University of Cambridge, The University of Texas at Austin, McGill University, University of Science and Technology of China, Massachusetts Institute of Technology, Zhejiang University, The Hong Kong University of Science and Technology, Washington University in St. Louis</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15567" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15567</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a two-phase Scientific Discovery Evaluation (SDE) framework, which uses scenario-grounded benchmarks across multiple scientific domains to assess LLMs on question-level accuracy and project-level tasks like hypothesis generation and experiment design. It concludes that current LLMs show a significant performance gap in scientific discovery compared to general benchmarks, exhibit diminishing returns from scaling, and are far from being general scientific &quot;superintelligences,&quot; though they still demonstrate promise in various discovery projects.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How Smoothing is N-simplicial Attention?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [attention mechanisms], [N-simplicial attention, higher-order interactions, Rotary Position Embeddings (RoPE), simplex selection, over-smoothing, Lipschitz bound]</li>
<li class=""><strong>authors:</strong> Alexandre Dussolle, Pietro Liò</li>
<li class=""><strong>institution:</strong> University of Cambridge, École des Ponts, IP Paris</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15600" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15600</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces N-simplicial attention, a method that generalizes standard attention to higher-order token interactions and adapts it for Rotary Position Embeddings (RoPE). It also proposes a cost-effective simplex selection mechanism to manage computational complexity. The authors demonstrate that, despite enabling higher-order interactions, N-simplicial attention itself suffers from over-smoothing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Evaluating Metrics for Safety with LLM-as-Judges</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [LLM-as-Judges, weighted metrics, confidence thresholds, context sensitivity, safety evaluation, human review]</li>
<li class=""><strong>authors:</strong> Kester Clegg, Richard Hawkins, Ibrahim Habli, Tom Lawton</li>
<li class=""><strong>institution:</strong> University of York, Bradford Royal Infirmary</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15617" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15617</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a safety evaluation method for LLMs in critical applications by focusing on evidence from LLM-as-Judges frameworks. It suggests using a basket of weighted metrics and context-sensitive error severity to lower risk, with low-confidence judgments triggering human review. The main conclusion is that such an approach can enhance the reliability of LLMs in safety-critical information flows.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Low-Rank Adaptation (LoRA), supervised fine-tuning (SFT), parameter-efficient fine-tuning (PEFT), rank sweep, representational drift, attention patterns]</li>
<li class=""><strong>authors:</strong> Darshita Rathore, Vineet Kumar, Chetna Bansal, Anindya Moitra</li>
<li class=""><strong>institution:</strong> PayPal</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15634" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15634</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper comprehensively evaluates the trade-offs between full supervised fine-tuning (SFT) and Low-Rank Adaptation (LoRA) for fine-tuning large language models. It finds that LoRA, especially at specific rank values, can achieve competitive or even superior performance to SFT on reasoning tasks, while also analyzing the structural changes in model representations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [diffusion transformer (DiT), in-context learning, Effect-LoRA, spatiotemporal sparse tokenization, two-stage training, few-shot video editing]</li>
<li class=""><strong>authors:</strong> Yuanhang Li, Yiren Song, Junzhe Bai, Xinran Liang, Hu Yang, Libiao Jin, Qi Mao</li>
<li class=""><strong>institution:</strong> Communication University of China, National University of Singapore, Baidu Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15635" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15635</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IC-Effect is an instruction-guided video VFX editing framework based on Diffusion Transformers (DiT) that uses the source video as a contextual condition and employs a two-stage training strategy with Effect-LoRA for precise effect injection and background preservation. It introduces spatiotemporal sparse tokenization for computational efficiency. The method demonstrates high-quality, temporally consistent visual effects editing from limited data, enabling new possibilities for video creation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [continual learning], [energy-based model, progressive parameter selection, pseudo-sample generation, catastrophic forgetting mitigation]</li>
<li class=""><strong>authors:</strong> Xiaodi Li, Dingcheng Li, Rujun Gao, Mahmoud Zamani, Feng Mi, Latifur Khan</li>
<li class=""><strong>institution:</strong> Mayo Clinic, Google, Texas A&amp;M University, The University of Texas at Dallas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15658" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15658</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces PPSEBM, a framework combining an Energy-Based Model with Progressive Parameter Selection to address catastrophic forgetting in continual learning for NLP tasks. It uses task-specific parameters and generates pseudo-samples from prior tasks to retain past knowledge. Experimental results show PPSEBM outperforms state-of-the-art methods in mitigating forgetting.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reasoning and self-critique], [stepwise think-critique, reinforcement learning, self-critique, chain of thought, process reward models]</li>
<li class=""><strong>authors:</strong> Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan LU</li>
<li class=""><strong>institution:</strong> University of Science and Technology of China, Microsoft Research Asia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15662" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15662</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single large language model, trained using a hybrid reinforcement learning objective. Experiments on mathematical reasoning benchmarks show that STC enhances critical thinking capabilities and produces more interpretable reasoning traces.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Explaining the Reasoning of Large Language Models Using Attribution Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretability], [attribution methods, context attribution, attribution graph, CAGE, faithfulness]</li>
<li class=""><strong>authors:</strong> Chase Walker, Rickard Ewetz</li>
<li class=""><strong>institution:</strong> University of Florida</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15663" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15663</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the CAGE framework, which uses an attribution graph to explain autoregressive LLMs by quantifying how each generated token is influenced by both the prompt and all prior tokens, preserving causality and row stochasticity. This approach improves the faithfulness of context attributions by accounting for inter-generational influences, achieving average gains of up to 40% over existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [vision-text compression, VTCBench, DeepSeek-OCR, Glyph, VTC-Retrieval, VTC-Reasoning, VTC-Memory]</li>
<li class=""><strong>authors:</strong> Hongbo Zhao, Meng Wang, Fei Zhu, Wenzhuo Liu, Bolin Ni, Fanhu Zeng, Gaofeng Meng, Zhaoxiang Zhang</li>
<li class=""><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science &amp; Innovation, CAS; Tencent Hunyuan Team</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15649" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15649</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces VTCBench, the first benchmark to evaluate Vision-Language Models&#x27; ability to understand long context using Vision-Text Compression (VTC), a technique that converts long text into dense 2D images for token efficiency. The study systematically tests models on retrieval, reasoning, and memory tasks with VTC-compressed inputs. The main conclusion is that most VLMs perform poorly on long-context understanding with VTC, despite good OCR decoding, failing to capture long-range associations in the compressed visual context.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [llm interpretability], [LatentQA, Activation Oracles, activation analysis, fine-tuning detection, natural language queries]</li>
<li class=""><strong>authors:</strong> Adam Karvonen, James Chua, Clément Dumas, Kit Fraser-Taliente, Subhash Kantamneni, Julian Minder, Euan Ong, Arnab Sen Sharma, Daniel Wen, Owain Evans, Samuel Marks</li>
<li class=""><strong>institution:</strong> MATS, Truthful AI, EPFL, ENS Paris-Saclay, Northeastern University, Anthropic</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15674" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15674</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Activation Oracles, models trained using the LatentQA approach to answer natural language questions about the internal activations of other LLMs. The core finding is that these oracles, especially when trained on diverse datasets, can generalize to out-of-distribution tasks and effectively verbalize hidden information, such as knowledge from fine-tuning, often matching or exceeding prior white-box interpretability methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [gradient-guided reinforcement learning, G2RL, PPO, KL control, final-layer sensitivity]</li>
<li class=""><strong>authors:</strong> Zhenwen Liang, Sidi Lu, Wenhao Yu, Kishan Panaganti, Yujun Zhou, Haitao Mi, Dong Yu</li>
<li class=""><strong>institution:</strong> Tencent AI Lab, University of Notre Dame</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15687</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces G2RL, a gradient-guided reinforcement learning framework that uses the model&#x27;s own gradient directions to guide exploration, rather than external heuristics like entropy bonuses. It shows that G2RL improves reasoning performance across multiple benchmarks by encouraging diverse and orthogonal update directions. The results indicate that a policy&#x27;s internal update geometry provides a more effective basis for exploration in LLM reinforcement learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] BashArena: A Control Setting for Highly Privileged AI Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [AI control, red teaming, blue teaming, adversarial evaluation, system administration tasks, sabotage detection, Linux environment, control protocols]</li>
<li class=""><strong>authors:</strong> Adam Kaufman, James Lucassen, Tyler Tracy, Cody Rushing, Aryan Bhatt</li>
<li class=""><strong>institution:</strong> Redwood Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15688" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15688</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces BashArena, a control setting with 637 Linux system administration tasks and sabotage objectives to study AI control techniques for highly privileged agents. It evaluates frontier LLMs in an adversarial game between red teams (performing sabotage) and blue teams (detecting it), finding that Claude Sonnet 4.5 can evade detection by GPT-4.1 mini 26% of the time, establishing a baseline for more effective control protocols.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [video-action model, flow matching, inverse dynamics model, imitation learning, vision-language-action model]</li>
<li class=""><strong>authors:</strong> Jonas Pai, Liam Achenbach, Victoriano Montesinos, Benedek Forrai, Oier Mees, Elvis Nava</li>
<li class=""><strong>institution:</strong> mimic robotics, Microsoft Zurich, ETH Zurich, ETH AI Center, UC Berkeley</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15692" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15692</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces mimic-video, a Video-Action Model that pairs a pretrained internet-scale video model with a flow matching-based action decoder to generate robot actions from video latent representations. This approach leverages video pretraining to capture both semantics and visual dynamics, isolating the control problem and achieving state-of-the-art performance with 10x greater sample efficiency compared to traditional Vision-Language-Action models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Artism: AI-Driven Dual-Engine System for Art Generation and Critique</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep learning, multi-agent systems, conceptual collage, AI-driven critical loops]</li>
<li class=""><strong>authors:</strong> Shuai Liu, Yiqing Tian, Yang Chen, Mar Canet Sola</li>
<li class=""><strong>institution:</strong> Academy of Media Arts Cologne, Goldsmiths University of London, Royal College of Art, Tallinn University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15710" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15710</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a dual-engine AI system called Artism, consisting of AIDA (an artificial artist social network) and the Ismism Machine for critique, to simulate art historical trajectories and conceptual innovation. The core method leverages deep learning and multi-agent collaboration to shift from unidirectional critique to an interactive, reflexive practice. It concludes by introducing a general AI-driven critical loop methodology, offering new possibilities for the computational analysis of art.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [predictive concept decoder, communication bottleneck, sparse concept list, encoder-decoder, auto-interp score, fine-tuning]</li>
<li class=""><strong>authors:</strong> Vincent Huang, Dami Choi, Daniel D. Johnson, Sarah Schwettmann, Jacob Steinhardt</li>
<li class=""><strong>institution:</strong> Transluce</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15712" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15712</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Predictive Concept Decoders (PCDs), an end-to-end trained architecture where an encoder compresses a model&#x27;s internal activations into a sparse list of concepts, and a decoder uses this list to answer questions about the model&#x27;s behavior. The method is pretrained on large datasets and then finetuned, showing that the interpretability and downstream performance of the bottleneck concepts improve with more data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Spatia: Video Generation with Updatable Spatial Memory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [spatial memory, 3D scene point cloud, visual SLAM, dynamic-static disentanglement, camera control, 3D-aware editing]</li>
<li class=""><strong>authors:</strong> Jinjing Zhao, Fangyun Wei, Zhening Liu, Hongyang Zhang, Chang Xu, Yan Lu</li>
<li class=""><strong>institution:</strong> The University of Sydney, Microsoft Research, HKUST, University of Waterloo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15716</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Spatia, a video generation framework that uses an updatable 3D scene point cloud as persistent spatial memory to enhance long-term spatial consistency. It iteratively generates video clips conditioned on this memory and updates it via visual SLAM, enabling applications like explicit camera control and 3D-aware interactive editing.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] PyFi: Toward Pyramid-like Financial Image Understanding for VLMs via Adversarial Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [adversarial agents, Monte Carlo Tree Search (MCTS), question chains, pyramid-like reasoning, vision language models (VLMs), fine-tuning, synthetic dataset]</li>
<li class=""><strong>authors:</strong> Yuqun Zhang, Yuxuan Zhao, Sijia Chen</li>
<li class=""><strong>institution:</strong> The Hong Kong University of Science and Technology (Guangzhou), Yantai Research Institute, Harbin Engineering University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14735" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14735</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PyFi, a framework that uses a multi-agent adversarial mechanism under Monte Carlo Tree Search to synthesize a large-scale, pyramid-structured financial image QA dataset without human annotation. Fine-tuning VLMs on this dataset enables them to decompose complex financial questions into simpler sub-questions, leading to significant accuracy improvements on the benchmark.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Scaling Causal Mediation for Complex Systems: A Framework for Root Cause Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [cluster infrastructure], [causal mediation analysis, directed acyclic graphs (DAGs), root cause analysis, multiple treatments, multiple mediators, effect decomposition]</li>
<li class=""><strong>authors:</strong> Alessandro Casadei, Sreyoshi Bhaduri, Rohit Malshe, Pavan Mullapudi, Raj Ratan, Ankush Pole, Arkajit Rakshit</li>
<li class=""><strong>institution:</strong> Amazon</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14764" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14764</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a scalable causal mediation analysis framework designed for complex systems represented by high-dimensional directed acyclic graphs with multiple interacting treatments and mediators. It systematically decomposes total effects into direct and indirect components to identify root causes. The method is demonstrated through case studies in fulfillment center logistics, showing its practical utility for diagnosing operational systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] VERAFI: Verified Agentic Financial Intelligence through Neurosymbolic Policy Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [neurosymbolic policy generation, agentic framework, dense retrieval, cross-encoder reranking, financial tool-enabled agents, GAAP compliance, SEC requirements, mathematical validation]</li>
<li class=""><strong>authors:</strong> Adewale Akinfaderin, Shreyas Subramanian</li>
<li class=""><strong>institution:</strong> Amazon Web Services</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14744" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14744</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces VERAFI, a framework that combines dense retrieval and cross-encoder reranking with financial tool-enabled agents and a neurosymbolic policy layer for automated reasoning and compliance checking. The integrated approach significantly improves factual correctness on financial benchmarks, demonstrating that incorporating domain-specific verification policies is crucial for achieving trustworthy financial AI.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Multiscale Cross-Modal Mapping of Molecular, Pathologic, and Radiologic Phenotypes in Lipid-Deficient Clear Cell Renal CellCarcinoma</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical imaging and computational pathology], [cross-modal mapping, multi-omics, computational pathology, radiomics, hierarchical modeling, molecular phenotyping]</li>
<li class=""><strong>authors:</strong> Ying Cui, Dongzhe Zheng, Ke Yu, Xiyin Zheng, Xiaorui Wang, Xinxiang Li, Yan Gu, Lin Fu, Xinyi Chen, Wenjie Mei, Xin-Gui Peng</li>
<li class=""><strong>institution:</strong> Southeast University, Princeton University, Columbia University, University of Science and Technology of China, Nanjing University, Lanzhou University of Technology, Lianyungang First People&#x27;s Hospital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14750" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14750</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper establishes a hierarchical cross-scale framework that uses cross-modal mapping to transfer molecular signatures to histological and CT imaging phenotypes for the preoperative identification of a high-risk renal cancer subtype. The method integrates multi-scale features from pathology (PathoDCCD) and radiology (RadioDCCD) to predict molecular subtypes. It demonstrates that this approach can reliably identify patients with the poorest clinical outcomes across multiple patient cohorts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Magnification-Aware Distillation (MAD): A Self-Supervised Framework for Unified Representation Learning in Gigapixel Whole-Slide Images</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computational pathology], [self-supervised learning, vision transformer, cross-scale distillation, magnification-invariant representation, whole-slide image analysis]</li>
<li class=""><strong>authors:</strong> Mahmut S. Gokmen, Mitchell A. Klusty, Peter T. Nelson, Allison M. Neltner, Sen-Ching Samson Cheung, Thomas M. Pearce, David A Gutman, Brittany N. Dugger, Devavrat S. Bisht, Margaret E. Flanagan, V. K. Cody Bumgardner</li>
<li class=""><strong>institution:</strong> University of Kentucky, University of Pittsburgh, Emory University, University of California Davis, University of Texas Health</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14796" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14796</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Magnification-Aware Distillation (MAD), a self-supervised framework that learns unified image representations by linking low-magnification context with spatially aligned high-magnification detail in whole-slide images. The resulting foundation model, MAD-NP, demonstrates strong resolution-invariant learning, as shown by a classifier trained on 10x embeddings maintaining 96.7% performance on unseen 40x tiles. The work concludes that this approach enables scalable, magnification-robust analysis using a unified embedding space.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Restless Multi-Process Multi-Armed Bandits with Applications to Self-Driving Microscopies</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [decision theory], [restless multi-armed bandits, Whittle index, Markov chains, Thompson Sampling, Bayesian UCB, epsilon-Greedy]</li>
<li class=""><strong>authors:</strong> Jaume Anguera Peris, Songtao Cheng, Hanzhao Zhang, Wei Ouyang, Joakim Jaldén</li>
<li class=""><strong>institution:</strong> KTH Royal Institute of Technology, SciLifeLab</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14930" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14930</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Restless Multi-Process Multi-Armed Bandit (RMPMAB) framework, which models experimental regions as ensembles of Markov chains to capture biological heterogeneity. It derives closed-form expressions for process behavior and designs scalable Whittle index policies. The method significantly outperforms existing bandit algorithms in simulations and live-cell imaging, capturing more biological events and reducing regret, demonstrating its potential for autonomous smart microscopy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Artificial Intelligence for the Assessment of Peritoneal Carcinosis during Diagnostic Laparoscopy for Advanced Ovarian Cancer</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [deep learning, video analysis, segmentation, classification, Fagotti score, diagnostic laparoscopy, Dice score, F1-score, RMSE]</li>
<li class=""><strong>authors:</strong> Riccardo Oliva, Farahdiba Zarin, Alice Zampolini Faustini, Armine Vardazaryan, Andrea Rosati, Vinkle Srivastav, Nunzia Del Villano, Jacques Marescaux, Giovanni Scambia, Pietro Mascagni, Nicolas Padoy, Anna Fagotti</li>
<li class=""><strong>institution:</strong> Fondazione Policlinico Universitario Agostino Gemelli IRCCS, Università Cattolica del Sacro Cuore, IRCAD, University of Strasbourg, IHU Strasbourg, Università degli studi di Modena</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.14797" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.14797</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a deep learning system to analyze diagnostic laparoscopy videos for advanced ovarian cancer, automating the assessment of peritoneal carcinosis and predicting the Fagotti score to guide surgical decisions. The AI model segments anatomical structures and tumor lesions, then classifies video-level features to estimate surgical feasibility. The results demonstrate reproducible performance, suggesting AI can standardize intraoperative tumor burden assessment and support clinical decision-making.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hierarchical deep reinforcement learning, double deep Q-network, constrained soft actor-critic, Lagrangian multipliers, centralized training and decentralized execution]</li>
<li class=""><strong>authors:</strong> Jiayang Wan, Ke He, Yafei Wang, Fan Liu, Wenjin Wang, Shi Jin</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories, University of Luxembourg</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15119" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15119</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a two-level hierarchical deep reinforcement learning framework for joint link selection and trajectory optimization in UAV mobility management within SAGIN. The method uses a top-level DDQN for discrete link selection and a lower-level constrained SAC with Lagrangian multipliers for continuous trajectory optimization under QoS constraints. Simulation results show the proposed scheme outperforms benchmarks in throughput, link switching frequency, and QoS satisfaction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251218] Meta-learners for few-shot weakly-supervised optic disc and cup segmentation on fundus images</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [meta-learning, few-shot learning, weakly-supervised segmentation, sparse labels, Omni meta-training, Efficient Omni ProtoSeg (EO-ProtoSeg)]</li>
<li class=""><strong>authors:</strong> Pandega Abyan Zumarsyah, Igi Ardiyanto, Hanung Adi Nugroho</li>
<li class=""><strong>institution:</strong> Universitas Gadjah Mada</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.15061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.15061</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes improved meta-learners for few-shot, weakly-supervised segmentation of the optic disc and cup in fundus images. The core method introduces Omni meta-training for balanced data usage and efficient versions to reduce computational costs, along with sparsification techniques for generating scribbles. The best model, EO-ProtoSeg, achieves high segmentation accuracy using only one sparsely labeled image, outperforming methods that require more labels and being comparable to heavier unsupervised domain adaptation approaches.</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-18T07:21:37.000Z" itemprop="dateModified">Dec 18, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/category/csai"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">cs.AI</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/csce"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.CE</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-18" class="table-of-contents__link toc-highlight">2025-12-18</a></li></ul></div></div></div></div></div><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div>
</body>
</html>