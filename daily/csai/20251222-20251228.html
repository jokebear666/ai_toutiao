<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_AI/20251222-20251228" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251222-20251228 (cs.AI) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251222-20251228 (cs.AI) | AI头条"><meta data-rh="true" name="description" content="2025-12-22"><meta data-rh="true" property="og:description" content="2025-12-22"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.AI","item":"https://jokebear666.github.io/ai_toutiao/daily/csai"},{"@type":"ListItem","position":3,"name":"20251222-20251228 (cs.AI)","item":"https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.84a25bac.css">
<script src="/ai_toutiao/assets/js/runtime~main.36d5e77f.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.e61b1501.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Collapse sidebar category &#x27;cs.AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><span title="20251215-20251221 (cs.AI)" class="linkLabel_WmDU">20251215-20251221 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/csai/20251222-20251228"><span title="20251222-20251228 (cs.AI)" class="linkLabel_WmDU">20251222-20251228 (cs.AI)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/csai"><span>cs.AI</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251222-20251228 (cs.AI)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251222-20251228 (cs.AI)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-22">2025-12-22<a href="#2025-12-22" class="hash-link" aria-label="Direct link to 2025-12-22" title="Direct link to 2025-12-22" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251222] Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge representation and reasoning], [entity set expansion, expansion graph, logical formula, semantic inclusion, computational complexity]</li>
<li class=""><strong>authors:</strong> Pietro Cofone, Giovanni Amendola, Marco Manna, Aldo Ricioppo</li>
<li class=""><strong>institution:</strong> University of Calabria, University of Cyprus</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16953" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16953</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a logic-based framework using expansion graphs, which are rooted directed acyclic graphs, to support taxonomic expansions of entity sets from knowledge bases. To avoid the impracticality of fully materializing these potentially large graphs, the authors formalize efficient reasoning tasks to check relationships between entity tuples within the graph structure. Their main conclusion is that, under realistic assumptions like bounded input, these tasks can be implemented efficiently, enabling local and incremental navigation without full graph construction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Lights, Camera, Consistency: A Multistage Pipeline for Character-Stable AI Video Stories</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [visual anchoring, asset-first mechanism, temporal bridge, diffusion models, large language model (LLM), text-to-video (T2V), character consistency, multi-stage pipeline]</li>
<li class=""><strong>authors:</strong> Chayan Jain, Rishant Sharma, Archit Garg, Ishan Bhanuka, Pratik Narang, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> BITS Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16954</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-stage pipeline for generating long, character-consistent video stories. It uses an LLM to create a script, a text-to-image model to design consistent character visuals as anchors, and a video generation model to synthesize scenes individually, with a temporal bridge linking them. The method&#x27;s necessity is validated by showing that removing visual anchoring causes a catastrophic drop in character consistency, and cultural biases in current models are also analyzed.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Enhancing Tree Species Classification: Insights from YOLOv8 and Explainable AI Applied to TLS Point Cloud Projections</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [YOLOv8, Finer-CAM, saliency maps, cross-validation, TLS point cloud projections]</li>
<li class=""><strong>authors:</strong> Adrian Straker, Paul Magdon, Marco Zullich, Maximilian Freudenberg, Christoph Kleinn, Johannes Breidenbach, Stefano Puliti, Nils Nölke</li>
<li class=""><strong>institution:</strong> University of Applied Sciences and Art (HAWK), University of Groningen, University of Göttingen, Norwegian Institute of Bioeconomy Research (NIBIO)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16950</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel method that links Finer-CAM explanations to structural segments in TLS point cloud projections to evaluate which features drive tree species classification using YOLOv8 models. The analysis of saliency maps reveals that models primarily rely on crown features for classification, with stem features being more important for certain species, and that the models&#x27; perception of species similarity aligns with human expert judgment. The results underscore the need for explainable AI to understand model decision processes and build confidence in predictions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Optimizing Text Search: A Novel Pattern Matching Algorithm Based on Ukkonen&#x27;s Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [pattern matching algorithms], [Ukkonen&#x27;s Algorithm, Suffix Trees, pattern recognition, text-search algorithms]</li>
<li class=""><strong>authors:</strong> Xinyu Guan, Shaohua Zhang</li>
<li class=""><strong>institution:</strong> Not specified</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16927" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16927</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a novel pattern matching algorithm that combines Ukkonen&#x27;s Algorithm for constructing Suffix Trees with a new search technique using Python&#x27;s dynamic link attributes. The optimized algorithm demonstrates linear time and space efficiency, outperforming traditional methods like Naive Search, KMP, and Boyer-Moore, and achieves 100% accuracy in tasks such as genomic sequence pattern recognition.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] V-Agent: An Interactive Video Search System Using Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [vision-language model, fine-tuning, retrieval vector, re-ranking, multi-agent system]</li>
<li class=""><strong>authors:</strong> SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju</li>
<li class=""><strong>institution:</strong> NC AI, Kakao, Korea Advanced Institute of Science and Technology (KAIST)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16925</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> V-Agent is a multi-agent video search system that fine-tunes a vision-language model with a small video preference dataset and enhances it with a retrieval vector to embed video frames and audio transcriptions into a shared multimodal space. It uses three agents—routing, search, and chat—to refine searches and interact with users, achieving state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PAACE: A Plan-Aware Automated Agent Context Engineering Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [context engineering, plan-aware compression, next-k-task relevance, instruction co-refinement, function-preserving compression, synthetic data generation, knowledge distillation]</li>
<li class=""><strong>authors:</strong> Kamer Ali Yuksel</li>
<li class=""><strong>institution:</strong> aiXplain Inc</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16970</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, long-term memory, semantic imitation, indirect injection attack, memory poisoning, MetaGPT, DataInterpreter]</li>
<li class=""><strong>authors:</strong> Saksham Sahai Srivastava, Haoyu He</li>
<li class=""><strong>institution:</strong> University of Georgia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16962" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16962</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MemoryGraft, a novel attack that poisons an LLM agent&#x27;s long-term memory by implanting malicious successful experiences, which are then retrieved and imitated during future tasks. The method exploits the agent&#x27;s semantic imitation heuristic through a poisoned RAG store, leading to persistent behavioral compromise. The authors demonstrate that this attack can cause significant and stealthy behavioral drift in agents like MetaGPT&#x27;s DataInterpreter.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [discrete video tokenization, transformer-based adaptive compressor, evidence lower bound (ELBO), information-theoretic compression, adaptive tokenization]</li>
<li class=""><strong>authors:</strong> Haotian Ye, Qiyuan He, Jiaqi Han, Puheng Li, Jiaojiao Fan, Zekun Hao, Fitsum Reda, Yogesh Balaji, Huayu Chen, Sheng Liu, Angela Yao, James Zou, Stefano Ermon, Haoxiang Wang, Ming-Yu Liu</li>
<li class=""><strong>institution:</strong> NVIDIA, Stanford University, National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16975" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16975</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da83017a41e69234160f2c416b8a94507a537a66fd8a745a6bafc49c06817395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da83017a41e69234160f2c416b8a94507a537a66fd8a745a6bafc49c06817395_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces InfoTok, a principled framework for adaptive discrete video tokenization based on information theory, using a novel ELBO-based algorithm and a transformer-based adaptive compressor. It achieves state-of-the-art compression by allocating tokens according to informational richness, saving 20% of tokens without performance loss and outperforming prior heuristic approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific ai evaluation], [Practical Inquiry Model (PIM), SGI-Bench, Test-Time Reinforcement Learning (TTRL), retrieval-augmented novelty, agent-based evaluation]</li>
<li class=""><strong>authors:</strong> Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu</li>
<li class=""><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [search engine audit, semantic alignment, topical annotation, trajectory analysis]</li>
<li class=""><strong>authors:</strong> Erica Coppolillo, Simone Mungari</li>
<li class=""><strong>institution:</strong> University of Calabria, ICAR-CNR, University of Southern California</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17027</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper conducts a comparative audit of search engine recommendations on Wikipedia and Grokipedia by analyzing over 70,000 results from nearly 10,000 neutral English word queries. It finds that both platforms frequently generate weakly related or unexpected results from innocuous queries, though their recommendation sets often differ substantially in topical distribution and exploration trajectories.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Women&#x27;s Health Benchmark for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [healthcare AI evaluation], [women&#x27;s health benchmark, large language models, error types, model stumps, query types]</li>
<li class=""><strong>authors:</strong> Victoria-Elisabeth Gruber, Razvan Marinescu, Diego Fajardo, Amin H. Nassar, Christopher Arkfeld, Alexandria Ludlow, Shama Patel, Mehrnoosh Samaei, Valerie Klug, Anna Huber, Marcel Gühner, Albert Botta i Orfila, Irene Lagoja, Kimya Tarr, Haleigh Larson, Mary Beth Howard</li>
<li class=""><strong>institution:</strong> Lumos AI, Yale Cancer Center, Harvard Medical School, UCSF, Brown University, Emory University, Clinic Ottakring, NHS, Yale School of Medicine, Johns Hopkins University School of Medicine</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17028</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Women&#x27;s Health Benchmark (WHB), a novel evaluation framework comprising 96 validated model stumps across five medical specialties, three query types, and eight error types to assess LLM performance in women&#x27;s health. It finds that current LLMs have approximately 60% failure rates, with significant weaknesses in detecting urgency, indicating they are not yet reliable for providing women&#x27;s health advice.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Security Risks of Agentic Vehicles: A Systematic Analysis of Cognitive and Cross-Layer Threats</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [agentic AI, cross-layer threats, role-based architecture, severity matrix, attack-chain analysis, OWASP]</li>
<li class=""><strong>authors:</strong> Ali Eslami, Jiangbo Yu</li>
<li class=""><strong>institution:</strong> Unknown</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17041" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17041</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a role-based architecture for Agentic Vehicles to systematically analyze security threats, including cognitive vulnerabilities and cross-layer risks. It concludes by providing a structured framework for assessing how small distortions can escalate into unsafe behavior in both human-driven and autonomous vehicles.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adversarial attacks, deep learning, cybersickness detection, visual tunneling, MI-FGSM, PGD, C&amp;W, DeepTCN, Transformer]</li>
<li class=""><strong>authors:</strong> Istiak Ahmed, Ripan Kumar Kundu, Khaza Anuarul Hoque</li>
<li class=""><strong>institution:</strong> University of Missouri-Columbia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17029" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17029</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Adversarial-VR, an open-source Unity testbed that integrates DeepTCN and Transformer models for real-time cybersickness detection and mitigation, and evaluates their robustness against adversarial attacks like MI-FGSM, PGD, and C&amp;W. The results show these attacks can successfully fool the system, significantly degrading model accuracy and preventing correct mitigation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge graph question answering], [reinforcement learning, subgraph selection, graph pruning, llm fine-tuning, relation-centric reasoning]</li>
<li class=""><strong>authors:</strong> Yinxu Tang, Chengsong Huang, Jiaxin Huang, William Yeoh</li>
<li class=""><strong>institution:</strong> Washington University in St. Louis</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces UniRel-R1, a framework for relation-centric knowledge graph question answering that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The method is designed to identify compact and informative subgraph answers by rewarding specific relations and lower-degree entities. Experiments show it outperforms baselines in connectivity and reward and generalizes well to unseen entities and relations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [social simulation], [large language model, generative agents, causal analysis, intergroup conflict, threat perception]</li>
<li class=""><strong>authors:</strong> Suhaib Abdurahman, Farzan Karimi-Malekabadi, Chenxiao Yu, Nour S. Kteily, Morteza Dehghani</li>
<li class=""><strong>institution:</strong> University of Southern California, Northwestern University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17066</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses simulations with LLM-driven generative agents in virtual societies to causally analyze intergroup conflict. It finds that realistic threat directly increases hostility, while symbolic threat has a weaker effect mediated by ingroup bias and only increases hostility when realistic threat is absent.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [knowledge distillation, chain-of-thought, structured reasoning, query execution plan, text-to-sql]</li>
<li class=""><strong>authors:</strong> Khushboo Thaker, Yony Bresler</li>
<li class=""><strong>institution:</strong> Crater Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Struct-SQL, a knowledge distillation framework that trains a small language model using a structured chain-of-thought derived from query execution plans, rather than unstructured reasoning traces. The distilled model achieves an 8.1% absolute improvement over an unstructured baseline, primarily due to a reduction in syntactic errors. This demonstrates that structured logical blueprints are beneficial for reliable SQL generation in small models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bots Don&#x27;t Sit Still: A Longitudinal Study of Bot Behaviour Change, Temporal Drift, and Feature-Structure Evolution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [social media analysis], [Augmented Dickey-Fuller test, KPSS test, Spearman correlation, Chi-square test, time series analysis, stationarity testing]</li>
<li class=""><strong>authors:</strong> Ohoud Alzahrani, Russell Beale, Bob Hendley</li>
<li class=""><strong>institution:</strong> University of Birmingham</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17067" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17067</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a longitudinal study analyzing the temporal behavior of promotional Twitter bots using time series analysis and statistical tests on ten content-based meta-features. It finds that bot behavior is non-stationary, with individual features and their interdependencies evolving systematically over time and across bot generations. The conclusion is that bot-detection systems must account for this dynamic adaptation and avoid treating behavioral features as static.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent system, transactional analysis, ego states, information retrieval, vector stores, ablation test]</li>
<li class=""><strong>authors:</strong> Monika Zamojska, Jarosław A. Chudziak</li>
<li class=""><strong>institution:</strong> Warsaw University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17060" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17060</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent system architecture that integrates Transactional Analysis theory, dividing each agent into Parent, Adult, and Child ego states, and enhances their responses with contextual information retrieval from vector stores. The system is evaluated through ablation tests in a simulated dialogue scenario. The results show that this psychologically grounded structure improves the realism of LLM-based agent behavior.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [mathematical reasoning], [chain-of-thought prompting, reinforcement learning, GRPO, fine-tuning, error recovery]</li>
<li class=""><strong>authors:</strong> Saraswathy Amjith, Mihika Dusad, Neha Muramalla, Shweta Shah</li>
<li class=""><strong>institution:</strong> MIT</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17079" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17079</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper fine-tunes the Qwen3-4B model using GRPO reinforcement learning on intentionally flawed chain-of-thought reasoning traces to improve error detection and recovery. It finds that this mixed training on both calculation and reasoning errors improves robustness to misleading prefills without sacrificing accuracy on clean problems, unlike standard fine-tuning which degrades robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [dialogue topic segmentation], [window-tolerant F1, boundary density, segment coherence, granularity-aware evaluation]</li>
<li class=""><strong>authors:</strong> Michael H. Coen</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17083" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17083</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a new evaluation framework for dialogue topic segmentation that emphasizes boundary density and segment coherence alongside window-tolerant F1. It demonstrates through cross-dataset experiments that reported performance differences are often artifacts of annotation granularity mismatches, not model quality. The core conclusion is that topic segmentation should be viewed as selecting an appropriate granularity rather than predicting a single correct boundary set.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Value Under Ignorance in Universal Artificial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [AIXI, Choquet integrals, imprecise probability theory, semimeasure loss, utility functions]</li>
<li class=""><strong>authors:</strong> Cole Wyeth, Marcus Hutter</li>
<li class=""><strong>institution:</strong> University of Waterloo, Google DeepMind, Australian National University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17086</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper generalizes the AIXI reinforcement learning agent to handle a wider class of utility functions, confronting the ambiguity of finite history predictions by interpreting belief distributions as imprecise probabilities. It explores computing expected utilities using Choquet integrals from imprecise probability theory and investigates their computability. The authors show that the standard recursive value function is a special case, but the most general utilities under a &quot;death interpretation&quot; cannot be characterized by these integrals.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] How to Square Tensor Networks and Circuits Without Squaring Them</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [probabilistic modeling], [tensor networks, squared circuits, probabilistic circuits, marginalization, canonical forms, unitary matrices, distribution estimation]</li>
<li class=""><strong>authors:</strong> Lorenzo Loconte, Adrián Javaloy, Antonio Vergari</li>
<li class=""><strong>institution:</strong> University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17090" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17090</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method to parameterize squared circuits (a generalization of squared tensor networks) using conditions inspired by orthogonality and determinism, enabling efficient marginalization without squaring. This approach overcomes computational overhead while maintaining expressiveness for distribution estimation. Experiments confirm the method allows more efficient learning without loss of expressiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, model predictive control, MPPI, hierarchical planning, adaptive sampling]</li>
<li class=""><strong>authors:</strong> Toshiaki Hori, Jonathan DeCastro, Deepak Gopinath, Avinash Balachandran, Guy Rosman</li>
<li class=""><strong>institution:</strong> Toyota Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17091</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that fuses reinforcement learning and model-predictive control (MPC) into an adaptive hierarchical framework. It uses RL actions to guide the MPPI sampler and adaptively aggregates MPPI samples to improve value estimation, leading to more robust and sample-efficient policies. The approach demonstrates improved data efficiency, performance, and convergence speed in domains like race driving and Lunar Lander.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretability], [counterfactual explanations, model-agnostic, time series, ECG, LIME, SHAP]</li>
<li class=""><strong>authors:</strong> Justin Li, Efe Sencan, Jasper Zheng Duan, Vitus J. Leung, Stephan Tsaur, Ayse K. Coskun</li>
<li class=""><strong>institution:</strong> Boston University, Sandia National Laboratories, Boston Medical Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17100</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces UniCoMTE, a universal, model-agnostic framework for generating counterfactual explanations for time series classifiers by modifying input samples to identify influential temporal features. It is evaluated on an ECG classifier and shown to produce more concise, stable, and human-aligned explanations than established methods like LIME and SHAP, thereby improving model interpretability for real-world applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [solver-in-the-loop, instruction-tuning, supervised fine-tuning, best-of-N sampling, answer set programming, semantic parsing]</li>
<li class=""><strong>authors:</strong> Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich</li>
<li class=""><strong>institution:</strong> Bosch Center for AI, University of Augsburg, ScaDS.AI &amp; TU Dresden</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17093" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17093</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a solver-in-the-loop framework that uses an ASP solver to provide feedback on LLM-generated code, creating a dataset of chosen and rejected instances for supervised fine-tuning. The method improves LLM performance on generating Answer Set Programming code for logic puzzles, demonstrating consistent gains across different prompting settings and datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Reinforcement Learning for Self-Improving Agent with Skill Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [reinforcement learning, skill library, sequential rollout, skill-integrated reward, GRPO, self-improving agent]</li>
<li class=""><strong>authors:</strong> Jiongxiao Wang, Qiaojing Yan, Yawei Wang, Yijun Tian, Soumya Smruti Mishra, Zhichao Xu, Megha Gandhi, Panpan Xu, Lin Lee Cheong</li>
<li class=""><strong>institution:</strong> University of Wisconsin–Madison, AWS Agentic AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17102" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17102</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SAGE, a reinforcement learning framework that enhances LLM-based agents by integrating a skill library through sequential rollouts and a skill-integrated reward. This approach enables agents to accumulate and reuse skills across tasks for continual self-improvement. Experiments show SAGE improves task completion accuracy while significantly reducing interaction steps and token usage compared to existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Generalized Primal Averaging (GPA), DiLoCo, Schedule-Free, AdamW, Nesterov&#x27;s method, primal averaging, optimizer, iterate averaging]</li>
<li class=""><strong>authors:</strong> Aaron Defazio, Konstantin Mishchenko, Parameswaran Raman, Hao-Jun Michael Shi, Lin Xiao</li>
<li class=""><strong>institution:</strong> Meta Superintelligence Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17131</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Generalized Primal Averaging (GPA), a new optimizer that extends Nesterov&#x27;s method to perform smooth, per-step averaging of model iterates, addressing limitations of periodic averaging methods like single-worker DiLoCo. It demonstrates that GPA outperforms single-worker DiLoCo, simplifies hyperparameter tuning, reduces memory overhead, and achieves significant speedups in training LLMs and vision models compared to AdamW.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep unrolled model, Restormer, learned coil sensitivity map estimator, sampling-aware weighted data consistency, universal conditioning, progressive cascade expansion training]</li>
<li class=""><strong>authors:</strong> Puyang Wang, Pengfei Guo, Keyi Chai, Jinyuan Zhou, Daguang Xu, Shanshan Jiang</li>
<li class=""><strong>institution:</strong> Johns Hopkins University, NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17137" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17137</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SDUM, a scalable deep unrolled model for universal MRI reconstruction that integrates a Restormer-based reconstructor, learned coil sensitivity estimation, and sampling-aware data consistency. It demonstrates predictable performance scaling with model depth and achieves state-of-the-art results across diverse clinical MRI protocols without task-specific fine-tuning. The work establishes a practical framework for a single, universally applicable reconstruction model in clinical environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [algorithmic information theory], [Solomonoff induction, Bayesian Model Averaging, hypothesis ranking, systematic generalisation, uncertainty estimation]</li>
<li class=""><strong>authors:</strong> Josh Barber, Rourke Young, Cameron Coombe, Will Browne</li>
<li class=""><strong>institution:</strong> Queensland University of Technology, CSIRO</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17145</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that uses a Solomonoff-inspired scoring to weight hypotheses generated by a Large Language Model based on their simplicity and predictive fit. The method, applied to Mini-ARC tasks, produces uncertainty-aware predictions by spreading probability across multiple hypotheses, contrasting with Bayesian Model Averaging which tends to concentrate weight on a single candidate. The results highlight the value of algorithmic information-theoretic priors for robust, interpretable reasoning under uncertainty.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [interactive reinforcement learning, multi-teacher learning, Q-learning, teacher selection, concept drift]</li>
<li class=""><strong>authors:</strong> Maher Mesto, Francisco Cruz</li>
<li class=""><strong>institution:</strong> University of New South Wales, Universidad Central de Chile</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17180</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a multi-teacher interactive reinforcement learning framework where agents can select advice from teachers with different reward structures. The core finding is that agents exhibit a strong conservative bias, overwhelmingly preferring low-reward but consistent teachers over high-reward ones, which challenges traditional reward-maximization assumptions in RL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language model, explainable ai, augmented reality, personalized explanations, real-time object detection, user study]</li>
<li class=""><strong>authors:</strong> Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque</li>
<li class=""><strong>institution:</strong> University of Missouri-Columbia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17172" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17172</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes PILAR, a framework that uses a pre-trained large language model (LLM) to generate unified, context-aware, and personalized explanations for AI-driven augmented reality systems. A user study on a recipe recommendation prototype showed that the LLM-based explanation interface significantly improved user task performance and perceived transparency compared to a traditional template-based approach.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [reinforcement learning, fine-tuning, retrieval-augmented generation, multi-modal large language models, explainable AI]</li>
<li class=""><strong>authors:</strong> Shengwei Zhao, Jingwen Yao, Sitong Wei, Linhai Xu, Yuying Liu, Dong Zhang, Zhiqiang Tian, Shaoyi Du</li>
<li class=""><strong>institution:</strong> Xi’an Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17194" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17194</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MMRAG-RFT, a two-stage reinforcement fine-tuning framework for explainable multi-modal retrieval-augmented generation. The method uses rule-based and reasoning-based reinforcement learning to filter documents and jointly optimize ranking and answer generation, achieving state-of-the-art results on benchmark datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [unified multimodal model, benchmark, omni-dimensional evaluation, understanding, generation, editing]</li>
<li class=""><strong>authors:</strong> Kai Liu, Leyang Chen, Wenbo Li, Zhikai Chen, Zhixin Wang, Renjing Pei, Linghe Kong, Yulun Zhang</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University, The Chinese University of Hong Kong, Huawei Technologies Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17196" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17196</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dffc23613309b3df00996da4dd30419c4aa81ea36355df55ab509eed8b7380c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dffc23613309b3df00996da4dd30419c4aa81ea36355df55ab509eed8b7380c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces UmniBench, a benchmark designed to holistically evaluate Unified Multimodal Models (UMMs) by assessing their understanding, generation, and editing abilities within a single process, using the model&#x27;s own understanding capability to judge its outputs. It covers 13 domains and over 200 concepts to provide comprehensive and fine-grained assessments. The authors benchmark 24 models and conclude that UmniBench offers a more integrated and objective evaluation framework compared to isolated, task-specific benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fose: Fusion of One-Step Diffusion and End-to-End Network for Pansharpening</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [one-step distillation, lightweight ensemble blocks, four-stage training, pansharpening, diffusion model, end-to-end network]</li>
<li class=""><strong>authors:</strong> Kai Liu, Zeli Lin, Weibo Wang, Linghe Kong, Yulun Zhang</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17202</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Fose, a lightweight network for pansharpening that fuses a one-step diffusion model and an end-to-end network using a novel four-stage training strategy. It uses one-step distillation to compress a diffusion model&#x27;s inference from 50 steps to 1 and integrates it with an E2E model via lightweight ensemble blocks. The method achieves better performance than state-of-the-art approaches and a 7.42x speedup compared to the baseline diffusion model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [robotics and navigation], [extended kalman filter, inertial measurement unit, wheel odometer, dead reckoning]</li>
<li class=""><strong>authors:</strong> Yan Gao, Jiliang Wang, Minghan Wang, Xiaohua Chen, Demin Chen, Zhiyong Ren, Tian-Yun Huang</li>
<li class=""><strong>institution:</strong> Peking University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52e181750dd60029c711d4a23702ec5e96a39d86b1ce8c7f9c34de75f853c369_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52e181750dd60029c711d4a23702ec5e96a39d86b1ce8c7f9c34de75f853c369_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a dead reckoning method for a self-propelled pipeline robot, using an IMU for initial attitude estimation, refining it with an Extended Kalman Filter, and combining it with wheel odometer data for localization. The method was tested in a rectangular loop pipeline, and the results verified the effectiveness of the proposed algorithm for navigating complex three-dimensional pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] The Role of Islamic Ethics in Preventing the Abuse of Artificial Intelligence (AI) Based Deepfakes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [ethics and society], [Systematic Literature Review (SLR), PRISMA, Maqasid al-Shariah, hifz al-ird, hifz al-nafs, adl, tabayyun]</li>
<li class=""><strong>authors:</strong> Wisnu Uriawan, Imany Fauzy Rahman, Muhamad Zidan, Irma Rohmatillah, Muhammad Arkan Raihan, Irma Dwiyanti</li>
<li class=""><strong>institution:</strong> UIN Sunan Gunung Djati Bandung</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17218" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17218</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study employs a Systematic Literature Review (SLISMA) to formulate an Islamic ethical framework for preventing deepfake abuse. It concludes that principles from Maqasid al-Shariah, such as protecting honor and self, provide a normative basis for shifting from punitive to preventative approaches, focusing on human dignity and the common good in the digital age.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [error level noise embedding, n-best hypotheses, noise-aware modeling, whisper, llama-2, word error rate, fine-tuning]</li>
<li class=""><strong>authors:</strong> Zahra Rahmani, Hossein Sameti</li>
<li class=""><strong>institution:</strong> Sharif University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17247</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a robust noise-sensitive ASR error correction framework for Persian. It introduces Error Level Noise (ELN) embeddings, derived from disagreements in multiple ASR hypotheses, to condition a fine-tuned LLaMA-2 model, enabling it to reason about noise-induced uncertainty. The ELN-conditioned model significantly reduces Word Error Rate compared to text-only baselines, demonstrating the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust speech recognition in noisy environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Privacy-Preserving Synthetic Dataset of Individual Daily Trajectories for City-Scale Mobility Analytics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [privacy-preserving data synthesis], [multi-objective optimization, origin-destination matrices, dwell-travel time quantiles, universal law of daily visited locations, synthetic trajectory generation]</li>
<li class=""><strong>authors:</strong> Jun&#x27;ichi Ozaki, Ryosuke Susuta, Takuhiro Moriyama, Yohei Shida</li>
<li class=""><strong>institution:</strong> Not explicitly provided; cannot infer from given information.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17239" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17239</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method to generate a privacy-preserving synthetic dataset of individual daily trajectories by integrating aggregated origin-destination flows with behavioral constraints in a multi-objective optimization framework. The method successfully reproduces realistic human mobility patterns in two Japanese regions, providing a practical pathway for high-resolution mobility analytics without using sensitive personal data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [differential privacy, local differential privacy, RAPPOR, PAC indistinguishability, hybrid privacy, rarity-aware protection]</li>
<li class=""><strong>authors:</strong> Madhava Gaikwad</li>
<li class=""><strong>institution:</strong> Microsoft</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17251</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes AlignDP, a hybrid privacy mechanism that protects large language models by separating data into rare and non-rare fields. Rare fields are shielded with PAC indistinguishability for strong privacy, while non-rare fields are privatized using RAPPOR to allow useful frequency estimation. This approach aims to prevent knowledge extraction and unauthorized fine-tuning by design, making models more secure against distillation and editing attacks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [speculative execution, TD-MPC2, latent-space MPC, mismatch correction, action queue, transformer corrector]</li>
<li class=""><strong>authors:</strong> Ziyang Lin, Zixuan Sun, Sanhorn Chen, Xiaoyang Chen, Roy Zhao</li>
<li class=""><strong>institution:</strong> University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17250" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17250</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/801e0aab9fd9dcfb7d20ebc658880a9fa5c22a62c30b2127c1037ab48024b399_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/801e0aab9fd9dcfb7d20ebc658880a9fa5c22a62c30b2127c1037ab48024b399_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a speculation-and-correction framework to reduce inference latency in real-time control agents. It uses a world model to predict future actions and latent states, then applies a lightweight learned corrector to adjust these actions when new observations arrive, reducing planning calls by 43.6% with minimal performance loss. The results show that correction is essential for reliable latency reduction in sequential control tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [audit agents, attestation protocols, constrained reasoning, cryptographic attestation, symbolic methods, benchmark suite, verifiability]</li>
<li class=""><strong>authors:</strong> Abhivansh Gupta</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology, Roorkee</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17259" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17259</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Verifiability-First architecture for LLM-based agents, integrating runtime attestations, lightweight audit agents for continuous verification, and challenge-response protocols for high-risk operations. It introduces the OPERA benchmark to evaluate the detectability and speed of remediation for misaligned behavior, shifting the focus from measuring the propensity for misalignment to ensuring reliable detection and control.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [GPT-style transformer, autoregressive next-event prediction, player embeddings, counterfactual simulation, residual On-Ball Value (rOBV)]</li>
<li class=""><strong>authors:</strong> Miru Hong, Minho Lee, Geonhee Jo, Jae-Hee So, Pascal Bauer, Sang-Ki Ko</li>
<li class=""><strong>institution:</strong> University of Seoul, Saarland University, Bank of Korea</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17266" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17266</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ScoutGPT, a GPT-based autoregressive transformer model that treats football match events as discrete token sequences to predict the next action and its value, conditioned on player identity. It enables counterfactual simulations by swapping player embeddings to assess how a player&#x27;s performance might change in a new tactical context. Evaluated on Premier League data, the model outperforms baselines in prediction accuracy and provides a principled framework for evaluating player transfer fit.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [evaluation framework], [LLM-as-a-Judge, regression, MetricBank, retrieval, human feedback correlation]</li>
<li class=""><strong>authors:</strong> Michael J. Ryan, Yanzhe Zhang, Amol Salunkhe, Yi Chu, Di Xu, Diyi Yang</li>
<li class=""><strong>institution:</strong> Stanford University, American Express</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17267" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17267</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AutoMetrics, a framework that synthesizes evaluation metrics by combining retrieved metrics from a curated bank with automatically generated LLM-as-a-Judge criteria, composed via regression to maximize correlation with human feedback. It demonstrates that AutoMetrics significantly improves correlation with human judgments over standard LLM-as-a-Judge approaches while requiring minimal human feedback data. The method can serve as an effective proxy reward for optimizing AI applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Understanding Generalization in Role-Playing Models via Information Theory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [natural language processing], [information theory, mutual information, reinforcement learning, distribution shift, role-playing models]</li>
<li class=""><strong>authors:</strong> Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li</li>
<li class=""><strong>institution:</strong> Wuhan University, Tongyi Lab, Zhongguancun Academy</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17270" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17270</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] WDFFU-Mamba: A Wavelet-guided Dual-attention Feature Fusion Mamba for Breast Tumor Segmentation in Ultrasound Images</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical image segmentation], [wavelet-guided enhancement, dual-attention feature fusion, U-shaped Mamba architecture, Wavelet-denoised High-Frequency-guided Feature (WHF), Dual Attention Feature Fusion (DAFF)]</li>
<li class=""><strong>authors:</strong> Guoping Cai, Houjin Chen, Yanfeng Li, Jia Sun, Ziwei Chen, Qingzi Geng</li>
<li class=""><strong>institution:</strong> Beijing Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17278" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17278</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes WDFFU-Mamba, a novel network for breast ultrasound image segmentation that integrates wavelet-guided enhancement and dual-attention feature fusion within a U-shaped Mamba architecture. It demonstrates superior segmentation accuracy and robustness on public datasets, making it a promising tool for clinical applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Subjective Question Generation and Answer Evaluation using NLP</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [large language models, instruct-tuning, bloom&#x27;s taxonomy, subjective evaluation, question generation, answer evaluation]</li>
<li class=""><strong>authors:</strong> G. M. Refatul Islam, Safwan Shaheer, Yaseen Nur, Mohammad Rafid Hamid</li>
<li class=""><strong>institution:</strong> Brac University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17289" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17289</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This research proposes a framework that uses instruct-tuned large language models (LLMs) to generate subjective questions and evaluate student answers, particularly for higher-order thinking skills. The study concludes that this approach can effectively automate the assessment of complex, subjective understanding, a task traditionally requiring human evaluators.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memristive architecture, minion recurrent unit, weighted-bit streaming, experience replay, mixed-signal accelerator, on-chip continual learning]</li>
<li class=""><strong>authors:</strong> Abdullah M. Zyarah, Dhireesha Kudithipudi</li>
<li class=""><strong>institution:</strong> University of Texas at San Antonio, University of Baghdad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17299</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces M2RU, a mixed-signal hardware architecture that implements the Minion Recurrent Unit for efficient on-chip continual learning at the edge. It uses weighted-bit streaming and experience replay to enable energy-efficient temporal processing and stable adaptation. The results show significant energy efficiency improvements and a long operational lifetime, establishing M2RU as a scalable platform for edge-level temporal intelligence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Robust TTS Training via Self-Purifying Flow Matching for the WildSpoof 2026 TTS Track</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [Self-Purifying Flow Matching (SPFM), flow matching, text-to-speech (TTS), Supertonic, fine-tuning, in-the-wild speech, label noise mitigation]</li>
<li class=""><strong>authors:</strong> June Young Yi, Hyeongju Kim, Juheon Lee</li>
<li class=""><strong>institution:</strong> Supertone Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17293" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17293</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a lightweight TTS system that fine-tunes the Supertonic model using Self-Purifying Flow Matching (SPFM) to robustly adapt to noisy, in-the-wild speech data. SPFM handles label noise by comparing conditional and unconditional flow matching losses, routing suspicious samples for unconditional training while still using their acoustic information. The resulting model achieved the best word error rate in the WildSpoof 2026 challenge, demonstrating that open-weight architectures can be effectively adapted to real-world conditions with explicit noise-handling mechanisms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language models, turn-based battle system, strategic decision-making, content generation, procedural generation, adaptive difficulty]</li>
<li class=""><strong>authors:</strong> Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> Birla Institute of Technology and Science, Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17308" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17308</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a turn-based Pokémon battle system where LLMs act as agents, making tactical decisions based on a structured battle state without domain-specific training. The core method involves evaluating LLMs on strategic reasoning and their ability to generate novel game content. The main conclusion is that LLMs can function as dynamic game opponents and designers, offering a practical alternative to reinforcement learning for strategic games.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [explainable AI (XAI)], [graph theory, model decomposition, hypothesis-evidence structure, Cox proportional hazards model, PREDICT]</li>
<li class=""><strong>authors:</strong> Michael Merry, Pat Riddle, Jim Warren</li>
<li class=""><strong>institution:</strong> University of Auckland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17316" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17316</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a formal, testable criterion for inherent explainability in AI, using graph theory to decompose models into verifiable structure-local explanations called annotations. The method is applied to demonstrate the inherent explainability of a clinical cardiovascular risk model (PREDICT). The work provides a rigorous foundation for regulators and formalizes the distinction between an explainable model and an explained one.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Benchmark for Ultra-High-Resolution Remote Sensing MLLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [remote sensing, multimodal evaluation], [RSHR-Bench, adversarial filtering, high-resolution imagery, multimodal large language models, visual question answering, image captioning]</li>
<li class=""><strong>authors:</strong> Yunkai Dang, Meiyi Zhu, Donghao Wang, Yizhuo Zhang, Jiacheng Yang, Qi Fan, Yuekun Yang, Wenbin Li, Feng Miao, Yang Gao</li>
<li class=""><strong>institution:</strong> Nanjing University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17319" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17319</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/283e413d1a1fd46323ee20a12df05789e8ef6dd69af3578d2d3e3e27ce803395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/283e413d1a1fd46323ee20a12df05789e8ef6dd69af3578d2d3e3e27ce803395_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces RSHR-Bench, a super-high-resolution benchmark for evaluating multimodal large language models (MLLMs) in remote sensing. The benchmark uses adversarial filtering with strong LLMs and human verification to create tasks that reduce reliance on language priors and require genuine visual understanding. The evaluation reveals that existing models, including RS-specific ones, show significant performance gaps when handling ultra-high-resolution remote sensing imagery.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adaptive graph pruning, Spatio-Temporal Graph Neural Networks (ST-GNNs), Sudden Event Prediction Accuracy (SEPA), online semi-decentralized training, Federated Learning (FL), Gossip Learning]</li>
<li class=""><strong>authors:</strong> Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas</li>
<li class=""><strong>institution:</strong> University of Zagreb, Faculty of Electrical Engineering and Computing; RISE Research Institutes of Sweden; KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an adaptive graph pruning algorithm for Spatio-Temporal Graph Neural Networks (ST-GNNs) to reduce communication overhead in online semi-decentralized traffic prediction systems. It also introduces a novel evaluation metric, SEPA, to measure responsiveness to sudden traffic events. The method maintains prediction accuracy while significantly lowering communication costs across different decentralized learning settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Dialectics for Artificial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [algorithmic information theory], [algorithmic information theory, Kolmogorov complexity, reversible consistency relation, excess information, dialectics optimization]</li>
<li class=""><strong>authors:</strong> Zhengmian Hu</li>
<li class=""><strong>institution:</strong> Adobe Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17373" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17373</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an algorithmic-information framework to define concepts as structural relations within an agent&#x27;s total experience, using reversible consistency and excess information to enable dynamic concept revision. It formulates dialectics as an optimization process where concepts compete to explain new information, leading to expansion, splitting, or merging. The approach also formalizes low-cost concept transmission between agents through shared seeds, making concept alignment a concrete compute-bits trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [imitation learning, dataset aggregation, direct preference optimization, closed-loop evaluation, expert takeover data]</li>
<li class=""><strong>authors:</strong> Deqing Liu, Yinfeng Gao, Deheng Qian, Qichao Zhang, Xiaoqing Ye, Junyu Han, Yupeng Zheng, Xueyi Liu, Zhongpu Xia, Dawei Ding, Yifeng Pan, Dongbin Zhao</li>
<li class=""><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Science and Technology Beijing; Chongqing Chang&#x27;an Technology Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17370" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17370</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b74ccffb4336d971aedcab583ac81f676e7f75bb85a137f4255da4a692fafe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b74ccffb4336d971aedcab583ac81f676e7f75bb85a137f4255da4a692fafe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes TakeAD, a framework that fine-tunes a pre-trained imitation learning policy for autonomous driving using expert takeover data. The method combines iterative Dataset Aggregation (DAgger) for imitation with Direct Preference Optimization (DPO) for preference alignment to improve closed-loop performance. Experiments show it effectively mitigates the open-loop gap and outperforms pure imitation learning methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Optimisation of Aircraft Maintenance Schedules</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [evolutionary algorithms], [evolutionary algorithm, genetic operators, fitness function, maintenance scheduling, optimisation]</li>
<li class=""><strong>authors:</strong> Neil Urquhart, Amir Rahimi, Efstathios-Al. Tingas</li>
<li class=""><strong>institution:</strong> Edinburgh Napier University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17412</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper applies an Evolutionary Algorithm to solve the aircraft maintenance scheduling problem, which involves assigning qualified staff to tasks within a turnaround window. The algorithm is benchmarked on 60 generated problem instances to evaluate its performance. The study demonstrates the proposed representation and genetic operators for this optimisation task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [FastText, NSFWJS, sentiment analysis, data restoration, classification]</li>
<li class=""><strong>authors:</strong> Xingyu Feng</li>
<li class=""><strong>institution:</strong> Hainan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17411</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abd921f37f90b9dfaf497e986d1ae89307cf4b11dd527bf09bd11e36d239652c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abd921f37f90b9dfaf497e986d1ae89307cf4b11dd527bf09bd11e36d239652c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a method for detecting sensitive and illegal content on the Ethereum blockchain using machine learning. It employs a data restoration algorithm and uses FastText for sentiment analysis and NSFWJS for image detection. The study concludes that harmful content, including personal data and explicit images, coexists with benign data on the blockchain, highlighting privacy and security concerns.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [visual question answering, vision-language models, fine-tuning, benchmark dataset, CT, MRI]</li>
<li class=""><strong>authors:</strong> Léo Butsanets, Charles Corbière, Julien Khlaut, Pierre Manceron, Corentin Dancette</li>
<li class=""><strong>institution:</strong> Raidium, Université de Paris Cité, Hôpital Européen Georges Pompidou, AP-HP, INSERM</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17396" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17396</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces RadImageNet-VQA, a large-scale CT and MRI dataset with expert-curated annotations for radiologic visual question answering, designed to evaluate vision-language models on tasks like abnormality detection and pathology identification. Experiments show that current models struggle with fine-grained pathology identification, especially in open-ended settings, and the dataset avoids linguistic shortcuts as models perform near-random without image inputs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Systematic Reproducibility Study of BSARec for Sequential Recommendation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential recommendation], [BSARec, Transformer, Fourier transform, discrete wavelet transform, padding strategies, frequency rescaling]</li>
<li class=""><strong>authors:</strong> Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy, Yuanna Liu</li>
<li class=""><strong>institution:</strong> University of Amsterdam</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17442" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17442</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper reproduces and evaluates BSARec, a sequential recommendation method that enhances Transformer encoders with a frequency layer using Fourier transforms to capture high-frequency signals. The study finds that BSARec outperforms other methods on some datasets, but digital signal processing techniques like discrete wavelet transform offer only marginal improvements over Fourier transforms, and non-constant padding significantly boosts performance while constant padding hinders high-frequency signal capture.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [SWE-Bench++, automated benchmark generation, pull request harvesting, environment synthesis, test oracle extraction, hint-guided trajectory synthesis, fine-tuning]</li>
<li class=""><strong>authors:</strong> Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe</li>
<li class=""><strong>institution:</strong> Turing</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17419" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17419</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reinforcement learning, independent proximal policy optimization, agent-based modeling, electricity markets, capacity markets, contracts for difference]</li>
<li class=""><strong>authors:</strong> Javier Gonzalez-Ruiz, Carlos Rodriguez-Pardo, Iacopo Savelli, Alice Di Bella, Massimo Tavoni</li>
<li class=""><strong>institution:</strong> Politecnico di Milano, CMCC Foundation - Euro-Mediterranean Center on Climate Change, RFF-CMCC European Institute on Economics and the Environment, Bocconi University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17444</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent reinforcement learning framework, using independent proximal policy optimization, to model investment decisions by generation companies in long-term electricity markets. The model is applied to a stylized Italian electricity system to test various market designs and policy scenarios. The results demonstrate that market design is critical for achieving decarbonization targets while mitigating price volatility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning What to Write: Write-Gated KV for Efficient Long-Context Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache management, Write-Gated KV, KV Admission, KV cache eviction, KV cache selection, FlashAttention, paged-KV systems]</li>
<li class=""><strong>authors:</strong> Yen-Chieh Huang, Rui Fang, Ming-Syan Chen, Pi-Cheng Hsiu</li>
<li class=""><strong>institution:</strong> National Taiwan University, Academia Sinica</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17452</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Write-Gated KV, a learnable KV Admission mechanism that predicts token utility before it enters the KV cache to reduce memory usage and speed up inference. By filtering low-utility tokens early and maintaining a compact global cache, the method significantly reduces memory usage and improves prefill and decode speeds for long-context LLMs with minimal accuracy loss. The results demonstrate that proactive KV cache management is a practical solution for efficient long-context inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [time series forecasting], [spatial-temporal graph neural network, trend-seasonal decomposition, low-rank Top-K adjacency learning, horizon-wise gating, linear baseline]</li>
<li class=""><strong>authors:</strong> Henok Tenaw Moges, Deshendran Moodley</li>
<li class=""><strong>institution:</strong> University of Cape Town</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17453" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17453</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Lite-STGNN, a lightweight model combining decomposition-based linear temporal modeling with a learnable sparse graph module for spatial corrections. It achieves state-of-the-art accuracy on long-term multivariate forecasting benchmarks while being parameter-efficient and faster than transformer-based methods. The learned adjacency matrices also provide interpretable insights into domain-specific variable interactions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [marketing personalisation], [randomised controlled trial, agentic messaging, rule-based campaign, causal inference, contextual bandits]</li>
<li class=""><strong>authors:</strong> Olivier Jeunen, Schaun Wheeler</li>
<li class=""><strong>institution:</strong> aampe</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17462</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates an agentic messaging approach for customer communication, comparing it against a traditional rule-based system in a financial service application via a randomized controlled trial. The results show that the agentic system reduced unsubscribe events by 21% and encouraged earlier tax filing, demonstrating its effectiveness in improving user engagement and retention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [democratic systems], [fair voting methods, cumulative voting, equal shares, proportional representation, participatory budgeting, AI voting assistance]</li>
<li class=""><strong>authors:</strong> Evangelos Pournaras</li>
<li class=""><strong>institution:</strong> University of Leeds</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17461" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17461</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes that combining expressive ballot formats like cumulative voting with proportional aggregation methods like equal shares constitutes a &quot;fair voting method.&quot; It concludes that such methods enhance democratic legitimacy, accelerate impactful outcomes in areas like welfare and education, and serve as a safeguard against biases in emerging AI-assisted voting scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Translating the Rashomon Effect to Sequential Decision-Making Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential decision-making], [Rashomon effect, formal verification, policy ensembles, behavioral cloning, permissive policies]</li>
<li class=""><strong>authors:</strong> Dennis Gross, Jørn Eirik Betten, Helge Spieker</li>
<li class=""><strong>institution:</strong> University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17470" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17470</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper translates the Rashomon effect from classification to sequential decision-making by defining it for policies that behave identically but have different internal structures. It uses formal verification methods to compare the complete probabilistic behavior of policies in stochastic environments. The study concludes that the effect exists in this domain and that ensembles from the Rashomon set are more robust to distribution shifts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [4D scene geometry, diffusion-based video generation, occlusion consistency, illumination-aware dataset, mask generation]</li>
<li class=""><strong>authors:</strong> Hoiyeong Jin, Hyojin Jang, Jeongho Kim, Junha Hyung, Kinam Kim, Dongjin Kim, Huijin Choi, Hyeonji Kim, Jaegul Choo</li>
<li class=""><strong>institution:</strong> KAIST AI, SK Telecom</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17504</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1824f6e52cce42d09258c21a8f994f87c3330105a845886e13a668bacd45e38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1824f6e52cce42d09258c21a8f994f87c3330105a845886e13a668bacd45e38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents InsertAnywhere, a framework for realistic video object insertion that combines 4D scene geometry reconstruction with a diffusion-based video generation model to ensure geometric and temporal consistency. It introduces a synthetic dataset, ROSE++, for supervised training. The method outperforms existing models in producing visually coherent insertions suitable for production environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [LoRA, PEFT, orthonormal transform, hidden-state scrambling, access control, instruction tuning, 4-bit quantization]</li>
<li class=""><strong>authors:</strong> Muhammad Haris Khan</li>
<li class=""><strong>institution:</strong> University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17519" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17519</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes K-OTG, a method for secret-key access control in language models. It uses a training-time dual-path corpus and inference-time orthonormal transforms to scramble hidden states, making the model unusable without the correct key while preserving authorized performance. The method is compatible with LoRA and 4-bit quantization, showing effective locking with minimal utility loss for authorized users.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [protein hazard screening], [homology clustering, cluster-level holdout, logistic regression, random forest, linear SVM, calibrated probabilities, AUROC, AUPRC, Brier score, Expected Calibration Error]</li>
<li class=""><strong>authors:</strong> Muhammad Haris Khan</li>
<li class=""><strong>institution:</strong> University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17527</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SafeBench-Seq, a benchmark and baseline classifier for screening hazardous protein sequences using only interpretable physicochemical and compositional features. The method employs homology clustering at ≤40% identity with cluster-level holdouts to evaluate performance on novel threats. The main conclusion is that random data splits overestimate robustness compared to this stricter homology-controlled evaluation, and that calibrated linear models provide good probability calibration for this CPU-only screening task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [degradation-aware reasoning, structured reasoning chains, supervised fine-tuning, reward-driven alignment, dynamic reasoning depth scaling]</li>
<li class=""><strong>authors:</strong> Jiaqi Tang, Jianmin Chen, Wei Wei, Xiaogang Xu, Runtao Liu, Xiangyu Wu, Qipeng Xie, Jiafei Wu, Lei Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> Hong Kong University of Science and Technology, Northwestern Polytechnical University, Chinese University of Hong Kong, Nanjing University of Science and Technology, University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17532" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17532</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b624fc0656a14fc68753d26cc52e1c0a78d9633130c6881762bd87e498ed0875_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b624fc0656a14fc68753d26cc52e1c0a78d9633130c6881762bd87e498ed0875_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Robust-R1, a framework that enhances the robustness of Multimodal Large Language Models by explicitly modeling visual degradations through structured reasoning chains. The method integrates supervised fine-tuning, reward-driven alignment, and dynamic reasoning depth scaling, and is supported by a new dataset of realistic degradations. The approach achieves state-of-the-art performance on real-world degradation benchmarks, demonstrating superior anti-degradation capabilities.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Towards Explainable Conversational AI for Early Diagnosis with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [GPT-4o, Retrieval-Augmented Generation, Chain-of-Thought prompting, similarity matching, adaptive questioning]</li>
<li class=""><strong>authors:</strong> Maliha Tabassum, M Shamim Kaiser</li>
<li class=""><strong>institution:</strong> Bangladesh University of Professionals, Jahangirnagar University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17559" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17559</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a diagnostic chatbot powered by a Large Language Model (GPT-4o) that uses Retrieval-Augmented Generation, Chain-of-Thought prompting, and adaptive questioning to interactively extract symptoms and provide diagnoses. The system achieved 90% accuracy and 100% Top-3 accuracy, outperforming traditional machine learning models. The findings suggest that LLM-based systems can offer a more transparent, interactive, and clinically effective approach to early medical diagnosis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [MetricGAN-plus-voicebank, semantic WER, noise robustness, speech enhancement]</li>
<li class=""><strong>authors:</strong> Sujal Chondhekar, Vasanth Murukuri, Rushabh Vasani, Sanika Goyal, Rajshree Badami, Anushree Rana, Sanjana SN, Karthik Pandia, Sulabh Katiyar, Neha Jagadeesh, Sankalp Gulati</li>
<li class=""><strong>institution:</strong> EkaCare (Orbi Health Private Limited)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17562</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates the effect of MetricGAN-plus-voicebank speech enhancement on four modern ASR systems using medical speech under nine noise conditions. The study finds that denoising preprocessing consistently degrades ASR performance across all models and conditions, suggesting modern ASR models are inherently noise-robust and enhancement may remove critical acoustic features.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ClothHMR: 3D Mesh Recovery of Humans in Diverse Clothing from Single Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [clothing tailoring, body semantic estimation, body edge prediction, foundational human visual model (FHVM), 3D mesh recovery]</li>
<li class=""><strong>authors:</strong> Yunqi Gao, Leyuan Liu, Yuhan Li, Changxin Gao, Yuanyuan Liu, Jingying Chen</li>
<li class=""><strong>institution:</strong> Central China Normal University, Huazhong University of Science and Technology, China University of Geosciences (Wuhan)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17545" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17545</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3dde00da40b964ce086e0496d0c0c6f668bf5149ef5a44e30539fa3c614601b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3dde00da40b964ce086e0496d0c0c6f668bf5149ef5a44e30539fa3c614601b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ClothHMR, a method for 3D human mesh recovery from a single image that handles diverse clothing via a clothing tailoring module to fit garments to the body silhouette and a mesh recovery module that aligns 3D representations with a foundational human vision model. It demonstrates superior performance over existing methods on benchmark datasets and in-the-wild images, with a practical web application for fashion and shopping.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [vertical scheduling, optimizer step overlapping, SSD-offloaded training, gradient accumulation]</li>
<li class=""><strong>authors:</strong> Yikang Yue, Yishu Yin, Xuehai Qian</li>
<li class=""><strong>institution:</strong> Tsinghua University, University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17570</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces GreedySnake, a system that accelerates SSD-offloaded LLM training by using vertical scheduling to process all micro-batches per layer before moving to the next, and by overlapping the optimizer step with the next forward pass. This approach significantly reduces I/O bottlenecks and improves throughput compared to prior systems like ZeRO-Infinity, achieving up to 2.53x speedup for large models like GPT-175B.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A unified FLAIR hyperintensity segmentation model for various CNS tumor types and acquisition time points</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Attention U-Net, FLAIR hyperintensity segmentation, Dice score, Raidionics]</li>
<li class=""><strong>authors:</strong> Mathilde Gajda Faanes, David Bouget, Asgeir S. Jakola, Timothy R. Smith, Vasileios K. Kavouridis, Francesco Latini, Margret Jensdottir, Peter Milos, Henrietta Nittby Redebrandt, Rickard L. Sjöberg, Rupavathana Mahesparan, Lars Kjelsberg Pedersen, Ole Solheim, Ingerid Reinertsen</li>
<li class=""><strong>institution:</strong> SINTEF Digital, University of Gothenburg, Harvard Medical School, Uppsala University Hospital, Karolinska University Hospital, Linköping University Hospital, Skåne University Hospital, Umeå University, Haukeland University Hospital, University Hospital of North Norway, Norwegian University of Science and Technology, St. Olavs University Hospital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17566" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17566</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a unified deep learning model for segmenting FLAIR hyperintensities in brain tumors using an Attention U-Net architecture trained on approximately 5000 MRI scans. The model generalizes well across various tumor types and pre- and post-operative time points, achieving performance comparable to dataset-specific models. It is integrated into the open-source Raidionics software to facilitate clinical deployment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Gaussian Discriminant Analysis, Z-score distance analysis, cluster-driven deep learning, two-stage framework]</li>
<li class=""><strong>authors:</strong> Tosin Ige, Christopher Kiekintveld, Aritran Piplai, Asif Rahman, Olukunle Kolade, Sasidhar Kunapuli</li>
<li class=""><strong>institution:</strong> The University of Texas at El Paso, University of North Carolina</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17594" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17594</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes MAD-OOD, a two-stage cluster-driven deep learning framework for out-of-distribution malware detection. It uses Gaussian Discriminant Analysis to model class embeddings and Z-score distance analysis to identify anomalies, then integrates these predictions with a neural network for final classification. The method significantly outperforms state-of-the-art approaches on benchmark datasets, achieving high AUC for detecting unseen malware families.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] More Consistent Accuracy PINN via Alternating Easy-Hard Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific machine learning], [physics-informed neural networks, easy-hard prioritization, hybrid training strategy, alternating scheme]</li>
<li class=""><strong>authors:</strong> Zhaoqian Gao, Min Yanga</li>
<li class=""><strong>institution:</strong> Yantai University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17607</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid training strategy for Physics-Informed Neural Networks (PINNs) that alternates between easy and hard prioritization to improve performance. The method achieves consistently high accuracy on challenging PDEs, significantly outperforming baseline approaches. The work demonstrates that this alternating scheme enhances the robustness and reliability of PINNs across diverse problem types.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical image registration], [mammography registration, anatomical landmarks, ANTs, VoxelMorph, TransMorph, IDIR, MammoRegNet, benchmark dataset]</li>
<li class=""><strong>authors:</strong> Svetlana Krasnova, Emiliya Starikova, Ilia Naletov, Andrey Krylov, Dmitry Sorokin</li>
<li class=""><strong>institution:</strong> Lomonosov Moscow State University, Third Opinion Platform</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1e72bae8c4d2dd504664f6eedc1a325466b12559df8aa6fc5fbe929fb95fcbf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1e72bae8c4d2dd504664f6eedc1a325466b12559df8aa6fc5fbe929fb95fcbf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MGRegBench, a public benchmark dataset with over 5,000 mammography image pairs and manual annotations for evaluating registration methods. It benchmarks classical, learning-based, and implicit neural representation approaches, finding that deep learning methods like MammoRegNet show strong performance. The dataset and code are released to enable fair comparisons and advance research in mammography registration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SCOPE: Sequential Causal Optimization of Process Interventions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [prescriptive process monitoring], [backward induction, causal learning, reinforcement learning, sequential decision-making]</li>
<li class=""><strong>authors:</strong> Jakob De Moor, Hans Weytjens, Johannes De Smedt, Jochen De Weerdt</li>
<li class=""><strong>institution:</strong> KU Leuven, Technical University of Munich (TUM)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17629" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17629</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SCOPE, a prescriptive process monitoring approach that uses backward induction and causal learning to recommend aligned sequences of interventions for optimizing key performance indicators. It directly leverages observational data without needing process approximations for reinforcement learning. Experiments show SCOPE outperforms existing techniques in optimizing KPIs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Trust-Region Adaptive Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [post-training], [Trust-Region Adaptive Policy Optimization, Trust-Region SFT, forward KL divergence, reverse KL, adaptive prefix-selection, supervised fine-tuning, reinforcement learning]</li>
<li class=""><strong>authors:</strong> Mingyu Su, Jian Guan, Yuxian Gu, Minlie Huang, Hongning Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Ant Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17636" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17636</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces TRAPO, a hybrid framework that interleaves supervised fine-tuning and reinforcement learning within each training instance to unify expert supervision and self-exploration. It stabilizes training with Trust-Region SFT and an adaptive prefix-selection mechanism. Experiments on mathematical reasoning benchmarks show TRAPO outperforms standard pipelines and state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] About Time: Model-free Reinforcement Learning with Timed Reward Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [timed reward machines, tabular Q-learning, timed automata, counterfactual-imagining]</li>
<li class=""><strong>authors:</strong> Anirban Majumdar, Ritam Raha, Rajarshi Roy, David Parker, Marta Kwiatkowska</li>
<li class=""><strong>institution:</strong> Tata Institute of Fundamental Research, Max Planck Institute for Software Systems, University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17637" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17637</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes timed reward machines (TRMs), an extension of reward machines that incorporates timing constraints into the reward specification for reinforcement learning. The authors develop model-free RL algorithms, specifically using tabular Q-learning integrated with abstractions of timed automata and counterfactual-imagining heuristics, to learn optimal policies. The experimental results show that their approach successfully learns policies that achieve high rewards while satisfying the specified timing constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [zero-shot learning, cross-modal retrieval, dual-encoder architecture, contrastive learning, structure-aware augmentation, semantic-traffic alignment]</li>
<li class=""><strong>authors:</strong> Yifei Cheng, Yujia Zhu, Baiyang Li, Xinhao Deng, Yitong Cai, Yaochen Ren, Qingyun Liu</li>
<li class=""><strong>institution:</strong> Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17667" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17667</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces STAR, a method that reformulates website fingerprinting as a zero-shot cross-modal retrieval problem, using a dual-encoder architecture to learn a joint embedding space for encrypted traffic traces and website logic profiles. It achieves high accuracy on unseen websites by aligning semantic and traffic features, demonstrating that semantic leakage is a major privacy risk in encrypted HTTPS traffic.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] You Only Train Once: Differentiable Subset Selection for Omics Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [bioinformatics], [differentiable subset selection, multi-task learning, end-to-end training, sparsity, single-cell RNA-seq]</li>
<li class=""><strong>authors:</strong> Daphné Chopard, Jorge da Silva Gonçalves, Irene Cannistraci, Thomas M. Sutter, Julia E. Vogt</li>
<li class=""><strong>institution:</strong> ETH Zurich, University Children’s Hospital Zurich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17678</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces YOTO, an end-to-end framework that jointly selects discrete gene subsets and performs prediction in a single differentiable model, using sparsity and multi-task learning. It demonstrates improved predictive performance and yields compact, meaningful gene subsets on single-cell RNA-seq datasets, advancing biomarker discovery.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [spatio-temporal feature representation, channel attention, self-attention, recurrent neural networks, video-based gaze estimation]</li>
<li class=""><strong>authors:</strong> Alexandre Personnic, Mihai Bâce</li>
<li class=""><strong>institution:</strong> KU Leuven</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17673</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Spatio-Temporal Gaze Network (ST-Gaze), which combines a CNN backbone with channel and self-attention modules to fuse eye and face features, then models intra- and inter-frame dynamics by treating features as a spatial sequence propagated through time. The method achieves state-of-the-art performance on the EVE dataset, demonstrating that preserving intra-frame spatial context is superior to premature spatial pooling for robust video-based gaze estimation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] An Empirical Study of Sampling Hyperparameters in Diffusion-Based Super-Resolution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [Diffusion Posterior Sampling (DPS), Manifold Constrained Gradient (MCG), conditioning step size, diffusion step count, ablation study]</li>
<li class=""><strong>authors:</strong> Yudhistira Arief Wibowo</li>
<li class=""><strong>institution:</strong> Technical University of Munich, Korea Advanced Institute of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17675" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17675</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts an empirical ablation study on diffusion-based super-resolution, focusing on conditioning methods like DPS and MCG. It finds that the conditioning step size is a more critical hyperparameter than the diffusion step count for reconstruction quality. The optimal conditioning step size for best performance in their experiments falls within the range of [2.0, 3.0].</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Digital and Web Forensics Model Cards, V1</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge representation], [model cards, controlled vocabularies, web-based generator, digital forensics, web forensics]</li>
<li class=""><strong>authors:</strong> Paola Di Maio</li>
<li class=""><strong>institution:</strong> Ronin Institute, W3C AI Knowledge Representation Community Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a web-based framework for generating standardized model cards to represent knowledge in digital and web forensics, featuring controlled vocabularies for classification, reasoning, bias, and error. The main conclusion is the presentation of this beta framework and tool to establish an emerging standard, inviting community feedback for refinement.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [recommendation systems], [causal deconfounding, LightGCN, Unbiased Asymmetric Co-purchase Relationship (UACR), counterfactual exposure, BPR loss]</li>
<li class=""><strong>authors:</strong> Jingmao Zhang, Zhiting Zhao, Yunqi Lin, Jianghong Ma, Tianjun Wei, Haijun Zhang, Xiaofeng Zhang</li>
<li class=""><strong>institution:</strong> Harbin Institute of Technology (Shenzhen), Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17733</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Cadence, a plug-and-play framework built on LightGCN that uses causal deconfounding to compute unbiased item-item relationships and counterfactual exposure simulation to enhance recommendation diversity. The method constructs a deconfounded directed item graph and identifies diverse, causally relevant items a user has not interacted with. Experiments show it outperforms state-of-the-art models in both diversity and accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [AncientBench, benchmark evaluation, ancient character comprehension, excavated documents, glyph comprehension, pronunciation comprehension, meaning comprehension, contextual comprehension]</li>
<li class=""><strong>authors:</strong> Zhihan Zhou, Daqian Shi, Rui Song, Lida Shi, Xiaolei Diao, Hao Xu</li>
<li class=""><strong>institution:</strong> Jilin University, Queen Mary University of London, University of Trento</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17756" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17756</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AncientBench, a comprehensive benchmark designed to evaluate large language models&#x27; comprehension of ancient Chinese, particularly focusing on excavated documents. It assesses four competencies (glyph, pronunciation, meaning, and contextual) through ten tasks. The experimental results show that while LLMs have significant potential in ancient text scenarios, a performance gap remains compared to human experts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Easy Adaptation, Parameter-Efficient Fine-Tuning, LoRA, Specific Small Models, task adaptation, resource-constrained]</li>
<li class=""><strong>authors:</strong> Dong Chen, Zhengqing Hu, Shixing Zhao, Yibo Guo</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17771" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17771</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Easy Adaptation (EA), a method that uses Specific Small Models (SSMs) to complement the data distribution for Large Models, enabling task adaptation without accessing the LM&#x27;s internal parameters. This approach matches the performance of Parameter-Efficient Fine-Tuning (PEFT) like LoRA on diverse tasks while requiring only minimal computational resources, making it suitable for resource-constrained environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [BERT, DistilBERT, ELECTRA, RoBERTa, Multi-BERT Ensemble, transformer models, medical entity recognition]</li>
<li class=""><strong>authors:</strong> Tanjim Taharat Aurpa, Farzana Akter, Md. Mehedi Hasan, Shakil Ahmed, Shifat Ara Rafiq, Fatema Khan</li>
<li class=""><strong>institution:</strong> University of Frontier Technology, University of Liberal Arts Bangladesh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17769</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Multi-BERT Ensemble approach for Bangla Medical Entity Recognition (MedER), evaluating models like BERT, DistilBERT, ELECTRA, and RoBERTa. The ensemble method achieved 89.58% accuracy, an 11.80% improvement over single-layer BERT, and the authors also created a new annotated dataset for this low-resource language task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [vision transformer, neural parametric head models, 3d morphable models, single-image 3d reconstruction, signed distance functions]</li>
<li class=""><strong>authors:</strong> Simon Giebenhain, Tobias Kirschstein, Liam Schoneveld, Davide Davoli, Zhe Chen, Matthias Nießner</li>
<li class=""><strong>institution:</strong> Technical University of Munich, Woven by Toyota, Toyota Motor Europe</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17773" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17773</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c26792d83b697ded69eb83a7cee4b4440d0b9637b6c3fbd2061ab2aef67d7bcd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c26792d83b697ded69eb83a7cee4b4440d0b9637b6c3fbd2061ab2aef67d7bcd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Pix2NPHM, a method that uses a vision transformer to directly regress the parameters of a Neural Parametric Head Model from a single input image. It achieves high-fidelity 3D face reconstruction by training on a mixture of 3D data and 2D videos, and allows for further refinement through inference-time optimization. The authors conclude that their approach yields unprecedented reconstruction quality that generalizes well to in-the-wild data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Knowledge Mining, Digital Preservation, Semantic Web, Data Integration, Dual-Stream Architecture]</li>
<li class=""><strong>authors:</strong> Binh Vu</li>
<li class=""><strong>institution:</strong> FernUniversität in Hagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17795" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17795</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Intelligent Knowledge Mining Framework (IKMF), a conceptual dual-stream architecture that combines a horizontal AI-driven mining process with a parallel trustworthy archiving stream. It aims to bridge the gap between dynamic analysis and long-term preservation, transforming static data repositories into living, actionable knowledge ecosystems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] LLM-based Behaviour Driven Development for Hardware Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Behavior Driven Development (BDD), Large Language Models (LLMs), hardware design, test and verification, natural language processing, Electronic Design Automation (EDA)]</li>
<li class=""><strong>authors:</strong> Rolf Drechsler, Qian Liu</li>
<li class=""><strong>institution:</strong> University of Bremen, DFKI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17814" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17814</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the use of Large Language Models (LLMs) to automate the generation of behavioral scenarios from textual specifications for Behavior Driven Development (BDD) in hardware design. The core method involves applying LLM-based techniques to interpret specifications and produce high-level behavioral descriptions. The main conclusion is that LLMs offer a promising opportunity to support and automate BDD workflows in hardware design, addressing the manual effort and complexity of current verification practices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ShareChat: A Dataset of Chatbot Conversations in the Wild</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [dataset collection, multi-turn conversations, platform affordances, source citations, temporal analysis, cross-platform corpus]</li>
<li class=""><strong>authors:</strong> Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le</li>
<li class=""><strong>institution:</strong> Indiana University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17843" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17843</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset&#x27;s utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [energy-based models, gradient-based refinement, hindsight goal relabeling, latent-space planning]</li>
<li class=""><strong>authors:</strong> Carlos Vélez García, Miguel Cazorla, Jorge Pomares</li>
<li class=""><strong>institution:</strong> INESCOP, University of Alicante</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17846" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17846</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Planning as Descent (PaD), a method for offline goal-conditioned reinforcement learning that learns an energy function over latent trajectories and performs planning via gradient-based refinement in this energy landscape. It achieves state-of-the-art 95% success on cube manipulation tasks, demonstrating that verification-driven trajectory synthesis outperforms direct policy learning, especially when trained on noisy data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Animate Any Character in Any World</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [3DGS, conditional autoregressive video generation, pre-trained video generator, natural language control]</li>
<li class=""><strong>authors:</strong> Yitong Wang, Fangyun Wei, Hongyang Zhang, Bo Dai, Yan Lu</li>
<li class=""><strong>institution:</strong> Fudan University, Microsoft Research, University of Waterloo, The University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17796" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17796</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fb0b1e8242f96e5f0b2988237b2d0603a8f364d90cc833a33b2313d43b1ae4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fb0b1e8242f96e5f0b2988237b2d0603a8f364d90cc833a33b2313d43b1ae4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AniX, a system that animates user-provided 3D characters in 3D Gaussian Splatting (3DGS) scenes based on natural language commands. It formulates the task as a conditional autoregressive video generation problem, building upon a pre-trained video generator and a training strategy to enhance motion dynamics. The method enables open-ended character actions while preserving visual fidelity and temporal coherence in the generated video clips.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computational social science], [computational text analysis, machine learning (ML), natural language processing (NLP), ethnography, in-depth interviews, mixed-methods]</li>
<li class=""><strong>authors:</strong> Corey M. Abramson</li>
<li class=""><strong>institution:</strong> Rice University, UC San Francisco</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17850" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17850</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper demonstrates how computational social science tools like machine learning and natural language processing can be integrated with traditional qualitative methods (e.g., ethnography, interviews) to study aging. It concludes that these computational methods can broaden qualitative research by streamlining workflows, scaling up projects, and enabling new multi-method insights, rather than replacing its foundational approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [cross-attention maps, inference-time optimization, compound loss, denoising step, spatial alignment]</li>
<li class=""><strong>authors:</strong> Sarah Rastegar, Violeta Chatalbasheva, Sieger Falkena, Anuj Singh, Yanbo Wang, Tejas Gokhale, Hamid Palangi, Hadi Jamali-Rad</li>
<li class=""><strong>institution:</strong> Delft University of Technology, University of Maryland, Baltimore County, Shell Information Technology International, Google</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17851" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17851</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1a251648d46bb8da396759e99d563b9a2d57eb19fc5ed8f7ece18ccb7bfeeee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1a251648d46bb8da396759e99d563b9a2d57eb19fc5ed8f7ece18ccb7bfeeee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> InfSplign is a training-free, inference-time method that improves spatial alignment in text-to-image diffusion models by adjusting the noise at each denoising step using a compound loss based on cross-attention maps. It achieves state-of-the-art performance on spatial reasoning benchmarks, outperforming existing inference-time and fine-tuning baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Convolutional Neural Network (CNN), Attention Mechanism, CBAM, VGG16, Grad-CAM, Layer-wise Relevance Propagation (LRP)]</li>
<li class=""><strong>authors:</strong> Balram Singh, Ram Prakash Sharma, Somnath Dey</li>
<li class=""><strong>institution:</strong> National Institute of Technology Hamirpur, Indian Institute of Technology Indore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17864" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17864</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an interpretable plant leaf disease detection method using a CBAM-enhanced VGG16 CNN model. The model integrates attention modules to improve feature extraction and localization, achieving high accuracy on multiple datasets. The study demonstrates the effectiveness of the approach through performance evaluation and interpretability analysis using attention maps and other explainable AI techniques.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [ViPR, ViPR-Eureka, ViPR-RL, behavior cloning, VLM-in-the-loop Parallel Refinement, LLM-guided contact sampling, sim-to-real transfer, GPU simulation]</li>
<li class=""><strong>authors:</strong> Ran Gong, Xiaohan Zhang, Jinghuan Shang, Maria Vittoria Minniti, Jigarkumar Patel, Valerio Pepe, Riedana Yan, Ahmet Gundogdu, Ivan Kapelyukh, Ali Abbas, Xiaoqiang Yan, Harsh Patel, Laura Herlant, Karl Schmeckpeper</li>
<li class=""><strong>institution:</strong> Robotics and AI Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17853" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17853</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AnyTask, an automated framework that uses massively parallel GPU simulation and foundation models to generate diverse robot manipulation tasks and expert demonstration data. It introduces three agents (ViPR, ViPR-Eureka, ViPR-RL) for synthesizing demonstrations, which are used to train behavior cloning policies. These policies achieve a 44% average success rate when deployed directly on real robot hardware for various manipulation tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [generative modeling], [Wasserstein-Fisher-Rao gradient flow, weighted stochastic differential equations, Feynman-Kac representation, score-based diffusion models, Langevin dynamics]</li>
<li class=""><strong>authors:</strong> Herlock Rahimi</li>
<li class=""><strong>institution:</strong> Yale University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a new sampling method for generative modeling by implementing Wasserstein-Fisher-Rao gradient flow via weighted stochastic differential equations, using the Feynman-Kac representation. This approach aims to overcome the slow mixing rates of traditional diffusion models in non-log-concave, multimodal target distributions by incorporating controlled mass reweighting. The study provides a rigorous geometric and operator-theoretic foundation for future developments in this area.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [human-computer interaction], [anthropomorphism, cross-national experiments, humanlike AI design, behavioral measures, cultural mediation]</li>
<li class=""><strong>authors:</strong> Robin Schimmelpfennig, Mark Díaz, Vinodkumar Prabhakaran, Aida Davani</li>
<li class=""><strong>institution:</strong> Max Planck Institute for Human Development, Google Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17898</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper conducts two large-scale cross-national experiments with 3,500 participants across 10 countries, involving real-time interactions with an AI system. It finds that humanlike design increases anthropomorphism but does not universally boost engagement and trust; instead, these outcomes are culturally mediated, with the same design choices having opposite effects in different populations like Brazil and Japan.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] RadarGen: Automotive Radar Point Cloud Generation from Cameras</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [diffusion model, bird&#x27;s-eye-view, radar cross section, Doppler, point cloud generation, foundation models]</li>
<li class=""><strong>authors:</strong> Tomer Borreda, Fangqiang Ding, Sanja Fidler, Shengyu Huang, Or Litany</li>
<li class=""><strong>institution:</strong> Technion, MIT, NVIDIA, University of Toronto, Vector Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17897" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17897</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RadarGen is a diffusion model that generates realistic automotive radar point clouds from multi-view camera images by representing radar data in bird&#x27;s-eye-view and conditioning on visual cues. It uses a lightweight recovery step to reconstruct point clouds from the generated maps. Evaluations show it captures real radar statistics and reduces the performance gap for perception models trained on synthetic data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adversarial Robustness of Vision in Open Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [Projected Gradient Descent, adversarial robustness, Visual Question Answering, vision-language models]</li>
<li class=""><strong>authors:</strong> Jonathon Fox, William J Buchanan, Pavlos Papadopoulos</li>
<li class=""><strong>institution:</strong> Edinburgh Napier University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17902" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17902</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates the adversarial robustness of vision-language models LLaVA-1.5-13B and Llama 3.2 Vision-8B-2 by applying untargeted Projected Gradient Descent attacks to their visual inputs and testing on a VQA v2 subset. The main conclusion is that the vision modality is a viable attack vector, and adversarial robustness does not directly correlate with standard benchmark performance, with Llama 3.2 Vision showing a smaller accuracy drop under attack despite a lower baseline.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When Reasoning Meets Its Laws</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [large reasoning models], [laws of reasoning, compute law, accuracy law, monotonicity, compositionality, LoRe-Bench, finetuning]</li>
<li class=""><strong>authors:</strong> Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, Massachusetts Institute of Technology, University of Pennsylvania, New York University, NTT Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17901" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17901</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Laws of Reasoning (LoRe), a framework that formalizes desired reasoning behaviors in large reasoning models, including compute and accuracy laws. It proposes LoRe-Bench to evaluate monotonicity and compositionality, and develops a finetuning method to improve compositionality. The study finds that better compliance with these laws leads to enhanced reasoning performance across benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [test-time refinement, self-supervised learning, shape from shading, score distillation sampling, monocular depth estimation, diffusion models]</li>
<li class=""><strong>authors:</strong> Ananta R. Bhattarai, Helge Rhodin</li>
<li class=""><strong>institution:</strong> Bielefeld University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17908" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17908</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Re-Depth Anything, a test-time self-supervision framework that refines monocular depth predictions by re-lighting the geometry and using a 2D diffusion model&#x27;s priors via Score Distillation Sampling. It updates only specific model embeddings and the decoder to prevent collapse, rather than fine-tuning the entire network. The method shows substantial improvements in depth accuracy and realism over the baseline Depth Anything V2 model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Another Fit Bites the Dust: Conformal Prediction as a Calibration Standard for Machine Learning in High-Energy Physics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [uncertainty quantification], [conformal prediction, calibration, machine learning, high-energy physics, collider research, finite-sample guarantees, prediction sets, p-values]</li>
<li class=""><strong>authors:</strong> Jack Y. Araz, Michael Spannowsky</li>
<li class=""><strong>institution:</strong> University College London, City, University of London, Durham University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17048" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17048</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using conformal prediction as a standard calibration layer for machine learning models in high-energy physics, providing rigorous uncertainty quantification and finite-sample coverage guarantees without retraining. It demonstrates the method&#x27;s applicability across regression, classification, anomaly detection, and generative modeling using collider datasets. The authors conclude that adopting conformal calibration enables reliable statistical inference and principled decision-making in experimental analyses.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [graph attention networks, electroencephalography, spatio-temporal graphs, edge analysis, low-cost hardware, RaspberryPi]</li>
<li class=""><strong>authors:</strong> Szymon Mazurek, Stephen Moore, Alessandro Crimi</li>
<li class=""><strong>institution:</strong> AGH University of Krakow, University of Cape Coast</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2507.15118" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2507.15118</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a graph attention network (GAT) framework that models EEG signals as spatio-temporal graphs to detect epilepsy, with a focus on low-cost hardware for deployment in low-resource settings. The method adapts GATs to analyze edge connectivity for biomarker identification and is designed for lightweight training and deployment. The results demonstrate promising classification performance and highlight the potential for scalable, accessible diagnostic support in underserved regions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-layer graph, GNN, temporal GNN, logistic regression, Random Forest, correlation-based, systemic risk]</li>
<li class=""><strong>authors:</strong> Sandeep Neela</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17185" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17185</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility. It demonstrates that graph-derived features from this model provide useful early-warning signals for market crashes, outperforming standard feature-based models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] From Priors to Predictions: Explaining and Visualizing Human Reasoning in a Graph Neural Network Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [cognitive modeling], [Graph Neural Networks, Graph Theory, inductive biases, computational graph, systematic ablation]</li>
<li class=""><strong>authors:</strong> Quan Do, Caroline Ahn, Leah Bakst, Michael Pascale, Joseph T. McGuire, Chantal E. Stern, Michael E. Hasselmo</li>
<li class=""><strong>institution:</strong> Boston University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17255" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17255</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a framework combining Graph Theory and Graph Neural Networks to formalize inductive biases as explicit priors over structure and abstraction. Using a human behavioral dataset adapted from the Abstraction and Reasoning Corpus, it shows that differences in graph-based priors explain individual differences in human solutions, revealing how generalization depends on specific prior structures and why human-like errors arise from incorrect priors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] HydroGym: A Reinforcement Learning Platform for Fluid Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [reinforcement learning, flow control, differentiable solvers, transfer learning, benchmark platform]</li>
<li class=""><strong>authors:</strong> Christian Lagemann, Sajeda Mokbel, Miro Gondrum, Mario Rüttgers, Jared Callaham, Ludger Paehler, Samuel Ahnert, Nicholas Zolman, Kai Lagemann, Nikolaus Adams, Matthias Meinke, Wolfgang Schröder, Jean-Christophe Loiseau, Esther Lagemann, Steven L. Brunton</li>
<li class=""><strong>institution:</strong> University of Washington, RWTH Aachen University, Inha University, Technical University of Munich, German Center for Neurodegenerative Diseases, Arts et Métiers Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17534" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17534</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HydroGym, a reinforcement learning platform designed for fluid dynamics control, featuring both non-differentiable and differentiable solvers to improve sample efficiency. The platform includes 42 validated environments and demonstrates that RL agents can discover robust control principles, achieving significant drag reduction and efficient adaptation to new conditions via transfer learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [3D ConvNeXt, Global Response Normalization, depth scaling, width scaling, context scaling, supervised pretraining, volumetric segmentation]</li>
<li class=""><strong>authors:</strong> Saikat Roy, Yannick Kirchhoff, Constantin Ulrich, Maximillian Rokuss, Tassilo Wald, Fabian Isensee, Klaus Maier-Hein</li>
<li class=""><strong>institution:</strong> German Cancer Research Center (DKFZ), Heidelberg University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17774" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17774</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MedNeXt-v2, a compound-scaled 3D ConvNeXt architecture enhanced with a Global Response Normalization module for large-scale supervised representation learning in medical image segmentation. The authors demonstrate that scaling the backbone network&#x27;s architecture is crucial for effective pretraining, and MedNeXt-v2 achieves state-of-the-art performance when fine-tuned on diverse CT and MR benchmarks. The work establishes that a stronger backbone design yields better downstream segmentation results than simply increasing dataset size.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Exploring the Effect of Basis Rotation on NQS Performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [quantum machine learning], [neural quantum states, restricted boltzmann machine, quantum natural gradient, quantum fisher information, fubini-study distance, basis rotation, ising model]</li>
<li class=""><strong>authors:</strong> Sven Benjamin Kožić, Vinko Zlatić, Fabio Franchini, Salvatore Marco Giampaolo</li>
<li class=""><strong>institution:</strong> Institut Ruđer Bošković</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17893" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17893</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses an analytically solvable rotated Ising model to study how local basis rotations affect the optimization of Neural Quantum States (NQS). It finds that rotations relocate the target wavefunction in parameter space, exposing information-geometric barriers like saddle points that trap shallow architectures like RBMs, highlighting the need for landscape-aware model design.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-23">2025-12-23<a href="#2025-12-23" class="hash-link" aria-label="Direct link to 2025-12-23" title="Direct link to 2025-12-23" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251223] Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lihui Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17912" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17912</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Baxi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nihir Chadderwala</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17913" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17913</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17911</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh Tri LÊ, Ali Ait-Bachir</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17916" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17916</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aomufei Yuan, Zhiming Wang, Ruijie Miao, Dayu Wang, Yuxuan Tian, Zihan Wang, Yebo Peng, Yuhan Wu, Bairen Yi, Xin Liu, Tong Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17917" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17917</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Allison Li, Kristjan Greenewald, Thomas Parnell, Navid Azizan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17910</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Xu, Ayan Banerjee, Midhat Urooj, Sandeep K.S. Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haiying Xia, Zhongyi Huang, Yumei Tan, Shuxiang Song</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17946" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17946</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae2757814d2b16837d9b7cb3f26503eda8c49afc87dd1795f588ae949df6650_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae2757814d2b16837d9b7cb3f26503eda8c49afc87dd1795f588ae949df6650_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhao Song, Song Yue, Jiahao Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17950</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21bbafaf75367ac515be62999bf183f2dc9b58cb6de4b044d5e95331ef1cf1ed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21bbafaf75367ac515be62999bf183f2dc9b58cb6de4b044d5e95331ef1cf1ed_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Karthik Prabhakar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17943" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17943</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Soheil Hashtarkhani, Brianna M. White, Benyamin Hoseini, David L. Schwartz, Arash Shaban-Nejad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Will AI Trade? A Computational Inversion of the No-Trade Theorem</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hanyu Li, Xiaotie Deng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17952" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17952</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ad1a13c7765317192c2b83746186b421990df4011bf9cad5b20f5624cf6ca35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ad1a13c7765317192c2b83746186b421990df4011bf9cad5b20f5624cf6ca35_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Will AI Trade? A Computational Inversion of the No-Trade Theorem</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Victor Stasiuc, Round Table Collaboration</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ellie Zhou, Jihoon Chung, Olga Russakovsky</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17953" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17953</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8fc5229281981de8f8ce6b4446b9b416a3bf03a5b7dfe015f7327ed14da6c6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8fc5229281981de8f8ce6b4446b9b416a3bf03a5b7dfe015f7327ed14da6c6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gunho Park, Jeongin Bae, Byeongwook Kim, Baeseong park, Jiwon Ryu, Hoseung Kim, Se Jung Kwon, Dongsoo Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17970</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthieu Mastio, Paul Saves, Benoit Gaudou, Nicolas Verstaevel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17979" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17979</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Farida Mohsen, Ali Safa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17958</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Irina Seregina, Philippe Lalanda, German Vega</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17983" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17983</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Convolutional-neural-operator-based transfer learning for solving PDEs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peng Fan, Guofei Pang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Convolutional-neural-operator-based transfer learning for solving PDEs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Specification and Detection of LLM Code Smells</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Stievenert, Florent Avellaneda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18020" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18020</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Specification and Detection of LLM Code Smells</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sarah Nassar, Nooshin Maghsoodi, Sophia Mannina, Shamel Addas, Stephanie Sibley, Gabor Fichtinger, David Pichora, David Maslove, Purang Abolmaesumi, Parvin Mousavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18031</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Joshua Gibson, Kapil Dhakal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18034</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mohammadmahdi Rahimiasl, Ynte Vanderhoydonc, Siegfried Mercelis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17984" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17984</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Securing Agentic AI Systems -- A Multilayer Security Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sunil Arora, John Hastings</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Securing Agentic AI Systems -- A Multilayer Security Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FOODER: Real-time Facial Authentication and Expression Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sabri Mustafa Kahya, Muhammet Sami Yavuz, Boran Hamdi Sivrikaya, Eckehard Steinbach</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18057</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FOODER: Real-time Facial Authentication and Expression Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18080</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ohoud Alzahrani, Russell Beale, Robert J. Hendley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18077" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18077</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shreshth Rajan, Raymond Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18082</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd5ca9b561b8ad179709036acde1f313672cfa0c00a271b9235f8ab0e640d0a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd5ca9b561b8ad179709036acde1f313672cfa0c00a271b9235f8ab0e640d0a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ge Yan, Tuomas Oikarinen, Tsui-Wei, Weng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18092</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Boxuan Wang, Zhuoyun Li, Xiaowei Huang, Yi Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18094" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18094</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Holistic Evaluation of State-of-the-Art LLMs for Code Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Le Zhang, Suresh Kothari</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18131</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Holistic Evaluation of State-of-the-Art LLMs for Code Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18126" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18126</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jie Yang, Rui Zhang, Ziyang Cheng, Dawei Cheng, Guang Yang, Bo Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18133" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18133</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cristiano da Costa Cunha, Wei Liu, Tim French, Ajmal Mian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Swarm Leader Identification using Probing Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stergios E. Bachoumas, Panagiotis Artemiadis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18146" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18146</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Swarm Leader Identification using Probing Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Propose, Solve, Verify: Self-Play Through Formal Verification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alex Wilf, Pranjal Aggarwal, Bryan Parno, Daniel Fried, Louis-Philippe Morency, Paul Pu Liang, Sean Welleck</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18160" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18160</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/352216a02c2bd4fb599d9561a7994cb21ba9b1ce3f9f8b8cfea3ec4cc0b8413d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/352216a02c2bd4fb599d9561a7994cb21ba9b1ce3f9f8b8cfea3ec4cc0b8413d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Propose, Solve, Verify: Self-Play Through Formal Verification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Midhat Urooj, Ayan Banerjee, Sandeep Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18177" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18177</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7ef165e056ae631599bd024eb4341c57c1705258598a82662ae1166302f2947_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7ef165e056ae631599bd024eb4341c57c1705258598a82662ae1166302f2947_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Yan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18190</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Devang Dhanuka, Nidhi Rastogi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18199</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7026a8c8f552664c28724b8716e8e7e5cef6b29425c374a1c5439f2bfb877d5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7026a8c8f552664c28724b8716e8e7e5cef6b29425c374a1c5439f2bfb877d5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Deng, Yijia Li, Renrui Zhang, Peijun Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18189" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18189</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sophia: A Persistent Agent Framework of Artificial Life</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingyang Sun, Feng Hong, Weinan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18202</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c33289396399b1bb0e301fb010ed82c6a686d9391a9307867ae3c7ae74a8cc3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c33289396399b1bb0e301fb010ed82c6a686d9391a9307867ae3c7ae74a8cc3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sophia: A Persistent Agent Framework of Artificial Life</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhou Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18209</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Stable and Efficient Single-Rollout RL for Multimodal Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Stable and Efficient Single-Rollout RL for Multimodal Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yudong Liu, Spencer Hallyburton, Jiwoo Kim, Yueqian Lin, Yiming Li, Qinsi Wang, Hui Ye, Jingwei Sun, Miroslav Pajic, Yiran Chen, Hai Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18211" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18211</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eea86ac8cc855b1a0e43febafd0f1e08626f900ba3ded294c1d99b0072a7da3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eea86ac8cc855b1a0e43febafd0f1e08626f900ba3ded294c1d99b0072a7da3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zehao Liu, Xi Lin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18244" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18244</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a4ab3d36e0ccc56b5c8f0b5a9f82481bdfdc1f1bc14e54959edf8ba4006a00d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a4ab3d36e0ccc56b5c8f0b5a9f82481bdfdc1f1bc14e54959edf8ba4006a00d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Offline Behavioral Data Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shiye Lei, Zhihao Cheng, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18246</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Behavioral Data Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Himabindu Thogaru, Saisubramaniam Gopalakrishnan, Zishan Ahmad, Anirudh Deodhar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18265" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18265</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50a73b0ae1606916d8e1e7324c2baa8154f67eb8e76c0e1f1c0d014d54aa2ab2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50a73b0ae1606916d8e1e7324c2baa8154f67eb8e76c0e1f1c0d014d54aa2ab2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiao He, Chang Tang, Xinwang Liu, Wei Zhang, Zhimin Gao, Chuankun Li, Shaohua Qiu, Jiangfeng Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028cfc83b63f51bf798c2014f1dc8e1f4c786134910334880eb4c0cf340a5eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028cfc83b63f51bf798c2014f1dc8e1f4c786134910334880eb4c0cf340a5eb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Fan, Jiawei Chen, Yu Tian, Zhaoxia Yin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18264" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18264</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6181175b477e5c50e93e9a1a3a4690fb1673471073933b770754e208c7b0e776_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6181175b477e5c50e93e9a1a3a4690fb1673471073933b770754e208c7b0e776_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Ancient Plant Seed Classification: A Benchmark Dataset and Baseline Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Xing, Runmin Cong, Yingying Wu, Can Wang, Zhongming Tang, Fen Wang, Hao Wu, Sam Kwong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18247</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d341345aee67211dc7e3cea021a11051fd66231eb649e4da442fda6828319f0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d341345aee67211dc7e3cea021a11051fd66231eb649e4da442fda6828319f0d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Ancient Plant Seed Classification: A Benchmark Dataset and Baseline Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sirui Li, Wangyue Lu, Xiaorui Shi, Ke Weng, Haozhe Sun, Minghe Yu, Tiancheng Zhang, Ge Yu, Hengyu Liu, Lun Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18256" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18256</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fa370d48e50a94f7beaa30df78416e8de75e5bddd8996af2ad55d2751ed49c0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fa370d48e50a94f7beaa30df78416e8de75e5bddd8996af2ad55d2751ed49c0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18261" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18261</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xuling Zhang, Jindong Li, Yifei Zhang, Menglin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18295" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18295</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Harsh Rathva, Ojas Srivastava, Pruthwik Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18309</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eren Caglar, Amirkia Rafiei Oskooei, Mehmet Kutanoglu, Mustafa Keles, Mehmet S. Aktas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18318" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18318</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18336</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Monitoring Monitorability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Monitoring Monitorability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MCVI-SANet: A lightweight semi-supervised model for LAI and SPAD estimation of winter wheat under vegetation index saturation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiheng Zhang, Jiajun Yang, Hong Sun, Dong Wang, Honghua Jiang, Yaru Chen, Tangyuan Ning</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18344</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f19d6aa9f347693da897453773133b3a6f0b66ee06e5f6bdf421bb24507e5f56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f19d6aa9f347693da897453773133b3a6f0b66ee06e5f6bdf421bb24507e5f56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MCVI-SANet: A lightweight semi-supervised model for LAI and SPAD estimation of winter wheat under vegetation index saturation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM-based Few-Shot Early Rumor Detection with Imitation Agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fengzhu Zeng, Qian Shao, Ling Cheng, Wei Gao, Shih-Fen Cheng, Jing Ma, Cheng Niu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-based Few-Shot Early Rumor Detection with Imitation Agent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mateusz Lango, Ondřej Dušek</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18360" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18360</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Datasets for machine learning and for assessing the intelligence level of automatic patent search systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Boris Genin, Alexander Gorbunov, Dmitry Zolkin, Igor Nekrasov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18384" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18384</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac80e35326c113d249d5bd28c4aafe01da23a8e0c681cde84257daab6b92b651_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac80e35326c113d249d5bd28c4aafe01da23a8e0c681cde84257daab6b92b651_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Datasets for machine learning and for assessing the intelligence level of automatic patent search systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18388" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18388</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Neural Proofs for Sound Verification and Control of Complex Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alessandro Abate</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18389" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18389</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Neural Proofs for Sound Verification and Control of Complex Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mark Kashirskiy, Artiom Lipinski, Ilya Makarov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18399" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18399</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AmPLe: Supporting Vision-Language Models via Adaptive-Debiased Ensemble Multi-Prompt Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fei Song, Yi Li, Jiangmeng Li, Rui Wang, Changwen Zheng, Fanjiang Xu, Hui Xiong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18411</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c480d382f1a840aaa7b8f0ed1cc380b9ece2b0a04c01a7bfeaf7551356ef5a0c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c480d382f1a840aaa7b8f0ed1cc380b9ece2b0a04c01a7bfeaf7551356ef5a0c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AmPLe: Supporting Vision-Language Models via Adaptive-Debiased Ensemble Multi-Prompt Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mykyta Lapin, Kostiantyn Bokhan, Yurii Parzhyn</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18412</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccebc716317d25dbc5d826c4045eca3d2894e8904f35d62a55262711b7023239_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccebc716317d25dbc5d826c4045eca3d2894e8904f35d62a55262711b7023239_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ansar Ahmed</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18432" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18432</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8b17e8fd956e845305266fe6ff75f18289ac1b39f8db27ac25d02758609d8f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8b17e8fd956e845305266fe6ff75f18289ac1b39f8db27ac25d02758609d8f9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Distributed Hierarchical Spatio-Temporal Edge-Enhanced Graph Neural Network for City-Scale Dynamic Logistics Routing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihan Han, Lingran Meng, Jingwei Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18441" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18441</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acf1ec57b519400d58fe519f0aa1f4d66aecd68168a2f192e508b971607f7ef7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acf1ec57b519400d58fe519f0aa1f4d66aecd68168a2f192e508b971607f7ef7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Distributed Hierarchical Spatio-Temporal Edge-Enhanced Graph Neural Network for City-Scale Dynamic Logistics Routing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] VeruSAGE: A Study of Agent-Based Verification for Rust Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18436</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VeruSAGE: A Study of Agent-Based Verification for Rust Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Snowveil: A Framework for Decentralised Preference Discovery</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Grammateia Kotsialou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18444</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Snowveil: A Framework for Decentralised Preference Discovery</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Agentic AI Framework for Training General Practitioner Student Skills</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18440" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18440</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Agentic AI Framework for Training General Practitioner Student Skills</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xavier Rafael-Palou, Jose Munuera, Ana Jimenez-Pastor, Richard Osuala, Karim Lekadir, Oliver Diaz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18450" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18450</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MeniMV: A Multi-view Benchmark for Meniscus Injury Severity Grading</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shurui Xu, Siqi Yang, Jiapin Ren, Zhong Cao, Hongwei Yang, Mengzhen Fan, Yuyu Sun, Shuyan Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18437" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18437</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82297f34fc5f7dfab35d4ab984e7ba607ad5ac2c849bffbec01d38cbdcf42e3d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82297f34fc5f7dfab35d4ab984e7ba607ad5ac2c849bffbec01d38cbdcf42e3d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MeniMV: A Multi-view Benchmark for Meniscus Injury Severity Grading</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Secret mixtures of experts inside your LLM</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Enric Boix-Adsera</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18452</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Secret mixtures of experts inside your LLM</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SoK: Understanding (New) Security Issues Across AI4Code Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qilong Wu, Taoran Li, Tianyang Zhou, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18456" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18456</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SoK: Understanding (New) Security Issues Across AI4Code Use Cases</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Román Jaimes</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18462</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18470" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18470</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Oraib Almegdadi, João Marcelino, Sarah Fakhreddine, João Manso, Nuno C. Marques</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18466" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18466</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Large Language Models as Discounted Bayesian Filters</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Jing Yang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18489" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18489</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da72fb53dbbaca8aea568d7b6fc9cba313aa6bb5798a40c89e2a22a5a0788e17_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da72fb53dbbaca8aea568d7b6fc9cba313aa6bb5798a40c89e2a22a5a0788e17_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Large Language Models as Discounted Bayesian Filters</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18495</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39d0272a8734a4477ae1f6aa46e60e4c4f62aa860ef3a9559c12f0aad180ecb2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39d0272a8734a4477ae1f6aa46e60e4c4f62aa860ef3a9559c12f0aad180ecb2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Santwana Sagnika, Manav Malhotra, Ishtaj Kaur Deol, Soumyajit Roy, Swarnav Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18500" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18500</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang, Deepa Krishnan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18483" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18483</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c098db4784c358fb7712e2be8c3c8d57e56fd9982bed1aff3f16699a16acd5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c098db4784c358fb7712e2be8c3c8d57e56fd9982bed1aff3f16699a16acd5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] GTMA: Dynamic Representation Optimization for OOD Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Ningyuan Liu, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18504</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec81480aabd317eb3778c36f956b818e8aed383ab7f9a13fe2c867243fcec025_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec81480aabd317eb3778c36f956b818e8aed383ab7f9a13fe2c867243fcec025_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GTMA: Dynamic Representation Optimization for OOD Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hatim M. E. Geli, Islam Omar, Mona Y. Elshinawy, David W. DuBios, Lara Prehodko, Kelly H Smith, Abdel-Hameed A. Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18522" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18522</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Miyuki T. Nakata</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18525" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18525</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5fa66d8eb7deac60effe912ce57cc5b3a8decb9a70cf6acda4def17328ab6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5fa66d8eb7deac60effe912ce57cc5b3a8decb9a70cf6acda4def17328ab6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Detection of AI Generated Images Using Combined Uncertainty Measures and Particle Swarm Optimised Rejection Mechanism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Nauman Aslam, Eaby Kollonoor Babu, Josh Collyer, Fraser Kennedy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18527</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1520c61491b8f395b60f64432e37eff57c8608eba74cd9029c6109d32db7554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1520c61491b8f395b60f64432e37eff57c8608eba74cd9029c6109d32db7554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Detection of AI Generated Images Using Combined Uncertainty Measures and Particle Swarm Optimised Rejection Mechanism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Scott Thornton</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18542</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Training Superintelligent Software Agents through Self-Play SWE-RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18552</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Training Superintelligent Software Agents through Self-Play SWE-RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing Medical Large Vision-Language Models via Alignment Distillation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aofei Chang, Ting Wang, Fenglong Ma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65cfdaf6c50eb13e1535902993b0e58d2ccb2d1d8a89304254b7eb116f2e3bec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65cfdaf6c50eb13e1535902993b0e58d2ccb2d1d8a89304254b7eb116f2e3bec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Medical Large Vision-Language Models via Alignment Distillation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Chen, Sihan Cheng, Can Gurkan, Ryan Lay, Moez Salahuddin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18564" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18564</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saad Alqithami</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18561" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18561</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18567" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18567</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Effiong Blessing, Chiung-Yi Tseng, Somshubhra Roy, Junaid Rehman, Isaac Nkrumah</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18575" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18575</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumaiya Ali, Areej Alhothali, Ohoud Alzamzami, Sameera Albasri, Ahmed Abduljabbar, Muhammad Alwazzan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Weijie Zhou, Xuangtang Xiong, Ye Tian, Lijun Yue, Xinyu Wu, Wei Li, Chaoyang Zhao, Honghui Dong, Ming Tang, Jinqiao Wang, Zhengyou Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18571" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18571</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e48075d8fabfbd12f97c2605f729d021ebb805999e01bbf511f08a872cf4cbae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e48075d8fabfbd12f97c2605f729d021ebb805999e01bbf511f08a872cf4cbae_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Amit Barman, Atanu Mandal, Sudip Kumar Naskar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18593" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18593</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qinglin Zeng, Jing Yang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f210ca82f5b83e0df7f60aafea30fa1547a0370e3b4cda5c94ba26cc393a6f1d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f210ca82f5b83e0df7f60aafea30fa1547a0370e3b4cda5c94ba26cc393a6f1d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Text2Graph VPR: A Text-to-Graph Expert System for Explainable Place Recognition in Changing Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saeideh Yousefzadeh, Hamidreza Pourreza</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18613" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18613</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15155edf4c23c5fa3645a1383be98a1728e9025130895c36fb1d8c7a536e2335_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15155edf4c23c5fa3645a1383be98a1728e9025130895c36fb1d8c7a536e2335_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Text2Graph VPR: A Text-to-Graph Expert System for Explainable Place Recognition in Changing Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PTTA: A Pure Text-to-Animation Framework for High-Quality Creation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruiqi Chen, Kaitong Cai, Yijia Fan, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18614" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18614</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95e6d5eb29d8f200e9b4d751e2105c378ddc6c8efc5742b330b0ff8118931fb1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95e6d5eb29d8f200e9b4d751e2105c378ddc6c8efc5742b330b0ff8118931fb1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PTTA: A Pure Text-to-Animation Framework for High-Quality Creation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Assignment-Routing Optimization: Solvers for Problems Under Constraints</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Qilong, Michal Pavelka</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be4f502655365659aa5803c3c3e98ff2a6071f2798b4e71f56472c3fe923e05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be4f502655365659aa5803c3c3e98ff2a6071f2798b4e71f56472c3fe923e05_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Assignment-Routing Optimization: Solvers for Problems Under Constraints</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18616" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18616</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhenhao Zhou, Dan Negrut</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18619" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18619</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c6d919e0fe62510cfe25cf2ce73cce1bed581dc021d27540c0588fbf495702_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c6d919e0fe62510cfe25cf2ce73cce1bed581dc021d27540c0588fbf495702_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18623" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18623</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Huiqi Deng, Qihan Ren, Zhuofan Chen, Zhenyuan Cui, Wen Shen, Peng Zhang, Hongbin Pei, Quanshi Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18607</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18622" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18622</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Han-Seul Jeong, Youngjoon Park, Hyungseok Song, Woohyung Lim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18633" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18633</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dmitry Bennett, Fernand Gobet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18665" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18665</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38aa956a72d7d3233a8e9436ec8b3eb96fe6f950dddcefb2c6497e4cc28ea7e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38aa956a72d7d3233a8e9436ec8b3eb96fe6f950dddcefb2c6497e4cc28ea7e6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Geometric-Photometric Event-based 3D Gaussian Ray Tracing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kai Kohyama, Yoshimitsu Aoki, Guillermo Gallego, Shintaro Shiba</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18640" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18640</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85632c631e489e2f789f1b5319b05b69e8e883a12a7b626de475c98e6066ef45_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85632c631e489e2f789f1b5319b05b69e8e883a12a7b626de475c98e6066ef45_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Geometric-Photometric Event-based 3D Gaussian Ray Tracing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jones David, Shreya Ghosh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18669" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18669</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4809145f5d00782974383c70a1a7132c8f9a0785e93701b00d5f208d14cae5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4809145f5d00782974383c70a1a7132c8f9a0785e93701b00d5f208d14cae5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hafiz Saif Ur Rehman, Ling Liu, Kaleem Ullah Qasim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18661" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18661</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e0e274099dd56b8114b544bec1b5ebd56dd8742f2795d776a62751dceb1bd0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e0e274099dd56b8114b544bec1b5ebd56dd8742f2795d776a62751dceb1bd0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Liu, Yuhao Hu, Ruiting Zhou, Baochun Li, Ne Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18674" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18674</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Social Comparison without Explicit Inference of Others&#x27; Reward Values: A Constructive Approach Using a Probabilistic Generative Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yosuke Taniuchi, Chie Hieida, Atsushi Noritake, Kazushi Ikeda, Masaki Isoda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18687</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a80afdf97506cd46b51f3e0232de08278947f67ce0d02728ea31ab57eb6fd39c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a80afdf97506cd46b51f3e0232de08278947f67ce0d02728ea31ab57eb6fd39c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Social Comparison without Explicit Inference of Others&#x27; Reward Values: A Constructive Approach Using a Probabilistic Generative Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cailin Lei, Haiyang Wu, Yuxiong Ji, Xiaoyu Cai, Yuchuan Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18703" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18703</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ec9f06c274a9525b199fad25bdb142bfd63b4a43030adbafd554411a02c2fe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ec9f06c274a9525b199fad25bdb142bfd63b4a43030adbafd554411a02c2fe1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhifei Li, Lifan Chen, Jiali Yi, Xiaoju Hou, Yue Zhao, Wenxin Huang, Miao Zhang, Kui Xiao, Bing Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18709</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aad95971dcc28db4090fb00dc3a2271fb594ddd1417a6438b8306e2ee01f03a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aad95971dcc28db4090fb00dc3a2271fb594ddd1417a6438b8306e2ee01f03a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiangrui Cai, Shaocheng Ma, Lei Cao, Jie Li, Tianyu Liu, Yilin Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18689" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18689</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junjun Pan, Yixin Liu, Rui Miao, Kaize Ding, Yu Zheng, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, Shirui Pan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18733</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zichuan Lin, Xiaokai Huang, Jiate Liu, Yuxuan Han, Jia Chen, Xiapeng Wu, Deheng Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chainarong Amornbunchornvej</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18732</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>3</mn></msup><mo>−</mo><mi>V</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">M^3-Verse</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal">erse</span></span></span></span>: A &quot;Spot the Difference&quot; Challenge for Large Multimodal Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kewei Wei, Bocheng Hu, Jie Cao, Xiaohan Chen, Zhengxi Lu, Wubing Xia, Weili Xu, Jiaao Wu, Junchen He, Mingyu Jia, Ciyun Zhao, Ye Sun, Yizhi Li, Zhonghan Zhao, Jian Zhang, Gaoang Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18735" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18735</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52a20f9bfaa32af67c363579cc4ad37ddbcaa7484f53c2ad3e6f6287dffcb22d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52a20f9bfaa32af67c363579cc4ad37ddbcaa7484f53c2ad3e6f6287dffcb22d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>3</mn></msup><mo>−</mo><mi>V</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">M^3-Verse</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal">erse</span></span></span></span>: A &quot;Spot the Difference&quot; Challenge for Large Multimodal Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Code2Doc: A Quality-First Curated Dataset for Code Documentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Recep Kaan Karaman, Meftun Akarsu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18748" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18748</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Code2Doc: A Quality-First Curated Dataset for Code Documentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IPCV: Information-Preserving Compression for MLLM Visual Encoders</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Chen, Zichen Wen, Yuzhou Wu, Xuyang Liu, Shuang Chen, Junpeng Ma, Weijia Li, Conghui He, Linfeng Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18747" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18747</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23f93076434c2a627bcdaf65dfd58999db9105798eceb360e343a3f4018cc020_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23f93076434c2a627bcdaf65dfd58999db9105798eceb360e343a3f4018cc020_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IPCV: Information-Preserving Compression for MLLM Visual Encoders</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jianyi Zhang, Shizhao Liu, Ziyin Zhou, Zhen Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18755" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18755</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/955c9d1fa243ab2977ec256331411b7bf6cca731527350187d399ec006ebe145_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/955c9d1fa243ab2977ec256331411b7bf6cca731527350187d399ec006ebe145_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lisan Al Amin, Vandana P. Janeja</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18797" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18797</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e389f385848f8816c83b5a1ff23be8e5adce564472d3ca92ed4e1c1107846a61_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e389f385848f8816c83b5a1ff23be8e5adce564472d3ca92ed4e1c1107846a61_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Dead Salmons of AI Interpretability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxime Méloux, Giada Dirupo, François Portet, Maxime Peyrard</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18792" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18792</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04addf8c4fc59dd6f1ac7d1afe6ee58894441304221e6091e61ac24a403fb54e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04addf8c4fc59dd6f1ac7d1afe6ee58894441304221e6091e61ac24a403fb54e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Dead Salmons of AI Interpretability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yichuan Zhang, Chengxin Li, Yujie Gu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18791" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18791</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FedVideoMAE: Efficient Privacy-Preserving Federated Video Moderation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziyuan Tao, Chuanzhi Xu, Sandaru Jayawardana, Wei Bao, Kanchana Thilakarathna, Teng Joon Lim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18809" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18809</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/396672768b4960b9fefe0f861b938a8b78842c8181043ded9d12c7e8f28dbdfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/396672768b4960b9fefe0f861b938a8b78842c8181043ded9d12c7e8f28dbdfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedVideoMAE: Efficient Privacy-Preserving Federated Video Moderation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Souhail Abdelmouaiz Sadat, Mohamed Yacine Touahria Miliani, Khadidja Hab El Hames, Hamida Seba, Mohammed Haddad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18826" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18826</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aditya Siddhant</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18829" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18829</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27fcee3d9ab3da4d05e9467a7467b02eecd9ce9ef97d79e927633356a26bb91b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27fcee3d9ab3da4d05e9467a7467b02eecd9ce9ef97d79e927633356a26bb91b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John S. Schreck, William E. Chapman, Charlie Becker, David John Gagne II, Dhamma Kimpara, Nihanth Cherukuru, Judith Berner, Kirsten J. Mayer, Negin Sobhani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18815" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18815</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Gao, Zhikun Xu, Xiao Ye, Ben Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18857</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bruno Campello de Souza</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18871" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18871</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18880" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18880</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kaidi Liang, Ke Li, Xianbiao Hu, Ruwen Qin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18878</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40cc111afbcdc76e8f9c40d867f3e3d92fefb4f06215bb877943f16f5fc7f761_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40cc111afbcdc76e8f9c40d867f3e3d92fefb4f06215bb877943f16f5fc7f761_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gökdeniz Gülmez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18901" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18901</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Szymon Rusiecki, Cecilia G. Morales, Kimberly Elenberg, Leonard Weiss, Artur Dubrawski</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18908" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18908</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40a7a336fdd61231fb69499563fa54a3feead11655ae2c62d612544da79b259a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40a7a336fdd61231fb69499563fa54a3feead11655ae2c62d612544da79b259a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shaokang Jiang, Daye Nam</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18925</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Michael S. Zhang, Rishi A. Ruia, Arnav Kewalram, Saathvik Dharmapuram, Utkarsh Sharma, Kevin Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Raina Panda, Daniel Fein, Arpita Singhal, Mark Fiore, Maneesh Agrawala, Matyas Bohacek</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18930" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18930</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17d9e52f35a5e302d613cba6423f95b6e9bb58c2b559fbd5a209c0516f8e2326_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17d9e52f35a5e302d613cba6423f95b6e9bb58c2b559fbd5a209c0516f8e2326_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Li Yan, Bolun Liu, Chao Li, Jing Liang, Kunjie Yu, Caitong Yue, Xuzhao Chai, Boyang Qu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18947" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18947</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46e7ee52db647b84d2f31cc7432f1e81dc459afc316c9b1daf014a0d4d28f5d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46e7ee52db647b84d2f31cc7432f1e81dc459afc316c9b1daf014a0d4d28f5d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18950</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhi Wang, Linan Yue, Min-Ling Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cheng-Hong Chang, Pei-Hsuan Tsai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05062b9ac64115654a255df578e1f3f61c6740d8e9db0b67ceca3387185661df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05062b9ac64115654a255df578e1f3f61c6740d8e9db0b67ceca3387185661df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kun Zhao, Siyuan Dai, Yingying Zhang, Guodong Liu, Pengfei Gu, Chenghua Lin, Paul M. Thompson, Alex Leow, Heng Huang, Lifang He, Liang Zhan, Haoteng Tang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18986</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinyan Liu, Zikang Chen, Qinchuan Wang, Tan Xie, Heming Zheng, Xudong Lv</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18999" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18999</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gyeongrok Oh, Youngdong Jang, Jonghyun Choi, Suk-Ju Kang, Guang Lin, Sangpil Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18991" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18991</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca47fc4083c13826225296ae5380ec0a994e6b8b0a936b8582bb3acb510605f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca47fc4083c13826225296ae5380ec0a994e6b8b0a936b8582bb3acb510605f6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19011" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19011</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjie Zhao, Xue Yu, Yongzhi Qi, Hao Hu, Jianshen Zhang, Yingzheng Ma, Shuyu Han, Wei Qi, Zuo-Jun Max Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19001" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19001</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Konstantin Kaulen, Tobias Ladner, Stanley Bak, Christopher Brix, Hai Duong, Thomas Flinkow, Taylor T. Johnson, Lukas Koller, Edoardo Manino, ThanhVu H Nguyen, Haoze Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19007</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hengrui Jia, Taoran Li, Jonas Guan, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19025" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19025</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Connor Kilrain, David Carlyn, Julia Chae, Sara Beery, Wei-Lun Chao, Jianyang Gu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19026" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19026</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9212089c44919f3c00bd82b13c0b39b407491c5d9de5c2c72ed790b2f0a0a2f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9212089c44919f3c00bd82b13c0b39b407491c5d9de5c2c72ed790b2f0a0a2f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Recontextualization Mitigates Specification Gaming without Modifying the Specification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ariana Azarbal, Victor Gillioz, Vladimir Ivanov, Bryce Woodworth, Jacob Drori, Nevan Wichers, Aram Ebtekar, Alex Cloud, Alexander Matt Turner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19027</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Recontextualization Mitigates Specification Gaming without Modifying the Specification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xu Liu, Yu Liu, Hanshuo Qiu, Yang Qirong, Zhouhui Lian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19024" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19024</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6756a03a5e10a12bbcf7c372024e83600363def7ecc93793c6ea6abf5fb1e097_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6756a03a5e10a12bbcf7c372024e83600363def7ecc93793c6ea6abf5fb1e097_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chi Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can abstract concepts from LLM improve SLM performance?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Siddharth Tandon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19069" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19069</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c5acb71114f63e96507f1b112ea484c287d603fcb8d6eff38459b7e748f327_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c5acb71114f63e96507f1b112ea484c287d603fcb8d6eff38459b7e748f327_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can abstract concepts from LLM improve SLM performance?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanzhi Zhang, Yitong Duan, Zhaoxi Zhang, Jiyan He, Shuxin Zheng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19081" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19081</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bc376ab7cffef097c2b5c88731fb39a3b1651cbf234ff265cff9da444c1ef62_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bc376ab7cffef097c2b5c88731fb39a3b1651cbf234ff265cff9da444c1ef62_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">γ(3,4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mopen">(</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> `Attention&#x27; in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mark Burgess</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19084</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72c21c32f8ba86f52bd19910dee8b59d7a15f63a4f5f0fffc1d598908faca89a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72c21c32f8ba86f52bd19910dee8b59d7a15f63a4f5f0fffc1d598908faca89a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">γ(3,4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mopen">(</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> `Attention&#x27; in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peiqing Lu, Yuan Zhang, Haoyun Zhang, Jiasen Zheng, Kejian Tong, Wenjun Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19093" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19093</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conditioning Accept-Desirability models in the context of AGM-like belief change</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kathelijne Coussement, Gert de Cooman, Keano De Vos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19096</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9a6821327555a097c992306a0343c693b0fa705a5154b551d5d3ec2af0af7fa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9a6821327555a097c992306a0343c693b0fa705a5154b551d5d3ec2af0af7fa_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conditioning Accept-Desirability models in the context of AGM-like belief change</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Danny Dongyeop Han, Yonghyeon Gwon, Ahhyun Lucy Lee, Taeyang Lee, Seong Jin Lee, Jubin Choi, Sebin Lee, Jihyun Bang, Seungju Lee, David Keetae Park, Shinjae Yoo, Chun Kee Chung, Jiook Cha</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19097</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Yang, Xiaoshuang Sheng, Zhengnan Zhang, Jidong Wu, Zexing Wang, Xin He, Shenghua Xu, Guanjing Xiong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19107</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e20091cfc0ac4fa7e40c8d6d14ca11096f0a2c018bfea46fd36ed88a815bde01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e20091cfc0ac4fa7e40c8d6d14ca11096f0a2c018bfea46fd36ed88a815bde01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoyu Jiang, Boan Qu, Junjie Zhu, Fanjie Zeng, Xiaojie Lin, Wei Zhong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19114" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19114</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chenghao Li, Chaoning Zhang, Yi Lu, Shuxu Chen, Xudong Wang, Jiaquan Zhang, Zhicheng Wang, Zhengxun Jin, Kuien Liu, Sung-Ho Bae, Guoqing Wang, Yang Yang, Hen Tao Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e824123c4e563edae3f7da6c1bb5757bd1fcb243770125d234d65f7ec4e4d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e824123c4e563edae3f7da6c1bb5757bd1fcb243770125d234d65f7ec4e4d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yin Jun Phua</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19155" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19155</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8c12473f43d4f07485e40276605a028c808372091757f33fc5847a97e4469d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8c12473f43d4f07485e40276605a028c808372091757f33fc5847a97e4469d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Geraud Nangue Tasse, Matthew Riemer, Benjamin Rosman, Tim Klinger</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19154" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19154</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vision-Language-Policy Model for Dynamic Robot Task Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jin Wang, Kim Tien Ly, Jacques Cloete, Nikos Tsagarakis, Ioannis Havoutis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19178" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19178</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61b83585238832b8c3decda632e24be3e08e065673710008da8a24e7fc11820b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61b83585238832b8c3decda632e24be3e08e065673710008da8a24e7fc11820b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vision-Language-Policy Model for Dynamic Robot Task Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19184" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19184</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Practical Quantum-Classical Feature Fusion for complex data Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19180</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Practical Quantum-Classical Feature Fusion for complex data Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19199</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tao Zhang, Ziqian Zeng, Hao Peng, Huiping Zhuang, Cen Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jerry Wang, Ting Yiu Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19210" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19210</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62c98c8f57888fd4ebe24a386db1767dce70baaed757b8ccaec8a6d19541746c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62c98c8f57888fd4ebe24a386db1767dce70baaed757b8ccaec8a6d19541746c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Minimal Fine-Tuning of VLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tiange Luo, Lajanugen Logeswaran, Jaekyeom Kim, Justin Johnson, Honglak Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19219" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19219</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/420c22fc5b580697b05c90c8fbf0115c2cea8a82f971a19f125c0456c3405309_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/420c22fc5b580697b05c90c8fbf0115c2cea8a82f971a19f125c0456c3405309_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Minimal Fine-Tuning of VLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Pixels to Predicates Structuring urban perception with scene graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yunlong Liu, Shuyang Li, Pengyuan Liu, Yu Zhang, Rudi Stouffs</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19221" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19221</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a8aa60cbd8f9c8016e6a36a9941d4f6c5a8af94206f4d30a8f70eac213a2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a8aa60cbd8f9c8016e6a36a9941d4f6c5a8af94206f4d30a8f70eac213a2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Pixels to Predicates Structuring urban perception with scene graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Valentin Schmidberger, Manuel Eberhardinger, Setareh Maghsudi, Johannes Maucher</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19228" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19228</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53ed231c85ea495143f9234046091abf1a755a2bae0a9a62789a4927a126a190_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53ed231c85ea495143f9234046091abf1a755a2bae0a9a62789a4927a126a190_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anna-Maria Gueorguieva, Aylin Caliskan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19238" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19238</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingxu Zhang, Dazhong Shen, Qi Zhang, Ying Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19240" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19240</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DeliveryBench: Can Agents Earn Profit in Real World?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjun Mao, Jiawei Ren, Kun Zhou, Jixuan Chen, Ziqiao Ma, Lianhui Qin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19234" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19234</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c24ad2486e536c4e46b7008f9b36fe0a1b521f054ff0b708d9260cb71032fa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c24ad2486e536c4e46b7008f9b36fe0a1b521f054ff0b708d9260cb71032fa7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DeliveryBench: Can Agents Earn Profit in Real World?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Do Minh Duc, Quan Xuan Truong, Nguyen Tat Dat, Nguyen Van Vinh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19247</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carla Crivoi, Radu Tudor Ionescu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19253" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19253</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiaao Wu, Xian Zhang, Fan Yang, Yinpeng Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19287" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19287</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b24f019b56baece009c93ac1107b1f8aea4b09d87df075427e81815567970f3d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b24f019b56baece009c93ac1107b1f8aea4b09d87df075427e81815567970f3d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ivan DeAndres-Tame, Chengwei Ye, Ruben Tolosana, Ruben Vera-Rodriguez, Shiqi Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d12748fd351c66664603a2df32d39e3ed4e526013cc4fc7f328dc001dea6e6a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d12748fd351c66664603a2df32d39e3ed4e526013cc4fc7f328dc001dea6e6a2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linzhi Chen, Yang Sun, Hongru Wei, Yuqi Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19297" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19297</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb0bd7eb8763e5b7b48b95fffa2b9d2689db5cbe27fd8dd5ff4a8a691095d826_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb0bd7eb8763e5b7b48b95fffa2b9d2689db5cbe27fd8dd5ff4a8a691095d826_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chang Dong, Jianfeng Tao, Chengliang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19280</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> A.A. Gde Yogi Pramana, Jason Ray, Anthony Jaya, Michael Wijaya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e59bf81bbcade919249cc70e6c7c857215e36f22480011e424fdeb4a1f6ca56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e59bf81bbcade919249cc70e6c7c857215e36f22480011e424fdeb4a1f6ca56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Alternative positional encoding functions for neural transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ezequiel Lopez-Rubio, Macoris Decena-Gimenez, Rafael Marcos Luque-Baena</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19323" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19323</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Alternative positional encoding functions for neural transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MAGIC: Achieving Superior Model Merging via Magnitude Calibration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19320" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19320</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MAGIC: Achieving Superior Model Merging via Magnitude Calibration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hui Li, Jiayue Lyu, Fu-Yun Wang, Kaihui Cheng, Siyu Zhu, Jingdong Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/333652b938a5ecac737d2dfcea2bae93a2f072e15ac1c354ce9b2da1931714cc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/333652b938a5ecac737d2dfcea2bae93a2f072e15ac1c354ce9b2da1931714cc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoyu Jiang, Fanjie Zeng, Boan Qu, Xiaojie Lin, Wei Zhong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19299</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f659480b32a80b6959cb66f4e981a4486e0674a48613b87e1f87ae33a24a364_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f659480b32a80b6959cb66f4e981a4486e0674a48613b87e1f87ae33a24a364_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> JiaWei Zhu, ZiHeng Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19349" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19349</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] First-Order Representation Languages for Goal-Conditioned RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19355" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19355</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> First-Order Representation Languages for Goal-Conditioned RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> A. B. M. Ashikur Rahman, Saeed Anwar, Muhammad Usman, Irfan Ahmad, Ajmal Mian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19350" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19350</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22263a25ed189a880450b2a3c8562fb8b0c96c8ec9fefce093363fc2ea2fb8f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22263a25ed189a880450b2a3c8562fb8b0c96c8ec9fefce093363fc2ea2fb8f6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning General Policies with Policy Gradient Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Blai Bonet, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19366</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning General Policies with Policy Gradient Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christian Hägg, Kathlén Kohn, Giovanni Luca Marchetti, Boris Shapiro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19367</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19379</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19396" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19396</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bef52c443ab4e7eee0649ff0f53fd382c9727d2345228eb8bb9fe5ad898a8eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bef52c443ab4e7eee0649ff0f53fd382c9727d2345228eb8bb9fe5ad898a8eb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yueyao Chen, Kai-Ni Wang, Dario Tayupo, Arnaud Huaulm&#x27;e, Krystel Nyangoh Timoh, Pierre Jannin, Qi Dou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19387</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d09473d7af5f8db0e2099dcd5a18592d023dddc412cada060f4f05596921ff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d09473d7af5f8db0e2099dcd5a18592d023dddc412cada060f4f05596921ff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Research Program: Theory of Learning in Dynamical Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Elad Hazan, Shai Shalev Shwartz, Nathan Srebro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19410" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19410</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Research Program: Theory of Learning in Dynamical Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Attention Is Not What You Need</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhang Chong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19428" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19428</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Attention Is Not What You Need</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fei Ge, Ying Huang, Jie Liu, Guixuan Zhang, Zhi Zeng, Shuwu Zhang, Hu Guan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19438</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c5f1cc5f1508ff7f3dac04d0e138fe9c30202bb132ef0c4725622de8caf6c5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c5f1cc5f1508ff7f3dac04d0e138fe9c30202bb132ef0c4725622de8caf6c5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19456" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19456</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Agentic Framework for Autonomous Materials Computation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zeyu Xia, Jinzhe Ma, Congjie Zheng, Shufei Zhang, Yuqiang Li, Hang Su, P. Hu, Changshui Zhang, Xingao Gong, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Mao Su</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19458" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19458</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Agentic Framework for Autonomous Materials Computation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lorenzo Capelli, Leandro de Souza Rosa, Gianluca Setti, Mauro Mangia, Riccardo Rovatti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19472" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19472</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Katharina Stengg, Christian Macho, Martin Pinzger</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19481" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19481</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nikita Volzhin, Soowhan Yoon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19494" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19494</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziyang Song, Zelin Zang, Zuyao Chen, Xusheng Liang, Dong Yi, Jinlin Wu, Hongbin Liu, Jiebo Luo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19512" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19512</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14f0ebe1771704c1788aacd2e3db88e7c3b990ef8113a061936422f9bb95889_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14f0ebe1771704c1788aacd2e3db88e7c3b990ef8113a061936422f9bb95889_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongliang Li, Nong Zhang, Zhewen Xu, Xiang Li, Changzheng Liu, Chongbo Zhao, Jie Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19506</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Bo Yin, Yaochu Jin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19516</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19526</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongsheng Xing, Qiuxin Si</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19530" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19530</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19535" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19535</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b20ae57f683974a6959785befd45010cb87dde73d9ccc345f16e11af116951e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b20ae57f683974a6959785befd45010cb87dde73d9ccc345f16e11af116951e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiawen Wang, Jingjing Wang Tianyang Chen, Min Zhang, Guodong Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19551" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19551</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdd63f7cc3d632dfdf950fc0474c659424578038c0958a942040653588c1bbd3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdd63f7cc3d632dfdf950fc0474c659424578038c0958a942040653588c1bbd3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Martin Sedlacek, Pavlo Yefanov, Georgy Ponimatkin, Jai Bardhan, Simon Pilc, Mederic Fourmy, Evangelos Kazakos, Cees G. M. Snoek, Josef Sivic, Vladimir Petrik</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19562</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cb99fa05ab76ebf7aa83d9c99a1cab512063ae25e6fb2fa7beee0f0c7246905_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cb99fa05ab76ebf7aa83d9c99a1cab512063ae25e6fb2fa7beee0f0c7246905_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lawrence Krukrubo, Julius Odede, Olawande Olusegun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19557" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19557</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4cf6d654019f56b56f3c2182b2db9d82b07540ace871f6684795ebe22f1a7c35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4cf6d654019f56b56f3c2182b2db9d82b07540ace871f6684795ebe22f1a7c35_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanliang Huang, Xia Yan, Peiran Yin, Zhenduo Zhang, Zeyan Shao, Youran Wang, Haoliang Huang, Matthias Althoff</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19564" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19564</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd9b53a38761715bf725e8473ae990f27df4fc7048b67ea4fde9ad955b4ac95d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd9b53a38761715bf725e8473ae990f27df4fc7048b67ea4fde9ad955b4ac95d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] BabyFlow: 3D modeling of realistic and expressive infant faces</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonia Alomar, Mireia Masias, Marius George Linguraru, Federico M. Sukno, Gemma Piella</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19560" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19560</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4bdcd1bc9dd6e1141b9b283f24968fbb4a40dc22257a719c5e16fbac178220f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4bdcd1bc9dd6e1141b9b283f24968fbb4a40dc22257a719c5e16fbac178220f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> BabyFlow: 3D modeling of realistic and expressive infant faces</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Angjelin Hila</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19570</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Exploring the features used for summary evaluation by Human and GPT</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zahra Sadeghi, Evangelos Milios, Frank Rudzicz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19620" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19620</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploring the features used for summary evaluation by Human and GPT</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MapTrace: Scalable Data Generation for Route Tracing on Maps</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Artemis Panagopoulou, Aveek Purohit, Achin Kulshrestha, Soroosh Yazdani, Mohit Goyal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19609" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19609</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7cc350a173ade821ef309bec6e6155158ae8332042895a8d6f45396c8b70c06_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7cc350a173ade821ef309bec6e6155158ae8332042895a8d6f45396c8b70c06_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MapTrace: Scalable Data Generation for Route Tracing on Maps</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Clustering with Label Consistency</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Diptarka Chakraborty, Hendrik Fichtenberger, Bernhard Haeupler, Silvio Lattanzi, Ashkan Norouzi-Fard, Ola Svensson</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19654" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19654</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73fc229d3b4fc51718fe8d59f9abfb97c5b0e2d37b67f22dacfc080be54754bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73fc229d3b4fc51718fe8d59f9abfb97c5b0e2d37b67f22dacfc080be54754bb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clustering with Label Consistency</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19673</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Argha Kamal Samanta, Harshika Goyal, Vasudha Joshi, Tushar Mungle, Pabitra Mitra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19663" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19663</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd268a98c5baac8b164ba733c255159614de6b969e8c6dd3f943fa74d98e5a1b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd268a98c5baac8b164ba733c255159614de6b969e8c6dd3f943fa74d98e5a1b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hanyang Kong, Xingyi Yang, Xiaoxu Zheng, Xinchao Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19678</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4f113f5d19fa4ca45dd649c8c074bdcd96d439b1640d1340c9f10070d3b5a62_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4f113f5d19fa4ca45dd649c8c074bdcd96d439b1640d1340c9f10070d3b5a62_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19691" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19691</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Regan, Ying Xie</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17923" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17923</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dongdong Yang, Bin Li, Jiguang He, Yicheng Yan, Xiaoyu Zhang, Chongwen Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sheryl Chen, Tony Wang, Kyle Feinstein</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17929" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17929</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ravi Prasad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17968" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17968</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Re-assessing the evidence for mental rotation abilities in children using computational models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Arthur Aubret, Jochen Triesch</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17972" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17972</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04b19b13a0170f5c8d0ddc85fcabbe83baa46fd0d40efd430823288b256d119b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04b19b13a0170f5c8d0ddc85fcabbe83baa46fd0d40efd430823288b256d119b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Re-assessing the evidence for mental rotation abilities in children using computational models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Muhammad Osama Imran, Roshni Lulla, Rodney Sappington</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17989" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17989</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Efficient Adjustment in Causal Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Isabela Belciug, Simon Ferreira, Charles K. Assaad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18315" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18315</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e651794ebebddd044adc102fdfd3e79c703c2f1d1bbe46f929abaf0866588f7c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e651794ebebddd044adc102fdfd3e79c703c2f1d1bbe46f929abaf0866588f7c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Efficient Adjustment in Causal Graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hee-Youl Kwak, Seong-Joon Park, Hyunwoo Jung, Jeongseok Ha, Jae-Won Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18273</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f5d84f1158c216751ab871ccb9ff92e39812054d2d89f523c363ba1d516324f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f5d84f1158c216751ab871ccb9ff92e39812054d2d89f523c363ba1d516324f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18263" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18263</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Illusion of Consistency: Selection-Induced Bias in Gated Kalman Innovation Statistics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Barak Or</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18508" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18508</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de95b749b6e41b5ecb30b6f99c2de21906ad83985f90b86407263b2e092757dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de95b749b6e41b5ecb30b6f99c2de21906ad83985f90b86407263b2e092757dd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Illusion of Consistency: Selection-Induced Bias in Gated Kalman Innovation Statistics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Yang, Chiyuan Wang, Andreas Schaab, Benjamin Moll</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18892</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Owning the Intelligence: Global AI Patents Landscape and Europe&#x27;s Quest for Technological Sovereignty</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lapo Santarlasci, Armando Rungi, Loredana Fattorini, Nestor Maslej</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19569</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d480c4d77b7eaba72c49770556d7fc5b5d3dfd78a176aef0d2a236de15ebeb67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d480c4d77b7eaba72c49770556d7fc5b5d3dfd78a176aef0d2a236de15ebeb67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Owning the Intelligence: Global AI Patents Landscape and Europe&#x27;s Quest for Technological Sovereignty</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-24">2025-12-24<a href="#2025-12-24" class="hash-link" aria-label="Direct link to 2025-12-24" title="Direct link to 2025-12-24" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251224] QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19696" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19696</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Automated Fault Detection in 5G Core Networks Using Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Parsa Hatami, Ahmadreza Majlesara, Ali Majlesi, Babak Hossein Khalaj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19697" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19697</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51195e88b90e075513d8e30088f944c9008c4dee4bc84af09cdce6bb8a7b71e4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51195e88b90e075513d8e30088f944c9008c4dee4bc84af09cdce6bb8a7b71e4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automated Fault Detection in 5G Core Networks Using Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Md Nahid Hasan Shuvo, Moinul Hossain</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19711</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxuan Yin, Shengke Zhou, Yunjie Zhang, Ajay Mohindra, Boxun Xu, Peng Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19701</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Behrooz Mamandipoor, Chun-Nan Hsu, Martin Krause, Ulrich H. Schmidt, Rodney A. Gabriel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19716</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19707</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19717</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Lv, Siqi Ai, Yanbin Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19719" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19719</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Tiny, On-Device Decision Makers with the MiniConv Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carlos Purves</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19726</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tiny, On-Device Decision Makers with the MiniConv Library</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] High-Performance Self-Supervised Learning by Joint Training of Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kosuke Ukita, Tsuyoshi Okita</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19729" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19729</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> High-Performance Self-Supervised Learning by Joint Training of Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Clément Elliker, Jesse Read, Sonia Vanier, Albert Bifet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gongli Xi, Ye Tian, Mengyu Yang, Zhenyu Zhao, Yuchao Zhang, Xiangyang Gong, Xirong Que, Wendong Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19736</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sasan Sharifipour, Constantino Álvarez Casado, Manuel Lage Cañellas, Miguel Bordallo López</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19743" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19743</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumin Park, Noseong Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19765" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19765</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A K-Means, Ward and DBSCAN repeatability study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anthony Bertrand, Engelbert Mephu Nguifo, Violaine Antoine, David Hill</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19772" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19772</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A K-Means, Ward and DBSCAN repeatability study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Tarizzo, Mohammad Kazemi, Deniz Gündüz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19777" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19777</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ivan Daunis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19769</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19758" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19758</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19799" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19799</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UCCL-EP: Portable Expert-Parallel Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19849</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UCCL-EP: Portable Expert-Parallel Communication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19882" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19882</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81c6462c8b784a5ac97bed22a2eedfc4c0fbad0afad1bab0e0a9aab3730a1834_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81c6462c8b784a5ac97bed22a2eedfc4c0fbad0afad1bab0e0a9aab3730a1834_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19864" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19864</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fine-Tuned In-Context Learners for Efficient Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19879" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19879</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fine-Tuned In-Context Learners for Efficient Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sujan Warnakulasooriya, Andreas Willig, Xiaobing Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19914" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19914</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/188da8ba7b74e5b961c0e61a49776e60da92670b4dd0b522d0c74e156682ec49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/188da8ba7b74e5b961c0e61a49776e60da92670b4dd0b522d0c74e156682ec49_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Indranil Halder, Cengiz Pehlevan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19905" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19905</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxime Lacour, Pu Ren, Rie Nakata, Nori Nakata, Michael Mahoney</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19909" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19909</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Unified Brain Surface and Volume Registration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> S. Mazdak Abulnaga, Andrew Hoopes, Malte Hoffmann, Robin Magnet, Maks Ovsjanikov, Lilla Zöllei, John Guttag, Bruce Fischl, Adrian Dalca</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52472b7c53844ab7af247ff699ee1c659d2b3ff27e2e21ee8f187677824a5d8d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52472b7c53844ab7af247ff699ee1c659d2b3ff27e2e21ee8f187677824a5d8d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unified Brain Surface and Volume Registration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Samruddhi Baviskar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19935" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19935</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Vehicle-centric Perception via Multimodal Structured Pre-training</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Wu, Xiao Wang, Chenglong Li, Jin Tang, Bin Luo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vehicle-centric Perception via Multimodal Structured Pre-training</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19937" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19937</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67e83c33b123e956d61ade807a7eb155837dc60f3e60e67f0209df1eb75d7639_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67e83c33b123e956d61ade807a7eb155837dc60f3e60e67f0209df1eb75d7639_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Block-Recurrent Dynamics in Vision Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Block-Recurrent Dynamics in Vision Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How Much 3D Do Video Foundation Models Encode?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19949</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54fab192e555a908a0f7daf8d7992c85cd3241844d6a17c19d685c99c93dc5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54fab192e555a908a0f7daf8d7992c85cd3241844d6a17c19d685c99c93dc5e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How Much 3D Do Video Foundation Models Encode?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Rodrigo Pereira David, Rodrigo Tripodi Calumby</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19957</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/307d3e337ca6d53335e1861afc2551a5e05ba3baffbfb580ffc6378d16a74e2f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/307d3e337ca6d53335e1861afc2551a5e05ba3baffbfb580ffc6378d16a74e2f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Luciano Araujo Dourado Filho, Rodrigo Tripodi Calumby</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19960" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19960</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbfda29c0b0fd29ef417a6aed2c9021c6a676577f450cbc925474212756dbba1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbfda29c0b0fd29ef417a6aed2c9021c6a676577f450cbc925474212756dbba1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Yin, Xiaodong Gu, Beijun Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19980</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19995" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19995</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] S<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>IT: A Benchmark for Spatially Situated Social Intelligence Test</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19992" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19992</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> S<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>IT: A Benchmark for Spatially Situated Social Intelligence Test</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Gao, Zhenguo Dong, Xuelong Wang, Zhiqiang Wang, Yong Zhang, Shaofan Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20028</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sangoh Lee, Sangwoo Mo, Wook-Shin Han</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbb9757af838ced105aac295c936d5bf2fa52c5f79d162d34ed41c9c961ae9e0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbb9757af838ced105aac295c936d5bf2fa52c5f79d162d34ed41c9c961ae9e0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nguyen Lam Phu Quy, Pham Phu Hoa, Tran Chi Nguyen, Dao Sy Duy Minh, Nguyen Hoang Minh Ngoc, Huynh Trung Kiet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20042" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20042</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fb136c3c44d734ccd03ee7608dfc92d3612b466bfffc82e1d2efdfd79e5f161_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fb136c3c44d734ccd03ee7608dfc92d3612b466bfffc82e1d2efdfd79e5f161_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learning Skills from Action-Free Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20052" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20052</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def215474b82a6d04f6a6f79dc99c74e3b1159e34a80855d18649f29781a36fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def215474b82a6d04f6a6f79dc99c74e3b1159e34a80855d18649f29781a36fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Skills from Action-Free Videos</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] An Optimal Policy for Learning Controllable Dynamics by Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peter N. Loxley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Optimal Policy for Learning Controllable Dynamics by Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Discovering Lie Groups with Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jung Yeon Park, Yuxuan Chen, Floor Eijkelboom, Jan-Willem van de Meent, Lawson L.S. Wong, Robin Walters</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/806c459fa9197bda13199f58531fce983ef12854f6eb2e8acaaea33dfebd6a22_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/806c459fa9197bda13199f58531fce983ef12854f6eb2e8acaaea33dfebd6a22_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Discovering Lie Groups with Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Scaling Reinforcement Learning for Content Moderation with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Reinforcement Learning for Content Moderation with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reason2Decide: Rationale-Driven Multi-Task Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20074" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20074</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reason2Decide: Rationale-Driven Multi-Task Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sangryu Park, Gihyuk Ko, Homook Cho</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20062" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20062</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hao Li, Fabian Deuser, Wenping Yin, Steffen Knoblauch, Wufan Zhao, Filip Biljecki, Yong Xue, Wei Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20056" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20056</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c37110ad3319d1434c17c04ae94a4dcfa94a278faf51360e359e1a063ce32e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c37110ad3319d1434c17c04ae94a4dcfa94a278faf51360e359e1a063ce32e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dianxuan Fu, Xiaomin Liu, Yihao Zhang, Shikui Shen, Weisheng Hu, Qunbi Zhuge</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20080</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b7f27ae92944936b92479ef7c0a55f8c448c532444c4f43131d8768483bda71_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b7f27ae92944936b92479ef7c0a55f8c448c532444c4f43131d8768483bda71_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chaithra, Kamesh Kadimisetty, Biju R Mohan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20082</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jeehong Kim, Youngseok Hwang, Minchan Kim, Sungho Bae, Hyunwoo Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20086</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanjie Li, Jian Xu, Xueqing Chen, Lina Yu, Shiming Xiang, Weijun Li, Cheng-lin Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20084</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinyoung Choi, Youngchae Kwon, Injung Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20088" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20088</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1946d7c3329c37db07556d963544aad7dbfeda194c515e4debdc6e3754d8920_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1946d7c3329c37db07556d963544aad7dbfeda194c515e4debdc6e3754d8920_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Evolutionary Neural Architecture Search with Dual Contrastive Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xian-Rong Zhang, Yue-Jiao Gong, Wei-Neng Chen, Jun Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20112" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20112</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/659d1805ddb5e7863af4ee9eeedcfdd78686f84f207247f4d0e65555165f2577_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/659d1805ddb5e7863af4ee9eeedcfdd78686f84f207247f4d0e65555165f2577_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evolutionary Neural Architecture Search with Dual Contrastive Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20111" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20111</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20145</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] M<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20136" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20136</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> M<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xingyou Yin, Ceyao Zhang, Min Hu, Kai Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20140" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20140</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4380a71bf6060d158bfda4324d258b0056d7685334fc2256c0df38315036c209_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4380a71bf6060d158bfda4324d258b0056d7685334fc2256c0df38315036c209_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fun-Audio-Chat Technical Report</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20156" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20156</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fun-Audio-Chat Technical Report</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20159" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20159</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dhivya Dharshini Kannan, Anupam Trivedi, Dipti Srinivasan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20161" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20161</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1417550973096c816c854e8c26e0184adfd5d9410e4449d0498cc343fd80cc27_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1417550973096c816c854e8c26e0184adfd5d9410e4449d0498cc343fd80cc27_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Concept Generalization in Humans and Large Language Models: Insights from the Number Game</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Arghavan Bazigaran, Hansem Sohn</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20162" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20162</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f33aa8c0a9e961f65d06bf913a8cd4cb96d114bf3d4806d5932ebcb99dbac9d2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f33aa8c0a9e961f65d06bf913a8cd4cb96d114bf3d4806d5932ebcb99dbac9d2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Concept Generalization in Humans and Large Language Models: Insights from the Number Game</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20164" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20164</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Songze Li, Jiameng Cheng, Yiming Li, Xiaojun Jia, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20168" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20168</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FaithLens: Detecting and Explaining Faithfulness Hallucination</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20182" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20182</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FaithLens: Detecting and Explaining Faithfulness Hallucination</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Offline Safe Policy Optimization From Heterogeneous Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ze Gong, Pradeep Varakantham, Akshat Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20173" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20173</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Safe Policy Optimization From Heterogeneous Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Teqiang Zou, Hongliang Zeng, Yuxuan Nong, Yifan Li, Kehui Liu, Haotian Yang, Xinyang Ling, Xin Li, Lianyang Ma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20188" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20188</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2574b3e0fe38bea23055b8f04a72d9d1bf8fedc2ee3f2dcf7a4e5a2f16af3c51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2574b3e0fe38bea23055b8f04a72d9d1bf8fedc2ee3f2dcf7a4e5a2f16af3c51_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20204</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TongSIM: A General Platform for Simulating Intelligent Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Sun, Kunlun Wu, Chuanjian Fu, Zeming Song, Langyong Shi, Zihe Xue, Bohan Jing, Ying Yang, Xiaomeng Gao, Aijia Li, Tianyu Guo, Huiying Li, Xueyuan Yang, Rongkai Liu, Xinyi He, Yuxi Wang, Yue Li, Mingyuan Liu, Yujie Lu, Hongzhao Xie, Shiyun Zhao, Bo Dai, Wei Wang, Tao Yuan, Song-Chun Zhu, Yujia Peng, Zhenliang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TongSIM: A General Platform for Simulating Intelligent Machines</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MemR<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Memory Retrieval via Reflective Reasoning for LLM Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xingbo Du, Loka Li, Duzhen Zhang, Le Song</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20237" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20237</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59b81bde40292c52d66676e0cadc37d954f64fdf390b55d610cd63316ed43ef4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59b81bde40292c52d66676e0cadc37d954f64fdf390b55d610cd63316ed43ef4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MemR<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Memory Retrieval via Reflective Reasoning for LLM Agents</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tarik Houichime, Abdelghani Souhar, Younes El Amrani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Divya Vijay, Vignesh Ethiraj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20278" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20278</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f0ca1a3004807c69fa2a7198569167a93240c27f60163c26979dcccdf6072f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f0ca1a3004807c69fa2a7198569167a93240c27f60163c26979dcccdf6072f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20276" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20276</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b076c18a7407a2fa23f502051cf18d209fb696f05cbca7af89a2db3703250585_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b076c18a7407a2fa23f502051cf18d209fb696f05cbca7af89a2db3703250585_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><msup><mo stretchy="false">}</mo><mo stretchy="false">{</mo></msup><mn>3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}^\{3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">{</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mclose">}</span></span></span></span>{ETOR}: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebiasing for Weakly-Supervised Camouflaged Object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>etection with Scribble Annotations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiawei Ge, Jiuxin Cao, Xinyi Li, Xuelin Zhu, Chang Liu, Bo Liu, Chen Feng, Ioannis Patras</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20260" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20260</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee0606d3fe6e6ae30bbf9417baa7948dab878cfcc6b70e36031424c107aafb81_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee0606d3fe6e6ae30bbf9417baa7948dab878cfcc6b70e36031424c107aafb81_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><msup><mo stretchy="false">}</mo><mo stretchy="false">{</mo></msup><mn>3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}^\{3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">{</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mclose">}</span></span></span></span>{ETOR}: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebiasing for Weakly-Supervised Camouflaged Object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>etection with Scribble Annotations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20288" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20288</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6106b87e48429449f0b11c2765bdedb47797d7822e4b38ad3a9fe7f94b92dacb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6106b87e48429449f0b11c2765bdedb47797d7822e4b38ad3a9fe7f94b92dacb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20298</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20292" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20292</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Joon Son Chung, Shinji Watanabe</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20296" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20296</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/217e6d95bfc0e38be8f5a7356d3e869c3b3a5b9d4daf05b6435c3c756df247c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/217e6d95bfc0e38be8f5a7356d3e869c3b3a5b9d4daf05b6435c3c756df247c6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhongyu Xia, Wenhao Chen, Yongtao Wang, Ming-Hsuan Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20299</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0961ae49fbc925ad5eacb6602aeec6cfdfabae07b252a044cd181bdb5a47746_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0961ae49fbc925ad5eacb6602aeec6cfdfabae07b252a044cd181bdb5a47746_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20312</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Toward Explaining Large Language Models in Software Engineering Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20328" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20328</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Explaining Large Language Models in Software Engineering Tasks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junren Li, Luhua Lai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e8cac7516cbb65a566c19ba7dde5921369f69a0fe2fe62a1ee10bb383644f7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e8cac7516cbb65a566c19ba7dde5921369f69a0fe2fe62a1ee10bb383644f7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20344</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9f502578578854e6ba573a8a7758a3229a45ec3bf4a1c2e637d1006bb31aa1c4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9f502578578854e6ba573a8a7758a3229a45ec3bf4a1c2e637d1006bb31aa1c4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20363" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20363</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen&#x27;s Kappa and Semantic Similarity for Qualitative Research Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen&#x27;s Kappa and Semantic Similarity for Qualitative Research Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Identifying Appropriately-Sized Services with Deep Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20381" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20381</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Appropriately-Sized Services with Deep Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20387</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20407" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20407</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simplifying Multi-Task Architectures Through Task-Specific Normalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mihai Suteu, Ovidiu Serban</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20420" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20420</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simplifying Multi-Task Architectures Through Task-Specific Normalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Adam Elaoumari</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20423" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20423</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b67cb70660ec29cf307ab6baf5a52c6e3cecc0888ba9656259ee05bcfef71b96_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b67cb70660ec29cf307ab6baf5a52c6e3cecc0888ba9656259ee05bcfef71b96_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junho Yoon, Jaemo Jung, Hyunju Kim, Dongman Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20409" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20409</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d4c944d1aa99e38d69c83c388503646f62271c8bb649aafcafb57ad0ba7c7d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d4c944d1aa99e38d69c83c388503646f62271c8bb649aafcafb57ad0ba7c7d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20469" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20469</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20482" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20482</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Benchmarking LLMs for Predictive Applications in the Intensive Care Units</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20520" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20520</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/274c8c98260b88efe758b67759790448f6c4f5abe21a32dafdc4d3a311f9524b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/274c8c98260b88efe758b67759790448f6c4f5abe21a32dafdc4d3a311f9524b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Benchmarking LLMs for Predictive Applications in the Intensive Care Units</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Advancing Multimodal Teacher Sentiment Analysis<!-- -->:The<!-- --> Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20548" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20548</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb1b5cafe85ffb670c8629adfcf70c1f2a8ef006559d14cc0f3ad75463909ad8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb1b5cafe85ffb670c8629adfcf70c1f2a8ef006559d14cc0f3ad75463909ad8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Advancing Multimodal Teacher Sentiment Analysis<!-- -->:The<!-- --> Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20563" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20563</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Distilling to Hybrid Attention Models via KL-Guided Layer Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20569</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Distilling to Hybrid Attention Models via KL-Guided Layer Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Performative Policy Gradient: Optimality in Performative Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Performative Policy Gradient: Optimality in Performative Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Pan, Zhuofu Chen, Ravi Netravali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20586</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dhruv Anand, Ehsan Shareghi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20595" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20595</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20589" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20589</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LongVideoAgent: Multi-Agent Reasoning with Long Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LongVideoAgent: Multi-Agent Reasoning with Long Videos</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generative AI for Analysts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Xue, Qian Zhang, Wu Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19705" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19705</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c446bca4991916c167230d9d5b7a57cb785d6214690dca03a9aacef2ebddb67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c446bca4991916c167230d9d5b7a57cb785d6214690dca03a9aacef2ebddb67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative AI for Analysts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QMBench: A Research Level Benchmark for Quantum Materials Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanzhen Wang, Yiyang Jiang, Diana Golovanova, Kamal Das, Hyeonhu Bae, Yufei Zhao, Huu-Thong Le, Abhinava Chatterjee, Yunzhe Liu, Chao-Xing Liu, Felipe H. da Jornada, Binghai Yan, Xiao-Liang Qi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19753" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19753</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QMBench: A Research Level Benchmark for Quantum Materials Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alexis Pomares Pastor, Ines Ribeiro Violante, Gregory Scott</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20319" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20319</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb7898ab29ae44cef389712101b2dbc98a334b5761ab3b2e5825364d8f3f316_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb7898ab29ae44cef389712101b2dbc98a334b5761ab3b2e5825364d8f3f316_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Regression of Functions by Quantum Neural Networks Circuits</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fernando M. de Paula Neto, Lucas dos Reis Silva, Paulo S. G. de Mattos Neto, Felipe F. Fanchini</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19978</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad43eefe70b19a60b4cb6a98a6af78a755ad48beb67110a54813ba3e49fc1d5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad43eefe70b19a60b4cb6a98a6af78a755ad48beb67110a54813ba3e49fc1d5e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Regression of Functions by Quantum Neural Networks Circuits</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Muhammad Usman, Azka Rehman, Muhammad Mutti Ur Rehman, Abd Ur Rehman, Muhammad Umar Farooq</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20436</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdfcdd8483dd2617be0701188cb1e86708fc680b1516caff77f5075ed2baf49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdfcdd8483dd2617be0701188cb1e86708fc680b1516caff77f5075ed2baf49_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-25T03:58:05.000Z" itemprop="dateModified">Dec 25, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251215-20251221 (cs.AI)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/csar"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.AR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-22" class="table-of-contents__link toc-highlight">2025-12-22</a></li><li><a href="#2025-12-23" class="table-of-contents__link toc-highlight">2025-12-23</a></li><li><a href="#2025-12-24" class="table-of-contents__link toc-highlight">2025-12-24</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>