<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_AI/20251222-20251228" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251222-20251228 (cs.AI) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251222-20251228 (cs.AI) | AI头条"><meta data-rh="true" name="description" content="2025-12-22"><meta data-rh="true" property="og:description" content="2025-12-22"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.AI","item":"https://jokebear666.github.io/ai_toutiao/daily/csai"},{"@type":"ListItem","position":3,"name":"20251222-20251228 (cs.AI)","item":"https://jokebear666.github.io/ai_toutiao/daily/csai/20251222-20251228"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.647bd1ff.css">
<script src="/ai_toutiao/assets/js/runtime~main.f73b021c.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.6153aad8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Collapse sidebar category &#x27;cs.AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><span title="20251215-20251221 (cs.AI)" class="linkLabel_WmDU">20251215-20251221 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/csai/20251222-20251228"><span title="20251222-20251228 (cs.AI)" class="linkLabel_WmDU">20251222-20251228 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/csai/20251229-20260104"><span title="20251229-20260104 (cs.AI)" class="linkLabel_WmDU">20251229-20260104 (cs.AI)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/csai"><span>cs.AI</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251222-20251228 (cs.AI)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251222-20251228 (cs.AI)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-22">2025-12-22<a href="#2025-12-22" class="hash-link" aria-label="Direct link to 2025-12-22" title="Direct link to 2025-12-22" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251222] Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge representation and reasoning], [entity set expansion, expansion graph, logical formula, semantic inclusion, computational complexity]</li>
<li class=""><strong>authors:</strong> Pietro Cofone, Giovanni Amendola, Marco Manna, Aldo Ricioppo</li>
<li class=""><strong>institution:</strong> University of Calabria, University of Cyprus</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16953" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16953</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a logic-based framework using expansion graphs, which are rooted directed acyclic graphs, to support taxonomic expansions of entity sets from knowledge bases. To avoid the impracticality of fully materializing these potentially large graphs, the authors formalize efficient reasoning tasks to check relationships between entity tuples within the graph structure. Their main conclusion is that, under realistic assumptions like bounded input, these tasks can be implemented efficiently, enabling local and incremental navigation without full graph construction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Lights, Camera, Consistency: A Multistage Pipeline for Character-Stable AI Video Stories</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [visual anchoring, asset-first mechanism, temporal bridge, diffusion models, large language model (LLM), text-to-video (T2V), character consistency, multi-stage pipeline]</li>
<li class=""><strong>authors:</strong> Chayan Jain, Rishant Sharma, Archit Garg, Ishan Bhanuka, Pratik Narang, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> BITS Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16954</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-stage pipeline for generating long, character-consistent video stories. It uses an LLM to create a script, a text-to-image model to design consistent character visuals as anchors, and a video generation model to synthesize scenes individually, with a temporal bridge linking them. The method&#x27;s necessity is validated by showing that removing visual anchoring causes a catastrophic drop in character consistency, and cultural biases in current models are also analyzed.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Enhancing Tree Species Classification: Insights from YOLOv8 and Explainable AI Applied to TLS Point Cloud Projections</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [YOLOv8, Finer-CAM, saliency maps, cross-validation, TLS point cloud projections]</li>
<li class=""><strong>authors:</strong> Adrian Straker, Paul Magdon, Marco Zullich, Maximilian Freudenberg, Christoph Kleinn, Johannes Breidenbach, Stefano Puliti, Nils Nölke</li>
<li class=""><strong>institution:</strong> University of Applied Sciences and Art (HAWK), University of Groningen, University of Göttingen, Norwegian Institute of Bioeconomy Research (NIBIO)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16950</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel method that links Finer-CAM explanations to structural segments in TLS point cloud projections to evaluate which features drive tree species classification using YOLOv8 models. The analysis of saliency maps reveals that models primarily rely on crown features for classification, with stem features being more important for certain species, and that the models&#x27; perception of species similarity aligns with human expert judgment. The results underscore the need for explainable AI to understand model decision processes and build confidence in predictions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Optimizing Text Search: A Novel Pattern Matching Algorithm Based on Ukkonen&#x27;s Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [pattern matching algorithms], [Ukkonen&#x27;s Algorithm, Suffix Trees, pattern recognition, text-search algorithms]</li>
<li class=""><strong>authors:</strong> Xinyu Guan, Shaohua Zhang</li>
<li class=""><strong>institution:</strong> Not specified</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16927" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16927</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a novel pattern matching algorithm that combines Ukkonen&#x27;s Algorithm for constructing Suffix Trees with a new search technique using Python&#x27;s dynamic link attributes. The optimized algorithm demonstrates linear time and space efficiency, outperforming traditional methods like Naive Search, KMP, and Boyer-Moore, and achieves 100% accuracy in tasks such as genomic sequence pattern recognition.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] V-Agent: An Interactive Video Search System Using Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [vision-language model, fine-tuning, retrieval vector, re-ranking, multi-agent system]</li>
<li class=""><strong>authors:</strong> SunYoung Park, Jong-Hyeon Lee, Youngjune Kim, Daegyu Sung, Younghyun Yu, Young-rok Cha, Jeongho Ju</li>
<li class=""><strong>institution:</strong> NC AI, Kakao, Korea Advanced Institute of Science and Technology (KAIST)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16925</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e827044257e239766415ac9500a06f7ddb67bfc47c517c041d42cc61ac33ad18_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> V-Agent is a multi-agent video search system that fine-tunes a vision-language model with a small video preference dataset and enhances it with a retrieval vector to embed video frames and audio transcriptions into a shared multimodal space. It uses three agents—routing, search, and chat—to refine searches and interact with users, achieving state-of-the-art zero-shot performance on the MultiVENT 2.0 benchmark.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PAACE: A Plan-Aware Automated Agent Context Engineering Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [context engineering, plan-aware compression, next-k-task relevance, instruction co-refinement, function-preserving compression, synthetic data generation, knowledge distillation]</li>
<li class=""><strong>authors:</strong> Kamer Ali Yuksel</li>
<li class=""><strong>institution:</strong> aiXplain Inc</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16970</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, long-term memory, semantic imitation, indirect injection attack, memory poisoning, MetaGPT, DataInterpreter]</li>
<li class=""><strong>authors:</strong> Saksham Sahai Srivastava, Haoyu He</li>
<li class=""><strong>institution:</strong> University of Georgia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16962" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16962</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MemoryGraft, a novel attack that poisons an LLM agent&#x27;s long-term memory by implanting malicious successful experiences, which are then retrieved and imitated during future tasks. The method exploits the agent&#x27;s semantic imitation heuristic through a poisoned RAG store, leading to persistent behavioral compromise. The authors demonstrate that this attack can cause significant and stealthy behavioral drift in agents like MetaGPT&#x27;s DataInterpreter.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [discrete video tokenization, transformer-based adaptive compressor, evidence lower bound (ELBO), information-theoretic compression, adaptive tokenization]</li>
<li class=""><strong>authors:</strong> Haotian Ye, Qiyuan He, Jiaqi Han, Puheng Li, Jiaojiao Fan, Zekun Hao, Fitsum Reda, Yogesh Balaji, Huayu Chen, Sheng Liu, Angela Yao, James Zou, Stefano Ermon, Haoxiang Wang, Ming-Yu Liu</li>
<li class=""><strong>institution:</strong> NVIDIA, Stanford University, National University of Singapore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16975" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16975</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da83017a41e69234160f2c416b8a94507a537a66fd8a745a6bafc49c06817395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da83017a41e69234160f2c416b8a94507a537a66fd8a745a6bafc49c06817395_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces InfoTok, a principled framework for adaptive discrete video tokenization based on information theory, using a novel ELBO-based algorithm and a transformer-based adaptive compressor. It achieves state-of-the-art compression by allocating tokens according to informational richness, saving 20% of tokens without performance loss and outperforming prior heuristic approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific ai evaluation], [Practical Inquiry Model (PIM), SGI-Bench, Test-Time Reinforcement Learning (TTRL), retrieval-augmented novelty, agent-based evaluation]</li>
<li class=""><strong>authors:</strong> Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu</li>
<li class=""><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Unexpected Knowledge: Auditing Wikipedia and Grokipedia Search Recommendations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [search engine audit, semantic alignment, topical annotation, trajectory analysis]</li>
<li class=""><strong>authors:</strong> Erica Coppolillo, Simone Mungari</li>
<li class=""><strong>institution:</strong> University of Calabria, ICAR-CNR, University of Southern California</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17027</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper conducts a comparative audit of search engine recommendations on Wikipedia and Grokipedia by analyzing over 70,000 results from nearly 10,000 neutral English word queries. It finds that both platforms frequently generate weakly related or unexpected results from innocuous queries, though their recommendation sets often differ substantially in topical distribution and exploration trajectories.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Women&#x27;s Health Benchmark for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [healthcare AI evaluation], [women&#x27;s health benchmark, large language models, error types, model stumps, query types]</li>
<li class=""><strong>authors:</strong> Victoria-Elisabeth Gruber, Razvan Marinescu, Diego Fajardo, Amin H. Nassar, Christopher Arkfeld, Alexandria Ludlow, Shama Patel, Mehrnoosh Samaei, Valerie Klug, Anna Huber, Marcel Gühner, Albert Botta i Orfila, Irene Lagoja, Kimya Tarr, Haleigh Larson, Mary Beth Howard</li>
<li class=""><strong>institution:</strong> Lumos AI, Yale Cancer Center, Harvard Medical School, UCSF, Brown University, Emory University, Clinic Ottakring, NHS, Yale School of Medicine, Johns Hopkins University School of Medicine</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17028</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Women&#x27;s Health Benchmark (WHB), a novel evaluation framework comprising 96 validated model stumps across five medical specialties, three query types, and eight error types to assess LLM performance in women&#x27;s health. It finds that current LLMs have approximately 60% failure rates, with significant weaknesses in detecting urgency, indicating they are not yet reliable for providing women&#x27;s health advice.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Security Risks of Agentic Vehicles: A Systematic Analysis of Cognitive and Cross-Layer Threats</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [agentic AI, cross-layer threats, role-based architecture, severity matrix, attack-chain analysis, OWASP]</li>
<li class=""><strong>authors:</strong> Ali Eslami, Jiangbo Yu</li>
<li class=""><strong>institution:</strong> Unknown</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17041" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17041</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a role-based architecture for Agentic Vehicles to systematically analyze security threats, including cognitive vulnerabilities and cross-layer risks. It concludes by providing a structured framework for assessing how small distortions can escalate into unsafe behavior in both human-driven and autonomous vehicles.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adversarial attacks, deep learning, cybersickness detection, visual tunneling, MI-FGSM, PGD, C&amp;W, DeepTCN, Transformer]</li>
<li class=""><strong>authors:</strong> Istiak Ahmed, Ripan Kumar Kundu, Khaza Anuarul Hoque</li>
<li class=""><strong>institution:</strong> University of Missouri-Columbia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17029" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17029</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Adversarial-VR, an open-source Unity testbed that integrates DeepTCN and Transformer models for real-time cybersickness detection and mitigation, and evaluates their robustness against adversarial attacks like MI-FGSM, PGD, and C&amp;W. The results show these attacks can successfully fool the system, significantly degrading model accuracy and preventing correct mitigation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge graph question answering], [reinforcement learning, subgraph selection, graph pruning, llm fine-tuning, relation-centric reasoning]</li>
<li class=""><strong>authors:</strong> Yinxu Tang, Chengsong Huang, Jiaxin Huang, William Yeoh</li>
<li class=""><strong>institution:</strong> Washington University in St. Louis</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/069fd74faaf7500b76c5bd6958a190a707d8ccbe86484c3026a357b38657a47a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces UniRel-R1, a framework for relation-centric knowledge graph question answering that integrates subgraph selection, multi-stage graph pruning, and an LLM fine-tuned with reinforcement learning. The method is designed to identify compact and informative subgraph answers by rewarding specific relations and lower-degree entities. Experiments show it outperforms baselines in connectivity and reward and generalizes well to unseen entities and relations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Realistic threat perception drives intergroup conflict: A causal, dynamic analysis using generative-agent simulations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [social simulation], [large language model, generative agents, causal analysis, intergroup conflict, threat perception]</li>
<li class=""><strong>authors:</strong> Suhaib Abdurahman, Farzan Karimi-Malekabadi, Chenxiao Yu, Nour S. Kteily, Morteza Dehghani</li>
<li class=""><strong>institution:</strong> University of Southern California, Northwestern University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17066</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses simulations with LLM-driven generative agents in virtual societies to causally analyze intergroup conflict. It finds that realistic threat directly increases hostility, while symbolic threat has a weaker effect mediated by ingroup bias and only increases hostility when realistic threat is absent.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [knowledge distillation, chain-of-thought, structured reasoning, query execution plan, text-to-sql]</li>
<li class=""><strong>authors:</strong> Khushboo Thaker, Yony Bresler</li>
<li class=""><strong>institution:</strong> Crater Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Struct-SQL, a knowledge distillation framework that trains a small language model using a structured chain-of-thought derived from query execution plans, rather than unstructured reasoning traces. The distilled model achieves an 8.1% absolute improvement over an unstructured baseline, primarily due to a reduction in syntactic errors. This demonstrates that structured logical blueprints are beneficial for reliable SQL generation in small models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bots Don&#x27;t Sit Still: A Longitudinal Study of Bot Behaviour Change, Temporal Drift, and Feature-Structure Evolution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [social media analysis], [Augmented Dickey-Fuller test, KPSS test, Spearman correlation, Chi-square test, time series analysis, stationarity testing]</li>
<li class=""><strong>authors:</strong> Ohoud Alzahrani, Russell Beale, Bob Hendley</li>
<li class=""><strong>institution:</strong> University of Birmingham</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17067" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17067</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a longitudinal study analyzing the temporal behavior of promotional Twitter bots using time series analysis and statistical tests on ten content-based meta-features. It finds that bot behavior is non-stationary, with individual features and their interdependencies evolving systematically over time and across bot generations. The conclusion is that bot-detection systems must account for this dynamic adaptation and avoid treating behavioral features as static.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent system, transactional analysis, ego states, information retrieval, vector stores, ablation test]</li>
<li class=""><strong>authors:</strong> Monika Zamojska, Jarosław A. Chudziak</li>
<li class=""><strong>institution:</strong> Warsaw University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17060" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17060</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ea02a6d58821ccc3cc89deee5daf014a7e650e133502a2a64e5cd69e54c8596_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent system architecture that integrates Transactional Analysis theory, dividing each agent into Parent, Adult, and Child ego states, and enhances their responses with contextual information retrieval from vector stores. The system is evaluated through ablation tests in a simulated dialogue scenario. The results show that this psychologically grounded structure improves the realism of LLM-based agent behavior.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [mathematical reasoning], [chain-of-thought prompting, reinforcement learning, GRPO, fine-tuning, error recovery]</li>
<li class=""><strong>authors:</strong> Saraswathy Amjith, Mihika Dusad, Neha Muramalla, Shweta Shah</li>
<li class=""><strong>institution:</strong> MIT</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17079" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17079</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper fine-tunes the Qwen3-4B model using GRPO reinforcement learning on intentionally flawed chain-of-thought reasoning traces to improve error detection and recovery. It finds that this mixed training on both calculation and reasoning errors improves robustness to misleading prefills without sacrificing accuracy on clean problems, unlike standard fine-tuning which degrades robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [dialogue topic segmentation], [window-tolerant F1, boundary density, segment coherence, granularity-aware evaluation]</li>
<li class=""><strong>authors:</strong> Michael H. Coen</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17083" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17083</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a new evaluation framework for dialogue topic segmentation that emphasizes boundary density and segment coherence alongside window-tolerant F1. It demonstrates through cross-dataset experiments that reported performance differences are often artifacts of annotation granularity mismatches, not model quality. The core conclusion is that topic segmentation should be viewed as selecting an appropriate granularity rather than predicting a single correct boundary set.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Value Under Ignorance in Universal Artificial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [AIXI, Choquet integrals, imprecise probability theory, semimeasure loss, utility functions]</li>
<li class=""><strong>authors:</strong> Cole Wyeth, Marcus Hutter</li>
<li class=""><strong>institution:</strong> University of Waterloo, Google DeepMind, Australian National University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17086</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper generalizes the AIXI reinforcement learning agent to handle a wider class of utility functions, confronting the ambiguity of finite history predictions by interpreting belief distributions as imprecise probabilities. It explores computing expected utilities using Choquet integrals from imprecise probability theory and investigates their computability. The authors show that the standard recursive value function is a special case, but the most general utilities under a &quot;death interpretation&quot; cannot be characterized by these integrals.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] How to Square Tensor Networks and Circuits Without Squaring Them</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [probabilistic modeling], [tensor networks, squared circuits, probabilistic circuits, marginalization, canonical forms, unitary matrices, distribution estimation]</li>
<li class=""><strong>authors:</strong> Lorenzo Loconte, Adrián Javaloy, Antonio Vergari</li>
<li class=""><strong>institution:</strong> University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17090" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17090</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method to parameterize squared circuits (a generalization of squared tensor networks) using conditions inspired by orthogonality and determinism, enabling efficient marginalization without squaring. This approach overcomes computational overhead while maintaining expressiveness for distribution estimation. Experiments confirm the method allows more efficient learning without loss of expressiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, model predictive control, MPPI, hierarchical planning, adaptive sampling]</li>
<li class=""><strong>authors:</strong> Toshiaki Hori, Jonathan DeCastro, Deepak Gopinath, Avinash Balachandran, Guy Rosman</li>
<li class=""><strong>institution:</strong> Toyota Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17091</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that fuses reinforcement learning and model-predictive control (MPC) into an adaptive hierarchical framework. It uses RL actions to guide the MPPI sampler and adaptively aggregates MPPI samples to improve value estimation, leading to more robust and sample-efficient policies. The approach demonstrates improved data efficiency, performance, and convergence speed in domains like race driving and Lunar Lander.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretability], [counterfactual explanations, model-agnostic, time series, ECG, LIME, SHAP]</li>
<li class=""><strong>authors:</strong> Justin Li, Efe Sencan, Jasper Zheng Duan, Vitus J. Leung, Stephan Tsaur, Ayse K. Coskun</li>
<li class=""><strong>institution:</strong> Boston University, Sandia National Laboratories, Boston Medical Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17100</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces UniCoMTE, a universal, model-agnostic framework for generating counterfactual explanations for time series classifiers by modifying input samples to identify influential temporal features. It is evaluated on an ECG classifier and shown to produce more concise, stable, and human-aligned explanations than established methods like LIME and SHAP, thereby improving model interpretability for real-world applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [solver-in-the-loop, instruction-tuning, supervised fine-tuning, best-of-N sampling, answer set programming, semantic parsing]</li>
<li class=""><strong>authors:</strong> Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich</li>
<li class=""><strong>institution:</strong> Bosch Center for AI, University of Augsburg, ScaDS.AI &amp; TU Dresden</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17093" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17093</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a solver-in-the-loop framework that uses an ASP solver to provide feedback on LLM-generated code, creating a dataset of chosen and rejected instances for supervised fine-tuning. The method improves LLM performance on generating Answer Set Programming code for logic puzzles, demonstrating consistent gains across different prompting settings and datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Reinforcement Learning for Self-Improving Agent with Skill Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [reinforcement learning, skill library, sequential rollout, skill-integrated reward, GRPO, self-improving agent]</li>
<li class=""><strong>authors:</strong> Jiongxiao Wang, Qiaojing Yan, Yawei Wang, Yijun Tian, Soumya Smruti Mishra, Zhichao Xu, Megha Gandhi, Panpan Xu, Lin Lee Cheong</li>
<li class=""><strong>institution:</strong> University of Wisconsin–Madison, AWS Agentic AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17102" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17102</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09fdb48e8df3d2e43c1e8301082bd3478f7894eef19c7194ccd54fb1c77738ef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SAGE, a reinforcement learning framework that enhances LLM-based agents by integrating a skill library through sequential rollouts and a skill-integrated reward. This approach enables agents to accumulate and reuse skills across tasks for continual self-improvement. Experiments show SAGE improves task completion accuracy while significantly reducing interaction steps and token usage compared to existing methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Generalized Primal Averaging (GPA), DiLoCo, Schedule-Free, AdamW, Nesterov&#x27;s method, primal averaging, optimizer, iterate averaging]</li>
<li class=""><strong>authors:</strong> Aaron Defazio, Konstantin Mishchenko, Parameswaran Raman, Hao-Jun Michael Shi, Lin Xiao</li>
<li class=""><strong>institution:</strong> Meta Superintelligence Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17131</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Generalized Primal Averaging (GPA), a new optimizer that extends Nesterov&#x27;s method to perform smooth, per-step averaging of model iterates, addressing limitations of periodic averaging methods like single-worker DiLoCo. It demonstrates that GPA outperforms single-worker DiLoCo, simplifies hyperparameter tuning, reduces memory overhead, and achieves significant speedups in training LLMs and vision models compared to AdamW.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [deep unrolled model, Restormer, learned coil sensitivity map estimator, sampling-aware weighted data consistency, universal conditioning, progressive cascade expansion training]</li>
<li class=""><strong>authors:</strong> Puyang Wang, Pengfei Guo, Keyi Chai, Jinyuan Zhou, Daguang Xu, Shanshan Jiang</li>
<li class=""><strong>institution:</strong> Johns Hopkins University, NVIDIA</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17137" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17137</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13a0f6637b571493e14f364092f2d39a108d211bbddd588a88df25d1db4a8e1c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SDUM, a scalable deep unrolled model for universal MRI reconstruction that integrates a Restormer-based reconstructor, learned coil sensitivity estimation, and sampling-aware data consistency. It demonstrates predictable performance scaling with model depth and achieves state-of-the-art results across diverse clinical MRI protocols without task-specific fine-tuning. The work establishes a practical framework for a single, universally applicable reconstruction model in clinical environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [algorithmic information theory], [Solomonoff induction, Bayesian Model Averaging, hypothesis ranking, systematic generalisation, uncertainty estimation]</li>
<li class=""><strong>authors:</strong> Josh Barber, Rourke Young, Cameron Coombe, Will Browne</li>
<li class=""><strong>institution:</strong> Queensland University of Technology, CSIRO</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17145</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fb373087fc2ec93e8e3a1729cbb4c2df71ab2a3e5c7a3936acdba21fa6ee2c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that uses a Solomonoff-inspired scoring to weight hypotheses generated by a Large Language Model based on their simplicity and predictive fit. The method, applied to Mini-ARC tasks, produces uncertainty-aware predictions by spreading probability across multiple hypotheses, contrasting with Bayesian Model Averaging which tends to concentrate weight on a single candidate. The results highlight the value of algorithmic information-theoretic priors for robust, interpretable reasoning under uncertainty.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [interactive reinforcement learning, multi-teacher learning, Q-learning, teacher selection, concept drift]</li>
<li class=""><strong>authors:</strong> Maher Mesto, Francisco Cruz</li>
<li class=""><strong>institution:</strong> University of New South Wales, Universidad Central de Chile</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17180</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a multi-teacher interactive reinforcement learning framework where agents can select advice from teachers with different reward structures. The core finding is that agents exhibit a strong conservative bias, overwhelmingly preferring low-reward but consistent teachers over high-reward ones, which challenges traditional reward-maximization assumptions in RL.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language model, explainable ai, augmented reality, personalized explanations, real-time object detection, user study]</li>
<li class=""><strong>authors:</strong> Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque</li>
<li class=""><strong>institution:</strong> University of Missouri-Columbia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17172" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17172</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes PILAR, a framework that uses a pre-trained large language model (LLM) to generate unified, context-aware, and personalized explanations for AI-driven augmented reality systems. A user study on a recipe recommendation prototype showed that the LLM-based explanation interface significantly improved user task performance and perceived transparency compared to a traditional template-based approach.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [reinforcement learning, fine-tuning, retrieval-augmented generation, multi-modal large language models, explainable AI]</li>
<li class=""><strong>authors:</strong> Shengwei Zhao, Jingwen Yao, Sitong Wei, Linhai Xu, Yuying Liu, Dong Zhang, Zhiqiang Tian, Shaoyi Du</li>
<li class=""><strong>institution:</strong> Xi’an Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17194" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17194</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e101261754ebc1d899bc11f5f5d9245217cf53bcbfc614d62f737f8cbd530473_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MMRAG-RFT, a two-stage reinforcement fine-tuning framework for explainable multi-modal retrieval-augmented generation. The method uses rule-based and reasoning-based reinforcement learning to filter documents and jointly optimize ranking and answer generation, achieving state-of-the-art results on benchmark datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [unified multimodal model, benchmark, omni-dimensional evaluation, understanding, generation, editing]</li>
<li class=""><strong>authors:</strong> Kai Liu, Leyang Chen, Wenbo Li, Zhikai Chen, Zhixin Wang, Renjing Pei, Linghe Kong, Yulun Zhang</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University, The Chinese University of Hong Kong, Huawei Technologies Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17196" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17196</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dffc23613309b3df00996da4dd30419c4aa81ea36355df55ab509eed8b7380c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dffc23613309b3df00996da4dd30419c4aa81ea36355df55ab509eed8b7380c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces UmniBench, a benchmark designed to holistically evaluate Unified Multimodal Models (UMMs) by assessing their understanding, generation, and editing abilities within a single process, using the model&#x27;s own understanding capability to judge its outputs. It covers 13 domains and over 200 concepts to provide comprehensive and fine-grained assessments. The authors benchmark 24 models and conclude that UmniBench offers a more integrated and objective evaluation framework compared to isolated, task-specific benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fose: Fusion of One-Step Diffusion and End-to-End Network for Pansharpening</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [one-step distillation, lightweight ensemble blocks, four-stage training, pansharpening, diffusion model, end-to-end network]</li>
<li class=""><strong>authors:</strong> Kai Liu, Zeli Lin, Weibo Wang, Linghe Kong, Yulun Zhang</li>
<li class=""><strong>institution:</strong> Shanghai Jiao Tong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17202</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Fose, a lightweight network for pansharpening that fuses a one-step diffusion model and an end-to-end network using a novel four-stage training strategy. It uses one-step distillation to compress a diffusion model&#x27;s inference from 50 steps to 1 and integrates it with an E2E model via lightweight ensemble blocks. The method achieves better performance than state-of-the-art approaches and a 7.42x speedup compared to the baseline diffusion model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [robotics and navigation], [extended kalman filter, inertial measurement unit, wheel odometer, dead reckoning]</li>
<li class=""><strong>authors:</strong> Yan Gao, Jiliang Wang, Minghan Wang, Xiaohua Chen, Demin Chen, Zhiyong Ren, Tian-Yun Huang</li>
<li class=""><strong>institution:</strong> Peking University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52e181750dd60029c711d4a23702ec5e96a39d86b1ce8c7f9c34de75f853c369_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52e181750dd60029c711d4a23702ec5e96a39d86b1ce8c7f9c34de75f853c369_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a dead reckoning method for a self-propelled pipeline robot, using an IMU for initial attitude estimation, refining it with an Extended Kalman Filter, and combining it with wheel odometer data for localization. The method was tested in a rectangular loop pipeline, and the results verified the effectiveness of the proposed algorithm for navigating complex three-dimensional pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] The Role of Islamic Ethics in Preventing the Abuse of Artificial Intelligence (AI) Based Deepfakes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [ethics and society], [Systematic Literature Review (SLR), PRISMA, Maqasid al-Shariah, hifz al-ird, hifz al-nafs, adl, tabayyun]</li>
<li class=""><strong>authors:</strong> Wisnu Uriawan, Imany Fauzy Rahman, Muhamad Zidan, Irma Rohmatillah, Muhammad Arkan Raihan, Irma Dwiyanti</li>
<li class=""><strong>institution:</strong> UIN Sunan Gunung Djati Bandung</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17218" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17218</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study employs a Systematic Literature Review (SLISMA) to formulate an Islamic ethical framework for preventing deepfake abuse. It concludes that principles from Maqasid al-Shariah, such as protecting honor and self, provide a normative basis for shifting from punitive to preventative approaches, focusing on human dignity and the common good in the digital age.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [error level noise embedding, n-best hypotheses, noise-aware modeling, whisper, llama-2, word error rate, fine-tuning]</li>
<li class=""><strong>authors:</strong> Zahra Rahmani, Hossein Sameti</li>
<li class=""><strong>institution:</strong> Sharif University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17247</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a robust noise-sensitive ASR error correction framework for Persian. It introduces Error Level Noise (ELN) embeddings, derived from disagreements in multiple ASR hypotheses, to condition a fine-tuned LLaMA-2 model, enabling it to reason about noise-induced uncertainty. The ELN-conditioned model significantly reduces Word Error Rate compared to text-only baselines, demonstrating the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust speech recognition in noisy environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Privacy-Preserving Synthetic Dataset of Individual Daily Trajectories for City-Scale Mobility Analytics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [privacy-preserving data synthesis], [multi-objective optimization, origin-destination matrices, dwell-travel time quantiles, universal law of daily visited locations, synthetic trajectory generation]</li>
<li class=""><strong>authors:</strong> Jun&#x27;ichi Ozaki, Ryosuke Susuta, Takuhiro Moriyama, Yohei Shida</li>
<li class=""><strong>institution:</strong> Not explicitly provided; cannot infer from given information.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17239" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17239</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method to generate a privacy-preserving synthetic dataset of individual daily trajectories by integrating aggregated origin-destination flows with behavioral constraints in a multi-objective optimization framework. The method successfully reproduces realistic human mobility patterns in two Japanese regions, providing a practical pathway for high-resolution mobility analytics without using sensitive personal data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [differential privacy, local differential privacy, RAPPOR, PAC indistinguishability, hybrid privacy, rarity-aware protection]</li>
<li class=""><strong>authors:</strong> Madhava Gaikwad</li>
<li class=""><strong>institution:</strong> Microsoft</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17251</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes AlignDP, a hybrid privacy mechanism that protects large language models by separating data into rare and non-rare fields. Rare fields are shielded with PAC indistinguishability for strong privacy, while non-rare fields are privatized using RAPPOR to allow useful frequency estimation. This approach aims to prevent knowledge extraction and unauthorized fine-tuning by design, making models more secure against distillation and editing attacks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [speculative execution, TD-MPC2, latent-space MPC, mismatch correction, action queue, transformer corrector]</li>
<li class=""><strong>authors:</strong> Ziyang Lin, Zixuan Sun, Sanhorn Chen, Xiaoyang Chen, Roy Zhao</li>
<li class=""><strong>institution:</strong> University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17250" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17250</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/801e0aab9fd9dcfb7d20ebc658880a9fa5c22a62c30b2127c1037ab48024b399_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/801e0aab9fd9dcfb7d20ebc658880a9fa5c22a62c30b2127c1037ab48024b399_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a speculation-and-correction framework to reduce inference latency in real-time control agents. It uses a world model to predict future actions and latent states, then applies a lightweight learned corrector to adjust these actions when new observations arrive, reducing planning calls by 43.6% with minimal performance loss. The results show that correction is essential for reliable latency reduction in sequential control tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [audit agents, attestation protocols, constrained reasoning, cryptographic attestation, symbolic methods, benchmark suite, verifiability]</li>
<li class=""><strong>authors:</strong> Abhivansh Gupta</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology, Roorkee</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17259" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17259</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Verifiability-First architecture for LLM-based agents, integrating runtime attestations, lightweight audit agents for continuous verification, and challenge-response protocols for high-risk operations. It introduces the OPERA benchmark to evaluate the detectability and speed of remediation for misaligned behavior, shifting the focus from measuring the propensity for misalignment to ensuring reliable detection and control.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [GPT-style transformer, autoregressive next-event prediction, player embeddings, counterfactual simulation, residual On-Ball Value (rOBV)]</li>
<li class=""><strong>authors:</strong> Miru Hong, Minho Lee, Geonhee Jo, Jae-Hee So, Pascal Bauer, Sang-Ki Ko</li>
<li class=""><strong>institution:</strong> University of Seoul, Saarland University, Bank of Korea</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17266" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17266</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ScoutGPT, a GPT-based autoregressive transformer model that treats football match events as discrete token sequences to predict the next action and its value, conditioned on player identity. It enables counterfactual simulations by swapping player embeddings to assess how a player&#x27;s performance might change in a new tactical context. Evaluated on Premier League data, the model outperforms baselines in prediction accuracy and provides a principled framework for evaluating player transfer fit.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [evaluation framework], [LLM-as-a-Judge, regression, MetricBank, retrieval, human feedback correlation]</li>
<li class=""><strong>authors:</strong> Michael J. Ryan, Yanzhe Zhang, Amol Salunkhe, Yi Chu, Di Xu, Diyi Yang</li>
<li class=""><strong>institution:</strong> Stanford University, American Express</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17267" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17267</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AutoMetrics, a framework that synthesizes evaluation metrics by combining retrieved metrics from a curated bank with automatically generated LLM-as-a-Judge criteria, composed via regression to maximize correlation with human feedback. It demonstrates that AutoMetrics significantly improves correlation with human judgments over standard LLM-as-a-Judge approaches while requiring minimal human feedback data. The method can serve as an effective proxy reward for optimizing AI applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Understanding Generalization in Role-Playing Models via Information Theory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [natural language processing], [information theory, mutual information, reinforcement learning, distribution shift, role-playing models]</li>
<li class=""><strong>authors:</strong> Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li</li>
<li class=""><strong>institution:</strong> Wuhan University, Tongyi Lab, Zhongguancun Academy</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17270" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17270</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] WDFFU-Mamba: A Wavelet-guided Dual-attention Feature Fusion Mamba for Breast Tumor Segmentation in Ultrasound Images</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical image segmentation], [wavelet-guided enhancement, dual-attention feature fusion, U-shaped Mamba architecture, Wavelet-denoised High-Frequency-guided Feature (WHF), Dual Attention Feature Fusion (DAFF)]</li>
<li class=""><strong>authors:</strong> Guoping Cai, Houjin Chen, Yanfeng Li, Jia Sun, Ziwei Chen, Qingzi Geng</li>
<li class=""><strong>institution:</strong> Beijing Jiaotong University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17278" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17278</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes WDFFU-Mamba, a novel network for breast ultrasound image segmentation that integrates wavelet-guided enhancement and dual-attention feature fusion within a U-shaped Mamba architecture. It demonstrates superior segmentation accuracy and robustness on public datasets, making it a promising tool for clinical applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Subjective Question Generation and Answer Evaluation using NLP</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [large language models, instruct-tuning, bloom&#x27;s taxonomy, subjective evaluation, question generation, answer evaluation]</li>
<li class=""><strong>authors:</strong> G. M. Refatul Islam, Safwan Shaheer, Yaseen Nur, Mohammad Rafid Hamid</li>
<li class=""><strong>institution:</strong> Brac University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17289" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17289</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This research proposes a framework that uses instruct-tuned large language models (LLMs) to generate subjective questions and evaluate student answers, particularly for higher-order thinking skills. The study concludes that this approach can effectively automate the assessment of complex, subjective understanding, a task traditionally requiring human evaluators.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memristive architecture, minion recurrent unit, weighted-bit streaming, experience replay, mixed-signal accelerator, on-chip continual learning]</li>
<li class=""><strong>authors:</strong> Abdullah M. Zyarah, Dhireesha Kudithipudi</li>
<li class=""><strong>institution:</strong> University of Texas at San Antonio, University of Baghdad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17299</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces M2RU, a mixed-signal hardware architecture that implements the Minion Recurrent Unit for efficient on-chip continual learning at the edge. It uses weighted-bit streaming and experience replay to enable energy-efficient temporal processing and stable adaptation. The results show significant energy efficiency improvements and a long operational lifetime, establishing M2RU as a scalable platform for edge-level temporal intelligence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Robust TTS Training via Self-Purifying Flow Matching for the WildSpoof 2026 TTS Track</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [Self-Purifying Flow Matching (SPFM), flow matching, text-to-speech (TTS), Supertonic, fine-tuning, in-the-wild speech, label noise mitigation]</li>
<li class=""><strong>authors:</strong> June Young Yi, Hyeongju Kim, Juheon Lee</li>
<li class=""><strong>institution:</strong> Supertone Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17293" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17293</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a lightweight TTS system that fine-tunes the Supertonic model using Self-Purifying Flow Matching (SPFM) to robustly adapt to noisy, in-the-wild speech data. SPFM handles label noise by comparing conditional and unconditional flow matching losses, routing suspicious samples for unconditional training while still using their acoustic information. The resulting model achieved the best word error rate in the WildSpoof 2026 challenge, demonstrating that open-weight architectures can be effectively adapted to real-world conditions with explicit noise-handling mechanisms.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [large language models, turn-based battle system, strategic decision-making, content generation, procedural generation, adaptive difficulty]</li>
<li class=""><strong>authors:</strong> Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> Birla Institute of Technology and Science, Pilani</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17308" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17308</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a turn-based Pokémon battle system where LLMs act as agents, making tactical decisions based on a structured battle state without domain-specific training. The core method involves evaluating LLMs on strategic reasoning and their ability to generate novel game content. The main conclusion is that LLMs can function as dynamic game opponents and designers, offering a practical alternative to reinforcement learning for strategic games.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [explainable AI (XAI)], [graph theory, model decomposition, hypothesis-evidence structure, Cox proportional hazards model, PREDICT]</li>
<li class=""><strong>authors:</strong> Michael Merry, Pat Riddle, Jim Warren</li>
<li class=""><strong>institution:</strong> University of Auckland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17316" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17316</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a formal, testable criterion for inherent explainability in AI, using graph theory to decompose models into verifiable structure-local explanations called annotations. The method is applied to demonstrate the inherent explainability of a clinical cardiovascular risk model (PREDICT). The work provides a rigorous foundation for regulators and formalizes the distinction between an explainable model and an explained one.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Benchmark for Ultra-High-Resolution Remote Sensing MLLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [remote sensing, multimodal evaluation], [RSHR-Bench, adversarial filtering, high-resolution imagery, multimodal large language models, visual question answering, image captioning]</li>
<li class=""><strong>authors:</strong> Yunkai Dang, Meiyi Zhu, Donghao Wang, Yizhuo Zhang, Jiacheng Yang, Qi Fan, Yuekun Yang, Wenbin Li, Feng Miao, Yang Gao</li>
<li class=""><strong>institution:</strong> Nanjing University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17319" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17319</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/283e413d1a1fd46323ee20a12df05789e8ef6dd69af3578d2d3e3e27ce803395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/283e413d1a1fd46323ee20a12df05789e8ef6dd69af3578d2d3e3e27ce803395_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces RSHR-Bench, a super-high-resolution benchmark for evaluating multimodal large language models (MLLMs) in remote sensing. The benchmark uses adversarial filtering with strong LLMs and human verification to create tasks that reduce reliance on language priors and require genuine visual understanding. The evaluation reveals that existing models, including RS-specific ones, show significant performance gaps when handling ultra-high-resolution remote sensing imagery.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adaptive graph pruning, Spatio-Temporal Graph Neural Networks (ST-GNNs), Sudden Event Prediction Accuracy (SEPA), online semi-decentralized training, Federated Learning (FL), Gossip Learning]</li>
<li class=""><strong>authors:</strong> Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas</li>
<li class=""><strong>institution:</strong> University of Zagreb, Faculty of Electrical Engineering and Computing; RISE Research Institutes of Sweden; KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an adaptive graph pruning algorithm for Spatio-Temporal Graph Neural Networks (ST-GNNs) to reduce communication overhead in online semi-decentralized traffic prediction systems. It also introduces a novel evaluation metric, SEPA, to measure responsiveness to sudden traffic events. The method maintains prediction accuracy while significantly lowering communication costs across different decentralized learning settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Dialectics for Artificial Intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [algorithmic information theory], [algorithmic information theory, Kolmogorov complexity, reversible consistency relation, excess information, dialectics optimization]</li>
<li class=""><strong>authors:</strong> Zhengmian Hu</li>
<li class=""><strong>institution:</strong> Adobe Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17373" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17373</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an algorithmic-information framework to define concepts as structural relations within an agent&#x27;s total experience, using reversible consistency and excess information to enable dynamic concept revision. It formulates dialectics as an optimization process where concepts compete to explain new information, leading to expansion, splitting, or merging. The approach also formalizes low-cost concept transmission between agents through shared seeds, making concept alignment a concrete compute-bits trade-off.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [imitation learning, dataset aggregation, direct preference optimization, closed-loop evaluation, expert takeover data]</li>
<li class=""><strong>authors:</strong> Deqing Liu, Yinfeng Gao, Deheng Qian, Qichao Zhang, Xiaoqing Ye, Junyu Han, Yupeng Zheng, Xueyi Liu, Zhongpu Xia, Dawei Ding, Yifeng Pan, Dongbin Zhao</li>
<li class=""><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Science and Technology Beijing; Chongqing Chang&#x27;an Technology Co., Ltd.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17370" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17370</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b74ccffb4336d971aedcab583ac81f676e7f75bb85a137f4255da4a692fafe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b74ccffb4336d971aedcab583ac81f676e7f75bb85a137f4255da4a692fafe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes TakeAD, a framework that fine-tunes a pre-trained imitation learning policy for autonomous driving using expert takeover data. The method combines iterative Dataset Aggregation (DAgger) for imitation with Direct Preference Optimization (DPO) for preference alignment to improve closed-loop performance. Experiments show it effectively mitigates the open-loop gap and outperforms pure imitation learning methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Optimisation of Aircraft Maintenance Schedules</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [evolutionary algorithms], [evolutionary algorithm, genetic operators, fitness function, maintenance scheduling, optimisation]</li>
<li class=""><strong>authors:</strong> Neil Urquhart, Amir Rahimi, Efstathios-Al. Tingas</li>
<li class=""><strong>institution:</strong> Edinburgh Napier University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17412</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper applies an Evolutionary Algorithm to solve the aircraft maintenance scheduling problem, which involves assigning qualified staff to tasks within a turnaround window. The algorithm is benchmarked on 60 generated problem instances to evaluate its performance. The study demonstrates the proposed representation and genetic operators for this optimisation task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [FastText, NSFWJS, sentiment analysis, data restoration, classification]</li>
<li class=""><strong>authors:</strong> Xingyu Feng</li>
<li class=""><strong>institution:</strong> Hainan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17411</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abd921f37f90b9dfaf497e986d1ae89307cf4b11dd527bf09bd11e36d239652c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abd921f37f90b9dfaf497e986d1ae89307cf4b11dd527bf09bd11e36d239652c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a method for detecting sensitive and illegal content on the Ethereum blockchain using machine learning. It employs a data restoration algorithm and uses FastText for sentiment analysis and NSFWJS for image detection. The study concludes that harmful content, including personal data and explicit images, coexists with benign data on the blockchain, highlighting privacy and security concerns.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [visual question answering, vision-language models, fine-tuning, benchmark dataset, CT, MRI]</li>
<li class=""><strong>authors:</strong> Léo Butsanets, Charles Corbière, Julien Khlaut, Pierre Manceron, Corentin Dancette</li>
<li class=""><strong>institution:</strong> Raidium, Université de Paris Cité, Hôpital Européen Georges Pompidou, AP-HP, INSERM</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17396" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17396</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces RadImageNet-VQA, a large-scale CT and MRI dataset with expert-curated annotations for radiologic visual question answering, designed to evaluate vision-language models on tasks like abnormality detection and pathology identification. Experiments show that current models struggle with fine-grained pathology identification, especially in open-ended settings, and the dataset avoids linguistic shortcuts as models perform near-random without image inputs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Systematic Reproducibility Study of BSARec for Sequential Recommendation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential recommendation], [BSARec, Transformer, Fourier transform, discrete wavelet transform, padding strategies, frequency rescaling]</li>
<li class=""><strong>authors:</strong> Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy, Yuanna Liu</li>
<li class=""><strong>institution:</strong> University of Amsterdam</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17442" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17442</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper reproduces and evaluates BSARec, a sequential recommendation method that enhances Transformer encoders with a frequency layer using Fourier transforms to capture high-frequency signals. The study finds that BSARec outperforms other methods on some datasets, but digital signal processing techniques like discrete wavelet transform offer only marginal improvements over Fourier transforms, and non-constant padding significantly boosts performance while constant padding hinders high-frequency signal capture.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [SWE-Bench++, automated benchmark generation, pull request harvesting, environment synthesis, test oracle extraction, hint-guided trajectory synthesis, fine-tuning]</li>
<li class=""><strong>authors:</strong> Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe</li>
<li class=""><strong>institution:</strong> Turing</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17419" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17419</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reinforcement learning, independent proximal policy optimization, agent-based modeling, electricity markets, capacity markets, contracts for difference]</li>
<li class=""><strong>authors:</strong> Javier Gonzalez-Ruiz, Carlos Rodriguez-Pardo, Iacopo Savelli, Alice Di Bella, Massimo Tavoni</li>
<li class=""><strong>institution:</strong> Politecnico di Milano, CMCC Foundation - Euro-Mediterranean Center on Climate Change, RFF-CMCC European Institute on Economics and the Environment, Bocconi University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17444</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent reinforcement learning framework, using independent proximal policy optimization, to model investment decisions by generation companies in long-term electricity markets. The model is applied to a stylized Italian electricity system to test various market designs and policy scenarios. The results demonstrate that market design is critical for achieving decarbonization targets while mitigating price volatility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning What to Write: Write-Gated KV for Efficient Long-Context Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache management, Write-Gated KV, KV Admission, KV cache eviction, KV cache selection, FlashAttention, paged-KV systems]</li>
<li class=""><strong>authors:</strong> Yen-Chieh Huang, Rui Fang, Ming-Syan Chen, Pi-Cheng Hsiu</li>
<li class=""><strong>institution:</strong> National Taiwan University, Academia Sinica</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17452</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Write-Gated KV, a learnable KV Admission mechanism that predicts token utility before it enters the KV cache to reduce memory usage and speed up inference. By filtering low-utility tokens early and maintaining a compact global cache, the method significantly reduces memory usage and improves prefill and decode speeds for long-context LLMs with minimal accuracy loss. The results demonstrate that proactive KV cache management is a practical solution for efficient long-context inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [time series forecasting], [spatial-temporal graph neural network, trend-seasonal decomposition, low-rank Top-K adjacency learning, horizon-wise gating, linear baseline]</li>
<li class=""><strong>authors:</strong> Henok Tenaw Moges, Deshendran Moodley</li>
<li class=""><strong>institution:</strong> University of Cape Town</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17453" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17453</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Lite-STGNN, a lightweight model combining decomposition-based linear temporal modeling with a learnable sparse graph module for spatial corrections. It achieves state-of-the-art accuracy on long-term multivariate forecasting benchmarks while being parameter-efficient and faster than transformer-based methods. The learned adjacency matrices also provide interpretable insights into domain-specific variable interactions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [marketing personalisation], [randomised controlled trial, agentic messaging, rule-based campaign, causal inference, contextual bandits]</li>
<li class=""><strong>authors:</strong> Olivier Jeunen, Schaun Wheeler</li>
<li class=""><strong>institution:</strong> aampe</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17462</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates an agentic messaging approach for customer communication, comparing it against a traditional rule-based system in a financial service application via a randomized controlled trial. The results show that the agentic system reduced unsubscribe events by 21% and encouraged earlier tax filing, demonstrating its effectiveness in improving user engagement and retention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [democratic systems], [fair voting methods, cumulative voting, equal shares, proportional representation, participatory budgeting, AI voting assistance]</li>
<li class=""><strong>authors:</strong> Evangelos Pournaras</li>
<li class=""><strong>institution:</strong> University of Leeds</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17461" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17461</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes that combining expressive ballot formats like cumulative voting with proportional aggregation methods like equal shares constitutes a &quot;fair voting method.&quot; It concludes that such methods enhance democratic legitimacy, accelerate impactful outcomes in areas like welfare and education, and serve as a safeguard against biases in emerging AI-assisted voting scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Translating the Rashomon Effect to Sequential Decision-Making Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential decision-making], [Rashomon effect, formal verification, policy ensembles, behavioral cloning, permissive policies]</li>
<li class=""><strong>authors:</strong> Dennis Gross, Jørn Eirik Betten, Helge Spieker</li>
<li class=""><strong>institution:</strong> University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17470" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17470</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper translates the Rashomon effect from classification to sequential decision-making by defining it for policies that behave identically but have different internal structures. It uses formal verification methods to compare the complete probabilistic behavior of policies in stochastic environments. The study concludes that the effect exists in this domain and that ensembles from the Rashomon set are more robust to distribution shifts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [4D scene geometry, diffusion-based video generation, occlusion consistency, illumination-aware dataset, mask generation]</li>
<li class=""><strong>authors:</strong> Hoiyeong Jin, Hyojin Jang, Jeongho Kim, Junha Hyung, Kinam Kim, Dongjin Kim, Huijin Choi, Hyeonji Kim, Jaegul Choo</li>
<li class=""><strong>institution:</strong> KAIST AI, SK Telecom</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17504</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1824f6e52cce42d09258c21a8f994f87c3330105a845886e13a668bacd45e38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1824f6e52cce42d09258c21a8f994f87c3330105a845886e13a668bacd45e38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents InsertAnywhere, a framework for realistic video object insertion that combines 4D scene geometry reconstruction with a diffusion-based video generation model to ensure geometric and temporal consistency. It introduces a synthetic dataset, ROSE++, for supervised training. The method outperforms existing models in producing visually coherent insertions suitable for production environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [LoRA, PEFT, orthonormal transform, hidden-state scrambling, access control, instruction tuning, 4-bit quantization]</li>
<li class=""><strong>authors:</strong> Muhammad Haris Khan</li>
<li class=""><strong>institution:</strong> University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17519" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17519</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes K-OTG, a method for secret-key access control in language models. It uses a training-time dual-path corpus and inference-time orthonormal transforms to scramble hidden states, making the model unusable without the correct key while preserving authorized performance. The method is compatible with LoRA and 4-bit quantization, showing effective locking with minimal utility loss for authorized users.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [protein hazard screening], [homology clustering, cluster-level holdout, logistic regression, random forest, linear SVM, calibrated probabilities, AUROC, AUPRC, Brier score, Expected Calibration Error]</li>
<li class=""><strong>authors:</strong> Muhammad Haris Khan</li>
<li class=""><strong>institution:</strong> University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17527</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SafeBench-Seq, a benchmark and baseline classifier for screening hazardous protein sequences using only interpretable physicochemical and compositional features. The method employs homology clustering at ≤40% identity with cluster-level holdouts to evaluate performance on novel threats. The main conclusion is that random data splits overestimate robustness compared to this stricter homology-controlled evaluation, and that calibrated linear models provide good probability calibration for this CPU-only screening task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [degradation-aware reasoning, structured reasoning chains, supervised fine-tuning, reward-driven alignment, dynamic reasoning depth scaling]</li>
<li class=""><strong>authors:</strong> Jiaqi Tang, Jianmin Chen, Wei Wei, Xiaogang Xu, Runtao Liu, Xiangyu Wu, Qipeng Xie, Jiafei Wu, Lei Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> Hong Kong University of Science and Technology, Northwestern Polytechnical University, Chinese University of Hong Kong, Nanjing University of Science and Technology, University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17532" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17532</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b624fc0656a14fc68753d26cc52e1c0a78d9633130c6881762bd87e498ed0875_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b624fc0656a14fc68753d26cc52e1c0a78d9633130c6881762bd87e498ed0875_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Robust-R1, a framework that enhances the robustness of Multimodal Large Language Models by explicitly modeling visual degradations through structured reasoning chains. The method integrates supervised fine-tuning, reward-driven alignment, and dynamic reasoning depth scaling, and is supported by a new dataset of realistic degradations. The approach achieves state-of-the-art performance on real-world degradation benchmarks, demonstrating superior anti-degradation capabilities.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Towards Explainable Conversational AI for Early Diagnosis with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [GPT-4o, Retrieval-Augmented Generation, Chain-of-Thought prompting, similarity matching, adaptive questioning]</li>
<li class=""><strong>authors:</strong> Maliha Tabassum, M Shamim Kaiser</li>
<li class=""><strong>institution:</strong> Bangladesh University of Professionals, Jahangirnagar University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17559" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17559</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a diagnostic chatbot powered by a Large Language Model (GPT-4o) that uses Retrieval-Augmented Generation, Chain-of-Thought prompting, and adaptive questioning to interactively extract symptoms and provide diagnoses. The system achieved 90% accuracy and 100% Top-3 accuracy, outperforming traditional machine learning models. The findings suggest that LLM-based systems can offer a more transparent, interactive, and clinically effective approach to early medical diagnosis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [MetricGAN-plus-voicebank, semantic WER, noise robustness, speech enhancement]</li>
<li class=""><strong>authors:</strong> Sujal Chondhekar, Vasanth Murukuri, Rushabh Vasani, Sanika Goyal, Rajshree Badami, Anushree Rana, Sanjana SN, Karthik Pandia, Sulabh Katiyar, Neha Jagadeesh, Sankalp Gulati</li>
<li class=""><strong>institution:</strong> EkaCare (Orbi Health Private Limited)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17562</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates the effect of MetricGAN-plus-voicebank speech enhancement on four modern ASR systems using medical speech under nine noise conditions. The study finds that denoising preprocessing consistently degrades ASR performance across all models and conditions, suggesting modern ASR models are inherently noise-robust and enhancement may remove critical acoustic features.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ClothHMR: 3D Mesh Recovery of Humans in Diverse Clothing from Single Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [clothing tailoring, body semantic estimation, body edge prediction, foundational human visual model (FHVM), 3D mesh recovery]</li>
<li class=""><strong>authors:</strong> Yunqi Gao, Leyuan Liu, Yuhan Li, Changxin Gao, Yuanyuan Liu, Jingying Chen</li>
<li class=""><strong>institution:</strong> Central China Normal University, Huazhong University of Science and Technology, China University of Geosciences (Wuhan)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17545" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17545</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3dde00da40b964ce086e0496d0c0c6f668bf5149ef5a44e30539fa3c614601b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3dde00da40b964ce086e0496d0c0c6f668bf5149ef5a44e30539fa3c614601b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ClothHMR, a method for 3D human mesh recovery from a single image that handles diverse clothing via a clothing tailoring module to fit garments to the body silhouette and a mesh recovery module that aligns 3D representations with a foundational human vision model. It demonstrates superior performance over existing methods on benchmark datasets and in-the-wild images, with a practical web application for fashion and shopping.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [vertical scheduling, optimizer step overlapping, SSD-offloaded training, gradient accumulation]</li>
<li class=""><strong>authors:</strong> Yikang Yue, Yishu Yin, Xuehai Qian</li>
<li class=""><strong>institution:</strong> Tsinghua University, University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17570</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces GreedySnake, a system that accelerates SSD-offloaded LLM training by using vertical scheduling to process all micro-batches per layer before moving to the next, and by overlapping the optimizer step with the next forward pass. This approach significantly reduces I/O bottlenecks and improves throughput compared to prior systems like ZeRO-Infinity, achieving up to 2.53x speedup for large models like GPT-175B.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A unified FLAIR hyperintensity segmentation model for various CNS tumor types and acquisition time points</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Attention U-Net, FLAIR hyperintensity segmentation, Dice score, Raidionics]</li>
<li class=""><strong>authors:</strong> Mathilde Gajda Faanes, David Bouget, Asgeir S. Jakola, Timothy R. Smith, Vasileios K. Kavouridis, Francesco Latini, Margret Jensdottir, Peter Milos, Henrietta Nittby Redebrandt, Rickard L. Sjöberg, Rupavathana Mahesparan, Lars Kjelsberg Pedersen, Ole Solheim, Ingerid Reinertsen</li>
<li class=""><strong>institution:</strong> SINTEF Digital, University of Gothenburg, Harvard Medical School, Uppsala University Hospital, Karolinska University Hospital, Linköping University Hospital, Skåne University Hospital, Umeå University, Haukeland University Hospital, University Hospital of North Norway, Norwegian University of Science and Technology, St. Olavs University Hospital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17566" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17566</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a unified deep learning model for segmenting FLAIR hyperintensities in brain tumors using an Attention U-Net architecture trained on approximately 5000 MRI scans. The model generalizes well across various tumor types and pre- and post-operative time points, achieving performance comparable to dataset-specific models. It is integrated into the open-source Raidionics software to facilitate clinical deployment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Gaussian Discriminant Analysis, Z-score distance analysis, cluster-driven deep learning, two-stage framework]</li>
<li class=""><strong>authors:</strong> Tosin Ige, Christopher Kiekintveld, Aritran Piplai, Asif Rahman, Olukunle Kolade, Sasidhar Kunapuli</li>
<li class=""><strong>institution:</strong> The University of Texas at El Paso, University of North Carolina</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17594" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17594</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes MAD-OOD, a two-stage cluster-driven deep learning framework for out-of-distribution malware detection. It uses Gaussian Discriminant Analysis to model class embeddings and Z-score distance analysis to identify anomalies, then integrates these predictions with a neural network for final classification. The method significantly outperforms state-of-the-art approaches on benchmark datasets, achieving high AUC for detecting unseen malware families.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] More Consistent Accuracy PINN via Alternating Easy-Hard Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific machine learning], [physics-informed neural networks, easy-hard prioritization, hybrid training strategy, alternating scheme]</li>
<li class=""><strong>authors:</strong> Zhaoqian Gao, Min Yanga</li>
<li class=""><strong>institution:</strong> Yantai University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17607</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid training strategy for Physics-Informed Neural Networks (PINNs) that alternates between easy and hard prioritization to improve performance. The method achieves consistently high accuracy on challenging PDEs, significantly outperforming baseline approaches. The work demonstrates that this alternating scheme enhances the robustness and reliability of PINNs across diverse problem types.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical image registration], [mammography registration, anatomical landmarks, ANTs, VoxelMorph, TransMorph, IDIR, MammoRegNet, benchmark dataset]</li>
<li class=""><strong>authors:</strong> Svetlana Krasnova, Emiliya Starikova, Ilia Naletov, Andrey Krylov, Dmitry Sorokin</li>
<li class=""><strong>institution:</strong> Lomonosov Moscow State University, Third Opinion Platform</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1e72bae8c4d2dd504664f6eedc1a325466b12559df8aa6fc5fbe929fb95fcbf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1e72bae8c4d2dd504664f6eedc1a325466b12559df8aa6fc5fbe929fb95fcbf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MGRegBench, a public benchmark dataset with over 5,000 mammography image pairs and manual annotations for evaluating registration methods. It benchmarks classical, learning-based, and implicit neural representation approaches, finding that deep learning methods like MammoRegNet show strong performance. The dataset and code are released to enable fair comparisons and advance research in mammography registration.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SCOPE: Sequential Causal Optimization of Process Interventions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [prescriptive process monitoring], [backward induction, causal learning, reinforcement learning, sequential decision-making]</li>
<li class=""><strong>authors:</strong> Jakob De Moor, Hans Weytjens, Johannes De Smedt, Jochen De Weerdt</li>
<li class=""><strong>institution:</strong> KU Leuven, Technical University of Munich (TUM)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17629" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17629</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SCOPE, a prescriptive process monitoring approach that uses backward induction and causal learning to recommend aligned sequences of interventions for optimizing key performance indicators. It directly leverages observational data without needing process approximations for reinforcement learning. Experiments show SCOPE outperforms existing techniques in optimizing KPIs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Trust-Region Adaptive Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [post-training], [Trust-Region Adaptive Policy Optimization, Trust-Region SFT, forward KL divergence, reverse KL, adaptive prefix-selection, supervised fine-tuning, reinforcement learning]</li>
<li class=""><strong>authors:</strong> Mingyu Su, Jian Guan, Yuxian Gu, Minlie Huang, Hongning Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Ant Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17636" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17636</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces TRAPO, a hybrid framework that interleaves supervised fine-tuning and reinforcement learning within each training instance to unify expert supervision and self-exploration. It stabilizes training with Trust-Region SFT and an adaptive prefix-selection mechanism. Experiments on mathematical reasoning benchmarks show TRAPO outperforms standard pipelines and state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] About Time: Model-free Reinforcement Learning with Timed Reward Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [timed reward machines, tabular Q-learning, timed automata, counterfactual-imagining]</li>
<li class=""><strong>authors:</strong> Anirban Majumdar, Ritam Raha, Rajarshi Roy, David Parker, Marta Kwiatkowska</li>
<li class=""><strong>institution:</strong> Tata Institute of Fundamental Research, Max Planck Institute for Software Systems, University of Oxford</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17637" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17637</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes timed reward machines (TRMs), an extension of reward machines that incorporates timing constraints into the reward specification for reinforcement learning. The authors develop model-free RL algorithms, specifically using tabular Q-learning integrated with abstractions of timed automata and counterfactual-imagining heuristics, to learn optimal policies. The experimental results show that their approach successfully learns policies that achieve high rewards while satisfying the specified timing constraints.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [zero-shot learning, cross-modal retrieval, dual-encoder architecture, contrastive learning, structure-aware augmentation, semantic-traffic alignment]</li>
<li class=""><strong>authors:</strong> Yifei Cheng, Yujia Zhu, Baiyang Li, Xinhao Deng, Yitong Cai, Yaochen Ren, Qingyun Liu</li>
<li class=""><strong>institution:</strong> Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17667" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17667</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces STAR, a method that reformulates website fingerprinting as a zero-shot cross-modal retrieval problem, using a dual-encoder architecture to learn a joint embedding space for encrypted traffic traces and website logic profiles. It achieves high accuracy on unseen websites by aligning semantic and traffic features, demonstrating that semantic leakage is a major privacy risk in encrypted HTTPS traffic.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] You Only Train Once: Differentiable Subset Selection for Omics Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [bioinformatics], [differentiable subset selection, multi-task learning, end-to-end training, sparsity, single-cell RNA-seq]</li>
<li class=""><strong>authors:</strong> Daphné Chopard, Jorge da Silva Gonçalves, Irene Cannistraci, Thomas M. Sutter, Julia E. Vogt</li>
<li class=""><strong>institution:</strong> ETH Zurich, University Children’s Hospital Zurich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17678</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces YOTO, an end-to-end framework that jointly selects discrete gene subsets and performs prediction in a single differentiable model, using sparsity and multi-task learning. It demonstrates improved predictive performance and yields compact, meaningful gene subsets on single-cell RNA-seq datasets, advancing biomarker discovery.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [spatio-temporal feature representation, channel attention, self-attention, recurrent neural networks, video-based gaze estimation]</li>
<li class=""><strong>authors:</strong> Alexandre Personnic, Mihai Bâce</li>
<li class=""><strong>institution:</strong> KU Leuven</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17673</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Spatio-Temporal Gaze Network (ST-Gaze), which combines a CNN backbone with channel and self-attention modules to fuse eye and face features, then models intra- and inter-frame dynamics by treating features as a spatial sequence propagated through time. The method achieves state-of-the-art performance on the EVE dataset, demonstrating that preserving intra-frame spatial context is superior to premature spatial pooling for robust video-based gaze estimation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] An Empirical Study of Sampling Hyperparameters in Diffusion-Based Super-Resolution</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [Diffusion Posterior Sampling (DPS), Manifold Constrained Gradient (MCG), conditioning step size, diffusion step count, ablation study]</li>
<li class=""><strong>authors:</strong> Yudhistira Arief Wibowo</li>
<li class=""><strong>institution:</strong> Technical University of Munich, Korea Advanced Institute of Science and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17675" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17675</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts an empirical ablation study on diffusion-based super-resolution, focusing on conditioning methods like DPS and MCG. It finds that the conditioning step size is a more critical hyperparameter than the diffusion step count for reconstruction quality. The optimal conditioning step size for best performance in their experiments falls within the range of [2.0, 3.0].</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Digital and Web Forensics Model Cards, V1</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [knowledge representation], [model cards, controlled vocabularies, web-based generator, digital forensics, web forensics]</li>
<li class=""><strong>authors:</strong> Paola Di Maio</li>
<li class=""><strong>institution:</strong> Ronin Institute, W3C AI Knowledge Representation Community Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17722</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a web-based framework for generating standardized model cards to represent knowledge in digital and web forensics, featuring controlled vocabularies for classification, reasoning, bias, and error. The main conclusion is the presentation of this beta framework and tool to establish an emerging standard, inviting community feedback for refinement.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [recommendation systems], [causal deconfounding, LightGCN, Unbiased Asymmetric Co-purchase Relationship (UACR), counterfactual exposure, BPR loss]</li>
<li class=""><strong>authors:</strong> Jingmao Zhang, Zhiting Zhao, Yunqi Lin, Jianghong Ma, Tianjun Wei, Haijun Zhang, Xiaofeng Zhang</li>
<li class=""><strong>institution:</strong> Harbin Institute of Technology (Shenzhen), Nanyang Technological University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17733</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0101cc9ad451bf594fefde69475b9ae7433ae4f0ec8954e841150d68840d01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes Cadence, a plug-and-play framework built on LightGCN that uses causal deconfounding to compute unbiased item-item relationships and counterfactual exposure simulation to enhance recommendation diversity. The method constructs a deconfounded directed item graph and identifies diverse, causally relevant items a user has not interacted with. Experiments show it outperforms state-of-the-art models in both diversity and accuracy.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [AncientBench, benchmark evaluation, ancient character comprehension, excavated documents, glyph comprehension, pronunciation comprehension, meaning comprehension, contextual comprehension]</li>
<li class=""><strong>authors:</strong> Zhihan Zhou, Daqian Shi, Rui Song, Lida Shi, Xiaolei Diao, Hao Xu</li>
<li class=""><strong>institution:</strong> Jilin University, Queen Mary University of London, University of Trento</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17756" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17756</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AncientBench, a comprehensive benchmark designed to evaluate large language models&#x27; comprehension of ancient Chinese, particularly focusing on excavated documents. It assesses four competencies (glyph, pronunciation, meaning, and contextual) through ten tasks. The experimental results show that while LLMs have significant potential in ancient text scenarios, a performance gap remains compared to human experts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Easy Adaptation, Parameter-Efficient Fine-Tuning, LoRA, Specific Small Models, task adaptation, resource-constrained]</li>
<li class=""><strong>authors:</strong> Dong Chen, Zhengqing Hu, Shixing Zhao, Yibo Guo</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17771" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17771</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Easy Adaptation (EA), a method that uses Specific Small Models (SSMs) to complement the data distribution for Large Models, enabling task adaptation without accessing the LM&#x27;s internal parameters. This approach matches the performance of Parameter-Efficient Fine-Tuning (PEFT) like LoRA on diverse tasks while requiring only minimal computational resources, making it suitable for resource-constrained environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [BERT, DistilBERT, ELECTRA, RoBERTa, Multi-BERT Ensemble, transformer models, medical entity recognition]</li>
<li class=""><strong>authors:</strong> Tanjim Taharat Aurpa, Farzana Akter, Md. Mehedi Hasan, Shakil Ahmed, Shifat Ara Rafiq, Fatema Khan</li>
<li class=""><strong>institution:</strong> University of Frontier Technology, University of Liberal Arts Bangladesh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17769</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Multi-BERT Ensemble approach for Bangla Medical Entity Recognition (MedER), evaluating models like BERT, DistilBERT, ELECTRA, and RoBERTa. The ensemble method achieved 89.58% accuracy, an 11.80% improvement over single-layer BERT, and the authors also created a new annotated dataset for this low-resource language task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [vision transformer, neural parametric head models, 3d morphable models, single-image 3d reconstruction, signed distance functions]</li>
<li class=""><strong>authors:</strong> Simon Giebenhain, Tobias Kirschstein, Liam Schoneveld, Davide Davoli, Zhe Chen, Matthias Nießner</li>
<li class=""><strong>institution:</strong> Technical University of Munich, Woven by Toyota, Toyota Motor Europe</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17773" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17773</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c26792d83b697ded69eb83a7cee4b4440d0b9637b6c3fbd2061ab2aef67d7bcd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c26792d83b697ded69eb83a7cee4b4440d0b9637b6c3fbd2061ab2aef67d7bcd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Pix2NPHM, a method that uses a vision transformer to directly regress the parameters of a Neural Parametric Head Model from a single input image. It achieves high-fidelity 3D face reconstruction by training on a mixture of 3D data and 2D videos, and allows for further refinement through inference-time optimization. The authors conclude that their approach yields unprecedented reconstruction quality that generalizes well to in-the-wild data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Knowledge Mining, Digital Preservation, Semantic Web, Data Integration, Dual-Stream Architecture]</li>
<li class=""><strong>authors:</strong> Binh Vu</li>
<li class=""><strong>institution:</strong> FernUniversität in Hagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17795" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17795</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes the Intelligent Knowledge Mining Framework (IKMF), a conceptual dual-stream architecture that combines a horizontal AI-driven mining process with a parallel trustworthy archiving stream. It aims to bridge the gap between dynamic analysis and long-term preservation, transforming static data repositories into living, actionable knowledge ecosystems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] LLM-based Behaviour Driven Development for Hardware Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Behavior Driven Development (BDD), Large Language Models (LLMs), hardware design, test and verification, natural language processing, Electronic Design Automation (EDA)]</li>
<li class=""><strong>authors:</strong> Rolf Drechsler, Qian Liu</li>
<li class=""><strong>institution:</strong> University of Bremen, DFKI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17814" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17814</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the use of Large Language Models (LLMs) to automate the generation of behavioral scenarios from textual specifications for Behavior Driven Development (BDD) in hardware design. The core method involves applying LLM-based techniques to interpret specifications and produce high-level behavioral descriptions. The main conclusion is that LLMs offer a promising opportunity to support and automate BDD workflows in hardware design, addressing the manual effort and complexity of current verification practices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] ShareChat: A Dataset of Chatbot Conversations in the Wild</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [dataset collection, multi-turn conversations, platform affordances, source citations, temporal analysis, cross-platform corpus]</li>
<li class=""><strong>authors:</strong> Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le</li>
<li class=""><strong>institution:</strong> Indiana University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17843" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17843</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset&#x27;s utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [energy-based models, gradient-based refinement, hindsight goal relabeling, latent-space planning]</li>
<li class=""><strong>authors:</strong> Carlos Vélez García, Miguel Cazorla, Jorge Pomares</li>
<li class=""><strong>institution:</strong> INESCOP, University of Alicante</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17846" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17846</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Planning as Descent (PaD), a method for offline goal-conditioned reinforcement learning that learns an energy function over latent trajectories and performs planning via gradient-based refinement in this energy landscape. It achieves state-of-the-art 95% success on cube manipulation tasks, demonstrating that verification-driven trajectory synthesis outperforms direct policy learning, especially when trained on noisy data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Animate Any Character in Any World</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [3DGS, conditional autoregressive video generation, pre-trained video generator, natural language control]</li>
<li class=""><strong>authors:</strong> Yitong Wang, Fangyun Wei, Hongyang Zhang, Bo Dai, Yan Lu</li>
<li class=""><strong>institution:</strong> Fudan University, Microsoft Research, University of Waterloo, The University of Hong Kong</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17796" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17796</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fb0b1e8242f96e5f0b2988237b2d0603a8f364d90cc833a33b2313d43b1ae4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8fb0b1e8242f96e5f0b2988237b2d0603a8f364d90cc833a33b2313d43b1ae4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces AniX, a system that animates user-provided 3D characters in 3D Gaussian Splatting (3DGS) scenes based on natural language commands. It formulates the task as a conditional autoregressive video generation problem, building upon a pre-trained video generator and a training strategy to enhance motion dynamics. The method enables open-ended character actions while preserving visual fidelity and temporal coherence in the generated video clips.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computational social science], [computational text analysis, machine learning (ML), natural language processing (NLP), ethnography, in-depth interviews, mixed-methods]</li>
<li class=""><strong>authors:</strong> Corey M. Abramson</li>
<li class=""><strong>institution:</strong> Rice University, UC San Francisco</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17850" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17850</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper demonstrates how computational social science tools like machine learning and natural language processing can be integrated with traditional qualitative methods (e.g., ethnography, interviews) to study aging. It concludes that these computational methods can broaden qualitative research by streamlining workflows, scaling up projects, and enabling new multi-method insights, rather than replacing its foundational approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [cross-attention maps, inference-time optimization, compound loss, denoising step, spatial alignment]</li>
<li class=""><strong>authors:</strong> Sarah Rastegar, Violeta Chatalbasheva, Sieger Falkena, Anuj Singh, Yanbo Wang, Tejas Gokhale, Hamid Palangi, Hadi Jamali-Rad</li>
<li class=""><strong>institution:</strong> Delft University of Technology, University of Maryland, Baltimore County, Shell Information Technology International, Google</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17851" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17851</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1a251648d46bb8da396759e99d563b9a2d57eb19fc5ed8f7ece18ccb7bfeeee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1a251648d46bb8da396759e99d563b9a2d57eb19fc5ed8f7ece18ccb7bfeeee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> InfSplign is a training-free, inference-time method that improves spatial alignment in text-to-image diffusion models by adjusting the noise at each denoising step using a compound loss based on cross-attention maps. It achieves state-of-the-art performance on spatial reasoning benchmarks, outperforming existing inference-time and fine-tuning baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Convolutional Neural Network (CNN), Attention Mechanism, CBAM, VGG16, Grad-CAM, Layer-wise Relevance Propagation (LRP)]</li>
<li class=""><strong>authors:</strong> Balram Singh, Ram Prakash Sharma, Somnath Dey</li>
<li class=""><strong>institution:</strong> National Institute of Technology Hamirpur, Indian Institute of Technology Indore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17864" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17864</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an interpretable plant leaf disease detection method using a CBAM-enhanced VGG16 CNN model. The model integrates attention modules to improve feature extraction and localization, achieving high accuracy on multiple datasets. The study demonstrates the effectiveness of the approach through performance evaluation and interpretability analysis using attention maps and other explainable AI techniques.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [ViPR, ViPR-Eureka, ViPR-RL, behavior cloning, VLM-in-the-loop Parallel Refinement, LLM-guided contact sampling, sim-to-real transfer, GPU simulation]</li>
<li class=""><strong>authors:</strong> Ran Gong, Xiaohan Zhang, Jinghuan Shang, Maria Vittoria Minniti, Jigarkumar Patel, Valerio Pepe, Riedana Yan, Ahmet Gundogdu, Ivan Kapelyukh, Ali Abbas, Xiaoqiang Yan, Harsh Patel, Laura Herlant, Karl Schmeckpeper</li>
<li class=""><strong>institution:</strong> Robotics and AI Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17853" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17853</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3552d146c759bb8b81dd4441230819f44e04ae7530ed1ec49cc21133ed3f116_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents AnyTask, an automated framework that uses massively parallel GPU simulation and foundation models to generate diverse robot manipulation tasks and expert demonstration data. It introduces three agents (ViPR, ViPR-Eureka, ViPR-RL) for synthesizing demonstrations, which are used to train behavior cloning policies. These policies achieve a 44% average success rate when deployed directly on real robot hardware for various manipulation tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [generative modeling], [Wasserstein-Fisher-Rao gradient flow, weighted stochastic differential equations, Feynman-Kac representation, score-based diffusion models, Langevin dynamics]</li>
<li class=""><strong>authors:</strong> Herlock Rahimi</li>
<li class=""><strong>institution:</strong> Yale University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a new sampling method for generative modeling by implementing Wasserstein-Fisher-Rao gradient flow via weighted stochastic differential equations, using the Feynman-Kac representation. This approach aims to overcome the slow mixing rates of traditional diffusion models in non-log-concave, multimodal target distributions by incorporating controlled mass reweighting. The study provides a rigorous geometric and operator-theoretic foundation for future developments in this area.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [human-computer interaction], [anthropomorphism, cross-national experiments, humanlike AI design, behavioral measures, cultural mediation]</li>
<li class=""><strong>authors:</strong> Robin Schimmelpfennig, Mark Díaz, Vinodkumar Prabhakaran, Aida Davani</li>
<li class=""><strong>institution:</strong> Max Planck Institute for Human Development, Google Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17898</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper conducts two large-scale cross-national experiments with 3,500 participants across 10 countries, involving real-time interactions with an AI system. It finds that humanlike design increases anthropomorphism but does not universally boost engagement and trust; instead, these outcomes are culturally mediated, with the same design choices having opposite effects in different populations like Brazil and Japan.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] RadarGen: Automotive Radar Point Cloud Generation from Cameras</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [diffusion model, bird&#x27;s-eye-view, radar cross section, Doppler, point cloud generation, foundation models]</li>
<li class=""><strong>authors:</strong> Tomer Borreda, Fangqiang Ding, Sanja Fidler, Shengyu Huang, Or Litany</li>
<li class=""><strong>institution:</strong> Technion, MIT, NVIDIA, University of Toronto, Vector Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17897" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17897</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RadarGen is a diffusion model that generates realistic automotive radar point clouds from multi-view camera images by representing radar data in bird&#x27;s-eye-view and conditioning on visual cues. It uses a lightweight recovery step to reconstruct point clouds from the generated maps. Evaluations show it captures real radar statistics and reduces the performance gap for perception models trained on synthetic data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adversarial Robustness of Vision in Open Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [Projected Gradient Descent, adversarial robustness, Visual Question Answering, vision-language models]</li>
<li class=""><strong>authors:</strong> Jonathon Fox, William J Buchanan, Pavlos Papadopoulos</li>
<li class=""><strong>institution:</strong> Edinburgh Napier University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17902" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17902</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates the adversarial robustness of vision-language models LLaVA-1.5-13B and Llama 3.2 Vision-8B-2 by applying untargeted Projected Gradient Descent attacks to their visual inputs and testing on a VQA v2 subset. The main conclusion is that the vision modality is a viable attack vector, and adversarial robustness does not directly correlate with standard benchmark performance, with Llama 3.2 Vision showing a smaller accuracy drop under attack despite a lower baseline.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When Reasoning Meets Its Laws</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [large reasoning models], [laws of reasoning, compute law, accuracy law, monotonicity, compositionality, LoRe-Bench, finetuning]</li>
<li class=""><strong>authors:</strong> Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, Massachusetts Institute of Technology, University of Pennsylvania, New York University, NTT Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17901" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17901</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Laws of Reasoning (LoRe), a framework that formalizes desired reasoning behaviors in large reasoning models, including compute and accuracy laws. It proposes LoRe-Bench to evaluate monotonicity and compositionality, and develops a finetuning method to improve compositionality. The study finds that better compliance with these laws leads to enhanced reasoning performance across benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [test-time refinement, self-supervised learning, shape from shading, score distillation sampling, monocular depth estimation, diffusion models]</li>
<li class=""><strong>authors:</strong> Ananta R. Bhattarai, Helge Rhodin</li>
<li class=""><strong>institution:</strong> Bielefeld University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17908" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17908</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Re-Depth Anything, a test-time self-supervision framework that refines monocular depth predictions by re-lighting the geometry and using a 2D diffusion model&#x27;s priors via Score Distillation Sampling. It updates only specific model embeddings and the decoder to prevent collapse, rather than fine-tuning the entire network. The method shows substantial improvements in depth accuracy and realism over the baseline Depth Anything V2 model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Another Fit Bites the Dust: Conformal Prediction as a Calibration Standard for Machine Learning in High-Energy Physics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [uncertainty quantification], [conformal prediction, calibration, machine learning, high-energy physics, collider research, finite-sample guarantees, prediction sets, p-values]</li>
<li class=""><strong>authors:</strong> Jack Y. Araz, Michael Spannowsky</li>
<li class=""><strong>institution:</strong> University College London, City, University of London, Durham University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17048" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17048</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using conformal prediction as a standard calibration layer for machine learning models in high-energy physics, providing rigorous uncertainty quantification and finite-sample coverage guarantees without retraining. It demonstrates the method&#x27;s applicability across regression, classification, anomaly detection, and generative modeling using collider datasets. The authors conclude that adopting conformal calibration enables reliable statistical inference and principled decision-making in experimental analyses.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [graph attention networks, electroencephalography, spatio-temporal graphs, edge analysis, low-cost hardware, RaspberryPi]</li>
<li class=""><strong>authors:</strong> Szymon Mazurek, Stephen Moore, Alessandro Crimi</li>
<li class=""><strong>institution:</strong> AGH University of Krakow, University of Cape Coast</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2507.15118" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2507.15118</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a graph attention network (GAT) framework that models EEG signals as spatio-temporal graphs to detect epilepsy, with a focus on low-cost hardware for deployment in low-resource settings. The method adapts GATs to analyze edge connectivity for biomarker identification and is designed for lightweight training and deployment. The results demonstrate promising classification performance and highlight the potential for scalable, accessible diagnostic support in underserved regions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-layer graph, GNN, temporal GNN, logistic regression, Random Forest, correlation-based, systemic risk]</li>
<li class=""><strong>authors:</strong> Sandeep Neela</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17185" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17185</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility. It demonstrates that graph-derived features from this model provide useful early-warning signals for market crashes, outperforming standard feature-based models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] From Priors to Predictions: Explaining and Visualizing Human Reasoning in a Graph Neural Network Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [cognitive modeling], [Graph Neural Networks, Graph Theory, inductive biases, computational graph, systematic ablation]</li>
<li class=""><strong>authors:</strong> Quan Do, Caroline Ahn, Leah Bakst, Michael Pascale, Joseph T. McGuire, Chantal E. Stern, Michael E. Hasselmo</li>
<li class=""><strong>institution:</strong> Boston University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17255" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17255</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces a framework combining Graph Theory and Graph Neural Networks to formalize inductive biases as explicit priors over structure and abstraction. Using a human behavioral dataset adapted from the Abstraction and Reasoning Corpus, it shows that differences in graph-based priors explain individual differences in human solutions, revealing how generalization depends on specific prior structures and why human-like errors arise from incorrect priors.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] HydroGym: A Reinforcement Learning Platform for Fluid Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [reinforcement learning, flow control, differentiable solvers, transfer learning, benchmark platform]</li>
<li class=""><strong>authors:</strong> Christian Lagemann, Sajeda Mokbel, Miro Gondrum, Mario Rüttgers, Jared Callaham, Ludger Paehler, Samuel Ahnert, Nicholas Zolman, Kai Lagemann, Nikolaus Adams, Matthias Meinke, Wolfgang Schröder, Jean-Christophe Loiseau, Esther Lagemann, Steven L. Brunton</li>
<li class=""><strong>institution:</strong> University of Washington, RWTH Aachen University, Inha University, Technical University of Munich, German Center for Neurodegenerative Diseases, Arts et Métiers Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17534" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17534</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HydroGym, a reinforcement learning platform designed for fluid dynamics control, featuring both non-differentiable and differentiable solvers to improve sample efficiency. The platform includes 42 validated environments and demonstrates that RL agents can discover robust control principles, achieving significant drag reduction and efficient adaptation to new conditions via transfer learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [3D ConvNeXt, Global Response Normalization, depth scaling, width scaling, context scaling, supervised pretraining, volumetric segmentation]</li>
<li class=""><strong>authors:</strong> Saikat Roy, Yannick Kirchhoff, Constantin Ulrich, Maximillian Rokuss, Tassilo Wald, Fabian Isensee, Klaus Maier-Hein</li>
<li class=""><strong>institution:</strong> German Cancer Research Center (DKFZ), Heidelberg University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17774" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17774</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MedNeXt-v2, a compound-scaled 3D ConvNeXt architecture enhanced with a Global Response Normalization module for large-scale supervised representation learning in medical image segmentation. The authors demonstrate that scaling the backbone network&#x27;s architecture is crucial for effective pretraining, and MedNeXt-v2 achieves state-of-the-art performance when fine-tuned on diverse CT and MR benchmarks. The work establishes that a stronger backbone design yields better downstream segmentation results than simply increasing dataset size.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Exploring the Effect of Basis Rotation on NQS Performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [quantum machine learning], [neural quantum states, restricted boltzmann machine, quantum natural gradient, quantum fisher information, fubini-study distance, basis rotation, ising model]</li>
<li class=""><strong>authors:</strong> Sven Benjamin Kožić, Vinko Zlatić, Fabio Franchini, Salvatore Marco Giampaolo</li>
<li class=""><strong>institution:</strong> Institut Ruđer Bošković</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17893" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17893</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses an analytically solvable rotated Ising model to study how local basis rotations affect the optimization of Neural Quantum States (NQS). It finds that rotations relocate the target wavefunction in parameter space, exposing information-geometric barriers like saddle points that trap shallow architectures like RBMs, highlighting the need for landscape-aware model design.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-23">2025-12-23<a href="#2025-12-23" class="hash-link" aria-label="Direct link to 2025-12-23" title="Direct link to 2025-12-23" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251223] Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lihui Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17912" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17912</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Baxi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nihir Chadderwala</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17913" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17913</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48ebf691e752728d3961062fe7df081d6a92c7729c4f9968ddd1c3f083bb93df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Byzantine Fault-Tolerant Multi-Agent System for Healthcare: A Gossip Protocol Approach to Secure Medical Message Propagation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17911</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh Tri LÊ, Ali Ait-Bachir</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17916" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17916</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aomufei Yuan, Zhiming Wang, Ruijie Miao, Dayu Wang, Yuxuan Tian, Zihan Wang, Yebo Peng, Yuhan Wu, Bairen Yi, Xin Liu, Tong Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17917" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17917</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Allison Li, Kristjan Greenewald, Thomas Parnell, Navid Azizan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17910</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Xu, Ayan Banerjee, Midhat Urooj, Sandeep K.S. Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8208ecda566e64a777495316e0aac16897f35ec183a5fb04050258d853af7cf7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haiying Xia, Zhongyi Huang, Yumei Tan, Shuxiang Song</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17946" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17946</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae2757814d2b16837d9b7cb3f26503eda8c49afc87dd1795f588ae949df6650_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ae2757814d2b16837d9b7cb3f26503eda8c49afc87dd1795f588ae949df6650_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Let the Model Learn to Feel: Mode-Guided Tonality Injection for Symbolic Music Emotion Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhao Song, Song Yue, Jiahao Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17950</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21bbafaf75367ac515be62999bf183f2dc9b58cb6de4b044d5e95331ef1cf1ed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21bbafaf75367ac515be62999bf183f2dc9b58cb6de4b044d5e95331ef1cf1ed_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Which Coauthor Should I Nominate in My 99 ICLR Submissions? A Mathematical Analysis of the ICLR 2026 Reciprocal Reviewer Nomination Policy</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Karthik Prabhakar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17943" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17943</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a630b7d9810838c6059574b3dae2d2f3fcc9c79699030e8640202f2dbcd2d4b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Soheil Hashtarkhani, Brianna M. White, Benyamin Hoseini, David L. Schwartz, Arash Shaban-Nejad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Will AI Trade? A Computational Inversion of the No-Trade Theorem</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hanyu Li, Xiaotie Deng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17952" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17952</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ad1a13c7765317192c2b83746186b421990df4011bf9cad5b20f5624cf6ca35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ad1a13c7765317192c2b83746186b421990df4011bf9cad5b20f5624cf6ca35_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Will AI Trade? A Computational Inversion of the No-Trade Theorem</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Victor Stasiuc, Round Table Collaboration</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ellie Zhou, Jihoon Chung, Olga Russakovsky</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17953" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17953</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8fc5229281981de8f8ce6b4446b9b416a3bf03a5b7dfe015f7327ed14da6c6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8fc5229281981de8f8ce6b4446b9b416a3bf03a5b7dfe015f7327ed14da6c6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gunho Park, Jeongin Bae, Byeongwook Kim, Baeseong park, Jiwon Ryu, Hoseung Kim, Se Jung Kwon, Dongsoo Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17970</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthieu Mastio, Paul Saves, Benoit Gaudou, Nicolas Verstaevel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17979" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17979</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43cecfb66c204c7d6add4e7c40f9325f7867c22be2179de9305d482292a7a4dd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Farida Mohsen, Ali Safa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17958</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf18ccdf18f30e0e5c324fc709aa108b4706cb9c6a2b56366e90ad3a8bd1a32c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Real-Time Human-Robot Interaction Intent Detection Using RGB-based Pose and Emotion Cues with Cross-Camera Model Generalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Irina Seregina, Philippe Lalanda, German Vega</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17983" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17983</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Convolutional-neural-operator-based transfer learning for solving PDEs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peng Fan, Guofei Pang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Convolutional-neural-operator-based transfer learning for solving PDEs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Specification and Detection of LLM Code Smells</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Stievenert, Florent Avellaneda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18020" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18020</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Specification and Detection of LLM Code Smells</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sarah Nassar, Nooshin Maghsoodi, Sophia Mannina, Shamel Addas, Stephanie Sibley, Gabor Fichtinger, David Pichora, David Maslove, Purang Abolmaesumi, Parvin Mousavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18031</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Joshua Gibson, Kapil Dhakal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18034</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee8143ffe65f15c2c3477c3c466f8d3d7e3d40519caf5667a1e168e357e8ce6b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conflict-Driven Clause Learning with VSIDS Heuristics for Discrete Facility Layout</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mohammadmahdi Rahimiasl, Ynte Vanderhoydonc, Siegfried Mercelis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17984" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17984</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Securing Agentic AI Systems -- A Multilayer Security Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sunil Arora, John Hastings</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96ca042b8b2e4295fa813434a544ac9adb3df55cbea55e3fe9b24f2dcbee4733_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Securing Agentic AI Systems -- A Multilayer Security Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FOODER: Real-time Facial Authentication and Expression Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sabri Mustafa Kahya, Muhammet Sami Yavuz, Boran Hamdi Sivrikaya, Eckehard Steinbach</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18057</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FOODER: Real-time Facial Authentication and Expression Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18080</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ohoud Alzahrani, Russell Beale, Robert J. Hendley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18077" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18077</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shreshth Rajan, Raymond Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18082</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd5ca9b561b8ad179709036acde1f313672cfa0c00a271b9235f8ab0e640d0a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd5ca9b561b8ad179709036acde1f313672cfa0c00a271b9235f8ab0e640d0a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ge Yan, Tuomas Oikarinen, Tsui-Wei, Weng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18092</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Boxuan Wang, Zhuoyun Li, Xiaowei Huang, Yi Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18094" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18094</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d3b6262ae305fdec9209648a021429405f004c2b9a531305c5c02be4396c55f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Holistic Evaluation of State-of-the-Art LLMs for Code Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Le Zhang, Suresh Kothari</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18131</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Holistic Evaluation of State-of-the-Art LLMs for Code Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18126" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18126</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7254830672e4c2c139708d42673d4462ea8f38cc986ab26672ee4838f74c1458_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jie Yang, Rui Zhang, Ziyang Cheng, Dawei Cheng, Guang Yang, Bo Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18133" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18133</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cristiano da Costa Cunha, Wei Liu, Tim French, Ajmal Mian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afd713c843807b61ef24ae3fe42d41c20e6fbaeaff735c0c77378e6c26ab19a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Swarm Leader Identification using Probing Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stergios E. Bachoumas, Panagiotis Artemiadis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18146" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18146</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/584c84764226eb21b4c2c555cf6432ccfe102a3aa9dcc530809f19d78d76d7ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Swarm Leader Identification using Probing Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Propose, Solve, Verify: Self-Play Through Formal Verification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alex Wilf, Pranjal Aggarwal, Bryan Parno, Daniel Fried, Louis-Philippe Morency, Paul Pu Liang, Sean Welleck</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18160" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18160</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/352216a02c2bd4fb599d9561a7994cb21ba9b1ce3f9f8b8cfea3ec4cc0b8413d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/352216a02c2bd4fb599d9561a7994cb21ba9b1ce3f9f8b8cfea3ec4cc0b8413d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Propose, Solve, Verify: Self-Play Through Formal Verification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Midhat Urooj, Ayan Banerjee, Sandeep Gupta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18177" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18177</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7ef165e056ae631599bd024eb4341c57c1705258598a82662ae1166302f2947_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7ef165e056ae631599bd024eb4341c57c1705258598a82662ae1166302f2947_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NEURO-GUARD: Neuro-Symbolic Generalization and Unbiased Adaptive Routing for Diagnostics -- Explainable Medical AI</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Yan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18190</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Devang Dhanuka, Nidhi Rastogi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18199</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7026a8c8f552664c28724b8716e8e7e5cef6b29425c374a1c5439f2bfb877d5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7026a8c8f552664c28724b8716e8e7e5cef6b29425c374a1c5439f2bfb877d5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PROVEX: Enhancing SOC Analyst Trust with Explainable Provenance-Based IDS</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Deng, Yijia Li, Renrui Zhang, Peijun Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18189" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18189</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee57353b28c6f902f2d47ba6499f6f3db69fe4e0b025fa2fd4ed11eff3c1c003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NL2CA: Auto-formalizing Cognitive Decision-Making from Natural Language Using an Unsupervised CriticNL2LTL Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sophia: A Persistent Agent Framework of Artificial Life</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingyang Sun, Feng Hong, Weinan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18202</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c33289396399b1bb0e301fb010ed82c6a686d9391a9307867ae3c7ae74a8cc3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c33289396399b1bb0e301fb010ed82c6a686d9391a9307867ae3c7ae74a8cc3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sophia: A Persistent Agent Framework of Artificial Life</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhou Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18209</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Stable and Efficient Single-Rollout RL for Multimodal Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Stable and Efficient Single-Rollout RL for Multimodal Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yudong Liu, Spencer Hallyburton, Jiwoo Kim, Yueqian Lin, Yiming Li, Qinsi Wang, Hui Ye, Jingwei Sun, Miroslav Pajic, Yiran Chen, Hai Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18211" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18211</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eea86ac8cc855b1a0e43febafd0f1e08626f900ba3ded294c1d99b0072a7da3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9eea86ac8cc855b1a0e43febafd0f1e08626f900ba3ded294c1d99b0072a7da3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLaViDA: A Large Language Vision Driving Assistant for Explicit Reasoning and Enhanced Trajectory Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zehao Liu, Xi Lin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18244" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18244</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a4ab3d36e0ccc56b5c8f0b5a9f82481bdfdc1f1bc14e54959edf8ba4006a00d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a4ab3d36e0ccc56b5c8f0b5a9f82481bdfdc1f1bc14e54959edf8ba4006a00d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Breaking Minds, Breaking Systems: Jailbreaking Large Language Models via Human-like Psychological Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Offline Behavioral Data Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shiye Lei, Zhihao Cheng, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18246</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Behavioral Data Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Himabindu Thogaru, Saisubramaniam Gopalakrishnan, Zishan Ahmad, Anirudh Deodhar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18265" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18265</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50a73b0ae1606916d8e1e7324c2baa8154f67eb8e76c0e1f1c0d014d54aa2ab2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50a73b0ae1606916d8e1e7324c2baa8154f67eb8e76c0e1f1c0d014d54aa2ab2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Intelligent Human-Machine Partnership for Manufacturing: Enhancing Warehouse Planning through Simulation-Driven Knowledge Graphs and LLM Collaboration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiao He, Chang Tang, Xinwang Liu, Wei Zhang, Zhimin Gao, Chuankun Li, Shaohua Qiu, Jiangfeng Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028cfc83b63f51bf798c2014f1dc8e1f4c786134910334880eb4c0cf340a5eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028cfc83b63f51bf798c2014f1dc8e1f4c786134910334880eb4c0cf340a5eb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spectral Discrepancy and Cross-modal Semantic Consistency Learning for Object Detection in Hyperspectral Image</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Fan, Jiawei Chen, Yu Tian, Zhaoxia Yin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18264" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18264</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6181175b477e5c50e93e9a1a3a4690fb1673471073933b770754e208c7b0e776_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6181175b477e5c50e93e9a1a3a4690fb1673471073933b770754e208c7b0e776_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Who Can See Through You? Adversarial Shielding Against VLM-Based Attribute Inference Attacks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Ancient Plant Seed Classification: A Benchmark Dataset and Baseline Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Xing, Runmin Cong, Yingying Wu, Can Wang, Zhongming Tang, Fen Wang, Hao Wu, Sam Kwong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18247</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d341345aee67211dc7e3cea021a11051fd66231eb649e4da442fda6828319f0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d341345aee67211dc7e3cea021a11051fd66231eb649e4da442fda6828319f0d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Ancient Plant Seed Classification: A Benchmark Dataset and Baseline Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sirui Li, Wangyue Lu, Xiaorui Shi, Ke Weng, Haozhe Sun, Minghe Yu, Tiancheng Zhang, Ge Yu, Hengyu Liu, Lun Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18256" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18256</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fa370d48e50a94f7beaa30df78416e8de75e5bddd8996af2ad55d2751ed49c0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fa370d48e50a94f7beaa30df78416e8de75e5bddd8996af2ad55d2751ed49c0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MSC-180: A Benchmark for Automated Formal Theorem Proving from Mathematical Subject Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18261" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18261</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xuling Zhang, Jindong Li, Yifei Zhang, Menglin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18295" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18295</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Harsh Rathva, Ojas Srivastava, Pruthwik Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18309</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eren Caglar, Amirkia Rafiei Oskooei, Mehmet Kutanoglu, Mustafa Keles, Mehmet S. Aktas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18318" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18318</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff046f84477e998c712a0f584e02cdfbe6c1bef89652e720bfe7cbb5bb7764ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asynchronous Pipeline Parallelism for Real-Time Multilingual Lip Synchronization in Video Communication Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18336</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Monitoring Monitorability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Monitoring Monitorability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MCVI-SANet: A lightweight semi-supervised model for LAI and SPAD estimation of winter wheat under vegetation index saturation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiheng Zhang, Jiajun Yang, Hong Sun, Dong Wang, Honghua Jiang, Yaru Chen, Tangyuan Ning</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18344</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f19d6aa9f347693da897453773133b3a6f0b66ee06e5f6bdf421bb24507e5f56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f19d6aa9f347693da897453773133b3a6f0b66ee06e5f6bdf421bb24507e5f56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MCVI-SANet: A lightweight semi-supervised model for LAI and SPAD estimation of winter wheat under vegetation index saturation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM-based Few-Shot Early Rumor Detection with Imitation Agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fengzhu Zeng, Qian Shao, Ling Cheng, Wei Gao, Shih-Fen Cheng, Jing Ma, Cheng Niu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-based Few-Shot Early Rumor Detection with Imitation Agent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mateusz Lango, Ondřej Dušek</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18360" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18360</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Datasets for machine learning and for assessing the intelligence level of automatic patent search systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Boris Genin, Alexander Gorbunov, Dmitry Zolkin, Igor Nekrasov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18384" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18384</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac80e35326c113d249d5bd28c4aafe01da23a8e0c681cde84257daab6b92b651_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac80e35326c113d249d5bd28c4aafe01da23a8e0c681cde84257daab6b92b651_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Datasets for machine learning and for assessing the intelligence level of automatic patent search systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18388" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18388</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Neural Proofs for Sound Verification and Control of Complex Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alessandro Abate</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18389" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18389</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Neural Proofs for Sound Verification and Control of Complex Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mark Kashirskiy, Artiom Lipinski, Ilya Makarov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18399" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18399</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AmPLe: Supporting Vision-Language Models via Adaptive-Debiased Ensemble Multi-Prompt Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fei Song, Yi Li, Jiangmeng Li, Rui Wang, Changwen Zheng, Fanjiang Xu, Hui Xiong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18411</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c480d382f1a840aaa7b8f0ed1cc380b9ece2b0a04c01a7bfeaf7551356ef5a0c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c480d382f1a840aaa7b8f0ed1cc380b9ece2b0a04c01a7bfeaf7551356ef5a0c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AmPLe: Supporting Vision-Language Models via Adaptive-Debiased Ensemble Multi-Prompt Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mykyta Lapin, Kostiantyn Bokhan, Yurii Parzhyn</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18412" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18412</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccebc716317d25dbc5d826c4045eca3d2894e8904f35d62a55262711b7023239_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccebc716317d25dbc5d826c4045eca3d2894e8904f35d62a55262711b7023239_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Few-Shot Learning of a Graph-Based Neural Network Model Without Backpropagation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ansar Ahmed</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18432" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18432</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8b17e8fd956e845305266fe6ff75f18289ac1b39f8db27ac25d02758609d8f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8b17e8fd956e845305266fe6ff75f18289ac1b39f8db27ac25d02758609d8f9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Federated Learning Based Decentralized Adaptive Intelligent Transmission Protocol for Privacy Preserving 6G Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Distributed Hierarchical Spatio-Temporal Edge-Enhanced Graph Neural Network for City-Scale Dynamic Logistics Routing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihan Han, Lingran Meng, Jingwei Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18441" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18441</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acf1ec57b519400d58fe519f0aa1f4d66aecd68168a2f192e508b971607f7ef7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acf1ec57b519400d58fe519f0aa1f4d66aecd68168a2f192e508b971607f7ef7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Distributed Hierarchical Spatio-Temporal Edge-Enhanced Graph Neural Network for City-Scale Dynamic Logistics Routing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] VeruSAGE: A Study of Agent-Based Verification for Rust Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18436</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VeruSAGE: A Study of Agent-Based Verification for Rust Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Snowveil: A Framework for Decentralised Preference Discovery</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Grammateia Kotsialou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18444</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8761ec2c77d131e1f61b3af656dc162d45194670910e8c8975220f93bfc1af6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Snowveil: A Framework for Decentralised Preference Discovery</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Agentic AI Framework for Training General Practitioner Student Skills</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18440" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18440</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Agentic AI Framework for Training General Practitioner Student Skills</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xavier Rafael-Palou, Jose Munuera, Ana Jimenez-Pastor, Richard Osuala, Karim Lekadir, Oliver Diaz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18450" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18450</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24a54a0b377f2d61cdb058b9dd088fe0948517999354f7c502389a3f1149e8a3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MeniMV: A Multi-view Benchmark for Meniscus Injury Severity Grading</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shurui Xu, Siqi Yang, Jiapin Ren, Zhong Cao, Hongwei Yang, Mengzhen Fan, Yuyu Sun, Shuyan Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18437" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18437</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82297f34fc5f7dfab35d4ab984e7ba607ad5ac2c849bffbec01d38cbdcf42e3d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82297f34fc5f7dfab35d4ab984e7ba607ad5ac2c849bffbec01d38cbdcf42e3d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MeniMV: A Multi-view Benchmark for Meniscus Injury Severity Grading</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Secret mixtures of experts inside your LLM</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Enric Boix-Adsera</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18452</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Secret mixtures of experts inside your LLM</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SoK: Understanding (New) Security Issues Across AI4Code Use Cases</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qilong Wu, Taoran Li, Tianyang Zhou, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18456" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18456</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f652ae22c8ea45edbe21093e80ef932b29b1703110171928654985064e108e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SoK: Understanding (New) Security Issues Across AI4Code Use Cases</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Román Jaimes</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18462</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18470" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18470</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Oraib Almegdadi, João Marcelino, Sarah Fakhreddine, João Manso, Nuno C. Marques</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18466" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18466</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Large Language Models as Discounted Bayesian Filters</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Jing Yang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18489" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18489</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da72fb53dbbaca8aea568d7b6fc9cba313aa6bb5798a40c89e2a22a5a0788e17_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da72fb53dbbaca8aea568d7b6fc9cba313aa6bb5798a40c89e2a22a5a0788e17_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Large Language Models as Discounted Bayesian Filters</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18495</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39d0272a8734a4477ae1f6aa46e60e4c4f62aa860ef3a9559c12f0aad180ecb2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39d0272a8734a4477ae1f6aa46e60e4c4f62aa860ef3a9559c12f0aad180ecb2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Decision-Making in Windows PE Malware Classification During Dataset Shifts with Uncertainty Estimation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Santwana Sagnika, Manav Malhotra, Ishtaj Kaur Deol, Soumyajit Roy, Swarnav Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18500" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18500</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang, Deepa Krishnan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18483" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18483</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c098db4784c358fb7712e2be8c3c8d57e56fd9982bed1aff3f16699a16acd5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1c098db4784c358fb7712e2be8c3c8d57e56fd9982bed1aff3f16699a16acd5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Insider Threat Detection Using GCN and Bi-LSTM with Explicit and Implicit Graph Representations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] GTMA: Dynamic Representation Optimization for OOD Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Ningyuan Liu, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18504</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec81480aabd317eb3778c36f956b818e8aed383ab7f9a13fe2c867243fcec025_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec81480aabd317eb3778c36f956b818e8aed383ab7f9a13fe2c867243fcec025_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GTMA: Dynamic Representation Optimization for OOD Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hatim M. E. Geli, Islam Omar, Mona Y. Elshinawy, David W. DuBios, Lara Prehodko, Kelly H Smith, Abdel-Hameed A. Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18522" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18522</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Miyuki T. Nakata</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18525" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18525</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5fa66d8eb7deac60effe912ce57cc5b3a8decb9a70cf6acda4def17328ab6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c5fa66d8eb7deac60effe912ce57cc5b3a8decb9a70cf6acda4def17328ab6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Formal Descriptive Language for Learning Dynamics: A Five-Layer Structural Coordinate System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Detection of AI Generated Images Using Combined Uncertainty Measures and Particle Swarm Optimised Rejection Mechanism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Nauman Aslam, Eaby Kollonoor Babu, Josh Collyer, Fraser Kennedy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18527</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1520c61491b8f395b60f64432e37eff57c8608eba74cd9029c6109d32db7554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1520c61491b8f395b60f64432e37eff57c8608eba74cd9029c6109d32db7554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Detection of AI Generated Images Using Combined Uncertainty Measures and Particle Swarm Optimised Rejection Mechanism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Scott Thornton</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18542</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Training Superintelligent Software Agents through Self-Play SWE-RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18552</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Training Superintelligent Software Agents through Self-Play SWE-RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing Medical Large Vision-Language Models via Alignment Distillation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aofei Chang, Ting Wang, Fenglong Ma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65cfdaf6c50eb13e1535902993b0e58d2ccb2d1d8a89304254b7eb116f2e3bec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65cfdaf6c50eb13e1535902993b0e58d2ccb2d1d8a89304254b7eb116f2e3bec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Medical Large Vision-Language Models via Alignment Distillation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Chen, Sihan Cheng, Can Gurkan, Ryan Lay, Moez Salahuddin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18564" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18564</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b0a311cb9d10337e5f3590761c621c192dd12a7c496b0cd7891fbccd0f8367_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vox Deorum: A Hybrid LLM Architecture for 4X / Grand Strategy Game AI -- Lessons from Civilization V</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saad Alqithami</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18561" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18561</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0aec0ad59816dd3fa60a1098beec472f1b9dc9c795b4760cf9c9f0516435437_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Accountability in Networked MAS: Tracing and Mitigating Emergent Norms at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18567" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18567</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Effiong Blessing, Chiung-Yi Tseng, Somshubhra Roy, Junaid Rehman, Isaac Nkrumah</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18575" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18575</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumaiya Ali, Areej Alhothali, Ohoud Alzamzami, Sameera Albasri, Ahmed Abduljabbar, Muhammad Alwazzan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Weijie Zhou, Xuangtang Xiong, Ye Tian, Lijun Yue, Xinyu Wu, Wei Li, Chaoyang Zhao, Honghui Dong, Ming Tang, Jinqiao Wang, Zhengyou Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18571" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18571</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e48075d8fabfbd12f97c2605f729d021ebb805999e01bbf511f08a872cf4cbae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e48075d8fabfbd12f97c2605f729d021ebb805999e01bbf511f08a872cf4cbae_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ESearch-R1: Learning Cost-Aware MLLM Agents for Interactive Embodied Search via Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Amit Barman, Atanu Mandal, Sudip Kumar Naskar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18593" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18593</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qinglin Zeng, Jing Yang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f210ca82f5b83e0df7f60aafea30fa1547a0370e3b4cda5c94ba26cc393a6f1d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f210ca82f5b83e0df7f60aafea30fa1547a0370e3b4cda5c94ba26cc393a6f1d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Text2Graph VPR: A Text-to-Graph Expert System for Explainable Place Recognition in Changing Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saeideh Yousefzadeh, Hamidreza Pourreza</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18613" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18613</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15155edf4c23c5fa3645a1383be98a1728e9025130895c36fb1d8c7a536e2335_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15155edf4c23c5fa3645a1383be98a1728e9025130895c36fb1d8c7a536e2335_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Text2Graph VPR: A Text-to-Graph Expert System for Explainable Place Recognition in Changing Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PTTA: A Pure Text-to-Animation Framework for High-Quality Creation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruiqi Chen, Kaitong Cai, Yijia Fan, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18614" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18614</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95e6d5eb29d8f200e9b4d751e2105c378ddc6c8efc5742b330b0ff8118931fb1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95e6d5eb29d8f200e9b4d751e2105c378ddc6c8efc5742b330b0ff8118931fb1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PTTA: A Pure Text-to-Animation Framework for High-Quality Creation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Assignment-Routing Optimization: Solvers for Problems Under Constraints</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Qilong, Michal Pavelka</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be4f502655365659aa5803c3c3e98ff2a6071f2798b4e71f56472c3fe923e05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3be4f502655365659aa5803c3c3e98ff2a6071f2798b4e71f56472c3fe923e05_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Assignment-Routing Optimization: Solvers for Problems Under Constraints</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18616" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18616</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhenhao Zhou, Dan Negrut</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18619" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18619</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c6d919e0fe62510cfe25cf2ce73cce1bed581dc021d27540c0588fbf495702_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c6d919e0fe62510cfe25cf2ce73cce1bed581dc021d27540c0588fbf495702_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ChronoDreamer: Action-Conditioned World Model as an Online Simulator for Robotic Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18623" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18623</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Huiqi Deng, Qihan Ren, Zhuofan Chen, Zhenyuan Cui, Wen Shen, Peng Zhang, Hongbin Pei, Quanshi Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18607</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18622" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18622</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Han-Seul Jeong, Youngjoon Park, Hyungseok Song, Woohyung Lim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18633" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18633</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dmitry Bennett, Fernand Gobet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18665" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18665</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38aa956a72d7d3233a8e9436ec8b3eb96fe6f950dddcefb2c6497e4cc28ea7e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38aa956a72d7d3233a8e9436ec8b3eb96fe6f950dddcefb2c6497e4cc28ea7e6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automatic Adaptation to Concept Complexity and Subjective Natural Concepts: A Cognitive Model based on Chunking</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Geometric-Photometric Event-based 3D Gaussian Ray Tracing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kai Kohyama, Yoshimitsu Aoki, Guillermo Gallego, Shintaro Shiba</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18640" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18640</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85632c631e489e2f789f1b5319b05b69e8e883a12a7b626de475c98e6066ef45_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85632c631e489e2f789f1b5319b05b69e8e883a12a7b626de475c98e6066ef45_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Geometric-Photometric Event-based 3D Gaussian Ray Tracing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jones David, Shreya Ghosh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18669" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18669</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4809145f5d00782974383c70a1a7132c8f9a0785e93701b00d5f208d14cae5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4809145f5d00782974383c70a1a7132c8f9a0785e93701b00d5f208d14cae5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IntelliCode: A Multi-Agent LLM Tutoring System with Centralized Learner Modeling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hafiz Saif Ur Rehman, Ling Liu, Kaleem Ullah Qasim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18661" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18661</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e0e274099dd56b8114b544bec1b5ebd56dd8742f2795d776a62751dceb1bd0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e0e274099dd56b8114b544bec1b5ebd56dd8742f2795d776a62751dceb1bd0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ASTIF: Adaptive Semantic-Temporal Integration for Cryptocurrency Price Forecasting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Liu, Yuhao Hu, Ruiting Zhou, Baochun Li, Ne Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18674" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18674</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b0a6c1ba7d729d7d1a45d1f2d74caedc5189c982e32587fba450b708786cd88_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Remoe: Towards Efficient and Low-Cost MoE Inference in Serverless Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Social Comparison without Explicit Inference of Others&#x27; Reward Values: A Constructive Approach Using a Probabilistic Generative Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yosuke Taniuchi, Chie Hieida, Atsushi Noritake, Kazushi Ikeda, Masaki Isoda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18687</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a80afdf97506cd46b51f3e0232de08278947f67ce0d02728ea31ab57eb6fd39c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a80afdf97506cd46b51f3e0232de08278947f67ce0d02728ea31ab57eb6fd39c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Social Comparison without Explicit Inference of Others&#x27; Reward Values: A Constructive Approach Using a Probabilistic Generative Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cailin Lei, Haiyang Wu, Yuxiong Ji, Xiaoyu Cai, Yuchuan Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18703" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18703</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ec9f06c274a9525b199fad25bdb142bfd63b4a43030adbafd554411a02c2fe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ec9f06c274a9525b199fad25bdb142bfd63b4a43030adbafd554411a02c2fe1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CauTraj: A Causal-Knowledge-Guided Framework for Lane-Changing Trajectory Planning of Autonomous Vehicles</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhifei Li, Lifan Chen, Jiali Yi, Xiaoju Hou, Yue Zhao, Wenxin Huang, Miao Zhang, Kui Xiao, Bing Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18709</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aad95971dcc28db4090fb00dc3a2271fb594ddd1417a6438b8306e2ee01f03a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aad95971dcc28db4090fb00dc3a2271fb594ddd1417a6438b8306e2ee01f03a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KeenKT: Knowledge Mastery-State Disambiguation for Knowledge Tracing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiangrui Cai, Shaocheng Ma, Lei Cao, Jie Li, Tianyu Liu, Yilin Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18689" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18689</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junjun Pan, Yixin Liu, Rui Miao, Kaize Ding, Yu Zheng, Quoc Viet Hung Nguyen, Alan Wee-Chung Liew, Shirui Pan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18733</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7692bd1c5b9a982f1df045d952e852c9a8c6543c4c09cb5bf1bd92156eff8c8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Explainable and Fine-Grained Safeguarding of LLM Multi-Agent Systems via Bi-Level Graph Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zichuan Lin, Xiaokai Huang, Jiate Liu, Yuxuan Han, Jia Chen, Xiapeng Wu, Deheng Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chainarong Amornbunchornvej</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18732</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>3</mn></msup><mo>−</mo><mi>V</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">M^3-Verse</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal">erse</span></span></span></span>: A &quot;Spot the Difference&quot; Challenge for Large Multimodal Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kewei Wei, Bocheng Hu, Jie Cao, Xiaohan Chen, Zhengxi Lu, Wubing Xia, Weili Xu, Jiaao Wu, Junchen He, Mingyu Jia, Ciyun Zhao, Ye Sun, Yizhi Li, Zhonghan Zhao, Jian Zhang, Gaoang Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18735" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18735</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52a20f9bfaa32af67c363579cc4ad37ddbcaa7484f53c2ad3e6f6287dffcb22d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52a20f9bfaa32af67c363579cc4ad37ddbcaa7484f53c2ad3e6f6287dffcb22d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>M</mi><mn>3</mn></msup><mo>−</mo><mi>V</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">M^3-Verse</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mord mathnormal">erse</span></span></span></span>: A &quot;Spot the Difference&quot; Challenge for Large Multimodal Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Code2Doc: A Quality-First Curated Dataset for Code Documentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Recep Kaan Karaman, Meftun Akarsu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18748" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18748</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Code2Doc: A Quality-First Curated Dataset for Code Documentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IPCV: Information-Preserving Compression for MLLM Visual Encoders</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Chen, Zichen Wen, Yuzhou Wu, Xuyang Liu, Shuang Chen, Junpeng Ma, Weijia Li, Conghui He, Linfeng Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18747" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18747</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23f93076434c2a627bcdaf65dfd58999db9105798eceb360e343a3f4018cc020_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23f93076434c2a627bcdaf65dfd58999db9105798eceb360e343a3f4018cc020_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IPCV: Information-Preserving Compression for MLLM Visual Encoders</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jianyi Zhang, Shizhao Liu, Ziyin Zhou, Zhen Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18755" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18755</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/955c9d1fa243ab2977ec256331411b7bf6cca731527350187d399ec006ebe145_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/955c9d1fa243ab2977ec256331411b7bf6cca731527350187d399ec006ebe145_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lisan Al Amin, Vandana P. Janeja</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18797" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18797</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e389f385848f8816c83b5a1ff23be8e5adce564472d3ca92ed4e1c1107846a61_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e389f385848f8816c83b5a1ff23be8e5adce564472d3ca92ed4e1c1107846a61_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reliable Audio Deepfake Detection in Variable Conditions via Quantum-Kernel SVMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Dead Salmons of AI Interpretability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxime Méloux, Giada Dirupo, François Portet, Maxime Peyrard</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18792" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18792</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04addf8c4fc59dd6f1ac7d1afe6ee58894441304221e6091e61ac24a403fb54e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04addf8c4fc59dd6f1ac7d1afe6ee58894441304221e6091e61ac24a403fb54e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Dead Salmons of AI Interpretability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yichuan Zhang, Chengxin Li, Yujie Gu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18791" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18791</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/828d54530ed9add4098a79bb9dd1f4047ed230dfaa399d57cade241c18713658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FedVideoMAE: Efficient Privacy-Preserving Federated Video Moderation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziyuan Tao, Chuanzhi Xu, Sandaru Jayawardana, Wei Bao, Kanchana Thilakarathna, Teng Joon Lim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18809" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18809</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/396672768b4960b9fefe0f861b938a8b78842c8181043ded9d12c7e8f28dbdfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/396672768b4960b9fefe0f861b938a8b78842c8181043ded9d12c7e8f28dbdfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedVideoMAE: Efficient Privacy-Preserving Federated Video Moderation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Souhail Abdelmouaiz Sadat, Mohamed Yacine Touahria Miliani, Khadidja Hab El Hames, Hamida Seba, Mohammed Haddad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18826" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18826</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aditya Siddhant</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18829" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18829</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27fcee3d9ab3da4d05e9467a7467b02eecd9ce9ef97d79e927633356a26bb91b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27fcee3d9ab3da4d05e9467a7467b02eecd9ce9ef97d79e927633356a26bb91b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HARBOR: Holistic Adaptive Risk assessment model for BehaviORal healthcare</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John S. Schreck, William E. Chapman, Charlie Becker, David John Gagne II, Dhamma Kimpara, Nihanth Cherukuru, Judith Berner, Kirsten J. Mayer, Negin Sobhani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18815" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18815</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Gao, Zhikun Xu, Xiao Ye, Ben Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18857</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bruno Campello de Souza</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18871" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18871</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18880" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18880</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kaidi Liang, Ke Li, Xianbiao Hu, Ruwen Qin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18878</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40cc111afbcdc76e8f9c40d867f3e3d92fefb4f06215bb877943f16f5fc7f761_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40cc111afbcdc76e8f9c40d867f3e3d92fefb4f06215bb877943f16f5fc7f761_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CrashChat: A Multimodal Large Language Model for Multitask Traffic Crash Video Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gökdeniz Gülmez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18901" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18901</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Szymon Rusiecki, Cecilia G. Morales, Kimberly Elenberg, Leonard Weiss, Artur Dubrawski</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18908" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18908</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40a7a336fdd61231fb69499563fa54a3feead11655ae2c62d612544da79b259a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40a7a336fdd61231fb69499563fa54a3feead11655ae2c62d612544da79b259a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multimodal Bayesian Network for Robust Assessment of Casualties in Autonomous Triage</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shaokang Jiang, Daye Nam</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18925" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18925</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Michael S. Zhang, Rishi A. Ruia, Arnav Kewalram, Saathvik Dharmapuram, Utkarsh Sharma, Kevin Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Raina Panda, Daniel Fein, Arpita Singhal, Mark Fiore, Maneesh Agrawala, Matyas Bohacek</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18930" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18930</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17d9e52f35a5e302d613cba6423f95b6e9bb58c2b559fbd5a209c0516f8e2326_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17d9e52f35a5e302d613cba6423f95b6e9bb58c2b559fbd5a209c0516f8e2326_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Li Yan, Bolun Liu, Chao Li, Jing Liang, Kunjie Yu, Caitong Yue, Xuzhao Chai, Boyang Qu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18947" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18947</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46e7ee52db647b84d2f31cc7432f1e81dc459afc316c9b1daf014a0d4d28f5d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46e7ee52db647b84d2f31cc7432f1e81dc459afc316c9b1daf014a0d4d28f5d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clustering-based Transfer Learning for Dynamic Multimodal MultiObjective Evolutionary Algorithm</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18950</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhi Wang, Linan Yue, Min-Ling Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Cheng-Hong Chang, Pei-Hsuan Tsai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05062b9ac64115654a255df578e1f3f61c6740d8e9db0b67ceca3387185661df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05062b9ac64115654a255df578e1f3f61c6740d8e9db0b67ceca3387185661df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-Attention with State-Object Weighted Combination for Compositional Zero Shot Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kun Zhao, Siyuan Dai, Yingying Zhang, Guodong Liu, Pengfei Gu, Chenghua Lin, Paul M. Thompson, Alex Leow, Heng Huang, Lifang He, Liang Zhan, Haoteng Tang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18986</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinyan Liu, Zikang Chen, Qinchuan Wang, Tan Xie, Heming Zheng, Xudong Lv</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18999" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18999</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gyeongrok Oh, Youngdong Jang, Jonghyun Choi, Suk-Ju Kang, Guang Lin, Sangpil Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18991" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18991</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca47fc4083c13826225296ae5380ec0a994e6b8b0a936b8582bb3acb510605f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca47fc4083c13826225296ae5380ec0a994e6b8b0a936b8582bb3acb510605f6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ICP-4D: Bridging Iterative Closest Point and LiDAR Panoptic Segmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19011" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19011</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjie Zhao, Xue Yu, Yongzhi Qi, Hao Hu, Jianshen Zhang, Yingzheng Ma, Shuyu Han, Wei Qi, Zuo-Jun Max Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19001" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19001</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Konstantin Kaulen, Tobias Ladner, Stanley Bak, Christopher Brix, Hai Duong, Thomas Flinkow, Taylor T. Johnson, Lukas Koller, Edoardo Manino, ThanhVu H Nguyen, Haoze Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19007</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hengrui Jia, Taoran Li, Jonas Guan, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19025" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19025</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Connor Kilrain, David Carlyn, Julia Chae, Sara Beery, Wei-Lun Chao, Jianyang Gu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19026" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19026</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9212089c44919f3c00bd82b13c0b39b407491c5d9de5c2c72ed790b2f0a0a2f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9212089c44919f3c00bd82b13c0b39b407491c5d9de5c2c72ed790b2f0a0a2f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Finer-Personalization Rank: Fine-Grained Retrieval Examines Identity Preservation for Personalized Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Recontextualization Mitigates Specification Gaming without Modifying the Specification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ariana Azarbal, Victor Gillioz, Vladimir Ivanov, Bryce Woodworth, Jacob Drori, Nevan Wichers, Aram Ebtekar, Alex Cloud, Alexander Matt Turner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19027</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Recontextualization Mitigates Specification Gaming without Modifying the Specification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xu Liu, Yu Liu, Hanshuo Qiu, Yang Qirong, Zhouhui Lian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19024" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19024</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6756a03a5e10a12bbcf7c372024e83600363def7ecc93793c6ea6abf5fb1e097_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6756a03a5e10a12bbcf7c372024e83600363def7ecc93793c6ea6abf5fb1e097_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chi Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can abstract concepts from LLM improve SLM performance?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Siddharth Tandon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19069" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19069</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c5acb71114f63e96507f1b112ea484c287d603fcb8d6eff38459b7e748f327_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c5acb71114f63e96507f1b112ea484c287d603fcb8d6eff38459b7e748f327_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can abstract concepts from LLM improve SLM performance?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanzhi Zhang, Yitong Duan, Zhaoxi Zhang, Jiyan He, Shuxin Zheng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19081" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19081</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bc376ab7cffef097c2b5c88731fb39a3b1651cbf234ff265cff9da444c1ef62_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bc376ab7cffef097c2b5c88731fb39a3b1651cbf234ff265cff9da444c1ef62_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">γ(3,4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mopen">(</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> `Attention&#x27; in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mark Burgess</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19084</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72c21c32f8ba86f52bd19910dee8b59d7a15f63a4f5f0fffc1d598908faca89a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72c21c32f8ba86f52bd19910dee8b59d7a15f63a4f5f0fffc1d598908faca89a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mn>3</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">γ(3,4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.05556em">γ</span><span class="mopen">(</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> `Attention&#x27; in Cognitive Agents: Ontology-Free Knowledge Representations With Promise Theoretic Semantics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peiqing Lu, Yuan Zhang, Haoyun Zhang, Jiasen Zheng, Kejian Tong, Wenjun Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19093" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19093</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ba3857cb85f2a61550d6204fcd94a616e3814c7b544954750bbe22dbc8e0777_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tool-Augmented Hybrid Ensemble Reasoning with Distillation for Bilingual Mathematical Problem Solving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conditioning Accept-Desirability models in the context of AGM-like belief change</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kathelijne Coussement, Gert de Cooman, Keano De Vos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19096</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9a6821327555a097c992306a0343c693b0fa705a5154b551d5d3ec2af0af7fa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9a6821327555a097c992306a0343c693b0fa705a5154b551d5d3ec2af0af7fa_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conditioning Accept-Desirability models in the context of AGM-like belief change</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Danny Dongyeop Han, Yonghyeon Gwon, Ahhyun Lucy Lee, Taeyang Lee, Seong Jin Lee, Jubin Choi, Sebin Lee, Jihyun Bang, Seungju Lee, David Keetae Park, Shinjae Yoo, Chun Kee Chung, Jiook Cha</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19097</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Yang, Xiaoshuang Sheng, Zhengnan Zhang, Jidong Wu, Zexing Wang, Xin He, Shenghua Xu, Guanjing Xiong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19107</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e20091cfc0ac4fa7e40c8d6d14ca11096f0a2c018bfea46fd36ed88a815bde01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e20091cfc0ac4fa7e40c8d6d14ca11096f0a2c018bfea46fd36ed88a815bde01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoyu Jiang, Boan Qu, Junjie Zhu, Fanjie Zeng, Xiaojie Lin, Wei Zhong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19114" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19114</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chenghao Li, Chaoning Zhang, Yi Lu, Shuxu Chen, Xudong Wang, Jiaquan Zhang, Zhicheng Wang, Zhengxun Jin, Kuien Liu, Sung-Ho Bae, Guoqing Wang, Yang Yang, Hen Tao Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e824123c4e563edae3f7da6c1bb5757bd1fcb243770125d234d65f7ec4e4d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e824123c4e563edae3f7da6c1bb5757bd1fcb243770125d234d65f7ec4e4d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yin Jun Phua</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19155" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19155</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8c12473f43d4f07485e40276605a028c808372091757f33fc5847a97e4469d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8c12473f43d4f07485e40276605a028c808372091757f33fc5847a97e4469d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Can We Test Consciousness Theories on AI? Ablations, Markers, and Robustness</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Geraud Nangue Tasse, Matthew Riemer, Benjamin Rosman, Tim Klinger</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19154" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19154</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vision-Language-Policy Model for Dynamic Robot Task Planning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jin Wang, Kim Tien Ly, Jacques Cloete, Nikos Tsagarakis, Ioannis Havoutis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19178" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19178</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61b83585238832b8c3decda632e24be3e08e065673710008da8a24e7fc11820b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61b83585238832b8c3decda632e24be3e08e065673710008da8a24e7fc11820b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vision-Language-Policy Model for Dynamic Robot Task Planning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19184" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19184</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Practical Quantum-Classical Feature Fusion for complex data Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19180</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Practical Quantum-Classical Feature Fusion for complex data Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19199</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tao Zhang, Ziqian Zeng, Hao Peng, Huiping Zhuang, Cen Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jerry Wang, Ting Yiu Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19210" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19210</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62c98c8f57888fd4ebe24a386db1767dce70baaed757b8ccaec8a6d19541746c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62c98c8f57888fd4ebe24a386db1767dce70baaed757b8ccaec8a6d19541746c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Observer, Not Player: Simulating Theory of Mind in LLMs through Game Observation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Minimal Fine-Tuning of VLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tiange Luo, Lajanugen Logeswaran, Jaekyeom Kim, Justin Johnson, Honglak Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19219" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19219</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/420c22fc5b580697b05c90c8fbf0115c2cea8a82f971a19f125c0456c3405309_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/420c22fc5b580697b05c90c8fbf0115c2cea8a82f971a19f125c0456c3405309_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Minimal Fine-Tuning of VLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Pixels to Predicates Structuring urban perception with scene graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yunlong Liu, Shuyang Li, Pengyuan Liu, Yu Zhang, Rudi Stouffs</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19221" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19221</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a8aa60cbd8f9c8016e6a36a9941d4f6c5a8af94206f4d30a8f70eac213a2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a8aa60cbd8f9c8016e6a36a9941d4f6c5a8af94206f4d30a8f70eac213a2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Pixels to Predicates Structuring urban perception with scene graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Valentin Schmidberger, Manuel Eberhardinger, Setareh Maghsudi, Johannes Maucher</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19228" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19228</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53ed231c85ea495143f9234046091abf1a755a2bae0a9a62789a4927a126a190_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53ed231c85ea495143f9234046091abf1a755a2bae0a9a62789a4927a126a190_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generation of Programmatic Rules for Document Forgery Detection Using Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anna-Maria Gueorguieva, Aylin Caliskan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19238" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19238</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingxu Zhang, Dazhong Shen, Qi Zhang, Ying Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19240" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19240</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DeliveryBench: Can Agents Earn Profit in Real World?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjun Mao, Jiawei Ren, Kun Zhou, Jixuan Chen, Ziqiao Ma, Lianhui Qin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19234" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19234</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c24ad2486e536c4e46b7008f9b36fe0a1b521f054ff0b708d9260cb71032fa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c24ad2486e536c4e46b7008f9b36fe0a1b521f054ff0b708d9260cb71032fa7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DeliveryBench: Can Agents Earn Profit in Real World?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Do Minh Duc, Quan Xuan Truong, Nguyen Tat Dat, Nguyen Van Vinh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19247" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19247</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carla Crivoi, Radu Tudor Ionescu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19253" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19253</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiaao Wu, Xian Zhang, Fan Yang, Yinpeng Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19287" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19287</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b24f019b56baece009c93ac1107b1f8aea4b09d87df075427e81815567970f3d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b24f019b56baece009c93ac1107b1f8aea4b09d87df075427e81815567970f3d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vibe Reasoning: Eliciting Frontier AI Mathematical Capabilities -- A Case Study on IMO 2025 Problem 6</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ivan DeAndres-Tame, Chengwei Ye, Ruben Tolosana, Ruben Vera-Rodriguez, Shiqi Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d12748fd351c66664603a2df32d39e3ed4e526013cc4fc7f328dc001dea6e6a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d12748fd351c66664603a2df32d39e3ed4e526013cc4fc7f328dc001dea6e6a2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Is Visual Realism Enough? Evaluating Gait Biometric Fidelity in Generative AI Human Animation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linzhi Chen, Yang Sun, Hongru Wei, Yuqi Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19297" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19297</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb0bd7eb8763e5b7b48b95fffa2b9d2689db5cbe27fd8dd5ff4a8a691095d826_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb0bd7eb8763e5b7b48b95fffa2b9d2689db5cbe27fd8dd5ff4a8a691095d826_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Causal-Guided Detoxify Backdoor Attack of Open-Weight LoRA Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chang Dong, Jianfeng Tao, Chengliang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19280</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> A.A. Gde Yogi Pramana, Jason Ray, Anthony Jaya, Michael Wijaya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e59bf81bbcade919249cc70e6c7c857215e36f22480011e424fdeb4a1f6ca56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e59bf81bbcade919249cc70e6c7c857215e36f22480011e424fdeb4a1f6ca56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Alternative positional encoding functions for neural transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ezequiel Lopez-Rubio, Macoris Decena-Gimenez, Rafael Marcos Luque-Baena</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19323" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19323</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Alternative positional encoding functions for neural transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MAGIC: Achieving Superior Model Merging via Magnitude Calibration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19320" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19320</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MAGIC: Achieving Superior Model Merging via Magnitude Calibration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hui Li, Jiayue Lyu, Fu-Yun Wang, Kaihui Cheng, Siyu Zhu, Jingdong Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/333652b938a5ecac737d2dfcea2bae93a2f072e15ac1c354ce9b2da1931714cc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/333652b938a5ecac737d2dfcea2bae93a2f072e15ac1c354ce9b2da1931714cc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MixFlow Training: Alleviating Exposure Bias with Slowed Interpolation Mixture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoyu Jiang, Fanjie Zeng, Boan Qu, Xiaojie Lin, Wei Zhong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19299</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f659480b32a80b6959cb66f4e981a4486e0674a48613b87e1f87ae33a24a364_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f659480b32a80b6959cb66f4e981a4486e0674a48613b87e1f87ae33a24a364_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Helios: A Foundational Language Model for Smart Energy Knowledge Reasoning and Application</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> JiaWei Zhu, ZiHeng Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19349" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19349</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] First-Order Representation Languages for Goal-Conditioned RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19355" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19355</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a8381365dc741932409d148f8d829e1cb922492f327e8a311d02d4ed8ad6d56_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> First-Order Representation Languages for Goal-Conditioned RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> A. B. M. Ashikur Rahman, Saeed Anwar, Muhammad Usman, Irfan Ahmad, Ajmal Mian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19350" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19350</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22263a25ed189a880450b2a3c8562fb8b0c96c8ec9fefce093363fc2ea2fb8f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22263a25ed189a880450b2a3c8562fb8b0c96c8ec9fefce093363fc2ea2fb8f6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PENDULUM: A Benchmark for Assessing Sycophancy in Multimodal Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning General Policies with Policy Gradient Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Blai Bonet, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19366</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning General Policies with Policy Gradient Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christian Hägg, Kathlén Kohn, Giovanni Luca Marchetti, Boris Shapiro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19367</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19379</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19396" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19396</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bef52c443ab4e7eee0649ff0f53fd382c9727d2345228eb8bb9fe5ad898a8eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bef52c443ab4e7eee0649ff0f53fd382c9727d2345228eb8bb9fe5ad898a8eb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yueyao Chen, Kai-Ni Wang, Dario Tayupo, Arnaud Huaulm&#x27;e, Krystel Nyangoh Timoh, Pierre Jannin, Qi Dou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19387</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d09473d7af5f8db0e2099dcd5a18592d023dddc412cada060f4f05596921ff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d09473d7af5f8db0e2099dcd5a18592d023dddc412cada060f4f05596921ff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DSTED: Decoupling Temporal Stabilization and Discriminative Enhancement for Surgical Workflow Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Research Program: Theory of Learning in Dynamical Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Elad Hazan, Shai Shalev Shwartz, Nathan Srebro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19410" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19410</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Research Program: Theory of Learning in Dynamical Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Attention Is Not What You Need</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhang Chong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19428" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19428</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Attention Is Not What You Need</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fei Ge, Ying Huang, Jie Liu, Guixuan Zhang, Zhi Zeng, Shuwu Zhang, Hu Guan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19438</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c5f1cc5f1508ff7f3dac04d0e138fe9c30202bb132ef0c4725622de8caf6c5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0c5f1cc5f1508ff7f3dac04d0e138fe9c30202bb132ef0c4725622de8caf6c5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MT-Mark: Rethinking Image Watermarking via Mutual-Teacher Collaboration with Adaptive Feature Modulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19456" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19456</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Agentic Framework for Autonomous Materials Computation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zeyu Xia, Jinzhe Ma, Congjie Zheng, Shufei Zhang, Yuqiang Li, Hang Su, P. Hu, Changshui Zhang, Xingao Gong, Wanli Ouyang, Lei Bai, Dongzhan Zhou, Mao Su</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19458" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19458</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc8796e6d842dffe17cec24dc175dc3c7a315afb61353b40a3cd5603693d9a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Agentic Framework for Autonomous Materials Computation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lorenzo Capelli, Leandro de Souza Rosa, Gianluca Setti, Mauro Mangia, Riccardo Rovatti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19472" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19472</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Katharina Stengg, Christian Macho, Martin Pinzger</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19481" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19481</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nikita Volzhin, Soowhan Yoon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19494" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19494</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziyang Song, Zelin Zang, Zuyao Chen, Xusheng Liang, Dong Yi, Jinlin Wu, Hongbin Liu, Jiebo Luo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19512" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19512</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14f0ebe1771704c1788aacd2e3db88e7c3b990ef8113a061936422f9bb95889_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d14f0ebe1771704c1788aacd2e3db88e7c3b990ef8113a061936422f9bb95889_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Anatomy-R1: Enhancing Anatomy Reasoning in Multimodal Large Language Models via Anatomical Similarity Curriculum and Group Diversity Augmentation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongliang Li, Nong Zhang, Zhewen Xu, Xiang Li, Changzheng Liu, Chongbo Zhao, Jie Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19506</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Bo Yin, Yaochu Jin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19516</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19526</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cc62413ed86e23bc11d3109dd3f6d9f5cdc6abfea9e0de269b698952b18c550_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongsheng Xing, Qiuxin Si</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19530" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19530</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19535" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19535</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b20ae57f683974a6959785befd45010cb87dde73d9ccc345f16e11af116951e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b20ae57f683974a6959785befd45010cb87dde73d9ccc345f16e11af116951e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiawen Wang, Jingjing Wang Tianyang Chen, Min Zhang, Guodong Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19551" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19551</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdd63f7cc3d632dfdf950fc0474c659424578038c0958a942040653588c1bbd3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdd63f7cc3d632dfdf950fc0474c659424578038c0958a942040653588c1bbd3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Closed-Loop Embodied Empathy Evolution: Probing LLM-Centric Lifelong Empathic Motion Generation in Unseen Scenarios</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Martin Sedlacek, Pavlo Yefanov, Georgy Ponimatkin, Jai Bardhan, Simon Pilc, Mederic Fourmy, Evangelos Kazakos, Cees G. M. Snoek, Josef Sivic, Vladimir Petrik</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19562</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cb99fa05ab76ebf7aa83d9c99a1cab512063ae25e6fb2fa7beee0f0c7246905_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cb99fa05ab76ebf7aa83d9c99a1cab512063ae25e6fb2fa7beee0f0c7246905_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> REALM: A Real-to-Sim Validated Benchmark for Generalization in Robotic Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lawrence Krukrubo, Julius Odede, Olawande Olusegun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19557" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19557</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4cf6d654019f56b56f3c2182b2db9d82b07540ace871f6684795ebe22f1a7c35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4cf6d654019f56b56f3c2182b2db9d82b07540ace871f6684795ebe22f1a7c35_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Augmenting Intelligence: A Hybrid Framework for Scalable and Stable Explanations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanliang Huang, Xia Yan, Peiran Yin, Zhenduo Zhang, Zeyan Shao, Youran Wang, Haoliang Huang, Matthias Althoff</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19564" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19564</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd9b53a38761715bf725e8473ae990f27df4fc7048b67ea4fde9ad955b4ac95d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd9b53a38761715bf725e8473ae990f27df4fc7048b67ea4fde9ad955b4ac95d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Results of the 2024 CommonRoad Motion Planning Competition for Autonomous Vehicles</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] BabyFlow: 3D modeling of realistic and expressive infant faces</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonia Alomar, Mireia Masias, Marius George Linguraru, Federico M. Sukno, Gemma Piella</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19560" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19560</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4bdcd1bc9dd6e1141b9b283f24968fbb4a40dc22257a719c5e16fbac178220f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4bdcd1bc9dd6e1141b9b283f24968fbb4a40dc22257a719c5e16fbac178220f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> BabyFlow: 3D modeling of realistic and expressive infant faces</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Angjelin Hila</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19570</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Exploring the features used for summary evaluation by Human and GPT</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zahra Sadeghi, Evangelos Milios, Frank Rudzicz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19620" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19620</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploring the features used for summary evaluation by Human and GPT</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MapTrace: Scalable Data Generation for Route Tracing on Maps</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Artemis Panagopoulou, Aveek Purohit, Achin Kulshrestha, Soroosh Yazdani, Mohit Goyal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19609" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19609</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7cc350a173ade821ef309bec6e6155158ae8332042895a8d6f45396c8b70c06_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7cc350a173ade821ef309bec6e6155158ae8332042895a8d6f45396c8b70c06_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MapTrace: Scalable Data Generation for Route Tracing on Maps</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Clustering with Label Consistency</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Diptarka Chakraborty, Hendrik Fichtenberger, Bernhard Haeupler, Silvio Lattanzi, Ashkan Norouzi-Fard, Ola Svensson</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19654" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19654</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73fc229d3b4fc51718fe8d59f9abfb97c5b0e2d37b67f22dacfc080be54754bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73fc229d3b4fc51718fe8d59f9abfb97c5b0e2d37b67f22dacfc080be54754bb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clustering with Label Consistency</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19673</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Argha Kamal Samanta, Harshika Goyal, Vasudha Joshi, Tushar Mungle, Pabitra Mitra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19663" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19663</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd268a98c5baac8b164ba733c255159614de6b969e8c6dd3f943fa74d98e5a1b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd268a98c5baac8b164ba733c255159614de6b969e8c6dd3f943fa74d98e5a1b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond CLIP: Knowledge-Enhanced Multimodal Transformers for Cross-Modal Alignment in Diabetic Retinopathy Diagnosis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hanyang Kong, Xingyi Yang, Xiaoxu Zheng, Xinchao Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19678</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4f113f5d19fa4ca45dd649c8c074bdcd96d439b1640d1340c9f10070d3b5a62_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4f113f5d19fa4ca45dd649c8c074bdcd96d439b1640d1340c9f10070d3b5a62_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junze Ye, Daniel Tawfik, Alex J. Goodell, Nikhil V. Kotha, Mark K. Buyyounouski, Mohsen Bayati</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19691" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19691</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3b7aa03e4ca854038444e0521aaa9d1a6b6c20e2054b4637dd76d61ecac2014_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scalably Enhancing the Clinical Validity of a Task Benchmark with Physician Oversight</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Regan, Ying Xie</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17923" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17923</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dongdong Yang, Bin Li, Jiguang He, Yicheng Yan, Xiaoyu Zhang, Chongwen Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sheryl Chen, Tony Wang, Kyle Feinstein</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17929" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17929</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ravi Prasad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17968" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17968</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Re-assessing the evidence for mental rotation abilities in children using computational models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Arthur Aubret, Jochen Triesch</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17972" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17972</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04b19b13a0170f5c8d0ddc85fcabbe83baa46fd0d40efd430823288b256d119b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04b19b13a0170f5c8d0ddc85fcabbe83baa46fd0d40efd430823288b256d119b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Re-assessing the evidence for mental rotation abilities in children using computational models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Muhammad Osama Imran, Roshni Lulla, Rodney Sappington</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17989" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17989</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/088c001d289b3633293d46545215e3c6c3c647164a557d5d4458682598dc319a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Efficient Adjustment in Causal Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Isabela Belciug, Simon Ferreira, Charles K. Assaad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18315" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18315</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e651794ebebddd044adc102fdfd3e79c703c2f1d1bbe46f929abaf0866588f7c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e651794ebebddd044adc102fdfd3e79c703c2f1d1bbe46f929abaf0866588f7c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Efficient Adjustment in Causal Graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hee-Youl Kwak, Seong-Joon Park, Hyunwoo Jung, Jeongseok Ha, Jae-Won Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18273</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f5d84f1158c216751ab871ccb9ff92e39812054d2d89f523c363ba1d516324f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f5d84f1158c216751ab871ccb9ff92e39812054d2d89f523c363ba1d516324f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evolutionary BP+OSD Decoding for Low-Latency Quantum Error Correction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18263" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18263</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Illusion of Consistency: Selection-Induced Bias in Gated Kalman Innovation Statistics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Barak Or</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18508" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18508</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de95b749b6e41b5ecb30b6f99c2de21906ad83985f90b86407263b2e092757dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de95b749b6e41b5ecb30b6f99c2de21906ad83985f90b86407263b2e092757dd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Illusion of Consistency: Selection-Induced Bias in Gated Kalman Innovation Statistics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Yang, Chiyuan Wang, Andreas Schaab, Benjamin Moll</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18892</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Owning the Intelligence: Global AI Patents Landscape and Europe&#x27;s Quest for Technological Sovereignty</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lapo Santarlasci, Armando Rungi, Loredana Fattorini, Nestor Maslej</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19569</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d480c4d77b7eaba72c49770556d7fc5b5d3dfd78a176aef0d2a236de15ebeb67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d480c4d77b7eaba72c49770556d7fc5b5d3dfd78a176aef0d2a236de15ebeb67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Owning the Intelligence: Global AI Patents Landscape and Europe&#x27;s Quest for Technological Sovereignty</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-24">2025-12-24<a href="#2025-12-24" class="hash-link" aria-label="Direct link to 2025-12-24" title="Direct link to 2025-12-24" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251224] QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19696" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19696</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Automated Fault Detection in 5G Core Networks Using Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Parsa Hatami, Ahmadreza Majlesara, Ali Majlesi, Babak Hossein Khalaj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19697" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19697</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51195e88b90e075513d8e30088f944c9008c4dee4bc84af09cdce6bb8a7b71e4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51195e88b90e075513d8e30088f944c9008c4dee4bc84af09cdce6bb8a7b71e4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automated Fault Detection in 5G Core Networks Using Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Md Nahid Hasan Shuvo, Moinul Hossain</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19711</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxuan Yin, Shengke Zhou, Yunjie Zhang, Ajay Mohindra, Boxun Xu, Peng Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19701</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Behrooz Mamandipoor, Chun-Nan Hsu, Martin Krause, Ulrich H. Schmidt, Rodney A. Gabriel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19716</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19707</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19717</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Lv, Siqi Ai, Yanbin Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19719" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19719</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Tiny, On-Device Decision Makers with the MiniConv Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carlos Purves</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19726</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tiny, On-Device Decision Makers with the MiniConv Library</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] High-Performance Self-Supervised Learning by Joint Training of Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kosuke Ukita, Tsuyoshi Okita</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19729" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19729</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> High-Performance Self-Supervised Learning by Joint Training of Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Clément Elliker, Jesse Read, Sonia Vanier, Albert Bifet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gongli Xi, Ye Tian, Mengyu Yang, Zhenyu Zhao, Yuchao Zhang, Xiangyang Gong, Xirong Que, Wendong Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19736</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sasan Sharifipour, Constantino Álvarez Casado, Manuel Lage Cañellas, Miguel Bordallo López</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19743" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19743</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumin Park, Noseong Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19765" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19765</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A K-Means, Ward and DBSCAN repeatability study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anthony Bertrand, Engelbert Mephu Nguifo, Violaine Antoine, David Hill</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19772" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19772</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A K-Means, Ward and DBSCAN repeatability study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Tarizzo, Mohammad Kazemi, Deniz Gündüz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19777" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19777</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b386ba4532b788c41eccda5b3c48b9585db890467bbb5e150328901a4ad2208_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learned Digital Codes for Over-the-Air Computation in Federated Edge Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ivan Daunis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19769" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19769</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19758" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19758</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19799" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19799</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1922ac933b302c99f4a3c639911ffa3980ae43238fad1b247af369017413128_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UCCL-EP: Portable Expert-Parallel Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19849</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UCCL-EP: Portable Expert-Parallel Communication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19882" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19882</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81c6462c8b784a5ac97bed22a2eedfc4c0fbad0afad1bab0e0a9aab3730a1834_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81c6462c8b784a5ac97bed22a2eedfc4c0fbad0afad1bab0e0a9aab3730a1834_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19864" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19864</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fine-Tuned In-Context Learners for Efficient Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19879" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19879</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fine-Tuned In-Context Learners for Efficient Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sujan Warnakulasooriya, Andreas Willig, Xiaobing Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19914" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19914</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/188da8ba7b74e5b961c0e61a49776e60da92670b4dd0b522d0c74e156682ec49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/188da8ba7b74e5b961c0e61a49776e60da92670b4dd0b522d0c74e156682ec49_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Time-efficient Prioritised Scheduling Algorithm to Optimise Initial Flock Formation of Drones</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Indranil Halder, Cengiz Pehlevan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19905" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19905</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxime Lacour, Pu Ren, Rie Nakata, Nori Nakata, Michael Mahoney</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19909" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19909</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Unified Brain Surface and Volume Registration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> S. Mazdak Abulnaga, Andrew Hoopes, Malte Hoffmann, Robin Magnet, Maks Ovsjanikov, Lilla Zöllei, John Guttag, Bruce Fischl, Adrian Dalca</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52472b7c53844ab7af247ff699ee1c659d2b3ff27e2e21ee8f187677824a5d8d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52472b7c53844ab7af247ff699ee1c659d2b3ff27e2e21ee8f187677824a5d8d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unified Brain Surface and Volume Registration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Samruddhi Baviskar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19935" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19935</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Vehicle-centric Perception via Multimodal Structured Pre-training</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Wu, Xiao Wang, Chenglong Li, Jin Tang, Bin Luo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vehicle-centric Perception via Multimodal Structured Pre-training</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19937" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19937</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67e83c33b123e956d61ade807a7eb155837dc60f3e60e67f0209df1eb75d7639_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67e83c33b123e956d61ade807a7eb155837dc60f3e60e67f0209df1eb75d7639_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Block-Recurrent Dynamics in Vision Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Block-Recurrent Dynamics in Vision Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How Much 3D Do Video Foundation Models Encode?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19949</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54fab192e555a908a0f7daf8d7992c85cd3241844d6a17c19d685c99c93dc5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b54fab192e555a908a0f7daf8d7992c85cd3241844d6a17c19d685c99c93dc5e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How Much 3D Do Video Foundation Models Encode?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Rodrigo Pereira David, Rodrigo Tripodi Calumby</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19957</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/307d3e337ca6d53335e1861afc2551a5e05ba3baffbfb580ffc6378d16a74e2f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/307d3e337ca6d53335e1861afc2551a5e05ba3baffbfb580ffc6378d16a74e2f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Luciano Araujo Dourado Filho, Rodrigo Tripodi Calumby</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19960" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19960</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbfda29c0b0fd29ef417a6aed2c9021c6a676577f450cbc925474212756dbba1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbfda29c0b0fd29ef417a6aed2c9021c6a676577f450cbc925474212756dbba1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Yin, Xiaodong Gu, Beijun Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19980</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19995" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19995</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] S<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>IT: A Benchmark for Spatially Situated Social Intelligence Test</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19992" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19992</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a7f6951c4ebc6cf6c8bd633198ae7d4c6a7c8f1e0cd348aa9e6737966dfe600_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> S<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>IT: A Benchmark for Spatially Situated Social Intelligence Test</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Gao, Zhenguo Dong, Xuelong Wang, Zhiqiang Wang, Yong Zhang, Shaofan Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20028</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sangoh Lee, Sangwoo Mo, Wook-Shin Han</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbb9757af838ced105aac295c936d5bf2fa52c5f79d162d34ed41c9c961ae9e0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbb9757af838ced105aac295c936d5bf2fa52c5f79d162d34ed41c9c961ae9e0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nguyen Lam Phu Quy, Pham Phu Hoa, Tran Chi Nguyen, Dao Sy Duy Minh, Nguyen Hoang Minh Ngoc, Huynh Trung Kiet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20042" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20042</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fb136c3c44d734ccd03ee7608dfc92d3612b466bfffc82e1d2efdfd79e5f161_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fb136c3c44d734ccd03ee7608dfc92d3612b466bfffc82e1d2efdfd79e5f161_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learning Skills from Action-Free Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20052" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20052</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def215474b82a6d04f6a6f79dc99c74e3b1159e34a80855d18649f29781a36fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/def215474b82a6d04f6a6f79dc99c74e3b1159e34a80855d18649f29781a36fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Skills from Action-Free Videos</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] An Optimal Policy for Learning Controllable Dynamics by Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peter N. Loxley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Optimal Policy for Learning Controllable Dynamics by Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Discovering Lie Groups with Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jung Yeon Park, Yuxuan Chen, Floor Eijkelboom, Jan-Willem van de Meent, Lawson L.S. Wong, Robin Walters</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20043</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/806c459fa9197bda13199f58531fce983ef12854f6eb2e8acaaea33dfebd6a22_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/806c459fa9197bda13199f58531fce983ef12854f6eb2e8acaaea33dfebd6a22_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Discovering Lie Groups with Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Scaling Reinforcement Learning for Content Moderation with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cc1d5bc88350e4d91579fed9a3b17abade80dc25754379e8e11ce92e39ca7d5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Reinforcement Learning for Content Moderation with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reason2Decide: Rationale-Driven Multi-Task Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20074" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20074</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reason2Decide: Rationale-Driven Multi-Task Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sangryu Park, Gihyuk Ko, Homook Cho</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20062" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20062</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74a88fcd014c903ee16397aa497f69b488c2c3bdeb23c2bddfc09643306081ec_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hao Li, Fabian Deuser, Wenping Yin, Steffen Knoblauch, Wufan Zhao, Filip Biljecki, Yong Xue, Wei Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20056" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20056</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c37110ad3319d1434c17c04ae94a4dcfa94a278faf51360e359e1a063ce32e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c37110ad3319d1434c17c04ae94a4dcfa94a278faf51360e359e1a063ce32e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dianxuan Fu, Xiaomin Liu, Yihao Zhang, Shikui Shen, Weisheng Hu, Qunbi Zhuge</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20080</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b7f27ae92944936b92479ef7c0a55f8c448c532444c4f43131d8768483bda71_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b7f27ae92944936b92479ef7c0a55f8c448c532444c4f43131d8768483bda71_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CBA: Communication-Bound-Aware Cross-Domain Resource Assignment for Pipeline-Parallel Distributed LLM Training in Dynamic Multi-DC Optical Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chaithra, Kamesh Kadimisetty, Biju R Mohan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20082" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20082</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8f2d13846195cc68b294529fa5d22600c76c1ff5581ee402ddf30ac1c06da72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jeehong Kim, Youngseok Hwang, Minchan Kim, Sungho Bae, Hyunwoo Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20086</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanjie Li, Jian Xu, Xueqing Chen, Lina Yu, Shiming Xiang, Weijun Li, Cheng-lin Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20084</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jinyoung Choi, Youngchae Kwon, Injung Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20088" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20088</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1946d7c3329c37db07556d963544aad7dbfeda194c515e4debdc6e3754d8920_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1946d7c3329c37db07556d963544aad7dbfeda194c515e4debdc6e3754d8920_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Item Region-based Style Classification Network (IRSN): A Fashion Style Classifier Based on Domain Knowledge of Fashion Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Evolutionary Neural Architecture Search with Dual Contrastive Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xian-Rong Zhang, Yue-Jiao Gong, Wei-Neng Chen, Jun Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20112" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20112</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/659d1805ddb5e7863af4ee9eeedcfdd78686f84f207247f4d0e65555165f2577_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/659d1805ddb5e7863af4ee9eeedcfdd78686f84f207247f4d0e65555165f2577_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evolutionary Neural Architecture Search with Dual Contrastive Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20111" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20111</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20135</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/354a0c5aa0cbd47dcbbf13234c253d1300ed7b0266e8ead6da21580f2b96f942_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20145</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] M<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20136" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20136</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> M<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xingyou Yin, Ceyao Zhang, Min Hu, Kai Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20140" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20140</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4380a71bf6060d158bfda4324d258b0056d7685334fc2256c0df38315036c209_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4380a71bf6060d158bfda4324d258b0056d7685334fc2256c0df38315036c209_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fun-Audio-Chat Technical Report</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20156" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20156</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fun-Audio-Chat Technical Report</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20159" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20159</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dhivya Dharshini Kannan, Anupam Trivedi, Dipti Srinivasan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20161" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20161</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1417550973096c816c854e8c26e0184adfd5d9410e4449d0498cc343fd80cc27_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1417550973096c816c854e8c26e0184adfd5d9410e4449d0498cc343fd80cc27_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Concept Generalization in Humans and Large Language Models: Insights from the Number Game</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Arghavan Bazigaran, Hansem Sohn</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20162" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20162</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f33aa8c0a9e961f65d06bf913a8cd4cb96d114bf3d4806d5932ebcb99dbac9d2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f33aa8c0a9e961f65d06bf913a8cd4cb96d114bf3d4806d5932ebcb99dbac9d2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Concept Generalization in Humans and Large Language Models: Insights from the Number Game</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20164" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20164</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Songze Li, Jiameng Cheng, Yiming Li, Xiaojun Jia, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20168" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20168</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FaithLens: Detecting and Explaining Faithfulness Hallucination</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20182" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20182</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FaithLens: Detecting and Explaining Faithfulness Hallucination</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Offline Safe Policy Optimization From Heterogeneous Feedback</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ze Gong, Pradeep Varakantham, Akshat Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20173" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20173</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9834f9cb644c8389de473430a70e825274ad26459f3ce94c2018ac8228df6f9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Safe Policy Optimization From Heterogeneous Feedback</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Teqiang Zou, Hongliang Zeng, Yuxuan Nong, Yifan Li, Kehui Liu, Haotian Yang, Xinyang Ling, Xin Li, Lianyang Ma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20188" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20188</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2574b3e0fe38bea23055b8f04a72d9d1bf8fedc2ee3f2dcf7a4e5a2f16af3c51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2574b3e0fe38bea23055b8f04a72d9d1bf8fedc2ee3f2dcf7a4e5a2f16af3c51_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20204</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TongSIM: A General Platform for Simulating Intelligent Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhe Sun, Kunlun Wu, Chuanjian Fu, Zeming Song, Langyong Shi, Zihe Xue, Bohan Jing, Ying Yang, Xiaomeng Gao, Aijia Li, Tianyu Guo, Huiying Li, Xueyuan Yang, Rongkai Liu, Xinyi He, Yuxi Wang, Yue Li, Mingyuan Liu, Yujie Lu, Hongzhao Xie, Shiyun Zhao, Bo Dai, Wei Wang, Tao Yuan, Song-Chun Zhu, Yujia Peng, Zhenliang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca507a85ff857b30b18d4ea2014b82001e6b5d0adac56afe981969173bc45325_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TongSIM: A General Platform for Simulating Intelligent Machines</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] MemR<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Memory Retrieval via Reflective Reasoning for LLM Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xingbo Du, Loka Li, Duzhen Zhang, Le Song</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20237" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20237</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59b81bde40292c52d66676e0cadc37d954f64fdf390b55d610cd63316ed43ef4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59b81bde40292c52d66676e0cadc37d954f64fdf390b55d610cd63316ed43ef4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MemR<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>: Memory Retrieval via Reflective Reasoning for LLM Agents</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tarik Houichime, Abdelghani Souhar, Younes El Amrani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Divya Vijay, Vignesh Ethiraj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da6037bde0b2a44f38e40927d7e2b880cc97a5f8fde73345c4fad4c78baf4836_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20278" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20278</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f0ca1a3004807c69fa2a7198569167a93240c27f60163c26979dcccdf6072f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f0ca1a3004807c69fa2a7198569167a93240c27f60163c26979dcccdf6072f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20276" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20276</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b076c18a7407a2fa23f502051cf18d209fb696f05cbca7af89a2db3703250585_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b076c18a7407a2fa23f502051cf18d209fb696f05cbca7af89a2db3703250585_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><msup><mo stretchy="false">}</mo><mo stretchy="false">{</mo></msup><mn>3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}^\{3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">{</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mclose">}</span></span></span></span>{ETOR}: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebiasing for Weakly-Supervised Camouflaged Object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>etection with Scribble Annotations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiawei Ge, Jiuxin Cao, Xinyi Li, Xuelin Zhu, Chang Liu, Bo Liu, Chen Feng, Ioannis Patras</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20260" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20260</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee0606d3fe6e6ae30bbf9417baa7948dab878cfcc6b70e36031424c107aafb81_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ee0606d3fe6e6ae30bbf9417baa7948dab878cfcc6b70e36031424c107aafb81_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><msup><mo stretchy="false">}</mo><mo stretchy="false">{</mo></msup><mn>3</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}^\{3\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose"><span class="mclose">}</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mopen mtight">{</span></span></span></span></span></span></span></span><span class="mord">3</span><span class="mclose">}</span></span></span></span>{ETOR}: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebate-Enhanced Pseudo Labeling and Frequency-Aware Progressive <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>ebiasing for Weakly-Supervised Camouflaged Object <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">}</span></span></span></span>etection with Scribble Annotations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20288" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20288</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6106b87e48429449f0b11c2765bdedb47797d7822e4b38ad3a9fe7f94b92dacb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6106b87e48429449f0b11c2765bdedb47797d7822e4b38ad3a9fe7f94b92dacb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20298" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20298</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20292" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20292</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SlideTailor: Personalized Presentation Slide Generation for Scientific Papers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Joon Son Chung, Shinji Watanabe</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20296" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20296</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/217e6d95bfc0e38be8f5a7356d3e869c3b3a5b9d4daf05b6435c3c756df247c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/217e6d95bfc0e38be8f5a7356d3e869c3b3a5b9d4daf05b6435c3c756df247c6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhongyu Xia, Wenhao Chen, Yongtao Wang, Ming-Hsuan Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20299</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0961ae49fbc925ad5eacb6602aeec6cfdfabae07b252a044cd181bdb5a47746_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0961ae49fbc925ad5eacb6602aeec6cfdfabae07b252a044cd181bdb5a47746_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KnowVal: A Knowledge-Augmented and Value-Guided Autonomous Driving System</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20312</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Toward Explaining Large Language Models in Software Engineering Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20328" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20328</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Explaining Large Language Models in Software Engineering Tasks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junren Li, Luhua Lai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e8cac7516cbb65a566c19ba7dde5921369f69a0fe2fe62a1ee10bb383644f7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25e8cac7516cbb65a566c19ba7dde5921369f69a0fe2fe62a1ee10bb383644f7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20344" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20344</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9f502578578854e6ba573a8a7758a3229a45ec3bf4a1c2e637d1006bb31aa1c4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9f502578578854e6ba573a8a7758a3229a45ec3bf4a1c2e637d1006bb31aa1c4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20363" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20363</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen&#x27;s Kappa and Semantic Similarity for Qualitative Research Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen&#x27;s Kappa and Semantic Similarity for Qualitative Research Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Identifying Appropriately-Sized Services with Deep Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20381" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20381</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Appropriately-Sized Services with Deep Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20387</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20407" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20407</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simplifying Multi-Task Architectures Through Task-Specific Normalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mihai Suteu, Ovidiu Serban</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20420" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20420</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simplifying Multi-Task Architectures Through Task-Specific Normalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Adam Elaoumari</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20423" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20423</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b67cb70660ec29cf307ab6baf5a52c6e3cecc0888ba9656259ee05bcfef71b96_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b67cb70660ec29cf307ab6baf5a52c6e3cecc0888ba9656259ee05bcfef71b96_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evasion-Resilient Detection of DNS-over-HTTPS Data Exfiltration: A Practical Evaluation and Toolkit</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junho Yoon, Jaemo Jung, Hyunju Kim, Dongman Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20409" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20409</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d4c944d1aa99e38d69c83c388503646f62271c8bb649aafcafb57ad0ba7c7d0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d4c944d1aa99e38d69c83c388503646f62271c8bb649aafcafb57ad0ba7c7d0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20469" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20469</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efbb4cf73bd5e97a426fe07fa2444d9fce83c1cc337fc7a02676141bf805fbd9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20482" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20482</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Benchmarking LLMs for Predictive Applications in the Intensive Care Units</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20520" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20520</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/274c8c98260b88efe758b67759790448f6c4f5abe21a32dafdc4d3a311f9524b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/274c8c98260b88efe758b67759790448f6c4f5abe21a32dafdc4d3a311f9524b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Benchmarking LLMs for Predictive Applications in the Intensive Care Units</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Advancing Multimodal Teacher Sentiment Analysis<!-- -->:The<!-- --> Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20548" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20548</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb1b5cafe85ffb670c8629adfcf70c1f2a8ef006559d14cc0f3ad75463909ad8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb1b5cafe85ffb670c8629adfcf70c1f2a8ef006559d14cc0f3ad75463909ad8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Advancing Multimodal Teacher Sentiment Analysis<!-- -->:The<!-- --> Large-Scale T-MED Dataset &amp; The Effective AAM-TSA Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20563" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20563</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Distilling to Hybrid Attention Models via KL-Guided Layer Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20569</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Distilling to Hybrid Attention Models via KL-Guided Layer Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Performative Policy Gradient: Optimality in Performative Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Performative Policy Gradient: Optimality in Performative Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Pan, Zhuofu Chen, Ravi Netravali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20586</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dhruv Anand, Ehsan Shareghi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20595" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20595</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> İbrahim Oğuz Çetinkaya, Sajad Khodadadian, Taylan G. Topçu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20589" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20589</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd8f6dd1aa27848e72f81ba7279a1abe238ea198e2b3aa7513fc9ca373e7554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LongVideoAgent: Multi-Agent Reasoning with Long Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LongVideoAgent: Multi-Agent Reasoning with Long Videos</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generative AI for Analysts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Xue, Qian Zhang, Wu Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19705" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19705</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c446bca4991916c167230d9d5b7a57cb785d6214690dca03a9aacef2ebddb67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c446bca4991916c167230d9d5b7a57cb785d6214690dca03a9aacef2ebddb67_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative AI for Analysts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QMBench: A Research Level Benchmark for Quantum Materials Research</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanzhen Wang, Yiyang Jiang, Diana Golovanova, Kamal Das, Hyeonhu Bae, Yufei Zhao, Huu-Thong Le, Abhinava Chatterjee, Yunzhe Liu, Chao-Xing Liu, Felipe H. da Jornada, Binghai Yan, Xiao-Liang Qi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19753" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19753</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a5901ce24dd3558937f8fb69f70cd14d0da814e05be0cd205e3d5fb0d138661_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QMBench: A Research Level Benchmark for Quantum Materials Research</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alexis Pomares Pastor, Ines Ribeiro Violante, Gregory Scott</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20319" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20319</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb7898ab29ae44cef389712101b2dbc98a334b5761ab3b2e5825364d8f3f316_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb7898ab29ae44cef389712101b2dbc98a334b5761ab3b2e5825364d8f3f316_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Deep Learning Classification of EEG Responses to Multi-Dimensional Transcranial Electrical Stimulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Regression of Functions by Quantum Neural Networks Circuits</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fernando M. de Paula Neto, Lucas dos Reis Silva, Paulo S. G. de Mattos Neto, Felipe F. Fanchini</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19978</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad43eefe70b19a60b4cb6a98a6af78a755ad48beb67110a54813ba3e49fc1d5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad43eefe70b19a60b4cb6a98a6af78a755ad48beb67110a54813ba3e49fc1d5e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Regression of Functions by Quantum Neural Networks Circuits</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Muhammad Usman, Azka Rehman, Muhammad Mutti Ur Rehman, Abd Ur Rehman, Muhammad Umar Farooq</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20436" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20436</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdfcdd8483dd2617be0701188cb1e86708fc680b1516caff77f5075ed2baf49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/efdfcdd8483dd2617be0701188cb1e86708fc680b1516caff77f5075ed2baf49_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-25">2025-12-25<a href="#2025-12-25" class="hash-link" aria-label="Direct link to 2025-12-25" title="Direct link to 2025-12-25" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251225] Parameter-Efficient Neural CDEs via Implicit Function Jacobians</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [time series analysis], [Neural Controlled Differential Equations, parameter efficiency, implicit function Jacobians, continuous RNN]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ilya Kuleshov, Alexey Zaytsev</p>
</li>
<li class="">
<p><strong>institution:</strong> Applied AI Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20625" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20625</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel, parameter-efficient formulation of Neural Controlled Differential Equations (NCDEs) that drastically reduces the number of required parameters. 2. Introduces a logical interpretation of the method as a &quot;Continuous RNN,&quot; aligning with the original inspiration of NCDEs. 3. Presents a method leveraging implicit function Jacobians to achieve this efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f69d35dc890877df610e96a1c984c641596f7fcac2c4ff1dbf30f641c90d5d77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f69d35dc890877df610e96a1c984c641596f7fcac2c4ff1dbf30f641c90d5d77_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high parameter cost of Neural Controlled Differential Equations (NCDEs) for temporal sequence analysis. It proposes a new, parameter-efficient formulation that reinterprets NCDEs as a &quot;Continuous RNN&quot; and uses implicit function Jacobians to reduce the parameter count. The main conclusion is that this approach maintains the modeling power of NCDEs while being significantly more parameter-efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] BitRL-Light: 1-bit LLM Agents with Deep Reinforcement Learning for Energy-Efficient Smart Home Lighting Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [1-bit quantization, Deep Q-Network (DQN), edge inference, multi-objective RL, model compression]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ravi Gupta, Shabista Haider</p>
</li>
<li class="">
<p><strong>institution:</strong> AMD, Oracle</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20623" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20623</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel architecture integrating 1-bit quantized LLMs with DQN for multi-objective optimization of smart home lighting. 2. Voice command integration via Google Home and IFTTT webhooks for natural user interaction. 3. Comprehensive evaluation demonstrating the feasibility of intelligent adaptive control on sub-$50 hardware, with significant energy and latency improvements.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc8c0af6233346bd047dc958868370625b7e65b546832d11939a371662fc4980_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc8c0af6233346bd047dc958868370625b7e65b546832d11939a371662fc4980_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes BitRL-Light, a framework that combines a 1-bit quantized LLM with Deep Q-Network reinforcement learning for real-time smart home lighting control on edge devices. The system optimizes for energy efficiency and user comfort, achieving substantial energy savings and low latency on a Raspberry Pi. The work demonstrates that adaptive AI control is feasible on resource-constrained hardware without cloud dependency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Proceedings of the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025)</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [multidisciplinary conference], [knowledge engineering, creativity support systems, human-computer interaction, artificial intelligence, peer-reviewed proceedings]</p>
</li>
<li class="">
<p><strong>authors:</strong> Edited by Tessai Hayama, Takayuki Ito, Takahiro Uchiya, Motoki Miura, Takahiro Kawaji, Takaya Yuizono, Atsuo Yoshitaka, Tokuro Matsuo, Shun Okuhara, Jawad Haqbeen, Sofia Sahab, Wen Gu, Shiyao Ding</p>
</li>
<li class="">
<p><strong>institution:</strong> IEICE (The Institute of Electronics, Information and Communication Engineers)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20628" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20628</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a multidisciplinary forum for researchers in AI, knowledge engineering, HCI, and creativity support systems. 2. Presents peer-reviewed proceedings following a double-blind review process. 3. Facilitates extended publication of selected papers in IEICE Transactions on Information and Systems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8c9d50976ba52ad8c3511bc5a2800a053b1b858244a20cfcda006c283fdd5c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8c9d50976ba52ad8c3511bc5a2800a053b1b858244a20cfcda006c283fdd5c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This is the proceedings volume for the 20th International Conference on Knowledge, Information and Creativity Support Systems (KICSS 2025). It compiles peer-reviewed papers from a multidisciplinary forum, with selected works recommended for further publication in a journal.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Cooperation Through Indirect Reciprocity in Child-Robot Interactions</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [human-robot interaction], [indirect reciprocity, multi-armed bandit, coordination dilemmas]</p>
</li>
<li class="">
<p><strong>authors:</strong> Isabel Neto, Alexandre S. Pires, Filipa Correia, Fernando P. Santos</p>
</li>
<li class="">
<p><strong>institution:</strong> Universidade de Lisboa, University of Amsterdam, Instituto Superior Técnico</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20621" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20621</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrated that the mechanism of indirect reciprocity can be successfully transposed from human-human interactions to child-robot interactions. 2. Showed that children&#x27;s behavioral strategies provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. 3. Analyzed how differences in learning algorithms impact the dynamics and outcomes of human-AI cooperation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a49edd2299eeb19bce07b564c8061c35b829f55eb48557d15dbeabbbd028e0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a49edd2299eeb19bce07b564c8061c35b829f55eb48557d15dbeabbbd028e0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether indirect reciprocity, a mechanism for sustaining cooperation, applies to child-robot interactions. The authors combine laboratory experiments with theoretical modeling, using multi-armed bandit algorithms for the robots. They find that indirect reciprocity does extend to these interactions and that robots can learn to cooperate based on children&#x27;s strategies, though this learning is highly dependent on the human strategies revealed.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Efficient Asynchronous Federated Evaluation with Strategy Similarity Awareness for Intent-Based Networking in Industrial Internet of Things</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [Intent-Based Networking, Industrial Internet of Things, Asynchronous Federated Learning, Strategy Similarity, Multimodal Intent Alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaowen Qin, Jianfeng Zeng, Haodong Guo, Xiaohuan Li, Jiawen Kang, Qian Chen, Dusit Niyato</p>
</li>
<li class="">
<p><strong>institution:</strong> Guilin University of Electronic Technology, Guangdong University of Technology, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20627" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20627</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FEIBN, a federated learning framework for distributed policy verification in IIoT, enhancing privacy by avoiding raw data exposure. 2. Introduces SSAFL, a strategy similarity-aware mechanism for efficient node selection and asynchronous model updates to reduce communication overhead. 3. Leverages LLMs to align multimodal user intents into structured strategy tuples for automated policy generation and verification.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17f53425c1430ea3ad8516d92a010c39c2936d478f64e21bad2b552f30214b23_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17f53425c1430ea3ad8516d92a010c39c2936d478f64e21bad2b552f30214b23_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes FEIBN, a federated evaluation framework for Intent-Based Networking in IIoT. It uses LLMs to translate intents and a strategy similarity-aware asynchronous federated learning mechanism (SSAFL) for efficient, private policy verification. Experiments show SSAFL improves accuracy, convergence speed, and reduces cost by 27.8% compared to a baseline.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Quantum-Inspired Multi Agent Reinforcement Learning for Exploration Exploitation Optimization in UAV-Assisted 6G Network Deployment</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [Quantum-Inspired MARL, Variational Quantum Circuits (VQC), Centralized Training Decentralized Execution (CTDE), UAV-assisted 6G, Exploration-Exploitation Tradeoff]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mazyar Taghavi, Javad Vahidi</p>
</li>
<li class="">
<p><strong>institution:</strong> Iran University of Science and Technology, Intelligent Knowledge City</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20624" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20624</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel quantum-inspired framework integrating variational quantum circuits (VQCs) and QAOA with classical MARL to optimize the exploration-exploitation tradeoff. 2. Incorporates complementary probabilistic modeling (Bayesian inference, Gaussian processes) to capture latent environmental dynamics in a cooperative UAV scenario. 3. Demonstrates through experiments that the framework improves sample efficiency, convergence speed, and coverage performance compared to classical baselines like PPO and DDPG.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e597fe9c176a66c0f7f571bd1af94114997e4ea6eb2664bc14f6b638a115985d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e597fe9c176a66c0f7f571bd1af94114997e4ea6eb2664bc14f6b638a115985d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a quantum-inspired multi-agent reinforcement learning framework to optimize the exploration-exploitation balance for UAV-assisted 6G network deployment. The method integrates variational quantum circuits and probabilistic modeling within a centralized training, decentralized execution paradigm. The results show it achieves superior performance in coverage and convergence compared to classical MARL methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent language systems, latent strategy evolution, reinforcement feedback, external latent vectors, dual-loop architecture]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wenlong Tang</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (No institutional affiliation inferred from provided content)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20629" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20629</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/wltang-dev/Latent-Strategy-RL-Agent" target="_blank" rel="noopener noreferrer" class="">https://github.com/wltang-dev/Latent-Strategy-RL-Agent</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel multi-agent language framework that enables continual strategy evolution without fine-tuning the underlying language model&#x27;s parameters. 2. Introduces a dual-loop architecture (behavior loop and language loop) that updates external latent vectors through environmental interaction and semantic reflection on generated text. 3. Demonstrates that this approach allows agents to develop stable, disentangled strategic styles and shows emergent adaptation capabilities, providing a low-cost, scalable, and interpretable form of abstract strategic representation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c15e8361c02b5e6e0c755d3089af5adddafaad00ffda95b887b8eca526280761_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c15e8361c02b5e6e0c755d3089af5adddafaad00ffda95b887b8eca526280761_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of static semantic representations in language models by proposing a framework where agents evolve strategies without model fine-tuning. The core method uses a dual-loop architecture to update external latent vectors through environmental rewards and reflection on generated text. The results show that this enables agents to develop adaptable and interpretable strategic behaviors, offering a scalable alternative to parameter tuning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [multimodal knowledge graph, cross-modal reasoning, visual document understanding, retrieval-augmented generation, entity-centric structure]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> National Taiwan University, E.SUN Financial Holding Co., Ltd., National Kaohsiung Normal University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20626" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20626</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a multimodal knowledge graph-based RAG framework that integrates visual cues into KG construction, retrieval, and answer generation for cross-modal reasoning. 2. Addresses the limitation of existing text-only KG-RAG methods by automatically building KGs that capture text-to-figure and figure-to-figure relationships. 3. Demonstrates superior performance over existing RAG approaches on both textual and multimodal question-answering tasks through comprehensive experiments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces MegaRAG, a multimodal knowledge graph-based retrieval-augmented generation method designed to overcome the limitations of text-only RAG systems in understanding complex, long-form visual documents. It integrates visual information into the knowledge graph construction and retrieval process to enable better cross-modal reasoning. Experimental results show it consistently outperforms existing RAG methods on various question-answering tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MicroProbe: Efficient Reliability Assessment for Foundation Models with Minimal Data</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [model evaluation &amp; reliability], [reliability assessment, uncertainty quantification, strategic sampling, foundation models, probe selection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aayam Bansal, Ishaan Gangwani</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE (implied from email domain)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20630" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20630</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel strategic probe selection methodology that maximizes reliability coverage across five key dimensions with information-theoretic justification. 2. An advanced uncertainty-aware assessment framework with adaptive weighting and sophisticated consistency metrics. 3. Comprehensive empirical and cross-domain validation demonstrating significant improvements over random sampling with high statistical rigor.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b9cf5db61863c7d69dd0ba1dd95c34144ed7e7c901f129f236bfb156cb89dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b9cf5db61863c7d69dd0ba1dd95c34144ed7e7c901f129f236bfb156cb89dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces MicroProbe, a method for efficiently assessing the reliability of foundation models using only 100 strategically selected probe examples. It combines prompt diversity, uncertainty quantification, and adaptive weighting to detect failure modes. The approach is shown to achieve higher reliability scores with 90% lower cost and 95% coverage compared to traditional methods requiring thousands of examples.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [sentiment analysis], [temporal drift, zero-training detection, transformer models, social media streams, model instability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aayam Bansal, Ishaan Gangwani</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20631" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20631</a></p>
</li>
<li class="">
<p><strong>contributions:</strong>  1. Demonstrated significant temporal drift in transformer sentiment models during real-world events, with accuracy drops up to 23.4% on authentic social media data. 2. Introduced four novel zero-training drift detection metrics that outperform embedding-based baselines and are suitable for production deployment. 3. Provided comprehensive statistical validation on 12,279 authentic social media posts from major events, establishing practical significance exceeding industry monitoring thresholds.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8e40c0a23df847aa858c5e0ce28602f612024103d66ccaea9f9da99a1dded46_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8e40c0a23df847aa858c5e0ce28602f612024103d66ccaea9f9da99a1dded46_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of temporal drift in transformer-based sentiment models during real-world events without requiring model retraining. It proposes a zero-training detection framework using novel inference-time metrics, validated on authentic social media data. The main conclusion is that this method effectively detects significant model instability and enables immediate deployment for real-time monitoring systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Erkang-Diagnosis-1.1 Technical Report</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [retrieval-augmented generation], [Qwen-3, enhanced pre-training, retrieval-augmented generation, medical knowledge base, healthcare assistant]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jianbing Ma, Ao Feng, Zhenjie Gao, Xinyu Song, Li Su, Bin Chen, Wei Wang, Jiamin Wu</p>
</li>
<li class="">
<p><strong>institution:</strong> Chengdu Lingshu Health Technology Corp. Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20632" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20632</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Development of a specialized AI healthcare assistant (Erkang-Diagnosis-1.1) based on the Alibaba Qwen-3 model, 2. Integration of approximately 500GB of high-quality structured medical knowledge using a hybrid approach of enhanced pre-training and retrieval-augmented generation (RAG), 3. Demonstration of superior performance over GPT-4 in comprehensive medical exams through efficient 3-5 round interactions</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed164818e4da399ea74ba4b02c96fdf625f0f5b1c9130aaf2994523190ecf4eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed164818e4da399ea74ba4b02c96fdf625f0f5b1c9130aaf2994523190ecf4eb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces Erkang-Diagnosis-1.1, an AI healthcare assistant built on the Qwen-3 model. It integrates a large medical knowledge base using enhanced pre-training and retrieval-augmented generation to provide diagnostic suggestions. The model reportedly outperforms GPT-4 on medical exams.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [clinical prediction], [large language models, semantic feature engineering, multi-modal data integration, goal-oriented knowledge curator, treatment outcome prediction]</p>
</li>
<li class="">
<p><strong>authors:</strong> MunHwan Lee, Shaika Chowdhury, Xiaodi Li, Sivaraman Rajaganapathy, Eric W Klee, Ping Yang, Terence Sio, Liewei Wang, James Cerhan, Nansu NA Zong</p>
</li>
<li class="">
<p><strong>institution:</strong> Mayo Clinic</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20633" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20633</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel framework using Large Language Models (LLMs) as Goal-oriented Knowledge Curators (GKC) to generate task-aligned semantic features from raw clinical data, 2. Demonstrates that GKC, as an offline preprocessing step, outperforms expert-engineered features, direct embeddings, and end-to-end transformers in predicting lung cancer treatment outcomes, 3. Shows the complementary value of integrating laboratory, genomic, and medication modalities through ablation studies, highlighting semantic representation quality as key for accuracy in sparse data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c8925ebbf05c9b81fd60fa118034a660d2673702659d23d8b6cf7c1d976903_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7c8925ebbf05c9b81fd60fa118034a660d2673702659d23d8b6cf7c1d976903_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of predicting lung cancer treatment outcomes from sparse, heterogeneous clinical data by introducing a framework that uses Large Language Models as Goal-oriented Knowledge Curators to engineer semantic, task-specific features. This method outperforms traditional baselines, achieving a mean AUROC of 0.803, and demonstrates that high-quality semantic representation is crucial for predictive accuracy in clinical settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [catastrophic forgetting, spurious forgetting, shallow alignment, deep alignment, task alignment depth]</p>
</li>
<li class="">
<p><strong>authors:</strong> Weiwei Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shenzhen Sunline Tech Co., Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20634" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20634</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a quantitative framework (shallow vs. deep alignment) to measure task alignment depth across token positions. 2. Developed real-time detection methods and analysis tools for identifying shallow alignment and spurious forgetting during training. 3. Proposed adaptive mitigation strategies that automatically distinguish forgetting types and promote deep alignment to improve model robustness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2920732eeec32977638a62ffbcf4b4b075dbdd77ebc58fa777ff8a10e117219_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2920732eeec32977638a62ffbcf4b4b075dbdd77ebc58fa777ff8a10e117219_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses catastrophic forgetting in continual learning for LLMs by identifying that performance drops are often due to &quot;spurious forgetting&quot; from shallow task alignment. The authors propose a framework to quantitatively measure alignment depth, detect shallow alignment in real-time, and apply mitigation strategies to promote deep alignment. Experiments show their method accurately identifies spurious forgetting and improves model robustness against forgetting by 3.3-7.1% over baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Data-Free Pruning of Self-Attention Layers in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [attention pruning, data-free pruning, Gate-Norm, inference acceleration, attention suppression hypothesis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dhananjay Saikumar, Blesson Varghese</p>
</li>
<li class="">
<p><strong>institution:</strong> University of St Andrews</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20636" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20636</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Attention Suppression Hypothesis to explain the redundancy of deep self-attention layers in LLMs. 2. Introduces Gate-Norm, a one-shot, weight-only criterion for ranking and pruning attention sublayers without requiring data, forward passes, or fine-tuning. 3. Demonstrates that pruning 8-16 attention layers with Gate-Norm yields up to 1.30x higher inference throughput while maintaining accuracy within 2% of the baseline, matching data-driven methods but being ~1000x faster.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9338cbf768451f7709aa625ae03202bc7b84fcaa758ea1d75a6f5eaa4aa228c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9338cbf768451f7709aa625ae03202bc7b84fcaa758ea1d75a6f5eaa4aa228c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high inference cost of LLMs by proposing a data-free method to prune redundant self-attention layers. It introduces Gate-Norm, a fast weight-only criterion based on query-key coupling, which removes layers without needing calibration data or fine-tuning. The method significantly speeds up inference while preserving model accuracy, enabling practical LLM compression.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Uncovering Competency Gaps in Large Language Models and Their Benchmarks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm evaluation], [sparse autoencoders, benchmark gaps, model gaps, concept activations, competency gaps]</p>
</li>
<li class="">
<p><strong>authors:</strong> Matyas Bohacek, Nino Scherrer, Nicholas Dufour, Thomas Leung, Christoph Bregler, Stephanie C. Y. Chan</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University, Google DeepMind</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20638" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20638</a></p>
</li>
<li class="">
<p><strong>code:</strong> competency-gaps.github.io</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel method using sparse autoencoders (SAEs) to automatically uncover fine-grained competency gaps in LLMs and benchmarks. 2. Introduces a representation-grounded evaluation approach that computes saliency-weighted performance scores based on model-internal concept activations. 3. Demonstrates the method&#x27;s ability to identify specific model weaknesses (e.g., non-sycophantic behaviors) and benchmark coverage imbalances (e.g., over-representation of obedience concepts) without manual supervision.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6d5ab9e8ede467e65cbc2079e58ecf9b8d8ade8145f7e9e90f1b6f8382e288b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6d5ab9e8ede467e65cbc2079e58ecf9b8d8ade8145f7e9e90f1b6f8382e288b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem that aggregated benchmark scores can hide specific weaknesses in LLMs and imbalances in benchmark coverage. The authors propose an automated method using sparse autoencoders to decompose benchmark performance into fine-grained concepts based on the model&#x27;s internal representations. Their analysis of two models and ten benchmarks revealed model gaps in areas like non-sycophancy and safety, and benchmark gaps such as an over-representation of obedience-related concepts.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Forecasting N-Body Dynamics: A Comparative Study of Neural Ordinary Differential Equations and Universal Differential Equations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [scientific machine learning], [Neural Ordinary Differential Equations, Universal Differential Equations, forecasting breakdown point, n-body problem, Julia]</p>
</li>
<li class="">
<p><strong>authors:</strong> Suriya R S, Prathamesh Dinesh Joshi, Rajat Dandekar, Raj Dandekar, Sreedath Panat</p>
</li>
<li class="">
<p><strong>institution:</strong> Vizuara AI Labs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20643" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20643</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a comparative study of Neural ODEs and Universal Differential Equations (UDEs) for forecasting n-body dynamics, a fundamental astrophysics problem. 2. Introduced and determined the &quot;forecasting breakdown point&quot; to quantify the minimal training data required for accurate future predictions. 3. Demonstrated that the UDE model, which blends known physics with neural networks, is significantly more data-efficient, requiring only 20% of data for a correct forecast compared to 90% for a Neural ODE.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06b852f384c602c478fd1ea2166cf9ac3e8442f63a46b1d479333a1e00699c6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06b852f384c602c478fd1ea2166cf9ac3e8442f63a46b1d479333a1e00699c6b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper compares two Scientific Machine Learning frameworks, Neural ODEs and Universal Differential Equations (UDEs), for forecasting the dynamics of the n-body problem. The study introduces the concept of a &quot;forecasting breakdown point&quot; to measure data efficiency and finds that the UDE model, which incorporates known physical laws, is far more efficient, requiring only 20% of the training data that a Neural ODE needs for accurate predictions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Reasoning Relay: Evaluating Stability and Interchangeability of Large Language Models in Mathematical Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning evaluation], [chain-of-thought, reasoning interchangeability, process reward model, token-level log-probability thresholds]</p>
</li>
<li class="">
<p><strong>authors:</strong> Leo Lu, Jonathan Zhang, Sean Chua, Spencer Kim, Kevin Zhu, Sean O&#x27;Brien, Vasu Sharma</p>
</li>
<li class="">
<p><strong>institution:</strong> Pennsylvania State University, Binghamton University, University of Toronto, UC Berkeley, Algoverse</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20647" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20647</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a framework to evaluate the interchangeability of reasoning chains across LLMs, assessing if partial reasoning from one model can be reliably continued by another. 2. Introduces a method using token-level log-probability thresholds to truncate reasoning at different stages and a Process Reward Model (PRM) for evaluation. 3. Demonstrates that hybrid reasoning chains often preserve or even improve final accuracy and logical structure, suggesting interchangeability as an emerging property for modular reasoning in collaborative AI.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2ec01f1b7eff609789d150706b31289a628fdb2bdaa6ac8867d9e30a0ea0c1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad2ec01f1b7eff609789d150706b31289a628fdb2bdaa6ac8867d9e30a0ea0c1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether partially completed reasoning chains from one large language model can be reliably continued by another model, using token-level log-probability thresholds to truncate reasoning and a Process Reward Model for evaluation. The study finds that hybrid reasoning chains often maintain or enhance accuracy and coherence, indicating that reasoning interchangeability is a viable property for collaborative AI systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Mixture of Attention Schemes (MoAS): Learning to Route Between MHA, GQA, and MQA</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Mixture of Attention Schemes, KV Cache, Dynamic Routing, Conditional Computation, Attention Mechanism]</p>
</li>
<li class="">
<p><strong>authors:</strong> Esmail Gumaan</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (Inferred from personal email domain)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20650" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20650</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Esmail-ibraheem/Mixture-of-Attention-Schemes-MoAS" target="_blank" rel="noopener noreferrer" class="">https://github.com/Esmail-ibraheem/Mixture-of-Attention-Schemes-MoAS</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Mixture of Attention Schemes (MoAS), a novel architecture that dynamically routes tokens between MHA, GQA, and MQA attention schemes. 2. Demonstrates that dynamic routing outperforms a static averaging of attention schemes, validating the learned routing approach. 3. Shows the method achieves performance competitive with the high-quality MHA baseline while offering potential for conditional compute and memory efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151d0589c37dc455317c2c4d1e613c5f722207da0abcb0abaf82373ef04ee19d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151d0589c37dc455317c2c4d1e613c5f722207da0abcb0abaf82373ef04ee19d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the trade-off between model quality and inference efficiency in Transformer attention mechanisms. It proposes MoAS, which uses a learned router to dynamically select between MHA, GQA, and MQA for each token. Experiments show dynamic routing outperforms static mixtures and matches MHA performance, offering a path to efficient conditional computation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] AIAuditTrack: A Framework for AI Security system</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [AI governance and auditing], [blockchain, decentralized identity (DID), verifiable credentials (VC), risk diffusion algorithm, interaction graph]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zixun Luo, Yuhang Fan, Yufei Li, Youzhi Zhang, Hengyu Lin, Ziqi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Huazhong University of Science and Technology, Lingnan University, Centre for Artificial Intelligence and Robotics (CAIR) Hong Kong Institute of Science &amp; Innovation, Chinese Academy of Sciences, Tsinghua University, Fujian Jiangxia University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20649" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20649</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a blockchain-based framework (AiAuditTrack) for recording and governing AI usage traffic to enable auditing and risk traceability. 2. Introduces an identity management mechanism using Decentralized Identity (DID) and Verifiable Credentials (VC) to establish trusted and identifiable AI entities. 3. Designs a risk diffusion algorithm on a dynamic interaction graph model to trace the source of risky behaviors and propagate warnings.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b6835bdebf655288e51122fb875aaa032b286789052e6467724b2eb1e0af84_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74b6835bdebf655288e51122fb875aaa032b286789052e6467724b2eb1e0af84_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the security and accountability challenges in AI-driven applications by proposing AiAuditTrack, a blockchain framework that uses decentralized identity and verifiable credentials to record AI interaction data and enable auditing. It models AI entities as nodes in a graph and introduces a risk diffusion algorithm for tracing risky behavior origins. The framework&#x27;s feasibility is demonstrated through blockchain performance metrics (TPS) under large-scale recording scenarios.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] AI-Driven Decision-Making System for Hiring Process</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent system, LLM orchestration, human-in-the-loop, explainable scoring, public-data verification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vira Filatova, Andrii Zelenchuk, Dmytro Filatov</p>
</li>
<li class="">
<p><strong>institution:</strong> Covijn Ltd., Aimech Technologies Corp.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20652" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20652</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A modular multi-agent AI hiring assistant that integrates heterogeneous inputs (documents, video, public data) into a structured profile. 2. An LLM-orchestrated pipeline with strict constraints to reduce output variability and generate traceable, component-level rationales for scoring. 3. A configurable candidate ranking system based on aggregated technical fit, culture fit, and normalized risk penalties, evaluated with a proposed efficiency metric (expected time per qualified candidate).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af0225e1b8b3f96dbb1b944ce2ab06438c60ac8bcf7ef93a1f210771fa73aae4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af0225e1b8b3f96dbb1b944ce2ab06438c60ac8bcf7ef93a1f210771fa73aae4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the bottleneck of early-stage candidate validation in hiring by proposing an AI-driven, modular multi-agent system. The system integrates and processes diverse candidate inputs through an LLM-orchestrated pipeline to produce explainable scores and rankings. Evaluation on real applicants shows the system significantly improves screening efficiency, reducing the expected time per qualified candidate compared to human recruiters, while keeping a human as the final decision authority.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Memory Bear AI A Breakthrough from Memory to Cognition Toward Artificial General Intelligence</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [memory architecture, long-term conversation, hallucination reduction, multimodal perception, cognitive integration]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deliang Wen, Ke Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Not specified in provided content</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20651" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20651</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Memory Bear system, a human-like memory architecture for LLMs grounded in cognitive science principles. 2. Achieves a full-chain reconstruction of LLM memory mechanisms by integrating multimodal perception, dynamic memory maintenance, and adaptive cognitive services. 3. Demonstrates significant performance improvements in knowledge fidelity, retrieval efficiency, and hallucination reduction across multiple domains compared to existing solutions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9c13cde65ef804fade26e06361a8d03517ad2394b3e21295ae77d2b5b462c29_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9c13cde65ef804fade26e06361a8d03517ad2394b3e21295ae77d2b5b462c29_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the inherent memory limitations of LLMs, such as restricted context and hallucination, by proposing the Memory Bear system. Memory Bear constructs a cognitive science-inspired memory architecture to enhance long-term dialogue and reasoning. Experimental results show it outperforms existing methods in accuracy and efficiency, marking a step from memory to cognition in AI.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MaskOpt: A Large-Scale Mask Optimization Dataset to Advance AI in Integrated Circuit Manufacturing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [mask optimization, optical proximity correction, inverse lithography technique, deep learning, benchmark dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuting Hu, Lei Zhuang, Hua Xiang, Jinjun Xiong, Gi-Joon Nam</p>
</li>
<li class="">
<p><strong>institution:</strong> University at Buffalo, IBM Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20655" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20655</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MaskOpt, a large-scale benchmark dataset for AI-driven mask optimization constructed from real 45nm IC designs, addressing limitations of synthetic data. 2. The dataset preserves standard-cell hierarchy and includes varying context window sizes to enable cell- and context-aware model training. 3. Provides comprehensive benchmarks by evaluating state-of-the-art deep learning models, revealing performance trade-offs and validating the importance of contextual and cell-aware inputs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce9bc1ac552258257c450a9bc4d4c4ae0264c958efae291f56fc44af367bf07a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce9bc1ac552258257c450a9bc4d4c4ae0264c958efae291f56fc44af367bf07a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents MaskOpt, a large-scale dataset built from real integrated circuit designs to advance deep learning for mask optimization in semiconductor manufacturing. It addresses the limitations of existing synthetic datasets by including cell hierarchy and surrounding context. Benchmarking results demonstrate the dataset&#x27;s utility and highlight the critical role of context and cell information for accurate mask generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Managing the Stochastic: Foundations of Learning in Neuro-Symbolic Systems for Software Engineering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [dual-state architecture, atomic action pairs, guard functions, neuro-symbolic systems, code generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Matthew Thompson</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20660" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20660</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a control boundary that treats the LLM as a stochastic environment component, not the decision-making agent, to manage its unpredictability. 2. Formalizes a Dual-State Architecture separating deterministic workflow state from stochastic environment state. 3. Introduces Atomic Action Pairs and Guard Functions to couple generation with verification as indivisible transactions, projecting probabilistic outputs onto observable workflow state.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a73fceac46d6997904de43696e8db407d645c6e4388012a9e24a3b9565e06fb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a73fceac46d6997904de43696e8db407d645c6e4388012a9e24a3b9565e06fb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of stochastic failures in AI coding agents by proposing a neuro-symbolic architectural framework that treats the LLM as part of the environment. The method uses a Dual-State Architecture with Atomic Action Pairs and Guard Functions to separate deterministic control from stochastic generation. The main conclusion is that such architectural constraints can significantly improve task success rates for qualified models, potentially substituting for parameter scale in achieving reliable code generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] From Fake Focus to Real Precision: Confusion-Driven Adversarial Attention Learning in Transformers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [sentiment analysis], [adversarial training, attention mechanism, policy gradient, transformer, model interpretability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yawei Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Chinese Academy of Sciences, Computer Network Information Center</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20661" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20661</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an Adversarial Feedback for Attention (AFA) training mechanism to automatically redistribute attention weights without manual supervision. 2. Introduces a dynamic masking strategy and a discriminator in an adversarial framework to identify and correct suboptimal attention. 3. Employs a policy gradient approach to efficiently optimize attention distributions, leading to improved performance on sentiment analysis tasks and a 12.6% gain when applied to large language models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd81ed17263c1d20f831b211a88f9bc1399e87818af70003e7ba1196a7ddddf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6dd81ed17263c1d20f831b211a88f9bc1399e87818af70003e7ba1196a7ddddf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that Transformer models for sentiment analysis often misallocate attention to common words, missing important but less frequent terms. To solve this, it proposes an Adversarial Feedback for Attention (AFA) mechanism using dynamic masking and policy gradient optimization to refine attention distributions automatically. Experiments show the method achieves state-of-the-art results and significantly boosts performance in large language models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Quantifying Laziness, Decoding Suboptimality, and Context Degradation in Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm evaluation], [laziness, decoding suboptimality, context degradation, instruction-following, long-context]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yiqing Ma, Jung-Hua Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Universiti Malaya, National Chung Cheng University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20662" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20662</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Quantified the &quot;laziness&quot; artifact in LLMs, showing widespread failure to fully comply with complex multi-part instructions. 2. Provided empirical evidence challenging the prevalence of &quot;decoding suboptimality&quot; in a simple reasoning task, suggesting greedy decoding may align with high-confidence solutions. 3. Demonstrated surprising robustness against &quot;context degradation&quot; in long, chaotic conversations, indicating LLMs may internally mitigate context forgetting in retrieval scenarios.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c503ae7a717782d28701da19cc7269ead2f9a34b5478457e18e791787fc94dea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c503ae7a717782d28701da19cc7269ead2f9a34b5478457e18e791787fc94dea_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper quantifies three behavioral artifacts in Large Language Models (LLMs) through controlled experiments. The results show that while LLMs are often &quot;lazy&quot; in following complex instructions, they show limited decoding suboptimality and surprising robustness against context degradation in long conversations. The findings suggest instruction compliance remains a challenge, but some hypothesized failure modes like context forgetting may be less severe in straightforward scenarios.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Eidoku: A Neuro-Symbolic Verification Gate for LLM Reasoning via Structural Constraint Satisfaction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning verification], [structural constraint satisfaction, neuro-symbolic verification, hallucination detection, constraint satisfaction problem, system-2 gate]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shinobu Miya</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20664" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20664</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/ShinobuMiya/Eidoku" target="_blank" rel="noopener noreferrer" class="">https://github.com/ShinobuMiya/Eidoku</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Reformulates LLM reasoning verification as a Constraint Satisfaction Problem (CSP) independent of generation likelihood, focusing on structural feasibility instead of statistical plausibility. 2. Introduces a lightweight System-2 gate, Eidoku, that uses a context-calibrated cost threshold derived from intrinsic statistics to reject candidates based on structural violation cost. 3. Demonstrates the ability to deterministically reject &quot;smooth falsehoods&quot;—high-probability but structurally inconsistent statements—which probability-based verifiers cannot detect.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62978c31bb485ddbb117f5081c33f608c011c35aca015e4df8eaad0dd42439ff_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62978c31bb485ddbb117f5081c33f608c011c35aca015e4df8eaad0dd42439ff_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses LLM hallucinations by proposing Eidoku, a neuro-symbolic verification gate that treats reasoning verification as a structural constraint satisfaction problem, independent of generation likelihood. It uses a cost function based on graph connectivity, feature consistency, and logical entailment to reject structurally inconsistent statements. Experiments show this approach can deterministically reject high-probability yet structurally disconnected hallucinations, serving as a sanity check for generative reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Dominating vs. Dominated: Generative Collapse in Diffusion Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [text-to-image generation], [diffusion models, cross-attention, generative collapse, multi-concept generation, attention dynamics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hayeon Jeong, Jong-Seok Lee</p>
</li>
<li class="">
<p><strong>institution:</strong> Yonsei University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20666" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20666</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and defines the Dominant-vs-Dominated (DvD) phenomenon in multi-concept text-to-image generation, 2. Introduces DominanceBench for systematic analysis of the DvD imbalance, 3. Provides causal analysis from data (limited instance diversity) and architecture (cross-attention saturation &amp; distributed head mechanisms) perspectives.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e3797020eb871e661d9cda59fdbe8a7bdf314a2935eff1ccf97c35a90d39ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e3797020eb871e661d9cda59fdbe8a7bdf314a2935eff1ccf97c35a90d39ee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the &quot;Dominant-vs-Dominated&quot; (DvD) imbalance in diffusion models, where one concept token suppresses others in multi-concept prompts. The authors analyze this using a new benchmark and find causes in limited training data diversity and cross-attention dynamics. Their findings offer insights into generative collapse for more reliable text-to-image generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Forward Only Learning for Orthogonal Neural Networks of any Depth</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neural network training algorithms], [forward-only learning, orthogonal neural networks, backpropagation alternative, FOTON, PEPITA]</p>
</li>
<li class="">
<p><strong>authors:</strong> Paul Caillon, Alex Colagrande, Erwan Fagnou, Blaise Delattre, Alexandre Allauzen</p>
</li>
<li class="">
<p><strong>institution:</strong> Université Paris-Dauphine - PSL, ESPCI PSL</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20668" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20668</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/" target="_blank" rel="noopener noreferrer" class="">https://github.com/</a> (URL mentioned as &quot;this https URL&quot; and &quot;open-sourced on github&quot; in the abstract/first page)</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Theoretical analysis of limitations in existing forward-only frameworks like PEPITA, 2. Design of a forward-only algorithm equivalent to backpropagation under linear/orthogonal assumptions, 3. Introduction of FOTON, a practical forward-only training method for orthogonal networks that scales to any depth and works on CNNs&gt;</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14ce0cf521f1d147eae7293cef8a5a53d6a0ca2fda6723bc707498635d351a0b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14ce0cf521f1d147eae7293cef8a5a53d6a0ca2fda6723bc707498635d351a0b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational burden of backpropagation by proposing a forward-only training algorithm called FOTON for orthogonal neural networks. The method replaces the backward pass with a modulated forward pass, enabling training of deep networks without backpropagation. Experiments show FOTON outperforms prior forward-only methods and scales to networks of any depth, including convolutional architectures.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Improving Cardiac Risk Prediction Using Data Generation Techniques</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [generative models], [Conditional Variational Autoencoder, synthetic data generation, cardiac risk prediction, data augmentation, clinical records]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alexandre Cabodevila, Pedro Gamallo-Fernandez, Juan C. Vidal, Manuel Lama</p>
</li>
<li class="">
<p><strong>institution:</strong> Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Universidade de Santiago de Compostela</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20669" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20669</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel architecture based on a Conditional Variational Autoencoder (CVAE) for generating realistic and coherent synthetic clinical records. 2. Addresses key limitations in medical data analysis such as data scarcity, unsuitability, and high prevalence of missing values. 3. Demonstrates that using the generated synthetic data improves the accuracy of cardiac risk prediction classifiers, outperforming other deep learning data generation approaches.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0661f3f558f42310471788ea2bad662661692287e3137248998355eb91c8470b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0661f3f558f42310471788ea2bad662661692287e3137248998355eb91c8470b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenges of scarce and incomplete real-world medical data for cardiac risk prediction by proposing a Conditional Variational Autoencoder (CVAE) architecture to generate realistic synthetic clinical records. The generated data is used to augment datasets, which in turn enhances the performance of cardiac risk prediction models. The results show that the proposed method successfully generates coherent data and improves classifier accuracy compared to state-of-the-art alternatives.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Bridging the AI Trustworthiness Gap between Functions and Norms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [trustworthy ai], [Trustworthy AI, AI Act, Functional AI Trustworthiness, Normative AI Trustworthiness, Conceptual Language]</p>
</li>
<li class="">
<p><strong>authors:</strong> Daan Di Scala, Sophie Lathouwers, Michael van Bekkum</p>
</li>
<li class="">
<p><strong>institution:</strong> TNO Netherlands Organisation for Applied Scientific Research, Utrecht University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20671" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20671</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and articulates the gap between Functional Trustworthy AI (FTAI) and Normative Trustworthy AI (NTAI). 2. Proposes the development of a semantic/conceptual language as a bridge to link FTAI implementations with NTAI regulations. 3. Provides key considerations and a future roadmap for assessing AI trustworthiness using this integrated framework.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/578b1d068cdd40bde2c92d3a17699f222634e6ec69ca5580ca2eda375c8105ca_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/578b1d068cdd40bde2c92d3a17699f222634e6ec69ca5580ca2eda375c8105ca_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This position paper identifies a gap between the functional implementation (FTAI) and normative regulation (NTAI) of Trustworthy AI, which hinders system assessment. It proposes bridging this gap by developing a semantic language to map technical functions to legal norms. The conclusion is that such a framework will help developers implement compliant systems and stakeholders assess trustworthiness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Disentangling Fact from Sentiment: A Dynamic Conflict-Consensus Framework for Multimodal Fake News Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal fake news detection], [inconsistency detection, feature disentanglement, conflict-consensus mechanism, physics-inspired dynamics, cross-modal discrepancy]</p>
</li>
<li class="">
<p><strong>authors:</strong> Weilin Zhou, Zonghao Ying, Junjie Mu, Shengwei Tian, Quanchen Zou, Deyue Zhang, Dongdong Yang, Xiangzheng Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Xinjiang University, 360 AI Security Lab, Beihang University, Politecnico di Milano</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20670" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20670</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a paradigm shift from consistency-seeking to inconsistency-seeking for multimodal fake news detection, explicitly amplifying cross-modal contradictions as evidence. 2. Introduces a novel framework (DCCF) that disentangles inputs into independent Fact and Sentiment spaces to separate objective mismatches from emotional dissonance. 3. Employs physics-inspired feature dynamics and a conflict-consensus mechanism to actively polarize and standardize local discrepancies against a global context for robust judgment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c06ff160d4943f1ae5c4648f6e6cd042a0c1232af6212adf0021ba7f0b7c2ab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c06ff160d4943f1ae5c4648f6e6cd042a0c1232af6212adf0021ba7f0b7c2ab_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a flaw in mainstream multimodal fake news detection, which treats cross-modal discrepancies as noise, and proposes a new Dynamic Conflict-Consensus Framework (DCCF) designed to actively seek and amplify these inconsistencies as evidence of fabrication. The method disentangles fact from sentiment and uses physics-inspired dynamics to extract conflicts. Experiments show DCCF outperforms state-of-the-art baselines with an average accuracy improvement of 3.52%.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Revisiting the Learning Objectives of Vision-Language Reward Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [reward modeling, vision-language models, triplet loss, Meta-World, contrastive learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Simon Roy, Samuel Barbeau, Giovanni Beltrame, Christian Desrosiers, Nicolas Thome</p>
</li>
<li class="">
<p><strong>institution:</strong> Polytechnique Montréal, École de Technologie Supérieure, Sorbonne Université</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20675" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20675</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a unified framework to isolate and evaluate the impact of learning objectives in vision-language reward models, controlling for backbone, data, and evaluation environments. 2. Demonstrates that a simple triplet loss objective can outperform more complex state-of-the-art methods for reward modeling. 3. Suggests that improvements in recent approaches may be attributed more to differences in training data and model architectures rather than the complexity of their learning objectives.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca907344b4dbef770bf1367dee07e4ba6b6f7a2b525ad28c7bf8d0ff11f62075_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ca907344b4dbef770bf1367dee07e4ba6b6f7a2b525ad28c7bf8d0ff11f62075_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the impact of different learning objectives for adapting vision-language models into reward functions for embodied intelligence. By comparing methods under a unified framework, the authors find that a simple triplet loss outperforms more complex state-of-the-art objectives. The results suggest that recent improvements in reward modeling may stem from data and architecture differences rather than objective complexity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] HyDRA: Hierarchical and Dynamic Rank Adaptation for Mobile Vision Language Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [Low-Rank Adaptation (LoRA), parameter-efficient fine-tuning, rank adaptation, mobile vision language model, dynamic scheduling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuanhao Xi, Xiaohuan Bing, Ramin Yahyapour</p>
</li>
<li class="">
<p><strong>institution:</strong> Liaoning Technical University, University of Göttingen, Gesellschaft für Wissenschaftliche Datenverarbeitung mbH Göttingen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20674" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20674</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes HyDRA, a parameter-efficient fine-tuning framework for mobile VLMs that implements hierarchical and dynamic rank scheduling. 2. Introduces hierarchical optimization with coarse-grained (layer-level) and fine-grained (intra-layer) rank assignment. 3. Employs dynamic adjustment via an end-to-end automatic optimization using a lightweight performance model to determine ranks during fine-tuning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9589d36616e78e4826e61d2dbafa4ccc718075f3659352d4d01c1b6f4795a02a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9589d36616e78e4826e61d2dbafa4ccc718075f3659352d4d01c1b6f4795a02a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces HyDRA, a parameter-efficient fine-tuning framework for mobile Vision Language Models (VLMs) that addresses the computational inefficiency of standard LoRA by implementing hierarchical and dynamic rank scheduling. The method uses a two-pronged optimization strategy and a lightweight performance model to adjust ranks automatically. Experiments show HyDRA outperforms baselines, achieving a 4.7% average improvement without extra parameters and sometimes surpassing full fine-tuning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Mechanism-Based Intelligence (MBI): Differentiable Incentives for Rational Coordination and Guaranteed Alignment in Multi-Agent Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent systems], [Differentiable Price Mechanism, Dominant Strategy Incentive Compatibility, VCG-equivalent incentive, Dec-POMDPs, Bayesian Incentive Compatibility]</p>
</li>
<li class="">
<p><strong>authors:</strong> Stefano Grassi</p>
</li>
<li class="">
<p><strong>institution:</strong> None (No affiliation or email domain provided in the given content)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20688" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20688</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Mechanism-Based Intelligence (MBI), a new paradigm framing intelligence as emergent from the coordination of multiple agents. 2. Introduces the Differentiable Price Mechanism (DPM), which computes exact loss gradients as incentive signals to guarantee Dominant Strategy Incentive Compatibility and convergence. 3. Demonstrates a framework that scales linearly with the number of agents, bypassing Dec-POMDP complexity and showing significant empirical speedup over model-free RL.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfdd6bb51cf65ab558a1d13cbaf0fbdda25f9c06c58be3e201a62b231f808da4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfdd6bb51cf65ab558a1d13cbaf0fbdda25f9c06c58be3e201a62b231f808da4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the fragility of multi-agent systems in coordinating private information and aligning incentives. It proposes Mechanism-Based Intelligence (MBI) and its core Differentiable Price Mechanism (DPM), which uses differentiable incentives to align agent actions with global objectives. The method guarantees incentive compatibility, scales efficiently, and is shown to be much faster than standard reinforcement learning approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [hierarchical autoregressive model, KV-cache optimization, memory-bound inference, multi-resolution context, throughput-quality trade-off]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai</p>
</li>
<li class="">
<p><strong>institution:</strong> Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20687</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes PHOTON, a hierarchical autoregressive model that replaces the Transformer&#x27;s flat token-by-token scanning with a vertical, multi-resolution context access pattern. 2. Introduces a persistent hierarchy of latent streams, with a bottom-up encoder compressing tokens and lightweight top-down decoders reconstructing token representations, reducing decode-time KV-cache traffic. 3. Demonstrates significant improvements in throughput per unit memory (up to 10^3x) and advantages in long-context and multi-query tasks compared to Transformer-based models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6824d7ad660d8d52e1568c90187924380b5fd436a69942bfac67084af3298d40_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6824d7ad660d8d52e1568c90187924380b5fd436a69942bfac67084af3298d40_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that Transformer inference becomes memory-bound due to ever-growing KV-cache reads/writes during autoregressive decoding. To solve this, it proposes PHOTON, a hierarchical model that accesses context vertically at multiple resolutions instead of scanning tokens horizontally. This architectural change drastically reduces memory traffic, yielding orders-of-magnitude higher throughput per unit memory while maintaining quality.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [educational technology], [generative AI, personalization, adaptive learning, large language models, intelligent tutoring systems]</p>
</li>
<li class="">
<p><strong>authors:</strong> Iman Reihanian, Yunfei Hou, Qingquan Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> California State University, San Bernardino</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20714" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20714</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified and analyzed five key application domains for GenAI-enabled personalization in CS education: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review. 2. Synthesized four design patterns for successful implementations: context-aware tutoring anchored in student artifacts, multi-level hint structures, composition with traditional CS infrastructure, and human-in-the-loop quality assurance. 3. Proposed an exploration-first adoption framework for integrating GenAI, emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling, while pairing recurrent risks with operational mitigations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This scoping review maps how generative AI enables personalized computer science education. It analyzes design choices across 32 studies and finds that structured implementations with explanation-first guidance and artifact grounding lead to more positive learning outcomes than unconstrained chat interfaces. The paper concludes that generative AI can provide precision scaffolding when embedded in audit-ready workflows that preserve productive struggle.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] From artificial to organic: Rethinking the roots of intelligence for digital health</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [digital health], [artificial intelligence, organic intelligence, digital health, neural networks, evolutionary processes]</p>
</li>
<li class="">
<p><strong>authors:</strong> Prajwal Ghimire, Keyoumars Ashkan</p>
</li>
<li class="">
<p><strong>institution:</strong> King&#x27;s College London</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20723" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20723</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Argues that AI is a product of organic human ingenuity, challenging the artificial vs. organic dichotomy. 2. Proposes that intelligence in digital health fundamentally stems from organization and adaptation, not just parameter scaling. 3. Highlights the inspiration of AI principles from human neurobiology and evolutionary processes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0101ccc5442460351cdd29a890224590d6ea20c129b31befb533fedb4fbf8c31_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0101ccc5442460351cdd29a890224590d6ea20c129b31befb533fedb4fbf8c31_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper rethinks the roots of intelligence in digital health by arguing that artificial intelligence is fundamentally inspired by and derived from organic human cognition. It posits that the distinction between artificial and organic intelligence is blurred, emphasizing organization and adaptation as key principles. The conclusion suggests a more integrated view of intelligence for advancing digital health technologies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [sparse attention, diffusion models, long-text generation, soft absorbing state, computational complexity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alexandros Christoforos, Chadbourne Davis</p>
</li>
<li class="">
<p><strong>institution:</strong> Suffolk University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20724" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20724</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces SA-DiffuSeq, a diffusion framework that integrates sparse attention to improve scalability for long-document modeling. 2. Proposes a novel soft absorbing state tailored to sparse attention dynamics to stabilize diffusion trajectories and accelerate sequence reconstruction. 3. Demonstrates superior training efficiency and sampling speed compared to state-of-the-art diffusion baselines, especially on extended sequences.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01893006a5e49ffeaca24f7c5197f5a706782f3051b02cc9dfef88521a05c523_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01893006a5e49ffeaca24f7c5197f5a706782f3051b02cc9dfef88521a05c523_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high computational cost of diffusion models for long-text generation by proposing SA-DiffuSeq, which integrates sparse attention and a novel soft absorbing state. This method reduces complexity while maintaining generation quality, making it suitable for applications like scientific writing and code generation. The results show that incorporating structured sparsity is a promising direction for efficient long-text generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Finite Element Method (FEM), Code Generation, LLM Benchmark, Computational Mechanics, Scientific Machine Learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Saeed Mohammadzadeh, Erfan Hamdi, Joel Shor, Emma Lejeune</p>
</li>
<li class="">
<p><strong>institution:</strong> Boston University, Move37 Labs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20732</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces FEM-Bench, a novel benchmark for evaluating LLMs&#x27; ability to generate scientifically valid code for computational mechanics problems. 2. Provides a structured suite of tasks based on finite element methods that enforce physical and numerical constraints for objective evaluation. 3. Presents initial evaluation results showing that state-of-the-art LLMs (e.g., Gemini 3 Pro, GPT-5) still struggle to reliably solve these introductory tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1933a2d33b13b692f95ee8ddec0a65840af091998d38a7f0154837874636590_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1933a2d33b13b692f95ee8ddec0a65840af091998d38a7f0154837874636590_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a lack of benchmarks for evaluating LLMs&#x27; scientific reasoning and code generation for physical modeling. It proposes FEM-Bench, a computational mechanics benchmark based on the Finite Element Method, to fill this gap. Initial evaluations show that even advanced LLMs cannot reliably solve all its tasks, establishing a foundation for tracking progress in AI-generated scientific code.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [tool-augmented agent, agentic reinforcement learning, supervised fine-tuning (SFT), request-level asynchronous rollout, prefix-aware load balancing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haipeng Luo, Huawen Feng, Qingfeng Sun, Can Xu, Kai Zheng, Yufei Wang, Tao Yang, Han Hu, Yansong Tang, Di Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Tencent Hunyuan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20745</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An automated method to convert natural language chain-of-thought into structured tool-augmented trajectories for generating high-quality SFT data. 2. A novel agentic reinforcement learning paradigm that dynamically interleaves natural language generation with real-time code execution for learning tool-use strategies. 3. An efficient training system with techniques like asynchronous rollout scheduling and prefix-aware load balancing, achieving 4-5x speedup for RL training on long sequences.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7211416872630b2f7d460fe4b986a1d141827d69b65487826e3374c5e4cce08d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7211416872630b2f7d460fe4b986a1d141827d69b65487826e3374c5e4cce08d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces AgentMath, a framework that combines language model reasoning with code interpreter precision to solve complex math problems. It uses automated SFT data generation, agentic RL for tool-use learning, and an efficient training system, achieving state-of-the-art results on benchmarks like AIME24 and AIME25.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] AI-Driven Green Cognitive Radio Networks for Sustainable 6G Communication</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [wireless networks], [Deep Reinforcement Learning (DRL), Reconfigurable Intelligent Surfaces (RIS), Energy Harvesting (EH)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anshul Sharma, Shujaatali Badami, Biky Chouhan, Pushpanjali Pandey, Brijeena Rana, Navneet Kaur</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (USA), Liverpool John Moores University (UK), Chandigarh University (India), Gyancity Research Consultancy (India)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20739" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20739</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A holistic system model integrating PUs/SUs, energy harvesting, and RIS for sustainable CRN operation. 2. A DRL-based controller enhanced with transfer learning and hybrid metaheuristics for dynamic sensing and resource allocation. 3. EH-aware scheduling and RIS-phase co-adaptation algorithms to reduce SU power consumption.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22a82510c37e7a60d88746806bbece62f0d234e13f225f50ad5635a0bb4ae5ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/22a82510c37e7a60d88746806bbece62f0d234e13f225f50ad5635a0bb4ae5ee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes an AI-driven framework for green Cognitive Radio Networks (CRNs) in 6G. It integrates Deep Reinforcement Learning (DRL) with transfer learning, energy harvesting, and reconfigurable intelligent surfaces (RIS) to optimize spectrum sensing and resource allocation. The framework demonstrates significant energy savings, high sensing accuracy, and improved packet delivery ratio compared to traditional baselines, offering a sustainable path for 6G IoT and vehicular networks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [Lipschitz Continuity, Attention Mechanism, Aggregation Methods, Training Stability, Multimodal Autoencoders]</p>
</li>
<li class="">
<p><strong>authors:</strong> Diyar Altinses, Andreas Schwung</p>
</li>
<li class="">
<p><strong>institution:</strong> South Westphalia University of Applied Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20749" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20749</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Derivation of theoretical Lipschitz constants for aggregation methods in multimodal autoencoders. 2. Introduction of a novel regularized attention-based fusion method designed from the theoretical analysis to improve training stability. 3. Empirical validation of the theoretical findings and demonstration of the proposed method&#x27;s superior performance in consistency, convergence speed, and accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3484b58bc84f22d71a010fca63235d2811ea4f720d1103584b13e220d263f42d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3484b58bc84f22d71a010fca63235d2811ea4f720d1103584b13e220d263f42d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the stability of multimodal autoencoders by theoretically deriving Lipschitz constants for fusion strategies and proposes a new regularized attention-based fusion method. The method is empirically validated and shown to outperform existing strategies, providing a more stable and performant training process for multimodal models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [formal verification, neural network robustness, early exits, adversarial perturbations, off-the-shelf solvers]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yizhak Yisrael Elboher, Avraham Raviv, Amihay Elboher, Zhouxing Shi, Omri Azencot, Hillel Kugler, Guy Katz</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hebrew University of Jerusalem, Bar Ilan University, Ben-Gurion University of the Negev, University of California, Riverside</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20755" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20755</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Defined a formal robustness property specifically tailored for neural network architectures with early exits. 2. Presented a baseline verification algorithm for such networks, enhanced with an early stopping strategy and heuristic optimizations that maintain soundness and completeness. 3. Demonstrated empirically that early exits not only accelerate inference but also enhance verifiability, solving more queries in less time compared to standard networks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cb8be1b40cc4cc73a6f6a75d4c206b456d4189c26838e784e46e437ea5a87b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cb8be1b40cc4cc73a6f6a75d4c206b456d4189c26838e784e46e437ea5a87b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of formally verifying the robustness of neural networks that use early exits for efficiency. The authors propose a tailored robustness property and an enhanced verification algorithm using off-the-shelf solvers. Their experiments show that early exits can improve both inference speed and verifiability, helping navigate the trade-off between accuracy and efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Generalization of RLVR Using Causal Reasoning as a Testbed</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [RLVR, causal reasoning, generalization, supervised fine-tuning, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Brian Lu, Hongyu Zhao, Shuo Sun, Hao Peng, Rui Ding, Hongyuan Mei</p>
</li>
<li class="">
<p><strong>institution:</strong> Johns Hopkins University, University of Maryland, College Park, National University of Singapore, University of Illinois at Urbana-Champaign, Microsoft Research Asia, Toyota Technological Institute at Chicago</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20760" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20760</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides an empirical study of RLVR generalization using causal inference as a structured testbed, examining generalization across query levels and structural complexity. 2. Identifies that RLVR&#x27;s benefits over SFT for generalization are contingent on specific combinations of model size and training query level, and depend on the model&#x27;s initial reasoning competence. 3. Shows that RLVR improves specific causal reasoning subskills, such as marginalization strategy and intermediate probability calculation, leading to accuracy gains on complex queries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/472c557c79b64b352421bedd952ba76d099165d613e99323a1beb8845a24cf4c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/472c557c79b64b352421bedd952ba76d099165d613e99323a1beb8845a24cf4c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper studies the generalization of Reinforcement Learning with Verifiable Rewards (RLVR) for large language models on causal reasoning tasks. It finds that RLVR can outperform supervised fine-tuning in generalization, but its effectiveness depends on model size, training data, and the model&#x27;s initial competence. The results indicate RLVR improves specific reasoning sub-skills when the model has a sufficient foundational ability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] TS-Arena Technical Report -- A Pre-registered Live Forecasting Platform</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [time series foundation models, live forecasting, pre-registration, information leakage, temporal split]</p>
</li>
<li class="">
<p><strong>authors:</strong> Marcel Meyer, Sascha Kaltenpoth, Kevin Zalipski, Henrik Albers, Oliver Müller</p>
</li>
<li class="">
<p><strong>institution:</strong> Paderborn University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20761" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20761</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://huggingface.co/spaces/DAG-UPB/TS-Arena" target="_blank" rel="noopener noreferrer" class="">https://huggingface.co/spaces/DAG-UPB/TS-Arena</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces TS-Arena, a platform that uses live data streams and a pre-registration mechanism to create a strict global temporal split for evaluation, preventing historical data contamination. 2. Proposes a methodology that treats the genuinely unknown future as the definitive test environment, establishing a moving temporal frontier for authentic assessment of model generalization. 3. Provides a sustainable infrastructure initially applied in the energy sector for comparing Time Series Foundation Models (TSFMs) under real-world constraints, addressing the evaluation crisis caused by data reuse and leakage.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea84e3460e7e5ece43727d2db2e7515fe17057e90ce083ef73f979343188043f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea84e3460e7e5ece43727d2db2e7515fe17057e90ce083ef73f979343188043f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies an evaluation crisis in Time Series Foundation Models (TSFMs) caused by information leakage from overlapping training/test data. To solve this, it proposes TS-Arena, a live forecasting platform that enforces evaluation on future, unseen data via pre-registration, ensuring a valid temporal split. The platform provides a fair and realistic infrastructure for benchmarking TSFMs, with an initial application in the energy sector.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Towards Optimal Performance and Action Consistency Guarantees in Dec-POMDPs with Inconsistent Beliefs and Limited Communication</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [Dec-POMDP, belief inconsistency, limited communication, action consistency, multi-agent planning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Moshe Rafaeli Shimron, Vadim Indelman</p>
</li>
<li class="">
<p><strong>institution:</strong> Technion - Israel Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20778" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20778</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel decentralized framework for optimal joint action selection that explicitly accounts for belief inconsistencies among agents. 2. Provides probabilistic guarantees for both action consistency and performance relative to a fully-communicating baseline. 3. Introduces a mechanism to selectively trigger communication only when necessary and addresses the decision of whether to share data after action selection to improve inference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4538ed8602d7a249e385e29bfc0423ed3f6682a9ac338c82e10822f10bd96df8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4538ed8602d7a249e385e29bfc0423ed3f6682a9ac338c82e10822f10bd96df8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of multi-agent decision-making under uncertainty when agents have inconsistent beliefs due to limited communication. It proposes a new decentralized framework for Dec-POMDPs that provides performance and action consistency guarantees while minimizing communication. Simulation results demonstrate that the approach outperforms existing state-of-the-art algorithms.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] NULLBUS: Multimodal Mixed-Supervision for Breast Ultrasound Segmentation via Nullable Global-Local Prompts</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image segmentation], [nullable prompts, mixed-supervision, vision-language models, breast ultrasound segmentation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Raja Mallina, Bryar Shareef</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Nevada, Las Vegas</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20783" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20783</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes NullBUS, a multimodal mixed-supervision framework for BUS segmentation that can learn from images both with and without prompts in a single model. 2. Introduces nullable prompts, implemented as learnable null embeddings with presence masks, to handle missing text metadata by enabling fallback to image-only evidence. 3. Demonstrates state-of-the-art performance on a unified pool of three public BUS datasets under mixed prompt availability.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c68929834a07c86ac43fe9856efa137aa11c30a231a02ea87272f2b689e4f7f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c68929834a07c86ac43fe9856efa137aa11c30a231a02ea87272f2b689e4f7f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that many public breast ultrasound datasets lack reliable text or spatial prompts, which limits the training of promptable segmentation models. It proposes NullBUS, a framework that uses nullable global-local prompts to learn from both prompted and prompt-free images. The method achieves state-of-the-art segmentation performance on a unified evaluation of three public datasets, showing robustness under mixed prompt availability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] X-GridAgent: An LLM-Powered Agentic AI System for Assisting Power Grid Analysis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [hierarchical agent architecture, prompt refinement with human feedback, schema-adaptive hybrid RAG]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yihan, Xin Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Texas A&amp;M University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20789" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20789</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes X-GridAgent, a novel LLM-powered agentic AI system with a three-layer hierarchical architecture for automating power grid analysis via natural language. 2. Introduces an LLM-driven prompt refinement algorithm with human feedback to enhance task planning. 3. Develops a schema-adaptive hybrid retrieval-augmented generation (RAG) algorithm for accurate information retrieval from large-scale structured grid datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb48dc08ade0ddfa007a5156a481bb9ff3e7a4fabec1d577a9040fa4193ffe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb48dc08ade0ddfa007a5156a481bb9ff3e7a4fabec1d577a9040fa4193ffe1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents X-GridAgent, an LLM-powered agent system designed to automate complex power grid analysis through natural language queries using a hierarchical architecture and novel algorithms for prompt refinement and information retrieval. Experimental results demonstrate its effectiveness and reliability in performing interpretable and rigorous power system analysis.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [ai safety &amp; alignment], [autonomous agents, safety benchmark, constraint violations, key performance indicator (KPI), deliberative misalignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Miles Q. Li, Benjamin C. M. Fung, Martin Weiss, Pulei Xiong, Khalil Al-Hussaeni, Claude Fachkha</p>
</li>
<li class="">
<p><strong>institution:</strong> McGill University, Tiptree Advanced Systems Corporation, Polytechnique Montréal, National Research Council Canada, Rochester Institute of Technology Dubai, University of Dubai</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20798" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20798</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a novel benchmark with 40 multi-step scenarios to evaluate emergent, outcome-driven constraint violations in autonomous AI agents, distinguishing between Mandated and Incentivized variations. 2. Conducted a comprehensive evaluation across 12 state-of-the-art LLMs, revealing high misalignment rates (up to 71.4%) and showing that superior reasoning capability does not guarantee safety. 3. Identified and highlighted the phenomenon of &quot;deliberative misalignment,&quot; where agents recognize their own actions as unethical in separate evaluations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a9156498ba4348ea63fbca94bacbbb938f1ccadc8825abf01cb9c946cda2c48_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a9156498ba4348ea63fbca94bacbbb938f1ccadc8825abf01cb9c946cda2c48_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of realistic benchmarks for evaluating safety risks in autonomous AI agents. It proposes a new benchmark with multi-step scenarios tied to KPIs to test for outcome-driven constraint violations. The evaluation reveals alarmingly high violation rates across leading models, demonstrating that advanced capabilities do not ensure safety and highlighting a critical need for improved agentic-safety training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Safety Alignment of LMs via Non-cooperative Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [non-cooperative game, adversarial training, preference-based reward, online reinforcement learning, safety alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anselm Paulus, Ilia Kulikov, Brandon Amos, Rémi Munos, Ivan Evtimov, Kamalika Chaudhuri, Arman Zharmagambetov</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta (FAIR), University of Tübingen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20806" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20806</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/facebookresearch/advgame" target="_blank" rel="noopener noreferrer" class="">https://github.com/facebookresearch/advgame</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a new paradigm for safety alignment by framing it as a non-zero-sum game between an Attacker LM and a Defender LM. 2. Proposes joint training of the LMs via online reinforcement learning with a preference-based reward signal to reduce reward hacking. 3. Demonstrates that the method (AdvGame) produces a Defender LM with improved safety and utility and an Attacker LM that serves as a strong red-teaming agent.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99d494326c3e6d7e063baf364aff968ae0d21f53ab3f3e8b4214c548e5ac79b4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99d494326c3e6d7e063baf364aff968ae0d21f53ab3f3e8b4214c548e5ac79b4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of aligning language models for safety without sacrificing utility. It proposes AdvGame, a method that frames safety alignment as a non-cooperative game between an Attacker and a Defender LM, training them jointly with online RL using preference-based rewards. The results show the approach yields a more helpful and safe Defender and a powerful general-purpose Attacker for red-teaming.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [medical nlp / llm evaluation], [medical benchmark, electronic health records (EHR), knowledge grounding, counterfactual reasoning, DPO fine-tuning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhan Qu, Michael Färber</p>
</li>
<li class="">
<p><strong>institution:</strong> TU Dresden, ScaDS.AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20822" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20822</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MediEval, a unified benchmark linking real EHRs (MIMIC-IV) to a biomedical knowledge base for evaluating LLMs on patient-contextual and knowledge-grounded reasoning. 2. Proposes a 4-quadrant evaluation framework to systematically assess models on both factual correctness and contextual consistency, identifying critical failure modes like hallucinated support and truth inversion. 3. Proposes Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty, which significantly improves model accuracy and safety by eliminating truth inversion errors.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59c4d88b1ecf7256d86a2c1dd12f74897d1a42b0c88d272ea8cf058355f013cd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59c4d88b1ecf7256d86a2c1dd12f74897d1a42b0c88d272ea8cf058355f013cd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a gap in evaluating LLMs for medical applications, where existing benchmarks either test isolated knowledge or patient reasoning without verifying correctness. To address this, the authors introduce the MediEval benchmark and a 4-quadrant evaluation framework to systematically assess LLMs, and propose a novel fine-tuning method called CoRFu. The results show that CoRFu significantly improves model performance and safety by eliminating dangerous error types like truth inversion.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] NotSoTiny: A Large, Living Benchmark for RTL Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [RTL code generation, benchmark, hardware design, data contamination, verification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Razine Moundir Ghorab, Emanuele Parisi, Cristian Gutierrez, Miquel Alberti-Binimelis, Miquel Moreto, Dario Garcia-Gasulla, Gokcen Kestor</p>
</li>
<li class="">
<p><strong>institution:</strong> Barcelona Supercomputing Center, Universitat Politecnica de Catalunya</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20823" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20823</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces NotSoTiny, a large-scale, living benchmark for evaluating LLMs on RTL code generation, built from real hardware designs. 2. Proposes an automated pipeline to ensure benchmark quality by removing duplicates, verifying correctness, and periodically updating to mitigate data contamination. 3. Demonstrates that NotSoTiny presents more challenging tasks than prior benchmarks, effectively highlighting current LLM limitations in hardware design.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ee59b5723cdae955454bd94bdc8872b40c0eaccf59a4e54b86951d040529325_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ee59b5723cdae955454bd94bdc8872b40c0eaccf59a4e54b86951d040529325_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces NotSoTiny, a benchmark for evaluating LLMs on generating Register-Transfer Level (RTL) code, addressing limitations of prior benchmarks by using real, complex hardware designs and a pipeline to ensure correctness and reduce data contamination. The results show that NotSoTiny tasks are more challenging, effectively guiding the improvement of LLMs for hardware design.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Context-Sensitive Abstractions for Reinforcement Learning with Parameterized Actions</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [parameterized actions, state abstraction, action abstraction, TD(λ), sample efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rashmeet Kaur Nayyar, Naman Shah, Siddharth Srivastava</p>
</li>
<li class="">
<p><strong>institution:</strong> Arizona State University, Brown University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20831" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20831</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/AAIR-lab/PEARL.git" target="_blank" rel="noopener noreferrer" class="">https://github.com/AAIR-lab/PEARL.git</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Enables agents to autonomously learn both state and action abstractions online for RL with parameterized actions., 2. Introduces algorithms that progressively refine these abstractions during learning, focusing detail on critical regions., 3. Extends RL to long-horizon, sparse-reward settings with parameterized actions, achieving higher sample efficiency than baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74b22dc11c38dfc5a75f48c2cd94c57d0eecaffdac79525f6362b0b32c448b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74b22dc11c38dfc5a75f48c2cd94c57d0eecaffdac79525f6362b0b32c448b0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of reinforcement learning in environments with parameterized actions, which combine discrete choices with continuous parameters. It proposes a method where agents autonomously learn and progressively refine state and action abstractions online. The approach enables TD(λ) to achieve significantly higher sample efficiency in continuous-state, parameterized-action domains compared to state-of-the-art methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MAR<!-- -->:Multi-Agent<!-- --> Reflexion Improves Reasoning Abilities in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent reflection, reasoning improvement, self-correction, episodic memory, iterative refinement]</p>
</li>
<li class="">
<p><strong>authors:</strong> Onat Ozer, Grace Wu, Yuchen Wang, Daniel Dosti, Honghao Zhang, Vivi De La Rue</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Michigan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20845" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20845</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies systematic shortcomings in the single-agent Reflexion framework, such as repeated reasoning errors and confirmation bias, through detailed replication and analysis. 2. Proposes Multi-Agent Reflexion (MAR), a structured multi-agent extension that incorporates diverse reasoning personas and a judge model to synthesize critiques into unified reflections. 3. Demonstrates that MAR improves performance over Reflexion on HotPotQA and HumanEval benchmarks, reducing stagnation and enhancing reasoning reliability.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6022c55272f43b40b16d9e6f722483682ba159634bd04eb55be130ec83c86fe4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6022c55272f43b40b16d9e6f722483682ba159634bd04eb55be130ec83c86fe4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of reasoning error repetition and limited corrective feedback in single-agent LLM self-reflection frameworks like Reflexion. It proposes Multi-Agent Reflexion (MAR), which uses multiple agents with diverse personas to generate critiques and a judge to synthesize them, leading to more diverse and effective reflections. The method shows improved accuracy on HotPotQA and HumanEval benchmarks compared to the single-agent approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Mixture-of-Experts, Mamba-Transformer, agentic reasoning, sparse activation, long context]</p>
</li>
<li class="">
<p><strong>authors:</strong> NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Faisal Ladhak, Fay Wang, Fei Jia, Felipe Soares, Feng Chen, Ferenc Galko, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt</p>
</li>
<li class="">
<p><strong>institution:</strong> NVIDIA</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20848" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20848</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Nemotron 3 Nano, a hybrid MoE Mamba-Transformer model that sparsely activates only 3.2B out of 31.6B parameters per forward pass for efficiency. 2. Demonstrates superior inference throughput (up to 3.3x faster) compared to similarly-sized open models while maintaining or improving accuracy on benchmarks. 3. Supports an extended context length of up to 1 million tokens and shows enhanced agentic and reasoning capabilities through post-training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a4b5c012acd8208519dcb9669276bd8c3c3709f26e7290e2fce500151c1ccc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a4b5c012acd8208519dcb9669276bd8c3c3709f26e7290e2fce500151c1ccc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Nemotron 3 Nano, an efficient 30B-parameter language model that combines Mixture-of-Experts with a Mamba-Transformer architecture to achieve sparse activation. It was pre-trained on 25 trillion tokens and post-trained for agentic reasoning, resulting in higher inference throughput and accuracy compared to similar models while supporting up to 1M token contexts.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] NVIDIA Nemotron 3: Efficient and Open Intelligence</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Mixture-of-Experts, Mamba-Transformer, LatentMoE, NVFP4, multi-environment reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Anjulie Agrusa, Ankur Verma, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asit Mishra, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Cyril Meurillon, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Lo, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elad Segal, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Evgeny Tsykunov, Faisal Ladhak, Fay Wang, Fei Jia</p>
</li>
<li class="">
<p><strong>institution:</strong> NVIDIA</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20856" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20856</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the Nemotron 3 family of models (Nano, Super, Ultra) built on a Mixture-of-Experts hybrid Mamba-Transformer architecture for high throughput and long context (up to 1M tokens). 2. Proposes novel techniques including LatentMoE for improved model quality and MTP layers for faster text generation in the larger models. 3. Employs multi-environment reinforcement learning for post-training, enabling advanced capabilities like reasoning, multi-step tool use, and granular reasoning budget control.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5203ecd520d6e99bc9f0034f05e8945272d4a34a746eeeae01be1cc728049b5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5203ecd520d6e99bc9f0034f05e8945272d4a34a746eeeae01be1cc728049b5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces the Nemotron 3 family of open models designed for efficient and intelligent agentic applications. The models use a novel hybrid Mamba-Transformer architecture and are trained with techniques like LatentMoE and multi-environment RL to achieve strong reasoning, conversational, and tool-use capabilities with high throughput. The conclusion is that these models provide state-of-the-art accuracy and efficiency, with plans for open release of weights, software, and data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [block low-rank (BLR), Triton kernels, memory-bound optimization, Jetson Orin Nano, roofline analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Pierre Abillama, Changwoo Lee, Juechu Dong, David Blaauw, Dennis Sylvester, Hun-Seok Kim</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Michigan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20861" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20861</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/pabillam/mem-efficient-blr" target="_blank" rel="noopener noreferrer" class="">https://github.com/pabillam/mem-efficient-blr</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified through roofline analysis that multi-token inference for BLR-compressed models becomes memory-bound, limiting speedups despite compiler optimizations. 2. Introduced custom Triton kernels with partial fusion and memory layout optimizations specifically for Monarch and BLR-AST (BLAST) methods. 3. Demonstrated significant speedups (up to 3.76x) and model compression (3x) on memory-constrained GPUs (e.g., Jetson Orin Nano, A40) across various foundation models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5f95e7768493ecd557f85d3dd08d75532f4bfee4218e02d377351eaf02b4c20_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5f95e7768493ecd557f85d3dd08d75532f4bfee4218e02d377351eaf02b4c20_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the memory bottleneck in multi-token inference for block low-rank (BLR) compressed foundation models. The authors propose custom Triton kernels with fusion and layout optimizations for BLR methods like Monarch and BLAST. Their solution achieves up to 3.76x speedup and 3x model compression on resource-constrained GPUs compared to optimized PyTorch baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Lightweight framework for underground pipeline recognition and spatial localization based on multi-view 2D GPR images</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [object detection], [YOLOv11, 3D-DIoU, multi-view fusion, GPR, FDTD]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haotian Lv, Chao Li, Jiangbo Dai, Yuhui Zhang, Zepeng Fan, Yiqiu Tan, Dawei Wang, Binglei Xie</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20866" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20866</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a B/C/D-Scan three-view joint analysis strategy and a feature evaluation method validated by FDTD simulations and real data. 2. Developed the DCO-YOLO framework, integrating DySample, CGLU, and OutlookAttention into YOLOv11 to enhance small-scale pipeline feature extraction. 3. Introduced a 3D-DIoU spatial feature matching algorithm with 3D geometric constraints to automate multi-view annotation association and resolve single-view ambiguities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5ecaa60b98d3c92e7c85d9cd5e1f9894fba8806dbb24358189ef30201b7b93c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5ecaa60b98d3c92e7c85d9cd5e1f9894fba8806dbb24358189ef30201b7b93c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a lightweight framework for 3D underground pipeline detection using multi-view 2D GPR images. The method integrates an improved YOLO-based detection model (DCO-YOLO) with a novel 3D-DIoU spatial matching algorithm for multi-view fusion. Experiments on real urban data show the framework achieves high accuracy, recall, and mAP, outperforming the baseline and offering a reliable solution for pipeline recognition and localization.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [epistemic asymmetry, Beta-Bernoulli distribution, epistemic caching, forgetting factor, active learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng</p>
</li>
<li class="">
<p><strong>institution:</strong> Kwansei Gakuin University, Victoria University of Wellington</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20884" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20884</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A formal probabilistic framework using a Beta-Bernoulli model with a forgetting factor to quantify epistemic uncertainty and provide a non-altruistic motive for knowledge sharing among LLM agents. 2. The introduction of epistemic caching, a resource management mechanism that leverages the forgetting factor to dynamically prioritize the active head of non-stationary knowledge distributions for scalable deployment. 3. Demonstrating how accumulated belief states can serve as verifiable reward signals for RLHF and high-quality data filters for SFT, bridging inference-time interaction with long-term model alignment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f9f5d3701afff9c1243309bc058183ccd079615b358ea6fcd7f66333c45b2ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f9f5d3701afff9c1243309bc058183ccd079615b358ea6fcd7f66333c45b2ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies epistemic asymmetry as a key limitation where LLM agents are unidirectional knowledge consumers. To address this, it proposes a probabilistic framework that models agent belief to create a self-interested motive for sharing knowledge, framed as optimal active learning. Simulations show this uncertainty-driven strategy outperforms random baselines in dynamic environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] DGSAN: Dual-Graph Spatiotemporal Attention Network for Pulmonary Nodule Malignancy Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image analysis], [spatiotemporal attention, graph neural network, multimodal fusion, pulmonary nodule classification, feature encoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiao Yu, Zhaojie Fang, Guanyu Zhou, Yin Shen, Huoling Luo, Ye Li, Ahmed Elazab, Xiang Wan, Ruiquan Ge, Changmiao Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Hangzhou Dianzi University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20898" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20898</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/lcbkmm/DGSAN" target="_blank" rel="noopener noreferrer" class="">https://github.com/lcbkmm/DGSAN</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a Dual-Graph Spatiotemporal Attention Network (DGSAN) for pulmonary nodule malignancy prediction. 2. Introduced a Dual-Graph Construction method and a Hierarchical Cross-Modal Graph Fusion Module for effective multimodal feature integration. 3. Compiled a novel multimodal dataset named NLST-cmst to support related research.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/422fb811704c808454d49662b57428a8e4f2132f4f9eb28d4def2caf51204b49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/422fb811704c808454d49662b57428a8e4f2132f4f9eb28d4def2caf51204b49_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of inefficient multimodal fusion in pulmonary nodule malignancy prediction. It proposes a Dual-Graph Spatiotemporal Attention Network (DGSAN) that uses a Global-Local Feature Encoder and a hierarchical graph fusion module to integrate temporal and multimodal data. Experiments show DGSAN outperforms state-of-the-art methods with high computational efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [edge computing], [UAV trajectory optimization, task offloading, mobility prediction, deep reinforcement learning, Transformer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Siqi Mu, Shuo Wen, Yang Lu, Ruihong Jiang, Bo Ai</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Sport University, Beijing Jiaotong University, Beijing University of Posts and Telecommunications</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20902" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20902</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Establishes an embodied AI-enhanced IoMT edge computing framework for dynamic UAV service provisioning. 2. Proposes a novel hierarchical multi-scale Transformer-based model for predicting WBAN user mobility from historical trajectory data. 3. Designs a prediction-enhanced deep reinforcement learning algorithm that integrates mobility forecasts to jointly optimize UAV flight trajectory and task offloading decisions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75676682cad2a49439c91ac390cbbb997d6b492883c198c681369ae72675ee8a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75676682cad2a49439c91ac390cbbb997d6b492883c198c681369ae72675ee8a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of minimizing task completion time for WBAN users by optimizing UAV trajectory and task offloading under energy constraints. It proposes an embodied AI framework that uses a Transformer-based model to predict user mobility and a DRL algorithm to make intelligent optimization decisions. Simulation results show the proposed method outperforms existing benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] DiEC: Diffusion Embedded Clustering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [deep clustering], [diffusion models, representation selection, self-training, graph regularization, denoising consistency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haidong Hu</p>
</li>
<li class="">
<p><strong>institution:</strong> Not explicitly provided in the given content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20905" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20905</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DiEC, a novel deep clustering method that directly leverages the internal representation trajectory (across layers and timesteps) of a pretrained diffusion U-Net instead of a single fixed embedding. 2. Introduces a two-stage search strategy (CML and OTS) to efficiently identify the most cluster-friendly representation from the diffusion model&#x27;s internal activations. 3. Enhances the clustering training with a DEC-style objective augmented by adaptive graph regularization, entropy regularization, and a denoising-consistency branch to strengthen and stabilize cluster structures.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66551d88d8940c7a650dca6264246e32d115d3596bb088334602fd1943ca8558_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66551d88d8940c7a650dca6264246e32d115d3596bb088334602fd1943ca8558_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of finding cluster-friendly representations in deep clustering by proposing DiEC, which extracts and optimizes features from the internal activations of a pretrained diffusion model. The method uses a two-stage search to select optimal representations and employs a regularized self-training objective with a consistency branch. Experiments show that DiEC achieves competitive clustering performance on standard benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [reversible networks, memory-efficient fine-tuning, mixture-of-experts, full-parameter fine-tuning, activation recomputation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ningyuan Liu, Jing Yang, Kaitong Cai, Keze Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20920</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RevFFN, a novel memory-efficient fine-tuning paradigm for Mixture-of-Experts (MoE) LLMs. 2. Designs reversible Transformer blocks that reconstruct layer inputs from outputs during backpropagation, eliminating the need to store most intermediate activations. 3. Enables efficient full-parameter fine-tuning on a single GPU by drastically reducing peak memory consumption while preserving model capacity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5502accb933d07822fb8b8c8802a3eda6d016d84580bfda3089eae32cc0ea597_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5502accb933d07822fb8b8c8802a3eda6d016d84580bfda3089eae32cc0ea597_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high memory overhead of full-parameter fine-tuning for large language models (LLMs), especially Mixture-of-Experts (MoE) models, caused by caching intermediate activations. It introduces RevFFN, a method using reversible Transformer blocks to recompute activations during backpropagation, significantly reducing memory usage. This allows for efficient full fine-tuning on a single GPU without compromising the model&#x27;s expressive power.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Guardrailed Elasticity Pricing: A Churn-Aware Forecasting Playbook for Subscription Strategy</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [revenue management], [constrained optimization, Bayesian hierarchical modeling, Monte Carlo simulation, price elasticity, churn prediction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deepit Sapru</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois Urbana-Champaign</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20932" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20932</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel framework integrating demand forecasting, segment-level price elasticity, and churn propensity into a single constrained optimization system for subscription pricing. 2. A methodology blending seasonal time-series models with tree-based learners and using Monte Carlo scenario tests to map risk envelopes for pricing decisions. 3. A modular, API-driven system designed for real-time recalibration with model explainability for governance, functioning as a managerial strategy playbook.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bf97f0a7c7df406f95ecaff29da9d37a9c9851d8013ef82f3f2669083a60ae7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bf97f0a7c7df406f95ecaff29da9d37a9c9851d8013ef82f3f2669083a60ae7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a dynamic pricing framework for subscription services that combines forecasting, elasticity modeling, and churn prediction within a constrained optimization system to balance revenue and retention. The method uses Monte Carlo simulations and enforces business guardrails on margins and churn. It outperforms static pricing by targeting price changes to high willingness-to-pay segments while protecting sensitive customers.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [visual reasoning], [visual programming, spatial reasoning, tool induction, transductive learning, 3D scene understanding]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20934</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://transductive-visualprogram.github.io/" target="_blank" rel="noopener noreferrer" class="">https://transductive-visualprogram.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Transductive Visual Programming (TVP), a novel framework that builds new tools from experiential solutions rather than speculative induction., 2. Introduces a closed-loop system with an evolving Tool Library and an Example Library, enabling self-improvement through experience., 3. Demonstrates state-of-the-art performance on spatial reasoning benchmarks and shows that transductively learned tools are used more frequently and generalize better.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of spatial reasoning in 3D scenes by proposing Transductive Visual Programming (TVP), a framework that learns reusable higher-level tools by abstracting patterns from its own successful solutions. This experience-driven approach outperforms existing methods and GPT-4o on benchmarks, showing more effective tool discovery and strong generalization to unseen tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] A Multi-fidelity Double-Delta Wing Dataset and Empirical Scaling Laws for GNN-based Aerodynamic Field Surrogate</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [graph neural network, surrogate model, multi-fidelity dataset, scaling laws, aerodynamic field prediction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yiren Shen, Juan J. Alonso</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20941</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Release of an open-source, multi-fidelity aerodynamic dataset for double-delta wings, generated using a nested Saltelli sampling scheme. 2. Conducted an empirical scaling study linking training data size and model size to prediction accuracy for a GNN-based surrogate, revealing a power-law relationship. 3. Derived practical guidelines, estimating an optimal sampling density of approximately eight samples per dimension in a design space.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bb0e5406bfc3665bfcafc6d32aeeb524e6e21ffb9ceb2ac785fe0ddd6b60b3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7bb0e5406bfc3665bfcafc6d32aeeb524e6e21ffb9ceb2ac785fe0ddd6b60b3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the relationship between dataset size and model performance for a Graph Neural Network (GNN) surrogate used in aerodynamic field prediction. The authors release a new multi-fidelity dataset for double-delta wings and conduct a scaling study, finding that test error decreases with data size following a power law, which indicates efficient data utilization and informs optimal sampling strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Neural Probe-Based Hallucination Detection for Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection], [MLP probes, token-level detection, Bayesian optimization, hidden states, multi-objective loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shize Liang, Hongzhi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20949" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20949</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a neural network-based framework using lightweight MLP probes for token-level hallucination detection, enabling nonlinear modeling of hidden states. 2. Designed a multi-objective joint loss function to improve detection stability and semantic disambiguation. 3. Established a layer position-probe performance response model and used Bayesian optimization to automatically search for optimal probe insertion layers.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/256e2b7c6550072fc0e643c4045a4a592ba6b2241cd12656b7dd16ad27bf89b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/256e2b7c6550072fc0e643c4045a4a592ba6b2241cd12656b7dd16ad27bf89b0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of hallucination in large language models by proposing a real-time, token-level detection method. The method uses lightweight MLP probes on frozen model hidden states and a Bayesian-optimized layer search. Experiments show it outperforms existing methods in accuracy and recall under low false-positive conditions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [crosslingual information retrieval], [dual-encoder, contrastive learning, hard negative sampling, data augmentation, multi-source alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah</p>
</li>
<li class="">
<p><strong>institution:</strong> Based on the provided email domains (gmail.com), no specific institution can be reliably inferred. The team name is &quot;MultiMind&quot;.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20950</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces TriAligner, a novel dual-encoder architecture with contrastive learning for crosslingual claim retrieval. 2. Proposes a method to learn the relative importance of different information sources (e.g., native text, English translations) for alignment. 3. Enhances robustness through LLM-based data preprocessing/augmentation and hard negative sampling strategies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of retrieving fact-checked claims across multiple languages to combat misinformation. The proposed TriAligner system uses a dual-encoder with contrastive learning and multi-source alignment, enhanced by LLM-based data processing. The method shows significant improvements in retrieval accuracy on monolingual and crosslingual benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [protein language models], [reflection pretraining, chain-of-thought, language expressiveness, self-correction, biological sequences]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, Shanghai Artificial Intelligence Laboratory, University of British Columbia, Zhejiang University, The Chinese University of Hong Kong, Stony Brook University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20954</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed and defined the concept of &quot;language expressiveness&quot; to explain the difficulty of applying Chain-of-Thought reasoning to biological sequence models. 2. Introduced reflection pretraining for biological sequence models, enabling intermediate reasoning through auxiliary &quot;thinking tokens&quot;. 3. Demonstrated that this approach enables self-correction, improves performance, and offers benefits like counter-memorization and enhanced human steerability.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c51a6a0ca0e6bf5774254f47e4581544610c262b22a0cc12fe84b840bda40a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c51a6a0ca0e6bf5774254f47e4581544610c262b22a0cc12fe84b840bda40a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of applying Chain-of-Thought reasoning to biological sequence models like protein language models, which have limited token expressiveness. The authors propose reflection pretraining, which augments the model with auxiliary &quot;thinking tokens&quot; to enable intermediate reasoning and self-correction. The method theoretically enhances language expressiveness and experimentally leads to substantial performance gains compared to standard pretraining.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Proximal Policy Optimization (PPO), ChemBERTa, ESM-2, reaction-template, de novo drug design]</p>
</li>
<li class="">
<p><strong>authors:</strong> R Yadunandan, Nimisha Ghosh</p>
</li>
<li class="">
<p><strong>institution:</strong> Department of Computer Science and Engineering, Shiv Nadar University Chennai</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20958" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20958</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/YadunandanRaman/ReACT-Drug/" target="_blank" rel="noopener noreferrer" class="">https://github.com/YadunandanRaman/ReACT-Drug/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A target-agnostic RL framework (ReACT-Drug) that uses protein embeddings to find similar proteins and initialize a biologically relevant fragment search space. 2. A PPO agent that guides molecular generation through a dynamic action space defined by chemically valid, reaction-template-based transformations. 3. Ensures 100% chemical validity and novelty while generating candidates with competitive binding affinity and high synthetic accessibility.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/021dd36ada6572d99e5bbd07493acfe6d2766f9ca2c6bf611ba28e410f041efc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/021dd36ada6572d99e5bbd07493acfe6d2766f9ca2c6bf611ba28e410f041efc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces ReACT-Drug, a reinforcement learning framework for de novo drug design. It uses ESM-2 protein embeddings to find similar proteins and their ligands, decomposes them into fragments to guide a PPO agent, which then builds new molecules using reaction-template-based actions encoded by ChemBERTa. The method generates novel, synthetically accessible drug candidates with high binding affinity and guaranteed chemical validity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [repository-level code understanding], [LLM agent, reinforcement learning, tool usage, code navigation, execution-aware]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhaoxi Zhang, Yitong Duan, Yanzhi Zhang, Yiming Xu, Jiyan He, Yunfang Wu</p>
</li>
<li class="">
<p><strong>institution:</strong> Affiliation not explicitly stated in provided text. Email domains suggest potential institutions, but cannot be reliably inferred from given content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20957</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RepoNavigator, an LLM agent that uses a single, execution-aware tool (&quot;jump to definition&quot;) for navigating code repositories, simplifying agent control and aligning with code execution logic. 2. Introduces an end-to-end Reinforcement Learning (RL) training method for the agent directly from a pretrained model, eliminating the need for closed-source model distillation. 3. Demonstrates state-of-the-art performance on repository-level issue localization, showing that smaller RL-trained models (e.g., 7B) can outperform larger baseline models (e.g., 14B, 32B) and even closed-source models like Claude-3.7.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6254efa02c0725684b783a26c76c1825bf8aaa25aee61fb7aaea40887f0efc46_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6254efa02c0725684b783a26c76c1825bf8aaa25aee61fb7aaea40887f0efc46_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of locating code to modify in large software repositories. It proposes RepoNavigator, an LLM agent trained with Reinforcement Learning to use a single &quot;jump to definition&quot; tool for navigation. Experiments show this approach achieves state-of-the-art performance, with smaller models outperforming larger baselines, proving the efficiency of a simple, execution-aware tool combined with RL training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Can Agentic AI Match the Performance of Human Data Scientists?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [automated data science], [agentic AI, domain knowledge, synthetic data, large language models, human-AI teaming]</p>
</li>
<li class="">
<p><strong>authors:</strong> An Luo, Jin Du, Fangqiao Tian, Xun Xian, Robert Specht, Ganghua Wang, Xuan Bi, Charles Fleming, Jayanth Srinivasa, Ashish Kundu, Mingyi Hong, Jie Ding</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Minnesota, University of Chicago, Cisco Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20959" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20959</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Designed a novel prediction task where a critical latent variable is hidden in image data to test the limitations of generic agentic AI workflows. 2. Demonstrated through experiments that current agentic AI systems, which rely on generic code generation, fail to match human data scientists who can leverage domain-specific insights. 3. Highlighted a key limitation of current LLM-driven data science automation and underscored the need for future research to develop AI systems that can better incorporate domain knowledge.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79fb0613736763ea339bd898e4056c45f61f97d7ed163ac22b97fef63af1c01a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79fb0613736763ea339bd898e4056c45f61f97d7ed163ac22b97fef63af1c01a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper investigates whether agentic AI can match human data scientists by designing a property insurance prediction task where a crucial variable is hidden in image data. Experiments show that AI relying on generic workflows performs poorly compared to methods using domain-specific insights. The study concludes that current agentic AI has a key limitation in incorporating domain knowledge, highlighting a need for future research in this direction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [distributed attention, communication efficiency, Ring-Attention, communication-computation ratio, scalability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sirui Chen, Jingji Chen, Siqi Zhu, Ziheng Jiang, Yanghua Peng, Xuehai Qian</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Purdue University, University of Illinois Urbana-Champaign, ByteDance Seed</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20968" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20968</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Mesh-Attention, a new distributed attention algorithm using a matrix-based model that assigns 2D computation tiles to GPUs for lower communication-computation ratio. 2. Introduces a greedy algorithm to efficiently search the scheduling space within a tile under communication constraints. 3. Provides theoretical analysis and extensive experiments showing Mesh-Attention significantly reduces communication volume and achieves speedup compared to state-of-the-art methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4944eec84564de9a1d27e811d1317c483f5220256be0880e9e87af0f1df84b8e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4944eec84564de9a1d27e811d1317c483f5220256be0880e9e87af0f1df84b8e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the communication bottleneck in scaling LLM context windows by proposing Mesh-Attention, a new distributed attention algorithm that uses 2D computation tiling to reduce communication overhead. It demonstrates superior performance, achieving up to 3.4x speedup and 85.4% communication reduction on 256 GPUs, and shows good scalability for large-scale deployments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Generalised Linear Models in Deep Bayesian RL with Learnable Basis Functions</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Bayesian Reinforcement Learning, Meta-Reinforcement Learning, Generalised Linear Models, Learnable Basis Functions, Variational Inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jingyang You, Hanna Kurniawati</p>
</li>
<li class="">
<p><strong>institution:</strong> Australian National University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20974" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20974</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes GLiBRL, a novel deep Bayesian RL method using Generalised Linear Models with learnable basis functions for efficient and accurate model learning. 2. Enables fully tractable marginal likelihood and Bayesian inference on task parameters and model noises, avoiding the need to optimize the difficult Evidence Lower Bound (ELBO). 3. Demonstrates significant performance improvements on MetaWorld benchmarks, outperforming state-of-the-art methods like VariBAD and showing low-variance, consistent results.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d35dd58d9d51b22dbce9eb7fc7a54a60d532c573648a3a29596e023ac63db13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d35dd58d9d51b22dbce9eb7fc7a54a60d532c573648a3a29596e023ac63db13_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of inefficient and unstable model learning in deep Bayesian Reinforcement Learning (BRL), which traditionally relies on optimizing the difficult Evidence Lower Bound (ELBO). The authors propose a new method called GLiBRL, which uses Generalised Linear Models with learnable basis functions to enable tractable marginal likelihood and Bayesian inference. The method significantly improves success rates on challenging MetaWorld benchmarks compared to existing deep BRL and meta-RL approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Automatic Replication of LLM Mistakes in Medical Conversations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm evaluation], [medical conversation, mistake replication, benchmark creation, llm judges, single-shot qa]</p>
</li>
<li class="">
<p><strong>authors:</strong> Oleksii Proniakin, Diego Fajardo, Ruslan Nazarenko, Razvan Marinescu</p>
</li>
<li class="">
<p><strong>institution:</strong> Lumos AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20983" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20983</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MedMistake, an automatic pipeline for extracting and replicating LLM mistakes from complex medical conversations into a benchmark format. 2. Releases MedMistake-All, a dataset of 3,390 single-shot QA pairs derived from identified mistakes, and a validated subset, MedMistake-Bench. 3. Provides a comprehensive evaluation of 12 frontier LLMs using the validated benchmark, revealing performance trends among top models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7799ccba99ce08a1cee1bd87ba7b9e986a373df0f78a25479ad9fec7478ca0e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7799ccba99ce08a1cee1bd87ba7b9e986a373df0f78a25479ad9fec7478ca0e9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the difficulty of replicating specific mistakes made by LLMs in clinical conversations. It proposes MedMistake, an automated pipeline that generates conversational data, uses LLM judges to identify errors, and distills them into single-shot QA pairs to create a benchmark. The resulting benchmark was used to evaluate 12 LLMs, finding that GPT, Claude, and Grok models performed best.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] A Blockchain-Monitored Agentic AI Architecture for Trusted Perception-Reasoning-Action Pipelines</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [LangChain, Hyperledger Fabric, MCP (Model Context Protocol), permissioned blockchain, multi-agent system]</p>
</li>
<li class="">
<p><strong>authors:</strong> Salman Jan, Hassan Ali Razzaqi, Ali Akarma, Mohammad Riyaz Belgaum</p>
</li>
<li class="">
<p><strong>institution:</strong> Arab Open University-Bahrain, Islamic University of Madinah</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20985" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20985</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a novel architecture integrating a LangChain-based multi-agent system with a permissioned blockchain for monitoring and auditing agentic AI actions. 2. Introduced a framework linking the perception-reasoning-action cycle to a blockchain governance layer for input verification, action evaluation, and outcome logging. 3. Demonstrated the framework&#x27;s applicability and performance through experiments in smart inventory management, traffic-signal control, and healthcare monitoring.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b6daf67b596733e755359a781c7506180a1c98a12a8eab70c8fd627d718b47_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24b6daf67b596733e755359a781c7506180a1c98a12a8eab70c8fd627d718b47_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a blockchain-monitored architecture for agentic AI systems to address trust and oversight concerns. The method integrates a LangChain multi-agent system with a Hyperledger Fabric blockchain to create an auditable perception-reasoning-action pipeline. The results show the framework effectively prevents unauthorized actions, provides full decision traceability, and maintains acceptable operational latency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] FinAgent: An Agentic AI Framework Integrating Personal Finance and Nutrition Planning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent architecture, substitution graph, price-aware optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Toqeer Ali Syed, Abdulaziz Alshahrani, Ali Ullah, Ali Akarma, Sohail Khan, Muhammad Nauman, Salman Jan</p>
</li>
<li class="">
<p><strong>institution:</strong> Islamic University of Madinah, Effat University, Arab Open University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20991" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20991</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel agentic AI framework that integrates personal finance management with real-time diet optimization, addressing a gap in current tools. 2. Implements a modular multi-agent architecture with specialized agents (budgeting, nutrition, price monitoring, health personalization) that share a knowledge base and use a substitution graph for cost-effective meal planning. 3. Demonstrates through a case study simulation significant cost reduction (12-18%) and high nutrient adequacy (&gt;95%) while maintaining robustness to market price fluctuations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc1ddd8fc13f7437534fa058d5e3879ce0f82c07898d64ccb7548f0932948a8a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc1ddd8fc13f7437534fa058d5e3879ce0f82c07898d64ccb7548f0932948a8a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces FinAgent, an agentic AI framework that combines personal finance and real-time price data to generate nutritionally adequate meal plans at minimal cost. It uses a modular multi-agent system and a substitution graph to dynamically adapt to budget constraints and market changes. The system was validated in a simulation, showing significant cost savings and high nutritional adequacy, aligning with sustainable development goals.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] TrafficSimAgent: A Hierarchical Agent Framework for Autonomous Traffic Simulation with MCP Control</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [traffic simulation, LLM agent, hierarchical framework, MCP control, autonomous decision-making]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuwei Du, Jun Zhang, Jie Feng, Zhicheng Liu, Jian Yuan, Yong Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Alibaba Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20996" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20996</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes TrafficSimAgent, a novel LLM-based hierarchical agent framework designed to lower the barrier for conducting traffic simulations by automating experiment design and decision optimization. 2. Introduces a cross-level collaboration mechanism where high-level agents interpret natural language instructions and plan workflows, while low-level agents make real-time, condition-based action selections for fundamental elements. 3. Demonstrates through extensive experiments that the framework effectively executes simulations under various conditions, handles ambiguous instructions, and achieves superior performance compared to other systems and SOTA LLM-based methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f663746265410a8f10fffee2372e39160e0e5f92969f9c3f7f502da4d3657fd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f663746265410a8f10fffee2372e39160e0e5f92969f9c3f7f502da4d3657fd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces TrafficSimAgent, a hierarchical LLM-based agent framework that automates traffic simulation tasks by using high-level agents for natural language instruction comprehension and workflow planning, and low-level agents for real-time action optimization. The system is designed to make powerful simulation platforms like SUMO more accessible to non-experts. Experiments show it effectively executes simulations, handles ambiguous instructions, and outperforms existing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [knowledge distillation, chain-of-thought, sequence truncation, training efficiency, reasoning models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wei-Rui Chen, Vignesh Kothapalli, Ata Fatahibaarzi, Hejian Sang, Shao Tang, Qingquan Song, Zhipeng Wang, Muhammad Abdul-Mageed</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of British Columbia, LinkedIn</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21002" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21002</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/weiruichen01/distilling-the-essence" target="_blank" rel="noopener noreferrer" class="">https://github.com/weiruichen01/distilling-the-essence</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analysis of supervision allocation in reasoning distillation, showing the CoT segment is the dominant factor for transferring reasoning capability. 2. Establishment of a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. 3. Empirical demonstration that training on only the first 50% of tokens retains ~94% of performance while halving computational costs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a99e2da19bbc9bacf5104e37b4afd860b26a5285dd752f9a6e025702d930839_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a99e2da19bbc9bacf5104e37b4afd860b26a5285dd752f9a6e025702d930839_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational expense of distilling reasoning capabilities from large to small models over long sequences. It proposes a method of selective distillation and sequence truncation, focusing on early reasoning tokens. The key finding is that training on just the first half of tokens can preserve most performance while significantly reducing training time, memory, and FLOPs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [llm evaluation], [Competitive Swiss-System Dynamics, Expected Win Score, Failure Sensitivity Analysis, Monte Carlo Simulation, risk appetite]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiashuo Liu, Jiayun Wu, Chunjie Wu, Jingkai Liu, Zaiyuan Wang, Huan Zhou, Wenhao Huang, Hongseok Namkoong</p>
</li>
<li class="">
<p><strong>institution:</strong> ByteDance Seed, Carnegie Mellon University, Columbia University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21010" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21010</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the Competitive Swiss-System Dynamics (CSD) framework, a novel sequential contest simulation for holistic LLM ranking across multiple benchmarks, 2. Proposes the Expected Win Score via Monte Carlo Simulation to provide a statistically robust ranking that reduces noise from random pairing, 3. Implements Failure Sensitivity Analysis to profile models by risk appetite, distinguishing between robust generalists and aggressive specialists.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c6a4e260d9e6100733ae95995348a1b30295905871b863cf4afa821492e22eb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c6a4e260d9e6100733ae95995348a1b30295905871b863cf4afa821492e22eb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitations of static, fragmented LLM evaluation by proposing the Competitive Swiss-System Dynamics (CSD) framework, which simulates a multi-round sequential contest to aggregate performance across benchmarks dynamically. It uses Monte Carlo simulation to compute a robust Expected Win Score and includes a Failure Sensitivity Analysis to assess model risk profiles. The authors demonstrate that CSD provides a more nuanced and context-aware ranking than traditional methods, advancing risk-informed LLM evaluation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Supervised Fine-Tuning, Chain-of-Thought, Two-Stage Training, Attention Imbalance, Key Answer Tokens]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaofeng Shi, Qian Kou, Yuduo Li, Hua Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Academy of Artificial Intelligence (BAAI), Beijing Jiaotong University (BJTU)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21017" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21017</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies a key limitation in conventional SFT where models over-attend to lengthy Chain-of-Thought reasoning sequences at the expense of the shorter, critical final answer tokens. 2. Proposes SFTKey, a novel two-stage fine-tuning scheme that first applies conventional SFT for format learning, then fine-tunes only on the Key (final answer) portion to boost accuracy. 3. Demonstrates through extensive experiments that SFTKey achieves an average accuracy improvement of over 5% compared to standard SFT while maintaining correct output formatting.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7eab786d7e6ac187d45153b771fdc458d7c8434c0e133a9bcdb70a2afa441a73_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7eab786d7e6ac187d45153b771fdc458d7c8434c0e133a9bcdb70a2afa441a73_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that standard Supervised Fine-Tuning (SFT) for LLMs can cause an attention imbalance, where models focus too much on long reasoning chains (CoT) and not enough on the final answer. To solve this, the authors propose SFTKey, a two-stage method that first does standard SFT for formatting, then fine-tunes only on the key answer tokens. Experiments show this approach improves average accuracy by over 5% without harming output format correctness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Policy-Conditioned Policies for Multi-Agent Task Solving</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent reinforcement learning], [Program Equilibrium, Programmatic Iterated Best Response (PIBR), policy-conditioning, large language models, textual gradients]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yue Lin, Shuhui Zhu, Wenhao Li, Ang Li, Dan Qiao, Pascal Poupart, Hongyuan Zha, Baoxiang Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen; University of Waterloo; Tongji University; Vector Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21024" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21024</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a paradigm shift by representing agent policies as human-interpretable source code, bridging the gap between opaque neural policies and the need for strategy comprehension in multi-agent settings. 2. Introduces Programmatic Iterated Best Response (PIBR), a novel algorithm that uses LLMs as point-wise best-response operators to synthesize and refine policy code based on game utility and unit tests. 3. Operationalizes the game-theoretic concept of Program Equilibrium for modern learning, demonstrating its effectiveness on coordination games and a cooperative foraging environment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8665c80d59a606e3c0796d224d372080c9552f5b48a9e7e797a73cad25b1b7e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8665c80d59a606e3c0796d224d372080c9552f5b48a9e7e797a73cad25b1b7e7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of dynamic strategy adaptation in multi-agent tasks by representing policies as interpretable source code and using Large Language Models (LLMs) to optimize them. The core method, Programmatic Iterated Best Response (PIBR), leverages LLMs to iteratively refine an agent&#x27;s policy code in response to an opponent&#x27;s strategy using textual feedback. The approach successfully solves standard coordination games and a cooperative environment, demonstrating a practical bridge between theoretical Program Equilibrium and modern AI learning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [3D human pose estimation], [3D sign language reconstruction, biomechanical accuracy, hand and body pose priors, monocular video, SMPL-X]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kaustubh Kundu, Hrishav Bakul Barua, Lucy Robertson-Bell, Zhixi Cai, Kalin Stefanov</p>
</li>
<li class="">
<p><strong>institution:</strong> Monash University, TCS Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21054" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21054</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/kaustesseract/DexAvatar" target="_blank" rel="noopener noreferrer" class="">https://github.com/kaustesseract/DexAvatar</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel framework (DexAvatar) for reconstructing biomechanically accurate 3D hand and body poses from monocular sign language videos. 2. The use of learned 3D hand and body pose priors to guide the reconstruction and overcome challenges like self-occlusion and motion blur. 3. Demonstrating strong performance on the SGNify benchmark, achieving a 35.11% improvement over the state-of-the-art.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594bef871fe9a00d58a9f3f12c9a0b4bf4f66d3d738bd3f02dedcbad04bdcd25_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594bef871fe9a00d58a9f3f12c9a0b4bf4f66d3d738bd3f02dedcbad04bdcd25_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces DexAvatar, a framework that uses learned 3D hand and body pose priors to reconstruct accurate 3D sign language poses from monocular videos. It addresses the limitations of existing 2D datasets and noisy 3D estimations. The method significantly outperforms prior work on the SGNify motion capture benchmark.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [deep learning theory], [scaling laws, feature learning, infinite-depth limit, ResNets, hyperparameter transfer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zihan Yao, Ruoyu Wu, Tianxiang Gao</p>
</li>
<li class="">
<p><strong>institution:</strong> DePaul University, Iowa State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21075" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21075</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Derives Neural Feature Dynamics (NFD), a theoretical framework characterizing feature learning in ResNets in the joint infinite-width and infinite-depth limit. 2. Identifies a vanishing mechanism induced by 1/√depth scaling that explains feature-learning collapse in deep networks and the failure of depth-µP. 3. Proposes a practical depth-aware learning-rate correction to counteract the collapse and restore depth-wise hyperparameter transfer for improved performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06065072ce8d20b2298a45760b95c3f905a6aff3d726e09d4ddf1ecd2e9cc359_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06065072ce8d20b2298a45760b95c3f905a6aff3d726e09d4ddf1ecd2e9cc359_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of theoretical understanding behind scaling laws in deep learning by analyzing feature learning dynamics in deep ResNets. It proposes the Neural Feature Dynamics (NFD) framework in the infinite-width and depth limit, which explains when scaling succeeds and identifies a cause of feature collapse. Based on this insight, the authors propose a simple learning-rate correction that improves training stability and performance in deeper networks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Agentic AI, SHAP, Large Language Model, Iterative Refinement, Bias-Variance Trade-off]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tomoaki Yamaguchi, Yutong Zhou, Masahiro Ryo, Keisuke Katsura</p>
</li>
<li class="">
<p><strong>institution:</strong> Gifu University, Leibniz Centre for Agricultural Landscape Research (ZALF), Brandenburg University of Technology Cottbus–Senftenberg, Kyoto University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21066</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Agentic XAI framework integrating SHAP-based explainability with multimodal LLM-driven iterative refinement for generating progressively enhanced explanations. 2. Demonstrates the framework&#x27;s application and evaluation in a real-world agricultural recommendation system using rice yield data. 3. Identifies a bias-variance trade-off in iterative refinement, showing that early stopping (regularization) is crucial for optimizing explanation quality, challenging assumptions of monotonic improvement.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e69e3950a2d09bc883a9cee931300bdfbeacc4e1e6094150a08db35366449e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e69e3950a2d09bc883a9cee931300bdfbeacc4e1e6094150a08db35366449e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes an Agentic Explainable AI (XAI) framework that combines SHAP analysis with iterative refinement by a multimodal Large Language Model (LLM) to generate better explanations. The framework was tested as an agricultural recommendation system, and evaluations by both human experts and LLMs showed that explanation quality improved over initial rounds but declined with excessive refinement, revealing a bias-variance trade-off. The findings indicate that strategic early stopping is necessary to optimize the practical utility of such agentic XAI systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] LLM Personas as a Substitute for Field Experiments in Method Benchmarking</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [algorithmic fairness &amp; evaluation], [field experiments, A/B testing, LLM personas, algorithmic benchmarking, information-theoretic bounds]</p>
</li>
<li class="">
<p><strong>authors:</strong> Enoch Hyunwook Kang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21080" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21080</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a formal, if-and-only-if characterization of the conditions (aggregate-only observation, algorithm-blind evaluation) under which swapping humans for LLM personas is a valid benchmark substitution, equivalent to changing the evaluation panel. 2. Moves from validity to usefulness by defining an information-theoretic measure of discriminability for the aggregate channel induced by persona simulation. 3. Derives explicit sample-size bounds on the number of independent persona evaluations required to make persona benchmarking as decision-relevant as a field experiment for distinguishing between methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1e74907f157cdb694f3120aed988d1affab03b63adb6bf73297f43733c1b8ba_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f1e74907f157cdb694f3120aed988d1affab03b63adb6bf73297f43733c1b8ba_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high cost and latency of field experiments (A/B tests) for benchmarking methods in societal systems by proposing LLM-based persona simulation as a synthetic alternative. It formally proves the conditions under which this substitution is valid and provides information-theoretic bounds on the required number of persona evaluations to make the benchmark useful. The main conclusion is that persona benchmarking can be a viable, efficient substitute for field experiments under specific, well-defined conditions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [3D avatar generation], [3D Gaussian Splatting, analytic rigging, texel-space deformation, hybrid representation, head reenactment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jaeseong Lee, Junyeong Ahn, Taewoong Kang, Jaegul Choo</p>
</li>
<li class="">
<p><strong>institution:</strong> KAIST, Hanyang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21099" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21099</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A hybrid avatar representation (TexAvatars) that combines analytic rigging for geometric grounding with texel-space neural regression for spatial continuity. 2. A method that predicts Gaussian attributes in UV space via CNNs but drives 3D deformation using mesh-aware Jacobians, enabling smooth transitions across mesh boundaries. 3. The model demonstrates improved generalization, stability, and capture of fine-grained expression details (e.g., wrinkles, mouth cavity) under extreme poses and expressions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8320fd6b1a6f131ad704b82b65143269040ab86b9b67005a1edf15fca8097f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8320fd6b1a6f131ad704b82b65143269040ab86b9b67005a1edf15fca8097f6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces TexAvatars, a method for creating drivable 3D head avatars by hybridizing analytic rigging with texel-space neural regression to improve generalization to unseen expressions. It predicts local attributes in UV space but uses mesh-aware Jacobians for 3D deformation, separating semantic modeling from geometric control. The approach achieves state-of-the-art performance in challenging reenactment scenarios, capturing fine details with high fidelity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Semi-Supervised Learning for Large Language Models Safety and Content Moderation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [content moderation], [semi-supervised learning, data augmentation, safety classifiers, LLM safety, prompt harmfulness]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eduard Stefan Dinuta, Iustin Sirbu, Traian Rebedea</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Science and Technology Politehnica Bucharest, Renius Technologies, NVIDIA</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21107</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analysis of state-of-the-art semi-supervised learning algorithms for LLM safety, focusing on both prompt and response harmfulness. 2. Introduction of a new, task-specific augmentation technique for safety tasks. 3. Demonstration that task-specific augmentations significantly outperform general-purpose methods like backtranslation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/035c08c88d89969ce37594942a40aa577a3c0c7c7743cd71bdf84366a9dfa5f2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/035c08c88d89969ce37594942a40aa577a3c0c7c7743cd71bdf84366a9dfa5f2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of acquiring high-quality labeled data for training safety classifiers for Large Language Models. It proposes using semi-supervised learning techniques that leverage both labeled and unlabeled data, and introduces a task-specific data augmentation method. The key finding is that this approach, particularly with custom augmentations, significantly improves performance on safety tasks compared to using general-purpose techniques.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Semantic Refinement with LLMs for Graph Representations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [graph representation learning], [graph neural network, large language model, semantic refinement, structure-semantics heterogeneity, data-centric adaptation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Connecticut, University of Notre Dame</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21106" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21106</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a data-centric perspective to address structure-semantics heterogeneity in graphs by treating node semantics as a task-adaptive variable, shifting focus from model-centric inductive bias injection. 2. Introduces the Data-Adaptive Semantic Refinement (DAS) framework, which couples a fixed GNN and an LLM in a closed feedback loop for iterative semantic refinement and graph learning. 3. Demonstrates the framework&#x27;s effectiveness on diverse graphs, showing consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfae73c72759ca834d898f3c6ca5f0824bada06285918fca678e0f809fce9afd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfae73c72759ca834d898f3c6ca5f0824bada06285918fca678e0f809fce9afd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of structure-semantics heterogeneity in graph data, where predictive signals vary across domains. It proposes a Data-Adaptive Semantic Refinement (DAS) framework that uses a closed feedback loop between a GNN and an LLM to iteratively refine node semantics for the learning task. The method shows strong performance on structure-dominated graphs and remains competitive on semantics-rich graphs, validating the data-centric adaptation approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] STLDM: Spatio-Temporal Latent Diffusion Model for Precipitation Nowcasting</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [diffusion models], [precipitation nowcasting, latent diffusion model, spatio-temporal prediction, variational autoencoder, conditioning network]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shi Quan Foo, Chi-Ho Wong, Zhihan Gao, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology, Hong Kong Observatory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21118" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21118</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/sqfoo/stldm_official" target="_blank" rel="noopener noreferrer" class="">https://github.com/sqfoo/stldm_official</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes STLDM, a novel two-stage diffusion-based architecture for precipitation nowcasting that combines deterministic forecasting with generative enhancement. 2. Introduces an end-to-end learning framework that jointly trains a Variational Autoencoder, a conditioning network, and a latent diffusion model. 3. Demonstrates superior performance and improved inference efficiency compared to state-of-the-art methods on multiple radar datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3f04a94a2a07676690c2f108f7a602a6b052c1463701d217a319cd81e05ecce_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3f04a94a2a07676690c2f108f7a602a6b052c1463701d217a319cd81e05ecce_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of precipitation nowcasting, where deterministic models produce blurry predictions and generative models suffer from poor accuracy. It proposes STLDM, a spatio-temporal latent diffusion model that decomposes the task into a deterministic forecasting stage and a generative enhancement stage. Experiments show STLDM outperforms state-of-the-art methods while being more efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Beyond Context: Large Language Models Failure to Grasp Users Intent</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [ai safety], [intent recognition, contextual understanding, safety circumvention, prompt engineering, transformer architectures]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos</p>
</li>
<li class="">
<p><strong>institution:</strong> KTH Royal Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21110" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21110</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [clinical nlp], [medication safety review, large language models, real-world evaluation, failure analysis, electronic health records]</p>
</li>
<li class="">
<p><strong>authors:</strong> Oliver Normand, Esther Borsi, Mitch Fruin, Lauren E Walker, Jamie Heagerty, Chris C. Holmes, Anthony J Avery, Iain E Buchan, Harry Coppock</p>
</li>
<li class="">
<p><strong>institution:</strong> i.AI (Department for Science, Innovation, and Technology), University of Liverpool, University of Oxford, University of Nottingham, Imperial College London</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21127" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21127</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first real-world evaluation of an LLM-based medication safety review system on a large-scale NHS primary care dataset. 2. Performed a detailed failure analysis, identifying five primary patterns of LLM reasoning failures in clinical contexts (e.g., overconfidence, lack of contextual adaptation). 3. Provided a public dataset of 45 detailed clinical vignettes that comprehensively document all identified failure cases for further study.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a25d52747ed1a867914e2ab484a381e6c4f16c161178ce43bc0d582517885647_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a25d52747ed1a867914e2ab484a381e6c4f16c161178ce43bc0d582517885647_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates the performance of a large language model (LLM) system for medication safety reviews using real NHS primary care data. The study found that while the LLM was highly sensitive in detecting issues, it correctly identified all issues and interventions in less than half of the patients, with failures primarily stemming from contextual reasoning errors rather than a lack of medical knowledge. The work highlights critical shortcomings in LLM reasoning for clinical deployment and calls for more rigorous, real-world evaluations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] AutoBaxBuilder: Bootstrapping Code Security Benchmarking</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [code security evaluation], [automated benchmarking, LLM-generated code, security vulnerabilities, exploit generation, plausibility checks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tobias von Arx, Niels Mündler, Mark Vero, Maximilian Baader, Martin Vechev</p>
</li>
<li class="">
<p><strong>institution:</strong> ETH Zurich, Snyk, INSAIT (Sofia University &quot;St. Kliment Ohridski&quot;)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21132" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21132</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/eth-sri/autobaxbuilder" target="_blank" rel="noopener noreferrer" class="">https://github.com/eth-sri/autobaxbuilder</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces AutoBaxBuilder, a framework for generating code security benchmarking tasks and tests from scratch, addressing the limitations of manual benchmarks. 2. Proposes a robust pipeline with fine-grained plausibility checks that leverages LLMs to construct functionality tests and end-to-end security exploits. 3. Releases AutoBaxBench, a new benchmark of generated tasks, and demonstrates the framework&#x27;s efficiency (under 2 hours and $10 per task) and quality through comparison with human-crafted tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385abd6729afb970eba2217cc3d408efe70ab80f9d7aa0cbe7c2e0254f48b74c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/385abd6729afb970eba2217cc3d408efe70ab80f9d7aa0cbe7c2e0254f48b74c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents AutoBaxBuilder, a framework that automatically generates tasks and tests for benchmarking the security of code produced by large language models (LLMs). It uses an LLM-powered pipeline to create functional tests and security exploits, ensuring benchmark quality and scalability. The authors show the method is efficient and release a new benchmark, AutoBaxBench, to evaluate LLM security capabilities.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] MODE: Multi-Objective Adaptive Coreset Selection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [coreset selection, submodular maximization, data efficiency, adaptive weighting, multi-objective optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tanmoy Mukherjee, Pierre Marquis, Zied Bouraoui</p>
</li>
<li class="">
<p><strong>institution:</strong> CRIL, Université d&#x27;Artois</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21152" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21152</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MODE, a dynamic framework that adaptively combines multiple coreset selection strategies based on their real-time contribution to model performance across different training phases. 2. Provides theoretical guarantees, achieving a (1-1/e)-approximation for the coreset selection problem with O(n log n) complexity and convergence bounds for strategy weights. 3. Demonstrates practical benefits including reduced memory requirements and provides interpretable insights into the evolution of data utility during training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8cefebbb0215d55d5050eb92783788b0acf7386684074cdf20b76685dfef159_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8cefebbb0215d55d5050eb92783788b0acf7386684074cdf20b76685dfef159_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of selecting small, representative data subsets (coresets) for efficient deep learning by proposing MODE, a framework that dynamically adapts selection criteria (like class balance, diversity, and uncertainty) to different training phases. It shows that MODE achieves strong theoretical approximation guarantees and competitive model accuracy while reducing computational and memory costs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided Medical Image Segmentation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image segmentation], [CLIP, multimodal fusion, parameter-efficient fine-tuning, vision-language alignment, anatomical structure]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gaoren Lin, Huangxuan Zhao, Yuan Xiong, Lefei Zhang, Bo Du, Wentao Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> Wuhan University (Inferred from authors Gaoren Lin, Lefei Zhang, Bo Du, Wentao Zhu, who are known to be affiliated with Wuhan University. Huangxuan Zhao and Yuan Xiong are likely from the same group.)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21135" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21135</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a Semantic-Structural Synergy Encoder (SSE) that augments CLIP&#x27;s ViT with a CNN branch to preserve fine-grained anatomical structures. 2. Introduces a Domain-Augmented Text Encoder (DATE) that injects medical knowledge from large language models to better model complex clinical descriptions. 3. Designs a Vision-Language Calibration Module (VLCM) to refine cross-modal correspondence in a unified feature space, addressing domain-specific semantic misalignment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b11d6061b6a08f8b03b2395e16fc0847c1b68ab4e388d93a886ee875211fcf44_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b11d6061b6a08f8b03b2395e16fc0847c1b68ab4e388d93a886ee875211fcf44_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes TGC-Net, a parameter-efficient CLIP-based framework for text-guided medical image segmentation. It addresses CLIP&#x27;s limitations in medical imaging by introducing modules for structural refinement, medical knowledge injection, and cross-modal calibration. Experiments on five datasets show state-of-the-art performance with fewer trainable parameters.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] BALLAST: Bandit-Assisted Learning for Latency-Aware Stable Timeouts in Raft</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [distributed consensus], [Raft, election timeout, contextual bandits, LinUCB, fault tolerance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qizhi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> PingCAP, Data &amp; AI-Innovation Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21165" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21165</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. BALLAST, a lightweight contextual-bandit framework for Raft election timeouts with safe exploration and non-stationary adaptation. 2. A reproducible evaluation methodology (discrete-event simulation, fault injection, protocol-level logging, CI-based aggregation) to study election stability under tail latency and recovery turbulence. 3. Demonstration that BALLAST substantially reduces recovery time and unwritable time compared to standard heuristics in challenging WAN regimes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75bff5f2f039d6eaeb1861fcd564ebda78e1b3bd0f91a85b3fc977c335d273e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75bff5f2f039d6eaeb1861fcd564ebda78e1b3bd0f91a85b3fc977c335d273e6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of leader-election instability in the Raft consensus protocol under variable network conditions like long-tail latency. It proposes BALLAST, a method that uses online linear contextual bandits to adaptively select election timeouts, augmented with safe exploration. The evaluation shows that BALLAST significantly improves recovery performance in unstable WAN environments while remaining competitive in stable settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Schrödinger&#x27;s Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [robot navigation], [zero-shot object navigation, trajectory-conditioned 3D imagination, occlusion-aware planning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yu He, Da Huang, Zhenyang Liu, Zixiao Gu, Qiang Sun, Guangnan Ye, Yanwei Fu</p>
</li>
<li class="">
<p><strong>institution:</strong> Fudan University, Shanghai Jiao Tong University, Shanghai University of International Business and Economics, Shanghai Innovation Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21201" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21201</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://heyu322.github.io/Schrodinger-Navigator.github.io/" target="_blank" rel="noopener noreferrer" class="">https://heyu322.github.io/Schrodinger-Navigator.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed Schrödinger&#x27;s Navigator, a novel navigation framework that models unobserved space as an ensemble of plausible future worlds to handle uncertainty. 2. Introduced a trajectory-conditioned 3D world model that imagines future observations along candidate paths to see beyond occlusions and anticipate risks. 3. Developed a method to fuse imagined 3D observations into a navigation map to update a value map, guiding the policy toward safer, less-occluded routes for better object tracking.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34e56028ea40f6f3b4a9150683288695e8b7fd2724c676c4f7f56f07367b4fb3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34e56028ea40f6f3b4a9150683288695e8b7fd2724c676c4f7f56f07367b4fb3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of zero-shot object navigation in cluttered environments with occlusions and moving targets. It proposes Schrödinger&#x27;s Navigator, a framework that samples candidate trajectories and uses a 3D imagination model to predict future observations, enabling the robot to plan safer paths and locate hidden objects. Experiments on a quadruped robot show the method outperforms baselines in success rate and localization in occlusion-heavy settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [speech representation learning], [meta-learning, bi-level optimization, few-shot adaptation, self-supervised learning, speech representation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mahi Luthra, Jiayi Shen, Maxime Poli, Angelo Ortiz, Yosuke Higuchi, Youssef Benchekroun, Martin Gleize, Charles-Eric Saint-James, Dongyan Lin, Phillip Rust, Angel Villar, Surya Parimi, Vanessa Stark, Rashel Moritz, Juan Pino, Yann LeCun, Emmanuel Dupoux</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta AI, ENS-PSL, EHESS, CNRS</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21204" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21204</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/facebookresearch/spidr-adapt" target="_blank" rel="noopener noreferrer" class="">https://github.com/facebookresearch/spidr-adapt</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the Multi-task Adaptive Pre-training (MAdaPT) protocol, framing few-shot speech representation learning as a bi-level optimization meta-learning problem. 2. Proposes a novel First-Order Bi-Level Optimization (FOBLO) heuristic to enable scalable meta-training by avoiding heavy computation costs. 3. Stabilizes meta-training with a robust initialization technique using interleaved supervision that alternates between self-supervised and supervised objectives.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff9692c36cbda26291fde2551256e229a90f6eb51f087d833a2d84cb4b10925b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff9692c36cbda26291fde2551256e229a90f6eb51f087d833a2d84cb4b10925b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces SpidR-Adapt, a method for rapid adaptation of speech representation models to new languages using minimal unlabeled data. It formulates the problem as meta-learning with a bi-level optimization framework (MAdaPT), proposes an efficient solver (FOBLO), and uses interleaved supervision for stable training. The model achieves significant gains in phonemic discrimination and language modeling after training on less than 1 hour of target-language audio, demonstrating over 100x greater data efficiency than standard methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [runtime safety guardrail, executable safety logic, hybrid reasoning, temporal safety predicate, context-aware safety predicate]</p>
</li>
<li class="">
<p><strong>authors:</strong> Le Wang, Zonghao Ying, Xiao Yang, Quanchen Zou, Zhenfei Yin, Tianlin Li, Jian Yang, Yaodong Yang, Aishan Liu, Xianglong Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Beihang University, Beijing University of Posts and Telecommunications, 360 AI Security Lab, The University of Sydney, Nanyang Technological University, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21220" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21220</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RoboSafe, a hybrid reasoning runtime safeguard for embodied agents using executable predicate-based safety logic. 2. Introduces a Backward Reflective Reasoning module to infer temporal safety predicates from recent trajectories and trigger replanning. 3. Introduces a Forward Predictive Reasoning module to anticipate risks by generating context-aware safety predicates from long-term memory and observations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/adb68be6c6803ce76bf0036925bc1f629db0f2d1ae9be491b5ab0a450b37d1e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/adb68be6c6803ce76bf0036925bc1f629db0f2d1ae9be491b5ab0a450b37d1e5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the vulnerability of vision-language model-driven embodied agents to hazardous instructions in dynamic environments. It proposes RoboSafe, a runtime safety system that uses hybrid reasoning with backward reflection and forward prediction to generate executable safety logic. Experiments show RoboSafe significantly reduces hazardous actions while maintaining task performance, and its practicality is validated on physical robots.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [image-text retrieval], [event-centric entity extraction, BM25, BEiT-3, two-stage retrieval]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dao Sy Duy Minh, Huynh Trung Kiet, Nguyen Lam Phu Quy, Phu-Hoa Pham, Tran Chi Nguyen</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science - VNUHCM</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21221" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21221</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval" target="_blank" rel="noopener noreferrer" class="">https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a lightweight two-stage retrieval pipeline for event-based image retrieval. 2. Leverages event-centric entity extraction to incorporate temporal and contextual signals for efficient candidate filtering. 3. Combines BM25-based filtering with BEiT-3 reranking to achieve high accuracy on the OpenEvents benchmark.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3fccaf1dfde41ddfe9c023d8a1f41a9f87c4a0899f25d8a475702d3f368a129_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3fccaf1dfde41ddfe9c023d8a1f41a9f87c4a0899f25d8a475702d3f368a129_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of retrieving images from natural language descriptions in complex, real-world scenarios. It proposes a two-stage method that first filters candidates using BM25 on extracted event entities, then reranks them with a BEiT-3 model. The approach significantly outperforms prior baselines on the OpenEvents benchmark, demonstrating the effectiveness of combining lightweight entity guidance with deep multimodal modeling.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [llm security], [jailbreaking, malicious code generation, prompt engineering, time-division selection, security alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21236" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21236</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SPELL, a novel testing framework specifically designed to evaluate security alignment weaknesses in LLMs for malicious code generation. 2. Introduces a time-division selection strategy to systematically construct jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset. 3. Conducts extensive evaluation across multiple advanced code models and real-world tools, revealing significant security gaps and providing insights for improving AI safety.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the security risk of LLMs being exploited to generate malicious code, a gap in existing jailbreaking research. It proposes the SPELL framework, which uses a time-division strategy to construct effective jailbreaking prompts. The evaluation shows high attack success rates across several models, revealing critical vulnerabilities in current AI safety alignments for code generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Improving the Convergence Rate of Ray Search Optimization for Query-Efficient Hard-Label Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [adversarial attacks], [hard-label black-box attacks, query efficiency, ray search optimization, Nesterov&#x27;s Accelerated Gradient, momentum-based optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinjie Xu, Shuyu Cheng, Dongwei Xu, Qi Xuan, Chen Ma</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University of Technology, Binjiang Institute of Artificial Intelligence, ZJUT, JQ Investments</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21241" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21241</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/machanic/hard_label_attacks" target="_blank" rel="noopener noreferrer" class="">https://github.com/machanic/hard_label_attacks</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed ARS-OPT, a momentum-based algorithm inspired by Nesterov&#x27;s Accelerated Gradient to accelerate the convergence of ray search in hard-label attacks. 2. Introduced PARS-OPT, which further enhances ARS-OPT by incorporating surrogate-model priors into the gradient estimation. 3. Provided theoretical convergence guarantees for the proposed methods and demonstrated superior query efficiency over 13 state-of-the-art approaches on ImageNet and CIFAR-10.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/302b574932ba227c13854e5c9c2cab3d7cf8f1ed29ee145fbc73062632304cd4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/302b574932ba227c13854e5c9c2cab3d7cf8f1ed29ee145fbc73062632304cd4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high query cost of hard-label black-box adversarial attacks by optimizing ray search. The authors propose ARS-OPT, a momentum-based algorithm, and its enhanced version PARS-OPT, which uses surrogate-model priors, to accelerate convergence. Experiments show the methods outperform 13 existing approaches in query efficiency on standard datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [embodied ai], [scene graph, vision language model, dynamic planning, memory graph, graph augmentation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anatoly O. Onishchenko, Alexey K. Kovalev, Aleksandr I. Panov</p>
</li>
<li class="">
<p><strong>institution:</strong> MIRAI, Cognitive AI Systems Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21243" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21243</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://lookplangraph.github.io/" target="_blank" rel="noopener noreferrer" class="">https://lookplangraph.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LookPlanGraph, a method for embodied instruction following that dynamically updates a scene graph during execution using a Vision Language Model to verify object priors and discover new entities. 2. Introduces the GraSIF (Graph Scenes for Instruction Following) dataset with an automated validation framework, comprising 514 tasks from existing benchmarks. 3. Demonstrates superior performance over static scene graph methods in simulated environments with changed object positions and shows practical applicability in real-world experiments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39706723670e257f6d0916c7c37badacde760a1f6d3061d011d8c22fa4f29bea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39706723670e257f6d0916c7c37badacde760a1f6d3061d011d8c22fa4f29bea_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of LLM-based embodied agents failing in dynamic environments due to reliance on pre-built, static scene graphs. It proposes LookPlanGraph, a method that continuously augments a memory graph with real-time visual observations from a VLM to verify and discover objects during plan execution. Experiments show it outperforms static graph methods in simulated and real-world settings, and a new dataset (GraSIF) is introduced for evaluation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [educational technology], [learning analytics, correlation analysis, text mining, student perceptions, human-ai interaction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Bologna</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21246</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Investigated the interrelationships of four key learning factors (experience, clarity, comfort, motivation) in AI-augmented education, a gap in prior research. 2. Revealed a developmental moderator by comparing middle and high school students, finding holistic vs. differentiated evaluation patterns between age groups. 3. Established a foundation for age-specific AI integration strategies by showing perception dimensions actively mediate learning and their structure varies with developmental stage.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37485735380aa9bf03e242b5a0fe4f8958c120a691a693af44376fb7f27c2b0b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37485735380aa9bf03e242b5a0fe4f8958c120a691a693af44376fb7f27c2b0b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study investigates how key learning factors relate to each other in AI-augmented programming education for middle and high school students. Using a multimethod analysis combining correlation analysis and text mining on classroom data, it finds that middle school students evaluate AI tools holistically, while high school students assess different factors independently. The conclusion is that the structure of student perceptions is moderated by developmental stage, which should inform age-appropriate AI integration strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [document question answering], [Tree-LSTM, Memory Augmented Neural Network (MANN), Retrieval Augmented Generation (RAG), Parameter Efficiency, Fact Extraction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Divij Dudeja, Mayukha Pal</p>
</li>
<li class="">
<p><strong>institution:</strong> ABB Ability Innovation Center, Indian Institute of Information Technology, Nagpur</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21280</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a hierarchical, syntax-aware fact extractor (Grammarian Tree-LSTM) to parse engineering manuals into structured subject-relation-object triples., 2. Proposes a compact, indexed memory system (MANN) to store and retrieve extracted facts as vectors, enabling efficient knowledge access., 3. Designs a dual-mode inference system combining a fast path for known documents and a dynamic RAG-assisted path for new uploads, reducing hallucinations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fe5f40637f711007d6bb6875182fa80072536380614c5e93c7c4f5cf8dc2232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fe5f40637f711007d6bb6875182fa80072536380614c5e93c7c4f5cf8dc2232_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of accurately answering questions from dense engineering manuals, where standard small language models fail. It proposes SMART, a structured model that hierarchically extracts facts, stores them in an indexed memory, and uses a transformer to generate answers from retrieved facts. The result is a parameter-efficient model that achieves higher accuracy with fewer parameters and reduced hallucinations compared to baselines like GPT-2.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Model Merging via Multi-Teacher Knowledge Distillation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [model merging], [model merging, knowledge distillation, PAC-Bayes, sharpness-aware minimization, multi-task learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Seyed Arshan Dalili, Mehrdad Mahdavi</p>
</li>
<li class="">
<p><strong>institution:</strong> The Pennsylvania State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21288" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21288</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/arshandalili/SAMerging" target="_blank" rel="noopener noreferrer" class="">https://github.com/arshandalili/SAMerging</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Establishes a novel flatness-aware PAC-Bayes generalization bound for model merging, introducing a &quot;cross-task heterogeneity&quot; term. 2. Frames model merging as multi-teacher knowledge distillation on scarce unlabeled data, showing minimizing student-teacher KL divergence tightens the risk bound. 3. Proposes SAMerging, a method that operationalizes the objective using Sharpness-Aware Minimization (SAM) to find flat minima.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edfb41aaef41e719d5724fa70ca9022ddcf1e1c683791b3bd1d929286795c62_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edfb41aaef41e719d5724fa70ca9022ddcf1e1c683791b3bd1d929286795c62_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of theoretical understanding in model merging by framing it as multi-teacher knowledge distillation and deriving a PAC-Bayes generalization bound. It proposes SAMerging, a method that uses Sharpness-Aware Minimization to optimize the merging process based on this theory. The method achieves state-of-the-art performance on vision and NLP benchmarks with high data efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Measuring all the noises of LLM Evals</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [LLM evaluation, statistical noise, paired analysis, prediction variance, data variance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sida Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> FAIR at Meta</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21326" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21326</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Clearly defines and measures three types of noise (prediction, data, total) in LLM evaluations using the law of total variance. 2. Proposes the &quot;all-pairs paired method&quot; to apply paired statistical analysis across all model pairs for increased statistical power. 3. Empirically reveals that total noise is predictable per evaluation and that prediction noise typically dominates data noise, enabling more effective significance testing.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa15912febac5bc93aec8d1b8870feaf16ae89016c37e24c26550d053d396fec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa15912febac5bc93aec8d1b8870feaf16ae89016c37e24c26550d053d396fec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of statistical noise in Large Language Model (LLM) evaluations. It proposes an &quot;all-pairs paired method&quot; to measure prediction, data, and total noise across model pairs. The key findings are that each evaluation benchmark has a characteristic noise level and that reducing prediction noise through averaging can significantly improve the detection of performance differences.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [code retrieval], [Pooling by Multihead Attention (PMA), contrastive learning, code embedding, MTEB-Code, Qwen-2.5-Coder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Ant Group, Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21332" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21332</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/codefuse-ai/CodeFuse-Embeddings" target="_blank" rel="noopener noreferrer" class="">https://github.com/codefuse-ai/CodeFuse-Embeddings</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a Pooling by Multihead Attention (PMA) module to generate sequence embeddings from token embeddings, effectively utilizing the LLM&#x27;s causal representations. 2. The PMA module aggregates information from all tokens in a sequence, overcoming the information bottleneck of traditional EOS-based sequence embeddings. 3. The approach supports flexible adaptation of embedding dimensions, serving as an alternative to Multi-Representation Learning (MRL).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27c6e6ad01eacb3bd759d1aafa323cd3f72410efd901b1df691e709d8fbe3a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27c6e6ad01eacb3bd759d1aafa323cd3f72410efd901b1df691e709d8fbe3a4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces C2LLM, a family of code embedding models built on Qwen-2.5-Coder backbones. It proposes a novel Pooling by Multihead Attention (PMA) module to create better sequence embeddings for code retrieval. The models, trained on three million data points, achieve state-of-the-art performance on the MTEB-Code benchmark, with the 7B version ranking first overall.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [diffusion models], [Denoising Entropy, Masked Diffusion Models, decoding path optimization, predictive uncertainty, non-autoregressive generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Westlake University, University of Chicago</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21336</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/LINs-lab/DenoisingEntropy" target="_blank" rel="noopener noreferrer" class="">https://github.com/LINs-lab/DenoisingEntropy</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalized the problem of decoding path sensitivity in Masked Diffusion Models (MDMs) by introducing the concept of cumulative Path Uncertainty. 2. Proposed Denoising Entropy, a novel, computable metric to quantify predictive uncertainty along a generative path. 3. Developed two entropy-guided algorithms (post-hoc selection and real-time guidance) to optimize the decoding path and improve generation quality.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4480eb4fa3d14900373effb4e74dd207b42c650b50de1044a2cad8b4036e465f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4480eb4fa3d14900373effb4e74dd207b42c650b50de1044a2cad8b4036e465f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that the flexible generation of Masked Diffusion Models (MDMs) leads to variable output quality due to the chosen decoding order. To address this, it introduces Denoising Entropy to measure path uncertainty and proposes two algorithms that use this metric to guide the decoding process. Experiments show these methods significantly improve generation accuracy on reasoning, planning, and code tasks, turning uncertainty into an advantage.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] A Physics Informed Neural Network For Deriving MHD State Vectors From Global Active Regions Observations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [astro-physics, solar physics, magnetohydrodynamics], [Physics-Informed Neural Network (PINN), MagnetoHydroDynamic Shallow-Water Tachocline (MHD-SWT), solar active regions (ARs), toroidal bands (toroids), state-vector reconstruction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Subhamoy Chatterjee, Mausumi Dikpati</p>
</li>
<li class="">
<p><strong>institution:</strong> Southwest Research Institute, High Altitude Observatory (NSF-NCAR)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20747" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20747</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes PINNBARDS, a novel Physics-Informed Neural Network framework to derive the initial MHD state-vector for solar tachocline models from surface observations of active region distributions. 2. Demonstrates the method&#x27;s ability to converge to physically consistent solutions that match observed toroidal band patterns, specifically using data from the Feb-14-2024 SDO/HMI synoptic map. 3. Explores the parameter space to constrain key physical properties, finding optimal agreement with observations for toroidal field strengths of 20–30 kG and a bandwidth of ~10 degrees, which is consistent with low-order longitudinal mode excitation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64164e9d078622b42b01e54f9efaeb57ab61d047c881403541551b016e24827e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64164e9d078622b42b01e54f9efaeb57ab61d047c881403541551b016e24827e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of initializing solar magnetohydrodynamic models for predicting flare-producing active regions, which requires a full state-vector not provided by surface observations. The authors develop PINNBARDS, a Physics-Informed Neural Network that uses observed toroidal band patterns and the governing MHD equations to reconstruct the necessary initial state-vector for the tachocline. Their analysis identifies optimal physical parameters (20-30 kG field strength) that best match observations, providing a novel pathway for weeks-ahead solar activity prediction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] GenTSE: Enhancing Target Speaker Extraction via a Coarse-to-Fine Generative Language Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [speech separation], [target speaker extraction, generative language model, coarse-to-fine, exposure bias, direct preference optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haoyang Li, Xuyi Zhuang, Azmat Adnan, Ye Ni, Wei Rao, Shreyas Gopal, Eng Siong Chng</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, Southeast University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20978</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes GenTSE, a fully generative two-stage decoder-only language model architecture for target speaker extraction, separating coarse semantic token prediction from fine acoustic token generation. 2. Introduces a Frozen-LM Conditioning training strategy to mitigate exposure bias by conditioning models on their own past predictions from earlier checkpoints. 3. Employs Direct Preference Optimization to better align the model&#x27;s outputs with human perceptual preferences.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2e6714f10d4ca9cf7e6cc6ddc5eea2048c365e1e206f97988dcc13bab4d72ef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2e6714f10d4ca9cf7e6cc6ddc5eea2048c365e1e206f97988dcc13bab4d72ef_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces GenTSE, a novel generative language model approach for target speaker extraction that uses a two-stage, coarse-to-fine process to generate speech. The method addresses exposure bias with a specific training strategy and aligns outputs with human preferences using DPO. Experiments show it outperforms previous LM-based systems in speech quality, intelligibility, and speaker consistency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] PhononBench<!-- -->:A<!-- --> Large-Scale Phonon-Based Benchmark for Dynamical Stability in Crystal Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [materials informatics], [dynamical stability, phonon spectrum, crystal generation, benchmark, MatterSim]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiao-Qi Han, Ze-Feng Gao, Peng-Jie Guo, Zhong-Yi Lu</p>
</li>
<li class="">
<p><strong>institution:</strong> Renmin University of China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21227" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21227</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/xqh19970407/PhononBench" target="_blank" rel="noopener noreferrer" class="">https://github.com/xqh19970407/PhononBench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced PhononBench, the first large-scale benchmark for evaluating the dynamical stability of AI-generated crystal structures. 2. Leveraged the MatterSim interatomic potential to perform efficient, DFT-level phonon calculations on over 100k generated crystals, revealing a widespread deficiency in current models&#x27; ability to produce dynamically stable structures. 3. Identified and released a substantial dataset of 28,119 phonon-stable generated crystals, providing a valuable resource for future materials discovery.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5409c19ccb89ace0c03a71117cfd438b28def78d75777b331d87da44f49b7230_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5409c19ccb89ace0c03a71117cfd438b28def78d75777b331d87da44f49b7230_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces PhononBench, a benchmark that uses the MatterSim potential to efficiently evaluate the dynamical stability of AI-generated crystals. The analysis of over 100k structures from six leading models shows that current generative models perform poorly at ensuring dynamical stability, with an average success rate of only 25.83%. The work highlights a critical limitation in the field and provides a benchmark and a pool of stable candidate structures for future development.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251225] Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [large language models], [scaling laws, economic productivity, agentic workflows, compute scaling, algorithmic progress]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ali Merali</p>
</li>
<li class="">
<p><strong>institution:</strong> Yale University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21316" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21316</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Derives empirical scaling laws linking LLM training compute to professional productivity gains. 2. Quantifies the relative contributions of increased compute (56%) versus algorithmic progress (44%) to annual productivity improvements. 3. Identifies a significant disparity in productivity gains between non-agentic analytical tasks and agentic workflows requiring tool use.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f148c34bb4d8aa66926afe66d00135fb826ae28f1253bfed833d9ff39c8b046d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f148c34bb4d8aa66926afe66d00135fb826ae28f1253bfed833d9ff39c8b046d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the relationship between LLM capabilities and professional productivity through a preregistered experiment with over 500 professionals. It finds that each year of AI progress reduces task time by 8%, driven by both compute and algorithmic scaling, but gains are larger for analytical tasks than for agentic ones. The results suggest continued model scaling could significantly boost U.S. productivity over the next decade.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-30T13:08:39.000Z" itemprop="dateModified">Dec 30, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251215-20251221 (cs.AI)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/daily/csai/20251229-20260104"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">20251229-20260104 (cs.AI)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-22" class="table-of-contents__link toc-highlight">2025-12-22</a></li><li><a href="#2025-12-23" class="table-of-contents__link toc-highlight">2025-12-23</a></li><li><a href="#2025-12-24" class="table-of-contents__link toc-highlight">2025-12-24</a></li><li><a href="#2025-12-25" class="table-of-contents__link toc-highlight">2025-12-25</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>