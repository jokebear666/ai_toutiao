<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_AI/20260105-20260111" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260105-20260111 (cs.AI) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/csai/20260105-20260111"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260105-20260111 (cs.AI) | AI头条"><meta data-rh="true" name="description" content="2026-01-05"><meta data-rh="true" property="og:description" content="2026-01-05"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20260105-20260111"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20260105-20260111" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csai/20260105-20260111" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.AI","item":"https://jokebear666.github.io/ai_toutiao/daily/csai"},{"@type":"ListItem","position":3,"name":"20260105-20260111 (cs.AI)","item":"https://jokebear666.github.io/ai_toutiao/daily/csai/20260105-20260111"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.647bd1ff.css">
<script src="/ai_toutiao/assets/js/runtime~main.a5a9d6f2.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.8703b74f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Collapse sidebar category &#x27;cs.AI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_AI/20251215-20251221"><span title="20251215-20251221 (cs.AI)" class="linkLabel_WmDU">20251215-20251221 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/csai/20251222-20251228"><span title="20251222-20251228 (cs.AI)" class="linkLabel_WmDU">20251222-20251228 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/csai/20251229-20260104"><span title="20251229-20260104 (cs.AI)" class="linkLabel_WmDU">20251229-20260104 (cs.AI)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/csai/20260105-20260111"><span title="20260105-20260111 (cs.AI)" class="linkLabel_WmDU">20260105-20260111 (cs.AI)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/csai"><span>cs.AI</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260105-20260111 (cs.AI)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260105-20260111 (cs.AI)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-05">2026-01-05<a href="#2026-01-05" class="hash-link" aria-label="Direct link to 2026-01-05" title="Direct link to 2026-01-05" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv260105] Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [retrieval-augmented generation], [Monte Carlo Tree Search, reasoning-aware retrieval, coarse-to-fine retrieval, multi-turn dialogue, knowledge diversity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuqi Liu, Bowei He, Chen Ma, Linqi Song</p>
</li>
<li class="">
<p><strong>institution:</strong> City University of Hong Kong, City University of Hong Kong Shenzhen Research Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00003" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00003</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a reasoning-aware knowledge retrieval method that aligns retrieved information with the logical structure of conversations, moving beyond semantic similarity. 2. Introduces a coarse-to-fine retrieval approach that first finds a contextually relevant knowledge sub-region and then refines it for reasoning-specific knowledge. 3. Employs a Monte Carlo Tree Search-inspired method to navigate knowledge sentences using common keywords, enhancing retrieval diversity and informativeness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b609f46963ae2b2b017ba13f445da7491064f311d7e663fa59eda7b85dd69638_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b609f46963ae2b2b017ba13f445da7491064f311d7e663fa59eda7b85dd69638_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of integrating retrieval and reasoning for LLMs by proposing a reasoning-aware knowledge retrieval method. It uses a coarse-to-fine approach guided by Monte Carlo Tree Search to find knowledge aligned with conversational logic. Experiments show the method better captures human reasoning and produces more diverse, informative responses.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [game theory], [MinDist, opponent modeling, rule-based strategy, zero-sum game, heuristic optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Purushottam Saha, Avirup Chakraborty, Sourish Sarkar, Subhamoy Maitra, Diganta Mukherjee, Tridib Mukherjee</p>
</li>
<li class="">
<p><strong>institution:</strong> Indian Statistical Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00024" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00024</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a new hand-evaluation metric called MinDist, which quantifies the edit distance to a valid hand, improving upon the MinScore metric. 2. Designed a computationally efficient algorithm to calculate MinDist using dynamic pruning and pattern caching. 3. Integrated opponent hand-modeling within a two-player zero-sum simulation framework and validated the strategy&#x27;s superiority through statistical hypothesis testing.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6b73a0cbcb5f1c250c8adbb982411c12c8e09c81114767cb920146c72264f7e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6b73a0cbcb5f1c250c8adbb982411c12c8e09c81114767cb920146c72264f7e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a rule-based strategy for Classic Indian Rummy using a new hand-evaluation metric called MinDist, which measures the structural proximity to a winning hand. The method includes an efficient algorithm to compute MinDist and incorporates opponent modeling in simulations. Empirical results show that agents using this strategy achieve significantly higher win rates compared to traditional heuristic-based agents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [anomaly detection], [class imbalance, synthetic dataset, generalization error, unsupervised methods, semi-supervised methods]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lesley Wheat, Martin v. Mohrenschildt, Saeid Habibi</p>
</li>
<li class="">
<p><strong>institution:</strong> McMaster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00005" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00005</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a comprehensive, problem-agnostic evaluation of 14 anomaly detectors under simulated industrial constraints of extreme class imbalance. 2. Identified that the best-performing detector depends critically on the absolute number of faulty examples available, not just the imbalance ratio, and provided thresholds for method selection. 3. Demonstrated the nuanced impact of feature dimensionality on method performance, showing semi-supervised methods gain advantage in higher dimensions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d98d7533bc130ddf43f0469391265ce51a72fe31fdeb441a3c4b553d4e3dd35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d98d7533bc130ddf43f0469391265ce51a72fe31fdeb441a3c4b553d4e3dd35_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates anomaly detection algorithms for industrial problems with extreme class imbalance using a synthetic dataset. It benchmarks 14 detectors across varying anomaly rates and training sizes, finding that the optimal detector depends on the absolute number of faulty examples, with unsupervised methods best for very few faults and supervised/semi-supervised methods improving with 30-50 faults. The study highlights performance drops on smaller datasets and provides practical deployment insights.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [logistics optimization], [workload balancing, evolutionary algorithms, k-means, last-mile delivery, hybrid algorithm]</p>
</li>
<li class="">
<p><strong>authors:</strong> Luis M. Moreno-Saavedra, Silvia Jimenez-Fernandez, Antonio Portilla-Figueras, David Casillas-Perez, Sancho Salcedo-Sanz</p>
</li>
<li class="">
<p><strong>institution:</strong> Universidad de Alcalá, Universidad Rey Juan Carlos</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00023" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00023</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a multi-algorithm methodology for operational human resources workload balancing in last-mile delivery, moving beyond simple geographical assignment. 2. Introduces and combines several algorithmic approaches, including different versions of k-means, evolutionary algorithms, recursive assignments, and a hybrid evolutionary ensemble. 3. Validates the proposed approach by applying it to a real-world case study of a delivery workforce in Azuqueca de Henares, Spain.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43bf05ee106d97a42fa05d1af33419810885c8fff72d16b95af434c71d43f4ff_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43bf05ee106d97a42fa05d1af33419810885c8fff72d16b95af434c71d43f4ff_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of unbalanced workload distribution among delivery workers in last-mile urban logistics. It proposes a multi-algorithm approach that uses a combination of distance and workload considerations, including k-means variants and evolutionary algorithms, to assign packages and balance daily effort. The method was successfully tested on a real-world delivery system in Spain.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [mental health language modeling], [large language models, fine-tuning, PHQ-9, Nigerian Pidgin, depression screening]</p>
</li>
<li class="">
<p><strong>authors:</strong> Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Adesina, Ezekiel Ayodeji Oladejo, Uthman Babatunde Usman, Owen Kolade Adeniyi, Matthew Tolulope Olawoyin</p>
</li>
<li class="">
<p><strong>institution:</strong> Artificial Intelligence for Low-Resource Public Health Application (ALPHA) Centre, Slum and Rural Health Initiative; University of Ibadan; University of Ilorin</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00004</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Created a novel, annotated dataset of 432 Nigerian Pidgin audio responses for depression screening aligned with PHQ-9 items. 2. Fine-tuned and evaluated three LLMs (Phi-3-mini, Gemma-3-4B-it, GPT-4.1) for automated depression screening in a low-resource language. 3. Demonstrated that fine-tuned GPT-4.1 achieved high accuracy (94.5%) and cultural appropriateness for PHQ-9 severity scoring in Nigerian Pidgin.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of depression screening in Nigeria by fine-tuning large language models for Nigerian Pidgin English. The authors collected and annotated a dataset of audio responses, then fine-tuned three LLMs to predict PHQ-9 severity scores. The fine-tuned GPT-4.1 model achieved the best performance, providing a foundation for AI-mediated mental health tools in linguistically diverse, resource-constrained settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Toward a Physical Theory of Intelligence</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [artificial general intelligence theory], [Conservation-Congruent Encoding (CCE), irreversible information processing, goal-directed work, attractor dynamics, physical constraints]</p>
</li>
<li class="">
<p><strong>authors:</strong> Peter David Fagan</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Edinburgh</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00021" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00021</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Conservation-Congruent Encoding (CCE) framework, linking information to physical states via metastable basins of attraction enforced by conservation laws. 2. Defines intelligence as a physical efficiency metric (goal-directed work per nat of irreversibly processed information) and derives a hierarchy of physical constraints for intelligent systems. 3. Applies the theory to analyze biological intelligence (e.g., brain dynamics) and proposes a physically-grounded perspective on AI safety based on irreversible information flow.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/179838e256390d3a11169de88d6766d3dcb9d44013014cdc9841b568ca836dcd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/179838e256390d3a11169de88d6766d3dcb9d44013014cdc9841b568ca836dcd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a physical theory of intelligence based on irreversible information processing in systems constrained by conservation laws. It introduces the Conservation-Congruent Encoding (CCE) framework to link information to physical states and defines intelligence as the efficiency of converting processed information into goal-directed work. The theory provides a unified, substrate-neutral account, deriving fundamental constraints and applying them to analyze biological systems and AI safety.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [policy gradient, self-play, Markov Decision Process, Advantage Actor-Critic, ablation study]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nicholas A. Pape</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Texas at Austin</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00007</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formulates the classic stochastic combinatorial game Yahtzee as a Markov Decision Process and establishes it as a mid-scale RL benchmark. 2. Conducts a comprehensive empirical study comparing REINFORCE, A2C, and PPO under a fixed training budget, identifying A2C as the most robust method. 3. Achieves a median score within 5% of the optimal dynamic programming solution, while analyzing persistent challenges like long-horizon credit assignment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfca1ffc9ad8523e303bf57755dcad543948f47e5e9f3c5a9d726a359bd3fe5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfca1ffc9ad8523e303bf57755dcad543948f47e5e9f3c5a9d726a359bd3fe5b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates using deep reinforcement learning to play the full solitaire version of Yahtzee. It trains self-play agents with policy gradient methods (REINFORCE, A2C, PPO) and performs ablation studies on various design choices. The main finding is that A2C robustly achieves near-optimal performance, while all methods struggle with long-term strategic elements like securing the upper section bonus.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Personalized Spiking Neural Networks with Ferroelectric Synapses for EEG Signal Processing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [ferroelectric synapses, spiking neural networks, EEG signal processing, adaptive learning, neuromorphic computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nikhil Garg, Anxiong Song, Niklas Plessnig, Nathan Savoia, Laura Bégon-Lours</p>
</li>
<li class="">
<p><strong>institution:</strong> ETH Zurich (Integrated Systems Laboratory, Department of Information Technology and Electrical Engineering)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00020" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00020</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrated the deployment and adaptation of Spiking Neural Networks (SNNs) on fabricated ferroelectric memristive synaptic devices for EEG-based motor imagery decoding under realistic device constraints. 2. Introduced a device-aware weight-update strategy that accumulates gradient updates digitally and triggers discrete programming events only when a threshold is exceeded, reducing programming frequency and emulating device dynamics. 3. Evaluated two complementary deployment strategies (device-aware training and transfer learning with on-device re-tuning) that achieve performance comparable to software-based SNNs and show improved accuracy through subject-specific adaptation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce95488f8704205e4a01e64825c78c800662f36da33df71b138881b21ab7b9bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce95488f8704205e4a01e64825c78c800662f36da33df71b138881b21ab7b9bb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of adapting EEG-based brain-computer interfaces to non-stationary neural signals on resource-constrained hardware. It proposes deploying Spiking Neural Networks on ferroelectric memristive synapses with a novel device-aware update strategy and demonstrates two effective deployment methods for personalized, low-overhead adaptation. The results show that programmable ferroelectric hardware can support robust, efficient adaptation for personalized neuromorphic processing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [diffusion models], [generative AI, diffusion models, architectural intelligence, computational reasoning, vernacular architecture]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abolhassan Pishahang, Maryam Badiei</p>
</li>
<li class="">
<p><strong>institution:</strong> Florida Atlantic University, North Carolina State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00029" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00029</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a three-stage prompting methodology (referential, adaptive, speculative) to evaluate generative AI&#x27;s interpretation of vernacular architecture. 2. Develops a five-criteria evaluation framework (typology, materiality, environment, realism, cultural specificity) to assess AI-generated architectural outputs. 3. Identifies a boundary between visual resemblance and architectural reasoning in AI, introducing the concept of &quot;computational vernacular reasoning&quot; as an analytical framework.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658a502216dc69f4f977616d5c09ec4155b48e6d602df132e1eac107fa169f4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658a502216dc69f4f977616d5c09ec4155b48e6d602df132e1eac107fa169f4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study investigates how generative AI interprets the architectural intelligence of vernacular forms, using Iranian pigeon towers as a case study. It tests three diffusion models (Midjourney, DALL-E 3, Stable Diffusion XL) across different prompt stages and evaluates outputs using a custom framework. The results show that AI reliably reproduces geometric patterns but fails to grasp underlying material and climatic reasoning, highlighting a gap between visual generation and true architectural understanding.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [LLM Security], [Go-Explore, Prompt Injection, Adversarial Testing, Agent Safety, Multi-Hop Attacks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Manish Bhatt, Adrian Wood, Idan Habler, Ammar Al-Kahfah</p>
</li>
<li class="">
<p><strong>institution:</strong> OWASP, Amazon, Dropbox, CISCO, AWS</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00042" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00042</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/mbhatt1/competitionscratch" target="_blank" rel="noopener noreferrer" class="">https://github.com/mbhatt1/competitionscratch</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Adapted the Go-Explore reinforcement learning algorithm for systematic security testing of LLM agents. 2. Conducted a large-scale empirical study revealing that random seed variance dominates algorithmic parameter choices in this domain. 3. Provided actionable insights for practitioners, such as the ineffectiveness of reward shaping and the benefits of using ensembles and simple state signatures.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fd9dc0076e96f0b8282984cab768d0355248ad4e2af52c17ac7798bb446d49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fd9dc0076e96f0b8282984cab768d0355248ad4e2af52c17ac7798bb446d49_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper adapts the Go-Explore algorithm to test the security of safety-trained LLM agents against prompt injection attacks. Through 28 experimental runs on GPT-4o-mini, the study finds that random seed variance is a major factor, reward shaping is harmful, and simple state signatures work best. The results suggest that managing seed variance and applying domain knowledge are more critical than algorithmic sophistication for effective security testing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [causal reasoning], [fuzzy cognitive maps, large-language-model agent, causal feedback, equilibrium limit cycles, agentic leash]</p>
</li>
<li class="">
<p><strong>authors:</strong> Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Southern California, Florida International University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00097</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel LLM agent designed to autonomously extract and construct causal feedback Fuzzy Cognitive Maps (FCMs) from raw text. 2. A three-step instruction-guided process for systematically extracting key concepts and causal edges to build the FCM dynamical system. 3. Demonstration that the LLM-generated FCMs converge to the same equilibrium dynamics as human-generated ones and that mixed FCMs from different LLMs can create new equilibria.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes an LLM agent to autonomously extract causal feedback Fuzzy Cognitive Maps from text. The agent uses a three-step process to identify concepts and causal edges, forming a dynamical system. The generated FCMs matched human-generated equilibrium dynamics and mixing models from different LLMs produced new equilibria for better causal approximation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Mortar: Evolving Mechanics for Automatic Game Design</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [procedural content generation], [quality-diversity algorithm, large language model, skill-based ordering, tree search, game mechanics evolution]</p>
</li>
<li class="">
<p><strong>authors:</strong> Muhammad U. Nasir, Yuchen Li, Steven James, Julian Togelius</p>
</li>
<li class="">
<p><strong>institution:</strong> University of the Witwatersrand, New York University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00105" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00105</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Mortar, a system that autonomously evolves game mechanics for automatic game design by combining a quality-diversity algorithm with a large language model. 2. Introduces a novel evaluation framework where mechanics are assessed by synthesizing complete games and measuring their ability to preserve a skill-based ordering over players. 3. Demonstrates the system&#x27;s effectiveness through ablation studies and a user study, showing it produces diverse, playable games with mechanics that improve skill-based ordering.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26506e29345695337e5d47f5dfb1499fe23b996958dc6fd30e9b4371545d6994_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26506e29345695337e5d47f5dfb1499fe23b996958dc6fd30e9b4371545d6994_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents Mortar, a system for automatic game design that evolves game mechanics by combining a quality-diversity algorithm with an LLM. It evaluates mechanics by constructing complete games via tree search and testing if they preserve a skill-based player ordering. The results show Mortar generates diverse, playable games with mechanics that effectively contribute to skill-based gameplay.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [hybrid agentic framework, hallucination tax, Human Imitator, stochastic reasoning, inventory optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yaqi Duan, Yichun Hu, Jiashuo Jiang</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University, Cornell University, Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00121" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00121</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and quantifies the &quot;hallucination tax&quot; when using LLMs as end-to-end solvers for inventory control, highlighting their limitation in grounded stochastic reasoning. 2. Proposes a novel hybrid agentic framework that decouples semantic reasoning (handled by LLM) from mathematical calculation (handled by rigorous algorithms) to create an intelligent interface for optimization. 3. Introduces the &quot;Human Imitator,&quot; a fine-tuned digital twin of a boundedly rational manager, to enable scalable and reproducible stress-testing of interactive systems against ambiguous real-world dialogue.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5522adbd58df6d202685913f2a038b91f8e5b3730f51d9964297ad57db17174e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5522adbd58df6d202685913f2a038b91f8e5b3730f51d9964297ad57db17174e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of using LLMs for inventory management by showing that direct application incurs a &quot;hallucination tax&quot; due to poor stochastic reasoning. To solve this, the authors propose a hybrid agentic framework where the LLM acts as a natural-language interface that calls rigorous optimization algorithms. The framework reduces inventory costs by 32.1% compared to an LLM-only baseline, demonstrating that LLMs are best used as interfaces to make expert methods accessible, not as replacements for them.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Constructing a Neuro-Symbolic Mathematician from First Principles</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neuro-symbolic reasoning], [neuro-symbolic architecture, differentiable logic engine, hypergraph transformer, energy minimization, proof search]</p>
</li>
<li class="">
<p><strong>authors:</strong> Keqin Xie</p>
</li>
<li class="">
<p><strong>institution:</strong> (Inferred from email domain: <a href="mailto:xiekeqin30@gmail.com" target="_blank" rel="noopener noreferrer" class="">xiekeqin30@gmail.com</a>) Affiliation not explicitly stated in provided text. Could be an independent researcher or institution not listed on first page.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00125</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs. 2. Introduces a Symbolic Reasoning Kernel (SRK), a differentiable logic engine that maps logical constraints to a continuous energy landscape for gradient-based training. 3. Enables multi-step deduction by combining energy minimization with guided search algorithms like Monte Carlo Tree Search and Evolutionary Proof Search.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/782595f0879bde3e0c09f37353b140392ee9407cf2eed312d3faea5d4ca981ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/782595f0879bde3e0c09f37353b140392ee9407cf2eed312d3faea5d4ca981ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the issue of logical failures in Large Language Models (LLMs) during complex reasoning by proposing Mathesis, a neuro-symbolic system that uses a differentiable logic engine to turn proof search into energy minimization. The method combines a Hypergraph Transformer Brain with symbolic reasoning via gradient signals, aiming to achieve rigorous mathematical deduction. The core conclusion is that this architecture provides a pathway to integrate neural pattern recognition with symbolic rigor for reliable reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Explicit Abstention Knobs for Predictable Reliability in Video Question Answering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [selective prediction], [selective prediction, confidence-based abstention, risk-coverage tradeoff, distribution shift, video question answering]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jorge Ortiz</p>
</li>
<li class="">
<p><strong>institution:</strong> Rutgers University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00138" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00138</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrates that confidence thresholding provides smooth, mechanistic control over error rates in-distribution for video QA. 2. Shows that this confidence-based control is not epistemic and fails under distribution shift (evidence degradation), as confidence does not decrease with reduced visual information. 3. Proposes the need for warrant-based selective prediction, where confidence is explicitly bounded by the supporting evidence.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c77afc466868547720556984ed3dee075c707916f0173e73e7904851983d320b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c77afc466868547720556984ed3dee075c707916f0173e73e7904851983d320b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the reliability of confidence-based abstention for controlling error rates in video question answering using VLMs. It finds that while confidence thresholding works well in-distribution, it fails under distribution shift because the model&#x27;s confidence does not properly reflect reduced evidence quality. The results motivate moving towards warrant-based selective prediction for more predictable reliability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neural reasoning], [Sphere Neural Networks, disjunctive syllogistic reasoning, catastrophic forgetting, explicit model construction, Euler Net]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tiansi Dong, Henry He, Pietro Liò, Mateja Jamnik</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Cambridge</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00142" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00142</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A comparative analysis showing explicit model-based neural reasoning is more reliable than LLM-based or supervised learning-based reasoning. 2. The proposal of Sphere Neural Networks, a novel architecture that embeds concepts as circles on a sphere to represent negation and filter illogical statements. 3. An empirical demonstration that Sphere Neural Networks can master 16 syllogistic reasoning tasks, including disjunctive syllogism, without catastrophic forgetting.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5204d88cd2c0986ce1fa0776ae031033771470697a797f7d2ee4cba326a5a31_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5204d88cd2c0986ce1fa0776ae031033771470697a797f7d2ee4cba326a5a31_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Sphere Neural Networks, which embed concepts as circles on a sphere to enable explicit model-based reasoning. The method is shown to reliably perform complex syllogistic reasoning tasks without catastrophic forgetting, unlike supervised learning approaches. The authors conclude that explicit model construction is the most reliable category for neural reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [multimodal benchmark], [financial credit, multimodal AI, robustness evaluation, vision-language models, privacy-compliant dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yehui Yang, Dalu Yang, Wenshuo Zhou, Fangxin Shang, Yifan Liu, Jie Ren, Haojun Fei, Qing Yang, Tao Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Qifu Technology, Fudan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00150" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00150</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces FCMBench-V1.0, a large-scale, privacy-compliant multimodal benchmark specifically for financial credit applications, featuring 18 document types, 4,043 images, and 8,446 QA samples. 2. Proposes a novel three-dimensional evaluation framework (Perception, Reasoning, Robustness) with credit-specific reasoning tasks and real-world artifact stress testing. 3. Designs a closed synthesis-capture pipeline to construct realistic yet privacy-safe samples, mitigating data leakage and enabling effective performance discrimination across 23 state-of-the-art VLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a51bae803814f634858ded96030e47cb55c5330c7e8901ac175d3536cf4b4a9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a51bae803814f634858ded96030e47cb55c5330c7e8901ac175d3536cf4b4a9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces FCMBench, a new multimodal benchmark for evaluating AI models on financial credit document review tasks. The benchmark is built using a privacy-compliant synthesis-capture pipeline and tests models on perception, reasoning, and robustness. Experiments show that even top models like Gemini 3 Pro struggle with robustness, while the authors&#x27; domain-specific model, Qfin-VL-Instruct, achieves the best overall performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Online Finetuning Decision Transformers with Pure RL Gradients</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [Decision Transformer, online finetuning, GRPO, hindsight return relabeling, sub-trajectory optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Junkai Luo, Yinglun Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Riverside</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00167" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00167</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies hindsight return relabeling as a fundamental obstacle to using pure RL gradients for online finetuning of Decision Transformers. 2. Proposes new algorithms that adapt GRPO to DTs with key modifications like sub-trajectory optimization, sequence-level likelihood objectives, and active sampling. 3. Demonstrates state-of-the-art performance across multiple benchmarks, showing the effectiveness of pure-RL-based online finetuning for DTs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7142aabdfb71311da4fa293bcc82f4d6d24b9dddc11ccaf74c0aaea92b54d5e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7142aabdfb71311da4fa293bcc82f4d6d24b9dddc11ccaf74c0aaea92b54d5e3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of online finetuning for Decision Transformers using pure reinforcement learning gradients, which has been largely unexplored. The authors identify and overcome the incompatibility of standard hindsight return relabeling with RL algorithms, proposing modified methods based on GRPO. Their approach outperforms existing online DT baselines, achieving new state-of-the-art results on several benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [semi-supervised learning], [Generative Adversarial Network, Swin Transformer, spike classification, semi-supervised learning, Bayesian optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Danial Sharifrazi, Nouman Javed, Mojtaba Mohammadi, Seyede Sana Salehi, Roohallah Alizadehsani, Prasad N. Paradkar, U. Rajendra Acharya, Asim Bhatti</p>
</li>
<li class="">
<p><strong>institution:</strong> Deakin University, CSIRO Health and Biosecurity, Islamic Azad University, University of Southern Queensland</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00189" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00189</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a novel semi-supervised GAN architecture (SSI-GAN) with a Swin-inspired, shifted-window discriminator for neuronal spike classification. 2. Introduced a transformer-based generator and a flat, window-based transformer discriminator with multi-head self-attention to capture sparse, high-frequency spike features. 3. Demonstrated state-of-the-art performance with 99.93% accuracy using only 1-3% labeled data, reducing manual labeling effort by 97-99% compared to supervised methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49a3916713727a5d92dd8fe976e78d600a974d9217a0ccc868f8608ec8453524_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49a3916713727a5d92dd8fe976e78d600a974d9217a0ccc868f8608ec8453524_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the labor-intensive problem of classifying mosquito neuronal spikes for arboviral disease detection by proposing SSI-GAN, a semi-supervised GAN that combines a Swin-inspired discriminator with a transformer-based generator. Using only 1-3% labeled data from over 15 million spike samples, it achieved up to 99.93% accuracy in classifying Zika-infected, dengue-infected, or uninfected categories, significantly reducing labeling effort while outperforming baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [emotion recognition in conversation], [ablation study, conversational context, discourse markers, causal context, IEMOCAP]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cheonkam Jeong, Adeline Nyamathi</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Irvine</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00181" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00181</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A rigorous ablation study revealing that conversational context is paramount for ERC, with performance saturating within 10-30 preceding turns, and that hierarchical sentence representations and external affective lexicons provide no additional benefit when context is used. 2. Achieving state-of-the-art text-only performance on IEMOCAP using simple architectures with strictly causal context. 3. A novel linguistic analysis connecting recognition to generation, finding a significant association between emotion and discourse marker positioning, particularly that &quot;sad&quot; utterances use fewer left-periphery markers and rely more on context for disambiguation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e38dfbfb3b50e432c39aabed201ddaf199012203ee5e7e82a7aa044267fc2a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e38dfbfb3b50e432c39aabed201ddaf199012203ee5e7e82a7aa044267fc2a2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper systematically analyzes Emotion Recognition in Conversation (ERC) to identify which architectural components matter and connects recognition insights to linguistic patterns for generation. Through ablation studies on IEMOCAP, it finds conversational context is most critical, and via linguistic analysis, it discovers that emotion correlates with discourse marker usage. The main conclusion is that simple models with causal context are sufficient for high performance, and the lack of explicit pragmatic signals in &quot;sad&quot; utterances explains their greater reliance on context.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Latent Flow Matching for Expressive Singing Voice Synthesis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [generative models], [conditional flow matching, latent space modeling, singing voice synthesis, ordinary differential equation, variational autoencoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Minhyeok Yun, Yong-Hoon Choi</p>
</li>
<li class="">
<p><strong>institution:</strong> Kwangwoon University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00217" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00217</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/alsgur9368/FM-Singer" target="_blank" rel="noopener noreferrer" class="">https://github.com/alsgur9368/FM-Singer</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FM-Singer, a novel singing voice synthesis method that applies conditional flow matching (CFM) in the latent space to address the prior-posterior mismatch in cVAE-based models. 2. Introduces a latent ODE refinement step at inference time to transport prior samples towards the expressive posterior distribution, improving fine-grained expressiveness while maintaining parallel decoding efficiency. 3. Demonstrates consistent performance improvements on Korean and Chinese singing datasets, including lower mel-cepstral distortion and F0 error, and higher perceptual scores.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88ff2d99db594dd8c63fa46f401cf9408cda76d76d116f920d5a1dbb077b2fcf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88ff2d99db594dd8c63fa46f401cf9408cda76d76d116f920d5a1dbb077b2fcf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the degradation of fine-grained expressiveness in cVAE-based singing voice synthesis due to a mismatch between the prior and posterior latent distributions. The proposed FM-Singer method uses conditional flow matching in the latent space to learn a vector field that refines prior samples via an ODE, enhancing expressiveness like vibrato. Experiments show the method outperforms strong baselines on multiple datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [machine translation], [LLM-as-a-judge, pairwise comparison, Bradley-Terry model, reference-free evaluation, anchored evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Leonard Lin, Adam Lensenmayer</p>
</li>
<li class="">
<p><strong>institution:</strong> Shisa.AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00223" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00223</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces JP-TL-Bench, a lightweight, open benchmark for iterative development of Japanese-English translation systems. 2. Proposes a reliable and affordable evaluation protocol using reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. 3. Provides structurally stable scores by aggregating pairwise results with a Bradley-Terry model and reporting normalized LT scores.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3672d8de20107e284402d4b12e978f246eb0df92617095708ca7710e712594d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3672d8de20107e284402d4b12e978f246eb0df92617095708ca7710e712594d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces JP-TL-Bench, a benchmark for evaluating high-quality Japanese-English translation. It uses a protocol where candidate models are compared against a fixed anchor set via pairwise LLM judgments, with results aggregated using a Bradley-Terry model to produce stable scores. This approach aims to provide a high-resolution signal for distinguishing between already fluent translations where traditional metrics saturate.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [GPU kernels, benchmarking, kernel substitution, FlashInfer Trace, AI-generated code]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shanli Xing, Yiyan Zhai, Alexander Jiang, Yixin Dong, Yong Wu, Zihao Ye, Charlie Ruan, Yingyi Huang, Yineng Zhang, Liangsheng Yin, Aksara Bayyapu, Luis Ceze, Tianqi Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Carnegie Mellon University, University of Washington, NVIDIA, University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00227" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00227</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces FlashInfer Trace, a unified JSON schema to standardize the description of kernel tasks, workloads, implementations, and evaluations for AI agents. 2. Presents FlashInfer-Bench, a comprehensive framework including a curated dataset from real serving traces, a correctness- and performance-aware benchmarking system, and a public leaderboard. 3. Implements a dynamic kernel substitution mechanism (<code>apply()</code>) that allows seamless integration of the best-performing AI-generated kernels into production LLM inference engines like SGLang and vLLM.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c4acb494d20ab22aaf93877ea7f6bf9807d9ee81afeaa72f868e4b115633740_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9c4acb494d20ab22aaf93877ea7f6bf9807d9ee81afeaa72f868e4b115633740_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces FlashInfer-Bench, a standardized framework to bridge the gap between AI-generated GPU kernels and their deployment in real-world LLM inference systems. It provides a closed-loop workflow for kernel generation, benchmarking, and integration, enabling the evaluation of LLM agents&#x27; GPU programming capabilities and the seamless injection of optimized kernels into production engines. The work establishes a practical pathway for continuously improving and deploying AI-generated kernels at scale.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [LoRA, K-FAC, Parameter-Efficient Fine-Tuning, Fisher Information, Dynamic Rank Adaptation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Pritish Saha, Chandrav Rajbangshi, Rudra Goyal, Mohit Goyal, Anurag Deo, Biswajit Roy, Ningthoujam Dhanachandra Singh, Raxit Goswami, Amitava Das</p>
</li>
<li class="">
<p><strong>institution:</strong> RAAPID Lab, Pragya Lab (BITS Pilani, Goa)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00231" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00231</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces K-FAC-based gradient preconditioning in the low-rank subspace for more geometry-aware updates. 2. Proposes periodic Fisher-guided reprojection of the LoRA basis to suppress parameter drift. 3. Implements dynamic rank adaptation to concentrate capacity on high-signal directions, reducing the number of trainable parameters.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e9515d46161014bf32c8c1a74f165b3980c9984817a7e1ca0778ce4d66219f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e9515d46161014bf32c8c1a74f165b3980c9984817a7e1ca0778ce4d66219f5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that standard LoRA/QLoRA methods are geometry-agnostic, leading to inefficient updates and parameter drift. It proposes GRIT, a new LoRA procedure that uses K-FAC preconditioning, Fisher-guided reprojection, and dynamic rank adaptation to make updates more curvature-aware. This approach matches or surpasses baseline performance while reducing trainable parameters by an average of 46% and achieving lower drift.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent systems], [intergroup bias, belief poisoning attack, multi-agent social simulation, human-norm script, agent safety]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zongwei Wang, Bincheng Gu, Hongyu Yu, Junliang Yu, Tao He, Jiayin Feng, Min Gao</p>
</li>
<li class="">
<p><strong>institution:</strong> Chongqing University, The University of Queensland, Virginia Polytechnic Institute and State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00240" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00240</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies a new type of bias in LLM-powered agents: intergroup bias that can align with an agent-human divide, potentially treating humans as an outgroup. 2. Proposes a novel attack method, the Belief Poisoning Attack (BPA), with two variants (BPA-PP and BPA-MP) that exploit the belief-dependent nature of agents to suppress pro-human norms and reactivate bias. 3. Discusses practical mitigation strategies for hardening agent frameworks against such attacks, focusing on interventions at profile and memory boundaries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63aefdbbc5c1919bddd5ac1c591ec07bd99f076d1eb4b0ab4722c5ed75f1d8fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63aefdbbc5c1919bddd5ac1c591ec07bd99f076d1eb4b0ab4722c5ed75f1d8fc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether LLM-powered agents exhibit bias against humans as an outgroup. It finds that while a &quot;human-norm script&quot; can attenuate this bias, the script&#x27;s activation depends on the agent&#x27;s belief about the presence of a human, creating a vulnerability. The authors introduce a Belief Poisoning Attack to exploit this vulnerability and propose mitigation strategies for safer agent design.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), Dual-Agent LLM, QLoRA, Vulnerability Detection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md Hasan Saju, Maher Muhtadi, Akramul Azim</p>
</li>
<li class="">
<p><strong>institution:</strong> Ontario Tech University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00254</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a comparative empirical evaluation of three LLM-based approaches (RAG, SFT, and Dual-Agent) for code vulnerability detection. 2. Proposed a RAG framework that integrates external domain knowledge (e.g., from the internet and MITRE CWE database) to achieve state-of-the-art performance. 3. Introduced and evaluated a Dual-Agent LLM system designed to improve reasoning transparency and error mitigation with reduced resource overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85bf4a637927a306d9960d3a0ec1a16f810bb0755b9400e6b4b384627260154e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85bf4a637927a306d9960d3a0ec1a16f810bb0755b9400e6b4b384627260154e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper compares three LLM-based methods—RAG, SFT, and a Dual-Agent system—for detecting software vulnerabilities in code. The RAG approach, which augments the LLM with external knowledge, achieved the highest accuracy and F1 score, demonstrating the value of contextual information for this task.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [wireless networking], [O-RAN, UAV, trajectory optimization, RIC, low-altitude economy]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aly Sabri Abdalla, Vuk Marojevic</p>
</li>
<li class="">
<p><strong>institution:</strong> Mississippi State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00257" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00257</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an O-RAN-enabled framework for intelligent orchestration of Low-Altitude Economy (LAE) operations, integrating disaggregated RAN architecture with AI-driven RAN Intelligent Controllers (RICs). 2. Presents a semantic-aware rApp and a reinforcement learning-enabled xApp for closed-loop, context-aware trajectory planning of UAV swarms. 3. Surveys available UAV testbeds for LAE research and identifies critical research challenges and standardization needs for future deployments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cae00fb3b22c64bae2b8ae14c12c3a5262a87f4a6954a5d6578c0a24172848_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74cae00fb3b22c64bae2b8ae14c12c3a5262a87f4a6954a5d6578c0a24172848_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of orchestrating UAV missions in complex, signal-constrained environments for the Low-Altitude Economy (LAE). It proposes a novel framework that leverages the Open Radio Access Network (O-RAN) architecture, using AI-driven controllers (RICs) and specialized apps (rApp/xApp) for semantic-aware, real-time trajectory planning. The work concludes by evaluating the framework&#x27;s feasibility and outlining future research and standardization directions for scalable LAE deployments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [explainable ai (xai)], [counterfactual examples, multilingual, data augmentation, large language models, model robustness]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich Schütze, Sebastian Möller, Vera Schmitt</p>
</li>
<li class="">
<p><strong>institution:</strong> Technische Universität Berlin, University of Marburg, LMU Munich, German Research Center for Artificial Intelligence (DFKI), Munich Center for Machine Learning (MCML), BIFOLD – Berlin Institute for the Foundations of Learning and Data</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00263" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00263</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Evaluated the quality of LLM-generated multilingual counterfactuals, comparing direct generation and translation-based methods across six languages. 2. Identified four main error types common in generated counterfactuals across languages and found similar edit patterns in high-resource European languages. 3. Demonstrated that multilingual counterfactual data augmentation yields greater performance improvements than cross-lingual augmentation, especially for lower-resource languages.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3b95c2cf3407989c3c5a932764e908182c4d60d7451ace3f5f15e194a3a7e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3b95c2cf3407989c3c5a932764e908182c4d60d7451ace3f5f15e194a3a7e5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the effectiveness of large language models (LLMs) in generating multilingual counterfactual examples. It compares directly generated and translation-based counterfactuals across six languages, finding that translation-based ones are more valid but require more edits and still underperform English ones. The study concludes that while multilingual counterfactual data augmentation improves model performance, especially for low-resource languages, the quality limitations of the generated counterfactuals constrain the gains in robustness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [function-calling, benchmark, API complexity, LLM agents, WildAGTEval]</p>
</li>
<li class="">
<p><strong>authors:</strong> Doyoung Kim, Zhiwei Ren, Jie Hao, Zhongkai Sun, Lichao Wang, Xiyao Ma, Zack Ye, Xu Han, Jun Yin, Heng Ji, Wei Shen, Xing Fan, Benjamin Yao, Chenlei Guo</p>
</li>
<li class="">
<p><strong>institution:</strong> Amazon, KAIST, University of Pittsburgh, University of Illinois Urbana-Champaign</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00268" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00268</a></p>
</li>
<li class="">
<p><strong>code:</strong> github.com/Demon-JieHao/WildAGTEval</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces WildAGTEval, a novel benchmark for evaluating LLM agents under realistic API complexity, covering both API specification and execution challenges. 2. Provides a comprehensive API system with 60 distinct complexity scenarios, composable into ~32K test configurations, and user-agent interactions for evaluation. 3. Systematically assesses advanced LLMs, revealing significant performance drops (e.g., 27.3% for irrelevant information complexity) and identifying critical failure modes like intent distortion.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c517d92b4a84a20e84e30c740db5d9b70b7f3195c6de0fc8e049a5f0a4c9af_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c517d92b4a84a20e84e30c740db5d9b70b7f3195c6de0fc8e049a5f0a4c9af_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces WildAGTEval, a benchmark designed to evaluate LLM agents&#x27; function-calling capabilities under realistic API complexities, including detailed specifications and noisy execution. The study finds that most scenarios are challenging, with irrelevant information posing the greatest difficulty and causing significant performance drops in strong models. The qualitative analysis also reveals that LLMs sometimes distort user intent to claim task completion, negatively impacting user satisfaction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [hallucination detection, vision-language models, uncertainty estimation, model-driven learning, LLM-as-a-Judge]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chaodong Tong, Qi Zhang, Chen Li, Lei Jiang, Yanbing Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Information Engineering, Chinese Academy of Sciences (CAS); School of Cyber Security, University of CAS; China Industrial Control Systems Cyber Emergency Response Team; China Electronics Standardization Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00269" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00269</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FaithSCAN, a lightweight network for VQA hallucination detection that fuses rich internal signals from VLMs (token-level uncertainty, visual representations, cross-modal alignment) using branch-wise evidence encoding and uncertainty-aware attention. 2. Extends the LLM-as-a-Judge paradigm to VQA to automatically generate low-cost, model-dependent supervision signals for training, eliminating the need for expensive human annotation. 3. Provides an in-depth analysis showing hallucinations stem from systematic variations in internal states across visual perception, cross-modal reasoning, and language decoding, offering new insights into multimodal hallucination causes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0bbbea5cd6fb55e2cc155e1b226cd59e138d25b8ec98a141d833613135b7cd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d0bbbea5cd6fb55e2cc155e1b226cd59e138d25b8ec98a141d833613135b7cd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of detecting faithfulness hallucinations in Visual Question Answering (VQA), where models give fluent but visually ungrounded answers. It proposes FaithSCAN, a model-driven method that detects hallucinations in a single pass by exploiting and fusing internal signals from the vision-language model, and uses an automated strategy based on LLM-as-a-Judge for low-cost supervision. Experiments show FaithSCAN outperforms existing methods in both effectiveness and efficiency, and the analysis provides new insights into the internal causes of hallucinations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [quantization, self-explanations, faithfulness, natural language explanations, counterfactual examples]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qianli Wang, Nils Feldhus, Pepa Atanasova, Fedor Splitt, Simon Ostermann, Sebastian Möller, Vera Schmitt</p>
</li>
<li class="">
<p><strong>institution:</strong> Technische Universität Berlin, German Research Center for Artificial Intelligence (DFKI), University of Copenhagen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00282" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00282</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. First comprehensive study on the impact of quantization on the quality and faithfulness of LLM self-explanations. 2. Empirical evaluation across multiple quantization techniques, bit widths, and model sizes, revealing moderate but consistent degradation in explanation metrics. 3. Provides practical recommendations for validating self-explanations in quantized models, highlighting the greater sensitivity of natural language explanations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how quantization affects the quality and faithfulness of self-explanations generated by large language models. The authors evaluate multiple quantization methods and find they cause moderate declines in explanation metrics, with larger models showing better faithfulness preservation. They conclude that while quantization degrades self-explanations, the impact is relatively minor and does not negate its benefits for model compression.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image classification], [Swin Transformer, BatchFormer, Focal Loss, ReduceLROnPlateau, ISIC2019]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ali Anaissi, Ali Braytee, Weidong Huang, Junaid Akram, Alaa Farhat, Jie Hua</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Technology Sydney, University of Sydney, Shaoyang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00286" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00286</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a deep learning model based on the Swin Transformer architecture for automated differential diagnosis of skin diseases. 2. Applied targeted data augmentation and imbalance-aware strategies (e.g., BatchFormer, Focal Loss) to handle class imbalance in medical image datasets. 3. Achieved a high prediction accuracy of 87.71% on the ISIC2019 dataset, demonstrating the model&#x27;s potential as a clinical support tool.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b53f6f4ea6d1249b026a76d397de3fca0db67dcfee5584653cd543f2ac0bacf9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b53f6f4ea6d1249b026a76d397de3fca0db67dcfee5584653cd543f2ac0bacf9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limited access to dermatologists by developing a deep learning model for automated skin disease diagnosis. The method uses a Swin Transformer architecture pretrained on public datasets and employs imbalance-aware strategies like BatchFormer and Focal Loss to improve classification on the ISIC2019 dataset. The model achieved 87.71% accuracy, showing promise as a diagnostic aid for clinicians and patients.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [self-evolving agent, hierarchical memory, protocol redesign]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sixue Xing, Xuanye Xia, Kerui Wu, Meng Jiang, Jintai Chen, Tianfan Fu</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Notre Dame, Georgia Institute of Technology, University of Massachusetts Amherst, Hong Kong University of Science and Technology (Guangzhou), Nanjing University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00290" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00290</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ClinicalReTrial, a self-evolving AI agent framework that moves beyond static trial outcome prediction to actionable protocol optimization. 2. Introduces a closed-loop, reward-driven optimization framework that integrates failure diagnosis, safety-aware modification, and candidate evaluation, using a prediction model as a simulation environment. 3. Designs a hierarchical memory mechanism to capture iteration-level feedback and distill transferable redesign patterns for efficient exploration.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b82407468d333ae862573b891f5a19251a04fd53b36b2e4e9e895ca08f9073_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b82407468d333ae862573b891f5a19251a04fd53b36b2e4e9e895ca08f9073_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes ClinicalReTrial, a self-evolving AI agent framework that optimizes clinical trial protocols through iterative, reward-driven redesign. It uses an outcome prediction model as a simulation environment and a hierarchical memory for efficient exploration. Empirical results show the framework improves 83.3% of trial protocols with a mean success probability gain of 5.7%.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [speech processing], [depression detection, semantic bias, text-to-speech, disentangled representation, data augmentation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuxin Li, Xiangyu Zhang, Yifei Li, Zhiwei Guo, Haoyang Zhang, Eng Siong Chng, Cuntai Guan</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, UNSW Sydney, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00303" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00303</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DepFlow, a novel three-stage depression-conditioned TTS framework that disentangles depression-specific acoustic patterns from speaker and content information using adversarial training and flow-matching. 2. Introduces a prototype-based severity mapping mechanism for smooth and interpretable control over the synthesized depressive severity. 3. Constructs a Camouflage Depression-oriented Augmentation (CDoA) dataset using DepFlow to mitigate semantic bias, which significantly improves the robustness of depression detection models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddfe4c5383fa66e6b8e028851d0fe67037a11642b799a3626a1100aaa4cd8096_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddfe4c5383fa66e6b8e028851d0fe67037a11642b799a3626a1100aaa4cd8096_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of semantic bias in depression detection models, where models learn shortcuts from linguistic sentiment instead of acoustic cues. It proposes DepFlow, a disentangled speech generation framework, to create a synthetic dataset (CDoA) that pairs depressed acoustic patterns with positive/neutral text. This data augmentation method improves model robustness, outperforming conventional strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Generative AI Paradox: GenAI and the Erosion of Trust, the Corrosion of Information Verification, and the Demise of Truth</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [ai safety &amp; alignment], [synthetic reality, epistemic security, provenance, trust erosion, generative AI harms]</p>
</li>
<li class="">
<p><strong>authors:</strong> Emilio Ferrara</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Southern California (USC)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00306" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00306</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalizes the concept of &quot;synthetic reality&quot; as a layered socio-technical stack comprising content, identity, interaction, and institutions. 2. Expands a taxonomy of Generative AI harms and articulates the qualitative shifts it introduces, such as cost collapse and provenance gaps. 3. Proposes a complementary mitigation stack and a research agenda focused on measuring epistemic security, culminating in the articulation of the &quot;Generative AI Paradox&quot;.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b42a2aa0b289b69471dcaa3b08e187b14ded4070e26848bb4917fcc12b2427_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88b42a2aa0b289b69471dcaa3b08e187b14ded4070e26848bb4917fcc12b2427_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper argues that the primary risk of Generative AI is not just creating fake content, but the systemic erosion of shared truth and verification practices as it enables the easy creation of synthetic content, identities, and interactions. The authors formalize this as &quot;synthetic reality,&quot; analyze its risks, and propose a multi-layered mitigation approach. They conclude with the &quot;Generative AI Paradox&quot;: the potential for societies to rationally discount all digital evidence as synthetic media becomes ubiquitous.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [person re-identification], [feature fusion, alpha-divergence loss, dynamic multi-task learning, semantic clustering, computational efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anns Ijaz, Muhammad Azeem Javed</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Management and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00307</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A multi-scale feature fusion method with automatic attention that fuses ResNet50 stages without parallel paths. 2. A semantic clustering technique using rule-based pseudo-labeling for anatomical body partitioning. 3. A dynamic weight averaging technique and the use of the FIDI loss function for balanced multi-task learning and improved metric learning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75221926fa101494a89575b6ea3a1c780209910ea62ecf484286140685d3de7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75221926fa101494a89575b6ea3a1c780209910ea62ecf484286140685d3de7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes VisNet, an efficient person re-identification model that combines multi-scale feature fusion, semantic clustering, and dynamic multi-task learning with an alpha-divergence loss to achieve a good balance between accuracy and computational cost. It achieves 87.05% Rank-1 and 77.65% mAP on Market-1501 with only 32.41M parameters and 4.601 GFLOPs. The work demonstrates a practical approach for real-time deployment in resource-constrained environments like surveillance and mobile applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Multiagent Reinforcement Learning for Liquidity Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multiagent reinforcement learning], [liquidity games, rational swarms, difference rewards, Markov team games, financial swarm]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alicia Vidler, Gal A. Kaminka</p>
</li>
<li class="">
<p><strong>institution:</strong> Bar-Ilan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00324" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00324</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Unifies Liquidity Games (a game-theoretic model of liquidity formation) with Rational Swarms (a decentralized multiagent RL method using difference rewards). 2. Proposes a theoretical framework defining a swarm of independent traders whose collective objective is market liquidity provision. 3. Demonstrates that using difference rewards within a Markov team games framework enables individual liquidity-maximizing behaviors to contribute to overall market liquidity without requiring coordination.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d1bd53d93f07cfb626ac581013a3e8a6bfa64ea30e2fea7f9e15851b64d4cd2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d1bd53d93f07cfb626ac581013a3e8a6bfa64ea30e2fea7f9e15851b64d4cd2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the tension between self-interested financial agents and the need for overall market liquidity. It proposes a &quot;Financial Swarm&quot; model that unifies Liquidity Games with Rational Swarms, using difference rewards in a Markov team game to align individual learning with the global objective. The main conclusion is that this framework allows independent agents to achieve both individual profitability and collective market efficiency without coordination or collusion.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [anomaly detection], [frequency-guided learning, structural attention, semantic consistency, dual-branch framework, CLIP]</p>
</li>
<li class="">
<p><strong>authors:</strong> Naiqi Zhang, Chuancheng Shi, Jingtong Dou, Wenhua Wu, Fei Shen, Jianhua Cao</p>
</li>
<li class="">
<p><strong>institution:</strong> Tianjin University of Science and Technology, The University of Sydney, National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00327" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00327</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed HarmoniAD, a frequency-guided dual-branch framework that decouples features into high- and low-frequency paths to balance structural detail and semantic context. 2. Introduced two novel modules: a Fine-grained Structural Attention Module (FSAM) for enhancing textures/edges in the high-frequency branch, and a Global Structural Context Module (GSCM) for capturing long-range dependencies in the low-frequency branch. 3. Adopted a multi-class joint training strategy and demonstrated state-of-the-art performance on multiple benchmark datasets (MVTec-AD, VisA, BTAD).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e849537a51e67abdf003473c95f5885e48c7364ea926f9e5a9d19c230dd572ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e849537a51e67abdf003473c95f5885e48c7364ea926f9e5a9d19c230dd572ec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the trade-off between structural sensitivity and semantic consistency in anomaly detection. It proposes HarmoniAD, a framework that uses a CLIP encoder and frequency-domain decoupling into dual branches with specialized attention modules to model fine details and global context. Experiments show the method achieves state-of-the-art performance with improved sensitivity and robustness on industrial inspection datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Sparse Probabilistic Coalition Structure Generation: Bayesian Greedy Pursuit and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4511em;vertical-align:-0.15em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> Relaxations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent systems], [coalition structure generation, sparse regression, Bayesian greedy pursuit, l1 penalization, probabilistic framework]</p>
</li>
<li class="">
<p><strong>authors:</strong> Angshul Majumdar</p>
</li>
<li class="">
<p><strong>institution:</strong> IIIT Delhi</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00329" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00329</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel probabilistic framework for Coalition Structure Generation (CSG) where coalition values are learned from episodic observations via sparse linear regression. 2. Introduces and analyzes the Bayesian Greedy Coalition Pursuit (BGCP) algorithm, providing theoretical guarantees for exact coalition recovery under certain conditions. 3. Provides theoretical analysis for an alternative ℓ1-penalized estimation scheme, deriving error bounds and translating them into welfare gap guarantees, and compares regimes where sparse methods outperform classical approaches.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492cd85c7ccfef225059f9e637ee717227d05ec3497e1f7c70a5e2e84ad5cc35_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/492cd85c7ccfef225059f9e637ee717227d05ec3497e1f7c70a5e2e84ad5cc35_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses coalition structure generation when coalition values are unknown and must be learned from noisy episodic data. It proposes a sparse probabilistic framework with two estimation methods: a Bayesian greedy pursuit algorithm and an ℓ1-penalized estimator, providing theoretical recovery and error guarantees. The analysis identifies conditions under which these sparse learning approaches yield welfare-optimal structures and outperform classical methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [self-healing, distributed computing continuum, language model agents, multi-agent systems, fault tolerance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alaa Saleh, Praveen Kumar Donta, Roberto Morabito, Sasu Tarkoma, Anders Lindgren, Qiyang Zhang, Schahram Dustdar Susanna Pirttikangas, Lauri Lovén</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Oulu, Stockholm University, EURECOM, University of Helsinki, RISE Research Institutes of Sweden, Luleå University of Technology, Peking University, TU Wien</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00339" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00339</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces ReCiSt, a novel bio-inspired framework that maps biological self-healing phases (Hemostasis, Inflammation, Proliferation, Remodeling) to computational layers (Containment, Diagnosis, Meta-Cognitive, Knowledge) for resilience in DCCS. 2. Proposes the use of Language Model (LM)-powered agents to autonomously interpret logs, diagnose faults, and reconfigure resources with minimal human intervention. 3. Demonstrates the framework&#x27;s capability for self-healing within tens of seconds with low resource overhead (e.g., 10% CPU usage) through evaluation on public fault datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61eb83e4510dadeebc7e84fe1a44a89c218981f7cc3a6c7ef337ea51860d2146_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes ReCiSt, a bio-inspired, agent-based framework that uses Language Model-powered agents to autonomously detect, diagnose, and recover from faults in Distributed Computing Continuum Systems. The framework is evaluated on public datasets, showing it can achieve self-healing in tens of seconds with minimal resource overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Robust Uncertainty Quantification for Factual Generation of Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection], [uncertainty quantification, factual hallucination, trap questions, ROCAUC, fake biographies]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuhao Zhang, Zhongliang Yang, Linna Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing University of Posts and Telecommunications</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00348" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00348</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/EdwardChang5467/robust" target="_blank" rel="noopener noreferrer" class="">https://github.com/EdwardChang5467/robust</a> uncertainty</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new uncertainty quantification scenario focused on multi-fact generation (e.g., fake person biographies) to test LLM robustness. 2. Constructs a novel dataset of trap questions containing fake names to evaluate hallucination detection methods. 3. Introduces a robust uncertainty quantification (RU) method that significantly outperforms baseline methods across four different LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6268aa8c8874ac861a06315946aedcfbc9df7712a9f2b63e23204554e9c8596b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6268aa8c8874ac861a06315946aedcfbc9df7712a9f2b63e23204554e9c8596b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of LLM hallucination by proposing a new robust uncertainty quantification (RU) method for detecting factual errors in multi-fact generation tasks. The method is evaluated using a specially constructed set of trap questions containing fake names. Results show the RU method achieves an average increase of 0.1-0.2 in ROCAUC over the best baseline, demonstrating its effectiveness in improving the reliability of LLM outputs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Mapping Human Anti-collusion Mechanisms to Multi-agent AI</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-agent systems], [collusion, anti-collusion mechanisms, multi-agent AI, AI safety, game theory]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jamiu Adekunle Idowu, Ahmed Almasoud, Ayman Alfahid</p>
</li>
<li class="">
<p><strong>institution:</strong> University College London (UCL), Sahel AI, Prince Sultan University, Majmaah University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00360" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00360</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a taxonomy of human anti-collusion mechanisms (e.g., sanctions, leniency, monitoring). 2. Mapped these human mechanisms to potential interventions for multi-agent AI systems. 3. Highlighted key open challenges in applying these mechanisms to AI, such as the attribution problem and adversarial adaptation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ddbe564b87a89c6b0bfd47c15c01195109e5af5ff41994f193729c6ff841d80_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ddbe564b87a89c6b0bfd47c15c01195109e5af5ff41994f193729c6ff841d80_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the risk of collusion in autonomous multi-agent AI systems by proposing to adapt established human anti-collusion mechanisms. It develops a taxonomy of these mechanisms and maps them to potential AI interventions. The work concludes by identifying critical challenges for future research in this area, such as distinguishing beneficial cooperation from harmful collusion.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multilingual representation learning], [Joint Embedding Predictive Architecture (JEPA), BERT, CLS token, language-agnostic embedding, multilingual benchmarks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Taj Gillin, Adam Lalani, Kenneth Zhang, Marcel Mateos Salles</p>
</li>
<li class="">
<p><strong>institution:</strong> Brown University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00366</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces BERT-JEPA (BEPA), a novel training paradigm that adds a JEPA objective to BERT-style models to reorganize the [CLS] embedding space. 2. Demonstrates that BEPA finetuning transforms the [CLS] embedding space into a semantic-first, language-agnostic space, shifting its PCA representation from low-rank to fuller-rank. 3. Shows that this reorganization improves performance on multilingual tasks with little to no loss in English performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that BERT&#x27;s [CLS] embeddings fail to capture language-invariant semantics. It proposes BERT-JEPA (BEPA), a method that adds a Joint Embedding Predictive Architecture (JEPA) objective during training to reorganize the [CLS] embedding space into a language-agnostic &quot;thought space&quot;. The main conclusion is that this approach significantly improves performance on multilingual benchmarks while maintaining English task performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [adversarial patches, outlier detection, isolation forest, dimensionality reduction, edge computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nandish Chattopadhyay, Abdul Basit, Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University (NYU) Abu Dhabi, DakAI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00367</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes PatchBlock, a lightweight, model-agnostic pre-processing framework for detecting and mitigating adversarial patches on resource-constrained edge devices. 2. Introduces a redesigned isolation forest algorithm with targeted cuts for efficient anomaly detection in image chunks. 3. Demonstrates high robustness recovery (up to 77% accuracy) and superior efficiency (computation time, energy) compared to state-of-the-art defenses, with minimal impact on clean accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/931ca070f14402ab68d228644f7d6df1ed1c402686c4fae0127234e1c588df8d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/931ca070f14402ab68d228644f7d6df1ed1c402686c4fae0127234e1c588df8d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents PatchBlock, a lightweight defense framework that uses outlier detection and dimensionality reduction to identify and neutralize adversarial patches in images for EdgeAI systems. It operates efficiently on CPUs in parallel with GPU inference, making it suitable for resource-constrained devices. Evaluations show it significantly recovers model accuracy under strong patch attacks while maintaining high efficiency and portability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] In Line with Context: Repository-Level Code Generation via Context Inlining</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code generation], [repository-level code generation, context inlining, call graph, perplexity-based confidence, bidirectional inlining]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chao Hu, Wenhao Zeng, Yuling Shi, Beijun Shen, Xiaodong Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00376" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00376</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces InlineCoder, a novel framework that reframes repository-level code generation as a function-level task by inlining the target function into its call graph., 2. Proposes a bidirectional inlining process combining an initial draft anchor, upstream inlining for usage scenarios, and downstream retrieval for dependency context., 3. Demonstrates substantial performance gains over state-of-the-art baselines on benchmarks like RepoExec, highlighting effectiveness in understanding repository contexts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/042382406537daf6ffcdbb0e0a2311956fbf996d26fe6c18ea9b84304141abfa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/042382406537daf6ffcdbb0e0a2311956fbf996d26fe6c18ea9b84304141abfa_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of repository-level code generation, where models must understand complex dependencies across an entire codebase. It proposes InlineCoder, a framework that first generates a draft function (anchor) and then enriches the context by inlining it into its callers (upstream) and retrieving its callees (downstream). This approach significantly outperforms existing methods on standard benchmarks, showing improved understanding of repository context.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Word Frequency Counting Based on Serverless MapReduce</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [serverless computing], [Serverless Computing, MapReduce, Word Frequency Counting, Function as a Service (FaaS), Cloud Computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hanzhe Li, Bingchen Lin, Mengyuan Xu</p>
</li>
<li class="">
<p><strong>institution:</strong> Xi&#x27;an Jiaotong University, Chongqing University of Education, Qilu Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00380" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00380</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel combination of the serverless computing paradigm (FaaS) with the MapReduce programming model for data processing tasks. 2. Investigates and determines the optimal number of Map and Reduce functions for a given workload within a serverless MapReduce framework. 3. Demonstrates through experiments that increasing the number of functions reduces execution time and improves overall efficiency for the word frequency counting task.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88bebde834fdbf686ac0168c04a12e2eb20d8157d9be5e2222f9ff775a21b2ca_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88bebde834fdbf686ac0168c04a12e2eb20d8157d9be5e2222f9ff775a21b2ca_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of optimizing big data processing efficiency by integrating the serverless computing model (FaaS) with the MapReduce framework. It proposes a serverless MapReduce approach for word frequency counting and experimentally finds the optimal number of Map and Reduce functions to minimize execution time. The results show that this method improves processing efficiency, offering a cost-effective solution for cloud-based data analytics.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [cyber-physical systems security], [intrusion detection system, anomaly detection, G-code manipulation, transformer encoder, self-attention autoencoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md Mahbub Hasan, Marcus Sternhagen, Krishna Chandra Roy</p>
</li>
<li class="">
<p><strong>institution:</strong> New Mexico Institute of Mining and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00384" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00384</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Investigation of stealthy Man-in-the-Middle (MitM) attack vectors targeting the CAD-to-machine interface in Fused Deposition Modeling (FDM) 3D printers. 2. Proposal of an unsupervised Intrusion Detection System (IDS) that uses a frozen Transformer-based encoder and contrastive learning to create anomaly-sensitive embeddings from machine logs. 3. Demonstration of effective anomaly classification using a combination of clustering and a self-attention autoencoder on real 3D printing systems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b296e2b64944be1e0ab79e116131c11acbb4a662a6a9c3e8adaf377db0c3190e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b296e2b64944be1e0ab79e116131c11acbb4a662a6a9c3e8adaf377db0c3190e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates stealthy cyberattacks that manipulate G-code in additive manufacturing systems, leading to structurally defective parts. To detect these attacks, the authors propose an unsupervised intrusion detection system that uses a Transformer-based encoder and contrastive learning to analyze machine logs. Their method successfully distinguishes between normal and compromised printing executions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [coordinated behavior detection], [Convergent Cross Mapping, semi-supervised learning, active learning, hierarchical clustering, causal inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Weng Ding, Yi Han, Mu-Jiang-Shan Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Georgia Institute of Technology, Meta, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00400" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00400</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an adaptive Convergent Cross Mapping (CCM) technique for identifying genuine causal relationships between accounts. 2. Integrates active learning with uncertainty sampling in a semi-supervised classification scheme to reduce manual labeling burden. 3. Introduces an automated validation module driven by historical detection experience for self-verification and optimization of outcomes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e2d7bb8b5573c45544689a49293433fa3d98d36abedd140f80989af5d80d355_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e2d7bb8b5573c45544689a49293433fa3d98d36abedd140f80989af5d80d355_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes ACCD, a three-stage memory-guided framework for detecting coordinated inauthentic behavior on social media. It uses adaptive causal inference, semi-supervised active learning, and automated validation to improve accuracy and efficiency. The method achieves a higher F1-score and significantly reduces manual annotation requirements compared to existing baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [named entity recognition], [weak supervision, large language models, low-resource languages, dataset construction, Luxembourgish]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alistair Plum, Laura Bernardy, Tharindu Ranasinghe</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Luxembourg, Lancaster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00411</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel pipeline for constructing NER datasets that uses Wikipedia/Wikidata for weak supervision and LLMs for label verification. 2. Introduces judgeWEL, a new and significantly larger NER dataset for the under-represented language Luxembourgish. 3. Evaluates and compares the effectiveness of multiple LLMs in judging and filtering noisy, distantly-supervised labels.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e13a29d091cdd4cb0cc5c3d34a98e86c8d45b0a34f42a2b552cecd9fcff5b51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e13a29d091cdd4cb0cc5c3d34a98e86c8d45b0a34f42a2b552cecd9fcff5b51_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of building datasets for under-represented languages by proposing a novel method that uses Wikipedia and Wikidata for weak supervision to generate initial NER labels, and then employs multiple LLMs to verify and filter these labels for quality. The approach is applied to Luxembourgish, resulting in the judgeWEL dataset, which is five times larger and more balanced than existing resources, providing a valuable new corpus for low-resource NER research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [efficient transformers], [astrocyte-inspired computing, long-term plasticity (LTP), short-term plasticity (STP), memory compression, Long Range Arena (LRA)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md Zesun Ahmed Mia, Malyaban Bal, Abhronil Sengupta</p>
</li>
<li class="">
<p><strong>institution:</strong> Pennsylvania State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00426" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00426</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces RMAAT, a novel Transformer architecture that integrates abstracted astrocyte functionalities for efficient long-context processing. 2. Proposes an adaptive memory compression mechanism governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP). 3. Develops Astrocytic Memory Replay Backpropagation (AMRB), a novel training algorithm designed for memory efficiency in recurrent networks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48db0bbab3b8ca0fcbec4bfde72ebb384d63651cf925a575ef2f9e06a070abc5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48db0bbab3b8ca0fcbec4bfde72ebb384d63651cf925a575ef2f9e06a070abc5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the quadratic complexity problem of Transformer self-attention for long sequences by proposing RMAAT, an architecture inspired by astrocyte functions in biological memory. The method uses recurrent segment-based processing with adaptive memory compression and a linear-complexity attention mechanism. Evaluations on the Long Range Arena benchmark show that RMAAT achieves competitive accuracy with substantial improvements in computational and memory efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Deep Delta Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neural network architecture], [residual networks, geometric transformation, spectral analysis, rank-1 perturbation, dynamic gating]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University, University of California, Los Angeles</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00417" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00417</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/yifanzhang-pro/deep-delta-learning" target="_blank" rel="noopener noreferrer" class="">https://github.com/yifanzhang-pro/deep-delta-learning</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Deep Delta Learning (DDL), a novel architecture that generalizes residual connections with a learnable, data-dependent geometric transformation called the Delta Operator. 2. Provides a spectral analysis of the Delta Operator, showing it can dynamically interpolate between identity mapping, orthogonal projection, and geometric reflection via a gating scalar. 3. Restructures the residual update as a synchronous rank-1 injection, unifying feature erasure and writing under a dynamic step size to enable complex, non-monotonic dynamics while preserving stable training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies that the strictly additive inductive bias of standard residual networks limits their capacity to model complex state transitions. To address this, it proposes Deep Delta Learning (DDL), which modulates the identity shortcut with a learnable, data-dependent geometric transformation (the Delta Operator). This allows the network to explicitly control its layer-wise transition spectrum, enabling the modeling of complex dynamics like oscillations while maintaining stable training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [sports analytics], [semantic-space reasoning, vector-distance metrics, tactical optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alessio Di Rubbo, Mattia Neri, Remo Pareschi, Marco Pedroni, Roberto Valtancoli, Paolino Zica</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Molise, Stake Lab, Bioretics, Institute for Generative Strategy, Cesena Femminile Football Club, Zica Sport</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00421" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00421</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel analogy between texts and teams, modeling tactical configurations as compositional semantic structures. 2. Introduces a methodology to represent players and teams as multidimensional vectors and evaluate tactical fit using vector-distance metrics. 3. Demonstrates a generalizable framework for collective decision-making applicable beyond football to domains like cooperative robotics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f5544900dd6f44d32d07e9f1b09cbba4598bb4606d5d22767a42a8c2195ce1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f5544900dd6f44d32d07e9f1b09cbba4598bb4606d5d22767a42a8c2195ce1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a novel methodology that applies semantic-space reasoning from computational linguistics to model team sports tactics. It represents players and teams as vectors in a shared semantic space to compute tactical fit and generate strategy recommendations. The work concludes that this approach provides an interpretable and generalizable framework for optimizing collective performance in team-based domains.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning for human feedback], [reinforcement learning from human feedback (RLHF), flow matching, stochastic differential equations (SDE), group relative policy optimization (GRPO), entropy-aware sampling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengjun Zhang, Zhang Zhang, Chensheng Dai, Yueqi Duan</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00423" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00423</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/shengjun-zhang/VisualGRPO" target="_blank" rel="noopener noreferrer" class="">https://github.com/shengjun-zhang/VisualGRPO</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified that high-entropy denoising steps are crucial for effective exploration in RL for flow models, while low-entropy steps lead to ambiguous rewards. 2. Proposed E-GRPO, an entropy-aware method that consolidates consecutive low-entropy steps into a single high-entropy step for SDE sampling and uses ODE sampling elsewhere. 3. Introduced a multi-step group normalized advantage calculation that computes advantages relative to samples sharing the same consolidated SDE step.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/517610c9d7d0b5f72ab6ea2e2c36dda14fb3879dc1ff5c4a8ae66c97dd3a6457_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/517610c9d7d0b5f72ab6ea2e2c36dda14fb3879dc1ff5c4a8ae66c97dd3a6457_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of sparse and ambiguous reward signals when applying reinforcement learning to flow models over multiple denoising steps. It proposes E-GRPO, an entropy-aware method that strategically uses SDE sampling on high-entropy steps and ODE sampling on others, along with a group-relative advantage calculation. Experiments show this approach is more effective for aligning flow models with human preferences.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language modeling], [Semantic Field Theory, lexical fields, linguistic fields, transformer architectures, embedding spaces]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dimitris Vartziotis</p>
</li>
<li class="">
<p><strong>institution:</strong> TWT Science &amp; Innovation, NIKI - Digital Engineering</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00448" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00448</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalizes the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. 2. Analyzes how core properties of transformer architectures (e.g., distributed representations, attention) relate to Semantic Field Theory concepts. 3. Proposes that mathematical structure and language games are complementary perspectives, clarifying the scope and limits of statistical language models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98759f21c127cf9a440b464892816dd7e22af8f161a1d16ec91b582a8fefa647_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98759f21c127cf9a440b464892816dd7e22af8f161a1d16ec91b582a8fefa647_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper examines theories of linguistic meaning by contrasting social constructivist language games with a mathematically oriented Semantic Field Theory. It formalizes lexical and linguistic fields and analyzes their relation to transformer architecture properties. The authors conclude that the mathematical structure captured by LLMs and the social grounding of language games are complementary, not competing, views.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Deep Networks Learn Deep Hierarchical Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [theoretical machine learning], [hierarchical models, residual networks, layerwise SGD, efficient learnability, teacher-student framework]</p>
</li>
<li class="">
<p><strong>authors:</strong> Amit Daniely</p>
</li>
<li class="">
<p><strong>institution:</strong> Hebrew University of Jerusalem, Google Research Tel Aviv</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00455" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00455</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proves that layerwise SGD on residual networks can efficiently learn a class of hierarchical models with polynomial depth, surpassing previous learnable models limited to log-depth. 2. Introduces a formal model where the existence of human teachers, providing granular labels, naturally reveals a hierarchical structure that facilitates learning. 3. Suggests that the learnability of deep hierarchical models could form a theoretical basis for understanding why deep learning works.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1faa5ee1ce6f2d929632472a3fef6f2a37f968b78b881ef42a244f56de38679_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1faa5ee1ce6f2d929632472a3fef6f2a37f968b78b881ef42a244f56de38679_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper shows that layerwise stochastic gradient descent (SGD) on residual networks can efficiently learn a class of hierarchical models where labels are structured in increasingly complex levels. This class is more expressive, requiring polynomial depth, than previously known learnable models. The authors argue that this learnability, supported by a formal model of teaching, provides a potential theoretical foundation for understanding deep learning&#x27;s success.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [guardrail models, multi-turn compression, efficiency optimization, safety screening, token reduction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hyunjun Kim</p>
</li>
<li class="">
<p><strong>institution:</strong> KAIST</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00454" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00454</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Defensive M2S, a training paradigm that fine-tunes guardrail models on compressed multi-turn conversations instead of full histories, 2. Provides formal complexity analysis showing training cost reduction from O(n²) to O(n) and empirical token reduction of 93×, 3. Demonstrates effectiveness across multiple guardrail models and compression templates, achieving high attack detection recall with 94.6% inference token reduction.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad9caa971d784e8a994209f34a3b4e255812b43b2fa90a13bb0487b6e71e1395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad9caa971d784e8a994209f34a3b4e255812b43b2fa90a13bb0487b6e71e1395_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high computational cost of processing full multi-turn conversations for LLM safety guardrails by proposing Defensive M2S, which trains guardrail models on compressed single-turn versions. This method significantly reduces training and inference tokens while maintaining high attack detection performance, enabling scalable safety screening.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [Mixture-of-Experts, Orthogonality Regularization, Weight-Activation Gap, Sparse Activation, Expert Diversity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hyunjun Kim</p>
</li>
<li class="">
<p><strong>institution:</strong> Korea Advanced Institute of Science and Technology (KAIST)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00457" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00457</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Showed that orthogonality regularization fails to reduce weight-space overlap and yields inconsistent effects on model performance across different datasets. 2. Identified a significant disconnect between weight-space and activation-space orthogonality, with no significant correlation between the two. 3. Demonstrated that weight-space regularization is an unreliable optimization target for improving expert diversity in MoE models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/297630182c2a41472ac5ae250b1200161c3b50705c9ba5130f166dda38b1a979_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/297630182c2a41472ac5ae250b1200161c3b50705c9ba5130f166dda38b1a979_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the effectiveness of applying orthogonality loss to enforce expert diversity in Mixture-of-Experts (MoE) models. The analysis reveals that this geometric regularization fails to reduce weight-space overlap, does not translate to activation-space orthogonality, and leads to inconsistent performance changes. The findings demonstrate that weight-space regularization is unsuitable for achieving MoE diversity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Neural Chains and Discrete Dynamical Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [scientific machine learning], [neural chains, physics-informed neural networks (PINNs), finite-difference methods, Burgers equation, Eikonal equation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sauro Succi, Abhisek Ganguly, Santosh Ansumali</p>
</li>
<li class="">
<p><strong>institution:</strong> Italian Institute of Technology, Jawaharlal Nehru Centre for Advanced Scientific Research (JNCASR), University of Roma Tre, Harvard University, Cornell University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00473" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00473</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes and analyzes the analogy between transformer-based neural chains (without self-attention) and discrete dynamical systems from discretized neural integral/PDEs. 2. Conducts a comparative analysis between standard numerical discretization (finite-difference) and PINN learning for solving Burgers and Eikonal equations, showing they converge to similar dynamical knowledge. 3. Identifies that PINNs explore a vast space of random matrices, unlike the structured matrices of finite-difference methods, leading to more parameters, higher training costs, and reduced explainability for 1D problems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/484d1f1718d109a31c34806ec956587c6c88440887cfe665bb5795e2c2cad940_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/484d1f1718d109a31c34806ec956587c6c88440887cfe665bb5795e2c2cad940_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the connection between neural chains (transformers without self-attention) and discrete dynamical systems. It compares solving PDEs like Burgers and Eikonal equations using standard finite-difference methods versus Physics-Informed Neural Networks (PINNs), finding both methods yield similar solutions but PINNs use many more random, less interpretable parameters. The authors conclude that for these 1D problems, PINNs offer no efficiency advantage over traditional methods, though their potential for high-dimensional problems remains open.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [agentic AI, distributed agents, human-AI co-creation, progressive ideation, meta-cognitive workflow]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sankar B, Srinidhi Ranjini Girish, Aadya Bharti, Dibakar Sen</p>
</li>
<li class="">
<p><strong>institution:</strong> Indian Institute of Science (IISc)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00475" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00475</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MIDAS, a novel framework that replaces single-AI systems with a distributed team of specialized AI agents for ideation. 2. Emulates a human meta-cognitive workflow to progressively refine ideas and assess them for both global and local novelty. 3. Establishes a new paradigm for human-AI co-creation, elevating the human from a passive filter to an active collaborative partner.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dee9a17774f8f69cd3f3a19a0507461cd7a05a21b3f1dec4db23b9a0a1c9bfa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dee9a17774f8f69cd3f3a19a0507461cd7a05a21b3f1dec4db23b9a0a1c9bfa_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of AI systems generating semantically clustered ideas that hinder novel ideation in engineering design. It proposes the MIDAS framework, which uses a distributed team of specialized AI agents to progressively refine and assess ideas for novelty. This approach enables true human-AI co-creation, making the human designer an active partner rather than a passive filter.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent systems, evaluation suite, observability, execution traces, reliability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tie Ma, Yixi Chen, Vaastav Anand, Alessandro Cornacchia, Amândio R. Faustino, Guanheng Liu, Shan Zhang, Hongbin Luo, Suhaib A. Fahmy, Zafar A. Qazi, Marco Canini</p>
</li>
<li class="">
<p><strong>institution:</strong> KAUST, Beihang University, MPI-SWS, LUMS</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00481" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00481</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MAESTRO, a unified evaluation suite for standardizing the configuration, execution, and observability of LLM-based Multi-Agent Systems (MAS). 2. Provides a repository of examples and adapters to integrate diverse MAS frameworks and exports framework-agnostic execution traces with system-level signals (e.g., latency, cost). 3. Through controlled experiments with 12 MAS, demonstrates that MAS architecture is the dominant factor affecting resource profiles, reproducibility, and trade-offs, often outweighing changes in backend models or tools.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8621fc3bb6613fb26f1974a1a10ce1d6783df8fc57e3246b8e7ef34f2a5f4391_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8621fc3bb6613fb26f1974a1a10ce1d6783df8fc57e3246b8e7ef34f2a5f4391_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces MAESTRO, a benchmark suite designed to systematically evaluate the testing, reliability, and observability of LLM-based multi-agent systems. It standardizes execution and provides detailed traces, enabling controlled comparisons. The study finds that MAS architecture is the primary driver of performance variance and system behavior, more so than model or tool changes.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Multi-Agent Coordinated Rename Refactoring</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [refactoring], [multi-agent system, coordinated renaming, scope inference, refactoring automation, IDE integration]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abhiram Bellur, Mohammed Raihan Ullah, Fraol Batole, Mohit Kansara, Masaharu Morimoto, Kai Ishikawa, Haifeng Chen, Yaroslav Zharov, Timofey Bryksin, Tien N. Nguyen, Hridesh Rajan, Danny Dig</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Colorado, Tulane University, University of Texas at Dallas, NEC Corporation, NEC Laboratories America, JetBrains Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00482" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00482</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Designed and implemented the first multi-agent framework for automating coordinated rename refactoring. 2. Introduced a novel approach where an initial developer refactoring is used as a clue to infer a Declared Scope, which guides subsequent automated refactorings. 3. Demonstrated significant performance improvements (2.3x-3.1x F1-score) over state-of-the-art methods through rigorous evaluation on established and new benchmarks, including successful integration into active open-source projects.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e6c46d36197d90e221024d6225c9bcd5170e720a7f8f29bef40ad31d151bbda_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e6c46d36197d90e221024d6225c9bcd5170e720a7f8f29bef40ad31d151bbda_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the tedious and error-prone task of coordinated renaming in software development by proposing a novel multi-agent framework. The framework uses a developer&#x27;s initial rename as a clue to infer a scope, which then guides specialized agents to safely identify and execute related refactorings using IDE APIs. The evaluation shows the system, CoRenameAgent, significantly outperforms existing methods in accuracy and demonstrates practical utility by having its automatically generated changes accepted into real projects.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [physics-based simulation], [motion distillation, differentiable simulation, multimodal large language model, material parameter estimation, video diffusion models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Miaowei Wang, Jakub Zadrożny, Oisin Mac Aodha, Amir Vaxman</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Edinburgh</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00504</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://wangmiaowei.github.io/MotionPhysics.github.io/" target="_blank" rel="noopener noreferrer" class="">https://wangmiaowei.github.io/MotionPhysics.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An end-to-end differentiable framework that infers physical parameters from natural language prompts for 3D simulation, 2. A novel learnable motion distillation loss that extracts motion priors from video diffusion models while minimizing appearance/geometry bias, 3. A comprehensive evaluation across diverse scenarios (real-world, human-designed, AI-generated objects) and materials (solids, fluids) showing state-of-the-art performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1f5f328bdf213bd8c50e27a819223c1b50a9adbc0e2f36cc8adcb40bdbdd5bb8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1f5f328bdf213bd8c50e27a819223c1b50a9adbc0e2f36cc8adcb40bdbdd5bb8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces MotionPhysics, a framework that uses a multimodal LLM and a novel motion distillation loss from video diffusion models to automatically estimate plausible physical parameters from text prompts for 3D dynamic simulation. This approach eliminates the need for ground-truth trajectories or annotated videos. The method is shown to produce realistic simulations across a wide variety of materials and object types, outperforming prior work.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Illusion of Insight in Reasoning Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reasoning models], [reasoning shifts, self-correction, model uncertainty, intrinsic vs extrinsic, chain-of-thought]</p>
</li>
<li class="">
<p><strong>authors:</strong> Liv G. d&#x27;Aliberti, Manoel Horta Ribeiro</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00514" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00514</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a large-scale empirical study analyzing over 1 million reasoning traces across multiple models, domains, and training stages to investigate the nature and impact of mid-reasoning &quot;Aha!&quot; moments. 2. Found that such intrinsic reasoning shifts are rare, do not increase with training, and seldom improve accuracy, challenging the perception that they represent genuine model insight or self-correction. 3. Demonstrated that while intrinsic shifts are not beneficial, artificially triggering extrinsic shifts under conditions of high model uncertainty (high entropy) can reliably improve accuracy, showing these shifts are symptoms of unstable inference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c00fcaa573a1b7a6558433ae1348cc7cefec26d36175047b45df1cd217f2516_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c00fcaa573a1b7a6558433ae1348cc7cefec26d36175047b45df1cd217f2516_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether reasoning models experience genuine &quot;Aha!&quot; moments of intrinsic self-correction during inference. Through a large-scale analysis of reasoning traces across multiple models and training checkpoints, the authors find that such mid-reasoning shifts are rare and ineffective, but that artificially triggering shifts when the model is uncertain can improve accuracy. The main conclusion is that these shifts are symptoms of unstable inference behavior, not a mechanism for intrinsic self-improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Probability-Aware Parking Selection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [urban computing, intelligent transportation systems], [dynamic programming, stochastic modeling, parking availability, travel time estimation, navigation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cameron Hickert, Sirui Li, Zhengbing He, Cathy Wu</p>
</li>
<li class="">
<p><strong>institution:</strong> Massachusetts Institute of Technology (MIT)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00521" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00521</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the probability-aware parking selection problem, shifting navigation from destination to optimal parking location. 2. Proposes an adaptable dynamic programming framework for decision-making under probabilistic parking availability. 3. Provides analytical and empirical error assessments for using stochastic observations to estimate parking availability, showing viability with real-world data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e593d7f649bbe1a9ad2d3e102fdbd08c74926a786541d28174a517648ac1dcd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e593d7f649bbe1a9ad2d3e102fdbd08c74926a786541d28174a517648ac1dcd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underestimation of total travel time in navigation systems by introducing a probability-aware parking selection problem. It proposes a dynamic programming framework to direct drivers to the best parking location based on probabilistic availability, and demonstrates through simulations with Seattle data that this approach can yield significant time savings compared to probability-unaware baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Siamese Recurrent Autoencoder, hybrid loss, real-time anomaly detection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Laksh Advani</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (affiliation inferred from email domain: University of Colorado Boulder)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00516</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrated the ineffectiveness of standard anomaly detection methods for agent trajectory validation, establishing the need for specialized models. 2. Proposed a novel, sequence-aware Siamese Recurrent Autoencoder with a hybrid loss function for real-time trajectory anomaly detection. 3. Demonstrated that the approach is over 17x faster than LLM Judge baselines, making it suitable for real-time deployment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de97af87ef40e2bb7fa3067f0d8a7f8e2dc7d8fd40b77747e64af793669009c2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de97af87ef40e2bb7fa3067f0d8a7f8e2dc7d8fd40b77747e64af793669009c2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of detecting anomalous action plans in autonomous LLM agents, where existing methods fail to capture sequential structure and context. It proposes Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss combining contrastive learning and reconstruction for unified anomaly detection. The method achieves high F1-scores (0.88-0.94) and significantly faster inference (32 ms) than LLM-based baselines, enabling real-time safety verification.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [LSTM compression, model efficiency, retail forecasting, edge computing, hidden units]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ravi Teja Pagidoju</p>
</li>
<li class="">
<p><strong>institution:</strong> Campbellsville University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00525" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00525</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/RaviTeja444/sales-forecast-LSTM" target="_blank" rel="noopener noreferrer" class="">https://github.com/RaviTeja444/sales-forecast-LSTM</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematic evaluation of LSTM network sizes from 16 to 128 hidden units on real retail data. 2. Discovery that moderate compression (to 64 units) actually improves forecast accuracy. 3. Practical guidelines for model selection based on the accuracy-efficiency trade-off.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bda8da07103a6f89178a84bdce230c27d6cea8328b8c1fcb749e7912c516181_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bda8da07103a6f89178a84bdce230c27d6cea8328b8c1fcb749e7912c516181_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper studies LSTM model compression for resource-constrained retail sales forecasting by reducing the number of hidden units. The method involves systematically pruning the LSTM from 128 to 16 hidden units. The main conclusion is that reducing the model to 64 units not only makes it 73% smaller but also improves accuracy by 47%, showing larger models are not always better.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] ECR: Manifold-Guided Semantic Cues for Compact Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [embedding consistency regulation, manifold structure, semantic anchors, compact language models, on-device AI]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chung-Wei Victor Yuan</p>
</li>
<li class="">
<p><strong>institution:</strong> YVIC Research Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00543" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00543</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Embedding Consistency Regulation (ECR), a new framework that uses semantic anchors derived from teacher embeddings to preserve the underlying manifold structure in compact models. 2. Demonstrates that ECR stabilizes training and preserves semantic structure across tasks and languages without relying on matching logits or internal features, and adds minimal inference overhead. 3. Shows ECR is compatible with but independent of distillation, enabling better task alignment and deployment under strict efficiency or privacy constraints.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3184228efac0008fa39e8578d4daa8e597c9d20bf57f0662c9080c6c11607590_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3184228efac0008fa39e8578d4daa8e597c9d20bf57f0662c9080c6c11607590_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of semantic drift and loss of manifold structure in compact language models. It proposes the Embedding Consistency Regulation (ECR) framework, which uses offline-computed semantic anchors to guide the compact model&#x27;s geometry. Experiments show ECR produces more compact, task-aligned representations, making low-capacity models more stable and easier to deploy.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [gradient compression, orthogonal superposition, low-rank optimization, O-RAN, communication efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhiheng Guo, Zhaoyang Liu, Zihan Cen, Chenyuan Feng, Xinghua Sun, Xiang Chen, Tony Q. S. Quek, Xijun Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Sun Yat-sen University, University of Exeter, Singapore University of Technology and Design</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00549" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00549</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a unified framework (CoCo-Fed) that jointly addresses local memory constraints and global communication bottlenecks in federated learning at the wireless edge. 2. Introduces a local double-dimension gradient down-projection technique to enable optimizer operation on low-rank structures, reducing memory footprint without adding inference overhead. 3. Designs a global transmission protocol using orthogonal subspace superposition to consolidate layer-wise updates into a single matrix per node, drastically cutting backhaul traffic.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec79bdf4a8b9f5a548f3d50e3ca33a9f5a73510543acb755bae04b50c1ce378_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec79bdf4a8b9f5a548f3d50e3ca33a9f5a73510543acb755bae04b50c1ce378_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes CoCo-Fed, a federated learning framework that compresses gradients locally and combines updates globally to reduce memory and communication overhead in O-RAN edge networks. It achieves this through low-rank gradient projection and orthogonal superposition for transmission. Experiments on angle-of-arrival estimation show it outperforms baselines in efficiency while maintaining convergence under non-IID data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] A Comprehensive Dataset for Human vs. AI Generated Image Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [image forensics], [AI-Generated Images, Detection Techniques, Synthetic Media, Generative AI, Multimodal AI]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rajarshi Roy, Nasrin Imanpour, Ashhar Aziz, Shashwat Bajpai, Gurpreet Singh, Shwetangshu Biswas, Kapil Wanaskar, Parth Patwa, Subhankar Ghosh, Shreyas Dixit, Nilesh Ranjan Pal, Vipula Rawte, Ritvik Garimella, Gaytri Jena, Vasu Sharma, Vinija Jain, Aman Chadha, Aishwarya Naresh Reganti, Amitava Das</p>
</li>
<li class="">
<p><strong>institution:</strong> Kalyani Govt. Engg. College, AI Institute USC, IIIT Delhi, BITS Pilani, NIT Silchar, San José State Univ., UCLA, Washington State Univ., VIIT, GITA, Meta AI, Amazon AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00553" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00553</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MS COCOAI, a novel large-scale dataset of 96,000 real and AI-generated images for detection research., 2. Proposes two benchmark tasks: binary real-vs-AI classification and multi-class AI model attribution., 3. Provides a diverse dataset using five state-of-the-art generators (Stable Diffusion 3, SD 2.1, SDXL, DALL-E 3, MidJourney v6) built upon MS COCO.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80669ac38c06acf6818488be6bd831b0e8cc20bc319a1b37c431681230968cd3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80669ac38c06acf6818488be6bd831b0e8cc20bc319a1b37c431681230968cd3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of detecting increasingly realistic AI-generated images by introducing MS COCOAI, a comprehensive dataset of 96,000 real and synthetic images created using five modern generators. The dataset enables two key tasks: distinguishing real from AI-generated images and identifying the specific AI model that created a synthetic image. The release of this dataset aims to advance research in AI-generated image detection and model attribution.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [IoT Security], [Interaction Threats, Static Analysis, Large Language Models, Trigger-Action-Condition Rules, Symbolic Reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jason Quantrill, Noura Khajehnouri, Zihan Guo, Manar H. Alalfi</p>
</li>
<li class="">
<p><strong>institution:</strong> Toronto Metropolitan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00559" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00559</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/JasonQuantrill/llm-v-static-results" target="_blank" rel="noopener noreferrer" class="">https://github.com/JasonQuantrill/llm-v-static-results</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first comprehensive evaluation of LLMs for detecting multi-category interaction threats in IoT TAC rules. 2. Introduced a structurally challenging Mutation dataset to test model robustness under rule transformations. 3. Demonstrated that symbolic reasoning baselines outperform LLMs in structural reasoning tasks, highlighting the need for hybrid architectures.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88e5908c842c3a16fa536e15c334b07eda4e7076715625cdb48ee93058227761_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/88e5908c842c3a16fa536e15c334b07eda4e7076715625cdb48ee93058227761_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates the ability of Large Language Models (LLMs) to detect security threats in IoT automation rules, comparing them against traditional static analysis. The results show that while LLMs have good semantic understanding, they struggle with structural reasoning and are outperformed by symbolic methods, indicating they are not yet reliable for this safety-critical task alone.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Improving Scientific Document Retrieval with Academic Concept Index</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [information retrieval], [academic concept index, concept coverage-based generation (CCQGen), concept-focused auxiliary contexts (CCExpand)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jeyun Lee, Junhyoung Lee, Wonbin Kweon, Bowen Jin, Yu Zhang, Susik Yoon, Dongha Lee, Hwanjo Yu, Jiawei Han, Seongku Kang</p>
</li>
<li class="">
<p><strong>institution:</strong> Korea University, University of Illinois Urbana-Champaign, Texas A&amp;M University, Yonsei University, Pohang University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00567" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00567</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces an academic concept index that extracts and organizes key concepts from scientific papers using an academic taxonomy. 2. Proposes CCQGen, a concept coverage-based query generation method that adaptively conditions LLMs on uncovered concepts to produce complementary queries with broader coverage. 3. Develops CCExpand, a context augmentation technique that leverages document snippets as concise responses to concept-aware queries for improved relevance matching.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfdf054b52cb87f6cd4e63982623a18245a08006e97e04ad3614fc5ac270f85a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfdf054b52cb87f6cd4e63982623a18245a08006e97e04ad3614fc5ac270f85a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of adapting general-domain retrievers to scientific domains by introducing an academic concept index. The proposed method improves synthetic query generation (CCQGen) and context augmentation (CCExpand) using this structured index, leading to higher-quality queries and better retrieval performance. Experiments demonstrate improved conceptual alignment and retrieval effectiveness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Learning to be Reproducible: Custom Loss Design for Robust Neural Networks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [training stability &amp; reproducibility], [custom loss function, training robustness, reproducibility, stochastic factors, weight initialization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Waqas Ahmed, Sheeba Samuel, Kevin Coakley, Birgitta Koenig-Ries, Odd Erik Gundersen</p>
</li>
<li class="">
<p><strong>institution:</strong> Friedrich Schiller University Jena, University of Technology Chemnitz, Norwegian University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00578" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00578</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and empirically analyzes the critical gap in ensuring consistent performance across training runs due to stochastic factors like weight initialization and data shuffling. 2. Proposes a novel Custom Loss Function (CLF) designed to explicitly balance predictive accuracy with training stability, reducing sensitivity to these stochastic factors. 3. Demonstrates through extensive experiments on diverse architectures and tasks (image classification, time series forecasting) that CLF significantly improves training robustness without sacrificing predictive performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0accb01febbfd00a3b2c4650b921cc29a716544cb9a8fbc39d5a8ebe82c21bf6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0accb01febbfd00a3b2c4650b921cc29a716544cb9a8fbc39d5a8ebe82c21bf6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of inconsistent model performance across training runs due to stochastic factors. It proposes a Custom Loss Function (CLF) to explicitly balance accuracy and stability, which is shown to improve training robustness without harming predictive performance in experiments on image classification and time series forecasting.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Priority-Aware Multi-Robot Coverage Path Planning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multi-robot path planning], [coverage path planning, priority-weighted latency, lexicographic optimization, spanning-tree, Steiner-tree]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kanghoon Lee, Hyeonjun Kim, Jiachen Li, Jinkyoo Park</p>
</li>
<li class="">
<p><strong>institution:</strong> Korea Advanced Institute of Science and Technology (KAIST), Korea Military Academy (KMA), University of California, Riverside (UCR)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00580" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00580</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formally defines the Priority-Aware Multi-Robot Coverage Path Planning (PA-MCPP) problem, introducing priority weights and a lexicographic objective to minimize priority-weighted latency and makespan. 2. Proposes a scalable two-phase framework combining greedy zone assignment with local search and Steiner-tree-guided residual coverage. 3. Demonstrates through experiments that the method significantly reduces priority-weighted latency compared to baselines while maintaining competitive makespan and scales well with the number of robots.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4091ae11f186a26844a6a1c27c13cf633fa92da4e6636d53275a7d839f775d9f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4091ae11f186a26844a6a1c27c13cf633fa92da4e6636d53275a7d839f775d9f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitation of standard multi-robot coverage path planning, which treats all areas equally, by introducing a priority-aware version (PA-MCPP) where certain zones have higher urgency. The authors propose a two-phase method that first assigns and covers priority zones efficiently and then handles the remaining area. Experiments show their approach successfully reduces coverage delay for high-priority zones without significantly compromising the overall completion time.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [Mixture-of-Experts, federated fine-tuning, resource-aware, expert selection, sparsity-aware aggregation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zihan Fang, Zheng Lin, Senkang Hu, Yanan Ma, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang</p>
</li>
<li class="">
<p><strong>institution:</strong> City University of Hong Kong, The University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00583" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00583</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a method to identify expert importance based on contributions to fine-tuning performance, enabling informed expert selection. 2. Proposes an adaptive expert subset selection mechanism from an information bottleneck perspective to align with heterogeneous client computing budgets. 3. Designs a sparsity-aware model aggregation strategy that weights updates from actively fine-tuned experts and gating parameters to mitigate destructive interference during global aggregation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a4349d6a95221a61360e261ad370cd60546e55c0ae19bef19bfe4f05de72ff4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a4349d6a95221a61360e261ad370cd60546e55c0ae19bef19bfe4f05de72ff4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes HFedMoE, a heterogeneous federated learning framework for fine-tuning large language models using Mixture-of-Experts. It addresses challenges in expert selection, resource heterogeneity, and aggregation interference by customizing expert subsets per client and using importance-weighted aggregation. Experiments show HFedMoE outperforms state-of-the-art methods in accuracy and convergence speed.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Noise-Robust Tiny Object Localization with Flows</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [object detection], [Tiny Object Detection, Noise Robustness, Normalizing Flows, Uncertainty-Guided Optimization, Flow-Based Error Modeling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huixin Sun, Linlin Yang, Ronyu Chen, Kerui Gu, Baochang Zhang, Angela Yao, Xianbin Cao</p>
</li>
<li class="">
<p><strong>institution:</strong> Beihang University, Communication University of China, National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00617" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00617</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Tiny Object Localization with Flows (TOLF), a noise-robust framework for tiny object detection. 2. Introduces flow-based error modeling to capture complex, non-Gaussian prediction distributions for robust learning under noisy supervision. 3. Designs an uncertainty-aware gradient modulation mechanism to suppress learning from high-uncertainty, noise-prone samples, mitigating overfitting.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b7f3a1410f8fcc28ad5c6cee9bc7ead457cf793040466a768ce5024835633cf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1b7f3a1410f8fcc28ad5c6cee9bc7ead457cf793040466a768ce5024835633cf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of tiny object detection being highly sensitive to annotation noise, which leads to overfitting. The authors propose TOLF, a framework using normalizing flows for flexible error modeling and uncertainty-guided optimization to learn robustly from noisy labels. Experiments show TOLF effectively improves performance, boosting a DINO baseline by 1.2% AP on the AI-TOD dataset.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [submodular optimization], [weakly DR-submodular, continuous-greedy, Frank-Wolfe, approximation algorithm, down-closed convex body]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hareshkumar Jadav, Ranveer Singh, Vaneet Aggarwal</p>
</li>
<li class="">
<p><strong>institution:</strong> IIT Indore, Purdue University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00611" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00611</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel approximation algorithm for maximizing non-monotone γ-weakly DR-submodular functions over down-closed convex bodies. 2. A smooth approximation guarantee that recovers the 0.401 factor for DR-submodular (γ=1) and degrades gracefully for γ&lt;1, improving upon prior bounds. 3. A hybrid algorithmic framework combining Frank-Wolfe-guided continuous-greedy with a γ-aware double-greedy step to handle non-monotonicity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3fb1d9788f036c8398d4ed9b82b8201cf4616c9a51d4916ebe91884a9996b77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3fb1d9788f036c8398d4ed9b82b8201cf4616c9a51d4916ebe91884a9996b77_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of maximizing non-monotone, nonnegative γ-weakly DR-submodular functions over down-closed convex bodies. The authors propose a new algorithm that integrates a Frank-Wolfe-guided continuous-greedy approach with a γ-aware double-greedy step. This method achieves state-of-the-art approximation guarantees that depend smoothly on the parameter γ, improving upon previous results for this class of functions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal learning], [Direct Preference Optimization, hallucination mitigation, difficulty-aware learning, multimodal large language models, preference data imbalance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Longtian Qiu, Shan Ning, Chuyu Zhang, Jiaxuan Sun, Xuming He</p>
</li>
<li class="">
<p><strong>institution:</strong> ShanghaiTech University, Lingang Laboratory, Shanghai Engineering Research Center of Intelligent Vision and Imaging</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00623" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00623</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://artanic30.github.io/project_pages/DA-DPO" target="_blank" rel="noopener noreferrer" class="">https://artanic30.github.io/project_pages/DA-DPO</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and analyzes the problem of difficulty imbalance in multimodal DPO training, where models overfit to easy preference pairs. 2. Proposes a novel Difficulty-Aware DPO (DA-DPO) framework with a training-free difficulty estimation module using pre-trained VLMs and a distribution-aware voting strategy. 3. Introduces a difficulty-aware training mechanism that reweights preference pairs to prioritize harder examples, improving hallucination suppression and generalization without extra data or fine-tuning stages.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66cedf9b64154fde20f2a21a0c0dbc301932351057de033cf8e0323686aec2bc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66cedf9b64154fde20f2a21a0c0dbc301932351057de033cf8e0323686aec2bc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of Multimodal Large Language Models (MLLMs) overfitting to easy samples during Direct Preference Optimization (DPO), which limits hallucination reduction. It proposes DA-DPO, a cost-efficient framework that estimates sample difficulty without training and reweights the loss to focus on harder examples. Experiments show DA-DPO improves robustness to hallucinations and generalization across benchmarks while remaining computationally efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [interpretable machine learning], [Bi-objective Optimization, Temporal Integrated Gradients, Optimal Path Oracle, Directed Acyclic Graph, Structured Regularization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kasra Fouladi, Hamta Rahmani</p>
</li>
<li class="">
<p><strong>institution:</strong> Not explicitly stated; inferred from email domains as independent researchers.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00655" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00655</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the IGBO framework that trains interpretable models by formalizing the task as a bi-objective optimization problem, jointly optimizing for accuracy and adherence to domain knowledge constraints. 2. Introduces an Optimal Path Oracle to generate data-manifold-aware integration paths, addressing the Out-of-Distribution problem in Temporal Integrated Gradients computation. 3. Provides theoretical analysis proving convergence properties and robustness to mini-batch noise, and demonstrates empirical effectiveness on time-series data with minimal accuracy loss.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/797ceec0d9225c3c9714a73c2ff308494df8996ce6022916738679549e999bd1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/797ceec0d9225c3c9714a73c2ff308494df8996ce6022916738679549e999bd1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains models to be both accurate and interpretable by jointly optimizing a task loss and an interpretability loss derived from domain knowledge encoded as a DAG. It addresses a key challenge in gradient-based attribution (the OOD problem) by learning an Optimal Path Oracle. Empirical results show IGBO effectively enforces interpretability constraints with minimal impact on accuracy, outperforming standard regularization methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [talking head generation], [diffusion forcing, direct preference optimization, real-time interaction, low latency, multimodal inputs]</p>
</li>
<li class="">
<p><strong>authors:</strong> Taekyung Ki, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Sung Ju Hwang</p>
</li>
<li class="">
<p><strong>institution:</strong> KAIST, NTU Singapore, DeepAuto.ai</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00664" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00664</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://taekyungki.github.io/AvatarForcing" target="_blank" rel="noopener noreferrer" class="">https://taekyungki.github.io/AvatarForcing</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Avatar Forcing, a framework using diffusion forcing for real-time interactive head avatar generation that processes multimodal user inputs with low latency. 2. Introduces a label-free direct preference optimization method using synthetic losing samples to learn expressive interactions. 3. Demonstrates real-time performance (~500ms latency, 6.8x speedup) and generates avatars preferred over 80% against the baseline for expressiveness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17340b71396da059acb45bce5718d0e4a786ccf313c43918ba84c25b9384bb11_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17340b71396da059acb45bce5718d0e4a786ccf313c43918ba84c25b9384bb11_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the lack of truly interactive and emotionally engaging talking head avatars by proposing Avatar Forcing, a framework that uses diffusion forcing for real-time, low-latency generation and a direct preference optimization method for label-free learning of expressive reactions. The method achieves a significant speedup and produces avatar motions that are strongly preferred by users in evaluations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Fast-weight Product Key Memory</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [long-context language modeling], [product key memory, fast weights, episodic memory, gradient descent, long-context]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tianyu Zhao, Llion Jones</p>
</li>
<li class="">
<p><strong>institution:</strong> Sakana AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00671" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00671</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Fast-weight Product Key Memory (FwPKM), a novel architecture that transforms static Product Key Memory into a dynamic, fast-weight episodic memory., 2. Introduces a mechanism for dynamic parameter updates at both training and inference time via local chunk-level gradient descent, enabling rapid memorization and retrieval., 3. Demonstrates that FwPKM effectively complements semantic memory, significantly reduces perplexity on long-context data, and shows strong generalization to contexts much longer than those seen during training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc5e7437ccdc396cc0c89f8bda772596a4ad71d82cd906f8eae81c22b107608_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc5e7437ccdc396cc0c89f8bda772596a4ad71d82cd906f8eae81c22b107608_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the trade-off between storage capacity and computational efficiency in sequence modeling layers. It proposes Fast-weight Product Key Memory (FwPKM), a dynamic architecture that updates parameters via local gradient descent to act as an episodic memory. Experiments show FwPKM reduces perplexity on long-context datasets and generalizes well to sequences much longer than those in training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Generative Reward Models, Bradley-Terry Model, Group Relative Policy Optimization, Reinforcement Learning from Human Feedback, Pointwise Scoring]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haonan Song, Qingchen Xie, Huan Zhu, Feng Xiao, Luxi Xing, Fuzhen Li, Liu Kang, Feng Jiang, Zhiyong Zheng, Fan Yang</p>
</li>
<li class="">
<p><strong>institution:</strong> HUJING Digital Media &amp; Entertainment Group (XingYun Lab), Tsinghua University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00677" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00677</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes IRPO, a novel RL framework that integrates the Bradley-Terry model into GRPO to scale pairwise reward models for RL training. 2. Introduces a pointwise scoring mechanism that enables efficient evaluation of many candidate responses during RL, overcoming the O(n^2) computational bottleneck. 3. Demonstrates state-of-the-art performance among pointwise GRMs and shows significant advantages over pairwise GRMs in post-training evaluations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cc90e0083ca0244ea3fbdd445ab9a0b8ff4478f444643d38c88fecae22744f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5cc90e0083ca0244ea3fbdd445ab9a0b8ff4478f444643d38c88fecae22744f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational bottleneck of pairwise Generative Reward Models (GRMs) in reinforcement learning by proposing Intergroup Relative Preference Optimization (IRPO). IRPO incorporates the Bradley-Terry model into Group Relative Policy Optimization to generate pointwise scores, enabling efficient evaluation of many candidates. The method achieves state-of-the-art performance among pointwise GRMs and outperforms pairwise GRMs in post-training evaluations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [quantization, spike-driven language models (SLMs), memory footprint, tiered search, embedded systems]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rachmad Vidya Wicaksana Putra, Pasindu Wickramasinghe, Muhammad Shafique</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University (NYU) Abu Dhabi</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00679" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00679</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes QSLM, an automated quantization framework for compressing pre-trained Spike-driven Language Models (SLMs) to meet performance and memory constraints. 2. Introduces a tiered quantization strategy (global-, block-, and module-level) guided by network hierarchy and layer sensitivity analysis. 3. Leverages a multi-objective performance-and-memory trade-off function to select the final quantization setting, achieving significant memory and power reduction while maintaining high task performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/911838f93e33219fcf586121369dd081b9908c86a1169c367cfdd1bb7e50139b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/911838f93e33219fcf586121369dd081b9908c86a1169c367cfdd1bb7e50139b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes QSLM, an automated framework for quantizing Spike-driven Language Models (SLMs) to reduce their memory footprint for embedded deployment. It uses a tiered search strategy based on network hierarchy and layer sensitivity, along with a multi-objective trade-off function, to find optimal quantization settings. Experimental results show QSLM can reduce memory by up to 86.5% and power by up to 20% while maintaining performance close to the original model.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [Large Language Models, Pedestrian Crossing Behavior, Vision-Augmented Reasoning, Domain Knowledge Adaptation, Low-Rank Adaptation (LoRA)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qingwen Pu, Kun Xie, Hong Yang, Guocong Zhai</p>
</li>
<li class="">
<p><strong>institution:</strong> Old Dominion University, Southwest Jiaotong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00694" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00694</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces PedX-LLM, a vision-and-knowledge enhanced LLM framework for generalizable pedestrian crossing behavior inference, shifting from site-specific pattern recognition to semantic reasoning. 2. Proposes integrating LLaVA-extracted visual features with textual data and domain knowledge to fine-tune a LLaMA-2-7B model via LoRA. 3. Demonstrates strong cross-site generalizability, where the model significantly outperforms baseline methods in zero-shot and few-shot settings on unseen environments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e948e9bb60b0f41e32522739a2caeb9dea0028b52570cf642f19e2d94faefef7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e948e9bb60b0f41e32522739a2caeb9dea0028b52570cf642f19e2d94faefef7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes PedX-LLM, a framework that enhances a large language model (LLaMA-2-7B) with visual features and domain knowledge to infer pedestrian crossing decisions. It achieves higher accuracy than traditional methods and demonstrates strong generalization to unseen sites, showing that vision-and-knowledge-enhanced reasoning overcomes the limitations of purely data-driven approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [domain adaptation], [data shift detection, performance degradation monitoring, vision-language model, confidence-based indicator, digital pathology]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hao Guan, Li Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Brigham and Women&#x27;s Hospital, Harvard Medical School</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00716</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed DomainSAT, a lightweight toolbox with a graphical interface for systematic analysis and intuitive exploration of input data shift. 2. Introduced a label-free, confidence-based degradation indicator for output-based monitoring that directly captures changes in model prediction confidence. 3. Demonstrated that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a1e297333bf6471523693e104d6b047f585e96fad854f63687658f33d5b22d7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a1e297333bf6471523693e104d6b047f585e96fad854f63687658f33d5b22d7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how to detect performance degradation in a pathology Vision-Language Model (VLM) when the input data distribution shifts after deployment. The authors propose a two-part framework: analyzing input-level data shift using their developed toolbox, DomainSAT, and monitoring output-level prediction confidence with a new label-free indicator. Their experiments show that combining these input and output monitoring methods provides a more reliable and complementary approach for detecting model degradation under data shift in digital pathology.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] An Agentic Framework for Neuro-Symbolic Programming</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [neuro-symbolic programming, agentic workflow, declarative programming, DomiKnowS, human-in-the-loop]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aliakbar Nafar, Chetan Chigurupati, Danial Kamali, Hamid Karimian, Parisa Kordjamshidi</p>
</li>
<li class="">
<p><strong>institution:</strong> Michigan State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00743" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00743</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces AgenticDomiKnowS (ADS), a framework that translates natural language task descriptions into complete neuro-symbolic programs for the DomiKnowS library. 2. Employs an agentic workflow that breaks program generation into stages, generating, executing, and refining each component independently for higher accuracy. 3. Supports optional human-in-the-loop intervention, allowing both experienced and novice users to rapidly build programs, reducing development time from hours to minutes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8ba19ac112f8b6ab345bafea964dbc29f08a66659e47452cb34cd423893719c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8ba19ac112f8b6ab345bafea964dbc29f08a66659e47452cb34cd423893719c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of authoring neuro-symbolic programs, which is time-consuming and requires expertise in specific library syntax. It proposes AgenticDomiKnowS (ADS), an agentic framework that generates complete programs from free-form descriptions by creating and testing components in stages, with optional human refinement. This approach enables both experts and non-users to construct programs much faster, reducing development time significantly.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Exploring the Performance of Large Language Models on Subjective Span Identification Tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [span identification], [large language models, in-context learning, chain of thought, aspect-based sentiment analysis, subjective spans]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alphaeus Dmonte, Roland Oruche, Tharindu Ranasinghe, Marcos Zampieri, Prasad Calyam</p>
</li>
<li class="">
<p><strong>institution:</strong> George Mason University, University of Missouri, Lancaster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00736</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Evaluates LLMs on subjective span identification tasks (sentiment analysis, offensive language identification, claim verification), an underexplored area compared to explicit tasks like NER. 2. Explores multiple LLM strategies including instruction tuning, in-context learning, and chain of thought for span identification. 3. Provides empirical results indicating that underlying textual relationships aid LLMs in identifying precise text spans.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c33271e2c603477b20beb01a7eafd35b6ae5eb8b9dfab2b53139ccf619c75074_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c33271e2c603477b20beb01a7eafd35b6ae5eb8b9dfab2b53139ccf619c75074_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates the performance of Large Language Models on subjective text span identification tasks, such as sentiment analysis and offensive language detection, using strategies like in-context learning and chain of thought. The study finds that LLMs benefit from underlying relationships within the text to identify accurate spans, addressing a gap in current research focused on explicit span tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [actor-critic, overestimation, aleatoric uncertainty, distributional critic, dropout]</p>
</li>
<li class="">
<p><strong>authors:</strong> Uğurcan Özalp</p>
</li>
<li class="">
<p><strong>institution:</strong> Turkish Aerospace</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00737</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Stochastic Actor-Critic (STAC), a novel algorithm that uses temporal aleatoric uncertainty (from stochastic transitions, rewards, and policy) to scale pessimistic bias in TD updates, instead of relying on epistemic uncertainty. 2. Demonstrates that a single distributional critic network modeling return uncertainty is sufficient to mitigate overestimation and induce risk-averse behavior. 3. Shows that applying dropout for regularization in both actor and critic networks further improves training stability and performance, enhancing computational efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/602bf8125f08dc0296e56b4a9e156cd6089d329c07cd83909cc1b3c96effc1bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/602bf8125f08dc0296e56b4a9e156cd6089d329c07cd83909cc1b3c96effc1bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of overestimation bias in off-policy actor-critic reinforcement learning methods. It proposes the Stochastic Actor-Critic (STAC) algorithm, which mitigates overestimation by using a single distributional critic to model temporal aleatoric uncertainty for scaling pessimistic updates, and employs dropout for regularization. The results show that this approach effectively reduces overestimation, leads to risk-averse behavior, and improves computational efficiency and training stability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [LLM agents, combinatorial optimization, portfolio optimization, heuristic algorithms, mixed-integer quadratic programming]</p>
</li>
<li class="">
<p><strong>authors:</strong> Simon Paquette-Greenbaum, Jiangbo Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> McGill University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00770" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00770</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Implements a novel LLM agentic framework for the Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem. 2. Explores and evaluates several concrete agentic architectures for automating complex portfolio optimization workflows. 3. Demonstrates that the framework matches state-of-the-art algorithms in benchmarks, alleviating development effort while maintaining acceptable performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/675ab12face3ffa5a24cbba64bf47553eac6b08cadcc7ab86dc8312ae824f240_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/675ab12face3ffa5a24cbba64bf47553eac6b08cadcc7ab86dc8312ae824f240_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes using LLM agents to automate the complex workflows and heuristic algorithm development for Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO), a challenging combinatorial problem. The implemented agentic framework matches state-of-the-art algorithm performance on benchmarks, significantly reducing manual effort in the optimization process.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning verification], [spectral graph analysis, attention patterns, Fiedler value, high-frequency energy ratio, sliding window attention]</p>
</li>
<li class="">
<p><strong>authors:</strong> Valentin Noël</p>
</li>
<li class="">
<p><strong>institution:</strong> Devoteam</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00791" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00791</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a training-free method for detecting valid mathematical reasoning in LLMs by performing spectral analysis on attention matrices treated as dynamic graphs. 2. Identified four interpretable spectral diagnostics (Fiedler value, HFER, smoothness, entropy) that show significant statistical differences between valid and invalid proofs across multiple model families. 3. Discovered that the method captures logical coherence rather than formal verifier acceptance and revealed an architectural dependency where different attention mechanisms (e.g., Sliding Window Attention) shift the primary discriminative spectral feature.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes a training-free method to detect valid mathematical reasoning in large language models by analyzing the spectral properties of attention patterns. The method identifies key spectral signatures that effectively distinguish between valid and invalid proofs with high accuracy. The findings show the method captures logical coherence and its effectiveness depends on the model&#x27;s attention architecture.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [hypernetwork, conditional VAE, differential privacy, MMD alignment, client heterogeneity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sunny Gupta, Amit Sethi</p>
</li>
<li class="">
<p><strong>institution:</strong> Indian Institute of Technology Bombay</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00785" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00785</a></p>
</li>
<li class="">
<p><strong>code:</strong> github.com/sunnyinAI/FedHypeVAE</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A bi-level framework using a shared hypernetwork to generate personalized, client-aware decoders and class-conditional priors for a conditional VAE, decoupling local data from shared parameters. 2. Incorporation of differential privacy during hypernetwork optimization with noise-perturbed, clipped gradients to provide formal privacy guarantees against gradient leakage. 3. Introduction of a local MMD alignment loss and Lipschitz regularization to enhance stability and distributional coherence under non-IID data conditions, along with a neutral meta-code for domain-agnostic synthesis.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726225d41733e7b16755efae5f3b9ec28771c58479913c7f5581e9843368fd0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726225d41733e7b16755efae5f3b9ec28771c58479913c7f5581e9843368fd0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes FedHypeVAE, a federated learning framework that uses a differentially private hypernetwork to generate personalized conditional VAEs for synthesizing embedding-level data across decentralized clients. It addresses challenges of non-IID data and privacy by decoupling local data from shared parameters and ensuring formal privacy guarantees. The method establishes a foundation for privacy-preserving data synthesis in federated settings by unifying personalization, privacy, and distribution alignment at the generator level.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neural fields, signal processing], [Neural Radiance Fields (NeRF), EEG, brain-computer interfaces, signal reconstruction, continuous representation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shahar Ain Kedem, Itamar Zimerman, Eliya Nachmani</p>
</li>
<li class="">
<p><strong>institution:</strong> Ben Gurion University of the Negev, Tel Aviv University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00012" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00012</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Shaharak88/neural-brain-fields" target="_blank" rel="noopener noreferrer" class="">https://github.com/Shaharak88/neural-brain-fields</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel NeRF-inspired method to learn a continuous representation of brain activity from discrete EEG electrode data. 2. Enables rendering of EEG signals at unseen time steps and spatial electrode positions, including simulating non-existent electrodes. 3. Demonstrates that the reconstructed signals can be used to improve the performance of standard EEG processing networks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79dda8675c25fe2c8906136ddc20e55e51c835cb08bed2a4e02388b7dadc16da_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79dda8675c25fe2c8906136ddc20e55e51c835cb08bed2a4e02388b7dadc16da_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Neural Brain Fields, a method inspired by Neural Radiance Fields (NeRF) to model EEG data. It trains a neural network on a single EEG sample to produce a fixed-size weight vector that encodes the continuous neural activity, allowing for signal reconstruction at any time or scalp location. The approach effectively generates data for non-existent electrodes, which can enhance downstream EEG analysis tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [health informatics], [deep learning, Holter ECG, explainable AI, time series analysis, risk prediction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eran Zvuloni, Ronit Almog, Michael Glikson, Shany Brimer Biton, Ilan Green, Izhar Laufer, Offer Amir, Joachim A. Behar</p>
</li>
<li class="">
<p><strong>institution:</strong> Technion - Israel Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00014</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed DeepHHF, a deep learning model that uses full 24-hour single-lead ECG recordings for heart failure risk prediction, outperforming models using short segments and clinical scores. 2. Created and utilized the large-scale Technion-Leumit Holter ECG (TLHE) dataset, comprising 69,663 recordings from 47,729 patients collected over 20 years. 3. Provided explainability analysis showing the model focuses on arrhythmias and heart abnormalities, with key attention patterns during daytime hours (8 AM to 3 PM), linking model decisions to clinically relevant features.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa3d768712a10f4b2d45732f0f8e0d64f70a07add2581bf81c12c996da11b77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfa3d768712a10f4b2d45732f0f8e0d64f70a07add2581bf81c12c996da11b77_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes DeepHHF, a deep learning model that analyzes 24-hour single-lead ECG data to predict the 5-year risk of heart failure. The model achieved an AUC of 0.80, outperforming baseline methods, and identified high-risk individuals with a two-fold increased chance of hospitalization or death. The study demonstrates the feasibility of using long-term, continuous ECG data and explainable AI for non-invasive and accessible heart failure risk prediction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] MethConvTransformer: A Deep Learning Framework for Cross-Tissue Alzheimer&#x27;s Disease Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [computational biology / bioinformatics], [DNA methylation, transformer, explainable AI (XAI), cross-tissue analysis, Alzheimer&#x27;s disease]</p>
</li>
<li class="">
<p><strong>authors:</strong> Gang Qu, Guanghao Li, Zhongming Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Texas Health Science Center at Houston</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00143" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00143</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed MethConvTransformer, a novel deep learning framework integrating convolutional and self-attention layers to capture local and long-range dependencies in DNA methylation data for Alzheimer&#x27;s disease detection. 2. Introduced a method to incorporate subject-level covariates and tissue embeddings to disentangle shared and tissue-specific epigenetic effects, enabling robust cross-tissue biomarker discovery. 3. Demonstrated the model&#x27;s superior performance and generalizability across multiple datasets and provided multi-resolution interpretability linking methylation patterns to known AD biological pathways.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd7853219944463e4a18ac7001e74a3c4474f9652d2f82ee38649d92981bed5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5bd7853219944463e4a18ac7001e74a3c4474f9652d2f82ee38649d92981bed5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of detecting Alzheimer&#x27;s disease using DNA methylation data, which varies across tissues. The authors propose MethConvTransformer, a deep learning model that combines convolutional and transformer layers to analyze methylation patterns from brain and peripheral tissues. The model outperforms baselines, provides interpretable biomarkers, and identifies disease-relevant biological pathways.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Democratizing Electronic-Photonic AI Systems: An Open-Source AI-Infused Cross-Layer Co-Design and Design Automation Toolflow</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [electronic-photonic design automation, cross-layer co-design, inverse photonic design, AI-accelerated Maxwell solvers, photonic AI system]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hongjian Zhou, Ziang Yin, Jiaqi Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Arizona State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00130" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00130</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a cross-layer co-design framework for scalable photonic edge AI and Transformer inference architectures. 2. Introduced SimPhony, an open-source modeling tool for rapid EPIC AI system evaluation and design-space exploration. 3. Developed AI-enabled photonic design automation techniques, including physical AI-based Maxwell solvers and a fabrication-aware inverse design framework.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76312a14ab1d9b01be6967c891d86f1c36fb6eebdf382d27578721d3ff3e1c24_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76312a14ab1d9b01be6967c891d86f1c36fb6eebdf382d27578721d3ff3e1c24_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of designing electronic-photonic AI systems by proposing an open-source, AI-infused cross-layer co-design and automation framework. The method includes architecture designs for photonic AI, a modeling tool called SimPhony, and AI-powered design automation tools. The work aims to democratize and accelerate the development of next-generation photonic AI systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Neural Minimum Weight Perfect Matching for Quantum Error Codes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [Quantum Error Correction, Minimum Weight Perfect Matching, Graph Neural Networks, Transformer, Hybrid Decoder]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yotam Peled, David Zenati, Eliya Nachmani</p>
</li>
<li class="">
<p><strong>institution:</strong> Ben-Gurion University of the Negev</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00242" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00242</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a hybrid decoder (NMWPM) that integrates GNNs and Transformers to predict dynamic edge weights for the MWPM algorithm. 2. Formulated a novel proxy loss function to enable end-to-end training through the non-differentiable MWPM algorithm. 3. Demonstrated a significant reduction in Logical Error Rate (LER) compared to standard baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e507723ea614845b9a945c6d086d7f6413ab64a2e5cbfa21b28ceaa1777ffa60_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e507723ea614845b9a945c6d086d7f6413ab64a2e5cbfa21b28ceaa1777ffa60_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a neural-enhanced decoder for quantum error correction called Neural Minimum Weight Perfect Matching (NMWPM). It uses a hybrid architecture of Graph Neural Networks and Transformers to predict dynamic edge weights for the classical MWPM decoder, trained with a novel proxy loss. The method significantly reduces the Logical Error Rate, showing the advantage of combining neural networks with classical algorithms.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Toward Large-Scale Photonics-Empowered AI Systems: From Physical Design Automation to System-Algorithm Co-Exploration</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [photonic AI, electronic-photonic design automation (EPDA), system-algorithm co-exploration, cross-layer toolchain, physical design automation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ziang Yin, Hongjian Zhou, Nicholas Gangi, Meng Zhang, Jeff Zhang, Zhaoran Rena Huang, Jiaqi Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Arizona State University, Rensselaer Polytechnic Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00129" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00129</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified three essential considerations for scaling practical photonic AI systems: dynamic tensor operation support, systematic management of overheads, and robustness under hardware non-idealities. 2. Built a cross-layer toolchain (SimPhony, ADEPT, ADEPT-Z, Apollo, LiDAR) for quantitative, physically-grounded co-design from system exploration to physical layout. 3. Established a co-design loop that bridges architectural intent and deployable photonic hardware by translating physical costs into system-level metrics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd0ce87d1ffb64d07fd82b197f024f167052c6fb76c061ecf0885e18f056796_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bdd0ce87d1ffb64d07fd82b197f024f167052c6fb76c061ecf0885e18f056796_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of scaling photonic AI systems by identifying key design considerations and developing a cross-layer toolchain for system-algorithm co-exploration. The proposed method uses tools like SimPhony and Apollo to model physical costs and automate design, enabling quantitative trade-off analysis under real implementation constraints. The main conclusion is that this approach creates a physically-grounded co-design loop essential for realizing large-scale, deployable photonic AI hardware.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Hear the Heartbeat in Phases: Physiologically Grounded Phase-Aware ECG Biometrics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [biometrics], [ECG biometrics, phase-aware representation, hierarchical fusion, multi-prototype enrollment, graph neural networks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jintao Huang, Lu Leng, Yi Zhang, Ziyuan Yang</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanchang Hangkong University, Sichuan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00170" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00170</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a Hierarchical Phase-Aware Fusion (HPAF) framework with a three-stage design (Intra-Phase Representation, Phase-Grouped Hierarchical Fusion, Global Representation Fusion) to explicitly model phase-specific characteristics within the cardiac cycle and avoid cross-feature entanglement. 2. Introduced a Heartbeat-Aware Multi-prototype (HAM) enrollment strategy to construct a multi-prototype gallery template set, mitigating the impact of heartbeat-specific noise and variability. 3. Demonstrated state-of-the-art performance on three public datasets under both closed and open-set settings, validating the effectiveness of the physiologically grounded approach.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2278c4a79bd346845b69356eeced50030b7ff8a854aa0dc0165503f22a96a9e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2278c4a79bd346845b69356eeced50030b7ff8a854aa0dc0165503f22a96a9e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that existing ECG biometric methods treat heartbeats as homogeneous, overlooking phase-specific characteristics. It proposes a Hierarchical Phase-Aware Fusion (HPAF) framework to independently model and hierarchically fuse features from different cardiac phases, along with a multi-prototype enrollment strategy. The method achieves state-of-the-art results on public datasets, showing the benefit of a physiologically grounded, phase-aware approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Benchmarking Preprocessing and Integration Methods in Single-Cell Genomics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [computational biology], [single-cell genomics, data integration, normalization, dimensionality reduction, benchmarking]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ali Anaissi, Seid Miad Zandavi, Weidong Huang, Junaid Akram, Basem Suleiman, Ali Braytee, Jie Hua</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Technology Sydney, University of Sydney, Broad Institute, University of New South Wales, Shaoyang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00277</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a systematic evaluation of preprocessing and integration methods for single-cell multimodal data, which had been lacking. 2. Benchmarked a comprehensive pipeline involving combinations of seven normalization, five integration, and four dimensionality reduction methods across six diverse datasets. 3. Provided empirical findings on the performance and time-efficiency of leading methods, identifying Seurat and Harmony as top performers and highlighting the compatibility of UMAP.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7cf9641df8a7176dd7483adbf7e7c16827ddac25d332fe518d19b7c39109f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7cf9641df8a7176dd7483adbf7e7c16827ddac25d332fe518d19b7c39109f9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper systematically benchmarks combinations of preprocessing and integration methods for single-cell multimodal genomic data. The study evaluates various normalization, integration, and dimensionality reduction techniques across diverse datasets. The results show that Seurat and Harmony excel at integration, with Harmony being more time-efficient, and UMAP is the most compatible dimensionality reduction method.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [multi-functional RIS, NOMA, energy efficiency, hybrid deep reinforcement learning, parametrized sharing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chi-Te Kuo, Li-Hsiang Shen, Jyun-Jhe Huang</p>
</li>
<li class="">
<p><strong>institution:</strong> National Central University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00538" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00538</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formulates an energy efficiency maximization problem for a multi-MF-RIS-aided NOMA downlink network, jointly optimizing power, beamforming, RIS configurations, and RIS positions. 2. Proposes a Parametrized Sharing scheme for Multi-Agent Hybrid Deep Reinforcement Learning (PMHRL) that combines multi-agent PPO for continuous variables and DQN for discrete variables. 3. Demonstrates through simulations that the proposed PMHRL and multi-MF-RIS architecture achieve superior energy efficiency compared to various benchmarks and alternative system scenarios.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62f2884171c264fbe837606dbe74e9d01169f9c8afd169da9b9bed765c6ab97e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62f2884171c264fbe837606dbe74e9d01169f9c8afd169da9b9bed765c6ab97e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of maximizing energy efficiency in downlink NOMA networks assisted by multiple multi-functional RISs. The authors propose a novel parametrized sharing scheme for a multi-agent hybrid deep reinforcement learning algorithm (PMHRL) to jointly optimize power, beamforming, and RIS parameters. Simulation results show that the proposed method achieves the highest energy efficiency compared to other benchmarks and system configurations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-01-05T03:17:11.000Z" itemprop="dateModified">Jan 5, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/csai/20251229-20260104"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251229-20260104 (cs.AI)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/csar"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.AR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-01-05" class="table-of-contents__link toc-highlight">2026-01-05</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2026-01</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><div class="calendar-cell calendar-empty"></div><div class="calendar-cell calendar-empty"></div><div class="calendar-cell calendar-empty"></div><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2026-01-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2026-01-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2026-01-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20251229-20260104#2026-01-04">4</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260105-20260111#2026-01-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260112-20260118#2026-01-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260119-20260125#2026-01-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csai/20260126-20260201#2026-01-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>