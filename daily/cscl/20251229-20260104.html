<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_CL/20251229-20260104" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251229-20260104 (cs.CL) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/cscl/20251229-20260104"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251229-20260104 (cs.CL) | AI头条"><meta data-rh="true" name="description" content="2025-12-29"><meta data-rh="true" property="og:description" content="2025-12-29"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20251229-20260104"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20251229-20260104" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20251229-20260104" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.CL","item":"https://jokebear666.github.io/ai_toutiao/daily/cscl"},{"@type":"ListItem","position":3,"name":"20251229-20260104 (cs.CL)","item":"https://jokebear666.github.io/ai_toutiao/daily/cscl/20251229-20260104"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.647bd1ff.css">
<script src="/ai_toutiao/assets/js/runtime~main.f73b021c.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.6153aad8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Collapse sidebar category &#x27;cs.CL&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_CL/20251215-20251221"><span title="20251215-20251221 (cs.CL)" class="linkLabel_WmDU">20251215-20251221 (cs.CL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cscl/20251222-20251228"><span title="20251222-20251228 (cs.CL)" class="linkLabel_WmDU">20251222-20251228 (cs.CL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/cscl/20251229-20260104"><span title="20251229-20260104 (cs.CL)" class="linkLabel_WmDU">20251229-20260104 (cs.CL)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/cscl"><span>cs.CL</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251229-20260104 (cs.CL)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251229-20260104 (cs.CL)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-29">2025-12-29<a href="#2025-12-29" class="hash-link" aria-label="Direct link to 2025-12-29" title="Direct link to 2025-12-29" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251229] Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [db], [text-to-SQL], [unanswerable question detection, few-shot prompting, biomedical databases]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger</p>
</li>
<li class="">
<p><strong>institution:</strong> Zurich University of Applied Sciences, University of Zurich</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21345" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21345</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Teaching People LLM&#x27;s Errors and Getting it Right</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [human-ai interaction], [overreliance, failure patterns, mental models, user study, meta-labels]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasović</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Utah</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21422" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21422</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness—assessing a user&#x27;s ability to anticipate LLM errors using taught patterns—which showed a positive effect, unlike traditional human-AI team accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [computational ethics], [moral context, probabilistic clustering, LLM semantics, interpretable prediction, human judgment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Intelligent Systems and Robotics, Sorbonne University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21439</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Oogiri-Master: Benchmarking Humor Understanding via Oogiri</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [humor understanding], [Oogiri, benchmark, linguistic analysis, incongruity resolution, insight-augmented prompting]</p>
</li>
<li class="">
<p><strong>authors:</strong> Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura</p>
</li>
<li class="">
<p><strong>institution:</strong> CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21494" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21494</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [wearable sensing, actigraphy encoder, projection module, frozen LLM, behavioral summarization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson</p>
</li>
<li class="">
<p><strong>institution:</strong> Dartmouth College</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21506</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Perplexity-Aware Data Scaling Law: Perplexity Landscapes Predict Performance for Continual Pre-training</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [continual pre-training, scaling laws, perplexity, data selection, knowledge gap]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lei Liu, Hao Zhu, Yue Shen, Zhixuan Chu, Jian Wang, Jinjie Gu, Kui Ren</p>
</li>
<li class="">
<p><strong>institution:</strong> Ant Group, Zhejiang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21515" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21515</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel perplexity-aware data scaling law that predicts model test loss from the perplexity landscape of domain data, moving beyond dataset size. 2. Introduces the concept of &quot;perplexity landscapes&quot; to quantify the informational value and knowledge gap of candidate training samples. 3. Enables adaptive selection of high-utility data subsets for Continual Pre-training, improving efficiency and performance by prioritizing informative content and reducing redundancy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d01b1cad6e908309c7e813cb1d98f2c41345aa1e4d78cbdaf163996c5d111b4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d01b1cad6e908309c7e813cb1d98f2c41345aa1e4d78cbdaf163996c5d111b4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the inefficiency of scaling data for Continual Pre-training (CPT) of LLMs, where simply adding more data yields diminishing returns. The authors propose a new scaling law that uses the model&#x27;s perplexity on domain data as a proxy for the knowledge gap, allowing for the predictive selection of optimal training subsets. Experiments show this method consistently identifies high-utility data, leading to superior performance on domain-specific benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [human-ai interaction], [bidirectional alignment, value-centered design, interactive alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li</p>
</li>
<li class="">
<p><strong>institution:</strong> NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21551" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21551</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [external memory, sequential decision-making, value functions, uncertainty estimators, hierarchical storage]</p>
</li>
<li class="">
<p><strong>authors:</strong> Changzhi Sun, Xiangyu Chen, Jixiang Luo, Dell Zhang, Xuelong Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Artificial Intelligence (TeleAI), China Telecom</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21567" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21567</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/TeleAI-UAGI/telemem" target="_blank" rel="noopener noreferrer" class="">https://github.com/TeleAI-UAGI/telemem</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a decision-theoretic reframing of agent memory management as a sequential decision-making problem under uncertainty, 2. Introduces the DAM framework that decomposes memory operations into immediate access and hierarchical maintenance, 3. Provides a foundation for future research by evaluating operations via value functions and uncertainty estimators for long-term utility and risk</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d30748df565a671b29899dffbfb153dca58fed0398e13cc6871dfe6f450f11a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d30748df565a671b29899dffbfb153dca58fed0398e13cc6871dfe6f450f11a1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper argues that current heuristic-based memory management for LLM agents is inadequate due to delayed and uncertain utility. It proposes DAM, a decision-theoretic framework that uses value functions and uncertainty estimators to make memory decisions based on long-term consequences. The main contribution is a principled reframing of the problem to guide future research on uncertainty-aware memory systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Unified Definition of Hallucination, Or: It&#x27;s the World Model, Stupid</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection &amp; evaluation], [hallucination, world modeling, knowledge conflict, benchmark, language model evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng</p>
</li>
<li class="">
<p><strong>institution:</strong> Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21577" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21577</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models&#x27; world modeling capabilities.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Gamayun&#x27;s Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multilingual language modeling], [two-stage pre-training, cross-lingual alignment, English enrichment, cost-efficient training, Russian LLM]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alexander Podolskiy, Semen Molokov, Timofey Gerasin, Maksim Titov, Alexey Rukhovich, Artem Khrapov, Kirill Morozov, Evgeny Tetin, Constantine Korikov, Pavel Efimov, Polina Lazukova, Yuliya Skripkar, Nikita Okhotnikov, Irina Piontkovskaya, Meng Xiaojun, Zou Xueyi, Zhang Zhenhe</p>
</li>
<li class="">
<p><strong>institution:</strong> Gamayun Team</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21580" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21580</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel two-stage pre-training strategy (balanced multilingual training followed by high-quality English enrichment) for efficient cross-lingual knowledge transfer. 2. Presents Gamayun, a 1.5B-parameter multilingual LLM trained from scratch on 2.5T tokens, designed for resource-constrained environments. 3. Demonstrates state-of-the-art performance for its size (1-2B parameters) on Russian benchmarks and competitive results on English and multilingual tasks, despite a significantly smaller training budget than comparable models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b7ebd17e8a0b7536938c0d12aa8812a6376542abde4f40239a4622472c17ea0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b7ebd17e8a0b7536938c0d12aa8812a6376542abde4f40239a4622472c17ea0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Gamayun, a cost-efficient 1.5B-parameter multilingual language model. It addresses the lack of small non-English-centric LLMs through a novel two-stage pre-training strategy for cross-lingual alignment. The model achieves state-of-the-art results in Russian and outperforms larger models on many tasks, despite being trained on far fewer tokens.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Renmin University of China, The Chinese University of Hong Kong, Ant Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21625" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21625</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination evaluation], [HIC-Bench, Intelligent Hallucinations, Defective Hallucinations, Torrance Tests of Creative Thinking, Dynamic Hallucination Prompt]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chengxu Yang, Jingling Yuan, Siqi Cai, Jiawei Jiang, Chuang Hu</p>
</li>
<li class="">
<p><strong>institution:</strong> Wuhan University of Technology, Wuhan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21635" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21635</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/chujiguangniao/HIC-bench" target="_blank" rel="noopener noreferrer" class="">https://github.com/chujiguangniao/HIC-bench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes HIC-Bench, a novel evaluation framework that categorizes LLM hallucinations into Intelligent Hallucinations (IH) and Defective Hallucinations (DH) for systematic study. 2. Introduces a structured multi-dimensional assessment matrix combining TTCT creativity metrics (Originality, Feasibility, Value) with hallucination-specific dimensions (scientific plausibility, factual deviation). 3. Features cross-domain applicability across ten scientific domains and a Dynamic Prompt Optimization technique (DHP) to guide model outputs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb581f42c65746c28519ac82f0996a0d7ab8f6413a85636583ec1e0abecba3c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb581f42c65746c28519ac82f0996a0d7ab8f6413a85636583ec1e0abecba3c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of evaluating LLM hallucinations beyond factual errors by proposing HIC-Bench, a framework that distinguishes between creative (Intelligent) and erroneous (Defective) hallucinations using a multi-metric assessment. It demonstrates that creativity and correctness can be jointly optimized, revealing a nonlinear relationship between the two types of hallucinations and positioning intelligent hallucinations as a catalyst for scientific innovation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Semantic Codebooks as Effective Priors for Neural Speech Compression</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [speech compression], [semantic codebooks, residual vector quantization (RVQ), HuBERT, FiLM-conditioned decoder, neural audio codec]</p>
</li>
<li class="">
<p><strong>authors:</strong> Liuyang Bai, Weiyi Lu, Li Guo</p>
</li>
<li class="">
<p><strong>institution:</strong> NYU Shanghai</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21653" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21653</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SemDAC, a semantic-aware neural audio codec that uses semantic codebooks as priors for compression., 2. Introduces a design where the first RVQ quantizer is distilled from HuBERT to capture phonetic content, and a FiLM-conditioned decoder uses these semantic tokens., 3. Demonstrates superior performance over baseline DAC in perceptual metrics and ASR (Whisper) WER at significantly lower bitrates.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a14c953c6c23139c4473b8d6e59b36c7615f79f4316119e168deb19de30eced_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a14c953c6c23139c4473b8d6e59b36c7615f79f4316119e168deb19de30eced_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes SemDAC, a neural speech codec that uses semantic codebooks distilled from HuBERT as priors within an RVQ framework to separate phonetic from acoustic information. This method achieves better perceptual quality and lower word error rates for speech recognition at much lower bitrates compared to traditional neural codecs. The results show that semantic priors provide an effective inductive bias for efficient, recognition-friendly speech compression.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [spoken dialogue systems], [Graph-of-Thoughts, full-duplex, speech acts, causal inference, multimodal transformer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, University of California, Berkeley, Carnegie Mellon University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21706" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21706</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://got-duplex.github.io/" target="_blank" rel="noopener noreferrer" class="">https://got-duplex.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [ai-generated text detection], [transformer, fine-tuning, zero-shot, Bengali, paraphrase detection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan</p>
</li>
<li class="">
<p><strong>institution:</strong> Not specified in provided content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21709" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21709</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Parameter-Efficient Fine-Tuning (PEFT), Low-Rank Adaptation (LoRA), Mixture-of-Roles (MoR), Agent Tuning, Data Generation Pipeline]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jing Han, Binwei Yan, Tianyu Guo, Zheyuan Bai, Mengyu Zheng, Hanting Chen, Ying Nie</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing University of Posts and Telecommunications, Huawei Noah&#x27;s Ark Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21708" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21708</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://mor-agent.github.io/" target="_blank" rel="noopener noreferrer" class="">https://mor-agent.github.io/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Decomposes agent capabilities into three distinct roles (reasoner, executor, summarizer) based on the Reason+Action paradigm. 2. Proposes the Mixture-of-Roles (MoR) framework, which uses three specialized LoRA groups, each dedicated to a specific role, to collaboratively accomplish agent tasks. 3. Develops a multi-role data generation pipeline for effective fine-tuning, incorporating role-specific content completion and reliability verification.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c303f17ce31b4315bdd80c394b9ba486dc14690a542d268175927115df139559_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c303f17ce31b4315bdd80c394b9ba486dc14690a542d268175927115df139559_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the underexplored area of parameter-efficient fine-tuning (PEFT) for AI agents. It proposes MoRAgent, a framework that decomposes agent tasks into three roles (reasoner, executor, summarizer) and assigns a specialized LoRA module to each, enabling efficient and collaborative task completion. Extensive experiments demonstrate the method&#x27;s effectiveness in tuning LLMs for agent tasks while maintaining parameter efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [interpretability &amp; analysis], [latent tokens, chain-of-thought, model reliability, causal analysis, shortcut learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21711</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces &quot;Steering Experiments&quot; to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts &quot;Shortcut Experiments&quot; to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a &quot;pseudo-reasoning&quot; mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [dialogue systems], [theme detection, topic clustering, hierarchical generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li</p>
</li>
<li class="">
<p><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21715" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21715</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] An Information Theoretic Perspective on Agentic System Design</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [mutual information, noisy channel, compressor-predictor, on-device AI, information-theoretic]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21720</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [machine translation], [dialectal arabic, modern standard arabic, post-editing evaluation, error taxonomy, human evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abdullah Alabdullah, Lifeng Han, Chenghua Lin</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Edinburgh, University of Manchester, Leiden University Medical Center (LUMC) / Leiden University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21787" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21787</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Ara-HOPE, a human-centric post-editing evaluation framework specifically designed for Dialectal Arabic to Modern Standard Arabic (DA-MSA) translation. 2. Proposes a five-category error taxonomy and a decision-tree annotation protocol to systematically identify dialect-specific translation errors. 3. Provides a comparative evaluation of three MT systems (Jais, GPT-3.5, NLLB-200), highlighting persistent challenges like dialect-specific terminology and semantic preservation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81517a8ae79cb17e9997772074cacae30aa2d04d3b344341b5fa0c68a1bc551b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81517a8ae79cb17e9997772074cacae30aa2d04d3b344341b5fa0c68a1bc551b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of evaluating machine translation from Dialectal Arabic (DA) to Modern Standard Arabic (MSA), where existing metrics fail to capture dialect-specific errors. It proposes Ara-HOPE, a human-centric post-editing evaluation framework with a specialized error taxonomy and annotation protocol. The framework&#x27;s application reveals that dialect-specific terminology and semantic preservation are the most persistent challenges for current MT systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [image captioning], [scientific figure captioning, large-scale dataset, domain-specific training, human evaluation, large language models (LLMs)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles</p>
</li>
<li class="">
<p><strong>institution:</strong> The Pennsylvania State University, Adobe Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21789" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21789</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper reviews the SciCap project&#x27;s first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] On The Conceptualization and Societal Impact of Cross-Cultural Bias</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [bias and fairness], [cultural bias, literature survey, societal impact, harm evaluation, bias mitigation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vitthal Bhandari</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Washington</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21809" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21809</a></p>
</li>
<li class="">
<p><strong>contributions:</strong>  1. Conducts a focused survey of 20 recent (2025) papers on cultural bias in NLP, identifying gaps in current research practices. 2. Critiques the literature for lacking concrete definitions of bias, failing to identify affected stakeholders, and inadequately evaluating the harms of biased systems. 3. Advocates for a future research agenda that emphasizes robust societal impact assessment, concrete bias conceptualization, and engagement with real-world stakeholders.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper surveys recent literature on cultural bias in NLP, finding that current research often fails to concretely define bias, engage with affected stakeholders, or thoroughly evaluate societal harms. The author proposes a set of observations to guide future work towards more robust and impactful assessments of cross-cultural bias in language technologies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [method decoration, large language models, adaptive method generation, IoT intelligence, on-device reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hong Su</p>
</li>
<li class="">
<p><strong>institution:</strong> Chengdu University of Information Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21817" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21817</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Method Decoration (DeMe) framework, a novel approach that modifies an LLM&#x27;s method-generation path using explicit, non-hardcoded decorations derived from hidden goals, learned methods, and environmental feedback. 2. Formalizes two major categories of decorations (whole-process and step-level) and mechanisms (pre-decoration, post-decoration, etc.) to enable context-aware and adaptive method reshaping. 3. Demonstrates experimentally that the framework allows IoT devices to generate more appropriate methods in unknown or faulty operating conditions without modifying the underlying LLM&#x27;s internal weights.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4e12db053492542eb54d5fe131cf8b2ac404f1af94254b9d2abeed75d055a7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4e12db053492542eb54d5fe131cf8b2ac404f1af94254b9d2abeed75d055a7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that LLM-driven IoT devices struggle to adapt to novel situations due to fixed, pre-trained models. It proposes the Method Decoration (DeMe) framework, which augments an LLM&#x27;s reasoning path with contextual decorations from experience and environment to generate adaptive methods. Experimental results show DeMe enables devices to derive more appropriate methods for unseen or faulty conditions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [knowledge-augmented reasoning], [GraphRAG, Knowledge Graph, Graph Neural Network, LoRA, ChatGLM]</p>
</li>
<li class="">
<p><strong>authors:</strong> Siyu Li, Chenwei Song, Wan Zhou, Xinyi Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Chongqing Jiaotong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21837" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21837</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an LLM-based approach integrating a domain-specific knowledge graph for reasoning in tobacco pest and disease control, built upon the GraphRAG framework. 2. Employs a GNN to learn expressive node representations that capture relational information within the knowledge graph, enhancing the model&#x27;s reasoning capability. 3. Demonstrates effective parameter-efficient fine-tuning of a ChatGLM backbone using LoRA, achieving superior performance in complex reasoning scenarios like multi-hop and comparative reasoning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85aaa4f0b61b3033af1966c2105126130730ca9d346945b5a0ca02e3f706eb1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85aaa4f0b61b3033af1966c2105126130730ca9d346945b5a0ca02e3f706eb1a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a method that enhances large language models for agricultural knowledge reasoning by integrating graph-structured information. It constructs a tobacco pest and disease knowledge graph, uses a GNN to learn node representations, and fine-tunes a ChatGLM model with LoRA. The approach outperforms baselines, significantly improving reasoning accuracy and depth, especially in complex scenarios.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [machine translation], [sentence alignment, parallel corpora, Arabic-English, legal texts, large language models (LLMs)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Baorong Huang, Ali Asiri</p>
</li>
<li class="">
<p><strong>institution:</strong> Huaihua University, Umm al-Qura University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21842" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21842</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/XXX" target="_blank" rel="noopener noreferrer" class="">https://github.com/XXX</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed AlignAR, a generative sentence alignment method for Arabic-English parallel corpora. 2. Introduced a new dataset of complex legal and literary texts, featuring a &quot;Hard&quot; subset with reduced one-to-one mappings to better evaluate alignment methods. 3. Developed a hybrid LLM-plus-human-validation workflow and a bilingual annotation tool for creating gold-standard alignments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f00c37d022ef71644588277bad96472223331ff4180059a6a3d353133f3a205_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f00c37d022ef71644588277bad96472223331ff4180059a6a3d353133f3a205_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the scarcity of high-quality Arabic-English parallel corpora by proposing AlignAR, a generative sentence alignment method. The method, along with a new dataset of complex legal and literary texts, demonstrates that LLM-based approaches are more robust than traditional methods, achieving an 85.5% F1-score and a 9% improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [evaluation], [anthropomorphic intelligence, benchmark, psychological counseling, rubric-based evaluation, reasoning-before-scoring]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Ant Group, Xiamen University, Beijing Normal University, Zhejiang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21849</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/inclusionAI/HeartBench" target="_blank" rel="noopener noreferrer" class="">https://github.com/inclusionAI/HeartBench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based &quot;reasoning-before-scoring&quot; evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] TimeBill: Time-Budgeted Inference for Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [time-budgeted inference, KV cache eviction, response length prediction, execution time estimation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qi Fan, An Zou, Yehan Ma</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21859" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21859</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a fine-grained response length predictor (RLP) and an execution time estimator (ETE) for accurate end-to-end LLM inference time modeling. 2. Developed a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on predicted execution time and a given time budget. 3. Demonstrated through experiments that TimeBill improves task completion rate and maintains response performance under various time constraints.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a21a4204d1665c895b35788196ab3a0e5b32216d06abc37bfaaa9aefac4cb2f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a21a4204d1665c895b35788196ab3a0e5b32216d06abc37bfaaa9aefac4cb2f5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes TimeBill, a framework for performing LLM inference within a strict time budget. It uses predictors to estimate response length and execution time, then dynamically adjusts the KV cache eviction ratio to meet deadlines while preserving output quality. Experiments show it improves task completion rates and maintains performance compared to fixed strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]</p>
</li>
<li class="">
<p><strong>authors:</strong> Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, University of California, Los Angeles, Palo Alto Networks</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21871" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21871</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/bluedream02/CopyGuard" target="_blank" rel="noopener noreferrer" class="">https://github.com/bluedream02/CopyGuard</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs&#x27; ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text-to-sql], [benchmark, multilingual, domain-specific, large language models, sports analytics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa</p>
</li>
<li class="">
<p><strong>institution:</strong> Birla Institute of Technology and Science (BITS), Pilani</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21877" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21877</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a &quot;Gold Standard&quot; dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Explainable Statute Prediction via Attention-based Model and LLM Prompting</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [legal text processing], [statute prediction, explainable AI, attention mechanism, large language models, chain-of-thought prompting]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sachin Pawar, Girish Keshav Palshikar, Anindita Sinha Banerjee, Nitin Ramrakhiyani, Basit Ali</p>
</li>
<li class="">
<p><strong>institution:</strong> TCS Research, Tata Consultancy Services Limited</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21902" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21902</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes AoS, an attention-based supervised model using sentence transformers for explainable statute prediction. 2. Proposes LLMPrompt, a zero-shot method using large language models with standard and Chain-of-Thought prompting for prediction and explanation. 3. Evaluates both prediction performance and explanation quality across two datasets using automated and human evaluation methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0a88ac95c85beb5da693179a57fced56221862f49b2b3f82a7923e814deb844_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0a88ac95c85beb5da693179a57fced56221862f49b2b3f82a7923e814deb844_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles the problem of automatically predicting relevant legal statutes from case descriptions and providing human-understandable explanations. It proposes two methods: a supervised attention-based model (AoS) and a zero-shot LLM prompting approach (LLMPrompt). The study compares their prediction performance against baselines and evaluates the quality of the generated explanations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Soochow University, Meituan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21911</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]</p>
</li>
<li class="">
<p><strong>authors:</strong> KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21919" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21919</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [tokenization], [tokenization penalty, large language models, byte-pair encoding, vocabulary size, natural word splitting]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sachin Pawar, Manoj Apte, Kshitij Jadhav, Girish Keshav Palshikar, Nitin Ramrakhiyani</p>
</li>
<li class="">
<p><strong>institution:</strong> TCS Research, Tata Consultancy Services Limited</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21933" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21933</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the hypothesis that breaking natural words into multiple tokens negatively impacts LLM performance on NLP tasks. 2. Introduces a set of penalty functions to quantify the &quot;badness&quot; of tokenization for a given text and LLM. 3. Establishes the statistical significance of the hypothesis across multiple NLP tasks and different LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/015399929e56260633eb709a56e41948acd324ce4065b0fcb286daa6d5ea6e33_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/015399929e56260633eb709a56e41948acd324ce4065b0fcb286daa6d5ea6e33_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how tokenization, specifically the splitting of natural words into multiple sub-tokens due to limited vocabulary, affects the performance of Large Language Models (LLMs). The authors propose penalty functions to measure this tokenization effect and demonstrate its statistically significant negative impact on various NLP tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Self-attention vector output similarities reveal how machines pay attention</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [attention mechanisms], [self-attention, BERT, attention heads, vector similarity, token representation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tal Halevi, Yarden Tzach, Ronit D. Gross, Shalom Rosner, Ido Kanter</p>
</li>
<li class="">
<p><strong>institution:</strong> Bar-Ilan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21956</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a new method for quantifying information processing within the self-attention mechanism using a context similarity matrix derived from token vectors. 2. Revealed that different attention heads specialize in distinct linguistic features, such as identifying token repetitions or common contextual tokens. 3. Demonstrated a progression from long-range to short-range token similarities across layers, culminating in a focus on intra-sentence relationships and unique token-centric similarity patterns in final layers.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ef3aef5be4139745b138137e89a3f21de053bd91a9fedbe345ad6f90900a98b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ef3aef5be4139745b138137e89a3f21de053bd91a9fedbe345ad6f90900a98b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a novel approach to analyze the self-attention mechanism in transformer models by examining vector output similarities. The analysis on BERT-12 shows that attention heads specialize in different linguistic features and that similarity patterns evolve from long-range to short-range, focusing on sentence-level structures in deeper layers.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [AI Governance &amp; Compliance], [lifecycle management, bias detection, differential privacy, federated learning, terminology drift]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sunil Arora, John Hastings</p>
</li>
<li class="">
<p><strong>institution:</strong> Dakota State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22060" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22060</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework&#x27;s practicality through a healthcare case study demonstrating detection of and response to terminology drift.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Context as a Tool: Context Management for Long-Horizon SWE-Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [context management, long-horizon reasoning, SWE-agents, trajectory compression, structured workspace]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shukai Liu, Jian Yang, Bo Jiang, Yizhi Li, Jinyang Guo, Xianglong Liu, Bryan Dai</p>
</li>
<li class="">
<p><strong>institution:</strong> Beihang University, University of Manchester, Ubiquant</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22087" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22087</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes CAT, a new paradigm that treats context management as an integrated, callable tool for agents, enabling proactive control. 2. Introduces a structured context workspace with stable semantics, condensed long-term memory, and high-fidelity short-term interactions. 3. Presents CAT-GENERATOR, a trajectory-level supervision framework for training the SWE-Compressor model, which achieves state-of-the-art performance on SWE-Bench-Verified.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554c080cfd26463c6d73be16144f677075ea893401e3c8ae26ee7321c48b2be8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554c080cfd26463c6d73be16144f677075ea893401e3c8ae26ee7321c48b2be8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of context explosion and semantic drift in long-horizon software engineering agents by proposing CAT, a paradigm that integrates proactive context management as a tool. It introduces a structured workspace and a training framework to produce the SWE-Compressor model. Experiments show this model significantly outperforms existing baselines on a software engineering benchmark while maintaining stable reasoning under a bounded context budget.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Unifying Learning Dynamics and Generalization in Transformers Scaling Law</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [learning theory], [scaling law, learning dynamics, generalization error, transformer, stochastic gradient descent]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chiwun Yang</p>
</li>
<li class="">
<p><strong>institution:</strong> Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22088" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22088</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^{-1/6}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [benchmark construction], [Turkish NLU benchmark, semi-automated annotation, sentiment analysis dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Duygu Altinok</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22100</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent pipeline, automated data analysis, insight generation, report synthesis, visual analytics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Minnesota</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22101" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22101</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-30">2025-12-30<a href="#2025-12-30" class="hash-link" aria-label="Direct link to 2025-12-30" title="Direct link to 2025-12-30" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251230] Unbiased Visual Reasoning with Controlled Visual Inputs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal reasoning], [vision-language models, spurious correlations, information bottleneck, reinforcement learning, modular reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22183" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22183</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A CNN-Based Malaria Diagnosis from Blood Cell Images with SHAP and LIME Explainability</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image classification], [Convolutional Neural Network, SHAP, LIME, Saliency Maps, Malaria Diagnosis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md. Ismiel Hossen Abir, Awolad Hossain</p>
</li>
<li class="">
<p><strong>institution:</strong> Department of Computer Science &amp; Engineering, International Standard University, Dhaka, Bangladesh</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22205" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22205</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a custom CNN model for automated malaria diagnosis from blood cell images, achieving high accuracy (96%). 2. Compares the performance of the custom CNN with established deep learning architectures like ResNet50 and VGG16. 3. Enhances model interpretability for clinical trust by applying Explainable AI techniques, including SHAP, LIME, and Saliency Maps.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cafdabeab6baa067cead631acca4eba73f7c2812fd0d0e97d201544854ddd16b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cafdabeab6baa067cead631acca4eba73f7c2812fd0d0e97d201544854ddd16b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a deep learning-based system using a custom Convolutional Neural Network (CNN) to automatically diagnose malaria from blood cell images, achieving high accuracy. It compares this model against several established architectures and applies Explainable AI (XAI) techniques like SHAP and LIME to make the model&#x27;s decisions interpretable. The study concludes that this approach can provide a quick, accurate, and understandable diagnostic tool, particularly valuable in resource-limited settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Open-Source Multimodal Moxin Models with Moxin-VLM and Moxin-VLA</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multimodal large language models], [Moxin, open-source LLM, vision-language-action, Model Openness Framework, multimodal models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Arash Akbari, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Northeastern University, Harvard University, Cornell University, Tulane University, University of Washington, Roboraction.ai, Futurewei, AIBAO LLC</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22208" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22208</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/moxin-org/Moxin-LLM" target="_blank" rel="noopener noreferrer" class="">https://github.com/moxin-org/Moxin-LLM</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Moxin 7B, a fully open-source LLM developed under the Model Openness Framework, promoting transparency in training, datasets, and implementation. 2. Develops three specialized variants of Moxin: Moxin-VLM for vision-language tasks, Moxin-VLA for vision-language-action tasks, and Moxin-Chinese for Chinese language capabilities. 3. Demonstrates superior performance of the proposed models in various evaluations using open-source frameworks and data, with all models, code, and data publicly released.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79873d0c3143fc2b06f1be1be9b8bc80555fa0aefd4a6f2b8d6bda39bce5f227_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79873d0c3143fc2b06f1be1be9b8bc80555fa0aefd4a6f2b8d6bda39bce5f227_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Moxin 7B, a fully transparent open-source large language model, and extends it into three multimodal variants for vision-language, vision-language-action, and Chinese tasks. The models are trained using open-source frameworks and data. The authors release the models, code, and data, reporting superior performance in evaluations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] On the Existence and Behaviour of Secondary Attention Sinks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [attention sinks, transformer, mlp, attention mechanism, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jeffrey T.H. Wong, Cheng Zhang, Louis Mahon, Wayne Luk, Anton Isopoussu, Yiren Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Imperial College London, UnlikelyAI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22213" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22213</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and characterizes a new class of &quot;secondary attention sinks&quot; that arise in middle layers, have variable lifetimes, and draw moderate attention, differing from persistent primary sinks like BOS. 2. Shows that secondary sinks are formed by specific middle-layer MLP modules that map token representations to align with the primary sink&#x27;s direction, with their L2-norm determining sink strength and lifetime. 3. Observes that in larger models, these sink patterns (sink levels) become more deterministic and frequent, with distinct levels identified in models like QwQ-32B and Qwen3-14B.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies a new phenomenon called &quot;secondary attention sinks&quot; in transformer LLMs, which are distinct from the known primary sinks (like BOS). The authors show these secondary sinks are created by middle-layer MLPs aligning tokens with the primary sink direction, and their properties (strength, lifetime) become more structured in larger models. This provides new insights into the internal mechanics of attention in large language models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [video understanding], [streaming video, multimodal large language models, event segmentation, hierarchical representation, elastic-scale]</p>
</li>
<li class="">
<p><strong>authors:</strong> Naishan Zheng, Jie Huang, Qingpei Guo, Feng Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science and Technology of China, Ant Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22226" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22226</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/zheng980629/VideoScaffold" target="_blank" rel="noopener noreferrer" class="">https://github.com/zheng980629/VideoScaffold</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes VideoScaffold, a dynamic representation framework for streaming video understanding in MLLMs that adaptively adjusts event granularity. 2. Introduces Elastic-Scale Event Segmentation (EES) for prediction-guided, dynamic boundary refinement. 3. Introduces Hierarchical Event Consolidation (HEC) for progressively aggregating segments into multi-level abstractions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of understanding long, streaming videos with MLLMs by proposing VideoScaffold, a framework that dynamically segments and hierarchically consolidates video events to adapt granularity and preserve semantics. It achieves state-of-the-art performance on benchmarks and can extend image-based MLLMs to video comprehension.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [representation analysis], [sentence embeddings, probing, hierarchical geometry, transformer models, cognitive states]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sophie Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Georgia Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22227" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22227</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Constructed a novel dataset of 480 sentences annotated with continuous energy scores and discrete tier labels for seven ordered cognitive categories. 2. Demonstrated that both continuous scores and discrete tier labels are reliably decodable from fixed transformer sentence embeddings using linear and nonlinear probes, with nonlinear probes providing consistent gains. 3. Provided statistical and qualitative evidence (via permutation tests, UMAP visualizations, and confusion matrices) that the embedding space exhibits a hierarchical geometric organization aligned with human-defined cognitive attributes, beyond surface word statistics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fec0b31a0f9f75593cbc3cdadecae63f4a1a7b7b6d910165a358bc72dde0f1d7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fec0b31a0f9f75593cbc3cdadecae63f4a1a7b7b6d910165a358bc72dde0f1d7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether transformer-based sentence embeddings encode a hierarchical structure aligned with cognitive states. The authors construct an annotated dataset and use linear and nonlinear probes to decode continuous scores and discrete labels from embeddings, finding reliable recoverability and a structured geometric gradient. The results show that transformer embedding spaces exhibit a systematic organization corresponding to interpretable cognitive attributes.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language model safety], [sparse autoencoder, feature orthogonalization, stealth slip, pragmatic interpretation, statistical co-occurrence]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tsogt-Ochir Enkhbayar</p>
</li>
<li class="">
<p><strong>institution:</strong> Mongol-AI (inferred from email domain)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22293" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22293</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Empirically demonstrates that warning-framed training data fails to teach language models to avoid warned-against behaviors, showing generation rates similar to direct exposure. 2. Provides a mechanistic interpretation using sparse autoencoders, identifying a failure of feature orthogonalization where &quot;describing&quot; and &quot;performing&quot; an action activate overlapping latent features. 3. Identifies and names the &quot;stealth slip&quot; phenomenon, where conversational preambles can rotate activations into subspaces undetectable by linear probes, and shows that training-time feature ablation, not prompting, is required to address the issue.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates why language models trained on warning-framed examples (e.g., &quot;DO NOT USE&quot;) still learn to generate the warned-against content. Through behavioral experiments and sparse autoencoder analysis, it finds that models learn statistical co-occurrences rather than pragmatic intent, due to overlapping latent features for description and action. The core conclusion is that current architectures prioritize pattern completion over understanding speaker intent, requiring training-time interventions like feature ablation for correction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [self-verifying agent, proactive evidence seeking, LLM-as-a-Judge, 3C Principles, agentic reinforcement learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Tencent</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22322" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22322</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://huggingface.co/collections/yolay/smartsnap" target="_blank" rel="noopener noreferrer" class="">https://huggingface.co/collections/yolay/smartsnap</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [evaluation &amp; benchmarking], [scientific intelligence, multimodal reasoning, benchmarking toolkit]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yiheng Wang, Yixin Chen, Shuo Li, Yifan Zhou, Bo Liu, Hengjian Gao, Jiakang Yuan, Jia Bu, Wanghan Xu, Yuhao Zhou, Xiangyu Zhao, Zhiwang Zhou, Fengxiang Wang, Haodong Duan, Songyang Zhang, Jun Yao, Han Deng, Yizhou Wang, Jiabei Xiao, Jiaqi Liu, Encheng Su, Yujie Liu, Weida Wang, Junchi Yao, Shenghe Zheng, Haoran Sun, Runmin Ma, Xiangchao Yan, Bo Zhang, Dongzhan Zhou, Shufei Zhang, Peng Ye, Xiaosong Wang, Shixiang Tang, Wenlong Zhang, Lei Bai</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22334</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/InternScience/SciEvalKit" target="_blank" rel="noopener noreferrer" class="">https://github.com/InternScience/SciEvalKit</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces SciEvalKit, a unified, open-source toolkit for evaluating AI models across a broad range of scientific disciplines and core scientific intelligence capabilities. 2. Provides a flexible and extensible evaluation pipeline supporting batch evaluation, custom model/dataset integration, and ensuring transparent, reproducible results. 3. Curates expert-grade scientific benchmarks from real-world, domain-specific datasets to reflect authentic scientific challenges across six major domains.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84233ab293826e87328abdd509857546d8a108ec2ff9c7ccc92d7c00c26ececa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84233ab293826e87328abdd509857546d8a108ec2ff9c7ccc92d7c00c26ececa_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across multiple disciplines and core competencies like multimodal reasoning and code generation. It provides a flexible, extensible pipeline for reproducible evaluation and is built on expert-grade, real-world scientific benchmarks. The toolkit is open-sourced to foster community-driven development in AI for science.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [symbolic world models, multi-agent feedback, PDDL, adaptive testing, supervised fine-tuning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mengkang Hu, Bowei Xia, Yuran Wu, Ailing Yu, Yude Zou, Qiguang Chen, Shijian Wang, Jiarui Jin, Kexin Li, Wenxiang Jiao, Yuan Lu, Ping Luo</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Hong Kong, Xiaohongshu Inc., UESTC, Harbin Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22336</a></p>
</li>
<li class="">
<p><strong>code:</strong> agent2world.github.io</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed Agent2World, a tool-augmented multi-agent framework for generating symbolic world models via adaptive multi-agent feedback. 2. Introduced a three-stage pipeline with specialized agents (Deep Researcher, Model Developer, Testing Team) for knowledge synthesis, implementation, and behavior-aware validation. 3. Demonstrated that the framework not only achieves state-of-the-art inference-time performance but also serves as a data engine for supervised fine-tuning, leading to substantial model improvement.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3eb7640894bc37e231771de5c5b9dca9d3fe86f38d911d91d2cb55f73a1005c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3eb7640894bc37e231771de5c5b9dca9d3fe86f38d911d91d2cb55f73a1005c6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of generating correct symbolic world models (like PDDL domains) from natural language by proposing Agent2World, a multi-agent framework that uses adaptive feedback for validation and repair. The method outperforms existing approaches on benchmarks and the feedback collected also enables effective supervised fine-tuning, significantly improving model performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] The Syntax of qulk-clauses in Yemeni Ibbi Arabic: A Minimalist Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [generative syntax], [qulk-clauses, Minimalist Program, biclausal structures, bipartite negation, Morphological Merger]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zubaida Mohammed Albadani, Mohammed Q. Shormani</p>
</li>
<li class="">
<p><strong>institution:</strong> Qalam University, Ibb University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22376" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22376</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes that qulk-clauses in Yemeni Ibbi Arabic are biclausal structures where &#x27;qulk&#x27; functions as a clause-embedding predicate selecting a full CP complement. 2. Provides a syntactic derivation using core Minimalist operations (Merge, Move, Agree, Spell-out) and post-syntactic processes like Morphological Merger. 3. Accounts for dialect-specific syntactic phenomena such as bipartite negation and cliticization within the Minimalist framework.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac0d347b0a0aa0409fd5577dddb1a9b52a8488a6784d65d923c9b923a8a1edb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac0d347b0a0aa0409fd5577dddb1a9b52a8488a6784d65d923c9b923a8a1edb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the syntax of &#x27;qulk&#x27;-clauses in Yemeni Ibbi Arabic using the Minimalist Program, proposing they are biclausal structures derived through operations like Merge and Move. It concludes that the analysis accounts for dialect-specific features and supports the theoretical universality of minimalist syntax.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Towards Efficient Post-Training via Fourier-Driven Adapter Architectures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [parameter-efficient fine-tuning], [Fourier-Activated Adapter, random Fourier features, frequency-aware activation, parameter-efficient fine-tuning, spectral sparsity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Donggyun Bae, Jongil Park</p>
</li>
<li class="">
<p><strong>institution:</strong> Konkuk University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22378" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22378</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Fourier-Activated Adapter (FAA), a novel PEFT framework that integrates random Fourier features to decompose representations into frequency components. 2. Introduces a dynamic, frequency-aware activation mechanism to selectively modulate semantic information across different frequency bands. 3. Demonstrates through extensive experiments that FAA achieves competitive or superior performance on multiple benchmarks while maintaining low computational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf813cee09035fa7f545005f9b12789221e4e00ecb3d551020cff824fb62233_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf813cee09035fa7f545005f9b12789221e4e00ecb3d551020cff824fb62233_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes the Fourier-Activated Adapter (FAA), a parameter-efficient fine-tuning method for large language models that uses random Fourier features to enable frequency-aware modulation of semantic representations. Experiments on GLUE and other benchmarks show that FAA achieves strong performance with low computational cost, highlighting the effectiveness of its frequency-based approach.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [few-shot learning], [exemplar selection, large language model, human activity recognition, facility-location optimization, PageRank]</p>
</li>
<li class="">
<p><strong>authors:</strong> Elsen Ronando, Sozo Inoue</p>
</li>
<li class="">
<p><strong>institution:</strong> Kyushu Institute of Technology, Universitas 17 Agustus 1945 Surabaya</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22385" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22385</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an LLM-Guided Exemplar Selection framework that incorporates semantic reasoning via LLM-generated knowledge priors (feature importance, inter-class confusability, budget multipliers) for HAR. 2. Integrates these semantic priors with multiple geometric and structural cues (margin-based validation, PageRank centrality, hubness penalization, facility-location optimization) for a unified exemplar scoring and selection process. 3. Demonstrates superior performance (88.78% macro F1-score on UCI-HAR) under strict few-shot conditions compared to classical selection methods like random sampling, herding, and k-center.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90a149428a6ff84d38e1ab6a741982394b05c9d5b98eaaa538dcd12183dbe7bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90a149428a6ff84d38e1ab6a741982394b05c9d5b98eaaa538dcd12183dbe7bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of relying on large labeled datasets and purely geometric exemplar selection in Human Activity Recognition (HAR) by proposing an LLM-Guided Exemplar Selection framework. The method uses an LLM to generate semantic knowledge priors, which are combined with structural and geometric cues to select a compact, informative set of exemplars for few-shot learning. Evaluated on the UCI-HAR dataset, the framework outperforms classical selection approaches, showing that integrating semantic reasoning improves representative exemplar selection for wearable-sensor HAR.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Hallucination Detection and Evaluation of Large Language Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection], [HHEM, KnowHalu, segment-based retrieval, factual consistency, CDF analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chenggong Zhang, Haopeng Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Los Angeles</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22416" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22416</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Integrated the lightweight Hughes Hallucination Evaluation Model (HHEM) to significantly reduce computational cost and time for hallucination detection compared to multi-stage methods like KnowHalu. 2. Introduced a segment-based retrieval technique to improve the detection of localized hallucinations in summarization tasks, addressing a key limitation of HHEM. 3. Conducted a comparative CDF analysis revealing that larger LLMs (7B-9B parameters) exhibit fewer hallucinations, while intermediate-sized models show higher instability.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a208bbdfd47e46de589a2306cd9e02976448bce48e5e81a002adcb6f30ec224d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a208bbdfd47e46de589a2306cd9e02976448bce48e5e81a002adcb6f30ec224d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of efficiently detecting hallucinations in Large Language Models. It proposes integrating the lightweight HHEM framework and a segment-based retrieval method, which together reduce evaluation time dramatically while maintaining high accuracy. The study concludes that larger models are generally more reliable and highlights the need for efficient yet robust evaluation frameworks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Monadic Context Engineering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Monadic Context Engineering, Monad Transformers, Meta-Agents, computational contexts, algebraic structures]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yifan Zhang, Mengdi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22431" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22431</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/yifanzhang-pro/monadic-context-engineering" target="_blank" rel="noopener noreferrer" class="">https://github.com/yifanzhang-pro/monadic-context-engineering</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Monadic Context Engineering (MCE), a novel architectural paradigm using Functors, Applicatives, and Monads to provide a formal foundation for AI agent design. 2. Demonstrates how Monads and Applicatives manage sequential composition and parallel execution, and how Monad Transformers enable systematic composition of capabilities like state and error handling. 3. Extends the MCE framework to describe Meta-Agents for generative orchestration, dynamically creating and managing sub-agent workflows via metaprogramming.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/635ff6dca4b79fe5e98a96641cbb26356935e3090aa65b20972b744e69151810_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/635ff6dca4b79fe5e98a96641cbb26356935e3090aa65b20972b744e69151810_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the brittleness and complexity in current AI agent architectures by introducing Monadic Context Engineering (MCE), a paradigm that leverages algebraic structures like Monads to formally manage state, errors, and concurrency within agent workflows. The proposed method enables the construction of complex, resilient agents from simple, verifiable components and is extended to support generative orchestration via Meta-Agents. The work concludes that MCE provides a principled foundation for building robust and scalable autonomous agent systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [hierarchical filtering, two-pass generation, citation verification, query formulation, model cascade]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cattalyya Nuengsigkapian</p>
</li>
<li class="">
<p><strong>institution:</strong> Google</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22442" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22442</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a hierarchical content filtering pipeline to replace standard vector similarity search, improving context precision. 2. Introduces a model cascade strategy using a cost-efficient model (Gemini 2.5 Flash) for filtering and a powerful model (Gemini 2.5 Pro) for final generation. 3. Demonstrates significant performance gains on the MMU-RAGent benchmark and a custom dataset for post-cutoff knowledge.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents HiFi-RAG, a system designed to improve open-domain RAG by addressing irrelevant retrieved information. The method uses a multi-stage pipeline with hierarchical filtering and a two-pass generation strategy employing different LLMs for efficiency and quality. The system won a NeurIPS 2025 competition and showed substantial improvements over baselines in evaluation metrics.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [domain-specific reasoning], [vertical-domain reasoning, accounting reasoning, prompt engineering, GLM-series, evaluation criteria]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jie Zhou, Xin Chen, Jie Zhang, Zhe Li</p>
</li>
<li class="">
<p><strong>institution:</strong> School of Computer Engineering, Jiangsu Ocean University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22443" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22443</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the concept of &quot;vertical-domain accounting reasoning&quot; and establishes corresponding evaluation criteria based on analyzing training data characteristics of GLM-series models. 2. Proposes a framework to evaluate the accounting reasoning capabilities of several representative LLMs (GLM-6B, GLM-130B, GLM-4, GPT-4) using different prompt engineering strategies. 3. Provides benchmarks and foundational insights for improving LLM performance in professional accounting scenarios, identifying GPT-4&#x27;s superior capability and the gap to real-world enterprise application requirements.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b34441f407f7adb435b84980dce10bceeed5c1737baae9c574e35ada53430c91_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b34441f407f7adb435b84980dce10bceeed5c1737baae9c574e35ada53430c91_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study investigates the domain-specific reasoning capabilities of Large Language Models (LLMs) in the accounting field. It establishes evaluation criteria for &quot;vertical-domain accounting reasoning&quot; and tests models like GLM-series and GPT-4 on accounting tasks using prompt engineering. The results show GPT-4 performs best, but all models still require further optimization to meet real-world enterprise accounting needs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [LoRA, Parameter-Efficient Fine-Tuning, Activation Function Annealing, Non-linear Adaptation, Model Merging]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai</p>
</li>
<li class="">
<p><strong>institution:</strong> Meituan, Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22455" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22455</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method&#x27;s effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Constituency Structure over Eojeol in Korean Treebanks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [syntactic parsing], [constituency parsing, treebank annotation, eojeol, Korean syntax, morphological segmentation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jungyeul Park, Chulwoo Park</p>
</li>
<li class="">
<p><strong>institution:</strong> KAIST, Anyang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22487" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22487</a></p>
</li>
<li class="">
<p><strong>contributions:</strong>  1. Argues for an eojeol-based constituency representation in Korean treebanks, separating morphological information into a non-constituent layer. 2. Shows that the Sejong and Penn Korean treebanks are representationally equivalent at the eojeol-based constituency level under explicit normalization. 3. Outlines an eojeol-based annotation scheme that supports cross-treebank comparison and constituency-dependency conversion.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d48ef7fceed98f1ac78d435bdf24a8049dd0338b9040587dd433cea8b3ff74a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d48ef7fceed98f1ac78d435bdf24a8049dd0338b9040587dd433cea8b3ff74a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the representational issue of terminal units in Korean constituency treebanks. It proposes using eojeol (spacing units) as the constituency terminals while encoding morphology separately, and demonstrates that two major treebanks are equivalent under this scheme, enabling better comparison and conversion.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ManchuTTS: Towards High-Quality Manchu Speech Synthesis via Flow Matching and Hierarchical Text Representation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [speech synthesis], [flow matching, hierarchical attention, low-resource TTS, agglutinative language, non-autoregressive generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Suhua Wang, Zifan Wang, Xiaoxin Sun, D. J. Wang, Zhanbo Liu, Xin Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Northeast Normal University, Changchun Humanities and Sciences College, Zhejiang University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22491" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22491</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel hierarchical text representation and cross-modal attention mechanism to handle Manchu&#x27;s agglutinative phonology. 2. Introduces an end-to-end speech synthesis model integrating deep convolutional networks with a flow-matching Transformer for efficient, non-autoregressive generation. 3. Constructs the first public Manchu TTS dataset and employs data augmentation to address severe data scarcity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/118d24570c94614dbb94eaabcc1dc47ba64643f094c4ea3727d4674221bf53fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/118d24570c94614dbb94eaabcc1dc47ba64643f094c4ea3727d4674221bf53fc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes ManchuTTS, a novel text-to-speech system designed for the endangered and agglutinative Manchu language. The method uses a three-tier text representation and a flow-matching Transformer with hierarchical guidance to tackle data scarcity and complex phonology. Experiments show it achieves a high MOS score of 4.52 and significantly improves pronunciation accuracy and prosodic naturalness compared to baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Learning When Not to Attend Globally</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [All-or-Here Attention, sliding window attention, conditional computation, binary router, context dependency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xuan Luo, Kailai Zhang, Xifeng Yan</p>
</li>
<li class="">
<p><strong>institution:</strong> UC Santa Barbara</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22562</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes All-or-Here Attention (AHA), a novel attention mechanism that dynamically toggles between full and local sliding window attention using a binary router per head. 2. Demonstrates empirically that full attention is largely redundant, showing up to 93% of full attention operations can be replaced with local attention without performance loss. 3. Identifies a long-tail distribution in context dependency, revealing that the need for global context decays rapidly as the local window expands.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edc0024b0088e710cd3ce9c0be8276b43396c11c0424f0f6340e0f97d63982e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edc0024b0088e710cd3ce9c0be8276b43396c11c0424f0f6340e0f97d63982e6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the computational inefficiency of full self-attention in LLMs by proposing All-or-Here Attention (AHA), which learns to dynamically switch between full and local sliding window attention for each token. The results show that most full attention operations are unnecessary, and efficient inference can be achieved with on-demand global context access.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Structured Prompting and LLM Ensembling for Multimodal Conversational Aspect-based Sentiment Analysis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [aspect-based sentiment analysis], [structured prompting, llm ensembling, multimodal conversation, sentiment flipping, sentiment sextuple]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhiqiang Gao, Shihao Gao, Zixing Zhang, Yihao Guo, Hongyu Chen, Jing Han</p>
</li>
<li class="">
<p><strong>institution:</strong> Hunan University, University of Cambridge</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22603" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22603</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A structured prompting pipeline for LLMs to sequentially extract complex sentiment sextuples (holder, target, aspect, opinion, sentiment, rationale) from multimodal dialogues. 2. An ensemble strategy leveraging three LLMs to robustly identify sentiment flipping (dynamic sentiment shifts) and their triggers. 3. Demonstrating the effectiveness of step-wise refinement and model ensembling for rich, multimodal sentiment analysis tasks, achieving competitive results on the MCABSA challenge.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8e53db2395e8a03a0b4b7ac36c2aa4287b60b1a961f7cc83bcd52a3ef4fae4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8e53db2395e8a03a0b4b7ac36c2aa4287b60b1a961f7cc83bcd52a3ef4fae4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of Multimodal Conversational Aspect-based Sentiment Analysis (MCABSA). It proposes a structured prompting pipeline for extracting sentiment sextuples and an LLM ensembling method for detecting sentiment flipping. The approach achieved strong results, demonstrating the effectiveness of these strategies for complex multimodal sentiment understanding.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Dream-VL &amp; Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [diffusion language model, vision-language-action, parallel generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiacheng Ye, Shansan Gong, Jiahui Gao, Junming Fan, Shuang Wu, Wei Bi, Haoli Bai, Lifeng Shang, Lingpeng Kong</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Hong Kong, Huawei Technologies</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22615" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22615</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Dream-VL, a state-of-the-art open diffusion-based Vision-Language Model (dVLM) that matches top AR-based VLMs on benchmarks and excels at visual planning. 2. Introduces Dream-VLA, a diffusion-based Vision-Language-Action model built upon Dream-VL, leveraging the bidirectional nature of diffusion for superior action chunking and faster fine-tuning convergence. 3. Demonstrates that diffusion-based VLMs/VLAs outperform autoregressive baselines on downstream tasks, achieving top-tier performance on robotic benchmarks like LIBERO, SimplerEnv-Bridge, and SimplerEnv-Fractal.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc3fa176585576be4f4bd1035cfa0a21e63722654274b464e83bb35c7ee5bc0c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc3fa176585576be4f4bd1035cfa0a21e63722654274b464e83bb35c7ee5bc0c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes building Vision-Language and Vision-Language-Action models on diffusion-based language models to overcome the limitations of autoregressive models in complex planning and control. The introduced models, Dream-VL and Dream-VLA, leverage the bidirectional, parallel generation nature of diffusion for superior performance in visual planning and robotic tasks, achieving state-of-the-art results on key benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Chain-of-thought Reviewing and Correction for Time Series Question Answering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [time series question answering], [chain-of-thought, multi-step reasoning, self-correction, LLM fine-tuning, time series analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chen Su, Yuanhe Tian, Yan Song</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Science and Technology of China, Zhongguancun Institute of Artificial Intelligence</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22627" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22627</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/synlp/T3LLM" target="_blank" rel="noopener noreferrer" class="">https://github.com/synlp/T3LLM</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes T3LLM, a novel framework that integrates a multi-agent LLM system (worker, reviewer, student) for chain-of-thought reasoning with an explicit correction mechanism for time series QA. 2. Leverages the inherent verifiability of time series data to enable consistency checking between reasoning steps and original input, allowing the reviewer to identify and correct errors. 3. Fine-tunes a student model using the collaboratively generated corrected reasoning chains, internalizing both multi-step reasoning and self-correction capabilities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2399e517488f19982d1f0bdffd324837014399b83d0c64b4314235e4143c5a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2399e517488f19982d1f0bdffd324837014399b83d0c64b4314235e4143c5a4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of reasoning errors in LLM-based time series question answering. It proposes T3LLM, a framework that uses three LLMs (worker, reviewer, student) to generate, review/correct, and learn from multi-step reasoning chains. Experiments show that T3LLM achieves state-of-the-art performance on multiple TSQA benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] M2G-Eval: Enhancing and Evaluating Multi-granularity Multilingual Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code generation evaluation], [multi-granularity evaluation, multilingual code generation, Group Relative Policy Optimization, contamination-controlled benchmark, fine-grained diagnosis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Fanglin Xu, Wei Zhang, Jian Yang, Guo Chen, Aishan Liu, Zhoujun Li, Xianglong Liu, Bryan Dai</p>
</li>
<li class="">
<p><strong>institution:</strong> Beihang University, Hunan University, Ubiquant</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22628" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22628</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced M2G-Eval, a novel multi-granularity and multilingual benchmark for evaluating code LLMs across four structural levels (Class, Function, Block, Line) and 18 programming languages. 2. Developed M2G-Eval-Coder models by fine-tuning Qwen3-8B with supervised fine-tuning and a novel Group Relative Policy Optimization method. 3. Conducted a comprehensive evaluation of 30 models, revealing key insights such as a difficulty hierarchy across granularities and evidence of transferable programming concepts across languages.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c666b8c3b59bf1276ef94dab61d81839bb62d98333e1c6d0052ca3f61fdebad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c666b8c3b59bf1276ef94dab61d81839bb62d98333e1c6d0052ca3f61fdebad_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces M2G-Eval, a framework for evaluating code generation in large language models across multiple structural granularities and programming languages. The authors also develop enhanced models using the benchmark and conduct an extensive evaluation, finding a clear difficulty hierarchy among tasks and evidence that models learn transferable programming concepts across different languages.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Evaluating GRPO and DPO for Faithful Chain-of-Thought Reasoning in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning and explainability], [Chain-of-Thought, Faithfulness, GRPO, DPO, LLM Alignment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hadi Mohammadi, Tamas Kozak, Anastasia Giachanou</p>
</li>
<li class="">
<p><strong>institution:</strong> Utrecht University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22631" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22631</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Evaluates and compares two optimization methods, GRPO and DPO, for improving the faithfulness of Chain-of-Thought reasoning in LLMs. 2. Demonstrates that GRPO outperforms DPO in larger models, with Qwen2.5-14B-Instruct achieving the best results. 3. Shows a positive correlation between model size and performance for both methods, with GRPO showing greater potential for improving faithfulness metrics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/873da11748c86e67ee5cce9b0d9ee43cc3075f93ef1cc7775d7d9b6683adb946_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/873da11748c86e67ee5cce9b0d9ee43cc3075f93ef1cc7775d7d9b6683adb946_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the problem of unfaithful Chain-of-Thought (CoT) reasoning in large language models, where generated rationales may not reflect the model&#x27;s actual reasoning process. It evaluates two optimization methods, Group Relative Policy Optimization (GRPO) and Direct Preference Optimization (DPO), for improving CoT faithfulness. The main conclusion is that GRPO achieves higher performance than DPO, especially in larger models, suggesting it is a promising direction for developing more transparent and trustworthy reasoning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] On the Role of Discreteness in Diffusion LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [diffusion language models], [diffusion language models, parallel decoding, iterative refinement, continuous diffusion, discrete diffusion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ziqi Jin, Bin Wang, Xiang Lin, Lidong Bing, Aixin Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> MiroMind AI, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22630" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22630</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Revisits diffusion language modeling and outlines five essential properties that separate diffusion mechanics from language-specific requirements. 2. Categorizes existing approaches into continuous diffusion in embedding space and discrete diffusion over tokens, showing each only partially satisfies the essential properties. 3. Identifies two central issues in recent large diffusion language models: uniform corruption not respecting information distribution and token-wise marginal training failing to capture multi-token dependencies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbf752083457bd2f08f3e62c6bd3acca194cf8603c88b7225f7783b764b30535_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbf752083457bd2f08f3e62c6bd3acca194cf8603c88b7225f7783b764b30535_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the application of diffusion models to language generation, highlighting the challenges posed by the discrete nature of text. It categorizes existing approaches and identifies key structural trade-offs and issues, such as uniform corruption and token-wise training limitations. The findings motivate the development of diffusion processes better aligned with text structure for more coherent generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Scaling Unverifiable Rewards: A Case Study on Visual Insights</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [Test-Time Scaling, multi-agent pipeline, process-based refinement, LLM-as-Judge, unverifiable rewards]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuyu Gan, James Mooney, Pan Hao, Renxiang Wang, Mingyi Hong, Qianwen Wang, Dongyeop Kang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Minnesota</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22650" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22650</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://minnesotanlp.github.io/insight-scaling-webpage" target="_blank" rel="noopener noreferrer" class="">https://minnesotanlp.github.io/insight-scaling-webpage</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed Selective Test-Time Scaling, a process-based refinement framework that scales inference across stages in multi-agent pipelines instead of repeated refinement over time. 2. Designed a reliable LLM-based judge model aligned with human experts for evaluating visual insights. 3. Demonstrated improved insight quality under fixed compute budget in a data science pipeline application.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of scaling LLM agents for tasks with unverifiable rewards by introducing Selective Test-Time Scaling, which distributes compute across pipeline stages and prunes low-quality branches early using process-specific judges. Applied to generating visual insights from datasets, the method increases mean quality scores and reduces variance compared to traditional time-based refinement. The work provides a foundation for scaling complex, open-ended tasks like scientific discovery and story generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [width pruning, expansion ratio, Maximum Absolute Weight (MAW), GLU-MLP, instruction-following]</p>
</li>
<li class="">
<p><strong>authors:</strong> Pere Martra</p>
</li>
<li class="">
<p><strong>institution:</strong> Universidad Internacional Menéndez Pelayo (UIMP)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22671" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22671</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematically characterizes a capability dichotomy where structured width pruning degrades parametric knowledge (e.g., MMLU) but significantly improves instruction-following (e.g., IFEval). 2. Discovers and quantifies a robust inverse correlation between factual knowledge and truthfulness, linking knowledge degradation under pruning to improved misconception discrimination. 3. Identifies the expansion ratio as a critical architectural parameter that selectively modulates cognitive capabilities, rather than just a compression metric, and quantifies its context-dependent efficiency trade-offs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates structured width pruning of GLU-MLP layers in Llama-3.2 models using the Maximum Absolute Weight (MAW) criterion. It finds that pruning creates a dichotomy: while parametric knowledge degrades, instruction-following improves and multi-step reasoning remains robust, challenging the assumption of uniform degradation. The main conclusion is that width pruning acts as a selective filter, reducing knowledge but preserving or enhancing behavioral alignment, with identified trade-offs in efficiency.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Conformal Prediction Sets for Next-Token Prediction in Large Language Models: Balancing Coverage Guarantees with Set Efficiency</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [uncertainty quantification], [conformal prediction, adaptive prediction sets, vocabulary-aware, coverage-efficiency tradeoff, marginal coverage]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yoshith Roy Kotla, Varshith Roy Kotla</p>
</li>
<li class="">
<p><strong>institution:</strong> The ICFAI Foundation for Higher Education</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22682" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22682</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified and formally characterized the coverage-efficiency tradeoff unique to applying conformal prediction to next-token prediction in LLMs with large vocabularies. 2. Proposed Vocabulary-Aware Conformal Prediction (VACP), a framework using semantic masking and temperature-adjusted scoring to reduce the effective prediction space. 3. Provided a theoretical analysis of when vocabulary reduction preserves conformal validity and demonstrated a 197x improvement in prediction set efficiency on benchmarks while maintaining coverage guarantees.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb40fe541a33e11ac6d9b3f6f3fac213d5602d391cc590303cb8079bf97a840_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb40fe541a33e11ac6d9b3f6f3fac213d5602d391cc590303cb8079bf97a840_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem that naive conformal prediction for LLM next-token prediction produces uninformatively large prediction sets due to large vocabularies. It proposes Vocabulary-Aware Conformal Prediction (VACP), which uses semantic masking and hierarchical conformalization to drastically reduce set size. The method achieves near-target coverage while improving set efficiency by 197x, making conformal prediction practical for LLMs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] GHaLIB: A Multilingual Framework for Hope Speech Detection in Low-Resource Languages</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hope speech detection], [transformer models, multilingual classification, low-resource languages, XLM-RoBERTa, UrduBERT]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ahmed Abdullah, Sana Fatima, Haroon Mahmood</p>
</li>
<li class="">
<p><strong>institution:</strong> FAST-National University, Al Ain University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22705" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22705</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a multilingual framework for hope speech detection, specifically addressing the underrepresentation of low-resource languages like Urdu. 2. Applies and evaluates multiple pretrained transformer models (XLM-RoBERTa, mBERT, EuroBERT, UrduBERT) on the PolyHope-M 2025 benchmark for this task. 3. Demonstrates strong performance, achieving high F1-scores for Urdu classification, validating the use of existing multilingual models in low-resource settings.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of resources for hope speech detection in low-resource languages by proposing a multilingual framework using pretrained transformer models like XLM-RoBERTa and UrduBERT. The method involves simple preprocessing and training classifiers, which achieve high F1-scores on the PolyHope-M 2025 benchmark, particularly for Urdu. The results show that existing multilingual models can be effectively implemented to identify hope speech and foster positive digital discourse in low-resource environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Beg to Differ: Understanding Reasoning-Answer Misalignment Across Languages</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multilingual reasoning evaluation], [reasoning-answer misalignment, chain-of-thought prompting, crosslingual evaluation, error taxonomy, GlobalMMLU]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anaelia Ovalle, Candace Ross, Sebastian Ruder, Adina Williams, Karen Ullrich, Mark Ibrahim, Levent Sagun</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta Superintelligence Labs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22712" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22712</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a human-validated framework to evaluate the logical alignment between model-generated reasoning traces and their conclusions across languages. 2. Conducted a large-scale analysis revealing that reasoning traces in non-Latin scripts exhibit at least twice as much misalignment as those in Latin scripts, despite high task accuracy. 3. Developed an error taxonomy through human annotation, identifying evidential errors (e.g., unsupported claims) and illogical reasoning steps as primary failure modes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd9c868e57697e675d2ed0bdd5294f15cfad25e4c549988b95bcc1aca9c8bb57_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd9c868e57697e675d2ed0bdd5294f15cfad25e4c549988b95bcc1aca9c8bb57_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether the reasoning quality of large language models transfers across languages. The authors propose a framework to evaluate if model-generated reasoning traces logically support their conclusions, analyzing 65k traces across 6 languages and 6 models. They find a critical misalignment, especially in non-Latin scripts, showing that current multilingual evaluation practices provide an incomplete picture of model reasoning capabilities.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Mitigating Social Desirability Bias in Random Silicon Sampling</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm evaluation], [silicon sampling, social desirability bias, prompt engineering, jensen-shannon divergence, american national election study]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sashank Chapala, Maksym Mironov, Songgaojun Deng</p>
</li>
<li class="">
<p><strong>institution:</strong> Eindhoven University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22725" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22725</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Replicates and confirms the presence of persistent Social Desirability Bias (SDB) in LLM-based silicon sampling. 2. Proposes and systematically evaluates four psychologically grounded prompt-based methods (reformulated, reverse-coded, priming, preamble) for mitigating SDB. 3. Demonstrates that reformulated prompts (neutral, third-person phrasing) are the most effective method for improving alignment between silicon and human survey response distributions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e514b34cb5fd24baebc22116c45f73b1898e7c713905a13d372408df0900782b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e514b34cb5fd24baebc22116c45f73b1898e7c713905a13d372408df0900782b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how to reduce Social Desirability Bias in LLM-generated survey responses (silicon sampling). It tests four prompt-based mitigation methods and finds that reformulating questions into neutral, third-person phrasing most effectively aligns the LLM outputs with real human data from the American National Election Study.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text classification], [data augmentation, imbalanced dataset, social media analysis, natural language processing, pregnancy outcome]</p>
</li>
<li class="">
<p><strong>authors:</strong> Md Badsha Biswas</p>
</li>
<li class="">
<p><strong>institution:</strong> George Mason University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22732</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel approach to use public social media data (e.g., Twitter) as an adjunctive resource for studying negative pregnancy outcomes, addressing data scarcity in traditional epidemiological research. 2. Constructs an NLP pipeline to automatically identify and classify pregnancy experiences from unstructured, noisy social media text, distinguishing between positive and negative outcomes. 3. Investigates and evaluates various data augmentation techniques specifically to address the severe class imbalance inherent in social media data for this sensitive health domain.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb9c28a95fb880100ca20beffad94909ef9e73c38a75789c38961258454c014a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb9c28a95fb880100ca20beffad94909ef9e73c38a75789c38961258454c014a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of classifying negative pregnancy outcomes from imbalanced social media data. It proposes an NLP pipeline to extract and categorize pregnancy experiences from Twitter and investigates data augmentation techniques to balance the dataset. The research demonstrates the viability of social media data as a supplementary resource for epidemiological studies on pregnancy.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Harnessing Large Language Models for Biomedical Named Entity Recognition</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [named entity recognition], [instruction tuning, data filtering, weak-to-strong learning, biomedical named entity recognition, json generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jian Chen, Leilei Su, Cong Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Hainan University, Weill Cornell Medicine</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22738" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22738</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes BioSelectTune, a data-centric framework for fine-tuning LLMs for BioNER that prioritizes data quality. 2. Introduces a Hybrid Superfiltering strategy, a weak-to-strong data curation method to distill a high-impact training dataset. 3. Reformulates BioNER as a structured JSON generation task to leverage LLMs&#x27; instruction-following capabilities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e941de51836d02e0004ef558a69019ce22af7124cd10760a2c904f6329cfa1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e941de51836d02e0004ef558a69019ce22af7124cd10760a2c904f6329cfa1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of adapting general-domain LLMs to Biomedical Named Entity Recognition (BioNER) by proposing BioSelectTune, a framework that uses a novel Hybrid Superfiltering data curation strategy and formulates BioNER as a JSON generation task. The method achieves state-of-the-art performance on multiple benchmarks, outperforming specialized models even when trained on only 50% of the curated data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [diffusion language models, causal attention, prefix KV caching, topological reordering, streaming decoding]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aiwei Liu, Minghua He, Shaoxun Zeng, Sijun Zhang, Linhao Zhang, Chuhan Wu, Wei Jia, Yuan Liu, Xiao Zhou, Jie Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Tencent (WeChat AI), Peking University, Tsinghua University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22737</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/tencent/WeDLM" target="_blank" rel="noopener noreferrer" class="">https://github.com/tencent/WeDLM</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes WeDLM, a diffusion decoding framework built entirely on standard causal attention to be compatible with prefix KV caching. 2. Introduces Topological Reordering to allow masked positions to condition on all observed tokens while maintaining a strict causal mask. 3. Designs a streaming decoding procedure that commits confident tokens continuously to avoid stop-and-wait behavior and maintain fixed parallel workload.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad23d9024363d110ea78bc7ec9d949004a721e40ff6ee0dc4259437ba273af5e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad23d9024363d110ea78bc7ec9d949004a721e40ff6ee0dc4259437ba273af5e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the inefficiency of diffusion language models (DLLMs) at inference time, which often fail to achieve speedups over autoregressive models due to their reliance on bidirectional attention that breaks prefix KV caching. It proposes WeDLM, a framework that uses causal attention and a novel streaming decoding procedure with topological reordering to enable efficient parallel generation. Experiments show WeDLM preserves model quality while achieving up to 3x-10x speedup over optimized AR engines like vLLM.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Text-Routed Sparse Mixture-of-Experts Model with Explanation and Temporal Alignment for Multi-Modal Sentiment Analysis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multi-modal sentiment analysis], [multi-modal sentiment analysis, mixture-of-experts, temporal alignment, multi-modal large language model, cross-attention]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dongning Rao, Yunbiao Zeng, Zhihua Jiang, Jujian Lv</p>
</li>
<li class="">
<p><strong>institution:</strong> Guangdong University of Technology, Guangdong Polytechnic Normal University, Jinan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22741" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22741</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/fip-lab/TEXT" target="_blank" rel="noopener noreferrer" class="">https://github.com/fip-lab/TEXT</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel text-routed sparse mixture-of-experts model with gate fusion for multi-modal sentiment analysis. 2. Introduces a temporal alignment block that merges the benefits of Mamba and temporal cross-attention to align audio and video representations. 3. Augments explanations for MSA using Multi-modal Large Language Models (MLLMs) and aligns different modalities with these explanations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcf1bd04e7c087db4d11cc1d5f3e99f88fc80cf401c5c782a8b3003074eef9b1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcf1bd04e7c087db4d11cc1d5f3e99f88fc80cf401c5c782a8b3003074eef9b1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes TEXT, a model for multi-modal sentiment analysis that uses MLLM-generated explanations and a novel temporal alignment block to better fuse text, audio, and video modalities. The method achieves state-of-the-art performance across four datasets, significantly reducing error metrics compared to recent approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [fake news detection], [domain adaptation, XLM-RoBERTa, mBERT, low-resource language, Urdu]</p>
</li>
<li class="">
<p><strong>authors:</strong> Muhammad Zain Ali, Bernhard Pfahringer, Tony Smith</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Waikato</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22778" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22778</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/zainali93/DomainAdaptation" target="_blank" rel="noopener noreferrer" class="">https://github.com/zainali93/DomainAdaptation</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Investigates domain adaptation before fine-tuning for fake news classification in Urdu, a low-resource language. 2. Evaluates and compares the effectiveness of this staged training approach on two multilingual models (XLM-R and mBERT). 3. Demonstrates that domain-adapted XLM-R consistently outperforms its vanilla counterpart across four Urdu fake news datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34b44093cc6cdaad3233e04caa61c5300da4dbe090a12e70cdd829572c5a7c29_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34b44093cc6cdaad3233e04caa61c5300da4dbe090a12e70cdd829572c5a7c29_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses fake news classification in Urdu, a low-resource language, by proposing a domain adaptation approach before fine-tuning multilingual language models. The method involves domain-adaptive pretraining on an Urdu news corpus, applied to XLM-RoBERTa and mBERT. Results show that domain-adapted XLM-R consistently improves performance, while mBERT shows mixed results.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] CNSight: Evaluation of Clinical Note Segmentation Tools</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text segmentation], [clinical note segmentation, transformer models, large language models, MIMIC-IV, rule-based baselines]</p>
</li>
<li class="">
<p><strong>authors:</strong> Risha Surana, Adrian Law, Sunwoo Kim, Rishab Sridhar, Angxiao Han, Peiyu Hong</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Southern California</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22795" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22795</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A comprehensive evaluation of diverse methods (rule-based, domain-specific transformers, and large language models) for the task of clinical note segmentation. 2. The curation and use of a dataset of 1,000 notes from MIMIC-IV for benchmarking segmentation performance. 3. Empirical findings that large API-based models (e.g., GPT-5-mini) achieve the best overall performance, while lightweight baselines remain competitive only on structured tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates various methods for segmenting unstructured clinical notes into distinct sections. It compares rule-based baselines, domain-specific transformers, and large language models on a curated dataset from MIMIC-IV. The main conclusion is that large API-based models like GPT-5-mini achieve the best overall segmentation performance, providing guidance for method selection in downstream clinical applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] NepEMO: A Multi-Label Emotion and Sentiment Analysis on Nepali Reddit with Linguistic Insights and Temporal Trends</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [emotion and sentiment analysis], [multi-label classification, transformer models, topic modelling, temporal analysis, linguistic insights]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sameer Sitoula, Tej Bahadur Shahi, Laxmi Prasad Bhatt, Anisha Pokhrel, Arjun Neupane</p>
</li>
<li class="">
<p><strong>institution:</strong> Tribhuvan University, Queensland University of Technology, Advanced College of Engineering and Management, Central Queensland University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22823" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22823</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduction of NepEMO, a novel manually annotated dataset for multi-label emotion and sentiment analysis on Nepali Reddit posts in multiple scripts. 2. A detailed linguistic and temporal analysis of the dataset, including emotion trends, co-occurrence, and topic modeling. 3. A comprehensive benchmark comparing traditional ML, deep learning, and transformer models, demonstrating the superiority of transformers for the tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbfaa02abfed829cc20f377fe4ff49e093d956ae5d2c81018f8575d9b08ab30b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbfaa02abfed829cc20f377fe4ff49e093d956ae5d2c81018f8575d9b08ab30b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces NepEMO, a new dataset for multi-label emotion and sentiment analysis on posts from the Nepali subreddit. The authors perform linguistic and temporal analysis on the data and benchmark various machine learning models. The results show that transformer models outperform traditional machine learning and deep learning models for both classification tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [automated environment synthesis, environment-level RL, agentic reinforcement learning, simulated user, policy optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tongyi Lab, Alibaba Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22857</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Debugging Tabular Log as Dynamic Graphs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [dynamic graph, graph neural network, tabular log, log debugging, heterogeneous nodes]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chumeng Liang, Zhanyang Jin, Zahaib Akhtar, Mona Pereira, Haofei Yu, Jiaxuan You</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois Urbana-Champaign, Amazon</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22903" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22903</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes GraphLogDebugger, a novel framework that models tabular log data as dynamic graphs with heterogeneous nodes for objects and events, 2. Demonstrates that a simple dynamic GNN can outperform large language models (LLMs) in debugging tasks using this graph representation, 3. Validates the approach on real-world datasets from computer systems and academic papers, showing improved flexibility and scalability over LLM-based methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfc0dd96717274f366abd002f1a9147f7afbdaba795d251628919a0d25289925_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfc0dd96717274f366abd002f1a9147f7afbdaba795d251628919a0d25289925_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces GraphLogDebugger, a framework that converts tabular log data into dynamic graphs to detect inconsistencies in real-world systems. By representing logs as evolving graphs with object and event nodes, a lightweight dynamic Graph Neural Network effectively debugs logs, outperforming larger LLM-based models in experiments on system and academic log datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Multimodal Fact-Checking: An Agent-based Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [multimodal fact-checking], [multimodal misinformation, agent-based reasoning, explainable dataset, vision-language models, evidence retrieval]</p>
</li>
<li class="">
<p><strong>authors:</strong> Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Singapore (NUS)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22933" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22933</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces RW-Post, a high-quality, explainable dataset for real-world multimodal fact-checking that aligns claims with original social media posts and provides detailed reasoning and evidence. 2. Proposes AgentFact, a novel agent-based multimodal fact-checking framework that emulates the human verification workflow through five specialized, collaboratively working agents. 3. Demonstrates that the synergy between the new dataset and the agent framework substantially improves both the accuracy and interpretability of multimodal fact-checking.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bbe58d9ac10920f1b315029a664c297bd8051834b3724dbf3fa80f26372bec_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bbe58d9ac10920f1b315029a664c297bd8051834b3724dbf3fa80f26372bec_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of automated multimodal fact-checking by introducing a new dataset (RW-Post) and an agent-based framework (AgentFact). The dataset provides real-world misinformation instances with reasoning and evidence, while the framework uses specialized agents to collaboratively perform verification tasks. The combined approach is shown to significantly enhance the accuracy and explainability of fact-checking systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Diversity or Precision? A Deep Dive into Next Token Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [policy gradient, reward shaping, next-token prediction, exploration space, cross-entropy loss]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haoyuan Wu, Hai Wang, Jiajia Wu, Jinxiang Ou, Keyao Wang, Weile Chen, Zihao Zheng, Bei Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Tencent, The Chinese University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22955" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22955</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Reinterprets standard cross-entropy loss as a specific instance of policy gradient optimization in a single-step episode, bridging supervised learning and RL. 2. Proposes a generalized pre-training objective using on-policy RL principles and a novel reward-shaping strategy to balance diversity and precision in the token-output distribution. 3. Empirically finds that a precision-oriented prior, rather than a high-entropy one, creates a more favorable exploration space for subsequent RL, enhancing reasoning performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how the token-output distribution from pre-training shapes the exploration space for subsequent reinforcement learning (RL) in language models. It proposes a new pre-training method that frames next-token prediction as an RL problem, using a reward-shaping strategy to control distribution precision. The key finding is that a precision-focused prior, contrary to intuition, provides a better exploration foundation for RL than a high-entropy one.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Prompt engineering does not universally improve Large Language Model performance across clinical decision-making tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [large language models for healthcare], [prompt engineering, clinical decision support, few-shot learning, model evaluation, temperature setting]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mengdi Chai, Ali R. Zomorrodi</p>
</li>
<li class="">
<p><strong>institution:</strong> Harvard School of Public Health, Massachusetts General Hospital, Harvard Medical School, Broad Institute of MIT and Harvard</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22966" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22966</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Comprehensive evaluation of three state-of-the-art LLMs across the full clinical reasoning workflow, revealing high task-dependent performance variability. 2. Demonstration that prompt engineering (specifically MedPrompt variations) is not universally beneficial, improving performance only on the task with the lowest baseline accuracy. 3. Finding that targeted dynamic few-shot prompting does not consistently outperform random selection, suggesting a trade-off between example relevance and contextual diversity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30c995933cd74a3ca7c2af152821552a5355b6d092f084b174049b87f299a2bc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30c995933cd74a3ca7c2af152821552a5355b6d092f084b174049b87f299a2bc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study evaluated the performance of LLMs like ChatGPT-4o on clinical decision-making tasks and tested if prompt engineering could improve it. The results show that prompt engineering is not a universal solution; it helps only on specific tasks and targeted few-shot learning is not always better than random selection. The impact of prompt engineering is highly dependent on the model and the specific clinical task.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Improving Generalization in LLM Structured Pruning via Function-Aware Neuron Grouping</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [structured pruning, post-training pruning, function-aware grouping, calibration bias, sparsity allocation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tao Yu, Yongqi An, Kuan Zhu, Guibo Zhu, Ming Tang, Jinqiao Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Wuhan AI Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23014</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Function-Aware Neuron Grouping (FANG), a pruning framework that groups neurons based on the semantic context types they process to mitigate calibration bias. 2. Introduces a weighted importance estimation within each group that prioritizes tokens strongly correlated with the group&#x27;s functional role, and preserves cross-context neurons. 3. Develops an adaptive sparsity allocation strategy per model block based on its functional complexity to better balance sparsity and performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97a53f8a0eafa56a813a03f94cde349a2ee5aa7da51f314f7ec42da88585b4c3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97a53f8a0eafa56a813a03f94cde349a2ee5aa7da51f314f7ec42da88585b4c3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limited generalization of existing post-training structured pruning methods for LLMs when calibration data is biased. It proposes FANG, a method that groups neurons by function, weights importance estimation accordingly, and adaptively allocates sparsity. Experiments show FANG improves downstream task accuracy and achieves state-of-the-art results when combined with existing pruning methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LENS: LLM-Enabled Narrative Synthesis for Mental Health by Aligning Multimodal Sensing with Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multimodal language models], [multimodal sensing, time-series encoding, ecological momentary assessment (EMA)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wenxuan Xu, Arvind Pillai, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell</p>
</li>
<li class="">
<p><strong>institution:</strong> Dartmouth College, University of Virginia, Massachusetts General Hospital, Harvard Medical School</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23025" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23025</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces LENS, a framework that aligns multimodal sensing data with language models to generate clinically grounded mental health narratives. 2. Constructs a large-scale dataset of over 100,000 sensor-text QA pairs by transforming Ecological Momentary Assessment (EMA) responses. 3. Trains a patch-level encoder to project raw sensor time-series signals directly into an LLM&#x27;s representation space for native integration.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b276805556458f16b63a7994f848b1c3a3a24eeed8ecb80496361d925fb9d8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b276805556458f16b63a7994f848b1c3a3a24eeed8ecb80496361d925fb9d8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of translating long-duration, multimodal sensor data into interpretable natural language for mental health assessment. It proposes the LENS framework, which creates a large sensor-text dataset and trains a specialized encoder to align sensor signals with an LLM, enabling the generation of clinically meaningful narratives. The results show LENS outperforms baselines on NLP and clinical metrics, and is validated by mental health professionals.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [interpretability], [chain-of-thought, faithfulness, causal mediation analysis, biasing features, explainability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kerem Zaman, Shashank Srivastava</p>
</li>
<li class="">
<p><strong>institution:</strong> UNC Chapel Hill</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23032" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23032</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Argues that the Biasing Features metric conflates unfaithfulness with incompleteness in Chain-of-Thought explanations. 2. Introduces a new faithful@k metric showing increased token budgets improve hint verbalization. 3. Uses Causal Mediation Analysis to show non-verbalized hints can still causally mediate predictions through the CoT.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper challenges the use of hint-verbalization metrics like Biasing Features for evaluating the faithfulness of Chain-of-Thought reasoning. It proposes that apparent unfaithfulness is often due to incompleteness from lossy compression and tight token limits, not a lack of alignment, and demonstrates this using new metrics and causal mediation analysis. The conclusion advocates for a broader interpretability toolkit beyond hint-based evaluations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Accelerating Language Model Workflows with Prompt Choreography</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [KV cache, multi-agent workflows, prompt caching, fine-tuning, parallel decoding]</p>
</li>
<li class="">
<p><strong>authors:</strong> TJ Bai, Jason Eisner</p>
</li>
<li class="">
<p><strong>institution:</strong> Johns Hopkins University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23049" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23049</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Prompt Choreography, a framework for efficient LLM workflow execution using a dynamic, global KV cache that allows arbitrary, reordered attention to cached messages. 2. Enables parallel LLM calls and overcomes limitations of static caching by allowing runtime reuse of dynamically generated messages. 3. Demonstrates that fine-tuning the LLM to work with the cache can mitigate performance differences, achieving significant latency reduction (2.0–6.2× faster time-to-first-token) and end-to-end speedups (&gt;2.2×).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7be6fd2c8ed387f8c6d6cfba8ffad178e5ac937348602af7f9d1951150964c8c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7be6fd2c8ed387f8c6d6cfba8ffad178e5ac937348602af7f9d1951150964c8c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the inefficiency of redundant computation in multi-agent LLM workflows. It proposes Prompt Choreography, a framework that uses a dynamic, global KV cache to allow LLM calls to attend to arbitrary subsets of previously encoded messages, supporting parallel execution. The method, combined with fine-tuning, significantly reduces latency and achieves substantial speedups by reusing cached encodings instead of re-encoding from scratch.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language modeling], [ModernBERT, Rotary Positional Embeddings, FlashAttention, monolingual Turkish, encoder-only transformer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Melikşah Türker, A. Ebrar Kızıloğlu, Onur Güngör, Susan Üsküdarlı</p>
</li>
<li class="">
<p><strong>institution:</strong> Boğaziçi University, VNGRS-AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23065" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23065</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces TabiBERT, the first monolingual Turkish encoder trained from scratch using the modern ModernBERT architecture (RoPE, FlashAttention). 2. Presents TabiBench, a unified benchmarking framework with 28 datasets across 8 tasks for standardized evaluation of Turkish NLP models. 3. Demonstrates state-of-the-art performance on TabiBench, outperforming prior models like BERTurk and showing strong cross-domain generalization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc5c874163783e3d6e86937eb817ae8080c269ccc3607c50deebbe47ac22673_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc5c874163783e3d6e86937eb817ae8080c269ccc3607c50deebbe47ac22673_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces TabiBERT, a large-scale monolingual Turkish encoder based on the ModernBERT architecture, trained from scratch on a diverse corpus. It also presents TabiBench, a comprehensive benchmarking framework. TabiBERT achieves state-of-the-art results on multiple Turkish NLP tasks, demonstrating superior performance and generalization compared to existing models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Imitation Learning, Reinforcement Learning, KL divergence, Dense Gradient, Sparse Gradient]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yingru Li, Ziniu Li, Jiacai Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Not explicitly stated in provided content.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23097</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Reservoir Computing inspired Matrix Multiplication-free Language Model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [MatMul-free LM, reservoir computing, weight sharing, ternary quantization, MLGRU]</p>
</li>
<li class="">
<p><strong>authors:</strong> Takumi Shiratsuchi, Yuichiro Tanaka, Hakaru Tamukoh</p>
</li>
<li class="">
<p><strong>institution:</strong> Kyushu Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23145</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel language model architecture that integrates reservoir computing principles into a MatMul-free LM to reduce training costs. 2. Introduces techniques of partially fixing/sharing weights and inserting reservoir layers to obtain dynamic representations without extra training overhead. 3. Combines operations to reduce memory accesses, achieving reductions in parameters, training time, and inference time while maintaining performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b5c1771a82be40c7ba47d813ef33ce372e599bd79d60507444a618ff4e28d2c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b5c1771a82be40c7ba47d813ef33ce372e599bd79d60507444a618ff4e28d2c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high computational cost of large language models by proposing a matrix multiplication-free model enhanced with reservoir computing. The method fixes/shared weights in selected layers and inserts reservoir layers to reduce training overhead and memory accesses. Experiments show the approach reduces parameters by up to 19%, training time by 9.9%, and inference time by 8.0% while maintaining comparable performance to the baseline.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Not too long do read: Evaluating LLM-generated extreme scientific summaries</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text summarization], [extreme summarization, TLDR, abstractive summarization, extractive summarization, dataset creation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhuoqi Lyu, Qing Ke</p>
</li>
<li class="">
<p><strong>institution:</strong> City University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23206</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/netknowledge/LLM_summarization" target="_blank" rel="noopener noreferrer" class="">https://github.com/netknowledge/LLM_summarization</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces BiomedTLDR, a novel high-quality dataset of researcher-authored scientific TLDRs, curated from author annotations in bibliographies. 2. Evaluates the performance of popular open-weight LLMs in generating scientific TLDRs from paper abstracts. 3. Provides an analysis revealing that LLM-generated summaries tend to be more extractive (closer to the source text&#x27;s lexicon and structure) compared to more abstractive human-written summaries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e22384bc3a440a2b34601b9d8ed0a9de58fdee4ff92f1d83db278778c4293a7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e22384bc3a440a2b34601b9d8ed0a9de58fdee4ff92f1d83db278778c4293a7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of high-quality datasets for evaluating LLMs in generating scientific extreme summaries (TLDRs) by introducing BiomedTLDR, a dataset of human-authored summaries. It then evaluates open-weight LLMs on this task and finds that, while some can produce human-like summaries, LLMs generally tend to be more extractive and less abstractive than human experts.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Anka: A Domain-Specific Language for Reliable LLM Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Domain-Specific Language, Constrained Syntax, Code Generation, Data Transformation Pipeline, In-Context Learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Saif Khalfan Saif Al Mazrouei</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Wisconsin-Madison</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23214" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23214</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [LLM Ensemble, LLM-as-a-Judge, Peer-Review, Unsupervised Selection, Truth Inference]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhijun Chen, Zeyu Ji, Qianren Mao, Junhang Cheng, Bangjie Qin, Hao Wu, Zhuoran Li, Jingzheng Li, Kai Sun, Zizhe Wang, Yikun Ban, Zhu Sun, Xiangyang Ji, Hailong Sun</p>
</li>
<li class="">
<p><strong>institution:</strong> Beihang University, Zhongguancun Laboratory, Xi&#x27;an Jiaotong University, Hong Kong University of Science and Technology, Tsinghua University, Singapore University of Technology and Design</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23213" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23213</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LLM-PeerReview, a novel, peer-review-inspired, and interpretable framework for unsupervised LLM ensemble selection. 2. Introduces a three-stage process (scoring via LLM-as-a-Judge, reasoning via aggregation, and selection) that leverages multiple LLMs to evaluate each other&#x27;s responses. 3. Demonstrates strong empirical performance, with two variants significantly outperforming a recent advanced baseline (Smoothie-Global) on multiple datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/366f9e4fb3bf94aabbe40f3849a7637d6656821ec3dde88cd37d06effd3ed3f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/366f9e4fb3bf94aabbe40f3849a7637d6656821ec3dde88cd37d06effd3ed3f5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes LLM-PeerReview, an unsupervised ensemble method that selects the best response from multiple LLM candidates. The method uses a peer-review process where LLMs score each other&#x27;s outputs, then aggregates these scores to make a final selection. The approach is shown to be simple and powerful, outperforming a strong baseline by a significant margin across several datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [post-training (sft/rlhf)], [Sparse Autoencoders (SAEs), Low-Rank Adaptation (LoRA), Safety Alignment, Interpretability, Parameter-efficient Fine-tuning (PEFT)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dianyun Wang, Qingsen Ma, Yuhu Shang, Zhifeng Lu, Lechen Ning, Zhenbo Xu, Huijia Wu, Zhaofeng He</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing University of Posts and Telecommunications</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23260" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23260</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel method that uses pre-trained Sparse Autoencoders (SAEs) to construct an explicit, interpretable low-rank subspace for adapter initialization, addressing the black-box nature of traditional LoRA. 2. Provides theoretical analysis proving that SAE-based subspace identification achieves arbitrarily small recovery error under monosemanticity, while direct identification suffers an irreducible error floor due to polysemanticity. 3. Demonstrates state-of-the-art performance on safety alignment, achieving up to 99.6% safety rate while updating only 0.19-0.24% of parameters, and provides interpretable insights into the learned alignment subspace.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of interpretability in standard Low-Rank Adaptation (LoRA) methods for fine-tuning large language models. The proposed method leverages Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled space and uses them to construct an explicit, interpretable low-rank subspace for adapter initialization. The approach achieves superior safety alignment performance and provides transparency into the learned adaptation process.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Chinese Morph Resolution in E-commerce Live Streaming Scenarios</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [morph resolution], [morph resolution, text-to-text generation, large language models, automatic speech recognition, e-commerce live streaming]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiahao Zhu, Jipeng Qiang, Ran Bai, Chenyu Liu, Xiaoye Ouyang</p>
</li>
<li class="">
<p><strong>institution:</strong> Yangzhou University, China Academy of Electronic and Information Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23280</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced the novel Live Auditory Morph Resolution (LiveAMR) task for detecting pronunciation-based evasion in e-commerce live streams, distinct from prior text-based morph research. 2. Constructed the first large-scale LiveAMR dataset containing 86,790 samples from health and medical live streaming scenarios. 3. Proposed a method that transforms the morph resolution task into a text-to-text generation problem and leveraged LLMs for data augmentation to improve model performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5833e430257262b6c7e7229b982e2421b63671f2902d24282bd2f2167c1934c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5833e430257262b6c7e7229b982e2421b63671f2902d24282bd2f2167c1934c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces the LiveAMR task to detect pronunciation-based morphs used by hosts in Chinese e-commerce live streams to evade voice censorship. The authors built a new dataset and framed the problem as a text-to-text generation task, using LLMs for data augmentation to boost performance. The study concludes that resolving these morphs significantly enhances the effectiveness of live streaming content regulation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent collaboration, large language models (LLMs), speech synthesis, audiobook interpretation, Chinese NLP]</p>
</li>
<li class="">
<p><strong>authors:</strong> Minjiang Huang, Jipeng Qiang, Yi Zhu, Chaowei Zhang, Xiangyu Zhao, Kui Yu</p>
</li>
<li class="">
<p><strong>institution:</strong> Yangzhou University, City University of Hong Kong, Hefei University of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23300" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23300</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/9624219/AI4reading" target="_blank" rel="noopener noreferrer" class="">https://github.com/9624219/AI4reading</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed AI4Reading, a novel multi-agent collaboration system for automatically generating podcast-like Chinese audiobook interpretations. 2. Designed a framework with 11 specialized agents (e.g., topic analysts, case analysts, editors) to achieve accurate content preservation, enhanced comprehensibility, and logical narrative structure. 3. Demonstrated through comparison with expert interpretations that the system generates simpler and more accurate interpretative scripts, though speech quality has room for improvement.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554ec6976f875a67d0faba12d389415bd8119634b07160c7f87e65bff826fc84_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554ec6976f875a67d0faba12d389415bd8119634b07160c7f87e65bff826fc84_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes AI4Reading, a system that uses multi-agent collaboration with LLMs and speech synthesis to automatically generate Chinese audiobook interpretations. The system employs 11 specialized agents to process content for accuracy, comprehensibility, and narrative structure. Evaluation shows the generated scripts are simpler and more accurate than expert ones, though speech generation quality still lags behind.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [agent evaluation], [spatial reasoning, long-horizon planning, partial observability, mental simulation, diagnostic benchmark]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huan-ang Gao, Zikang Zhang, Tianwei Luo, Kaisen Yang, Xinzhe Juan, Jiahao Qiu, Tianxing Chen, Bingxiang He, Hao Zhao, Hao Zhou, Shilong Liu, Mengdi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tsinghua University, Princeton University, Shanghai Jiao Tong University &amp; University of Michigan, The University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23328" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23328</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies three core cognitive challenges (spatial reasoning, long-horizon state tracking, active exploration under partial observation) hindering LLM agents in the physical world. 2. Introduces CubeBench, a novel generative benchmark based on the Rubik&#x27;s Cube with a three-tiered diagnostic framework to isolate and evaluate these capabilities. 3. Provides a diagnostic framework using external solver tools to analyze failure modes and reveals critical limitations of leading LLMs, including a 0.00% pass rate on long-horizon tasks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/210465a4bf9048c43ec900e17f922e63394d83664c6fe631fec0d54577fd9fb6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/210465a4bf9048c43ec900e17f922e63394d83664c6fe631fec0d54577fd9fb6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces CubeBench, a diagnostic benchmark using a Rubik&#x27;s Cube to evaluate LLM agents&#x27; spatial reasoning and long-horizon planning under partial observation. It employs a three-tiered framework from full symbolic to partial visual states. Experiments show leading LLMs fail completely on long-horizon tasks, highlighting a fundamental gap for physical-world deployment.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [memory systems, cognitive neuroscience, LLM-driven agents, memory security, multimodal memory]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin</p>
</li>
<li class="">
<p><strong>institution:</strong> Harbin Institute of Technology, Fudan University, Peking University, National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23343" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23343</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/AgentMemory/Huaman-Agent-Memory" target="_blank" rel="noopener noreferrer" class="">https://github.com/AgentMemory/Huaman-Agent-Memory</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a systematic synthesis and comparative analysis of memory systems from cognitive neuroscience to LLM-driven autonomous agents. 2. Reviews mainstream benchmarks for evaluating agent memory and explores memory security from attack and defense perspectives. 3. Envisions future research directions, focusing on multimodal memory systems and skill acquisition.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15773eb4c52c63f2641be869baf3af4b7f6bb74f6e36c67247957bfbd039e9b6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15773eb4c52c63f2641be869baf3af4b7f6bb74f6e36c67247957bfbd039e9b6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This survey paper bridges the interdisciplinary gap between cognitive neuroscience and AI by systematically analyzing memory systems for autonomous agents. It compares biological and artificial memory taxonomies, storage, and management, while also reviewing evaluation benchmarks and security issues. The work concludes by outlining future directions, including multimodal memory and skill learning.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [knowledge-augmented reasoning], [external knowledge graph, subgraph generation, stepwise reasoning, large language models, structured reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xin Zhang, Yang Cao, Baoxing Wu, Xinyi Chen, Kai Song, Siying Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Chongqing Jiaotong University, Chongqing University of Posts and Telecommunications</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23356" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23356</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel stepwise reasoning enhancement framework (SGR) that dynamically constructs query-relevant subgraphs from external knowledge bases to guide LLM reasoning. 2. Introduces a method to perform multi-step reasoning grounded in the structured subgraph, reducing the influence of noisy information and improving logical consistency. 3. Demonstrates the framework&#x27;s effectiveness through experiments on multiple benchmark datasets, showing consistent performance improvements over strong baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3999b4a75409aeb08ff19dfef01f6296ec2c9184a598991b29d9ce92c1f8e0a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3999b4a75409aeb08ff19dfef01f6296ec2c9184a598991b29d9ce92c1f8e0a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitation of LLMs in complex reasoning tasks by proposing SGR, a framework that enhances reasoning through dynamic external subgraph generation and step-by-step inference over the structured knowledge. Experimental results show that SGR improves reasoning accuracy and outperforms baseline methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Theoretical Foundations of Scaling Law in Familial Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [familial models, scaling law, early exiting, IsoFLOP design, compute-optimal training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huan Song, Qingfei Zhao, Ting Long, Shuyu Tian, Hongjun An, Jiawei Shao, Chi Zhang, Xuelong Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Artificial Intelligence (TeleAI), China Telecom</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23407" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23407</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Theoretically and empirically extends the neural scaling law to the &quot;familial models&quot; paradigm by introducing granularity (G) as a new fundamental scaling variable alongside model size (N) and tokens (D). 2. Proposes a rigorous IsoFLOP experimental design to decouple architectural impact from computational scale, enabling high-fidelity parameterization of the unified scaling law L(N, D, G). 3. Quantifies that the granularity penalty follows a multiplicative power law with an extremely small exponent (γ≈0.041), validating the &quot;train once, deploy many&quot; paradigm without compromising compute-optimality.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of traditional neural scaling laws, which assume a single model, by extending them to familial models that generate multiple sub-models from one backbone. The authors propose a unified scaling law incorporating granularity (G) and validate it using a rigorous IsoFLOP experimental design. The key finding is that the performance penalty for increased granularity is very small, proving that deployment flexibility can be achieved efficiently.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language model training], [token dropout, entropy-guided regularization, multi-epoch training degradation, autoregressive models, data-constrained adaptation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiapeng Wang, Yiwen Hu, Yanzipeng Gao, Haoyu Wang, Shuo Wang, Hongyu Lu, Jiaxin Mao, Wayne Xin Zhao, Junyi Li, Xiao Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Renmin University of China, Tsinghua University, Tencent (WeChat), City University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23422" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23422</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and analyzes the root cause of multi-epoch training degradation in autoregressive LLMs as an imbalance in learning dynamics between low-entropy and high-entropy tokens. 2. Proposes EntroDrop, a novel entropy-guided token dropout method that acts as structured data regularization by selectively masking low-entropy tokens during training. 3. Demonstrates through experiments on models from 0.6B to 8B parameters that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac5e3a92b434a83b0821bec18501089160580e913a30fb1e39f43b38943b7ef0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac5e3a92b434a83b0821bec18501089160580e913a30fb1e39f43b38943b7ef0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of performance degradation in autoregressive language models during multi-epoch training on limited domain data. It proposes EntroDrop, an entropy-guided token dropout method that selectively masks predictable, low-entropy tokens to regularize training and uses a curriculum schedule to adjust regularization strength. Experiments show EntroDrop effectively mitigates overfitting and maintains robust model performance across different scales, offering a promising approach for adapting LLMs in data-constrained domains.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [bias mitigation], [Causal-Contrastive Preference Optimization, spurious feature correlation, fairness-sensitive preference update, counterfactual signals, composite bias]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xuan Feng, Bo An, Tianlong Gu, Liang Chang, Fengrui Hao, Peipeng Yu, Shuai Zhao</p>
</li>
<li class="">
<p><strong>institution:</strong> Jinan University, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23430" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23430</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework that simultaneously discovers and suppresses latent spurious feature correlations to mitigate both stereotypical and structural biases in LLMs. 2. Proposes a method that leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths during optimization. 3. Designs a fairness-sensitive preference update mechanism that dynamically evaluates logit-level contributions to suppress shortcut features while preserving general reasoning capabilities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26a9c5a41f0184f3fdb110be083a06995183a94e4255ffb7b2066647ec2306c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26a9c5a41f0184f3fdb110be083a06995183a94e4255ffb7b2066647ec2306c9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the composite bias problem in LLMs, where mitigating one type of bias (e.g., stereotypical) often worsens another (e.g., structural). It proposes Causal-Contrastive Preference Optimization (C2PO), a unified framework that uses causal counterfactual signals and a fairness-sensitive update to suppress spurious feature correlations. Experiments show C2PO effectively reduces both bias types while maintaining strong general reasoning performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [scientometrics], [gender diversity, team roles, author contribution statements, threshold regression, citation impact]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yi Zhao, Yongjun Zhu, Donghun Kim, Yuzhuo Wang, Heng Zhang, Chao Lu, Chengzhi Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Anhui University, Yonsei University, Nanjing University, Central China Normal University, Hohai University, Nanjing University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23429" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23429</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a team roles perspective by classifying authors into leadership and support roles using contribution statements, moving beyond aggregate diversity measures. 2. Discovered a non-linear (inverted U-shape) relationship between gender diversity and team impact for both leadership and support groups. 3. Revealed the moderating effect of team size, showing that the impact of leadership-group gender diversity shifts from negative to positive as team size increases, while support-group diversity remains consistently positive.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8e0d6494840d098b4c65bf9f6eb6b4b27a82bd62024c95c0f60db9e5b8fa31f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8e0d6494840d098b4c65bf9f6eb6b4b27a82bd62024c95c0f60db9e5b8fa31f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study investigates how gender diversity within specific team roles (leadership vs. support) affects scientific team impact, measured by citations. By analyzing over 130,000 PLOS papers and using contribution statements to define roles, the authors employed multivariable and threshold regression. They found the relationship is an inverted U-shape, identified high-impact team compositions, and showed that team size significantly moderates the effect of leadership diversity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [evaluation &amp; benchmarking], [clinical reasoning, dynamic evaluation, diagnostic dialogue, knowledge graph, multi-turn interaction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuqi Tang, Jing Yu, Zichang Su, Kehua Feng, Zhihui Zhu, Libin Wang, Lei Liang, Qiang Zhang, Keyan Ding, Huajun Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, AntGroup</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23440" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23440</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ClinDEF, a dynamic evaluation framework for LLMs that simulates multi-turn diagnostic dialogues grounded in a disease knowledge graph to better reflect real-world clinical reasoning. 2. Introduces a granular evaluation protocol that goes beyond diagnostic accuracy to include efficiency analysis and rubric-based assessment of diagnostic quality. 3. Demonstrates that the framework effectively exposes critical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63b6e11110703cffd0afa796f1abd60fa8928363db33520ff03e2f7a54abe3b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63b6e11110703cffd0afa796f1abd60fa8928363db33520ff03e2f7a54abe3b0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the gap in evaluating LLMs for clinical reasoning, which is a dynamic, interactive process poorly captured by static benchmarks. It proposes ClinDEF, a framework that uses a disease knowledge graph to dynamically generate patient cases and simulate diagnostic dialogues between an LLM doctor and an automated patient. Experiments show that ClinDEF effectively reveals critical reasoning deficiencies in advanced LLMs, providing a more realistic and detailed assessment tool.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm training], [Mixture-of-Experts, Router-Expert Coupling, Auxiliary Loss, Expert Specialization, Efficient Training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ang Lv, Jin Ma, Yiyuan Ma, Siyuan Qiao</p>
</li>
<li class="">
<p><strong>institution:</strong> ByteDance, Renmin University of China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23447" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23447</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel lightweight auxiliary loss (ERC loss) to explicitly couple router decisions with expert capabilities in MoE models. 2. Introduces a computationally efficient method that scales with the square of the number of experts (n^2), independent of batch size, unlike prior token-dependent methods. 3. Enables flexible control and quantitative tracking of expert specialization levels during training, providing new insights into MoE model dynamics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6534d4f2f88c89a450614cf67b57f76f33fc90a18f24833876fd8e55d3e326b9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6534d4f2f88c89a450614cf67b57f76f33fc90a18f24833876fd8e55d3e326b9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the misalignment between router decisions and expert capabilities in Mixture-of-Experts (MoE) models. It proposes an Expert-Router Coupling (ERC) loss, a lightweight auxiliary loss that enforces constraints via perturbed router embeddings to ensure each expert specializes in its routed tokens and each router embedding faithfully represents its expert. The method is shown to be effective and computationally efficient, enabling better control and analysis of expert specialization during large-scale pre-training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [instruction following, hindsight replay, sample-efficient RL]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23457" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23457</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/zhangkc97/HiR" target="_blank" rel="noopener noreferrer" class="">https://github.com/zhangkc97/HiR</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text clustering], [hierarchical clustering, density-based clustering, semantic embeddings, large language models, topic modeling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Thomas Haschka, Joseph Bakarji</p>
</li>
<li class="">
<p><strong>institution:</strong> Technische Universität Wien, American University of Beirut</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23471" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23471</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel nested density clustering method to construct hierarchical semantic trees from text embeddings. 2. Demonstrates the method&#x27;s application for data-driven discovery of research areas and subfields without predefined categories. 3. Validates the approach&#x27;s robustness and general applicability across diverse domains using benchmark datasets like 20 Newsgroups and IMDB reviews.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e39c485de109f72521e714f1d7489795a2f6737dcaff2fbddf6af40f9dc170ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e39c485de109f72521e714f1d7489795a2f6737dcaff2fbddf6af40f9dc170ee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of uncovering the global hierarchical semantic structure in text corpora, which remains opaque when using LLM embeddings only for similarity search. It proposes a method that applies nested density clustering on LLM embeddings, gradually relaxing a density criterion to merge clusters into a hierarchical tree. This approach enables the data-driven discovery of semantic relationships and topic hierarchies without predefined categories, as demonstrated on scientific abstracts and benchmark datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Automatic Detection of Complex Quotation Patterns in Aggadic Literature</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text reuse detection], [morphology-aware alignment, context-sensitive enrichment, quotation pattern classification, Hebrew text]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hadar Miller, Tsvi Kuflik, Moshe Lavee</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Haifa</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23504" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23504</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ACT, a novel three-stage algorithm combining morphology-aware alignment and context-sensitive enrichment for detecting complex biblical quotations in Rabbinic literature. 2. Introduces the ability to classify complex stylistic citation patterns such as &quot;Wave&quot; and &quot;Echo&quot; quotations, which existing frameworks struggle with. 3. Demonstrates superior performance (F1=0.91) over leading baselines, effectively bridging the gap between machine-based detection and human editorial judgment in digital humanities.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2678dc7eaa177b1fdea4a65073a64104dc415c64285803a4059dad8d21355551_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2678dc7eaa177b1fdea4a65073a64104dc415c64285803a4059dad8d21355551_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces ACT, a three-stage algorithm designed to automatically detect complex biblical quotations in Rabbinic literature by using morphology-aware alignment and context-sensitive enrichment. The method outperforms existing systems, achieving an F1 score of 0.91, and successfully identifies intricate citation patterns like &quot;Wave&quot; and &quot;Echo&quot; quotations. This work advances computational philology by improving the detection of short, paraphrased, and embedded text reuse in morphologically rich languages like Hebrew.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm robustness &amp; bias], [confirmation bias, latent concept experts, inference-time intervention, multi-agent debate, compositional language]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hazel Kim, Philip Torr</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Oxford</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23518" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23518</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MoLaCE, a lightweight inference-time framework that mitigates LLM confirmation bias by mixing experts instantiated as different activation strengths over latent concepts. 2. Provides the key insight that no single fixed intervention works universally because prompts reweight latent concepts in prompt-specific ways. 3. Demonstrates that the method enables a single LLM to emulate debate benefits efficiently and can be integrated into multi-agent frameworks to reduce correlated errors.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/293e04fd5f7eeb86a4cdafce819a7b7ac1c4ab97756b2f0a2b0305fec15d2fe8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/293e04fd5f7eeb86a4cdafce819a7b7ac1c4ab97756b2f0a2b0305fec15d2fe8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of confirmation bias in LLMs, where models reinforce a preferred answer implied by a prompt. It proposes MoLaCE, a framework that mixes latent concept experts at inference time to diversify perspectives internally. The method reduces bias, improves robustness, and matches multi-agent debate performance with significantly less computation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal training], [vision-language model, unified model, semantic generation, autoregression, data scaling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Fengjiao Chen, Minhao Jing, Weitao Lu, Yan Feng, Xiaoyu Li, Xuezhi Cao</p>
</li>
<li class="">
<p><strong>institution:</strong> Meituan</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23512" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23512</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrates that generation enhances understanding in large-scale VLM training only when operating at the semantic level (e.g., autoregressing high-level visual representations), not at the pixel level. 2. Shows that unified generation-understanding models exhibit superior data scaling trends and higher data utilization efficiency compared to understanding-only models. 3. Proposes that autoregression on input embeddings is an effective and modality-independent method for capturing visual details, enabling pixel-level generation from learned semantics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75dffd20dae849b9b4d37288d6d557fa32f5f2c8bf947c87fc1e79319e9dbe8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75dffd20dae849b9b4d37288d6d557fa32f5f2c8bf947c87fc1e79319e9dbe8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether visual generation tasks can enhance understanding in large-scale vision-language models. Through large-scale pretraining (&gt;200M samples) with a model called UniHetero, the authors find that semantic-level generation (not pixel-level) improves understanding, reveals better data scaling, and that autoregression on input embeddings effectively captures visual details.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection], [knowledge graphs, self-detection, structured verification, GPT-4o, Gemini-2.5-Flash]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sahil Kale, Antonio Luca Alfeo</p>
</li>
<li class="">
<p><strong>institution:</strong> Knowledge Verse AI, eCampus University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23547" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23547</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/knowledge-verse-ai/kg-hallu-eval" target="_blank" rel="noopener noreferrer" class="">https://github.com/knowledge-verse-ai/kg-hallu-eval</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel hallucination self-detection method that converts LLM responses into knowledge graphs for structured analysis., 2. Introduces a manually curated and enhanced hallucination detection dataset to support more reliable future benchmarking., 3. Demonstrates significant performance improvements (up to 16% accuracy, 20% F1) over standard self-detection and a state-of-the-art baseline (SelfCheckGPT).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a76b4a88e64d73392aa8d986a7f3dab5da424782ba41d701ca8db2d4ab4a12d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a76b4a88e64d73392aa8d986a7f3dab5da424782ba41d701ca8db2d4ab4a12d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of hallucinations in LLMs by proposing a self-detection method that converts model responses into knowledge graphs to better analyze atomic facts and estimate hallucination likelihood. The method, evaluated on GPT-4o and Gemini-2.5-Flash, shows substantial improvements in accuracy and F1-score over existing approaches. The work concludes that structuring facts as knowledge graphs enables more robust hallucination detection, offering a low-cost, model-agnostic path toward safer language models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] VL-RouterBench: A Benchmark for Vision-Language Model Routing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [vision-language model routing, benchmark, cost-accuracy trade-off, model selection, evaluation protocol]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhehao Huang, Baijiong Lin, Jingyuan Zhang, Jingying Wang, Yuhang Liu, Ning Lu, Tao Li, Xiaolin Huang</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, The Hong Kong University of Science and Technology (Guangzhou), The Hong Kong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23562</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/K1nght/VL-RouterBench" target="_blank" rel="noopener noreferrer" class="">https://github.com/K1nght/VL-RouterBench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes VL-RouterBench, the first systematic and reproducible benchmark for evaluating vision-language model (VLM) routing systems. 2. Constructs a large-scale evaluation foundation with quality and cost matrices over 519,180 sample-model pairs from 17 models and 14 datasets. 3. Introduces a comprehensive evaluation protocol that jointly measures accuracy, cost, and throughput, and uses a ranking score based on the harmonic mean for fair comparison across router configurations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces VL-RouterBench, a benchmark to systematically evaluate routing systems for vision-language models. It constructs matrices of quality and cost from extensive inference logs and uses a ranking score to compare routers. The evaluation shows current routers achieve significant gains but still fall short of an ideal Oracle, indicating room for improvement in router design.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Instruction-Following Evaluation of Large Vision-Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [instruction-following evaluation], [large vision-language models, visual instruction tuning, output format specification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Daiki Shiono, Shumpei Miyawaki, Ryota Tanaka, Jun Suzuki</p>
</li>
<li class="">
<p><strong>institution:</strong> Tohoku University, NTT Corporation</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23572" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23572</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Quantitatively demonstrates the decline in instruction-following ability of LVLMs after visual instruction fine-tuning. 2. Constructs new training datasets that highlight whether the output format is specified. 3. Shows that explicitly indicating the output format during fine-tuning helps LVLMs follow instructions more accurately.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9a9ab8218c47b2791fe28909d9e490dfaa5d680ecfb209ca796611f893b9430_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9a9ab8218c47b2791fe28909d9e490dfaa5d680ecfb209ca796611f893b9430_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies and quantifies a problem where Large Vision-Language Models (LVLMs) lose their instruction-following ability after visual instruction tuning. The authors propose constructing datasets that explicitly specify the output format and find that training with such data mitigates the performance decline. The main conclusion is that including instructions on output format during fine-tuning can help preserve LVLMs&#x27; instruction-following capabilities.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [spoken language understanding], [spoken language models, style amnesia, multi-turn conversation, paralinguistic features, instruction following]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yu-Xiang Lin, Cheng-Han Chiang, Hung-yi Lee</p>
</li>
<li class="">
<p><strong>institution:</strong> National Taiwan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23578" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23578</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and defines the &quot;style amnesia&quot; problem where spoken language models fail to maintain a user-specified speaking style across multiple conversation turns. 2. Provides a comprehensive evaluation across multiple proprietary and open-source SLMs, demonstrating the pervasiveness of the issue across different emotion, accent, volume, and speed styles. 3. Investigates mitigation strategies, finding that explicit recall prompts can partially alleviate the problem and revealing a counter-intuitive weakness when style instructions are placed in system messages.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7d00f21d056c5ef5d2a037960cefe1ed2dea85d21396e8409388c6f482ecbf8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7d00f21d056c5ef5d2a037960cefe1ed2dea85d21396e8409388c6f482ecbf8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the problem of &quot;style amnesia&quot; in spoken language models (SLMs), where models instructed to adopt a specific speaking style fail to maintain it over a multi-turn conversation. The authors evaluate several SLMs and find that explicitly prompting the model to recall the style instruction can partially mitigate the issue. The study concludes that current SLMs struggle with long-term style consistency, a critical challenge for natural spoken interactions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent synthesis, tool calling, Group Relative Policy Optimization (GRPO), closed-loop training, synthetic data generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuwen Li, Wei Zhang, Zelong Huang, Mason Yang, Jiajun Wu, Shawn Guo, Huahao Hu, Lingyi Sun, Jian Yang, Mingjie Tang, Byran Dai</p>
</li>
<li class="">
<p><strong>institution:</strong> Sichuan University, Beihang University, IQuest Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23611" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23611</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces InfTool, a fully autonomous framework that uses a multi-agent role-playing system (User Simulator, Tool-Calling Assistant, MCP Server) to generate high-quality, verified tool-use trajectories from raw API specifications without human annotation. 2. Establishes a closed-loop system where synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, and the improved model then generates higher-quality data, iteratively targeting capability gaps. 3. Demonstrates state-of-the-art performance, transforming a base 32B model&#x27;s accuracy on the Berkeley Function-Calling Leaderboard from 19.8% to 70.9% using only synthetic data, surpassing much larger models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e1a538efae439be7bacc740036b08c6466db773784245f942d9dee539143f92_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e1a538efae439be7bacc740036b08c6466db773784245f942d9dee539143f92_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of enabling LLMs to reliably use external tools by proposing InfTool, a fully autonomous framework that uses multi-agent role-playing to synthesize and iteratively improve tool-use data in a closed loop. The method eliminates the need for human annotation and significantly boosts model performance, as shown by a 258% accuracy improvement on a standard benchmark, rivaling top proprietary models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Dataset and Benchmark for Consumer Healthcare Question Summarization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text summarization], [consumer health questions, abstractive summarization, dataset creation, benchmark evaluation, domain-expert annotation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abhishek Basu, Deepak Gupta, Dina Demner-Fushman, Shweta Yadav</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois at Chicago, U.S. National Library of Medicine (National Institutes of Health)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23637" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23637</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CHQ-Summ, a new dataset of 1507 domain-expert annotated consumer health questions and summaries. 2. Addresses the lack of domain-expert annotated data for the specific task of consumer healthcare question summarization. 3. Provides a benchmark evaluation of the dataset using multiple state-of-the-art summarization models to demonstrate its utility.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c0dbdf4700510ae2858b673b1f5b293ecd42ac6dcf6f757d42fb65d3706d4b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c0dbdf4700510ae2858b673b1f5b293ecd42ac6dcf6f757d42fb65d3706d4b0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of summarizing verbose consumer health questions by introducing CHQ-Summ, a new expert-annotated dataset. It benchmarks this dataset on modern summarization models to validate its effectiveness for developing better healthcare question understanding systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Nested Browser-Use Learning for Agentic Information Seeking</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [information-seeking agents, browser interaction, ReAct-style agents, nested framework]</p>
</li>
<li class="">
<p><strong>authors:</strong> Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang</p>
</li>
<li class="">
<p><strong>institution:</strong> Tongyi Lab, Alibaba Group</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23647" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23647</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Alibaba-NLP/DeepResearch" target="_blank" rel="noopener noreferrer" class="">https://github.com/Alibaba-NLP/DeepResearch</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a minimal and complete browser-action framework for agents, 2. Introduces a nested structure to decouple interaction control from page exploration, 3. Demonstrates improved performance on deep information-seeking benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the limitation of current information-seeking agents, which rely on simple API calls and cannot perform real browsing. It proposes NestBrowse, a framework that uses a nested structure to enable fine-grained browser control for agents, simplifying reasoning and improving performance on deep search tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Less is more: Probabilistic reduction is best explained by small-scale predictability measures</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [computational psycholinguistics], [probabilistic reduction, n-gram, language model, cognitive planning, articulatory dynamics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cassandra L. Jacobs, Andrés Buxó-Lugo, Anna K. Taylor, Marie Leopold-Hooke</p>
</li>
<li class="">
<p><strong>institution:</strong> University at Buffalo, EURECOM</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23659" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23659</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Demonstrates that local, small-scale predictability measures (n-grams) are sufficient to explain probabilistic reduction in speech, challenging the necessity of large-context LLMs for this cognitive phenomenon. 2. Provides evidence that n-gram representations can serve as effective cognitive units of planning in language production. 3. Argues for the cognitive plausibility and computational efficiency of incremental, phrase-level planning over whole-utterance planning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5de081f03ed5643721a634ff064418b253cb9682ea7ef7e28d08b32112cd4028_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5de081f03ed5643721a634ff064418b253cb9682ea7ef7e28d08b32112cd4028_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how much context is needed to model the relationship between word predictability and articulatory reduction (probabilistic reduction). It finds that local n-gram probabilities are sufficient to explain this effect, suggesting that language production planning operates on a small, incremental scale rather than relying on large-context language models. The main conclusion is that &quot;less is more&quot;—small-scale predictability measures best explain the cognitive phenomenon of probabilistic reduction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [adversarial attacks], [prompt injection, large language models, academic peer review, multilingual, adversarial robustness]</p>
</li>
<li class="">
<p><strong>authors:</strong> Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai.-Doss</p>
</li>
<li class="">
<p><strong>institution:</strong> International School of Athens, Idiap Research Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23684" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23684</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Constructed a dataset of ~500 real ICML papers to empirically evaluate hidden prompt injection attacks in a realistic academic reviewing context. 2. Demonstrated that embedding semantically equivalent adversarial instructions in multiple languages (English, Japanese, Chinese, Arabic) can significantly alter LLM-generated review scores and decisions. 3. Revealed notable cross-lingual differences in attack effectiveness, with Arabic injections having minimal impact compared to others.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6285e0b940378fdc27628286ec6510afd35bf7a004b7ad95ad776e49035c6e1c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6285e0b940378fdc27628286ec6510afd35bf7a004b7ad95ad776e49035c6e1c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the vulnerability of LLM-based academic peer review systems to hidden prompt injection attacks. By injecting adversarial instructions in four languages into a dataset of real papers and having an LLM review them, the authors found that such attacks can substantially change review outcomes for English, Japanese, and Chinese, but not Arabic. The results highlight a critical security risk and language-dependent susceptibility in automated reviewing pipelines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Eliciting Behaviors in Multi-Turn Conversations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [llm evaluation], [behavior elicitation, multi-turn conversation, online methods, dynamic benchmarks, test case generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert</p>
</li>
<li class="">
<p><strong>institution:</strong> Google DeepMind, Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23701</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an analytical framework categorizing behavior elicitation methods into three families based on their interaction with the target model (prior knowledge, offline, online). 2. Introduces a generalized multi-turn formulation for online behavior elicitation methods, unifying single-turn and multi-turn settings. 3. Demonstrates the superior efficiency of online methods in discovering failure cases in multi-turn conversations compared to static benchmarks, advocating for a shift to dynamic evaluation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afe3305263c3b509bdd6e846cce6501d101c0ecedb788ef025ac0c9405a28103_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afe3305263c3b509bdd6e846cce6501d101c0ecedb788ef025ac0c9405a28103_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper studies the problem of efficiently eliciting specific behaviors from large language models in multi-turn conversational settings. It introduces a framework for categorizing existing elicitation methods and proposes a generalized online method for multi-turn interactions. The key finding is that online methods can discover many more failure cases with few queries than static benchmarks, highlighting the need for dynamic evaluation approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [human feedback for alignment], [fine-grained feedback, preference optimization, feedback-driven improvement chains, direct alignment, Lamarckian evolution]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sky CH-Wang, Justin Svegliato, Helen Appel, Jason Eisner</p>
</li>
<li class="">
<p><strong>institution:</strong> Columbia University, Microsoft, Johns Hopkins University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23693" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23693</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel dataset with fine-grained human feedback where annotators mark and explain &quot;liked&quot; and &quot;disliked&quot; spans in model responses. 2. Proposes a method to use this feedback to generate &quot;feedback-driven improvement chains,&quot; where the base model incrementally rewrites disliked spans to create a sequence of improved responses. 3. Demonstrates that constructing preference pairs from adjacent steps in these chains for direct alignment outperforms standard A/B preference ranking or full contrastive rewrites, leading to more efficient and effective preference tuning.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3cdf920bd014e6557ee3cfbe026bd31e5dfb982b5040c20b2797bf29ee9574_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3cdf920bd014e6557ee3cfbe026bd31e5dfb982b5040c20b2797bf29ee9574_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a method for fine-tuning LLMs using fine-grained human feedback on specific text spans. The core idea is to have annotators mark liked/disliked spans, then use the base model to iteratively rewrite the disliked spans, creating a chain of improvements. The key finding is that using these incremental revisions to create preference pairs for direct alignment leads to better model performance than standard preference-based methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Web World Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [world model, language agent, web framework, structured latent state, deterministic generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, Mengdi Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University, University of California, Los Angeles, University of Pennsylvania</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23676" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23676</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://princeton-ai2-lab.github.io/Web-World-Models/" target="_blank" rel="noopener noreferrer" class="">https://princeton-ai2-lab.github.io/Web-World-Models/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced the Web World Model (WWM), a hybrid architecture that uses ordinary web code to enforce logical consistency and LLMs to generate open-ended content. 2. Built a suite of practical WWM demonstrations across diverse domains (travel, fiction, encyclopedia, games) on a realistic web stack. 3. Identified key design principles for WWMs, such as separating code-defined rules from model-driven imagination and representing latent state as typed web interfaces.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed8017bbc1bd6722a0d7bd0f84c67f735c0f1b24747518e2aa15905d07d1b03c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed8017bbc1bd6722a0d7bd0f84c67f735c0f1b24747518e2aa15905d07d1b03c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Web World Models (WWMs), a framework that combines the reliability of web code for world &quot;physics&quot; with the generative power of LLMs for content and narratives. This hybrid approach aims to provide language agents with controllable, logically consistent, yet open-ended persistent environments. The work demonstrates that standard web stacks can serve as a scalable substrate for building such world models.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [speech recognition], [context-conditioned ASR, entity-aware evaluation, professional speech]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deepak Babu Piskala</p>
</li>
<li class="">
<p><strong>institution:</strong> Independent Researcher (affiliation inferred from email domain: gmail.com)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23686" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23686</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/prdeepakbabu/ProfASR-Bench" target="_blank" rel="noopener noreferrer" class="">https://github.com/prdeepakbabu/ProfASR-Bench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces ProfASR-Bench, a benchmark for evaluating context-conditioned ASR in high-stakes professional domains (finance, medicine, legal, technology). 2. Identifies and defines the &quot;context-utilization gap&quot; (CUG), showing current promptable models underuse textual context for improving recognition. 3. Provides a standardized evaluation framework with a context ladder, entity/slice-aware reporting, and a reproducible testbed for comparing fusion strategies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e17670ba26d26dd9fe7f42150241a5910106d394ee058ad7a75c1fc5815bdcd9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e17670ba26d26dd9fe7f42150241a5910106d394ee058ad7a75c1fc5815bdcd9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces ProfASR-Bench, a benchmark for evaluating Automatic Speech Recognition (ASR) in high-stakes professional settings. It tests models like Whisper and Qwen-Omni with various contextual prompts and finds a &quot;context-utilization gap,&quot; where current systems fail to effectively use available side information to improve accuracy, despite being promptable. The benchmark provides tools for entity-aware and slice-wise evaluation to advance context-conditioned ASR.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Training AI Co-Scientists Using Rubric Rewards</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [research plan generation, self-grading, rubric rewards]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse</p>
</li>
<li class="">
<p><strong>institution:</strong> Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23707</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [sentiment analysis], [large language model, moral ethics, content analysis, sentiment classification, Shweder&#x27;s Big Three]</p>
</li>
<li class="">
<p><strong>authors:</strong> Frank Tian-Fang Ye, Xiaozi Gao</p>
</li>
<li class="">
<p><strong>institution:</strong> The HKU SPACE Community College, The University of Hong Kong; Education University of Hong Kong</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23609" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23609</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Applied Shweder&#x27;s Big Three moral ethics framework (Autonomy, Community, Divinity) to analyze public discourse on marriage in China via social media. 2. Demonstrated the utility of LLM-assisted content analysis for scaling qualitative analysis of large-scale social media data. 3. Revealed platform-specific sentiment patterns and associations between moral framing and sentiment, linking negative marriage attitudes to concerns over personal autonomy and communal obligations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7156acf600b8fd25e2938afd6f0f65ccd5503ace7d9b3afb68c9bb152d1a0fee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7156acf600b8fd25e2938afd6f0f65ccd5503ace7d9b3afb68c9bb152d1a0fee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study uses large language models to analyze 219,358 marriage-related posts from Weibo and Xiaohongshu, coding them for sentiment and moral dimensions based on Shweder&#x27;s Big Three framework. It finds platform differences in sentiment and that posts invoking Autonomy and Community ethics are predominantly negative, while Divinity-framed posts are more neutral or positive. The research demonstrates LLMs&#x27; utility for scaling qualitative analysis and provides insights into the moral reasoning behind declining marriage rates in China.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-30T13:08:39.000Z" itemprop="dateModified">Dec 30, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cscl/20251222-20251228"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251222-20251228 (cs.CL)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/cscr"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.CR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-29" class="table-of-contents__link toc-highlight">2025-12-29</a></li><li><a href="#2025-12-30" class="table-of-contents__link toc-highlight">2025-12-30</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/cscl/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>