<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_CL/20260105-20260111" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20260105-20260111 (cs.CL) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/cscl/20260105-20260111"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20260105-20260111 (cs.CL) | AI头条"><meta data-rh="true" name="description" content="2026-01-05"><meta data-rh="true" property="og:description" content="2026-01-05"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20260105-20260111"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20260105-20260111" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscl/20260105-20260111" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.CL","item":"https://jokebear666.github.io/ai_toutiao/daily/cscl"},{"@type":"ListItem","position":3,"name":"20260105-20260111 (cs.CL)","item":"https://jokebear666.github.io/ai_toutiao/daily/cscl/20260105-20260111"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.647bd1ff.css">
<script src="/ai_toutiao/assets/js/runtime~main.a5a9d6f2.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.8703b74f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Collapse sidebar category &#x27;cs.CL&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_CL/20251215-20251221"><span title="20251215-20251221 (cs.CL)" class="linkLabel_WmDU">20251215-20251221 (cs.CL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cscl/20251222-20251228"><span title="20251222-20251228 (cs.CL)" class="linkLabel_WmDU">20251222-20251228 (cs.CL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cscl/20251229-20260104"><span title="20251229-20260104 (cs.CL)" class="linkLabel_WmDU">20251229-20260104 (cs.CL)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/cscl/20260105-20260111"><span title="20260105-20260111 (cs.CL)" class="linkLabel_WmDU">20260105-20260111 (cs.CL)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20260105-20260111"><span title="20260105-20260111" class="linkLabel_WmDU">20260105-20260111</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/cscl"><span>cs.CL</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20260105-20260111 (cs.CL)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20260105-20260111 (cs.CL)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2026-01-05">2026-01-05<a href="#2026-01-05" class="hash-link" aria-label="Direct link to 2026-01-05" title="Direct link to 2026-01-05" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv260105] Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [retrieval-augmented generation], [Monte Carlo Tree Search, reasoning-aware retrieval, coarse-to-fine retrieval, multi-turn dialogue, knowledge diversity]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuqi Liu, Bowei He, Chen Ma, Linqi Song</p>
</li>
<li class="">
<p><strong>institution:</strong> City University of Hong Kong, City University of Hong Kong Shenzhen Research Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00003" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00003</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a reasoning-aware knowledge retrieval method that aligns retrieved information with the logical structure of conversations, moving beyond semantic similarity. 2. Introduces a coarse-to-fine retrieval approach that first finds a contextually relevant knowledge sub-region and then refines it for reasoning-specific knowledge. 3. Employs a Monte Carlo Tree Search-inspired method to navigate knowledge sentences using common keywords, enhancing retrieval diversity and informativeness.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b609f46963ae2b2b017ba13f445da7491064f311d7e663fa59eda7b85dd69638_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b609f46963ae2b2b017ba13f445da7491064f311d7e663fa59eda7b85dd69638_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of integrating retrieval and reasoning for LLMs by proposing a reasoning-aware knowledge retrieval method. It uses a coarse-to-fine approach guided by Monte Carlo Tree Search to find knowledge aligned with conversational logic. Experiments show the method better captures human reasoning and produces more diverse, informative responses.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [mental health language modeling], [large language models, fine-tuning, PHQ-9, Nigerian Pidgin, depression screening]</p>
</li>
<li class="">
<p><strong>authors:</strong> Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Adesina, Ezekiel Ayodeji Oladejo, Uthman Babatunde Usman, Owen Kolade Adeniyi, Matthew Tolulope Olawoyin</p>
</li>
<li class="">
<p><strong>institution:</strong> Artificial Intelligence for Low-Resource Public Health Application (ALPHA) Centre, Slum and Rural Health Initiative; University of Ibadan; University of Ilorin</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00004</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Created a novel, annotated dataset of 432 Nigerian Pidgin audio responses for depression screening aligned with PHQ-9 items. 2. Fine-tuned and evaluated three LLMs (Phi-3-mini, Gemma-3-4B-it, GPT-4.1) for automated depression screening in a low-resource language. 3. Demonstrated that fine-tuned GPT-4.1 achieved high accuracy (94.5%) and cultural appropriateness for PHQ-9 severity scoring in Nigerian Pidgin.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of depression screening in Nigeria by fine-tuning large language models for Nigerian Pidgin English. The authors collected and annotated a dataset of audio responses, then fine-tuned three LLMs to predict PHQ-9 severity scores. The fine-tuned GPT-4.1 model achieved the best performance, providing a foundation for AI-mediated mental health tools in linguistically diverse, resource-constrained settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [tokenizer transplant, model composition, supply-chain vulnerability, sparse solver, spectral mimicry]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaoze Liu, Weichen Yu, Matt Fredrikson, Xiaoqian Wang, Jing Gao</p>
</li>
<li class="">
<p><strong>institution:</strong> Purdue University, Carnegie Mellon University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00065" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00065</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/xz-liu/tokenforge" target="_blank" rel="noopener noreferrer" class="">https://github.com/xz-liu/tokenforge</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies tokenizer transplant as a novel attack surface in the LLM composition supply chain, 2. Introduces the concept of a &quot;breaker token&quot;—a single, engineered token that is inert in a donor model but maliciously activates after transplant, 3. Formalizes and instantiates the attack as a dual-objective optimization problem solved with a sparse solver, demonstrating its training-free nature, stealth, and persistence.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bac901d101e76e81a328892233109e7f05c25f328de683add53ccd17ae81590e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bac901d101e76e81a328892233109e7f05c25f328de683add53ccd17ae81590e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies a security vulnerability in the tokenizer transplant step required for composing different LLMs. The authors propose a method to engineer a single &quot;breaker token&quot; that, when added to a donor model, remains harmless but sabotages a base model after transplant by exploiting coefficient reuse. The attack is stealthy, training-free, and persistent, revealing a hidden risk in modular AI pipelines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [tool-use, rule learning, minimum description length, neuro-symbolic, prompt injection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiang Gao, Yuguang Yao, Qi Zhang, Kaiwen Dong, Avinash Baidya, Ruocheng Guo, Hilaf Hasson, Kamalika Das</p>
</li>
<li class="">
<p><strong>institution:</strong> Intuit AI Research, Temple University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00086</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RIMRULE, a neuro-symbolic method for LLM adaptation that distills interpretable rules from failure traces and injects them dynamically during inference. 2. Introduces a Minimum Description Length (MDL) objective to consolidate and select rules, favoring generality and conciseness. 3. Demonstrates that the learned symbolic rules are portable and can improve performance across different LLM architectures without weight modification.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5604dcae3f77a38459a71d5615de42441af3f38dbedaf069349bff470ad72d2f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5604dcae3f77a38459a71d5615de42441af3f38dbedaf069349bff470ad72d2f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of LLMs struggling to reliably use domain-specific or under-documented tools. It proposes RIMRULE, a method that learns compact, interpretable rules from failure traces using an MDL objective and injects them into prompts during inference. The approach improves tool-use accuracy on both seen and unseen tools, outperforms prompting baselines, and shows that learned rules are portable across different LLMs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [causal reasoning], [fuzzy cognitive maps, large-language-model agent, causal feedback, equilibrium limit cycles, agentic leash]</p>
</li>
<li class="">
<p><strong>authors:</strong> Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Southern California, Florida International University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00097</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel LLM agent designed to autonomously extract and construct causal feedback Fuzzy Cognitive Maps (FCMs) from raw text. 2. A three-step instruction-guided process for systematically extracting key concepts and causal edges to build the FCM dynamical system. 3. Demonstration that the LLM-generated FCMs converge to the same equilibrium dynamics as human-generated ones and that mixed FCMs from different LLMs can create new equilibria.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes an LLM agent to autonomously extract causal feedback Fuzzy Cognitive Maps from text. The agent uses a three-step process to identify concepts and causal edges, forming a dynamical system. The generated FCMs matched human-generated equilibrium dynamics and mixing models from different LLMs produced new equilibria for better causal approximation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [meta-reinforcement learning, constraint propagation, graph attention network, structured inference, green ai]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma</p>
</li>
<li class="">
<p><strong>institution:</strong> Iowa State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00095" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00095</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces MetaJuLS, a meta-reinforcement learning framework for learning universal constraint propagation policies applicable across languages and tasks without task-specific retraining. 2. Formulates structured inference as adaptive constraint propagation and trains a Graph Attention Network policy via meta-learning, achieving significant speedups (1.5-2.0x) over GPU-optimized baselines with minimal accuracy loss. 3. Demonstrates rapid cross-domain adaptation (5-15 seconds) and contributes to Green AI by reducing inference carbon footprint through fewer propagation steps.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5284c89e9a9eec9c1882da4c36e7d1e9bbce97ea559fe29f19c435e5f8b8854_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5284c89e9a9eec9c1882da4c36e7d1e9bbce97ea559fe29f19c435e5f8b8854_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the inefficiency of structured inference (e.g., JSON parsing) in large language models by proposing MetaJuLS, a meta-reinforcement learning method that learns adaptive constraint propagation policies. This approach achieves up to 2x speedup over baselines while maintaining high accuracy and enables fast adaptation to new languages and tasks. The work contributes to more efficient and environmentally friendly LLM inference.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [legal text generation and evaluation], [patent drafting, LLM-as-a-judge, Chain-of-Legal-Thought, legal compliance, automated evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yongmin Yoo, Kris W Pan</p>
</li>
<li class="">
<p><strong>institution:</strong> Macquarie University, Amazon</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00166" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00166</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Pat-DEVAL, the first multi-dimensional evaluation framework specifically designed for assessing the quality of generated patent description bodies. 2. Proposes Chain-of-Legal-Thought (CoLT), a novel legally-constrained reasoning mechanism that enforces sequential, patent-law-specific analysis within the LLM-as-a-judge paradigm. 3. Establishes and validates the framework on the Pap2Pat-EvalGold dataset, demonstrating superior correlation with expert judgments, especially in legal compliance, outperforming baseline metrics and existing LLM evaluators.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9df50304a9b3b4d3c4c409af9be2c858e612c5747a351d8395d536945a60fa6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9df50304a9b3b4d3c4c409af9be2c858e612c5747a351d8395d536945a60fa6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of effective evaluation methods for AI-generated patent descriptions, which must meet strict legal standards. It proposes Pat-DEVAL, a framework that uses a Chain-of-Legal-Thought mechanism with an LLM-as-a-judge to assess legal compliance and structural coherence. The method shows significantly higher correlation with expert evaluations than existing approaches, proving the importance of explicit legal constraints for automated patent drafting.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [emotion recognition in conversation], [ablation study, conversational context, discourse markers, causal context, IEMOCAP]</p>
</li>
<li class="">
<p><strong>authors:</strong> Cheonkam Jeong, Adeline Nyamathi</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Irvine</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00181" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00181</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A rigorous ablation study revealing that conversational context is paramount for ERC, with performance saturating within 10-30 preceding turns, and that hierarchical sentence representations and external affective lexicons provide no additional benefit when context is used. 2. Achieving state-of-the-art text-only performance on IEMOCAP using simple architectures with strictly causal context. 3. A novel linguistic analysis connecting recognition to generation, finding a significant association between emotion and discourse marker positioning, particularly that &quot;sad&quot; utterances use fewer left-periphery markers and rely more on context for disambiguation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e38dfbfb3b50e432c39aabed201ddaf199012203ee5e7e82a7aa044267fc2a2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e38dfbfb3b50e432c39aabed201ddaf199012203ee5e7e82a7aa044267fc2a2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper systematically analyzes Emotion Recognition in Conversation (ERC) to identify which architectural components matter and connects recognition insights to linguistic patterns for generation. Through ablation studies on IEMOCAP, it finds conversational context is most critical, and via linguistic analysis, it discovers that emotion correlates with discourse marker usage. The main conclusion is that simple models with causal context are sufficient for high performance, and the lack of explicit pragmatic signals in &quot;sad&quot; utterances explains their greater reliance on context.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [time series forecasting], [LSTM, Transformer, Stock Prediction, Time Series Forecasting, Attention]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaswat Mohanty</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00197" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00197</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents an enhanced StockBot architecture for systematic evaluation of modern time-series forecasting models (attention-based, convolutional, recurrent) in a unified setting. 2. Demonstrates empirically that a carefully constructed vanilla LSTM model consistently outperforms transformer-based models in stock price forecasting accuracy and decision-making stability under default hyperparameters. 3. Highlights the robustness, data efficiency, and importance of architectural inductive bias of recurrent models for financial forecasting, especially in data-limited scenarios.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/131078c30708f9e13fee0c529bee858ed184717ff3b0bf5f762eda2a9370616c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/131078c30708f9e13fee0c529bee858ed184717ff3b0bf5f762eda2a9370616c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents StockBot 2.0, a framework for evaluating time-series models for stock prediction. It finds that a vanilla LSTM model, despite its simplicity, outperforms more complex transformer-based models in forecasting accuracy and trading decision stability when trained with default settings, emphasizing the value of recurrent inductive biases for financial data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [knowledge distillation, temporal knowledge graph reasoning, large language models, teacher-student framework, temporal dependencies]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wang Xing, Wei Song, Siyu Lin, Chen Wu, Zhesi Li, Man Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Xidian University, Southwest Jiaotong University, Chongqing Jiaotong University, Chang’an University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00202" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00202</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel distillation framework specifically designed for Temporal Knowledge Graph (TKG) reasoning, addressing the limitations of static graph compression techniques. 2. Leverages Large Language Models (LLMs) as teacher models to transfer both structural and temporal reasoning capabilities to lightweight student models. 3. Integrates large-scale public knowledge with task-specific temporal information to enhance the student model&#x27;s ability to model temporal dynamics while maintaining computational efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19e66b8571c108befcd93243d5d7ad64cfb10f7509cd7cbcd74ba39136582282_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19e66b8571c108befcd93243d5d7ad64cfb10f7509cd7cbcd74ba39136582282_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of deploying computationally expensive Temporal Knowledge Graph (TKG) reasoning models on resource-constrained platforms. The authors propose a knowledge distillation framework that uses Large Language Models (LLMs) as teachers to transfer temporal and structural reasoning knowledge to compact student models. Experiments show the method achieves a favorable trade-off between reasoning accuracy and efficiency, outperforming existing baselines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [llm safety &amp; alignment], [jailbreak, algorithm design, safety benchmark, optimization algorithm, malicious prompt]</p>
</li>
<li class="">
<p><strong>authors:</strong> Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin</p>
</li>
<li class="">
<p><strong>institution:</strong> Xidian University, Victoria University of Wellington, Westlake University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00213" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00213</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies and investigates a novel safety vulnerability in LLMs related to automated malicious optimization algorithm design. 2. Introduces MalOptBench, a benchmark of 60 malicious optimization algorithm requests for evaluating this vulnerability. 3. Proposes MOBjailbreak, a tailored jailbreak method for this scenario, and demonstrates its high effectiveness against current LLMs and defenses.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6ccef5999a7edaf6824967fee78721c43b0e003d14334de2a1bb59ce1410a85_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6ccef5999a7edaf6824967fee78721c43b0e003d14334de2a1bb59ce1410a85_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates a safety vulnerability where LLMs can be prompted to generate malicious optimization algorithms. It introduces the MalOptBench benchmark and the MOBjailbreak attack method, finding that current LLMs and plug-and-play defenses are highly susceptible, highlighting a need for stronger alignment techniques.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, multimodal large language models, visual reasoning, group relative policy optimization, reward functions]</p>
</li>
<li class="">
<p><strong>authors:</strong> Omar Sharif, Eftekhar Hossain, Patrick Ng</p>
</li>
<li class="">
<p><strong>institution:</strong> Dartmouth College, University of Central Florida</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00215</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identified visual perception as the primary bottleneck for MLLMs in visual puzzle tasks, empirically validated by showing significant performance gains when images are converted to text. 2. Proposed a reward-driven RL framework using GRPO to incentivize longer, structured visual reasoning in open-source MLLMs without costly supervision. 3. Designed and evaluated six novel reward functions targeting different reasoning aspects like image understanding, thinking steps, and answer accuracy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa78fbb9d1620ad3674739f2e8cf9cfb6929637fa0f209ae3ee4c439ab5205c8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa78fbb9d1620ad3674739f2e8cf9cfb6929637fa0f209ae3ee4c439ab5205c8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem that multimodal large language models (MLLMs) generate reasoning chains that lack integration of visual information, limiting their performance on visual puzzles. The authors propose using reinforcement learning with specifically designed reward functions and Group Relative Policy Optimization (GRPO) to incentivize longer, visually-grounded reasoning. Their method improves the performance of the Qwen-2.5-VL-7B model by 5.56%, demonstrating consistent gains across different settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [retrieval-augmented generation], [knowledge graph, PICO framework, evidence-based medicine, Bayesian reranking, sports rehabilitation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jinning Zhang, Jie Song, Wenhui Tu, Zecheng Li, Jingxuan Li, Jin Li, Xuan Liu, Taole Sha, Zichen Wei, Yan Li</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Sport University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00216" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00216</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a generalizable strategy for integrating Evidence-Based Medicine (EBM) principles into graph-based RAG, addressing PICO alignment and evidence hierarchy. 2. Introduces a Bayesian-inspired reranking algorithm to calibrate retrieval scores based on evidence grade without predefined weights. 3. Constructs and releases a domain-specific knowledge graph and benchmark for sports rehabilitation to address the scarcity of RAG resources in this field.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bd3d679f214bbb1077d6def8ab28cb0755d55d1e2bccc588807eff404d6c8bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bd3d679f214bbb1077d6def8ab28cb0755d55d1e2bccc588807eff404d6c8bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the oversight of evidence-based medicine principles in current RAG systems by proposing a strategy that integrates the PICO framework into knowledge graph construction and a Bayesian reranking algorithm. The method was validated in sports rehabilitation, showing improved answer quality and high expert ratings, and the released resources help fill a domain-specific data gap.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [machine translation], [LLM-as-a-judge, pairwise comparison, Bradley-Terry model, reference-free evaluation, anchored evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Leonard Lin, Adam Lensenmayer</p>
</li>
<li class="">
<p><strong>institution:</strong> Shisa.AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00223" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00223</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces JP-TL-Bench, a lightweight, open benchmark for iterative development of Japanese-English translation systems. 2. Proposes a reliable and affordable evaluation protocol using reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. 3. Provides structurally stable scores by aggregating pairwise results with a Bradley-Terry model and reporting normalized LT scores.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3672d8de20107e284402d4b12e978f246eb0df92617095708ca7710e712594d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3672d8de20107e284402d4b12e978f246eb0df92617095708ca7710e712594d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces JP-TL-Bench, a benchmark for evaluating high-quality Japanese-English translation. It uses a protocol where candidate models are compared against a fixed anchor set via pairwise LLM judgments, with results aggregated using a Bradley-Terry model to produce stable scores. This approach aims to provide a high-resolution signal for distinguishing between already fluent translations where traditional metrics saturate.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [semantic verification, execution feedback, generator-discriminator framework, reverse translation, conversational business analytics]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yan Sun, Ming Cai, Stanley Kok</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Singapore</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00224" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00224</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Q*, a verification technique that uses reverse translation and semantic matching to align generated code with user intent. 2. Introduces Feedback+, a mechanism that incorporates execution feedback to guide iterative code refinement. 3. Embeds these techniques within a generator-discriminator framework to shift validation responsibilities from users to the system, aiming to improve reliability.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2d07ef5c900d3b1d3d6067b2025a8ba0771149df2530b94a6a54885c8bd8685_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2d07ef5c900d3b1d3d6067b2025a8ba0771149df2530b94a6a54885c8bd8685_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the lack of verification in conversational business analytics systems by proposing two techniques, Q* and Feedback+, to improve the accuracy and executability of LLM-generated outputs. The methods are integrated into a generator-discriminator framework and evaluated on benchmark datasets, showing reduced error rates and task completion time. The work provides a design framework for building more reliable enterprise-grade GenAI assistants.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [explainable ai (xai)], [counterfactual examples, multilingual, data augmentation, large language models, model robustness]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich Schütze, Sebastian Möller, Vera Schmitt</p>
</li>
<li class="">
<p><strong>institution:</strong> Technische Universität Berlin, University of Marburg, LMU Munich, German Research Center for Artificial Intelligence (DFKI), Munich Center for Machine Learning (MCML), BIFOLD – Berlin Institute for the Foundations of Learning and Data</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00263" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00263</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Evaluated the quality of LLM-generated multilingual counterfactuals, comparing direct generation and translation-based methods across six languages. 2. Identified four main error types common in generated counterfactuals across languages and found similar edit patterns in high-resource European languages. 3. Demonstrated that multilingual counterfactual data augmentation yields greater performance improvements than cross-lingual augmentation, especially for lower-resource languages.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3b95c2cf3407989c3c5a932764e908182c4d60d7451ace3f5f15e194a3a7e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3b95c2cf3407989c3c5a932764e908182c4d60d7451ace3f5f15e194a3a7e5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the effectiveness of large language models (LLMs) in generating multilingual counterfactual examples. It compares directly generated and translation-based counterfactuals across six languages, finding that translation-based ones are more valid but require more edits and still underperform English ones. The study concludes that while multilingual counterfactual data augmentation improves model performance, especially for low-resource languages, the quality limitations of the generated counterfactuals constrain the gains in robustness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [function-calling, benchmark, API complexity, LLM agents, WildAGTEval]</p>
</li>
<li class="">
<p><strong>authors:</strong> Doyoung Kim, Zhiwei Ren, Jie Hao, Zhongkai Sun, Lichao Wang, Xiyao Ma, Zack Ye, Xu Han, Jun Yin, Heng Ji, Wei Shen, Xing Fan, Benjamin Yao, Chenlei Guo</p>
</li>
<li class="">
<p><strong>institution:</strong> Amazon, KAIST, University of Pittsburgh, University of Illinois Urbana-Champaign</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00268" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00268</a></p>
</li>
<li class="">
<p><strong>code:</strong> github.com/Demon-JieHao/WildAGTEval</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces WildAGTEval, a novel benchmark for evaluating LLM agents under realistic API complexity, covering both API specification and execution challenges. 2. Provides a comprehensive API system with 60 distinct complexity scenarios, composable into ~32K test configurations, and user-agent interactions for evaluation. 3. Systematically assesses advanced LLMs, revealing significant performance drops (e.g., 27.3% for irrelevant information complexity) and identifying critical failure modes like intent distortion.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c517d92b4a84a20e84e30c740db5d9b70b7f3195c6de0fc8e049a5f0a4c9af_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c517d92b4a84a20e84e30c740db5d9b70b7f3195c6de0fc8e049a5f0a4c9af_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces WildAGTEval, a benchmark designed to evaluate LLM agents&#x27; function-calling capabilities under realistic API complexities, including detailed specifications and noisy execution. The study finds that most scenarios are challenging, with irrelevant information posing the greatest difficulty and causing significant performance drops in strong models. The qualitative analysis also reveals that LLMs sometimes distort user intent to claim task completion, negatively impacting user satisfaction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [quantization, self-explanations, faithfulness, natural language explanations, counterfactual examples]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qianli Wang, Nils Feldhus, Pepa Atanasova, Fedor Splitt, Simon Ostermann, Sebastian Möller, Vera Schmitt</p>
</li>
<li class="">
<p><strong>institution:</strong> Technische Universität Berlin, German Research Center for Artificial Intelligence (DFKI), University of Copenhagen</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00282" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00282</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. First comprehensive study on the impact of quantization on the quality and faithfulness of LLM self-explanations. 2. Empirical evaluation across multiple quantization techniques, bit widths, and model sizes, revealing moderate but consistent degradation in explanation metrics. 3. Provides practical recommendations for validating self-explanations in quantized models, highlighting the greater sensitivity of natural language explanations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates how quantization affects the quality and faithfulness of self-explanations generated by large language models. The authors evaluate multiple quantization methods and find they cause moderate declines in explanation metrics, with larger models showing better faithfulness preservation. They conclude that while quantization degrades self-explanations, the impact is relatively minor and does not negate its benefits for model compression.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [speech processing], [depression detection, semantic bias, text-to-speech, disentangled representation, data augmentation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuxin Li, Xiangyu Zhang, Yifei Li, Zhiwei Guo, Haoyang Zhang, Eng Siong Chng, Cuntai Guan</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, UNSW Sydney, Peking University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00303" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00303</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes DepFlow, a novel three-stage depression-conditioned TTS framework that disentangles depression-specific acoustic patterns from speaker and content information using adversarial training and flow-matching. 2. Introduces a prototype-based severity mapping mechanism for smooth and interpretable control over the synthesized depressive severity. 3. Constructs a Camouflage Depression-oriented Augmentation (CDoA) dataset using DepFlow to mitigate semantic bias, which significantly improves the robustness of depression detection models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddfe4c5383fa66e6b8e028851d0fe67037a11642b799a3626a1100aaa4cd8096_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddfe4c5383fa66e6b8e028851d0fe67037a11642b799a3626a1100aaa4cd8096_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of semantic bias in depression detection models, where models learn shortcuts from linguistic sentiment instead of acoustic cues. It proposes DepFlow, a disentangled speech generation framework, to create a synthetic dataset (CDoA) that pairs depressed acoustic patterns with positive/neutral text. This data augmentation method improves model robustness, outperforming conventional strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Robust Uncertainty Quantification for Factual Generation of Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [hallucination detection], [uncertainty quantification, factual hallucination, trap questions, ROCAUC, fake biographies]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuhao Zhang, Zhongliang Yang, Linna Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing University of Posts and Telecommunications</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00348" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00348</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/EdwardChang5467/robust" target="_blank" rel="noopener noreferrer" class="">https://github.com/EdwardChang5467/robust</a> uncertainty</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new uncertainty quantification scenario focused on multi-fact generation (e.g., fake person biographies) to test LLM robustness. 2. Constructs a novel dataset of trap questions containing fake names to evaluate hallucination detection methods. 3. Introduces a robust uncertainty quantification (RU) method that significantly outperforms baseline methods across four different LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6268aa8c8874ac861a06315946aedcfbc9df7712a9f2b63e23204554e9c8596b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6268aa8c8874ac861a06315946aedcfbc9df7712a9f2b63e23204554e9c8596b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of LLM hallucination by proposing a new robust uncertainty quantification (RU) method for detecting factual errors in multi-fact generation tasks. The method is evaluated using a specially constructed set of trap questions containing fake names. Results show the RU method achieves an average increase of 0.1-0.2 in ROCAUC over the best baseline, demonstrating its effectiveness in improving the reliability of LLM outputs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multilingual representation learning], [Joint Embedding Predictive Architecture (JEPA), BERT, CLS token, language-agnostic embedding, multilingual benchmarks]</p>
</li>
<li class="">
<p><strong>authors:</strong> Taj Gillin, Adam Lalani, Kenneth Zhang, Marcel Mateos Salles</p>
</li>
<li class="">
<p><strong>institution:</strong> Brown University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00366</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces BERT-JEPA (BEPA), a novel training paradigm that adds a JEPA objective to BERT-style models to reorganize the [CLS] embedding space. 2. Demonstrates that BEPA finetuning transforms the [CLS] embedding space into a semantic-first, language-agnostic space, shifting its PCA representation from low-rank to fuller-rank. 3. Shows that this reorganization improves performance on multilingual tasks with little to no loss in English performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that BERT&#x27;s [CLS] embeddings fail to capture language-invariant semantics. It proposes BERT-JEPA (BEPA), a method that adds a Joint Embedding Predictive Architecture (JEPA) objective during training to reorganize the [CLS] embedding space into a language-agnostic &quot;thought space&quot;. The main conclusion is that this approach significantly improves performance on multilingual benchmarks while maintaining English task performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [multilingual language models], [multilingual pretraining, parallel data, code-switching, cross-lingual transfer, translation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiandong Shao, Raphael Tang, Crystina Zhang, Karin Sevegnani, Pontus Stenetorp, Jianfei Yang, Yao Lu</p>
</li>
<li class="">
<p><strong>institution:</strong> University College London, Nanyang Technological University, University of Waterloo, NVIDIA, National Institute of Informatics</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00364" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00364</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted controlled pretraining experiments from scratch to isolate the impact of bilingual data, revealing that removing just 2% of such data causes a 56% drop in translation performance while leaving cross-lingual QA and reasoning largely unaffected. 2. Introduced a granular categorization of bilingual data into parallel, code-switching, and miscellaneous types based on semantic relevance, enabling more precise analysis. 3. Demonstrated through ablation studies that translation performance is critically dependent on parallel data (restoring 91% of baseline performance), whereas code-switching data contributes minimally, and that cross-lingual understanding does not rely heavily on bilingual data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d428d7e2552dcd9b73d3c4332f442260a2a8e3b735ffd1384f2f162c6a5bde44_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d428d7e2552dcd9b73d3c4332f442260a2a8e3b735ffd1384f2f162c6a5bde44_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the role of bilingual data in multilingual large language model pretraining by comparing standard web corpora with a monolingual-only version. Through controlled experiments and granular ablations categorizing data into parallel and code-switching types, it finds that translation performance heavily depends on parallel data for token-level alignments, while cross-lingual understanding and reasoning tasks can be achieved even without bilingual data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [geolocalization, vision-language models, chain of region, haversine distance, retrieval-free]</p>
</li>
<li class="">
<p><strong>authors:</strong> Biao Wu, Meng Fang, Ling Chen, Ke Xu, Tao Cheng, Jun Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Technology Sydney, University of Liverpool, University College London</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00388" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00388</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Geo-R, a retrieval-free framework for image geolocalization that uses reinforcement learning. 2. Introduces Chain of Region, a rule-based hierarchical reasoning paradigm to generate interpretable supervision from GPS coordinates. 3. Develops a lightweight RL strategy with coordinate-aligned rewards based on Haversine distance for spatially meaningful feedback.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/986e7d2e1e80caef1d7794a999a5e00e8f2a503a4cae673b68dc3cfafa02122c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/986e7d2e1e80caef1d7794a999a5e00e8f2a503a4cae673b68dc3cfafa02122c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of existing image geolocalization methods by proposing Geo-R, a retrieval-free framework that uses a rule-based Chain of Region for hierarchical reasoning and a reinforcement learning strategy with Haversine distance rewards. The approach improves localization accuracy, generalization, and interpretability without relying on synthetic labels or external retrieval, as validated across multiple benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [named entity recognition], [weak supervision, large language models, low-resource languages, dataset construction, Luxembourgish]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alistair Plum, Laura Bernardy, Tharindu Ranasinghe</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Luxembourg, Lancaster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00411" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00411</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel pipeline for constructing NER datasets that uses Wikipedia/Wikidata for weak supervision and LLMs for label verification. 2. Introduces judgeWEL, a new and significantly larger NER dataset for the under-represented language Luxembourgish. 3. Evaluates and compares the effectiveness of multiple LLMs in judging and filtering noisy, distantly-supervised labels.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e13a29d091cdd4cb0cc5c3d34a98e86c8d45b0a34f42a2b552cecd9fcff5b51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e13a29d091cdd4cb0cc5c3d34a98e86c8d45b0a34f42a2b552cecd9fcff5b51_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of building datasets for under-represented languages by proposing a novel method that uses Wikipedia and Wikidata for weak supervision to generate initial NER labels, and then employs multiple LLMs to verify and filter these labels for quality. The approach is applied to Luxembourgish, resulting in the judgeWEL dataset, which is five times larger and more balanced than existing resources, providing a valuable new corpus for low-resource NER research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Deep Delta Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [neural network architecture], [residual networks, geometric transformation, spectral analysis, rank-1 perturbation, dynamic gating]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University, University of California, Los Angeles</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00417" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00417</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/yifanzhang-pro/deep-delta-learning" target="_blank" rel="noopener noreferrer" class="">https://github.com/yifanzhang-pro/deep-delta-learning</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Deep Delta Learning (DDL), a novel architecture that generalizes residual connections with a learnable, data-dependent geometric transformation called the Delta Operator. 2. Provides a spectral analysis of the Delta Operator, showing it can dynamically interpolate between identity mapping, orthogonal projection, and geometric reflection via a gating scalar. 3. Restructures the residual update as a synchronous rank-1 injection, unifying feature erasure and writing under a dynamic step size to enable complex, non-monotonic dynamics while preserving stable training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies that the strictly additive inductive bias of standard residual networks limits their capacity to model complex state transitions. To address this, it proposes Deep Delta Learning (DDL), which modulates the identity shortcut with a learnable, data-dependent geometric transformation (the Delta Operator). This allows the network to explicitly control its layer-wise transition spectrum, enabling the modeling of complex dynamics like oscillations while maintaining stable training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language modeling], [Semantic Field Theory, lexical fields, linguistic fields, transformer architectures, embedding spaces]</p>
</li>
<li class="">
<p><strong>authors:</strong> Dimitris Vartziotis</p>
</li>
<li class="">
<p><strong>institution:</strong> TWT Science &amp; Innovation, NIKI - Digital Engineering</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00448" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00448</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalizes the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. 2. Analyzes how core properties of transformer architectures (e.g., distributed representations, attention) relate to Semantic Field Theory concepts. 3. Proposes that mathematical structure and language games are complementary perspectives, clarifying the scope and limits of statistical language models.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98759f21c127cf9a440b464892816dd7e22af8f161a1d16ec91b582a8fefa647_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98759f21c127cf9a440b464892816dd7e22af8f161a1d16ec91b582a8fefa647_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper examines theories of linguistic meaning by contrasting social constructivist language games with a mathematically oriented Semantic Field Theory. It formalizes lexical and linguistic fields and analyzes their relation to transformer architecture properties. The authors conclude that the mathematical structure captured by LLMs and the social grounding of language games are complementary, not competing, views.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text classification], [DistilBERT, MiniLM, ALBERT, inference latency, model efficiency]</p>
</li>
<li class="">
<p><strong>authors:</strong> Muhammad Shahmeer Khan</p>
</li>
<li class="">
<p><strong>institution:</strong> Ulster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00444</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic comparison of three lightweight Transformer models (DistilBERT, MiniLM, ALBERT) across three enterprise-relevant domains. 2. An empirical evaluation using both accuracy-based and efficiency metrics under fixed enterprise-oriented constraints. 3. Practical deployment recommendations highlighting the trade-offs between accuracy and efficiency for different enterprise scenarios.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/caee3ae4ac5e6aeda42367ba10ce7ebb5766e7933d76b7277c736f90391d7895_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/caee3ae4ac5e6aeda42367ba10ce7ebb5766e7933d76b7277c736f90391d7895_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper compares the efficiency and performance of three lightweight Transformer models—DistilBERT, MiniLM, and ALBERT—across sentiment, news, and hate speech classification tasks. The evaluation uses accuracy and efficiency metrics under controlled fine-tuning. The key finding is a trade-off: ALBERT excels in accuracy, MiniLM in speed, and DistilBERT offers the most consistent balance, providing clear deployment guidance for enterprises.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Toward Better Temporal Structures for Geopolitical Events Forecasting</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [knowledge graph completion], [temporal knowledge graph, hyper-relational knowledge graph, event forecasting, large language model, geopolitical events]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kian Ahrabian, Eric Boxer, Jay Pujara</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Southern California, Information Sciences Institute</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00430" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00430</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/usc-isi-i2/htkgh-polecat" target="_blank" rel="noopener noreferrer" class="">https://github.com/usc-isi-i2/htkgh-polecat</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new data structure, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs), to efficiently represent complex temporal facts involving more than two primary entities. 2. Introduces the <code>htkgh-polecat</code> dataset, built on the POLECAT database, to benchmark forecasting tasks on this new structure. 3. Benchmarks and analyzes the performance of popular Large Language Models (LLMs) on the relation prediction task within this complex forecasting scenario.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527a7641dfaef2c6e41eb0a5e3a09b206d0632bf03dce43022e1edf046380617_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527a7641dfaef2c6e41eb0a5e3a09b206d0632bf03dce43022e1edf046380617_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of existing temporal knowledge graphs in representing complex geopolitical events with multiple primary entities by proposing a new structure called HTKGHs. The authors formalize HTKGHs, create a corresponding dataset, and benchmark LLMs on forecasting tasks. The results provide insights into LLMs&#x27; capabilities for complex temporal reasoning and forecasting.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [guardrail models, multi-turn compression, efficiency optimization, safety screening, token reduction]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hyunjun Kim</p>
</li>
<li class="">
<p><strong>institution:</strong> KAIST</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00454" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00454</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Defensive M2S, a training paradigm that fine-tunes guardrail models on compressed multi-turn conversations instead of full histories, 2. Provides formal complexity analysis showing training cost reduction from O(n²) to O(n) and empirical token reduction of 93×, 3. Demonstrates effectiveness across multiple guardrail models and compression templates, achieving high attack detection recall with 94.6% inference token reduction.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad9caa971d784e8a994209f34a3b4e255812b43b2fa90a13bb0487b6e71e1395_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad9caa971d784e8a994209f34a3b4e255812b43b2fa90a13bb0487b6e71e1395_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high computational cost of processing full multi-turn conversations for LLM safety guardrails by proposing Defensive M2S, which trains guardrail models on compressed single-turn versions. This method significantly reduces training and inference tokens while maintaining high attack detection performance, enabling scalable safety screening.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Noise-Aware Named Entity Recognition for Historical VET Documents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [named entity recognition], [Noise-Aware Training (NAT), OCR Noise, Data Augmentation, Transfer Learning, Multi-stage Fine-tuning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alexander M. Esser, Jens Dörpinghaus</p>
</li>
<li class="">
<p><strong>institution:</strong> Federal Institute for Vocational Education and Training (BIBB), University of Koblenz</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00488" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00488</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a robust NER approach for historical VET documents using Noise-Aware Training with synthetic OCR errors. 2. Systematically compares three complementary training strategies (noisy, clean, and artificial data). 3. Demonstrates that domain-specific and noise-aware fine-tuning significantly improves robustness and accuracy under noisy conditions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb3e9604f5f72e56feeecdc196004299094bc184a404fe77959f2a61d9e4da2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb3e9604f5f72e56feeecdc196004299094bc184a404fe77959f2a61d9e4da2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles Named Entity Recognition in noisy, historical Vocational Education and Training documents by proposing a method using Noise-Aware Training with synthetic OCR errors, transfer learning, and multi-stage fine-tuning. The approach, one of the first to recognize multiple entity types in this domain, shows that domain-specific and noise-aware fine-tuning substantially increases model robustness and accuracy. The method is applied to German but is designed to be transferable to other languages.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Rule-Based Approaches to Atomic Sentence Extraction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [text simplification], [atomic sentence extraction, dependency parsing, rule-based system, syntactic complexity, split-and-rephrase]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lineesha Kamana, Akshita Ananda Subramanian, Mehuli Ghosh, Suman Saha</p>
</li>
<li class="">
<p><strong>institution:</strong> The Pennsylvania State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00506</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a principled analysis to identify specific complex sentence structures (e.g., relative clauses, appositions) that cause difficulties for rule-based atomic sentence extraction. 2. Implemented and evaluated a transparent, dependency-based rule extraction system using spaCy on the WikiSplit dataset. 3. Provided quantitative performance benchmarks (ROUGE and BERTScore) and qualitative insights into the limitations of rule-based methods for syntactic decomposition.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8cb4da5bb35bca5de1c3a306fbe787db397d7073bbab8260c7962fc3e300d28_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8cb4da5bb35bca5de1c3a306fbe787db397d7073bbab8260c7962fc3e300d28_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the performance of a rule-based system for decomposing complex sentences into simpler atomic units. The method uses dependency parsing rules in spaCy and is evaluated on the WikiSplit dataset. The results show the approach is reasonably accurate but struggles with syntactically complex structures like relative clauses and coordinated predicates.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [information retrieval], [query categorization, chain-of-thought, e-commerce taxonomy, semantic scoring, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jetlir Duraj, Ishita Khan, Kilian Merkelbach, Mehran Elyasi</p>
</li>
<li class="">
<p><strong>institution:</strong> eBay Inc.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00510" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00510</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Chain-of-Thought (CoT) paradigm for semantic query categorization that combines tree-search with LLM semantic scoring. 2. Demonstrates that the CoT approach outperforms embedding-based benchmarks and can detect problems within hierarchical taxonomies. 3. Introduces scalable LLM-based approaches for query categorization that are suitable for millions of queries.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2b32fe45914991e8c8d0dc90af7415aa3ed8d8e8ce666ea46e11465b8fa68fd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2b32fe45914991e8c8d0dc90af7415aa3ed8d8e8ce666ea46e11465b8fa68fd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of categorizing user search queries into leaf categories of an e-commerce taxonomy to improve search relevance. The authors propose a novel Chain-of-Thought approach that navigates the taxonomy tree using LLM semantic scoring. Their method outperforms embedding-based benchmarks and is shown to scale for real-world applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] The Illusion of Insight in Reasoning Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reasoning models], [reasoning shifts, self-correction, model uncertainty, intrinsic vs extrinsic, chain-of-thought]</p>
</li>
<li class="">
<p><strong>authors:</strong> Liv G. d&#x27;Aliberti, Manoel Horta Ribeiro</p>
</li>
<li class="">
<p><strong>institution:</strong> Princeton University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00514" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00514</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a large-scale empirical study analyzing over 1 million reasoning traces across multiple models, domains, and training stages to investigate the nature and impact of mid-reasoning &quot;Aha!&quot; moments. 2. Found that such intrinsic reasoning shifts are rare, do not increase with training, and seldom improve accuracy, challenging the perception that they represent genuine model insight or self-correction. 3. Demonstrated that while intrinsic shifts are not beneficial, artificially triggering extrinsic shifts under conditions of high model uncertainty (high entropy) can reliably improve accuracy, showing these shifts are symptoms of unstable inference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c00fcaa573a1b7a6558433ae1348cc7cefec26d36175047b45df1cd217f2516_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c00fcaa573a1b7a6558433ae1348cc7cefec26d36175047b45df1cd217f2516_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether reasoning models experience genuine &quot;Aha!&quot; moments of intrinsic self-correction during inference. Through a large-scale analysis of reasoning traces across multiple models and training checkpoints, the authors find that such mid-reasoning shifts are rare and ineffective, but that artificially triggering shifts when the model is uncertain can improve accuracy. The main conclusion is that these shifts are symptoms of unstable inference behavior, not a mechanism for intrinsic self-improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [question answering], [multi-hop QA, retrieval-reasoning process, execution procedure, RAG, agentic systems]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Pittsburgh, Google Cloud AI Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00536" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00536</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel four-axis design framework for analyzing the execution procedure of multi-hop QA systems, focusing on plan, index, control, and stopping criteria. 2. Systematically maps and compares representative multi-hop QA systems using this framework, making implicit procedural choices explicit and comparable. 3. Synthesizes empirical trends and trade-offs from standard benchmarks and identifies key open challenges for future retrieval-reasoning agents.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64e851b90551e53952c84444631a7585a225572c38194cb181b360edfef5c8e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64e851b90551e53952c84444631a7585a225572c38194cb181b360edfef5c8e1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This survey paper addresses the lack of explicit analysis of the procedural interaction between retrieval and reasoning in multi-hop question answering. It introduces a four-axis framework to systematically compare different systems based on their execution plan, index structure, control strategies, and stopping criteria. The main conclusion is that making these procedural choices explicit reveals recurring trade-offs and highlights open challenges like structure-aware planning and robust stopping.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] ECR: Manifold-Guided Semantic Cues for Compact Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [model compression (quantization/pruning)], [embedding consistency regulation, manifold structure, semantic anchors, compact language models, on-device AI]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chung-Wei Victor Yuan</p>
</li>
<li class="">
<p><strong>institution:</strong> YVIC Research Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00543" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00543</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Embedding Consistency Regulation (ECR), a new framework that uses semantic anchors derived from teacher embeddings to preserve the underlying manifold structure in compact models. 2. Demonstrates that ECR stabilizes training and preserves semantic structure across tasks and languages without relying on matching logits or internal features, and adds minimal inference overhead. 3. Shows ECR is compatible with but independent of distillation, enabling better task alignment and deployment under strict efficiency or privacy constraints.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3184228efac0008fa39e8578d4daa8e597c9d20bf57f0662c9080c6c11607590_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3184228efac0008fa39e8578d4daa8e597c9d20bf57f0662c9080c6c11607590_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of semantic drift and loss of manifold structure in compact language models. It proposes the Embedding Consistency Regulation (ECR) framework, which uses offline-computed semantic anchors to guide the compact model&#x27;s geometry. Experiments show ECR produces more compact, task-aligned representations, making low-capacity models more stable and easier to deploy.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [on-device ai], [LoRA, Mixture-of-Experts, CTC, multilingual ASR, language-agnostic]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yuang Zheng, Yuxiang Mei, Dongxing Xu, Jie Chen, Yanhua Long</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Normal University, Unisound AI Technology Co., Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00557" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00557</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model for lightweight multilingual ASR. 2. Introduces an LID-posterior-driven LoRA routing mechanism that enables true language-agnostic, single-pass decoding without prior language identity information. 3. Demonstrates that the proposed method achieves competitive performance with state-of-the-art two-stage inference methods while significantly improving decoding efficiency for low-resource applications.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbd2404a5aa3ab85ddcd83e20182b5cedff2831876ded928574f65b33a573d7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbd2404a5aa3ab85ddcd83e20182b5cedff2831876ded928574f65b33a573d7d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the high computational cost and latency of large multilingual ASR models like Whisper for edge deployment. It proposes a lightweight, language-agnostic system using a Hierarchical LoRA-MoE architecture with CTC, which enables efficient single-pass decoding without needing language labels. Experiments show the method achieves competitive performance with more complex two-stage systems, improving efficiency for low-resource multilingual ASR.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] InfoSynth: Information-Guided Benchmark Synthesis for LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [benchmark synthesis, information theory, genetic algorithm, code generation, KL-divergence]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ishir Garg, Neel Kolhe, Xuandong Zhao, Dawn Song</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Berkeley</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00575" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00575</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://ishirgarg.github.io/infosynth_web/" target="_blank" rel="noopener noreferrer" class="">https://ishirgarg.github.io/infosynth_web/</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel framework (InfoSynth) for automatically generating and evaluating reasoning benchmarks using information-theoretic principles. 2. Proposes KL-divergence and entropy-based metrics to quantify benchmark novelty and diversity without costly model evaluations. 3. An end-to-end pipeline that synthesizes robust Python coding problems using genetic algorithms and iterative code feedback, achieving 97% accuracy in generating test cases and solutions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/704b01a43cbeec6830597e2e4ae9ad64cd96a4119782924bce3b012150cf43af_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/704b01a43cbeec6830597e2e4ae9ad64cd96a4119782924bce3b012150cf43af_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces InfoSynth, a framework that automatically generates novel and diverse reasoning benchmarks for LLMs using information-theoretic guidance and genetic algorithms. It successfully creates Python coding problems with high accuracy and provides control over novelty and difficulty. The method offers a scalable, self-verifying pipeline for benchmark creation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [safety evaluation], [adversarial patterns, safety benchmark, lightweight llms, chinese-specific, over-refusal]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhenhong Zhou, Shilinlu Yan, Chuanpu Liu, Qiankun Li, Kun Wang, Zhigang Zeng</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, Beijing University of Posts and Telecommunications, Huazhong University of Science and Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00588" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00588</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://huggingface.co/datasets/Yaesir06/CSSBench" target="_blank" rel="noopener noreferrer" class="">https://huggingface.co/datasets/Yaesir06/CSSBench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CSSBench, a novel benchmark for evaluating LLM safety against Chinese-specific adversarial patterns like homophones and pinyin. 2. Covers six real-world Chinese safety domains and measures both attack success and over-refusal rates. 3. Demonstrates that Chinese-specific adversarial patterns pose a critical challenge for lightweight LLMs, revealing a safety evaluation gap.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c813f73ed4fa6559522ae2a06c96e70fccff1e58bac3263d589d9e1ba5dde9bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c813f73ed4fa6559522ae2a06c96e70fccff1e58bac3263d589d9e1ba5dde9bb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a gap in safety evaluation for lightweight LLMs against Chinese-specific adversarial patterns. To address this, it introduces CSSBench, a benchmark covering six domains and specific attack patterns. The evaluation shows these patterns are a significant challenge for lightweight models, highlighting the need for targeted safety measures.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [JourneyBench, policy adherence, User Journey Coverage Score, Dynamic-Prompt Agent, Standard Operating Procedures]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sumanth Balaji, Piyush Mishra, Aashraya Sachdeva, Suraj Agrawal</p>
</li>
<li class="">
<p><strong>institution:</strong> Observe.AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00596" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00596</a></p>
</li>
<li class="">
<p><strong>contributions:</strong>  1. Introduces JourneyBench, a novel benchmark for evaluating customer support LLM agents on their ability to adhere to complex, multi-step business policies and workflows. 2. Proposes the User Journey Coverage Score, a new metric to quantitatively measure an agent&#x27;s policy adherence across diverse and realistic support scenarios generated via graph representations. 3. Demonstrates that a Dynamic-Prompt Agent (DPA) design, which explicitly models policy control, significantly improves adherence, enabling smaller models to outperform larger ones on this critical operational metric.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2447eea55afc6d1b5ede006dd4130334fc9f6a1079fd81fa73d75aa31c86b038_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2447eea55afc6d1b5ede006dd4130334fc9f6a1079fd81fa73d75aa31c86b038_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of evaluating LLM agents for business policy adherence in customer support, beyond simple task completion. It introduces the JourneyBench benchmark and a Dynamic-Prompt Agent design. The results show that structured policy orchestration (DPA) is crucial for adherence, allowing smaller models to achieve strong performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [hallucination reduction, probabilistic guarantees, LLM-as-a-judge, ensemble voting, model-agnostic framework]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nils Rautenberg, Sven Schippkus</p>
</li>
<li class="">
<p><strong>institution:</strong> Deutsche Aktuarvereinigung e.V., University of Hamburg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00641" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00641</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Formalizes a framework for fixed-input tasks and proves that independent prompt repetition exponentially reduces the probability of all outputs being incorrect. 2. Incorporates an LLM-as-a-judge to identify correct answers and provides theoretical error bounds based on the judge&#x27;s performance. 3. Introduces majority voting over independent judge calls to strengthen imperfect judges, achieving ensemble-level error rates that decrease exponentially with the number of votes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/165c6ebcc0bde9cc29a648eab707a9a04b4f10c177d4c9ed7fc6ceee24692cf9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/165c6ebcc0bde9cc29a648eab707a9a04b4f10c177d4c9ed7fc6ceee24692cf9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of contextual hallucinations in LLMs for deterministic workflows. It proposes a model-agnostic framework that combines independent prompt repetition with an LLM-as-a-judge and majority voting to exponentially reduce hallucination probabilities. The method provides explicit probabilistic guarantees without modifying the underlying model.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [protein language models], [Direct Preference Optimization, thermodynamic stability, structural hallucinations, physics-informed alignment, energy landscape]</p>
</li>
<li class="">
<p><strong>authors:</strong> QiWei Meng</p>
</li>
<li class="">
<p><strong>institution:</strong> Xi’an Jiaotong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00647" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00647</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Physio-DPO, a physics-informed alignment framework that grounds protein language models in thermodynamic stability. 2. Introduces a magnitude-aware objective that scales optimization updates based on the physical energy gap between native and perturbed structures. 3. Demonstrates a hard negative mining strategy to generate linguistically plausible but structurally unsound decoys for more robust training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d5257f1ab79de5e0438ace6dd83c270bc2812ff4355d0389349edec8caeb93_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d5257f1ab79de5e0438ace6dd83c270bc2812ff4355d0389349edec8caeb93_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of structural hallucinations in protein language models, where generated sequences are linguistically likely but thermodynamically unstable. It proposes Physio-DPO, a physics-informed alignment method that incorporates the continuous energy landscape into the optimization process. Experiments show that Physio-DPO outperforms existing baselines, significantly reducing structural errors and increasing the foldability of generated proteins.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Fast-weight Product Key Memory</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [long-context language modeling], [product key memory, fast weights, episodic memory, gradient descent, long-context]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tianyu Zhao, Llion Jones</p>
</li>
<li class="">
<p><strong>institution:</strong> Sakana AI</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00671" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00671</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Fast-weight Product Key Memory (FwPKM), a novel architecture that transforms static Product Key Memory into a dynamic, fast-weight episodic memory., 2. Introduces a mechanism for dynamic parameter updates at both training and inference time via local chunk-level gradient descent, enabling rapid memorization and retrieval., 3. Demonstrates that FwPKM effectively complements semantic memory, significantly reduces perplexity on long-context data, and shows strong generalization to contexts much longer than those seen during training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc5e7437ccdc396cc0c89f8bda772596a4ad71d82cd906f8eae81c22b107608_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc5e7437ccdc396cc0c89f8bda772596a4ad71d82cd906f8eae81c22b107608_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the trade-off between storage capacity and computational efficiency in sequence modeling layers. It proposes Fast-weight Product Key Memory (FwPKM), a dynamic architecture that updates parameters via local gradient descent to act as an episodic memory. Experiments show FwPKM reduces perplexity on long-context datasets and generalizes well to sequences much longer than those in training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Sigmoid Head for Quality Estimation under Language Ambiguity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [quality estimation], [quality estimation, language ambiguity, sigmoid activation, negative sampling, underconfidence]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tu Anh Dinh, Jan Niehues</p>
</li>
<li class="">
<p><strong>institution:</strong> Karlsruhe Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00680" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00680</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/TuAnh23/sigmoid-confidence" target="_blank" rel="noopener noreferrer" class="">https://github.com/TuAnh23/sigmoid-confidence</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies architectural and training setup issues in LMs (softmax, single-reference training) that cause ambiguity-induced underconfidence, making model probability a poor quality signal. 2. Proposes the Sigmoid Head, an extra unembedding layer with sigmoid activation, to model output tokens independently for better quality estimation. 3. Introduces a heuristic for negative sampling during training to avoid selecting potentially correct alternative tokens, improving training without needing human-annotated quality data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26806e2d4eb9b20c12526f3d561ebccfd1dfbbd43c035727d581173184fcf3b3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26806e2d4eb9b20c12526f3d561ebccfd1dfbbd43c035727d581173184fcf3b3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem that language model probability is unreliable for quality estimation due to natural language ambiguity. It proposes a Sigmoid Head, an additional module with sigmoid activation and a specialized negative sampling heuristic, trained on standard LM data. This method provides a better quality signal than the original softmax head and is more robust in out-of-domain settings without requiring annotated quality data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [ticket troubleshooting, retrieval-augmented generation, instruction-tuning, domain-specific ranking, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohamed Trabelsi, Huseyin Uzunalioglu</p>
</li>
<li class="">
<p><strong>institution:</strong> Nokia Bell Labs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00691" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00691</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes TeleDoCTR, an end-to-end system for telecom ticket troubleshooting integrating classification, retrieval, and generation tasks. 2. Introduces a domain-specific and contextual approach combining ranking and generative models tailored for the telecom domain. 3. Demonstrates superior performance over state-of-the-art methods on a real-world telecom dataset, enhancing troubleshooting accuracy and efficiency.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b34be88d61fea64f35727dce1917583308996e63a1822af1e6ad8863fe6a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b34be88d61fea64f35727dce1917583308996e63a1822af1e6ad8863fe6a8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes TeleDoCTR, a system that automates telecom ticket troubleshooting by integrating domain-specific models for ticket classification, retrieval of similar historical tickets, and generation of fault analysis reports. It is evaluated on a real-world telecom dataset and shows improved performance over existing methods, making the troubleshooting process more accurate and efficient.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Exploring the Performance of Large Language Models on Subjective Span Identification Tasks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [span identification], [large language models, in-context learning, chain of thought, aspect-based sentiment analysis, subjective spans]</p>
</li>
<li class="">
<p><strong>authors:</strong> Alphaeus Dmonte, Roland Oruche, Tharindu Ranasinghe, Marcos Zampieri, Prasad Calyam</p>
</li>
<li class="">
<p><strong>institution:</strong> George Mason University, University of Missouri, Lancaster University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00736</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Evaluates LLMs on subjective span identification tasks (sentiment analysis, offensive language identification, claim verification), an underexplored area compared to explicit tasks like NER. 2. Explores multiple LLM strategies including instruction tuning, in-context learning, and chain of thought for span identification. 3. Provides empirical results indicating that underlying textual relationships aid LLMs in identifying precise text spans.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c33271e2c603477b20beb01a7eafd35b6ae5eb8b9dfab2b53139ccf619c75074_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c33271e2c603477b20beb01a7eafd35b6ae5eb8b9dfab2b53139ccf619c75074_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates the performance of Large Language Models on subjective text span identification tasks, such as sentiment analysis and offensive language detection, using strategies like in-context learning and chain of thought. The study finds that LLMs benefit from underlying relationships within the text to identify accurate spans, addressing a gap in current research focused on explicit span tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Memory Bank Compression for Continual Adaptation of Large Language Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [memory &amp; caching], [memory bank compression, codebook optimization, online resetting mechanism, Key-Value Low-Rank Adaptation (KV-LoRA)]</p>
</li>
<li class="">
<p><strong>authors:</strong> Thomas Katraouras, Dimitrios Rafailidis</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Thessaly</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00756" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00756</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/Thomkat/MBC" target="_blank" rel="noopener noreferrer" class="">https://github.com/Thomkat/MBC</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed MBC, a model that compresses the memory bank for continual learning via a codebook optimization strategy. 2. Introduced an online resetting mechanism to prevent codebook collapse and ensure stable learning. 3. Employed Key-Value Low-Rank Adaptation (KV-LoRA) in the LLM&#x27;s attention layers to efficiently utilize the compressed memory representations.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4b16d7a0bdd1f6fa0e71da5c21a92629d07342bdc56905e10612ee07549b8dd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4b16d7a0bdd1f6fa0e71da5c21a92629d07342bdc56905e10612ee07549b8dd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of memory bank growth in continual learning for LLMs by proposing MBC, which compresses the memory bank using codebook optimization and an online resetting mechanism. The method integrates KV-LoRA for efficient adaptation and achieves a 99.7% reduction in memory bank size while maintaining high accuracy on question-answering tasks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning verification], [spectral graph analysis, attention patterns, Fiedler value, high-frequency energy ratio, sliding window attention]</p>
</li>
<li class="">
<p><strong>authors:</strong> Valentin Noël</p>
</li>
<li class="">
<p><strong>institution:</strong> Devoteam</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00791" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00791</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a training-free method for detecting valid mathematical reasoning in LLMs by performing spectral analysis on attention matrices treated as dynamic graphs. 2. Identified four interpretable spectral diagnostics (Fiedler value, HFER, smoothness, entropy) that show significant statistical differences between valid and invalid proofs across multiple model families. 3. Discovered that the method captures logical coherence rather than formal verifier acceptance and revealed an architectural dependency where different attention mechanisms (e.g., Sliding Window Attention) shift the primary discriminative spectral feature.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes a training-free method to detect valid mathematical reasoning in large language models by analyzing the spectral properties of attention patterns. The method identifies key spectral signatures that effectively distinguish between valid and invalid proofs with high accuracy. The findings show the method captures logical coherence and its effectiveness depends on the model&#x27;s attention architecture.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [domain adaptation], [transformer models, ensemble learning, fine-tuning, cancer registry, pathology reports]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jonathan Simkin, Lovedeep Gondara, Zeeshan Rizvi, Gregory Doyle, Jeff Dowden, Dan Bond, Desmond Martin, Raymond Ng</p>
</li>
<li class="">
<p><strong>institution:</strong> University of British Columbia, Newfoundland &amp; Labrador Health Services</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00787" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00787</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first cross-provincial evaluation of adapting domain-specific transformer models (BCCRTron and GatorTron) for cancer surveillance, demonstrating their ability to generalize across jurisdictions with different reporting conventions. 2. Proposed a conservative OR-ensemble method that combines complementary text representation pipelines (synoptic-focused and diagnosis-focused), substantially reducing missed cancers and improving error coverage. 3. Implemented a privacy-preserving workflow where only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/20cadf176e434cff234318c2ab86906269a79285d0f4a0350b5eb92ee86ab3b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/20cadf176e434cff234318c2ab86906269a79285d0f4a0350b5eb92ee86ab3b0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study addresses the challenge of applying NLP models across different cancer registries with varying reporting formats. It fine-tunes two transformer models (BCCRTron and GatorTron) on data from a new jurisdiction and combines them using an OR-ensemble. The results show that this approach maintains high performance and significantly reduces missed cancer cases, demonstrating effective cross-jurisdictional adaptation with a privacy-preserving workflow.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv260105] Learning Speech Representations with Variational Predictive Coding</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [self-supervised speech representation learning], [predictive coding, variational inference, HuBERT, speech representations, self-supervised learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sung-Lin Yeh, Peter Bell, Hao Tang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Edinburgh</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2601.00100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2601.00100</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a variational predictive coding framework as the underlying principle behind the HuBERT objective, providing a theoretical foundation. 2. Derives two simple modifications to the HuBERT objective from this framework, leading to immediate performance improvements. 3. Demonstrates the framework&#x27;s generality by showing its connections to other objectives like APC, CPC, wav2vec, and BEST-RQ.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba27d9f18d7b89a2b06727180b097e2e420315e2b2adae6f4d672735f9e63346_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba27d9f18d7b89a2b06727180b097e2e420315e2b2adae6f4d672735f9e63346_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies the lack of a theoretical principle as a bottleneck for improving the HuBERT objective for speech representation learning. It proposes a variational predictive coding framework as this underlying principle, which not only explains HuBERT but also leads to simple, effective modifications that improve performance. The improved pre-training yields significant gains on downstream tasks like phone classification and automatic speech recognition, validating the importance of the predictive coding interpretation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2026-01-05T03:17:11.000Z" itemprop="dateModified">Jan 5, 2026</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cscl/20251229-20260104"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251229-20260104 (cs.CL)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/cscr"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.CR</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2026-01-05" class="table-of-contents__link toc-highlight">2026-01-05</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2026-01</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><div class="calendar-cell calendar-empty"></div><div class="calendar-cell calendar-empty"></div><div class="calendar-cell calendar-empty"></div><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2026-01-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2026-01-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2026-01-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20251229-20260104#2026-01-04">4</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260105-20260111#2026-01-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260112-20260118#2026-01-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260119-20260125#2026-01-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscl/20260126-20260201#2026-01-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>