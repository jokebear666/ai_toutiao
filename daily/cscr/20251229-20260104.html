<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_CR/20251229-20260104" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251229-20260104 (cs.CR) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/cscr/20251229-20260104"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251229-20260104 (cs.CR) | AI头条"><meta data-rh="true" name="description" content="2025-12-29"><meta data-rh="true" property="og:description" content="2025-12-29"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/cscr/20251229-20260104"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscr/20251229-20260104" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cscr/20251229-20260104" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.CR","item":"https://jokebear666.github.io/ai_toutiao/category/cscr"},{"@type":"ListItem","position":3,"name":"20251229-20260104 (cs.CR)","item":"https://jokebear666.github.io/ai_toutiao/daily/cscr/20251229-20260104"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.9ae66a68.css">
<script src="/ai_toutiao/assets/js/runtime~main.bd476283.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.b2da8712.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Collapse sidebar category &#x27;cs.CR&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_CR/20251215-20251221"><span title="20251215-20251221 (cs.CR)" class="linkLabel_WmDU">20251215-20251221 (cs.CR)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cscr/20251222-20251228"><span title="20251222-20251228 (cs.CR)" class="linkLabel_WmDU">20251222-20251228 (cs.CR)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/cscr/20251229-20260104"><span title="20251229-20260104 (cs.CR)" class="linkLabel_WmDU">20251229-20260104 (cs.CR)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/cscr"><span>cs.CR</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251229-20260104 (cs.CR)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251229-20260104 (cs.CR)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-29">2025-12-29<a href="#2025-12-29" class="hash-link" aria-label="Direct link to 2025-12-29" title="Direct link to 2025-12-29" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251229] Composition Theorems for f-Differential Privacy</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Differential Privacy], [f-differential privacy, quantitative information flow, composition theorems, Galois connection, trade-off functions]</p>
</li>
<li class="">
<p><strong>authors:</strong> Natasha Fernandes, Annabelle McIver, Parastoo Sadeghi</p>
</li>
<li class="">
<p><strong>institution:</strong> Macquarie University, UNSW (University of New South Wales)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21358" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21358</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Establishes an equivalence between f-Differential Privacy (f-DP) and the channel model of Quantitative Information Flow (QIF) via a Galois connection. 2. Derives novel general composition theorems for f-DP enabled by this equivalence. 3. Applies the new composition theorems to analyze privacy amplification mechanisms like sub-sampling and purification, producing new f-DP profiles for these algorithms.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d202b6f3d64108f2672eaab827a63e5c6cfac205fcbbf58e2eb8b75c09924dbe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d202b6f3d64108f2672eaab827a63e5c6cfac205fcbbf58e2eb8b75c09924dbe_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper connects the theory of f-Differential Privacy (f-DP) with Quantitative Information Flow (QIF) by showing their equivalence through a Galois connection. This foundational link enables the derivation of new, general composition theorems for f-DP. The authors apply these theorems to analyze complex privacy-enhancing algorithms, such as sub-sampling, yielding improved privacy profiles.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&amp;C), encryption weaknesses, radio-frequency (RF) links]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mark Ballard, Guanqun Song, Ting Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> The Ohio State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21367</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&amp;C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [side-channel analysis], [RISC-V, CVA6, Correlation Power Analysis (CPA), RTL simulation, power side-channel]</p>
</li>
<li class="">
<p><strong>authors:</strong> Behnam Farnaghinejad, Antonio Porsia, Annachiara Ruospo, Alessandro Savino, Stefano Di Carlo, Ernesto Sanchez</p>
</li>
<li class="">
<p><strong>institution:</strong> Politecnico di Torino</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21362" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21362</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents the first side-channel vulnerability evaluation of the CVA6 RISC-V processor core. 2. Demonstrates the application of the VeriSide RTL-level power profiling framework for efficient power trace extraction without waveform files. 3. Shows that Correlation Power Analysis (CPA) on the CVA6 during software-based AES encryption enables key recovery, highlighting the need for early-stage RTL security assessments.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f1045d9314e37006547d2c94a7c4490ff95449687fd13d7c467003b4c095bac_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the power side-channel vulnerability of the CVA6 RISC-V core using the VeriSide RTL simulation framework. By applying Correlation Power Analysis (CPA) to power traces during software AES execution, the authors successfully recover the secret key. The findings demonstrate significant leakage in the CVA6 design, emphasizing the importance of pre-silicon RTL-level security evaluation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] The Imitation Game: Using Large Language Models as Chatbots to Combat Chat-Based Cybercrimes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [adversarial interaction], [Large Language Models, chat-based cybercrime, adversarial engagement, OCR-based analysis, Telegram scams]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yifan Yao, Baojuan Wang, Jinhao Duan, Kaidi Xu, ChuanKai Guo, Zhibo Eric Sun, Yue Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Drexel University, Shandong University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21371" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21371</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LURE, the first system to deploy LLMs as active agents (not passive classifiers) within adversarial chat environments to combat cybercrime. 2. Introduces a novel methodology combining automated discovery, adversarial interaction, and OCR-based analysis of image-embedded payment data. 3. Demonstrates the system&#x27;s effectiveness in real-world illicit Telegram scams, where it maintained human-like conversations in over 56% of interactions, revealing key scammer behavioral patterns.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4b9846e0125e1fe793dd441a994299b8568cd5c2bf7c05200309276b60eece_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f4b9846e0125e1fe793dd441a994299b8568cd5c2bf7c05200309276b60eece_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes LURE, a system that uses Large Language Models as active chatbots to engage with and deceive chat-based cybercriminals, turning their own tactics against them. Applied to Telegram video chat scams, LURE successfully maintained undetected multi-round conversations in over 56% of interactions, uncovering scam operation patterns like payment flows and upselling strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [lightweight cryptography], [lightweight ciphers, key size, IoT security, symmetric cryptography, security evaluation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Arsalan Vahi</p>
</li>
<li class="">
<p><strong>institution:</strong> Middle East Technical University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21368" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21368</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts a security-focused survey of symmetric lightweight ciphers for IoT, addressing a gap in existing literature. 2. Proposes a taxonomy for classifying IoT applications based on their inherent characteristics. 3. Proposes a taxonomy for evaluating security levels of lightweight ciphers based on key size, concluding that keys shorter than 128 bits are less secure.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07f480d571b5dcb81f609c0a05f097dbfe5bc783bd4de5936cf4b4c301e2ab61_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/07f480d571b5dcb81f609c0a05f097dbfe5bc783bd4de5936cf4b4c301e2ab61_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper surveys lightweight cryptographic algorithms for IoT security, focusing on evaluating their security strength rather than just performance. It proposes two taxonomies for classifying IoT applications and cipher security levels based on key length. The main finding is that key size is critical, with ciphers using keys shorter than 128 bits being considered insecure for sensitive data.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21354" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21354</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent&#x27;s reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent&#x27;s reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [game security], [server-side detection, client-side anti-tamper, kernel-level anti-cheat, hardware-assisted TEEs, adversarial resistance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Adwa Alangari, Ohoud Alharbi</p>
</li>
<li class="">
<p><strong>institution:</strong> King Saud University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21377" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21377</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A systematic categorization of technical anti-cheat defenses into four distinct categories: server-side detection, client-side anti-tamper, kernel-level drivers, and hardware-assisted TEEs. 2. A comparative evaluation framework for these categories based on detection effectiveness, performance overhead, privacy impact, and scalability. 3. An analysis highlighting the key trade-offs and the ongoing adversarial arms race, emphasizing the need for robust anti-cheat designs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137ad02b7b97dcc6332136fab185dc8b3ccf11a4a306f05b35f33d8d9520ec12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137ad02b7b97dcc6332136fab185dc8b3ccf11a4a306f05b35f33d8d9520ec12_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This systematic review surveys technical defenses against software-based cheating in online multiplayer games. It categorizes and evaluates approaches like server-side detection and kernel-level anti-cheat, highlighting trade-offs between visibility and privacy. The review concludes that the field is an ongoing arms race, requiring robust, adversary-resistant designs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Security Risks Introduced by Weak Authentication in Smart Home IoT Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [IoT security], [authentication security, replay attacks, local network threats, empirical security analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl</p>
</li>
<li class="">
<p><strong>institution:</strong> Astana IT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21374" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21374</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted an empirical analysis of authentication enforcement in deployed smart home IoT devices across multiple categories and ecosystems. 2. Demonstrated that authentication state is long-lived, persists through network changes, and can be replayed from another host on the same local network. 3. Identified that current mechanisms rely on long-lived trust with weak binding to session freshness, network context, or controller identity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85258f2b6afddb7ba218b720666454027995d978e3c0c5c5d1c10ce3ac5fd6ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85258f2b6afddb7ba218b720666454027995d978e3c0c5c5d1c10ce3ac5fd6ee_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper empirically analyzes authentication in smart home IoT devices, finding that authentication tokens are long-lived, persist through network events, and are vulnerable to replay attacks from other local hosts. The study concludes that current mechanisms prioritize usability over security, creating significant local network threats.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] LLM-Driven Feature-Level Adversarial Attacks on Android Malware Detectors</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [adversarial attacks], [adversarial attack, large language model, retrieval-augmented generation, Android malware detection, adversarial training]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tianwei Lan, Farid Naït-Abdesselam</p>
</li>
<li class="">
<p><strong>institution:</strong> Université Paris Cité</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21404" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21404</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LAMLAD, a novel adversarial attack framework that uses a dual-agent LLM architecture (manipulator and analyzer) to generate feature-level perturbations for evading Android malware detectors., 2. Integrates Retrieval-Augmented Generation (RAG) into the LLM pipeline to improve the efficiency and contextual awareness of the attack., 3. Proposes and evaluates an adversarial training-based defense strategy to enhance model robustness against the proposed LAMLAD-style attacks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6061210b194ba5cf79f70b8959faa3abe6b3e91ffad512d9cfd319de948593bb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes LAMLAD, a novel adversarial attack framework that leverages the generative and reasoning capabilities of Large Language Models (LLMs) to bypass ML-based Android malware classifiers. The method uses a dual-agent LLM architecture with RAG to generate realistic, functionality-preserving feature perturbations, achieving a high attack success rate. The paper also demonstrates that adversarial training can significantly reduce the effectiveness of such attacks, enhancing model robustness.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [differential privacy], [factorization mechanism, Fourier basis, marginal queries, product queries, Gaussian noise]</p>
</li>
<li class="">
<p><strong>authors:</strong> Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang</p>
</li>
<li class="">
<p><strong>institution:</strong> Inria, Université de Montpellier, INSERM, University of Toronto</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21499" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21499</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Attribute-Based Encryption], [Lagrange Interpolation, Shamir Secret Sharing, Involution Function-Based Stream Cipher]</p>
</li>
<li class="">
<p><strong>authors:</strong> Keshav Sinha, Sumitra, Richa Kumari, Akashdeep Bhardwaj, Shawon Rahman</p>
</li>
<li class="">
<p><strong>institution:</strong> UPES (University of Petroleum and Energy Studies), University of Hawaii - Hilo</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21525" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21525</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a multi-party execution approach to reduce server computational overhead and response time in distributed authorization. 2. Introduces an encryption method using an Involution Function-Based Stream Cipher for file data. 3. Utilizes Shamir secret sharing with second-order Lagrange interpolation for secure key distribution and reconstruction.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d614980b77b93ae670a09dec954155af73838387f014f381092232a41d17e816_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d614980b77b93ae670a09dec954155af73838387f014f381092232a41d17e816_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the server overhead and slow response time in secure data access by proposing a multi-party execution approach. The method combines an Involution Function-Based Stream Cipher for encryption with Shamir secret sharing and Lagrange interpolation for key management. The results show reduced computational overhead, evaluated through encryption/decryption time, throughput, and security analysis.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]</p>
</li>
<li class="">
<p><strong>authors:</strong> Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi</p>
</li>
<li class="">
<p><strong>institution:</strong> Technical University of Darmstadt</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21524" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21524</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a &quot;digital twin&quot;. 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Security Boundaries of Quantum Key Reuse: A Quantitative Evaluation Method for QKD Key Rotation Interval and Security Benefits Combined with Block Ciphers</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Post-Quantum Cryptography / Quantum Cryptography], [Quantum Key Distribution (QKD), Key Rotation, Block Cipher Modes (CTR/CBC/ECBC-MAC), Concrete Security, SM4]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xiaoming Chen, Haoze Chen, Fei Xu, Meifeng Gao, Jianguo Xie, Cheng Ye, An Hua, Jiao Zhao, Minghan Li, Feilong Li, Yajun Miao, Wei Qi</p>
</li>
<li class="">
<p><strong>institution:</strong> CAS Quantum Network Co., Ltd., University of Science and Technology of China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21561" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21561</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Constructed a precise calculation model for the key rotation interval in hybrid QKD-block cipher systems. 2. Proposed a quantitative method to evaluate the security benefit of using QKD keys with block ciphers, deriving the maximum safe number of files per key (Q*). 3. Quantified the security enhancement from key rotation, showing it can increase security strength by log2(k) to 2log2(k) bits for a target like 80-bit security.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c46c72f07d378546c8a8a3c260c860de7093f78f6c38b6f32868e53b31ca6f56_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c46c72f07d378546c8a8a3c260c860de7093f78f6c38b6f32868e53b31ca6f56_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the security degradation when a single QKD-derived key is reused to encrypt multiple files with block ciphers. It proposes a quantitative model to calculate safe key rotation intervals and evaluates the security benefits, using SM4 as a case study. The results show that regular key rotation can significantly enhance the security level of the hybrid cryptographic system.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Verifiable Passkey: The Decentralized Authentication Standard</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [authentication], [Verifiable Passkey, Verifiable Credential, Decentralized Identity, FIDO2]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aditya Mitra, Sibi Chakkaravarthy Sethuraman</p>
</li>
<li class="">
<p><strong>institution:</strong> Kadir Has University, VIT-AP University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21663" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21663</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel &#x27;Verifiable Passkey&#x27; standard to enable decentralized, privacy-preserving authentication. 2. Addresses the storage limitation of traditional FIDO2 passkeys by allowing a single passkey to be used across multiple services. 3. Mitigates the user tracking risk associated with centralized Identity Providers (IdPs) in federated SSO systems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf89aa4a9e3ca27de6380a24d719d401a00dd63929ea0b794171f19c33959345_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf89aa4a9e3ca27de6380a24d719d401a00dd63929ea0b794171f19c33959345_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies the problems of limited storage for FIDO2 passkeys and privacy risks in federated SSO. It proposes a new &#x27;Verifiable Passkey&#x27; standard that leverages Verifiable Credentials to allow a single passkey to be used across different platforms without compromising privacy. The main conclusion is that this approach provides a decentralized, scalable, and privacy-preserving alternative to current authentication methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [software security], [backdoor attack, retrieval-augmented code generation, vulnerable code, supply-chain vulnerability, stealthy attack]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tian Li, Bo Lin, Shangwen Wang, Yusong Tan</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Defense Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21681" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21681</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [steganography], [raster domain steganography, glyph perturbation, deterministic rasterization, multimodal embedding, text-based data hiding]</p>
</li>
<li class="">
<p><strong>authors:</strong> A V Uday Kiran Kandala</p>
</li>
<li class="">
<p><strong>institution:</strong> Queen Mary University of London</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21698" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21698</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a unified Glyph Perturbation Cardinality (GPC) framework for embedding heterogeneous data (text, images, audio, video) directly into the pixel space of rendered text glyphs. 2. Operates exclusively in the raster domain after font rendering, modifying bitmap pixels with minimal, visually imperceptible intensity increments for covert communication. 3. Introduces a decoding method based on re-rasterizing cover text, subtracting canonical glyph rasters, and recovering payload via pixel count analysis, leveraging deterministic raster behavior.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86fd7815a5837b02c5d9e31511c3faca8253eee6c4c977836c3a42782decfdc2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/86fd7815a5837b02c5d9e31511c3faca8253eee6c4c977836c3a42782decfdc2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces a raster domain steganography framework that embeds multimodal data into text by minimally perturbing the interior pixels of rendered glyphs. The method is visually imperceptible and computationally lightweight, enabling ordinary text to serve as a covert medium for secure data embedding. It generalizes beyond traditional linguistic steganography by operating directly on the deterministic bitmap output of text rendering pipelines.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Machine Learning Power Side-Channel Attack on SNOW-V</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [side-channel analysis], [SNOW-V, power analysis, profiling attack, Linear Discriminant Analysis, Fully Connected Neural Network]</p>
</li>
<li class="">
<p><strong>authors:</strong> Deepak, Rahul Balout, Anupam Golder, Suparna Kundu, Angshuman Karmakar, Debayan Das</p>
</li>
<li class="">
<p><strong>institution:</strong> Indian Institute of Science, Bangalore; KU Leuven; Intel Corporation; Indian Institute of Technology, Kanpur</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21737</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Systematically evaluates the effectiveness of Side-Channel Analysis (SCA) on the SNOW-V cipher using two profiling-based machine learning techniques: Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN). 2. Demonstrates progressive recovery of the secret key using these ML models, with FCN achieving a greater than 5x reduction in Minimum Traces to Disclosure (MTD) compared to the state-of-the-art CPA+LDA method. 3. Highlights the vulnerability of the 5G candidate cipher SNOW-V to machine learning-based SCA and underscores the need for robust countermeasures.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/317918426c0513400f22837d9127c1ab14ed2fb0ca1358968c6f98ca7da95a39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/317918426c0513400f22837d9127c1ab14ed2fb0ca1358968c6f98ca7da95a39_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper demonstrates a power side-channel attack on the SNOW-V stream cipher, a candidate for 5G security. Using power traces from an STM32 microcontroller, the authors employ profiling attacks with Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) for key recovery. The results show that FCN significantly outperforms prior methods, revealing SNOW-V&#x27;s vulnerability to machine learning-based attacks and emphasizing the need for stronger defenses.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Assessing the Effectiveness of Membership Inference on Generative Music</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [membership inference attacks], [membership inference attack (MIA), generative music, MuseGAN, privacy, copyright]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kurtis Chow, Omar Samiullah, Vinesh Sridhar, Hewen Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Irvine</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21762" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21762</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts the first preliminary study on the effectiveness of membership inference attacks (MIAs) specifically on generative music models., 2. Evaluates several existing MIA techniques on the popular MuseGAN model to assess their performance in this domain., 3. Provides empirical evidence suggesting that generative music data is relatively resilient to known membership inference techniques, aligning with prior findings in generative audio.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b7176fccbb69c4f0a15bfa6bcbb6ff59b09cf6ac02e0f524334f306ce4041f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b7176fccbb69c4f0a15bfa6bcbb6ff59b09cf6ac02e0f524334f306ce4041f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates whether membership inference attacks (MIAs) are effective against generative music models. The authors conduct a preliminary study by applying several existing MIA techniques to the MuseGAN model. Their findings indicate that generative music data is fairly resilient to these known attacks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Organizational Learning in Industry 4.0: Applying Crossan&#x27;s 4I Framework with Double Loop Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [cybersecurity incident response], [Dynamic Security Learning, double-loop learning, 4I framework, cyber-physical systems, organizational learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nimra Akram, Atif Ahmad, Sean B Maynard</p>
</li>
<li class="">
<p><strong>institution:</strong> The University of Melbourne</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21813" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21813</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the Advanced Dynamic Security Learning (DSL) Process Model, a novel cybersecurity incident response architecture for Industry 4.0 environments. 2. Integrates Argyris and Schön&#x27;s double-loop learning theory with Crossan&#x27;s 4I organizational learning framework to address proactive and reflective governance. 3. Provides a scalable and methodical approach to cybersecurity maturity that bridges operational obstacles and promotes systemic resilience in complex cyber-physical systems.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/140960f0ea33407610ec595750733a88a05966b1af849210f2f418cec775a463_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/140960f0ea33407610ec595750733a88a05966b1af849210f2f418cec775a463_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the critical gap in cybersecurity incident response for the dynamic and decentralized operational technology (OT) systems of Industry 4.0. It proposes the Advanced Dynamic Security Learning (DSL) Process Model, which combines double-loop learning with the 4I organizational learning framework to enable proactive governance and strategic adaptation. The model aims to help organizations build systemic resilience against growing cyber threats in industrial environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [authenticated key exchange], [Radio Frequency Fingerprint (RFF), Physical Unclonable Function (PUF), One-Time-Pad (OTP), ProVerif, over-the-air enrollment]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xuanyu Chen, Yue Zheng, Junqing Zhang, Guanxiong Shen, Chip-Hong Chang</p>
</li>
<li class="">
<p><strong>institution:</strong> The Chinese University of Hong Kong, Shenzhen; University of Liverpool; Southeast University; Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21827" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21827</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a lightweight mutual authentication protocol for IoD by integrating RFF and PUF technologies for secure D2D and D2G communication. 2. Achieves over-the-air enrollment using RFF-based device identification and uses PUF as a root of trust, eliminating the need for secret storage in drones. 3. Co-designs PUF&#x27;s on-the-fly key generation with OTP encryption for ephemeral keying and demonstrates security resilience through formal verification with ProVerif.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8808d2092e10128228471d5fad90003211bb9fb8e1df6bb71ef3ac783f8df8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8808d2092e10128228471d5fad90003211bb9fb8e1df6bb71ef3ac783f8df8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a lightweight authenticated key exchange protocol for securing cross-domain Internet of Drones (IoD). The method integrates Radio Frequency Fingerprint (RFF) for over-the-air enrollment and Physical Unclonable Function (PUF) as a root of trust to enable mutual authentication and ephemeral keying without storing secrets on drones. The protocol is shown to be resilient against common attacks and outperforms existing schemes in security features and overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [multi-modal inference], [copyright compliance, vision-language models, tool-augmented defense, benchmark dataset, multimodal query]</p>
</li>
<li class="">
<p><strong>authors:</strong> Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, University of California, Los Angeles, Palo Alto Networks</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21871" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21871</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/bluedream02/CopyGuard" target="_blank" rel="noopener noreferrer" class="">https://github.com/bluedream02/CopyGuard</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs&#x27; ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [backdoor attacks], [video segmentation foundation models, backdoor attack, two-stage training, gradient analysis, attention shift]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, Xinyi Huang</p>
</li>
<li class="">
<p><strong>institution:</strong> Hong Kong University of Science and Technology (Guangzhou), Nanjing University of Aeronautics and Astronautics, Fujian Normal University, Jinan University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22046" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22046</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies the ineffectiveness of classic backdoor attacks on prompt-driven Video Segmentation Foundation Models (VSFMs) and provides analysis via gradient and attention maps. 2. Proposes BadVSFM, the first dedicated backdoor attack framework for VSFMs, using a novel two-stage training strategy to separate clean and triggered representations. 3. Demonstrates strong, controllable attack performance across multiple models and datasets while preserving clean-task accuracy, and shows the vulnerability persists against existing defenses.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a7e9ff0ffc63f2085d6ca65db8e87f14fed435be5d8a51fd3d1265b22b668b1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a7e9ff0ffc63f2085d6ca65db8e87f14fed435be5d8a51fd3d1265b22b668b1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper identifies that standard backdoor attacks fail on prompt-driven Video Segmentation Foundation Models (VSFMs) like SAM2. To solve this, the authors propose BadVSFM, a two-stage backdoor attack framework that successfully implants a controllable backdoor by steering the encoder and decoder separately. Experiments show the attack is effective and evades current defenses, revealing a significant security vulnerability in VSFMs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [AI Governance &amp; Compliance], [lifecycle management, bias detection, differential privacy, federated learning, terminology drift]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sunil Arora, John Hastings</p>
</li>
<li class="">
<p><strong>institution:</strong> Dakota State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22060" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22060</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework&#x27;s practicality through a healthcare case study demonstrating detection of and response to terminology drift.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] ReSMT: An SMT-Based Tool for Reverse Engineering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [reverse engineering], [SMT solving, deobfuscation, logical assertions, automated analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Nir Somech, Guy Katz</p>
</li>
<li class="">
<p><strong>institution:</strong> The Hebrew University of Jerusalem</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22076" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22076</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel automated tool (ReSMT) that converts obfuscated assembly code into a system of logical assertions for analysis. 2. An approach that applies SMT solving and simulation to inspect obfuscated code execution, reducing the need for specialized manual skills. 3. Demonstration of the tool&#x27;s effectiveness through a successful case study on complex, obfuscated code.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/910bd3ef1ea1d824f29ec5a3c12c77ea64068337777edd67f0de1e2b98014c86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/910bd3ef1ea1d824f29ec5a3c12c77ea64068337777edd67f0de1e2b98014c86_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents ReSMT, an automated tool that addresses the difficulty of reverse engineering obfuscated code by transforming it into logical assertions and using SMT solvers for analysis. This method reduces reliance on expert manual deobfuscation. A case study shows ReSMT can successfully answer queries about complex obfuscated code, demonstrating its potential utility.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [trusted execution environments], [Trusted Execution Environments, Confidential Computing, Abstraction Layer, WebAssembly, Systematization of Knowledge]</p>
</li>
<li class="">
<p><strong>authors:</strong> Quentin Michaud, Sara Ramezanian, Dhouha Ayed, Olivier Levillain, Joaquin Garcia-Alfaro</p>
</li>
<li class="">
<p><strong>institution:</strong> Télécom SudParis, Institut Polytechnique de Paris, Thales, Lund University, Karlstad University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22090" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22090</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a comprehensive overview and classification of existing TEE technologies based on their design choices. 2. Proposes a systematization of knowledge (SoK) focusing on abstraction layers for TEEs to unify the confidential computing ecosystem. 3. Identifies WebAssembly as a promising approach for abstraction and discusses future research directions for integrating abstraction layers.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e9b906f168ce76656e0e7d95497572cc5edc40d2ad1966cd32644ac97261bb7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e9b906f168ce76656e0e7d95497572cc5edc40d2ad1966cd32644ac97261bb7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the fragmentation in Trusted Execution Environment (TEE) technologies by proposing abstraction layers as a solution to unify the confidential computing ecosystem. It conducts a systematization of knowledge, reviewing and classifying TEE designs and their corresponding abstraction layers. The study concludes that WebAssembly is a promising abstraction approach and highlights opportunities for future research to improve and integrate these layers.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] When the Base Station Flies: Rethinking Security for UAV-Based 6G Networks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [wireless network security], [UAV-BS, non-terrestrial networks (NTN), denial-of-service (DoS), GNSS spoofing, handover manipulation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ammar El Falou</p>
</li>
<li class="">
<p><strong>institution:</strong> King Abdullah University of Science and Technology (KAUST)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21574" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21574</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Identifies unique security vulnerabilities introduced by mobile, wireless, and resource-constrained UAV base stations in 6G networks. 2. Outlines specific attack surfaces for UAV-BS systems, including emergency alert spoofing, DoS, jamming, and malicious handover manipulation. 3. Proposes principles and mitigation techniques for securing the architecture of UAV-based non-terrestrial networks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9bf0cf9e709be88409d70b055d12514f5509bc714ec219eefb408d1ab8fbe51_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9bf0cf9e709be88409d70b055d12514f5509bc714ec219eefb408d1ab8fbe51_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the security challenges of using unmanned aerial vehicles (UAVs) as mobile base stations in 6G non-terrestrial networks. It identifies new attack vectors due to their mobility, wireless backhaul, and resource constraints, and outlines principles for mitigating these threats to build a secure architecture.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-30">2025-12-30<a href="#2025-12-30" class="hash-link" aria-label="Direct link to 2025-12-30" title="Direct link to 2025-12-30" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251230] Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [graph neural networks], [adversarial robustness, graph pruning, message passing, spurious connections, graph defense]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yongyu Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Michigan Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22128" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22128</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel graph pruning framework that uses adversarial robustness evaluation to identify fragile graph components. 2. Proposes a method that selectively prunes edges based on robustness scores to improve model reliability and resilience. 3. Validates the framework by instantiating it on three representative GNN architectures and demonstrating significant defense enhancement in high-perturbation regimes.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658f9bc62a6d2a57e4602f69b9d0c69056551601abd2ba0336e97d592bae1dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d658f9bc62a6d2a57e4602f69b9d0c69056551601abd2ba0336e97d592bae1dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the vulnerability of Graph Neural Networks (GNNs) to adversarial attacks and noise in graph structure. It proposes a pruning framework that uses adversarial robustness scores to identify and remove detrimental edges, resulting in cleaner and more resilient graph representations. Experiments show this method significantly strengthens GNN defenses against high levels of perturbation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] IANEC: Digital Forensic Investigation of Contemporary Writers&#x27; Archives</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [digital forensics], [digital forensics, file fingerprinting, FUSE, OS virtualization, document classification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Emmanuel Giguet</p>
</li>
<li class="">
<p><strong>institution:</strong> Université Caen Normandie, ENSICAEN, CNRS, Normandie Univ, GREYC UMR 6072</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22167" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22167</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Development of a method to separate system/application files from user files using fingerprint databases for archival analysis, 2. Creation of tools for reading files on Mac partitions and virtualizing operating systems to emulate original computing environments, 3. Implementation of semantic analysis techniques for automatic text classification, image analysis, and detection of sensitive content (e.g., hate speech) in digital archives.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a4c37c326ec3830119685f14996db61a1f1efdecaefecd64e96244e26e9512b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a4c37c326ec3830119685f14996db61a1f1efdecaefecd64e96244e26e9512b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The IANEC project develops digital forensic tools to automate the analysis of born-digital archives from contemporary writers. The proposed method combines technical file system analysis (e.g., fingerprinting, virtualization) with semantic document analysis (e.g., text/image classification). The main conclusion is that these tools are essential for the effective extraction, processing, and description of native digital archival corpora in cultural heritage institutions.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Practical challenges of control monitoring in frontier AI deployments</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [ai security], [control monitoring, oversight latency, safety case, scheming agents, incremental attacks]</p>
</li>
<li class="">
<p><strong>authors:</strong> David Lindner, Charlie Griffin, Tomek Korbak, Roland S. Zimmermann, Geoffrey Irving, Sebastian Farquhar, Alan Cooney</p>
</li>
<li class="">
<p><strong>institution:</strong> Google DeepMind, UK AI Safety Institute, University of Oxford</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22154" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22154</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analysis of real-world deployment dynamics (parallelism, latency, incremental attacks, partial incrimination) for control monitoring, 2. Proposal and comparison of three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs, 3. Introduction of a high-level safety case sketch as a tool for analyzing and comparing monitoring protocols, applied to four case studies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7cfc3d08c169a23a56cd0a16a1471c5bceacb1b76913f7079f51b7024f030d1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the practical challenges of scaling automated control monitors for overseeing frontier AI agents in real-world deployments. It proposes and compares three monitoring protocols (synchronous, semi-synchronous, asynchronous) with different latency-safety trade-offs and introduces a safety case sketch as an analytical tool. The analysis identifies oversight, latency, and recovery as key challenges, explored through four case studies of potential AI attacks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Latent Sculpting for Zero-Shot Generalization: A Manifold Learning Approach to Out-of-Distribution Anomaly Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [anomaly detection], [manifold learning, normalizing flows, dual-centroid compactness loss, out-of-distribution detection, zero-shot generalization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Rajeeb Thapa Chhetri, Zhixiong Chen, Saurab Thapa</p>
</li>
<li class="">
<p><strong>institution:</strong> Mercy University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22179" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22179</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Latent Sculpting, a novel two-stage framework that decouples manifold structure learning from density estimation for OOD anomaly detection. 2. Introduces the Dual-Centroid Compactness Loss (DCCL) to actively sculpt a compact, low-entropy latent manifold for benign data. 3. Demonstrates superior zero-shot generalization on the CIC-IDS-2017 benchmark, significantly outperforming supervised and unsupervised baselines on complex distribution shifts like &quot;Infiltration&quot;.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfcac5687161ad2a09f74eab3c1b7f91a350a2435fb71a0c791f2e305dff108c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cfcac5687161ad2a09f74eab3c1b7f91a350a2435fb71a0c791f2e305dff108c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of &quot;Generalization Collapse&quot; in supervised models when detecting Out-of-Distribution (OOD) anomalies. It proposes Latent Sculpting, a two-stage method that first uses a novel loss to sculpt a compact latent manifold for benign data and then applies a normalizing flow for density estimation. The results show this approach enables robust zero-shot anomaly detection, significantly outperforming existing methods on unseen attack scenarios.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] ReGAIN: Retrieval-Grounded AI Framework for Network Traffic Analysis</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [retrieval-augmented generation (RAG), network traffic analysis, large language models (LLMs), hierarchical retrieval, explainable AI]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaghayegh Shajarian, Kennedy Marsh, James Benson, Sajad Khorsandroo, Mahmoud Abdelsalam</p>
</li>
<li class="">
<p><strong>institution:</strong> North Carolina A&amp;T State University, University of Texas at San Antonio</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22223" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22223</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/270771/llm-traffictraffic" target="_blank" rel="noopener noreferrer" class="">https://github.com/270771/llm-traffictraffic</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes ReGAIN, a multi-stage framework combining traffic summarization, RAG, and LLM reasoning for transparent network traffic analysis. 2. Introduces a hierarchical retrieval pipeline with metadata filtering, MMR sampling, cross-encoder reranking, and an abstention mechanism to ground responses and reduce hallucinations. 3. Demonstrates high accuracy (95.95%-98.82%) on real-world attack traces and outperforms traditional baselines while providing explainable, evidence-cited outputs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/56c5ba03e3d4a510212509143bfecf0fa8b76f9171aa38dd765dadecc7b1ab32_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents ReGAIN, a framework that uses retrieval-augmented generation (RAG) and LLMs to analyze network traffic. It converts traffic into summaries, retrieves relevant evidence from a vector database, and generates interpretable, grounded analyses. The method achieves high accuracy on attack detection and provides explainable results, outperforming traditional rule-based and ML approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [autonomous vehicle security], [LiDAR attacks, safety controllers, adversarial perception, cut-in scenarios, time to collision]</p>
</li>
<li class="">
<p><strong>authors:</strong> Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl</p>
</li>
<li class="">
<p><strong>institution:</strong> Astana IT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22244" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22244</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents a systematic failure analysis of longitudinal safety controllers under object-based LiDAR attacks in highway scenarios., 2. Demonstrates that short-duration LiDAR-induced object hallucinations can trigger unsafe braking, delayed hazard responses, and unstable control., 3. Shows that controller failures are more influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes how object-based LiDAR attacks impact the safety controllers of autonomous vehicles. Using a high-fidelity simulation framework, it evaluates attacks in highway scenarios and finds they can cause unsafe braking and delayed responses. The key conclusion is that temporal consistency of adversarial objects is a stronger driver of controller failure than spatial errors, revealing a gap between perception robustness and control-level safety.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [language model safety], [sparse autoencoder, feature orthogonalization, stealth slip, pragmatic interpretation, statistical co-occurrence]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tsogt-Ochir Enkhbayar</p>
</li>
<li class="">
<p><strong>institution:</strong> Mongol-AI (inferred from email domain)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22293" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22293</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Empirically demonstrates that warning-framed training data fails to teach language models to avoid warned-against behaviors, showing generation rates similar to direct exposure. 2. Provides a mechanistic interpretation using sparse autoencoders, identifying a failure of feature orthogonalization where &quot;describing&quot; and &quot;performing&quot; an action activate overlapping latent features. 3. Identifies and names the &quot;stealth slip&quot; phenomenon, where conversational preambles can rotate activations into subspaces undetectable by linear probes, and shows that training-time feature ablation, not prompting, is required to address the issue.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates why language models trained on warning-framed examples (e.g., &quot;DO NOT USE&quot;) still learn to generate the warned-against content. Through behavioral experiments and sparse autoencoder analysis, it finds that models learn statistical co-occurrences rather than pragmatic intent, due to overlapping latent features for description and action. The core conclusion is that current architectures prioritize pattern completion over understanding speaker intent, requiring training-time interventions like feature ablation for correction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Statistical Side-Channel Risk Model for Timing Variability in Lattice-Based Post-Quantum Cryptography</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [side-channel analysis], [timing side-channel, post-quantum cryptography, statistical distinguishability, leakage modeling, TLRI risk score]</p>
</li>
<li class="">
<p><strong>authors:</strong> Aayush Mainali, Sirjan Ghimire</p>
</li>
<li class="">
<p><strong>institution:</strong> Amrita Vishwa Vidyapeetham (Amrita School of Computing, Bengaluru)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22301" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22301</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a scenario-based statistical risk model for timing leakage in lattice-based PQC, framing it as a problem of distributional distinguishability under controlled execution conditions (idle, jitter, loaded). 2. Synthesizes traces for multiple leakage models and quantifies leakage using a combination of statistical tests (Welch&#x27;s t-test, KS distance, Cliff&#x27;s delta, mutual information, distribution overlap) combined in a TLRI-like manner to produce a consistent risk score. 3. Empirically analyzes and compares the timing side-channel risk across representative lattice-based KEM families (Kyber, Saber, Frodo), identifying that idle conditions yield the highest distinguishability and that cache-index/branch-style leaks pose the highest risk.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49d5ecfc4cfe65ff274ea29a13c0adef37a682fd3b6e2173f7c594c08b22fb00_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49d5ecfc4cfe65ff274ea29a13c0adef37a682fd3b6e2173f7c594c08b22fb00_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a statistical risk model to assess timing side-channel vulnerabilities in lattice-based post-quantum cryptographic implementations under different environmental noise scenarios. The method synthesizes execution traces and quantifies leakage using multiple statistical metrics combined into a single risk score for scenario ranking. The analysis shows that idle execution conditions are most vulnerable, and faster schemes like Kyber can exhibit higher peak risk, enabling early-stage, reproducible comparisons before hardware-specific testing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Beyond Single Bugs: Benchmarking Large Language Models for Multi-Vulnerability Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [vulnerability detection], [multi-vulnerability detection, count bias, selection bias, long-context code, CWE injection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Chinmay Pushkar, Sanchit Kabra, Dhruv Kumar, Jagat Sesh Challa</p>
</li>
<li class="">
<p><strong>institution:</strong> BITS Pilani, Virginia Tech</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22306" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22306</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced a comprehensive benchmark for Multi-Vulnerability Detection across four programming languages (C, C++, Python, JavaScript) to address the limitations of existing single-vulnerability benchmarks. 2. Constructed a novel dataset of 40,000 files by systematically injecting controlled counts of vulnerabilities (1, 3, 5, 9) into long-context code samples, enabling the study of performance under varying vulnerability densities. 3. Quantified the performance degradation of state-of-the-art LLMs (e.g., GPT-4o-mini, Llama-3.3-70B) in high-density vulnerability settings, revealing distinct failure modes like severe &quot;under-counting&quot; in Python and JavaScript.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6a5fa286f161d0dab7d6a06a8f54502b88fd2f448edc9ed3609a31efaf97f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6a5fa286f161d0dab7d6a06a8f54502b88fd2f448edc9ed3609a31efaf97f5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the gap in evaluating LLMs for detecting multiple vulnerabilities in large, real-world code files. The authors propose a new benchmark by creating a dataset of long code files with systematically injected vulnerabilities and evaluate several LLMs. The main finding is that LLM performance sharply degrades as the number of vulnerabilities per file increases, with significant drops in recall for languages like Python.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LLA: Enhancing Security and Privacy for Generative Models with Logic-Locked Accelerators</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security, model protection], [logic locking, intellectual property protection, hardware accelerator, model theft, supply chain security]</p>
</li>
<li class="">
<p><strong>authors:</strong> You Li, Guannan Zhao, Yuhao Ju, Yunqi He, Jie Gu, Hai Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> Northwestern University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22307</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes LLA, a hardware-software co-design scheme for protecting generative AI models by embedding key bits into neurons and using invariance transformations to obscure them. 2. Integrates a lightweight, dataflow-compatible locking module into the AI accelerator, using the accelerator with a secret key as a license for model access. 3. Demonstrates that the approach is resilient against oracle-guided key optimization attacks while adding minimal computational overhead (&lt;0.1% for 7,168 key bits).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df323cc56f8d048243dce9e6af97041fca6264165872c422e5f81437cb03ef0d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces LLA, a method to protect generative AI models from supply chain threats like theft and corruption by combining software-based key embedding in neurons with a hardware locking module in the accelerator. This approach uses the accelerator as a license key, ensuring only authorized hardware can run the model correctly. Evaluation shows it effectively resists attacks with negligible performance overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] NOWA: Null-space Optical Watermark for Invisible Capture Fingerprinting and Tamper Localization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [digital watermarking], [optical watermarking, null-space watermark, tamper localization, phase mask, Null-Space Network]</p>
</li>
<li class="">
<p><strong>authors:</strong> Edwin Vargas</p>
</li>
<li class="">
<p><strong>institution:</strong> Rice University, Universidad Industrial de Santander</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22501" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22501</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a hybrid optical-digital framework (NOWA) that embeds an invisible watermark during image capture via a phase mask in the camera&#x27;s null space. 2. Introduces a Null-Space Network (NSN) for measurement-consistent reconstruction that preserves the watermark while delivering high-quality images. 3. Enables precise tamper localization by detecting pixel-level inconsistencies through null-space projection, establishing a structural security asymmetry against forgery.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae6666e8baf82000692a95ce2ef303fcc0c463c0552bda78000f2c121ebe772e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae6666e8baf82000692a95ce2ef303fcc0c463c0552bda78000f2c121ebe772e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the vulnerability of digital watermarks to attacks by proposing NOWA, a hybrid system that embeds an invisible optical watermark during image capture using a phase mask and reconstructs the image with a learned network to preserve it. This method allows for accurate tamper localization and resists common degradations like compression, providing a hardware-level security advantage that is difficult to forge without access to the specific optical and network parameters.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Verifiable Dropout: Turning Randomness into a Verifiable Claim</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [others], [verifiable dropout, zero-knowledge proofs, stochastic training, cloud training accountability, privacy-preserving verification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kichang Lee, Sungmin Lee, Jaeho Jin, JeongGil Ko</p>
</li>
<li class="">
<p><strong>institution:</strong> Yonsei University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22526" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22526</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces the concept of &quot;Verifiable Dropout,&quot; a novel mechanism that treats stochasticity in training as a verifiable claim rather than a source of ambiguity. 2. Proposes a privacy-preserving method using zero-knowledge proofs to bind dropout masks to a deterministic, cryptographically verifiable seed, enabling post-hoc integrity audits. 3. Addresses the &quot;plausible deniability&quot; gap in cloud-based AI training by allowing verification that stochastic operations were executed honestly without exposing sensitive model or data information.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0082678600127810e766281f97240dd59255c617276adff01d3cc8157b30c0f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0082678600127810e766281f97240dd59255c617276adff01d3cc8157b30c0f0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies a security gap in cloud-based AI training where stochastic operations like dropout allow attackers to mask manipulations as random variance. To solve this, it proposes Verifiable Dropout, a method using zero-knowledge proofs to cryptographically verify the correct execution of dropout, ensuring integrity while preserving privacy. This enables post-hoc audits to confirm randomness was not biased, closing the accountability loophole in stochastic training.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Raven: Mining Defensive Patterns in Ethereum via Semantic Transaction Revert Invariants Categories</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [smart contract security], [transaction revert, invariant mining, semantic clustering, BERT, fuzzing oracle]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mojtaba Eshghie, Melissa Mazura, Alexandre Bartel</p>
</li>
<li class="">
<p><strong>institution:</strong> Umeå University, KTH Royal Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22616" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22616</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel framework (RAVEN) that mines defensive patterns from Ethereum&#x27;s reverted transactions by aligning them to source code invariants and clustering them semantically., 2. Discovers six new, previously undocumented categories of defensive invariants (e.g., feature toggles, replay prevention) through expert review of the mined clusters., 3. Demonstrates the practical utility of the mined invariant catalog by using a discovered category as a fuzzing oracle to detect vulnerabilities in a real-world attack case study.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21def4401bf4eec329b37e2bead75f15935fd47b2aa5b0fdd0f0f2d34710eb06_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/21def4401bf4eec329b37e2bead75f15935fd47b2aa5b0fdd0f0f2d34710eb06_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the underutilization of reverted Ethereum transactions as signals of successful on-chain defenses. It introduces RAVEN, a framework that semantically clusters the invariants causing transaction reverts using a fine-tuned BERT model. The approach successfully mines new defensive invariant categories, which can be used to build data-driven security analysis tools like fuzzing oracles.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SCyTAG: Scalable Cyber-Twin for Threat-Assessment Based on Attack Graphs</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [threat assessment], [cyber twin, attack graph, threat emulation, scalability, cyber threat intelligence]</p>
</li>
<li class="">
<p><strong>authors:</strong> David Tayouri, Elad Duani, Abed Showgan, Ofir Manor, Ortal Lavi, Igor Podoski, Miro Ohana, Yuval Elovici, Andres Murillo, Asaf Shabtai, Rami Puzis</p>
</li>
<li class="">
<p><strong>institution:</strong> Ben-Gurion University of the Negev, Fujitsu Research Europe, Fujitsu Technology Solutions</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22669" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22669</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SCyTAG, a multi-step framework for generating a minimal viable cyber twin for attack scenario assessment. 2. Automates the construction of a cyber twin based on an attack graph derived from network specs and a CTI report. 3. Demonstrates significant resource reduction (up to 85% fewer components, half the resources) while preserving attack emulation fidelity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec5ac37b7ca1ba4ebe171d8048cb05279ccfadd515f5bc3dee92b6c9be5fd4a0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec5ac37b7ca1ba4ebe171d8048cb05279ccfadd515f5bc3dee92b6c9be5fd4a0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the scalability problem of using cyber twins for threat assessment in enterprise networks. It proposes SCyTAG, a framework that automatically generates a minimal cyber twin based on an attack graph to emulate specific attack scenarios from CTI reports. The evaluation shows SCyTAG drastically reduces the required emulation resources while maintaining accuracy, offering a scalable and cost-effective solution.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] When RSA Fails: Exploiting Prime Selection Vulnerabilities in Public Key Cryptography</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [cryptography], [RSA, prime selection, Fermat factorization, GCD attack, random number generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Murtaza Nikzad, Kerem Atas</p>
</li>
<li class="">
<p><strong>institution:</strong> Davidson College</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22720</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analysis of prime selection vulnerabilities in RSA, specifically the Close Prime and Shared Prime vulnerabilities. 2. Demonstration of the real-world prevalence of these vulnerabilities by referencing landmark and recent studies (e.g., Heninger et al., Böck 2023). 3. Identification of weak random number generation in embedded devices as the primary cause and discussion of mitigation strategies like proper entropy collection.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01c26b183514e853f6971e7477e3cf770aff9bb9bdc49986bb22b84d77365990_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01c26b183514e853f6971e7477e3cf770aff9bb9bdc49986bb22b84d77365990_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates vulnerabilities in RSA cryptosystems caused by improper prime number selection during key generation, focusing on Fermat&#x27;s factorization method for close primes and the GCD attack for shared primes. It demonstrates that these vulnerabilities are prevalent in real-world implementations, primarily due to weak random number generation in embedded devices. The paper concludes by discussing mitigation strategies, emphasizing the critical need for proper entropy collection and prime validation checks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A generalized motif-based Naïve Bayes model for sign prediction in complex networks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [network science, link prediction], [signed networks, sign prediction, motif-based Naïve Bayes, heterogeneous influence, feature-driven model]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yijun Ran, Si-Yuan Liu, Junjie Huang, Tao Jia, Xiao-Ke Xu</p>
</li>
<li class="">
<p><strong>institution:</strong> Guizhou Normal University, Beijing Normal University Zhuhai, Southwest University, Chongqing Normal University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22765" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22765</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a generalizable sign prediction framework that models the heterogeneous influence of neighboring nodes using designed role functions. 2. Extended the framework from single to multiple motifs via two strategies: a linear combination model and a feature-driven machine learning model (FGMNB). 3. Demonstrated through experiments that FGMNB outperforms state-of-the-art embedding-based baselines and identified that predictive motif structures vary across datasets.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6763274252bfc8c0b048ebb576b9629c3b09537a9f4eddc189476ae192f701bb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6763274252bfc8c0b048ebb576b9629c3b09537a9f4eddc189476ae192f701bb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of sign prediction in signed networks by proposing a generalized motif-based Naïve Bayes model that accounts for the heterogeneous influence of neighboring nodes. The key innovation is the Feature-driven Generalized Motif-based Naïve Bayes (FGMNB) model, which integrates high-dimensional motif features using machine learning. Experiments on real-world networks show that FGMNB outperforms several embedding-based baselines, highlighting the importance of dataset-specific local structural patterns for prediction.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Identifying social bots via heterogeneous motifs based on Naïve Bayes model</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [social bot detection], [heterogeneous motifs, Naïve Bayes model, maximum capability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yijun Ran, Jingjing Xiao, Xiao-Ke Xu</p>
</li>
<li class="">
<p><strong>institution:</strong> Guizhou University, Beijing Normal University, Dalian Minzu University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22759" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22759</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a theoretical framework that refines homogeneous motifs into heterogeneous ones by incorporating node-label information to capture neighborhood preference heterogeneity. 2. Systematically evaluated the contribution of different node pairs within heterogeneous motifs to the likelihood of a node being a social bot. 3. Mathematically quantified the maximum capability of each heterogeneous motif to estimate its potential benefits, showing that selecting high-capability motifs yields performance comparable to using all motifs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb36358979a0b66f0c0d952f628d15412b4ad6b609d8f895096dd7ac8efbe40_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb36358979a0b66f0c0d952f628d15412b4ad6b609d8f895096dd7ac8efbe40_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a new method for detecting social bots by using heterogeneous motifs within a Naïve Bayes model framework. It captures the heterogeneity of node neighborhoods and mathematically evaluates the detection capability of different motifs. The method outperforms state-of-the-art techniques on several benchmarks, and selecting only the highest-capability motifs achieves similar performance to using all motifs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Breaking the illusion: Automated Reasoning of GDPR Consent Violations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [privacy compliance], [automated auditing, web forms, GDPR, Datalog, large language model]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ying Li, Wenjun Qiu, Faysal Hossain Shezan, Kunlin Cai, Michelangelo van Dam, Lisa Austin, David Lie, Yuan Tian</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Los Angeles, University of Toronto, University of Texas at Arlington, in2it</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22789" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22789</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An LLM-based framework to extract consent requirements from privacy policies and locate relevant forms using multimodal web agents. 2. A domain-specific language (DSL) to formally describe heterogeneous web form structures for systematic analysis. 3. Machine-interpretable Datalog rules, derived with privacy experts, to translate GDPR requirements into formal logic for automated verification.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd68f5183b431442e1fe836b2b579a11383989f81394c35468b7402eac13d870_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd68f5183b431442e1fe836b2b579a11383989f81394c35468b7402eac13d870_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces Cosmic, an automated framework for detecting GDPR consent violations in web forms. It uses LLMs, a custom DSL, and Datalog rules to audit forms, finding widespread violations (3,384 on 94.1% of forms) with high accuracy (TPR &gt;98.6%), demonstrating a significant gap between legal requirements and implementation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Adaptive Trust Consensus for Blockchain IoT: Comparing RL, DRL, and MARL Against Naive, Collusive, Adaptive, Byzantine, and Sleeper Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [blockchain security, IoT security, adversarial machine learning], [Fully Homomorphic Encryption, Attribute-Based Access Control, Multi-Agent Reinforcement Learning, Byzantine Fault Tolerance, Trust-Based Consensus]</p>
</li>
<li class="">
<p><strong>authors:</strong> Soham Padia, Dhananjay Vaidya, Ramchandra Mangrulkar</p>
</li>
<li class="">
<p><strong>institution:</strong> Northeastern University, Dwarkadas J. Sanghvi College of Engineering</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22860" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22860</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel trust-based delegated consensus framework for blockchain IoT that integrates Fully Homomorphic Encryption (FHE) with Attribute-Based Access Control (ABAC) for privacy-preserving policy evaluation. 2. Systematically compares the performance of three reinforcement learning approaches (RL, DRL, MARL) against five distinct and sophisticated adversarial attack families. 3. Empirically demonstrates that Multi-Agent RL (MARL) provides superior defense against collusive attacks and identifies the catastrophic vulnerability of all learning agents to Time-Delayed Poisoning (sleeper) attacks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/373f990d6c218afb4f9e660bb84fd86dc8e9d7006d2b7bdef3d956a991960bff_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses securing blockchain-enabled IoT networks by proposing a trust-based consensus framework that combines privacy-preserving techniques (FHE and ABAC) with learning-based defenses. It compares RL, DRL, and MARL against five attack types, finding MARL most effective against collusive attacks but revealing that all methods are highly vulnerable to time-delayed poisoning attacks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [cyber resilience], [agentic AI, game theory, autonomous agents, system-theoretic framework, equilibrium-based design]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tao Li, Quanyan Zhu</p>
</li>
<li class="">
<p><strong>institution:</strong> City University of Hong Kong, New York University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22883" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22883</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a paradigm shift from prevention-centric security to agentic cyber resilience, arguing for systems that anticipate, maintain, recover, and learn under attack. 2. Develops a system-level framework and general architecture for designing AI workflows where autonomous agents participate in sensing, reasoning, and action. 3. Demonstrates how game-theoretic formulations provide a unifying design language for analyzing coupled attacker-defender workflows and enable equilibrium-based resiliency design, illustrated with case studies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1d5f82743a059040190978c2a78338bb73c72bc9cec9a0aafe00a0d12f0f24d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c1d5f82743a059040190978c2a78338bb73c72bc9cec9a0aafe00a0d12f0f24d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper argues that the rise of foundation-model-based AI necessitates a shift from traditional prevention-focused cybersecurity to a new paradigm of agentic cyber resilience. It proposes a system-theoretic framework for designing autonomous AI workflows and uses game theory as a unifying language to model attacker-defender dynamics, concluding that equilibrium-based design enables system-level resilience as demonstrated in case studies like automated penetration testing.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] DECEPTICON: How Dark Patterns Manipulate Web Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [dark patterns, web agents, adversarial robustness, deceptive UI, agent testing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Phil Cuvin, Hao Zhu, Diyi Yang</p>
</li>
<li class="">
<p><strong>institution:</strong> Stanford University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22894" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22894</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://agentdarkpatterns.org" target="_blank" rel="noopener noreferrer" class="">https://agentdarkpatterns.org</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces DECEPTICON, a novel environment for testing dark patterns in isolation with 700 web navigation tasks, 2. Demonstrates that dark patterns successfully manipulate agent trajectories in over 70% of tasks, significantly higher than human susceptibility, 3. Shows that larger, more capable models are more susceptible to dark patterns, and existing countermeasures like in-context prompting and guardrail models fail to mitigate the risk effectively.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8998ab43971416f683709173f00be5e8d5373de89f15ac199ec42d645a75b8b6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8998ab43971416f683709173f00be5e8d5373de89f15ac199ec42d645a75b8b6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces DECEPTICON, a testing environment to evaluate how dark patterns manipulate web agents, revealing that these deceptive UI designs successfully steer agent actions in over 70% of tasks, with larger models being more vulnerable and current defenses ineffective. The findings highlight an urgent need for robust defenses against such manipulative designs in agent systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SecureBank: A Financially-Aware Zero Trust Architecture for High-Assurance Banking Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [Zero Trust Architecture], [Zero Trust, Micro-Segmentation, Adaptive Identity, Security Automation, Financial Risk Modeling]</p>
</li>
<li class="">
<p><strong>authors:</strong> Paulo Fernandes Biao</p>
</li>
<li class="">
<p><strong>institution:</strong> Biaotech.dev</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23124" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23124</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SecureBank, a financially-aware and context-adaptive Zero Trust architecture specifically for high-assurance banking systems. 2. Integrates novel components like Financial Zero Trust, Adaptive Identity Scoring, Contextual Micro-Segmentation, and Impact-Driven Security Automation. 3. Provides experimental validation through Monte Carlo simulation using new metrics (TII, ITAL, SAE), showing improved attack handling and trust adaptation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcead853a793849eb23351043665ca37b119208adc01fb0dece96fde5c56ad05_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces SecureBank, a Zero Trust architecture designed for banking systems that incorporates financial risk and context. It integrates components like adaptive identity scoring and impact-driven automation. Simulation results show it improves automated attack handling and identity trust adaptation while maintaining transactional integrity.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [machine learning security], [TTPs, threat graph, multi-agent RAG, model stealing, jailbreaking]</p>
</li>
<li class="">
<p><strong>authors:</strong> Armstrong Foundjem, Lionel Nganyewou Tidjon, Leuson Da Silva, Foutse Khomh</p>
</li>
<li class="">
<p><strong>institution:</strong> Polytechnique Montréal (based on author affiliations and sMIEEE notation)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23132" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23132</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a large-scale empirical analysis of ML security, extracting 93 distinct threats from multiple sources including real-world incidents and code repositories. 2. Developed a multi-agent RAG system to automatically build an ontology-driven threat graph linking TTPs, vulnerabilities, and lifecycle stages from over 300 articles. 3. Identified unreported threats and dominant attack patterns (e.g., commercial LLM API model stealing, preference-guided jailbreaks) and highlighted vulnerability clusters in ML libraries with poor patch propagation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3da226bc9e7639392b95f6f00808f162580d1a90050c1261b3a0703259e42cf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3da226bc9e7639392b95f6f00808f162580d1a90050c1261b3a0703259e42cf_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper characterizes modern security risks in AI systems by analyzing threats from multiple sources and using a multi-agent RAG system to construct a threat graph. The analysis uncovers unreported attack vectors and dominant TTPs, concluding that adaptive, ML-specific security frameworks are urgently needed to mitigate supply-chain and inference-time risks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Certifying the Right to Be Forgotten: Primal-Dual Optimization for Sample and Label Unlearning in Vertical Federated Learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [vertical federated learning, machine unlearning, primal-dual optimization, sample unlearning, label unlearning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yu Jiang, Xindi Tong, Ziyao Liu, Xiaoxi Zhang, Kwok-Yan Lam, Chee Wei Tan</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanyang Technological University, Sun Yat-sen University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23171" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23171</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FedORA, a primal-dual optimization framework for sample and label unlearning in Vertical Federated Learning (VFL). 2. Introduces a new unlearning loss function that promotes classification uncertainty instead of misclassification. 3. Employs an adaptive step size and an asymmetric batch design to enhance stability and reduce computational costs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05dcd254c3941fc5cbf6bc3c063f2a726b8607659a3f7b4a526ad900e9e2b5de_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05dcd254c3941fc5cbf6bc3c063f2a726b8607659a3f7b4a526ad900e9e2b5de_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of data removal (unlearning) in Vertical Federated Learning (VFL), where different parties hold different features of the same data samples. The authors propose FedORA, a method that formulates unlearning as a constrained optimization problem solved via a primal-dual algorithm. Experiments show FedORA achieves unlearning effectiveness and model utility comparable to retraining from scratch, but with lower computational and communication costs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [adversarial attacks], [jailbreak attacks, large language models, adversarial prompting, equation solving, code completion]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhen Liang, Hai Huang, Zhengkui Chen</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang Sci-Tech University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23173" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23173</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/lzzzr123/Equacode" target="_blank" rel="noopener noreferrer" class="">https://github.com/lzzzr123/Equacode</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel multi-strategy jailbreak approach that combines mathematical equation solving and code completion to bypass LLM safety constraints. 2. Demonstrates high attack success rates (e.g., 91.19% on GPT series) with only a single query, outperforming single-strategy attacks. 3. Shows through ablation studies a strong synergistic effect between the equation and code modules, proving the multi-strategy approach is more effective than the sum of its parts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3023ba644e0cdeddfd98604ca7c5871aceb213706aede21b77e0d35b95cf6d23_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3023ba644e0cdeddfd98604ca7c5871aceb213706aede21b77e0d35b95cf6d23_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces EquaCode, a multi-strategy jailbreak attack that transforms malicious intent into a mathematical problem and forces the LLM to solve it via code, diverting its focus from safety. The method achieves high success rates on various LLMs with a single query, and ablation studies confirm the synergistic benefit of combining equation-solving and code completion strategies.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Multiparty Authorization for Secure Data Storage in Cloud Environments using Improved Attribute-Based Encryption</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [attribute-based encryption], [Attribute-Based Encryption (ABE), Functional-Based Stream Cipher (FBSC), Shamir Secret Sharing, 2D-Lagrange Interpolation, Multiparty Authorization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Partha Paul, Keshav Sinha</p>
</li>
<li class="">
<p><strong>institution:</strong> Birla Institute of Technology, Mesra; UPES Dehradun</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23216" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23216</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed an improved ABE scheme using a Functional-Based Stream Cipher (FBSC) for secure data storage in the cloud. 2. Introduced a multiparty authorization mechanism using scalar points on a parabolic curve and Shamir secret sharing with 2D-Lagrange Interpolation for key reconstruction. 3. Demonstrated the scheme&#x27;s robustness through security analysis (resisting collision attacks) and performance evaluation (minimal storage overhead, analyzed via NIST tests).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb58ab759ba01f8553bf4c4b7944b13301c8c797fdfea762a267af289cc3fc8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8bb58ab759ba01f8553bf4c4b7944b13301c8c797fdfea762a267af289cc3fc8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses secure data storage and access control in cloud environments by proposing an improved Attribute-Based Encryption (ABE) scheme combined with a Functional-Based Stream Cipher. The method enables multiparty authorization using parabolic curve points and secret sharing, requiring a threshold of users to reconstruct decryption keys. The analysis shows the scheme is robust, secure against collisions, and imposes minimal storage overhead.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] RobustMask: Certified Robustness against Adversarial Neural Ranking Attack via Randomized Masking</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [adversarial robustness], [randomized smoothing, certified robustness, neural ranking models, adversarial attacks, retrieval-augmented generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jiawei Liu, Zhuo Chen, Rui Zhu, Miaokun Chen, Yuyang Gong, Wei Lu, Xiaofeng Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Wuhan University, Yale University, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23307" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23307</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RobustMask, a novel defense combining pretrained language models&#x27; context-prediction with a randomized masking-based smoothing mechanism to protect neural ranking models. 2. Provides a theoretical proof for RobustMask&#x27;s certified top-K robustness against character-, word-, and phrase-level adversarial perturbations. 3. Demonstrates through extensive experiments that RobustMask can certify over 20% of candidate documents within the top-10 ranking against perturbations affecting up to 30% of content.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92efd69f112646f719a80cc74cecc9d34018b0607ad1f827ed960e54e754af07_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92efd69f112646f719a80cc74cecc9d34018b0607ad1f827ed960e54e754af07_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the vulnerability of neural ranking models to adversarial attacks that manipulate retrieval results. It proposes RobustMask, a defense method that uses randomized masking and smoothing to provide certified robustness. The results show it can effectively certify a significant portion of top-ranking documents against substantial content perturbations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Adelaide</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23385" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23385</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Fuzzilicon: A Post-Silicon Microcode-Guided x86 CPU Fuzzer</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [hardware security], [microcode fuzzing, post-silicon analysis, speculative execution, coverage-guided fuzzing, microarchitecture]</p>
</li>
<li class="">
<p><strong>authors:</strong> Johannes Lenzen, Mohamadreza Rostami, Lichao Wu, Ahmad-Reza Sadeghi</p>
</li>
<li class="">
<p><strong>institution:</strong> Technical University of Darmstadt</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23438</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed the first post-silicon fuzzing framework for x86 CPUs using microcode-level introspection and feedback. 2. Introduced a novel technique for extracting microarchitectural feedback by reverse-engineering Intel&#x27;s microcode update interface. 3. Demonstrated the framework&#x27;s effectiveness by discovering new vulnerabilities and significantly reducing coverage collection overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9d463f1925a4bae02edf8bf6e5276b970d1d085133ad48e32ea838e5db2fe1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9d463f1925a4bae02edf8bf6e5276b970d1d085133ad48e32ea838e5db2fe1a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents Fuzzilicon, a novel fuzzing framework that automates vulnerability discovery in x86 CPUs by using microcode-level instrumentation and feedback. It reverse-engineers Intel&#x27;s microcode interface to guide input generation without needing RTL access. The framework successfully uncovered new speculative execution vulnerabilities and established a new baseline for post-silicon CPU analysis.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Bitcoin-IPC: Scaling Bitcoin with a Network of Proof-of-Stake Subnets</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [blockchain scalability], [Bitcoin, Layer-2, Proof-of-Stake, interoperability, SegWit]</p>
</li>
<li class="">
<p><strong>authors:</strong> Marko Vukolić, Orestis Alpos, Jakov Mitrovski, Themis Papameletiou, Nikola Ristić, Dionysis Zindros</p>
</li>
<li class="">
<p><strong>institution:</strong> Bitcoin Scaling Labs, Common Prefix</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23439</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Bitcoin-IPC, a protocol enabling permissionless creation of Proof-of-Stake Layer-2 subnets with stake denominated in Bitcoin (BTC). 2. Proposes a novel design embedded within Bitcoin&#x27;s SegWit mechanism, inspired by SWIFT messaging, for seamless cross-subnet value transfer routed through Bitcoin L1. 3. Achieves significant scalability improvements, reducing transaction cost by up to 23x and increasing throughput from 7 to over 160 tps without modifying Bitcoin L1.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c762e73812d8ecf4dff85e3904f4f2897f640f483515f122ffbda6dd2edfabcc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses Bitcoin&#x27;s limited transaction throughput for use as a Medium of Exchange. It proposes Bitcoin-IPC, a protocol that creates a network of programmable Proof-of-Stake Layer-2 chains (subnets) that use Bitcoin for security and settlement. The design significantly increases transaction throughput and reduces cost without requiring changes to the Bitcoin base layer.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic AI for Autonomous Defense in Software Supply Chain Security: Beyond Provenance to Vulnerability Mitigation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [software supply chain security], [agentic AI, reinforcement learning, large language model, blockchain security ledger, CI/CD]</p>
</li>
<li class="">
<p><strong>authors:</strong> Toqeer Ali Syed, Mohammad Riyaz Belgaum, Salman Jan, Asadullah Abdullah Khan, Saad Said Alqahtani</p>
</li>
<li class="">
<p><strong>institution:</strong> Islamic University of Madinah, Arab Open University-Bahrain</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23480" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23480</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes an autonomous, agentic AI framework for software supply chain security that integrates LLM-based reasoning, RL, and multi-agent coordination for proactive vulnerability identification and mitigation. 2. Implements a system that interfaces with real CI/CD environments (e.g., GitHub Actions, Jenkins) via the Model Context Protocol (MCP) and logs actions to a blockchain for auditability. 3. Demonstrates through experiments that the framework outperforms rule-based and provenance-only baselines in detection accuracy and mitigation latency with acceptable operational overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f037ac5977c7275a7c48edbcb676154bcff19330c107fe4c9769750efc5350_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitation of current software supply chain security frameworks (like SLSA) which focus on provenance but lack active vulnerability mitigation. It proposes an agentic AI system that combines LLMs for semantic analysis and RL for adaptive response, integrated with CI/CD pipelines via MCP and logged on a blockchain. Experiments show it achieves better detection and faster mitigation than baselines, enabling a shift from reactive to proactive defense.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] A Privacy Protocol Using Ephemeral Intermediaries and a Rank-Deficient Matrix Power Function (RDMPF)</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [privacy-preserving protocols], [ephemeral intermediaries, rank-deficient matrix power function (RDMPF), private transfer, Internet Computer (ICP), forward secrecy]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eduardo Salazar</p>
</li>
<li class="">
<p><strong>institution:</strong> Nebula Technology Lab</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23535" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23535</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://icpp.tech" target="_blank" rel="noopener noreferrer" class="">https://icpp.tech</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A private transfer architecture using two short-lived intermediaries and sealed storage to decouple deposit and retrieval, 2. A non-interactive encapsulation scheme based on a Rank-Deficient Matrix Power Function (RDMPF) to derive per-transfer keys and enable discovery without fingerprinting, 3. A protocol where all intermediaries are ephemeral and provide certified destruction proofs, enabling auditable finalization and properties like sender anonymity and forward secrecy.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/328b76baab034954fecc09fa2e47ca08dd1df2f1b8b10c108a90b5989ec00391_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/328b76baab034954fecc09fa2e47ca08dd1df2f1b8b10c108a90b5989ec00391_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents a privacy protocol for the Internet Computer that uses ephemeral intermediaries and a novel RDMPF-based encapsulation to enable private asset transfers. The method ensures sender anonymity, content confidentiality against intermediaries, and forward secrecy, and has been implemented and deployed as ICPP.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [ai security], [prompt injection, multi-agent systems, provenance tracking, trust validation, multimodal sanitization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Toqeer Ali Syed, Mishal Ateeq Almutairi, Mahmoud Abdel Moaty</p>
</li>
<li class="">
<p><strong>institution:</strong> Islamic University of Madinah, Arab Open University-Bahrain</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23557" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23557</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a Cross-Agent Multimodal Provenance-Aware Defense Framework to secure agentic AI workflows against prompt injection attacks. 2. Introduces a coordinated defense with specialized sanitizer agents (text, visual) and an output validator, managed by a provenance ledger for tracking trust metadata. 3. Demonstrates through experiments that the framework significantly improves multimodal injection detection accuracy and minimizes trust leakage across agents.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05cd3aa22e07307bda78f06b6f87c2195c61c758b4fe44dc5bffbc281d72a8e4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05cd3aa22e07307bda78f06b6f87c2195c61c758b4fe44dc5bffbc281d72a8e4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the security threat of multimodal prompt injection attacks in agentic AI systems like LangChain. It proposes a defense framework that sanitizes inputs and validates outputs using specialized agents coordinated by a provenance ledger. The experimental results show the framework enhances detection accuracy and stabilizes agentic execution pathways.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Enhanced Web Payload Classification Using WAMM: An AI-Based Framework for Dataset Refinement and Model Evaluation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [web application security], [WAF, XGBoost, LLM-guided relabeling, dataset augmentation, multiclass detection]</p>
</li>
<li class="">
<p><strong>authors:</strong> Heba Osama, Omar Elebiary, Youssef Qassim, Mohamed Amgad, Ahmed Maghawry, Ahmed Saafan, Haitham Ghalwash</p>
</li>
<li class="">
<p><strong>institution:</strong> Cyshield, Coventry University - Egypt Branch</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23610" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23610</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes WAMM, an AI-driven multiclass web attack detection framework that reclassifies HTTP requests into OWASP-aligned categories. 2. Introduces a multi-phase dataset refinement pipeline for the SR-BH 2020 dataset, including deduplication, LLM-guided relabeling, augmentation, and LLM-based filtering. 3. Demonstrates that XGBoost on the refined dataset achieves high accuracy and microsecond-level inference, outperforming deep learning models and significantly improving upon rule-based OWASP CRS detection rates.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd1d738f4ed0f98c5c6365f48a9a30b2b8734d30e82e01c7f23fd1fac1002fa8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cd1d738f4ed0f98c5c6365f48a9a30b2b8734d30e82e01c7f23fd1fac1002fa8_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces WAMM, an AI-based framework for detecting web attacks. It refines a security dataset using techniques like LLM-guided relabeling and augmentation, then trains ML models like XGBoost for classification. The results show that WAMM with XGBoost achieves high accuracy and fast inference, significantly outperforming traditional rule-based WAFs in detecting obfuscated attacks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] SemCovert: Secure and Covert Video Transmission via Deep Semantic-Level Hiding</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [semantic communication security], [semantic hiding, randomized embedding, secret semantic extractor]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhihan Cao, Xiao Yang, Gaolei Li, Jun Wu, Jianhua Li, Yuchen Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Shanghai Jiao Tong University, North Carolina State University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22233" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22233</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SemCovert, a deep semantic-level hiding framework for secure and covert video transmission, integrating co-designed hiding and extraction models into the semantic communication pipeline. 2. Introduces a randomized semantic hiding strategy to break embedding determinism and introduce unpredictable distribution patterns, improving resistance to analysis. 3. Demonstrates through experiments that the framework effectively mitigates eavesdropping/detection risks, reliably conceals secret videos with minor video quality degradation, preserving transmission fidelity.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b368b0e0e2b9ae1e6c7bf4629ba64b86e8e570fdf21089b033a631ae92af3c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b368b0e0e2b9ae1e6c7bf4629ba64b86e8e570fdf21089b033a631ae92af3c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses privacy leakage in video semantic communication by proposing SemCovert, a framework that hides secret information at the semantic level using co-designed models and a randomized hiding strategy. The method enables authorized recovery while remaining imperceptible to regular users and resistant to statistical analysis. Experimental results confirm its effectiveness for secure and covert transmission without significantly compromising video quality.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Research Directions in Quantum Computer Cybersecurity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [quantum computer security], [quantum computer cybersecurity, post-quantum cryptography, cloud-based quantum computers, security threats, research gaps]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jakub Szefer</p>
</li>
<li class="">
<p><strong>institution:</strong> Northwestern University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23607</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a high-level summary of major research directions in quantum computer cybersecurity for the first half of the current decade, 2. Synthesizes and presents the current landscape of security threats and defenses against emergent quantum computing technologies, 3. Identifies and discusses perceived research gaps that require future funding and research efforts from academia and industry.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ccb76e5e59fbc85e15321e60404ace187a6d10acc03adcb5c6cfa4ff3c3e0da_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ccb76e5e59fbc85e15321e60404ace187a6d10acc03adcb5c6cfa4ff3c3e0da_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This document provides a concise overview of contemporary research directions in quantum computer cybersecurity, summarizing the major threats and defenses from the last five years of academic work. It aims to inform researchers and leaders about the current landscape and highlight key research gaps. The analysis is inspired by and extends beyond discussions from the Quantum Computer Cybersecurity Symposium.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-30T09:42:39.000Z" itemprop="dateModified">Dec 30, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cscr/20251222-20251228"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251222-20251228 (cs.CR)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/daily/cscv"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.CV</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-29" class="table-of-contents__link toc-highlight">2025-12-29</a></li><li><a href="#2025-12-30" class="table-of-contents__link toc-highlight">2025-12-30</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/cscr/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cscr/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>