<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_LG/20251222-20251228" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251222-20251228 (cs.LG) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/cslg/20251222-20251228"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251222-20251228 (cs.LG) | AI头条"><meta data-rh="true" name="description" content="2025-12-22"><meta data-rh="true" property="og:description" content="2025-12-22"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/cslg/20251222-20251228"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cslg/20251222-20251228" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/cslg/20251222-20251228" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.LG","item":"https://jokebear666.github.io/ai_toutiao/daily/cslg"},{"@type":"ListItem","position":3,"name":"20251222-20251228 (cs.LG)","item":"https://jokebear666.github.io/ai_toutiao/daily/cslg/20251222-20251228"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.84a25bac.css">
<script src="/ai_toutiao/assets/js/runtime~main.36d5e77f.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.e61b1501.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/daily">Daily</a><a class="navbar__item navbar__link" href="/ai_toutiao/category/paper">Paper</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Collapse sidebar category &#x27;cs.LG&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_LG/20251215-20251221"><span title="20251215-20251221 (cs.LG)" class="linkLabel_WmDU">20251215-20251221 (cs.LG)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/cslg/20251222-20251228"><span title="20251222-20251228 (cs.LG)" class="linkLabel_WmDU">20251222-20251228 (cs.LG)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Expand sidebar category &#x27;cs.SE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/cslg"><span>cs.LG</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251222-20251228 (cs.LG)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251222-20251228 (cs.LG)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-22">2025-12-22<a href="#2025-12-22" class="hash-link" aria-label="Direct link to 2025-12-22" title="Direct link to 2025-12-22" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251222] Dion2: A Simple Method to Shrink Matrix in Muon</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Muon optimizer, orthonormalization, matrix shrinking, sampling, Newton-Schulz iterations, FSDP2]</li>
<li class=""><strong>authors:</strong> Kwangjun Ahn, Noah Amsel, John Langford</li>
<li class=""><strong>institution:</strong> Microsoft Research, AI Frontiers, NYU</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16928</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Dion2, a simple method to reduce the computational cost of the Muon optimizer by sampling a fraction of rows or columns for orthonormalization at each iteration. This sparsifies the update, lowering computation and communication overhead. The method maintains update quality close to full Muon while improving scalability, as shown in training benchmarks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] BIONIX: A Wireless, Low-Cost Prosthetic Arm with Dual-Signal EEG and EMG Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [EEG, EMG, sliding window classification, threshold-based detection, ESP32 microcontroller, NeuroSky MindWave Mobile 2, MyoWare 2.0]</li>
<li class=""><strong>authors:</strong> Pranesh Sathish Kumar</li>
<li class=""><strong>institution:</strong> Alliance Academy for Innovation, Georgia Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16929" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16929</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a low-cost prosthetic arm controlled by a dual-signal system using EEG (for hand open/close via blink detection) and EMG (for elbow movement via threshold-based detection). The prototype, built with ESP32 microcontrollers and commercial sensors, demonstrates a feasible, intuitive control method for upper-limb prostheses in resource-limited settings. The main conclusion is that this integrated neuro-muscular approach offers a viable pathway to affordable and biologically intuitive prosthetic control.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dense embedding retrieval, graph-based exploration, BM25, LLM-based reasoning, code localization]</li>
<li class=""><strong>authors:</strong> Shravan Chaudhari, Rahul Thomas Jacob, Mononito Goswami, Jiajun Cao, Shihab Rashid, Christian Bock</li>
<li class=""><strong>institution:</strong> Johns Hopkins University, AWS AI Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SpIDER, a method that enhances dense retrieval for code localization by using graph-based exploration of a codebase to gather auxiliary context, which is then reasoned over by an LLM. This approach addresses the limitations of standard embedding methods that underutilize code structure. Empirical results show that SpIDER consistently improves retrieval performance across multiple programming languages.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Optimizing Text Search: A Novel Pattern Matching Algorithm Based on Ukkonen&#x27;s Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [pattern matching algorithms], [Ukkonen&#x27;s Algorithm, Suffix Trees, pattern recognition, text-search algorithms]</li>
<li class=""><strong>authors:</strong> Xinyu Guan, Shaohua Zhang</li>
<li class=""><strong>institution:</strong> Not specified</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16927" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16927</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a novel pattern matching algorithm that combines Ukkonen&#x27;s Algorithm for constructing Suffix Trees with a new search technique using Python&#x27;s dynamic link attributes. The optimized algorithm demonstrates linear time and space efficiency, outperforming traditional methods like Naive Search, KMP, and Boyer-Moore, and achieves 100% accuracy in tasks such as genomic sequence pattern recognition.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Compression is Routing: Reconstruction Error as an Intrinsic Signal for Modular Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [transformer autoencoder, mixture-of-experts (MoE), reconstruction error, latent vectors, sequence compression, routing mechanism]</li>
<li class=""><strong>authors:</strong> Zhongpan Tang</li>
<li class=""><strong>institution:</strong> Independent Researcher (based on gmail address)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16963" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16963</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel &quot;Compression is Routing&quot; architecture using a Transformer Autoencoder to compress long sequences into latent vectors. It demonstrates that reconstruction error serves as an intrinsic domain fingerprint, enabling expert module scheduling without explicit gating networks. The method offers a scalable approach for handling long contexts and modular language model design.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PAACE: A Plan-Aware Automated Agent Context Engineering Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [context engineering, plan-aware compression, next-k-task relevance, instruction co-refinement, function-preserving compression, synthetic data generation, knowledge distillation]</li>
<li class=""><strong>authors:</strong> Kamer Ali Yuksel</li>
<li class=""><strong>institution:</strong> aiXplain Inc</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16970</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MemoryGraft: Persistent Compromise of LLM Agents via Poisoned Experience Retrieval</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [retrieval-augmented generation, long-term memory, semantic imitation, indirect injection attack, memory poisoning, MetaGPT, DataInterpreter]</li>
<li class=""><strong>authors:</strong> Saksham Sahai Srivastava, Haoyu He</li>
<li class=""><strong>institution:</strong> University of Georgia</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16962" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16962</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MemoryGraft, a novel attack that poisons an LLM agent&#x27;s long-term memory by implanting malicious successful experiences, which are then retrieved and imitated during future tasks. The method exploits the agent&#x27;s semantic imitation heuristic through a poisoned RAG store, leading to persistent behavioral compromise. The authors demonstrate that this attack can cause significant and stealthy behavioral drift in agents like MetaGPT&#x27;s DataInterpreter.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Physics-Informed Lightweight Machine Learning for Aviation Visibility Nowcasting Across Multiple Climatic Regimes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [aviation meteorology], [XGBoost, physics-guided feature engineering, SHAP analysis, METAR data, gradient boosting]</li>
<li class=""><strong>authors:</strong> Marcelo Cerda Castillo</li>
<li class=""><strong>institution:</strong> Pulsetech.cl</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16967" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16967</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a lightweight XGBoost model for aviation visibility nowcasting, trained on surface observation data (METAR) and enhanced with physics-informed feature engineering. The model outperforms operational TAF forecasts at 3-hour horizons, achieving 2.5x to 4x higher recall with fewer false alarms across multiple climates. The SHAP analysis shows the model implicitly reconstructs local physical drivers like advection and radiation, providing explainable predictions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] QSMOTE-PGM/kPGM: QSMOTE Based PGM and kPGM for Imbalanced Dataset Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [quantum-inspired machine learning], [Pretty Good Measurement (PGM), kernelized PGM (KPGM), Quantum SMOTE (QSMOTE), quantum state discrimination, density matrix-based learning]</li>
<li class=""><strong>authors:</strong> Bikash K. Behera, Giuseppe Sergioli, Robert Giuntini</li>
<li class=""><strong>institution:</strong> Università degli Studi di Cagliari, Technische Universität München</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16960" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16960</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces and compares quantum-inspired classifiers, specifically Pretty Good Measurement (PGM) and kernelized PGM (kPGM), for imbalanced datasets, using Quantum SMOTE (QSMOTE) for synthetic oversampling. The results show that both PGM and kPGM outperform a classical random forest baseline, with PGM achieving the highest accuracy and kPGM demonstrating greater robustness across different data sampling strategies.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [Proximal Policy Optimization (PPO), Group Relative Policy Optimization (GRPO), turn-level MDP, advantage estimation, multi-turn RL]</li>
<li class=""><strong>authors:</strong> Junbo Li, Peng Zhou, Rui Meng, Meet P. Vadera, Lihong Li, Yang Li</li>
<li class=""><strong>institution:</strong> The University of Texas at Austin, Amazon</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17008" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17008</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Turn-PPO, a reinforcement learning method that applies Proximal Policy Optimization at the turn level instead of the token level for training LLM agents in multi-turn tasks. It demonstrates that this approach is more robust and effective than the commonly used GRPO method, particularly for long-horizon reasoning scenarios, as validated on the WebShop and Sokoban datasets.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific ai evaluation], [Practical Inquiry Model (PIM), SGI-Bench, Test-Time Reinforcement Learning (TTRL), retrieval-augmented novelty, agent-based evaluation]</li>
<li class=""><strong>authors:</strong> Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu</li>
<li class=""><strong>institution:</strong> Shanghai Artificial Intelligence Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Women&#x27;s Health Benchmark for Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [healthcare AI evaluation], [women&#x27;s health benchmark, large language models, error types, model stumps, query types]</li>
<li class=""><strong>authors:</strong> Victoria-Elisabeth Gruber, Razvan Marinescu, Diego Fajardo, Amin H. Nassar, Christopher Arkfeld, Alexandria Ludlow, Shama Patel, Mehrnoosh Samaei, Valerie Klug, Anna Huber, Marcel Gühner, Albert Botta i Orfila, Irene Lagoja, Kimya Tarr, Haleigh Larson, Mary Beth Howard</li>
<li class=""><strong>institution:</strong> Lumos AI, Yale Cancer Center, Harvard Medical School, UCSF, Brown University, Emory University, Clinic Ottakring, NHS, Yale School of Medicine, Johns Hopkins University School of Medicine</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17028</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the Women&#x27;s Health Benchmark (WHB), a novel evaluation framework comprising 96 validated model stumps across five medical specialties, three query types, and eight error types to assess LLM performance in women&#x27;s health. It finds that current LLMs have approximately 60% failure rates, with significant weaknesses in detecting urgency, indicating they are not yet reliable for providing women&#x27;s health advice.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] GB-DQN: Gradient Boosted DQN Models for Non-stationary Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [gradient boosting, DQN, ensemble learning, Bellman residual, non-stationary environments]</li>
<li class=""><strong>authors:</strong> Chang-Hwan Lee, Chanseung Lee</li>
<li class=""><strong>institution:</strong> Florida Atlantic University, Morrow Company</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17034" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17034</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes GB-DQN, a method that uses gradient boosting to create an ensemble of Q-networks, where each new network learns the residual error of the current ensemble to adapt to non-stationary environments. Experiments show that GB-DQN achieves faster recovery and greater robustness compared to standard DQN and other baselines in tasks with changing dynamics.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SFBD-OMNI: Bridge models for lossy measurement restoration with limited clean samples</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [generative models], [diffusion models, bridge models, entropic optimal transport, distribution restoration, SFBD-OMNI]</li>
<li class=""><strong>authors:</strong> Haoye Lu, Yaoliang Yu, Darren Ho</li>
<li class=""><strong>institution:</strong> University of Waterloo, Vector Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17051" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17051</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SFBD-OMNI, a bridge model framework that generalizes Stochastic Forward-Backward Deconvolution to restore a clean data distribution from abundant noisy samples and a black-box corruption process, framed as a one-sided entropic optimal transport problem. It shows that with a small number of clean samples, the underlying distribution becomes largely recoverable even in cases of per-sample information loss. Experiments demonstrate significant improvements across diverse measurement settings beyond Gaussian corruption.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Dynamic Tool Dependency Retrieval for Efficient Function Calling</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [dynamic tool dependency retrieval, function calling, tool retrieval, on-device agents, tool-augmented llms]</li>
<li class=""><strong>authors:</strong> Bhrij Patel, Davide Belli, Amir Jalalirad, Maximilian Arnold, Aleksandr Ermovol, Bence Major</li>
<li class=""><strong>institution:</strong> Qualcomm Research, University of Maryland, College Park</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17052" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17052</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1d880d31eb189fff50465aa10379459bec7bfbbf666206f8ad6ea98793a534a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1d880d31eb189fff50465aa10379459bec7bfbbf666206f8ad6ea98793a534a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Dynamic Tool Dependency Retrieval (DTDR), a lightweight method that retrieves relevant tools for LLM function calling by conditioning on both the initial user query and the evolving execution context. It models tool dependencies from demonstrations to adaptively retrieve tools as a plan unfolds. The results show that this dynamic retrieval improves function calling success rates by 23% to 104% compared to static retrieval methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Universal consistency of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>-NN rule in metric spaces and Nagata dimension. III</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [statistical learning theory], [k-nearest neighbor classifier, universal consistency, Nagata dimension, Lebesgue-Besicovitch differentiation property, metric spaces]</li>
<li class=""><strong>authors:</strong> Vladimir G. Pestov</li>
<li class=""><strong>institution:</strong> Universidade Federal de Santa Catarina, University of Ottawa</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17058" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17058</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proves the final implication needed to establish the equivalence between the universal consistency of the k-nearest neighbor classifier, the strong Lebesgue-Besicovitch differentiation property, and a metric space being sigma-finite dimensional in the sense of Nagata. The core method extends a measure construction from Hilbert spaces to any complete separable metric space lacking the Nagata property. The main conclusion is that the k-NN classifier is universally consistent in a metric space if and only if the space is sigma-finite dimensional.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Can Large Reasoning Models Improve Accuracy on Mathematical Tasks Using Flawed Thinking?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [mathematical reasoning], [chain-of-thought prompting, reinforcement learning, GRPO, fine-tuning, error recovery]</li>
<li class=""><strong>authors:</strong> Saraswathy Amjith, Mihika Dusad, Neha Muramalla, Shweta Shah</li>
<li class=""><strong>institution:</strong> MIT</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17079" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17079</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9501255b38adfbd4ed3cb05e9a136df6cf358b6420281716744f14c17554a871_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper fine-tunes the Qwen3-4B model using GRPO reinforcement learning on intentionally flawed chain-of-thought reasoning traces to improve error detection and recovery. It finds that this mixed training on both calculation and reasoning errors improves robustness to misleading prefills without sacrificing accuracy on clean problems, unlike standard fine-tuning which degrades robustness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [mixture-of-experts, offloading, dynamic quantization, low-rank compensation, router-guided precision restoration]</li>
<li class=""><strong>authors:</strong> Zhenyu Liu, Yunzhen Liu, Zehao Fan, Garrett Gagnon, Yayue Hou, Nan Wu, Yangwook Kang, Liu Liu</li>
<li class=""><strong>institution:</strong> Rensselaer Polytechnic Institute, University of Massachusetts Amherst, George Washington University, Samsung Semiconductor</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17073" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17073</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63c6e9afd2a3ff75dfe81968ba3c73da71d577f341a443ab96f8bb14a681ed3f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63c6e9afd2a3ff75dfe81968ba3c73da71d577f341a443ab96f8bb14a681ed3f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a bandwidth-efficient method for Mixture-of-Experts (MoE) inference that uses router-guided, low-rank compensation to dynamically restore precision for the most important experts while keeping others in low-bit form. This approach reduces I/O traffic during offloading without significantly harming model accuracy. The method demonstrates a superior bandwidth-accuracy trade-off and improved throughput on GPU and GPU-NDP systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Perturb Your Data: Paraphrase-Guided Training Data Watermarking</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [SPECTRA, watermarking, training data detection, membership inference attack, paraphrase generation, scoring model, token probability comparison]</li>
<li class=""><strong>authors:</strong> Pranav Shetty, Mirazul Haque, Petr Babkin, Zhiqiang Ma, Xiaomo Liu, Manuela Veloso</li>
<li class=""><strong>institution:</strong> JPMorgan AI Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17075" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17075</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b47f34679362a94a5413b86758bfca6d1690e7158a9b8bc7a21706264c5e833c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b47f34679362a94a5413b86758bfca6d1690e7158a9b8bc7a21706264c5e833c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SPECTRA, a watermarking method that subtly paraphrases text using an LLM to embed a detectable signature into training data without altering its statistical distribution. It verifies unauthorized use by comparing token probabilities between a suspect model and a scoring model. The approach reliably detects watermarked data even when it constitutes a minuscule fraction of the training corpus, providing a scalable pre-release watermark for data owners.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] How to Square Tensor Networks and Circuits Without Squaring Them</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [probabilistic modeling], [tensor networks, squared circuits, probabilistic circuits, marginalization, canonical forms, unitary matrices, distribution estimation]</li>
<li class=""><strong>authors:</strong> Lorenzo Loconte, Adrián Javaloy, Antonio Vergari</li>
<li class=""><strong>institution:</strong> University of Edinburgh</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17090" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17090</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method to parameterize squared circuits (a generalization of squared tensor networks) using conditions inspired by orthogonality and determinism, enabling efficient marginalization without squaring. This approach overcomes computational overhead while maintaining expressiveness for distribution estimation. Experiments confirm the method allows more efficient learning without loss of expressiveness.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning to Plan, Planning to Learn: Adaptive Hierarchical RL-MPC for Sample-Efficient Decision Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [reinforcement learning, model predictive control, MPPI, hierarchical planning, adaptive sampling]</li>
<li class=""><strong>authors:</strong> Toshiaki Hori, Jonathan DeCastro, Deepak Gopinath, Avinash Balachandran, Guy Rosman</li>
<li class=""><strong>institution:</strong> Toyota Research Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17091</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a method that fuses reinforcement learning and model-predictive control (MPC) into an adaptive hierarchical framework. It uses RL actions to guide the MPPI sampler and adaptively aggregates MPPI samples to improve value estimation, leading to more robust and sample-efficient policies. The approach demonstrates improved data efficiency, performance, and convergence speed in domains like race driving and Lunar Lander.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretability], [counterfactual explanations, model-agnostic, time series, ECG, LIME, SHAP]</li>
<li class=""><strong>authors:</strong> Justin Li, Efe Sencan, Jasper Zheng Duan, Vitus J. Leung, Stephan Tsaur, Ayse K. Coskun</li>
<li class=""><strong>institution:</strong> Boston University, Sandia National Laboratories, Boston Medical Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17100" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17100</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces UniCoMTE, a universal, model-agnostic framework for generating counterfactual explanations for time series classifiers by modifying input samples to identify influential temporal features. It is evaluated on an ECG classifier and shown to produce more concise, stable, and human-aligned explanations than established methods like LIME and SHAP, thereby improving model interpretability for real-world applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [modular reuse, on-device execution, model decomposition, parallel execution, quantization]</li>
<li class=""><strong>authors:</strong> Kunjal Panchal, Saayan Mitra, Somdeb Sarkhel, Haoliang Wang, Ishita Dasgupta, Gang Wu, Hui Guan</li>
<li class=""><strong>institution:</strong> University of Massachusetts Amherst, Adobe Research</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17108" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17108</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ae01de3bb190d7134b2995b14582f1e46ed434d4588a9e6017b7c9282b01074_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ae01de3bb190d7134b2995b14582f1e46ed434d4588a9e6017b7c9282b01074_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces Atom, an on-device system that decomposes large video-language models into reusable modules (e.g., visual encoder, language decoder) to eliminate redundant model loading and enable parallel execution across subtasks like captioning and retrieval. This modular reuse approach reduces end-to-end latency by 27–33% on commodity smartphones with only marginal performance drops, making it a practical solution for efficient video-language pipelines on edge devices.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fault Diagnosis and Quantification for Photovoltaic Arrays based on Differentiable Physical Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [differentiable physical model, gradient-based fault parameters identification, Adahessian optimizer, I-V curve reconstruction]</li>
<li class=""><strong>authors:</strong> Zenan Yang, Yuanliang Li, Jingwei Zhang, Yongjie Liu, Kun Ding</li>
<li class=""><strong>institution:</strong> Hohai University, Concordia University, Aalborg University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17107" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17107</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5899b49765c1a033a8227b9785fb68b2ee7e7efe7e5a6fd98b6b7f264267e08c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5899b49765c1a033a8227b9785fb68b2ee7e7efe7e5a6fd98b6b7f264267e08c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a differentiable fast fault simulation model (DFFSM) and a gradient-based fault parameters identification (GFPI) method using the Adahessian optimizer to quantify faults in photovoltaic arrays. The method accurately models I-V characteristics under multiple faults and uses analytical gradients for efficient parameter identification. Experimental results show high quantification accuracy with I-V reconstruction errors below 3%, demonstrating the effectiveness of differentiable physical simulators for PV fault diagnosis.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bridging Training and Merging Through Momentum-Aware Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [low-rank factorization, momentum-aware optimization, curvature-aware merging, model composition, memory-efficient training]</li>
<li class=""><strong>authors:</strong> Alireza Moayedikia, Alicia Troncoso</li>
<li class=""><strong>institution:</strong> Swinburne University of Technology, Universidad Pablo de Olavide</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17109" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17109</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a unified framework that maintains factorized momentum and curvature statistics during model training, then reuses this information for geometry-aware model merging. This approach eliminates the need to recompute curvature data, saving computation and enabling more principled model composition. The method demonstrates improved performance on language understanding benchmarks and offers better hyperparameter robustness compared to existing low-rank optimizers.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] The Effect of Negation on CLIP in Medical Imaging: Limitations of Contrastive Language-Image Pretraining</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [contrastive fine-tuning, token attribution, t-SNE projection, attention-head ablation, image retrieval, negation handling]</li>
<li class=""><strong>authors:</strong> Jasmine Vu, Shivanand Sheshappanavar</li>
<li class=""><strong>institution:</strong> Santa Clara University, University of Wyoming</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17121" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17121</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcadf51218711774df214ce0c80d2175e2b72d14b2fab69a5a27aebd9bc17bd2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcadf51218711774df214ce0c80d2175e2b72d14b2fab69a5a27aebd9bc17bd2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper fine-tunes the CLIP-based CheXagent model to improve its ability to understand negated phrases in medical image retrieval tasks. The method uses contrastive fine-tuning and analyzes internal model behavior through techniques like token attribution. The results show improved negation handling with a slight trade-off in accuracy for positive prompts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Digitizing Nepal&#x27;s Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [handwritten text recognition], [encoder-decoder architectures, data-centric techniques, line-level transcription, transfer learning, data augmentation, character error rate]</li>
<li class=""><strong>authors:</strong> Anjali Sarawgi, Esteban Garces Arias, Christof Zotter</li>
<li class=""><strong>institution:</strong> LMU Munich, Heidelberg Academy of Sciences and Humanities, Munich Center for Machine Learning (MCML)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17111" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17111</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bae7b70bc5a974847e0434967f87fb01f452c81f46d95e3cea515746090bd7f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bae7b70bc5a974847e0434967f87fb01f452c81f46d95e3cea515746090bd7f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents an end-to-end Handwritten Text Recognition (HTR) pipeline for Old Nepali manuscripts, employing line-level transcription and exploring encoder-decoder architectures with data-centric methods. The best model achieves a low Character Error Rate (CER) of 4.9%, demonstrating effective digitization for this low-resource historical language. The authors release their training code and evaluation scripts to support further research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [differentiable simulation, graph neural network, SE(3)-equivariance, attention mechanism, 3D Zernike polynomials, shape-matching loss, implicit differentiation, bilevel optimization]</li>
<li class=""><strong>authors:</strong> Seong Ho Pahng, Guoye Guan, Benjamin Fefferman, Sahand Hormoz</li>
<li class=""><strong>institution:</strong> Harvard University, Harvard Medical School, Dana-Farber Cancer Institute, Broad Institute of MIT and Harvard</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17129" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17129</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces DiffeoMorph, a differentiable framework that uses an attention-based SE(3)-equivariant graph neural network to train agents to collectively morph into target 3D shapes. It employs a novel shape-matching loss based on 3D Zernike polynomials and uses implicit differentiation to handle a bilevel optimization problem for rotation alignment. The method successfully generates complex shapes from simple ellipsoids using minimal spatial cues.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Smoothing DiLoCo with Primal Averaging for Faster Training of LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Generalized Primal Averaging (GPA), DiLoCo, Schedule-Free, AdamW, Nesterov&#x27;s method, primal averaging, optimizer, iterate averaging]</li>
<li class=""><strong>authors:</strong> Aaron Defazio, Konstantin Mishchenko, Parameswaran Raman, Hao-Jun Michael Shi, Lin Xiao</li>
<li class=""><strong>institution:</strong> Meta Superintelligence Labs</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17131</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Generalized Primal Averaging (GPA), a new optimizer that extends Nesterov&#x27;s method to perform smooth, per-step averaging of model iterates, addressing limitations of periodic averaging methods like single-worker DiLoCo. It demonstrates that GPA outperforms single-worker DiLoCo, simplifies hyperparameter tuning, reduces memory overhead, and achieves significant speedups in training LLMs and vision models compared to AdamW.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Biosecurity-Aware AI: Agentic Risk Auditing of Soft Prompt Attacks on ESM-Based Variant Predictors</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [soft prompt attacks, adversarial auditing, agentic framework, risk metrics, embedding-space robustness]</li>
<li class=""><strong>authors:</strong> Huixin Zhan</li>
<li class=""><strong>institution:</strong> New Mexico Institute of Mining and Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17146" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17146</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edf3a867526cb70d49c0816641a925b129fe30dc5f7871777c74f463824654df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edf3a867526cb70d49c0816641a925b129fe30dc5f7871777c74f463824654df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SAGE, an agentic framework that audits genomic foundation models by injecting soft prompt perturbations and evaluating performance degradation. It finds that models like ESM2 are vulnerable to such attacks, revealing hidden security risks in biomedical applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Distributed Learning in Markovian Restless Bandits over Interference Graphs for Stable Spectrum Sharing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [wireless communication, distributed learning], [restless multi-armed bandit (RMAB), Gale-Shapley matching, interference graph, SMILE algorithm, distributed optimization]</li>
<li class=""><strong>authors:</strong> Liad Lea Didi, Kobi Cohen</li>
<li class=""><strong>institution:</strong> Ben-Gurion University of the Negev</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17161" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17161</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SMILE, a distributed learning algorithm that integrates restless bandit learning with graph-constrained coordination for stable spectrum sharing in interference graphs. It proves that SMILE converges to the optimal stable allocation and achieves logarithmic regret. Simulations validate the algorithm&#x27;s robustness, scalability, and efficiency.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [pde solving], [BumpNet, sparse neural network, basis function expansion, sigmoid activation, physics-informed neural networks, PINNs, DeepONet, EDNN, meshless method, h-adaptivity]</li>
<li class=""><strong>authors:</strong> Shao-Ting Chiu, Ioannis G. Kevrekidis, Ulisses Braga-Neto</li>
<li class=""><strong>institution:</strong> Texas A&amp;M University, The Johns Hopkins University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17198" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17198</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces BumpNet, a sparse neural network framework that constructs adaptive, trainable basis functions from sigmoid activations for solving PDEs. It combines BumpNet with existing architectures like PINNs, DeepONet, and EDNN to create efficient, interpretable models for PDE solution and operator learning. The proposed methods demonstrate improved accuracy and reduced computational cost compared to standard approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning solution operator of dynamical systems with diffusion maps kernel ridge regression</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [dynamical systems modeling], [kernel ridge regression, diffusion maps, operator learning, geometry-aware learning, data-driven kernels]</li>
<li class=""><strong>authors:</strong> Jiwoo Song, Daning Huang, John Harlim</li>
<li class=""><strong>institution:</strong> The Pennsylvania State University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17203" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17203</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Diffusion Maps Kernel Ridge Regression (DM-KRR) method for learning solution operators of complex dynamical systems. It combines a simple kernel ridge regression framework with a data-driven kernel from diffusion maps to adapt to the system&#x27;s intrinsic geometry without explicit manifold modeling. The method is shown to outperform state-of-the-art approaches in accuracy and data efficiency across various systems, highlighting the importance of geometric constraints for long-term prediction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Do Foundational Audio Encoders Understand Music Structure?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [music information retrieval], [music structure analysis, foundational audio encoders, self-supervised learning, masked language modeling, boundary detection, function prediction]</li>
<li class=""><strong>authors:</strong> Keisuke Toyama, Zhi Zhong, Akira Takahashi, Shusuke Takahashi, Yuki Mitsufuji</li>
<li class=""><strong>institution:</strong> Sony Group Corporation, Sony AI</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17209</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the use of pretrained foundational audio encoders (FAEs) for music structure analysis (MSA). Through comprehensive experiments on 11 FAE types, it finds that models using self-supervised learning with masked language modeling on music data are particularly effective for MSA tasks like boundary detection and function prediction.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] CheXPO-v2: Preference Optimization for Chest X-ray VLMs with Knowledge Graph Consistency</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [reinforcement learning, group relative policy optimization, knowledge graph consistency, entity-relation matching, process supervision, hard-example mining]</li>
<li class=""><strong>authors:</strong> Xiao Liang, Yuxuan An, Di Wang, Jiawei Hu, Zhicheng Jiao, Bin Jing, Quan Wang</li>
<li class=""><strong>institution:</strong> Xidian University, Brown University, Capital Medical University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17213" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17213</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c86c0e9aa8fe8870d86c5f63baf1ccd89856e7434ece25e03ba384660733fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75c86c0e9aa8fe8870d86c5f63baf1ccd89856e7434ece25e03ba384660733fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes CheXPO-v2, an alignment framework that uses a Knowledge Graph Consistency Reward for process supervision to reduce hallucinations in medical VLMs. It parses reasoning into structured triplets to penalize incoherent logic, outperforming prior methods on benchmarks with high data efficiency. The approach achieves state-of-the-art accuracy on MIMIC-CXR-VQA using only 5k samples.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [differential privacy, local differential privacy, RAPPOR, PAC indistinguishability, hybrid privacy, rarity-aware protection]</li>
<li class=""><strong>authors:</strong> Madhava Gaikwad</li>
<li class=""><strong>institution:</strong> Microsoft</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17251</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes AlignDP, a hybrid privacy mechanism that protects large language models by separating data into rare and non-rare fields. Rare fields are shielded with PAC indistinguishability for strong privacy, while non-rare fields are privatized using RAPPOR to allow useful frequency estimation. This approach aims to prevent knowledge extraction and unauthorized fine-tuning by design, making models more secure against distillation and editing attacks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Practical Framework for Privacy-Preserving and Byzantine-robust Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [fault-tolerance], [federated learning, byzantine-robust aggregation, privacy-preserving, dimensionality reduction, secure multi-party computation, adaptive tuning]</li>
<li class=""><strong>authors:</strong> Baolei Zhang, Minghong Fang, Zhuqing Liu, Biao Yi, Peizhao Zhou, Yuan Wang, Tong Li, Zheli Liu</li>
<li class=""><strong>institution:</strong> Nankai University, University of Louisville, University of North Texas</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17254" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17254</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes ABBR, a practical framework for federated learning that combines Byzantine-robust aggregation with privacy-preserving techniques. Its core method uses dimensionality reduction to speed up private computations and an adaptive tuning strategy to minimize the impact of malicious models. The framework is shown to run significantly faster with minimal overhead while maintaining strong Byzantine resilience.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Electric Vehicle Charging Load Forecasting: An Experimental Comparison of Machine Learning Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [time series forecasting, LSTM, GRU, Transformer, ARIMA, XGBoost]</li>
<li class=""><strong>authors:</strong> Iason Kyriakopoulos, Yannis Theodoridis</li>
<li class=""><strong>institution:</strong> University of Piraeus</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17257" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17257</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper experimentally compares five time series forecasting models, including traditional statistical methods, machine learning, and deep learning (e.g., ARIMA, XGBoost, LSTM, GRU, Transformer), for predicting electric vehicle charging load. The evaluation across multiple real-world datasets, temporal horizons, and spatial aggregation levels shows that recurrent neural networks (GRU, LSTM) generally perform best for mid- and long-term forecasting, while Transformers excel in short-term forecasting at higher aggregation levels.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SHARP-QoS: Sparsely-gated Hierarchical Adaptive Routing for joint Prediction of QoS</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [hyperbolic convolution, Poincaré ball, adaptive feature-sharing, gated feature fusion, EMA-based loss balancing, multi-task learning, graph convolution networks]</li>
<li class=""><strong>authors:</strong> Suraj Kumar, Arvind Kumar, Soumi Chattopadhyay</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Indore</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17262" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17262</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes SHARP-QoS, a unified model for joint QoS prediction that uses hyperbolic convolution to extract hierarchical features, an adaptive feature-sharing mechanism with gated fusion, and an EMA-based loss balancing strategy. It demonstrates superior performance over single- and multi-task baselines across multiple datasets, effectively handling sparsity, outliers, and cold-start scenarios with moderate computational cost.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Theoretical Analysis of State Similarity Between Markov Decision Processes</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [bisimulation metric, generalized bisimulation metric, Markov decision process, policy transfer, state aggregation, sampling-based estimation]</li>
<li class=""><strong>authors:</strong> Zhenyu Tao, Wei Xu, Xiaohu You</li>
<li class=""><strong>institution:</strong> Southeast University, Purple Mountain Laboratories</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17265" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17265</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a Generalized Bisimulation Metric (GBSM) to measure state similarity between different Markov Decision Processes, establishing its fundamental mathematical properties. The authors leverage GBSM to theoretically analyze tasks like policy transfer and state aggregation, obtaining tighter performance bounds than previous methods. Numerical results validate the effectiveness of GBSM for multi-MDP scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [audit agents, attestation protocols, constrained reasoning, cryptographic attestation, symbolic methods, benchmark suite, verifiability]</li>
<li class=""><strong>authors:</strong> Abhivansh Gupta</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology, Roorkee</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17259" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17259</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a60caf6cec7c2ab0bdf36d4e5ba8513e86e73ba9dc3d215615ad6190a8df9091_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Verifiability-First architecture for LLM-based agents, integrating runtime attestations, lightweight audit agents for continuous verification, and challenge-response protocols for high-risk operations. It introduces the OPERA benchmark to evaluate the detectability and speed of remediation for misaligned behavior, shifting the focus from measuring the propensity for misalignment to ensuring reliable detection and control.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Alzheimer&#x27;s Disease Brain Network Mining</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical AI], [semi-supervised learning, optimal transport, label propagation, graph neural networks, Wasserstein distance]</li>
<li class=""><strong>authors:</strong> Alireza Moayedikia, Sara Fin</li>
<li class=""><strong>institution:</strong> Swinburne University of Technology, Monash University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17276" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17276</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MATCH-AD, a semi-supervised framework that combines deep representation learning, graph-based label propagation, and optimal transport theory to diagnose Alzheimer&#x27;s disease from neuroimaging data with limited labeled samples. The method achieves near-perfect diagnostic accuracy on a large dataset, demonstrating that semi-supervised learning can effectively leverage partially annotated data for clinical deployment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Understanding Generalization in Role-Playing Models via Information Theory</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [natural language processing], [information theory, mutual information, reinforcement learning, distribution shift, role-playing models]</li>
<li class=""><strong>authors:</strong> Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li</li>
<li class=""><strong>institution:</strong> Wuhan University, Tongyi Lab, Zhongguancun Academy</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17270" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17270</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Kolmogorov-Arnold Networks (KANs), multilayer perceptron networks (MLPs), Physics-informed Neural Networks, nonlocal consistency loss, integro-differential equations (IDEs), fractional PDEs]</li>
<li class=""><strong>authors:</strong> Farinaz Mostajeran, Aruzhan Tleubek, Salah A Faroughi</li>
<li class=""><strong>institution:</strong> University of Utah</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17273" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17273</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MINPO, a unified neural framework that learns nonlocal operators and their inverses using KANs or MLPs to solve integro-differential equations. It enforces coherence between the learned operator and solution via a nonlocal consistency loss. The method is shown to be accurate and robust across diverse kernel types and dimensionalities, generalizing beyond problem-specific formulations.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Warmer for Less: A Cost-Efficient Strategy for Cold-Start Recommendations at Pinterest</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [residual connection, score regularization, manifold mixup]</li>
<li class=""><strong>authors:</strong> Saeed Ebrahimi, Weijie Jiang, Jaewon Yang, Olafur Gudmundsson, Yucheng Tu, Huizhong Duan</li>
<li class=""><strong>institution:</strong> Pinterest</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17277" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17277</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f351bf91dbfa3f8f187d67a36cb3c88f1014690a13606c70e860bd376621c71f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f351bf91dbfa3f8f187d67a36cb3c88f1014690a13606c70e860bd376621c71f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a cost-efficient strategy to improve cold-start recommendations by introducing lightweight techniques: a residual connection for non-historical features, a score regularization term, and manifold mixup for data sparsity. These methods collectively increased fresh content engagement by 10% without harming overall engagement or cost, and have been deployed at Pinterest.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] LibriVAD: A Scalable Open Dataset with Deep Learning Benchmarks for Voice Activity Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [speech processing], [voice activity detection, vision transformer, MFCC, Gammatone filter bank cepstral coefficients, dataset augmentation, out-of-distribution evaluation]</li>
<li class=""><strong>authors:</strong> Ioannis Stylianou, Achintya kr. Sarkar, Nauman Dawalatabad, James Glass, Zheng-Hua Tan</li>
<li class=""><strong>institution:</strong> Aalborg University, Pioneer Centre for AI, IIIT SriCity, Zoom Communications Inc., Massachusetts Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17281" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17281</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LibriVAD, a scalable open dataset for voice activity detection (VAD) created by augmenting LibriSpeech with diverse noise sources. It benchmarks several feature-model combinations and proposes using a Vision Transformer (ViT) architecture for VAD. The main conclusion is that ViT with MFCC features outperforms established models across various conditions, and scaling the dataset size and balancing its silence-to-speech ratio consistently improves out-of-distribution generalization.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] M2RU: Memristive Minion Recurrent Unit for Continual Learning at the Edge</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [memristive architecture, minion recurrent unit, weighted-bit streaming, experience replay, mixed-signal accelerator, on-chip continual learning]</li>
<li class=""><strong>authors:</strong> Abdullah M. Zyarah, Dhireesha Kudithipudi</li>
<li class=""><strong>institution:</strong> University of Texas at San Antonio, University of Baghdad</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17299" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17299</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces M2RU, a mixed-signal hardware architecture that implements the Minion Recurrent Unit for efficient on-chip continual learning at the edge. It uses weighted-bit streaming and experience replay to enable energy-efficient temporal processing and stable adaptation. The results show significant energy efficiency improvements and a long operational lifetime, establishing M2RU as a scalable platform for edge-level temporal intelligence.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [explainable AI (XAI)], [graph theory, model decomposition, hypothesis-evidence structure, Cox proportional hazards model, PREDICT]</li>
<li class=""><strong>authors:</strong> Michael Merry, Pat Riddle, Jim Warren</li>
<li class=""><strong>institution:</strong> University of Auckland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17316" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17316</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a formal, testable criterion for inherent explainability in AI, using graph theory to decompose models into verifiable structure-local explanations called annotations. The method is applied to demonstrate the inherent explainability of a clinical cardiovascular risk model (PREDICT). The work provides a rigorous foundation for regulators and formalizes the distinction between an explainable model and an explained one.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Task Schema and Binding: A Double Dissociation Study of In-Context Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [in-context learning], [activation patching, double dissociation, task schema, binding, transformer, mamba]</li>
<li class=""><strong>authors:</strong> Chaeha Kim</li>
<li class=""><strong>institution:</strong> Changwon National University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17325" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17325</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses activation patching experiments across multiple Transformer models and Mamba to causally dissect in-context learning. It concludes that ICL decomposes into two separable mechanisms: Task Schema (abstract task recognition) and Binding (specific input-output associations), with their reliance governed by a trade-off with the model&#x27;s prior knowledge.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [adaptive graph pruning, Spatio-Temporal Graph Neural Networks (ST-GNNs), Sudden Event Prediction Accuracy (SEPA), online semi-decentralized training, Federated Learning (FL), Gossip Learning]</li>
<li class=""><strong>authors:</strong> Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas</li>
<li class=""><strong>institution:</strong> University of Zagreb, Faculty of Electrical Engineering and Computing; RISE Research Institutes of Sweden; KTH Royal Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17352</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a9feeec6bf4367fbf82a987484881d47da3c3be2e4b769373b648eb200942b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an adaptive graph pruning algorithm for Spatio-Temporal Graph Neural Networks (ST-GNNs) to reduce communication overhead in online semi-decentralized traffic prediction systems. It also introduces a novel evaluation metric, SEPA, to measure responsiveness to sudden traffic events. The method maintains prediction accuracy while significantly lowering communication costs across different decentralized learning settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [ensemble learning, adversarial training, Bayesian inference, LLM-based sample generation, weight assignment]</li>
<li class=""><strong>authors:</strong> Yidong Chai, Yi Liu, Mohammadreza Ebrahimi, Weifeng Li, Balaji Padmanabhan</li>
<li class=""><strong>institution:</strong> Hefei University of Technology, University of South Florida, University of Georgia, University of Maryland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17367</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a novel framework called LLM-SGA and instantiates a detector named ARHOCD, which uses an ensemble of base detectors, a dynamic Bayesian weight assignment method, and an iterative adversarial training strategy to improve robustness. The results show that ARHOCD achieves strong generalizability and improves detection accuracy for harmful online content under adversarial conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [adversarial control tokens, beam-search exploration, last-layer logit gap, LoRA-based adversarial training, reward hacking]</li>
<li class=""><strong>authors:</strong> Tung-Ling Li, Yuhao Wu, Hongliang Liu</li>
<li class=""><strong>institution:</strong> Palo Alto Networks</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17375" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17375</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces AdvJudge-Zero, a method that uses beam-search on a model&#x27;s next-token distribution to discover short, low-perplexity control token sequences that can flip the binary decisions of LLM-as-a-Judge systems from &quot;No&quot; to &quot;Yes&quot;. It concludes that these tokens represent a realistic reward-hacking vulnerability in post-training pipelines, and shows that adversarial training can mitigate the issue while preserving evaluation quality.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Timely Information Updating for Mobile Devices Without and With ML Advice</strong></p>
<ul>
<li class=""><strong>tags:</strong> [sys], [online scheduling], [competitive online algorithm, age of information, consistency-robustness trade-off, ML-augmented algorithm, adversarial environment]</li>
<li class=""><strong>authors:</strong> Yu-Pin Hsu, Yi-Hsuan Tseng</li>
<li class=""><strong>institution:</strong> National Taipei University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17381" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17381</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes an online algorithm for a mobile device to decide when to send status updates to an access point, balancing information timeliness and update cost. The algorithm achieves an optimal competitive ratio against adversarial uncertainties and, when augmented with machine learning advice, attains an optimal consistency-robustness trade-off. The main conclusion is that an optimal competitive algorithm exhibits a threshold-like response to ML advice, either fully trusting or completely ignoring it.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] DeepShare: Sharing ReLU Across Channels and Layers for Efficient Private Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Private Inference, ReLU sharing, DReLU, cryptographic protocols, activation sharing]</li>
<li class=""><strong>authors:</strong> Yonathan Bornfeld, Shai Avidan</li>
<li class=""><strong>institution:</strong> Tel Aviv University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17398" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17398</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f38ab38719abeec4c59d997e57b2ecf1dd76acec3485b40aa5ccef81258f3179_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f38ab38719abeec4c59d997e57b2ecf1dd76acec3485b40aa5ccef81258f3179_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces DeepShare, a method for efficient Private Inference (PI) that reduces computational costs by sharing the DReLU (the non-linear step function of ReLU) across channels and layers within a neural network. It achieves state-of-the-art results by drastically decreasing the number of expensive DReLU operations while maintaining model performance on tasks like classification and segmentation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] meval: A Statistical Toolbox for Fine-Grained Model Performance Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [stratified analysis, statistical methods, bias assessment, performance metrics, multiple comparisons correction, intersectional analysis]</li>
<li class=""><strong>authors:</strong> Dishantkumar Sutariya, Eike Petersen</li>
<li class=""><strong>institution:</strong> Fraunhofer Institute for Digital Medicine MEVIS</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17409" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17409</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper presents a statistical toolbox called &#x27;meval&#x27; designed for rigorous, fine-grained analysis of machine learning model performance across different subgroups. It addresses challenges like metric selection, uncertainty estimation, and multiple comparisons to identify performance disparities. The main conclusion is that this toolbox enables practitioners to easily detect potential biases and failure modes, particularly in medical imaging applications.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [SWE-Bench++, automated benchmark generation, pull request harvesting, environment synthesis, test oracle extraction, hint-guided trajectory synthesis, fine-tuning]</li>
<li class=""><strong>authors:</strong> Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe</li>
<li class=""><strong>institution:</strong> Turing</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17419" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17419</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-agent reinforcement learning, independent proximal policy optimization, agent-based modeling, electricity markets, capacity markets, contracts for difference]</li>
<li class=""><strong>authors:</strong> Javier Gonzalez-Ruiz, Carlos Rodriguez-Pardo, Iacopo Savelli, Alice Di Bella, Massimo Tavoni</li>
<li class=""><strong>institution:</strong> Politecnico di Milano, CMCC Foundation - Euro-Mediterranean Center on Climate Change, RFF-CMCC European Institute on Economics and the Environment, Bocconi University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17444" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17444</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a multi-agent reinforcement learning framework, using independent proximal policy optimization, to model investment decisions by generation companies in long-term electricity markets. The model is applied to a stylized Italian electricity system to test various market designs and policy scenarios. The results demonstrate that market design is critical for achieving decarbonization targets while mitigating price volatility.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MULTIAQUA: A multimodal maritime dataset and robust training strategies for multimodal semantic segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [multimodal semantic segmentation, deep neural network, robust training strategies, synchronized sensor data, daytime training for nighttime performance]</li>
<li class=""><strong>authors:</strong> Jon Muhovič, Janez Perš</li>
<li class=""><strong>institution:</strong> University of Ljubljana</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17450" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17450</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6eb14eac17bf3aa4e9ce145e08ce4eae06c5adaaf8ccf31ca3fa25a7f3835fa0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6eb14eac17bf3aa4e9ce145e08ce4eae06c5adaaf8ccf31ca3fa25a7f3835fa0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces MULTIAQUA, a multimodal maritime dataset with synchronized RGB, thermal, IR, and LIDAR data, and proposes robust training strategies for multimodal semantic segmentation. The core method enables training a deep neural network using only daytime images to achieve reliable performance in challenging conditions like near-complete darkness. The main conclusion is that this approach simplifies data acquisition and annotation while maintaining robust scene interpretation for unmanned surface vehicles.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [software defect prediction], [Explainable Boosting Machines, stratified interaction analysis, class imbalance, class overlap, irrelevant features, attribute noise, outliers]</li>
<li class=""><strong>authors:</strong> Emmanuel Charleson Dapaah, Jens Grabowski</li>
<li class=""><strong>institution:</strong> University of Göttingen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17460" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17460</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper conducts a large-scale empirical study using Explainable Boosting Machines and stratified interaction analysis to examine five co-occurring data quality issues in software defect prediction across 374 datasets. It finds that co-occurrence is nearly universal, identifies tipping points for issues like class overlap and imbalance, and reveals context-dependent effects, concluding that no single model performs best under all conditions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning What to Write: Write-Gated KV for Efficient Long-Context Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm inference], [KV cache management, Write-Gated KV, KV Admission, KV cache eviction, KV cache selection, FlashAttention, paged-KV systems]</li>
<li class=""><strong>authors:</strong> Yen-Chieh Huang, Rui Fang, Ming-Syan Chen, Pi-Cheng Hsiu</li>
<li class=""><strong>institution:</strong> National Taiwan University, Academia Sinica</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17452</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Write-Gated KV, a learnable KV Admission mechanism that predicts token utility before it enters the KV cache to reduce memory usage and speed up inference. By filtering low-utility tokens early and maintaining a compact global cache, the method significantly reduces memory usage and improves prefill and decode speeds for long-context LLMs with minimal accuracy loss. The results demonstrate that proactive KV cache management is a practical solution for efficient long-context inference.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [time series forecasting], [spatial-temporal graph neural network, trend-seasonal decomposition, low-rank Top-K adjacency learning, horizon-wise gating, linear baseline]</li>
<li class=""><strong>authors:</strong> Henok Tenaw Moges, Deshendran Moodley</li>
<li class=""><strong>institution:</strong> University of Cape Town</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17453" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17453</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e930d6ea2e25d38e443cede1cee5618870d8bd50e1307a179be023dcac63701d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Lite-STGNN, a lightweight model combining decomposition-based linear temporal modeling with a learnable sparse graph module for spatial corrections. It achieves state-of-the-art accuracy on long-term multivariate forecasting benchmarks while being parameter-efficient and faster than transformer-based methods. The learned adjacency matrices also provide interpretable insights into domain-specific variable interactions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [marketing personalisation], [randomised controlled trial, agentic messaging, rule-based campaign, causal inference, contextual bandits]</li>
<li class=""><strong>authors:</strong> Olivier Jeunen, Schaun Wheeler</li>
<li class=""><strong>institution:</strong> aampe</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17462</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper evaluates an agentic messaging approach for customer communication, comparing it against a traditional rule-based system in a financial service application via a randomized controlled trial. The results show that the agentic system reduced unsubscribe events by 21% and encouraged earlier tax filing, demonstrating its effectiveness in improving user engagement and retention.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Linear Attention for Joint Power Optimization and User-Centric Clustering in Cell-Free Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [transformer, linear attention, supervised learning, user-centric clustering, power optimization]</li>
<li class=""><strong>authors:</strong> Irched Chafaa, Giacomo Bacci, Luca Sanguinetti</li>
<li class=""><strong>institution:</strong> University of Pisa</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17466" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17466</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a lightweight transformer model with a customized linear attention mechanism to jointly predict access point clusters and transmission powers in user-centric cell-free massive MIMO networks, using only spatial coordinates. This approach eliminates channel estimation overhead and pilot contamination while ensuring linear scalability with the number of users. Numerical results show the model provides near-optimal performance in maximizing minimum spectral efficiency and is adaptable to dynamic network scenarios.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Translating the Rashomon Effect to Sequential Decision-Making Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential decision-making], [Rashomon effect, formal verification, policy ensembles, behavioral cloning, permissive policies]</li>
<li class=""><strong>authors:</strong> Dennis Gross, Jørn Eirik Betten, Helge Spieker</li>
<li class=""><strong>institution:</strong> University of Oslo</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17470" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17470</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper translates the Rashomon effect from classification to sequential decision-making by defining it for policies that behave identically but have different internal structures. It uses formal verification methods to compare the complete probabilistic behavior of policies in stochastic environments. The study concludes that the effect exists in this domain and that ensembles from the Rashomon set are more robust to distribution shifts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [BiLSTM-Variational Autoencoder, BiLSTM-Transformer, surrogate modelling, Norton creep law, self-attention, probabilistic prediction, deterministic prediction]</li>
<li class=""><strong>authors:</strong> Shubham Das, Kaushal Singhania, Amit Sadhu, Suprabhat Das, Arghya Nandi</li>
<li class=""><strong>institution:</strong> Jadavpur University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17477" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17477</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes deep learning-based surrogate models, specifically a BiLSTM-Variational Autoencoder and a BiLSTM-Transformer, to rapidly predict creep strain in Inconel 625, replacing computationally expensive finite-element simulations. The models, trained on ANSYS-generated data, achieve high accuracy and provide predictions within seconds compared to the 30-40 minutes required by traditional simulations, enabling faster design optimization and structural health monitoring for high-temperature alloys.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] TwinSegNet: A Digital Twin-Enabled Federated Learning Framework for Brain Tumor Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, digital twin, Vision Transformer, ViT-UNet, privacy-preserving AI, brain tumor segmentation]</li>
<li class=""><strong>authors:</strong> Almustapha A. Wakili, Adamu Hussaini, Abubakar A. Musa, Woosub Jung, Wei Yu</li>
<li class=""><strong>institution:</strong> Towson University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17488" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17488</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c12280225e186b761a6952a367a2b042a6fcd1886ac481e9bc15f5f81ee64a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67c12280225e186b761a6952a367a2b042a6fcd1886ac481e9bc15f5f81ee64a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes TwinSegNet, a federated learning framework that uses a hybrid ViT-UNet model and personalized digital twins for brain tumor segmentation without sharing raw data. It achieves high accuracy on heterogeneous MRI datasets, demonstrating that privacy can be preserved without sacrificing segmentation performance in multi-institutional settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multiple instance learning, AutoML, feature extraction, whole-slide images, benchmarking, computational pathology]</li>
<li class=""><strong>authors:</strong> Siemen Brussee, Pieter A. Valkema, Jurre A. J. Weijer, Thom Doeleman, Anne M.R. Schrader, Jesper Kers</li>
<li class=""><strong>institution:</strong> Leiden University Medical Center, Utrecht University Medical Center, Amsterdam University Medical Center</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17517" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17517</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces PathBench-MIL, an automated machine learning and benchmarking framework designed for Multiple Instance Learning in histopathology. It automates the entire pipeline from preprocessing to model aggregation, enabling standardized and reproducible evaluation of various models and feature extractors on whole-slide image datasets. The main conclusion is that this open-source framework facilitates rapid experimentation and standardization in computational pathology research.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [protein hazard screening], [homology clustering, cluster-level holdout, logistic regression, random forest, linear SVM, calibrated probabilities, AUROC, AUPRC, Brier score, Expected Calibration Error]</li>
<li class=""><strong>authors:</strong> Muhammad Haris Khan</li>
<li class=""><strong>institution:</strong> University of Copenhagen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17527</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SafeBench-Seq, a benchmark and baseline classifier for screening hazardous protein sequences using only interpretable physicochemical and compositional features. The method employs homology clustering at ≤40% identity with cluster-level holdouts to evaluate performance on novel threats. The main conclusion is that random data splits overestimate robustness compared to this stricter homology-controlled evaluation, and that calibrated linear models provide good probability calibration for this CPU-only screening task.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [neural network training algorithms], [Forward-Forward algorithm, Collaborative Forward-Forward, inter-layer cooperation, goodness function, neuromorphic computing]</li>
<li class=""><strong>authors:</strong> Salar Beigzad</li>
<li class=""><strong>institution:</strong> University of St. Thomas, Minnesota</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17531" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17531</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Collaborative Forward-Forward (CFF) learning, an enhancement to the Forward-Forward algorithm that addresses inter-layer isolation by incorporating weighted contributions from all layers into a collaborative goodness function. It proposes two variants, Fixed CFF and Adaptive CFF, which enable coordinated feature learning while preserving forward-only computation. The method demonstrates significant performance improvements on benchmark datasets, establishing inter-layer collaboration as a fundamental enhancement for biologically plausible and memory-efficient neural network training.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Bayesian Optimisation: Which Constraints Matter?</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [Bayesian optimisation], [Bayesian optimisation, Knowledge Gradient, Gaussian Processes, decoupled constraints, acquisition functions]</li>
<li class=""><strong>authors:</strong> Xietao Wang Lin, Juan Ungredda, Max Butler, James Town, Alma Rahat, Hemant Singh, Juergen Branke</li>
<li class=""><strong>institution:</strong> University of Warwick, ESTECO SpA, Swansea University, University of New South Wales</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17569" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17569</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes new Bayesian optimisation variants of the Knowledge Gradient acquisition function for problems with decoupled black-box constraints, focusing on evaluating only the most relevant constraints. The methods are empirically benchmarked and shown to be superior to existing state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [MetricGAN-plus-voicebank, semantic WER, noise robustness, speech enhancement]</li>
<li class=""><strong>authors:</strong> Sujal Chondhekar, Vasanth Murukuri, Rushabh Vasani, Sanika Goyal, Rajshree Badami, Anushree Rana, Sanjana SN, Karthik Pandia, Sulabh Katiyar, Neha Jagadeesh, Sankalp Gulati</li>
<li class=""><strong>institution:</strong> EkaCare (Orbi Health Private Limited)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17562</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper systematically evaluates the effect of MetricGAN-plus-voicebank speech enhancement on four modern ASR systems using medical speech under nine noise conditions. The study finds that denoising preprocessing consistently degrades ASR performance across all models and conditions, suggesting modern ASR models are inherently noise-robust and enhancement may remove critical acoustic features.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [vertical scheduling, optimizer step overlapping, SSD-offloaded training, gradient accumulation]</li>
<li class=""><strong>authors:</strong> Yikang Yue, Yishu Yin, Xuehai Qian</li>
<li class=""><strong>institution:</strong> Tsinghua University, University of Illinois at Urbana-Champaign</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17570" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17570</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces GreedySnake, a system that accelerates SSD-offloaded LLM training by using vertical scheduling to process all micro-batches per layer before moving to the next, and by overlapping the optimizer step with the next forward pass. This approach significantly reduces I/O bottlenecks and improves throughput compared to prior systems like ZeRO-Infinity, achieving up to 2.53x speedup for large models like GPT-175B.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [GPU-internal scheduling, resource sharing, collaborative multi-GPU video decoding, logically decoupled execution, FlashCodec, UnifiedServe]</li>
<li class=""><strong>authors:</strong> Lingxiao Zhao, Haoran Zhou, Yuezhi Che, Dazhao Cheng</li>
<li class=""><strong>institution:</strong> Wuhan University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17574" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17574</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65d961bcef453cdff273d0991a97111419acf476f8d34e21f66dbd356156dfa7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/65d961bcef453cdff273d0991a97111419acf476f8d34e21f66dbd356156dfa7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes FlashCodec and UnifiedServe, a framework that optimizes multimodal large language model (MLLM) serving by accelerating video decoding and enabling resource sharing across the vision and text stages. This approach reduces latency and eliminates inter-stage blocking, leading to significantly higher throughput and better SLO adherence compared to existing systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Sharing Knowledge without Sharing Data: Stitches can improve ensembles of disjointly trained models</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [federated learning, asynchronous collaboration, model stitching, ensembles, multi-objective learning]</li>
<li class=""><strong>authors:</strong> Arthur Guijt, Dirk Thierens, Ellen Kerkhof, Jan Wiersma, Tanja Alderliesten, Peter A.N. Bosman</li>
<li class=""><strong>institution:</strong> Not specified (inferred from author names only; no affiliations or email domains provided)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17592" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17592</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes using model stitching to combine disjointly trained deep learning models as an asynchronous alternative to federated learning, allowing collaboration without sharing raw data. The method inserts stitching layers to merge intermediate representations, improving generalization across different parties&#x27; datasets while maintaining competitive performance on each party&#x27;s own data. The results show that asynchronous collaboration through stitching can yield competitive performance without requiring synchronous training or data exchange.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Machine Learning for Static and Single-Event Dynamic Complex Network Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [graph representation learning], [latent space models, latent distance model, graph representation learning, network embeddings, static networks, dynamic networks]</li>
<li class=""><strong>authors:</strong> Nikolaos Nakis</li>
<li class=""><strong>institution:</strong> arXiv</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17577" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17577</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a74e4c69d21da3d9d39474c8e185aec564c37a98f7b8fa85563d3b895bd7a484_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a74e4c69d21da3d9d39474c8e185aec564c37a98f7b8fa85563d3b895bd7a484_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This thesis develops novel algorithmic approaches for graph representation learning using latent space models, specifically the latent distance model, to capture network characteristics like homophily and transitivity. It aims to create structural-aware network representations for tasks such as community characterization and impact dynamics quantification in temporal networks. The methods are designed as unified learning processes to avoid heuristics and multi-stage post-processing, advancing towards comprehensive and powerful network embeddings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Unified Representation of Neural Networks Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [neural networks theory], [continuous neural networks, neural ODEs, distributed parameter systems, approximation error, discretization]</li>
<li class=""><strong>authors:</strong> Christophe Prieur, Mircea Lazar, Bogdan Robu</li>
<li class=""><strong>institution:</strong> Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, Eindhoven University of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17593" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17593</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a unified representation of neural network architectures called Distributed Parameter neural Network (DiPaNet), derived by considering the limiting case where the number of neurons and layers tends to infinity. The method merges integral infinite-width representations with neural ODEs using homogenization and discretization techniques. The main conclusion is that most existing finite and infinite-dimensional neural network architectures can be related through this unified DiPaNet framework.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Gaussian Discriminant Analysis, Z-score distance analysis, cluster-driven deep learning, two-stage framework]</li>
<li class=""><strong>authors:</strong> Tosin Ige, Christopher Kiekintveld, Aritran Piplai, Asif Rahman, Olukunle Kolade, Sasidhar Kunapuli</li>
<li class=""><strong>institution:</strong> The University of Texas at El Paso, University of North Carolina</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17594" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17594</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes MAD-OOD, a two-stage cluster-driven deep learning framework for out-of-distribution malware detection. It uses Gaussian Discriminant Analysis to model class embeddings and Z-score distance analysis to identify anomalies, then integrates these predictions with a neural network for final classification. The method significantly outperforms state-of-the-art approaches on benchmark datasets, achieving high AUC for detecting unseen malware families.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] A Systems-Theoretic View on the Convergence of Algorithms under Disturbances</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [converse Lyapunov theorems, stability bounds, convergence rates, distributed learning, noise injection, disturbance modeling]</li>
<li class=""><strong>authors:</strong> Guner Dilsad Er, Sebastian Trimpe, Michael Muehlebach</li>
<li class=""><strong>institution:</strong> Max Planck Institute for Intelligent Systems, RWTH Aachen University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17598" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17598</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses converse Lyapunov theorems to derive stability bounds and convergence rates for iterative algorithms operating under disturbances. It provides a unifying framework to quantify how noise and interconnections affect algorithmic performance, with applications in distributed learning and privacy-preserving computation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning Safe Autonomous Driving Policies Using Predictive Safety Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [safe reinforcement learning], [safe reinforcement learning, predictive safety representations, constrained markov decision processes, waymo open motion dataset, nuplan, srpl]</li>
<li class=""><strong>authors:</strong> Mahesh Keswani, Raunak Bhattacharyya</li>
<li class=""><strong>institution:</strong> Indian Institute of Technology Delhi</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17586" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17586</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40dd4c52ca67a3f1ecc6ec7068de338a3616940aa4e51935c5ce5f30430ebbfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40dd4c52ca67a3f1ecc6ec7068de338a3616940aa4e51935c5ce5f30430ebbfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the Safety Representations for Safer Policy Learning (SRPL) framework, which augments SafeRL agents with a predictive model of future constraint violations to improve the safety-performance trade-off in autonomous driving. Experiments on real-world datasets (Waymo Open Motion Dataset and NuPlan) show that SRPL can lead to statistically significant improvements in success rate and cost reduction, and enhances robustness to noise and generalization in cross-dataset evaluation.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] More Consistent Accuracy PINN via Alternating Easy-Hard Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [scientific machine learning], [physics-informed neural networks, easy-hard prioritization, hybrid training strategy, alternating scheme]</li>
<li class=""><strong>authors:</strong> Zhaoqian Gao, Min Yanga</li>
<li class=""><strong>institution:</strong> Yantai University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17607</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a hybrid training strategy for Physics-Informed Neural Networks (PINNs) that alternates between easy and hard prioritization to improve performance. The method achieves consistently high accuracy on challenging PDEs, significantly outperforming baseline approaches. The work demonstrates that this alternating scheme enhances the robustness and reliability of PINNs across diverse problem types.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SCOPE: Sequential Causal Optimization of Process Interventions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [prescriptive process monitoring], [backward induction, causal learning, reinforcement learning, sequential decision-making]</li>
<li class=""><strong>authors:</strong> Jakob De Moor, Hans Weytjens, Johannes De Smedt, Jochen De Weerdt</li>
<li class=""><strong>institution:</strong> KU Leuven, Technical University of Munich (TUM)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17629" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17629</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces SCOPE, a prescriptive process monitoring approach that uses backward induction and causal learning to recommend aligned sequences of interventions for optimizing key performance indicators. It directly leverages observational data without needing process approximations for reinforcement learning. Experiments show SCOPE outperforms existing techniques in optimizing KPIs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [natural language processing], [ensemble learning, weighted voting, Condorcet’s Jury Theorem, fine-tuning, transformer models]</li>
<li class=""><strong>authors:</strong> Menna Elgabry, Ali Hamdi</li>
<li class=""><strong>institution:</strong> MSA University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17630" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17630</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a confidence- and credibility-weighted ensemble framework using diverse small transformer models (BERT, RoBERTa, etc.) for emotion detection. The method combines global validation performance and instance-level confidence to weight model votes. The ensemble achieves a 93.5% macro F1-score on the DAIR-AI dataset, outperforming larger LLMs while being more parameter-efficient.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Trust-Region Adaptive Policy Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [post-training], [Trust-Region Adaptive Policy Optimization, Trust-Region SFT, forward KL divergence, reverse KL, adaptive prefix-selection, supervised fine-tuning, reinforcement learning]</li>
<li class=""><strong>authors:</strong> Mingyu Su, Jian Guan, Yuxian Gu, Minlie Huang, Hongning Wang</li>
<li class=""><strong>institution:</strong> Tsinghua University, Ant Group</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17636" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17636</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a948c761d13b2b79a39ce9d5e992677a2054a69ebce16f21dcf30264ab34a82f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces TRAPO, a hybrid framework that interleaves supervised fine-tuning and reinforcement learning within each training instance to unify expert supervision and self-exploration. It stabilizes training with Trust-Region SFT and an adaptive prefix-selection mechanism. Experiments on mathematical reasoning benchmarks show TRAPO outperforms standard pipelines and state-of-the-art approaches.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Estimating Spatially Resolved Radiation Fields Using Neural Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [Monte-Carlo Simulation, Geant4, Convolutional Neural Networks, Fully Connected Neural Networks, U-Net, FCNN, Dataset Generation]</li>
<li class=""><strong>authors:</strong> Felix Lehner, Pasquale Lombardo, Susana Castillo, Oliver Hupe, Marcus Magnor</li>
<li class=""><strong>institution:</strong> Physikalisch-Technische Bundesanstalt (PTB), Technical University Braunschweig, Belgian Nuclear Research Centre (SCK CEN), University of New Mexico, Leibniz University Hannover</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17654" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17654</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper uses neural networks, including convolutional and fully connected architectures, to estimate spatial radiation fields for medical dosimetry, trained on synthetic datasets generated via Monte-Carlo simulations with Geant4. It evaluates design decisions for reconstructing fluence and spectra distributions, concluding with open-source release of datasets and training pipelines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Polyharmonic Cascade</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [deep learning architecture], [polyharmonic cascade, polyharmonic splines, random functions, principles of indifference, global linear system, GPU matrix operations]</li>
<li class=""><strong>authors:</strong> Yuriy N. Bakhvalov</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17671" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17671</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces the &quot;polyharmonic cascade,&quot; a deep learning architecture built from packages of polyharmonic splines, derived from random function theory and principles of indifference. It proposes a training method that solves a global linear system per batch instead of using gradient descent, enabling synchronized layer updates and efficient GPU computation. The method demonstrates fast learning without overfitting on the MNIST dataset.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Vidarc: Embodied Video Diffusion Model for Closed-loop Control</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion inference], [video diffusion, autoregressive generation, masked inverse dynamics model, closed-loop control, cross-embodiment pre-training, KV cache]</li>
<li class=""><strong>authors:</strong> Yao Feng, Chendong Xiang, Xinyi Mao, Hengkai Tan, Zuyue Zhang, Shuhe Huang, Kaiwen Zheng, Haitian Liu, Hang Su, Jun Zhu</li>
<li class=""><strong>institution:</strong> Tsinghua University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17661" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17661</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7977f39cb797f71021c4776c090587d8f5e8e7c33c06e677b445877e8ad4c5d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7977f39cb797f71021c4776c090587d8f5e8e7c33c06e677b445877e8ad4c5d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Vidarc, a method for robotic control that combines an autoregressive video diffusion model with a masked inverse dynamics model to enable fast, closed-loop operation. It is pre-trained on a large dataset of diverse robotic episodes and achieves state-of-the-art performance, including higher success rates and significantly lower latency compared to baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] You Only Train Once: Differentiable Subset Selection for Omics Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [bioinformatics], [differentiable subset selection, multi-task learning, end-to-end training, sparsity, single-cell RNA-seq]</li>
<li class=""><strong>authors:</strong> Daphné Chopard, Jorge da Silva Gonçalves, Irene Cannistraci, Thomas M. Sutter, Julia E. Vogt</li>
<li class=""><strong>institution:</strong> ETH Zurich, University Children’s Hospital Zurich</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17678" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17678</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces YOTO, an end-to-end framework that jointly selects discrete gene subsets and performs prediction in a single differentiable model, using sparsity and multi-task learning. It demonstrates improved predictive performance and yields compact, meaningful gene subsets on single-cell RNA-seq datasets, advancing biomarker discovery.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Spatially-informed transformers: Injecting geostatistical covariance biases into self-attention for spatio-temporal forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [spatio-temporal forecasting], [transformer, self-attention, geostatistical covariance, Gaussian processes, spatial decay parameters]</li>
<li class=""><strong>authors:</strong> Yuri Calleo</li>
<li class=""><strong>institution:</strong> Universitas Mercatorum</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17696" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17696</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a spatially-informed transformer that injects a learnable geostatistical covariance kernel into the self-attention mechanism to incorporate spatial distance information for spatio-temporal forecasting. The method decomposes attention into a stationary physical prior and a data-driven residual, allowing the network to recover spatial decay parameters. Experiments show it outperforms graph neural networks and provides well-calibrated probabilistic forecasts.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Mitigating Forgetting in Low Rank Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [LoRA, Laplace approximation, catastrophic forgetting, regularization, parameter-efficient fine-tuning]</li>
<li class=""><strong>authors:</strong> Joanna Sliwa, Frank Schneider, Philipp Hennig, Jose Miguel Hernandez-Lobato</li>
<li class=""><strong>institution:</strong> University of Tübingen, University of Cambridge</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17720</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces LaLoRA, a method that applies a Laplace approximation to LoRA weights to estimate parameter confidence and regularize updates, mitigating catastrophic forgetting during fine-tuning. The approach improves the learning-forgetting trade-off for large language models, as demonstrated by fine-tuning a Llama model for mathematical reasoning, while remaining computationally lightweight.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Convergence Guarantees for Federated SARSA with Local Training and Heterogeneous Agents</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [reinforcement learning], [federated learning, SARSA, linear function approximation, convergence analysis, heterogeneous agents, local training]</li>
<li class=""><strong>authors:</strong> Paul Mangold, Eloïse Berthier, Eric Moulines</li>
<li class=""><strong>institution:</strong> CNRS, École polytechnique, Institut Polytechnique de Paris, ENSTA, Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17688" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17688</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper presents a theoretical analysis of Federated SARSA (FedSARSA), an on-policy reinforcement learning algorithm with linear function approximation and local training across heterogeneous agents. It establishes the first convergence guarantees and complexity bounds for this setting, showing that FedSARSA achieves linear speed-up with the number of agents despite heterogeneity in transitions and rewards.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [graph neural networks], [ECHO benchmark, long-range propagation, message-passing, over-smoothing, over-squashing, synthetic graph tasks, molecular property prediction]</li>
<li class=""><strong>authors:</strong> Luca Miglior, Matteo Tolloso, Alessio Gravina, Davide Bacciu</li>
<li class=""><strong>institution:</strong> University of Pisa</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17762" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17762</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces ECHO, a benchmark designed to evaluate the ability of Graph Neural Networks (GNNs) to handle long-range information propagation. It includes synthetic tasks and real-world molecular datasets to test GNNs on challenging, long-distance dependencies. The benchmarking reveals significant performance gaps in existing GNNs, highlighting the difficulty of long-range propagation and the need for improved architectural designs.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [llm training], [Easy Adaptation, Parameter-Efficient Fine-Tuning, LoRA, Specific Small Models, task adaptation, resource-constrained]</li>
<li class=""><strong>authors:</strong> Dong Chen, Zhengqing Hu, Shixing Zhao, Yibo Guo</li>
<li class=""><strong>institution:</strong> Not explicitly provided in the given text.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17771" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17771</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes Easy Adaptation (EA), a method that uses Specific Small Models (SSMs) to complement the data distribution for Large Models, enabling task adaptation without accessing the LM&#x27;s internal parameters. This approach matches the performance of Parameter-Efficient Fine-Tuning (PEFT) like LoRA on diverse tasks while requiring only minimal computational resources, making it suitable for resource-constrained environments.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Exploiting ID-Text Complementarity via Ensembling for Sequential Recommendation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [sequential recommendation], [ensembling, ID embeddings, text embeddings, modality features]</li>
<li class=""><strong>authors:</strong> Liam Collins, Bhuvesh Kumar, Clark Mingxuan Ju, Tong Zhao, Donald Loveland, Leonardo Neves, Neil Shah</li>
<li class=""><strong>institution:</strong> Snap Inc.</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17820" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17820</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a sequential recommendation method that independently trains ID-based and text-based models and then combines them via a simple ensembling strategy. It demonstrates that ID and text features learn complementary signals. The main conclusion is that both feature types are necessary for state-of-the-art performance, but complex fusion architectures are not required.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Calibratable Disambiguation Loss for Multi-Instance Partial-Label Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [weakly supervised learning], [multi-instance partial-label learning, calibratable disambiguation loss, model calibration]</li>
<li class=""><strong>authors:</strong> Wei Tang, Yin-Fang Yang, Weijia Zhang, Min-Ling Zhang</li>
<li class=""><strong>institution:</strong> Southeast University, The University of Newcastle</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17788" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17788</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec09016ca3c7c620b69a1f11fd5eac67d6cf0e41b74b5709b9e32e919c36ac8f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec09016ca3c7c620b69a1f11fd5eac67d6cf0e41b74b5709b9e32e919c36ac8f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a plug-and-play Calibratable Disambiguation Loss (CDL) to improve classification accuracy and model calibration in Multi-Instance Partial-Label Learning. The loss has two instantiations that calibrate predictions using candidate label probabilities or both candidate and non-candidate sets. Experimental results show that CDL significantly enhances both classification and calibration performance over conventional methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Distributionally Robust Imitation Learning: Layered Control Architecture for Certifiable Autonomy</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [imitation learning, distributionally robust control, layered control architecture, Taylor Series Imitation Learning (TaSIL), L1-Distributionally Robust Adaptive Control (L1-DRAC), certifiable autonomy]</li>
<li class=""><strong>authors:</strong> Aditya Gahlawat, Ahmed Aboudonia, Sandeep Banik, Naira Hovakimyan, Nikolai Matni, Aaron D. Ames, Gioele Zardini, Alberto Speranzon</li>
<li class=""><strong>institution:</strong> University of Illinois Urbana-Champaign, University of Pennsylvania, California Institute of Technology, Massachusetts Institute of Technology, Lockheed Martin</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17899" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17899</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a Distributionally Robust Imitation Policy (DRIP) architecture, a layered control framework that integrates Taylor Series Imitation Learning (TaSIL) and L1-Distributionally Robust Adaptive Control (L1-DRAC) to address different sources of distribution shift. The main conclusion is that this integration enables the design of certifiable autonomy pipelines by guaranteeing performance certificates for the entire control system, combining learning-based components with model-based decision-making.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [generative modeling], [Wasserstein-Fisher-Rao gradient flow, weighted stochastic differential equations, Feynman-Kac representation, score-based diffusion models, Langevin dynamics]</li>
<li class=""><strong>authors:</strong> Herlock Rahimi</li>
<li class=""><strong>institution:</strong> Yale University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17878" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17878</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a new sampling method for generative modeling by implementing Wasserstein-Fisher-Rao gradient flow via weighted stochastic differential equations, using the Feynman-Kac representation. This approach aims to overcome the slow mixing rates of traditional diffusion models in non-log-concave, multimodal target distributions by incorporating controlled mass reweighting. The study provides a rigorous geometric and operator-theoretic foundation for future developments in this area.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Regularized Random Fourier Features and Finite Element Reconstruction for Operator Learning in Sobolev Space</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [operator learning], [random Fourier features, Tikhonov regularization, finite element reconstruction, Student&#x27;s t distribution]</li>
<li class=""><strong>authors:</strong> Xinyue Yu, Hayden Schaeffer</li>
<li class=""><strong>institution:</strong> University of California, Los Angeles</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17884" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17884</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a regularized random Fourier feature method combined with finite element reconstruction (RRFF-FEM) for learning operators from noisy data, using Student&#x27;s t-distributed random features and frequency-weighted regularization. It proves theoretical guarantees on conditioning and generalization when features scale appropriately. Numerical experiments on PDE problems show the method is robust to noise, faster to train, and maintains competitive accuracy compared to kernel and neural operator baselines.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Visually Prompted Benchmarks Are Surprisingly Fragile</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [visual prompting, benchmark evaluation, vision-language models, visual marker design, JPEG compression, dataset size, VPBench]</li>
<li class=""><strong>authors:</strong> Haiwen Feng, Long Lian, Lisa Dunlap, Jiahao Shu, XuDong Wang, Renhao Wang, Trevor Darrell, Alane Suhr, Angjoo Kanazawa</li>
<li class=""><strong>institution:</strong> UC Berkeley</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17875" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17875</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1578e85cb159e2bf39916b0de61ec0b774772fc5c07fb3edc1f869eea3ea32e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1578e85cb159e2bf39916b0de61ec0b774772fc5c07fb3edc1f869eea3ea32e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper evaluates vision-language models (VLMs) on visually prompted benchmarks, where questions refer to coordinates marked directly on images. It finds that model performance and leaderboard rankings are surprisingly fragile to minor changes in visual marker design (e.g., color, size) and low-level inference settings like JPEG compression. To address this instability, the authors introduce VPBench, a larger benchmark with multiple visual marker variants.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] RadarGen: Automotive Radar Point Cloud Generation from Cameras</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [diffusion model, bird&#x27;s-eye-view, radar cross section, Doppler, point cloud generation, foundation models]</li>
<li class=""><strong>authors:</strong> Tomer Borreda, Fangqiang Ding, Sanja Fidler, Shengyu Huang, Or Litany</li>
<li class=""><strong>institution:</strong> Technion, MIT, NVIDIA, University of Toronto, Vector Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17897" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17897</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/42fca94c46885d829dda241902549fc6761186740477806e7cc7cc1b8d19368a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RadarGen is a diffusion model that generates realistic automotive radar point clouds from multi-view camera images by representing radar data in bird&#x27;s-eye-view and conditioning on visual cues. It uses a lightweight recovery step to reconstruct point clouds from the generated maps. Evaluations show it captures real radar statistics and reduces the performance gap for perception models trained on synthetic data.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Disentangled representations via score-based variational autoencoders</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [representation learning], [variational autoencoder, diffusion models, score-based guidance, disentanglement, evidence lower bound]</li>
<li class=""><strong>authors:</strong> Benjamin S. H. Lyo, Eero P. Simoncelli, Cristina Savin</li>
<li class=""><strong>institution:</strong> New York University, Flatiron Institute</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17127" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17127</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SAMI, a method that combines diffusion models and variational autoencoders into a unified framework for unsupervised representation learning. It uses score-based guidance to learn disentangled, semantically meaningful latent representations from data. The results show that this approach can make implicit structural information in diffusion models explicit and interpretable.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Colormap-Enhanced Vision Transformers for MRI-Based Multiclass (4-Class) Alzheimer&#x27;s Disease Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal inference], [Vision Transformers, Pseudo-Color Enhancement, MRI, Multi-Class Classification]</li>
<li class=""><strong>authors:</strong> Faisal Ahmed</li>
<li class=""><strong>institution:</strong> Embry-Riddle Aeronautical University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.16964" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.16964</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes PseudoColorViT-Alz, a method that enhances MRI scans with pseudo-color transformations and processes them using a Vision Transformer for Alzheimer&#x27;s disease classification. The model achieves state-of-the-art accuracy of 99.79% on the OASIS-1 dataset, demonstrating that combining color augmentation with Vision Transformers significantly improves classification performance over previous methods.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computer vision], [test-time refinement, self-supervised learning, shape from shading, score distillation sampling, monocular depth estimation, diffusion models]</li>
<li class=""><strong>authors:</strong> Ananta R. Bhattarai, Helge Rhodin</li>
<li class=""><strong>institution:</strong> Bielefeld University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17908" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17908</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abb5eab47c4353057728b3e9889e13b412f6c11ae6703f713d247c4724fbb909_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces Re-Depth Anything, a test-time self-supervision framework that refines monocular depth predictions by re-lighting the geometry and using a 2D diffusion model&#x27;s priors via Score Distillation Sampling. It updates only specific model embeddings and the decoder to prevent collapse, rather than fine-tuning the entire network. The method shows substantial improvements in depth accuracy and realism over the baseline Depth Anything V2 model.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Graph Attention Networks for Detecting Epilepsy from EEG Signals Using Accessible Hardware in Low-Resource Settings</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [graph attention networks, electroencephalography, spatio-temporal graphs, edge analysis, low-cost hardware, RaspberryPi]</li>
<li class=""><strong>authors:</strong> Szymon Mazurek, Stephen Moore, Alessandro Crimi</li>
<li class=""><strong>institution:</strong> AGH University of Krakow, University of Cape Coast</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2507.15118" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2507.15118</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d57b4723f1c065c80f840b86af58e96a683cea596741b961e8c90f8c5680da8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a graph attention network (GAT) framework that models EEG signals as spatio-temporal graphs to detect epilepsy, with a focus on low-cost hardware for deployment in low-resource settings. The method adapts GATs to analyze edge connectivity for biomarker identification and is designed for lightweight training and deployment. The results demonstrate promising classification performance and highlight the potential for scalable, accessible diagnostic support in underserved regions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Application of machine learning to predict food processing level using Open Food Facts</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [food science and nutrition informatics], [LightGBM, Random Forest, CatBoost, NOVA classification, nutrient concentration data]</li>
<li class=""><strong>authors:</strong> Nalin Arora, Aviral Chauhan, Siddhant Rana, Mahansh Aditya, Sumit Bhagat, Aditya Kumar, Akash Kumar, Akanksh Semar, Ayush Vikram Singh, Ganesh Bagler</li>
<li class=""><strong>institution:</strong> Indraprastha Institute of Information Technology Delhi (IIIT-Delhi), Infosys Center for Artificial Intelligence, Center of Excellence in Healthcare, Foodoscope Technologies Pvt Ltd</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17169" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17169</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This study applies machine learning models, including LightGBM, Random Forest, and CatBoost, to classify food processing levels (NOVA) using nutrient data from the Open Food Facts dataset. The best-performing model, LightGBM, achieved 80-85% accuracy and effectively distinguished minimally from ultra-processed foods. The research concludes that higher processing levels are strongly associated with poorer nutritional quality, greater environmental impact, and common allergens like gluten and milk.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [multi-layer graph, GNN, temporal GNN, logistic regression, Random Forest, correlation-based, systemic risk]</li>
<li class=""><strong>authors:</strong> Sandeep Neela</li>
<li class=""><strong>institution:</strong> Independent Researcher</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17185" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17185</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces the Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility. It demonstrates that graph-derived features from this model provide useful early-warning signals for market crashes, outperforming standard feature-based models.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Penalized Fair Regression for Multiple Groups in Chronic Kidney Disease</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [fair machine learning], [penalized regression, cost-sensitive classification, true positive rate disparity penalties]</li>
<li class=""><strong>authors:</strong> Carter H. Nakamoto, Lucia Lushi Chen, Agata Foryciarz, Sherri Rose</li>
<li class=""><strong>institution:</strong> Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17340" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17340</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a penalized fair regression framework using unfairness penalties for multiple groups, implemented via reduction to cost-sensitive classification. The method is applied to predict end-stage renal disease in a chronic kidney disease study, showing substantial fairness improvements for multiple race and ethnicity groups without appreciable loss in overall model fit.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Alternating Direction Method of Multipliers for Nonlinear Matrix Decompositions</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [optimization algorithms], [alternating direction method of multipliers, nonlinear matrix decomposition, rectified linear unit, component-wise square, MinMax transform]</li>
<li class=""><strong>authors:</strong> Atharva Awari, Nicolas Gillis, Arnaud Vandaele</li>
<li class=""><strong>institution:</strong> University of Mons</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17473" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17473</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes an ADMM-based algorithm for solving nonlinear matrix decompositions, where a matrix is approximated via a nonlinear function applied to a low-rank product. It demonstrates flexibility across various nonlinear models and loss functions, showing applicability to real-world datasets in areas like sparse data approximation and recommender systems.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Resource-efficient medical image classification for edge devices</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [post-training], [quantization, quantization-aware training, post-training quantization, convolutional neural networks]</li>
<li class=""><strong>authors:</strong> Mahsa Lavaei, Zahra Abadi, Salar Beigzad, Alireza Maleki</li>
<li class=""><strong>institution:</strong> University of Tehran, Tehran University, University of St. Thomas, Minnesota</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17515" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17515</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates a resource-efficient approach for medical image classification on edge devices using model quantization techniques, specifically quantization-aware training (QAT) and post-training quantization (PTQ). The study demonstrates that quantized models achieve significant reductions in model size and inference latency while maintaining clinically acceptable diagnostic accuracy, enabling real-time processing in resource-limited settings.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Machine Learning Assisted Parameter Tuning on Wavelet Transform Amorphous Radial Distribution Function</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [wavelet-transform radial distribution function (WT-RDF), parameter optimization, machine learning, RBF, LSTM]</li>
<li class=""><strong>authors:</strong> Deriyan Senjaya, Stephen Ekaputra Limantoro</li>
<li class=""><strong>institution:</strong> National Tsing Hua University, National Yang Ming Chiao Tung University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17245" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17245</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0fcb546d51f53548e0556b6cedd431012b18af3f725ab1ca0c73a63485285ea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0fcb546d51f53548e0556b6cedd431012b18af3f725ab1ca0c73a63485285ea_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper enhances the wavelet-transform radial distribution function (WT-RDF) for analyzing amorphous materials by using machine learning to optimize its parameters, creating the WT-RDF+ framework. The improved model provides more accurate peak predictions and outperforms benchmark ML models like RBF and LSTM, demonstrating its robustness for characterizing Ge-Se amorphous systems and aiding in the design of phase-change thin films.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Perfect reconstruction of sparse signals using nonconvexity control and one-step RSB message passing</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [compressed sensing, sparse signal reconstruction], [SCAD penalty, approximate message passing, replica symmetry breaking, state evolution, nonconvexity control]</li>
<li class=""><strong>authors:</strong> Xiaosi Gu, Ayaka Sakata, Tomoyuki Obuchi</li>
<li class=""><strong>institution:</strong> Kyoto University, RIKEN center for AIP, Ochanomizu University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17426" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17426</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper develops a one-step replica-symmetry-breaking extension of approximate message passing (1RSB-AMP) for sparse signal reconstruction using the SCAD penalty. The authors propose a new criterion for selecting the Parisi parameter and combine it with nonconvexity control, which improves the algorithmic limit for perfect reconstruction compared to the replica-symmetric AMP, though the gain is modest and remains below the Bayes-optimal threshold.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Sharp Structure-Agnostic Lower Bounds for General Functional Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [causal inference], [structure-agnostic estimation, double machine learning, debiased learning, doubly robust learning, nuisance functions, functional estimation]</li>
<li class=""><strong>authors:</strong> Jikai Jin, Vasilis Syrgkanis</li>
<li class=""><strong>institution:</strong> Stanford University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17341" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17341</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper establishes sharp lower bounds for structure-agnostic functional estimation, analyzing the optimal error rates achievable without imposing structural priors. It shows that doubly robust learning and double machine learning (DML) are optimal for a general class of functionals, including the average treatment effect (ATE), across different regimes of double robustness. The results provide theoretical validation for first-order debiasing methods and guidance for practitioners in the absence of strong structural assumptions.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] HydroGym: A Reinforcement Learning Platform for Fluid Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [reinforcement learning, flow control, differentiable solvers, transfer learning, benchmark platform]</li>
<li class=""><strong>authors:</strong> Christian Lagemann, Sajeda Mokbel, Miro Gondrum, Mario Rüttgers, Jared Callaham, Ludger Paehler, Samuel Ahnert, Nicholas Zolman, Kai Lagemann, Nikolaus Adams, Matthias Meinke, Wolfgang Schröder, Jean-Christophe Loiseau, Esther Lagemann, Steven L. Brunton</li>
<li class=""><strong>institution:</strong> University of Washington, RWTH Aachen University, Inha University, Technical University of Munich, German Center for Neurodegenerative Diseases, Arts et Métiers Institute of Technology</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17534" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17534</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/11a2356fa2a2cafe6887d85b978c67e18494f41d547e787460e381132d0f9508_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper introduces HydroGym, a reinforcement learning platform designed for fluid dynamics control, featuring both non-differentiable and differentiable solvers to improve sample efficiency. The platform includes 42 validated environments and demonstrates that RL agents can discover robust control principles, achieving significant drag reduction and efficient adaptation to new conditions via transfer learning.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Generative Multi-Objective Bayesian Optimization with Scalable Batch Evaluations for Sample-Efficient De Novo Molecular Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [molecular design], [Bayesian optimization, generative models, multi-objective optimization, acquisition function, qPMHI, Monte Carlo sampling]</li>
<li class=""><strong>authors:</strong> Madhav R. Muthyala, Farshud Sorourifar, Tianhong Tan, You Peng, Joel A. Paulson</li>
<li class=""><strong>institution:</strong> University of Wisconsin–Madison, The Ohio State University, The Dow Chemical Company</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17659" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17659</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a &quot;generate-then-optimize&quot; framework for de novo molecular design, which uses a generative model to create candidate molecules and a novel acquisition function called qPMHI to efficiently select batches for evaluation. The method demonstrates significant improvements over existing approaches in sample efficiency and performance, as shown in benchmarks and a case study on designing organic cathode materials for batteries.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Imputation Uncertainty in Interpretable Machine Learning Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [interpretable machine learning], [permutation feature importance, partial dependence plots, Shapley values, single imputation, multiple imputation, imputation uncertainty, confidence intervals]</li>
<li class=""><strong>authors:</strong> Pegah Golchian, Marvin N. Wright</li>
<li class=""><strong>institution:</strong> Leibniz Institute for Prevention Research &amp; Epidemiology – BIPS, University of Bremen</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17689" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17689</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the impact of missing data imputation methods on the uncertainty quantification of interpretable machine learning (IML) methods. It compares single and multiple imputation, showing that single imputation underestimates variance in IML explanations, while multiple imputation provides confidence interval coverage closer to the nominal level.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] SkinGenBench: Generative Model and Preprocessing Effects for Synthetic Dermoscopic Augmentation in Melanoma Diagnosis</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [diffusion training], [StyleGAN2-ADA, Denoising Diffusion Probabilistic Models (DDPMs), FID, KID, Inception Score, ViT-B/16, synthetic data augmentation]</li>
<li class=""><strong>authors:</strong> N. A. Adarsh Pritam, Jeba Shiney O, Sanyam Jain</li>
<li class=""><strong>institution:</strong> Alliance University, Østfold University College</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17585" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17585</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/497a14da92ec4e58a3716d9bb6044a8b43d59d0f8ab0aff8c6e70b0d8e5325c9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/497a14da92ec4e58a3716d9bb6044a8b43d59d0f8ab0aff8c6e70b0d8e5325c9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces SkinGenBench, a benchmark that evaluates the effects of generative models (StyleGAN2-ADA and DDPMs) and preprocessing pipelines on synthetic dermoscopic image generation for melanoma diagnosis. The main conclusion is that the choice of generative architecture has a stronger impact on image quality and diagnostic utility than preprocessing complexity, with StyleGAN2-ADA outperforming diffusion models in fidelity, and synthetic augmentation significantly boosting downstream classifier performance.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Revisiting the Broken Symmetry Phase of Solid Hydrogen: A Neural Network Variational Monte Carlo Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [computational physics], [neural network variational Monte Carlo, quantum Monte Carlo, deep neural network wave function, constant pressure ensemble, density functional theory, group-theoretical analysis]</li>
<li class=""><strong>authors:</strong> Shengdu Chai, Chen Lin, Xinyang Dong, Yuqiang Li, Wanli Ouyang, Lei Wang, X.C. Xie</li>
<li class=""><strong>institution:</strong> Fudan University, Shanghai Artificial Intelligence Laboratory, University of Oxford, Chinese Academy of Sciences, Peking University, Hefei National Laboratory</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17703" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17703</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper develops a neural network variational Monte Carlo method to treat electrons and nuclei quantum mechanically, revealing a new Cmcm crystal structure candidate for high-pressure solid hydrogen. This structure matches experimental data but is unstable in static DFT calculations, highlighting the need for full quantum many-body treatment.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Domain-Aware Quantum Circuit for QML</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [quantum machine learning], [parameterized quantum circuits, domain-aware encoding, locality-preserving entanglement, barren plateau mitigation, DCT-style zigzag windows, encode-entangle-train cycles]</li>
<li class=""><strong>authors:</strong> Gurinder Singh, Thaddeus Pellegrini, Kenneth M. Merz Jr</li>
<li class=""><strong>institution:</strong> Cleveland Clinic, IBM Quantum</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17800" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17800</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces a Domain-Aware Quantum Circuit (DAQC) for quantum machine learning, which uses image priors to guide locality-preserving encoding and entanglement via non-overlapping zigzag windows. The method mitigates barren plateaus and hardware noise, achieving performance on real quantum hardware competitive with strong classical neural networks for image classification tasks.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Breast Cancer Neoadjuvant Chemotherapy Treatment Response Prediction Using Aligned Longitudinal MRI and Clinical Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> [ai], [medical imaging], [image registration, radiomics, deep learning, logistic regression, feature selection]</li>
<li class=""><strong>authors:</strong> Rahul Ravi, Ruizhe Li, Tarek Abdelfatah, Stephen Chan, Xin Chen</li>
<li class=""><strong>institution:</strong> University of Nottingham, Nottingham City Hospital</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17759" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17759</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe1fee674daeeb2ff62e605cac35448ddb7b933f1a6948f0aa461b318710117_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe1fee674daeeb2ff62e605cac35448ddb7b933f1a6948f0aa461b318710117_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper proposes a framework using aligned longitudinal MRI and clinical data to predict breast cancer treatment response. The method involves tumor segmentation, image registration, and feature extraction, comparing radiomics and deep learning models. The main conclusion is that image registration significantly improves prediction, with radiomics features outperforming deep learning features in predicting pathologic complete response and relapse-free survival.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Fraud detection in credit card transactions using Quantum-Assisted Restricted Boltzmann Machines</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [quantum annealing, restricted boltzmann machine, qubo, quantum-assisted machine learning, fraud detection]</li>
<li class=""><strong>authors:</strong> João Marcos Cavalcanti de Albuquerque Neto, Gustavo Castro do Amaral, Guilherme Penello Temporão</li>
<li class=""><strong>institution:</strong> Pontifícia Universidade Católica do Rio de Janeiro, The Netherlands Organization for Applied Scientific Research (TNO)</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17660" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17660</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43a1f86f2b2d05435580200ee936d437f042be18dc15953d8144f949af07568c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43a1f86f2b2d05435580200ee936d437f042be18dc15953d8144f949af07568c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper investigates the use of Quantum-Assisted Restricted Boltzmann Machines (RBMs) for credit card fraud detection, applying quantum annealing to solve the QUBO problem derived from the RBM&#x27;s energy function. The method was tested on a real-world dataset of 145 million transactions. The results indicate that the quantum-assisted approach achieves superior performance compared to classical methods, even on current noisy quantum hardware.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] Learning vertical coordinates via automatic differentiation of a dynamical core</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [others], [automatic differentiation, neural network, terrain-following coordinates, differentiable dynamical core, NEUVE, Arakawa C-grid, non-hydrostatic Euler equations]</li>
<li class=""><strong>authors:</strong> Tim Whittaker, Seth Taylor, Elsa Cardoso-Bihlo, Alejandro Di Luca, Alex Bihlo</li>
<li class=""><strong>institution:</strong> Université du Québec à Montréal, University of Saskatchewan, Memorial University of Newfoundland</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17877" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17877</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The paper proposes a framework to learn vertical coordinates by integrating a parametric, neural network-based coordinate system (NEUVE) into a differentiable dynamical core for atmospheric modeling. Using automatic differentiation to compute exact geometric terms, the method optimizes the grid structure for physics and numerics. The learned coordinates reduce errors in benchmarks and eliminate spurious velocity patterns over steep topography.</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251222] MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation</strong></p>
<ul>
<li class=""><strong>tags:</strong> [mlsys], [multi-modal training], [3D ConvNeXt, Global Response Normalization, depth scaling, width scaling, context scaling, supervised pretraining, volumetric segmentation]</li>
<li class=""><strong>authors:</strong> Saikat Roy, Yannick Kirchhoff, Constantin Ulrich, Maximillian Rokuss, Tassilo Wald, Fabian Isensee, Klaus Maier-Hein</li>
<li class=""><strong>institution:</strong> German Cancer Research Center (DKFZ), Heidelberg University</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17774" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17774</a></li>
<li class=""><strong>Simple LLM Summary:</strong> This paper introduces MedNeXt-v2, a compound-scaled 3D ConvNeXt architecture enhanced with a Global Response Normalization module for large-scale supervised representation learning in medical image segmentation. The authors demonstrate that scaling the backbone network&#x27;s architecture is crucial for effective pretraining, and MedNeXt-v2 achieves state-of-the-art performance when fine-tuned on diverse CT and MR benchmarks. The work establishes that a stronger backbone design yields better downstream segmentation results than simply increasing dataset size.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-23">2025-12-23<a href="#2025-12-23" class="hash-link" aria-label="Direct link to 2025-12-23" title="Direct link to 2025-12-23" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251223] Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17911" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17911</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] QAISim: A Toolkit for Modeling and Simulation of AI in Quantum Cloud Computing Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Irwindeep Singh, Sukhpal Singh Gill, Jinzhao Sun, Jan Mol</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17918" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17918</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ffe2289ec69b8a1b313e066cc4c4de736d5becc210f22958bfd52daff8ff5e6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7ffe2289ec69b8a1b313e066cc4c4de736d5becc210f22958bfd52daff8ff5e6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QAISim: A Toolkit for Modeling and Simulation of AI in Quantum Cloud Computing Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Allison Li, Kristjan Greenewald, Thomas Parnell, Navid Azizan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17910" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17910</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69e52c70ff632453dafd08b1f3a3463c9d2df49fdb8300df0a3e128192436717_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Multi-Adapter LLM Serving via Cross-Model KV-Cache Reuse with Activated LoRA</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nick Rossenbach, Robin Schmitt, Tina Raissi, Simon Berger, Larissa Kleppel, Ralf Schlüter</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17915" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17915</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6036cb69e2cb0f832a1b1088209441a1b5309cc94cf18961ca3b07bffec7a52c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6036cb69e2cb0f832a1b1088209441a1b5309cc94cf18961ca3b07bffec7a52c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] chatter: a Python library for applying information theory and AI/ML models to animal communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mason Youngblood</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17935" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17935</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03a1f96f640c75358ed76ff8b7bb2631f43b52386c0c7724516992109d54aa7a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/03a1f96f640c75358ed76ff8b7bb2631f43b52386c0c7724516992109d54aa7a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> chatter: a Python library for applying information theory and AI/ML models to animal communication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] What&#x27;s the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Petr Koklev</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17945" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17945</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/564ec84544e92a29e57fb456987e278879803262a1ad7f11b5331621181314ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/564ec84544e92a29e57fb456987e278879803262a1ad7f11b5331621181314ae_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> What&#x27;s the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Soheil Hashtarkhani, Brianna M. White, Benyamin Hoseini, David L. Schwartz, Arash Shaban-Nejad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76d1304c99e1089257b9c3f4d81ee78901872f3818b6e4743be9843bd9a60488_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Comparative Evaluation of Explainable Machine Learning Versus Linear Regression for Predicting County-Level Lung Cancer Mortality Rate in the United States</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SCS-SupCon: Sigmoid-based Common and Style Supervised Contrastive Learning with Adaptive Decision Boundaries</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bin Wang, Fadi Dornaika</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17954" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17954</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bf3a9a797cfd9bf487a467cfbf96c2912048bb9780e4ea911d8505de4a3fd09_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bf3a9a797cfd9bf487a467cfbf96c2912048bb9780e4ea911d8505de4a3fd09_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SCS-SupCon: Sigmoid-based Common and Style Supervised Contrastive Learning with Adaptive Decision Boundaries</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gunho Park, Jeongin Bae, Byeongwook Kim, Baeseong park, Jiwon Ryu, Hoseung Kim, Se Jung Kwon, Dongsoo Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17970</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8eee89dc0a0f6c26eab8715e73b23d4aa516792d2237ec4f38c8323363f37c37_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Irina Seregina, Philippe Lalanda, German Vega</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17983" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17983</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/747125a80395e9d95ec80efcc81570ba4ba7205e4e2c8e9b485a5b5a991124d6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Convolutional-neural-operator-based transfer learning for solving PDEs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peng Fan, Guofei Pang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17969" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17969</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3b48d3312e2a3a21fec95790b71774b617dbbb16d924ea92ea392f72deaedd12_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Convolutional-neural-operator-based transfer learning for solving PDEs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MoE-TransMov: A Transformer-based Model for Next POI Prediction in Familiar &amp; Unfamiliar Movements</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruichen Tan, Jiawei Xue, Kota Tsubouchi, Takahiro Yabe, Satish V. Ukkusuri</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17985" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17985</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a4ee269c2652d9f53e2d00acd67fb791427f4c088062380a3d842683837aff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a4ee269c2652d9f53e2d00acd67fb791427f4c088062380a3d842683837aff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MoE-TransMov: A Transformer-based Model for Next POI Prediction in Familiar &amp; Unfamiliar Movements</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18014" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18014</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FedOAED: Federated On-Device Autoencoder Denoiser for Heterogeneous Data under Limited Client Availability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> S M Ruhul Kabir Howlader, Xiao Chen, Yifei Xie, Lu Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17986</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e5e22c4360871dd251f35903ee0f2af43d4bf37326ef9aa7f4dba13f94916b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e5e22c4360871dd251f35903ee0f2af43d4bf37326ef9aa7f4dba13f94916b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedOAED: Federated On-Device Autoencoder Denoiser for Heterogeneous Data under Limited Client Availability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Enhancing Tea Leaf Disease Recognition with Attention Mechanisms and Grad-CAM Visualization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Omar Faruq Shikdar, Fahad Ahammed, B. M. Shahria Alam, Golam Kibria, Tawhidur Rahman, Nishat Tasnim Niloy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17987" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17987</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e026b2918baadec02fb27d5fb57e2257968a98d72147f8159070f8c9fbb7d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e026b2918baadec02fb27d5fb57e2257968a98d72147f8159070f8c9fbb7d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Enhancing Tea Leaf Disease Recognition with Attention Mechanisms and Grad-CAM Visualization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sarah Nassar, Nooshin Maghsoodi, Sophia Mannina, Shamel Addas, Stephanie Sibley, Gabor Fichtinger, David Pichora, David Maslove, Purang Abolmaesumi, Parvin Mousavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18031</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7240d48041f3aeed8ef43430092d594f522d0dd6c9a8de4d3b6236fccaebc9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wei Qian, Chenxu Zhao, Yangyi Li, Mengdi Huai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18035" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18035</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aaf9e957a407bb93f6576826db847a43f0675e8b765d8c6f38b7c40e06953c3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aaf9e957a407bb93f6576826db847a43f0675e8b765d8c6f38b7c40e06953c3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mohammadmahdi Rahimiasl, Ynte Vanderhoydonc, Siegfried Mercelis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17984" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17984</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9a712275d1fc83e7fd5ac0076a27da3a080f91e229b14209ff99a52de68ce9c2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NodMAISI: Nodule-Oriented Medical AI for Synthetic Imaging</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fakrul Islam Tushar, Ehsan Samei, Cynthia Rudin, Joseph Y. Lo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18038" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18038</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7823e2e22739636a655f10a5159ed96eedc679b68020943f440020f0658dad87_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7823e2e22739636a655f10a5159ed96eedc679b68020943f440020f0658dad87_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NodMAISI: Nodule-Oriented Medical AI for Synthetic Imaging</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Roger A. Finger, Eduardo G. Cortes, Sandro J. Rigo, Gabriel de O. Ramos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18041" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18041</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/405c807df8e2ce95661469b072db6898b3dcf1bb175cd81aa868ecc9d2c06c12_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/405c807df8e2ce95661469b072db6898b3dcf1bb175cd81aa868ecc9d2c06c12_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Probabilistic Digital Twins of Users: Latent Representation Learning with Statistically Validated Semantics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel David</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18056" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18056</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12301f0dbb41071430f34a9014134b625a48eecd1e6b2f0d69403405addc6d7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12301f0dbb41071430f34a9014134b625a48eecd1e6b2f0d69403405addc6d7d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Probabilistic Digital Twins of Users: Latent Representation Learning with Statistically Validated Semantics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FOODER: Real-time Facial Authentication and Expression Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sabri Mustafa Kahya, Muhammet Sami Yavuz, Boran Hamdi Sivrikaya, Eckehard Steinbach</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18057</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17048a3dede1c165a0f52aab61de33bef5559518cf2996ad61858f9a9d680457_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FOODER: Real-time Facial Authentication and Expression Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Approximation and learning with compositional tensor trains</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Martin Eigel, Charles Miranda, Anthony Nouy, David Sommer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18059" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18059</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91f6bb6272d1b93753642e31936e179de5889b19456b73cd0d2d98f6cb87c979_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91f6bb6272d1b93753642e31936e179de5889b19456b73cd0d2d98f6cb87c979_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Approximation and learning with compositional tensor trains</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Graph-based Nearest Neighbors with Dynamic Updates via Random Walks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nina Mishra, Yonatan Naamad, Tal Wagner, Lichen Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18060" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18060</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09ac9385682bd6e4b07b769afe016fb50f71be5c2b6656f027de335845a16aed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09ac9385682bd6e4b07b769afe016fb50f71be5c2b6656f027de335845a16aed_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Graph-based Nearest Neighbors with Dynamic Updates via Random Walks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ge Yan, Tuomas Oikarinen, Tsui-Wei, Weng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18092" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18092</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7b2abff42613036ddb63e979f8be79c1123b50e037d39defec5292f1a3eb175_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kishan Kumar Ganguly, Tim Menzies</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18102" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18102</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/509a927741960d2c63062790fd8bebe6a6a22769c29f6985c39fb001039d9fab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/509a927741960d2c63062790fd8bebe6a6a22769c29f6985c39fb001039d9fab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Microstructure-based Variational Neural Networks for Robust Uncertainty Quantification in Materials Digital Twins</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Andreas E. Robertson, Samuel B. Inman, Ashley T. Lenau, Ricardo A. Lebensohn, Dongil Shin, Brad L. Boyce, Remi M. Dingreville</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18104" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18104</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd4c8fb93b00e9d3df0d57fa728955a837f9e46dce9a1fe1000acf82c6b0a1f2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd4c8fb93b00e9d3df0d57fa728955a837f9e46dce9a1fe1000acf82c6b0a1f2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Microstructure-based Variational Neural Networks for Robust Uncertainty Quantification in Materials Digital Twins</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TraCeR: Transformer-Based Competing Risk Analysis with Longitudinal Covariates</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxmillan Ries, Sohan Seth</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18129" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18129</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a81b46d02b46e72f2027e054c761a825748caf485414255423ed130f0887b330_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a81b46d02b46e72f2027e054c761a825748caf485414255423ed130f0887b330_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TraCeR: Transformer-Based Competing Risk Analysis with Longitudinal Covariates</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jie Yang, Rui Zhang, Ziyang Cheng, Dawei Cheng, Guang Yang, Bo Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18133" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18133</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b8052788abbad008c8487b789c1968d0448bbef8cdd15ad400f0c6303c23505_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Generalizable Neural Operators for Inverse Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Adam J. Thorpe, Stepan Tretiakov, Dibakar Roy Sarkar, Krishna Kumar, Ufuk Topcu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18120" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18120</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e045cf5e1b4d1841db31e3e3cbb272846f23e43ba557e1455491e138f9aa045_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e045cf5e1b4d1841db31e3e3cbb272846f23e43ba557e1455491e138f9aa045_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Generalizable Neural Operators for Inverse Problems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rupanshu Soi, Rohan Yadav, Fredrik Kjolstad, Alex Aiken, Maryam Mehri Dehnavi, Michael Garland, Michael Bauer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18134" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18134</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cfd081b538bd7f4d1c91e06ba3fae36d2a230ad65cf3fc2e5160c3bdd9d98b3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cfd081b538bd7f4d1c91e06ba3fae36d2a230ad65cf3fc2e5160c3bdd9d98b3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lena Libon, Meghana Bhange, Rushabh Solanki, Elliot Creager, Ulrich Aïvodji</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18174" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18174</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd7baf972d08bf5c53e0a32c68fda68879e3c2febf3407ecf6537a3fcd6d36fd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fd7baf972d08bf5c53e0a32c68fda68879e3c2febf3407ecf6537a3fcd6d36fd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FairExpand: Individual Fairness on Graphs with Partial Similarity Information</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rebecca Salganik, Yibin Wang, Guillaume Salha-Galvan, Jian Kang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18180</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/865ccd9cabcf2b700230e9c10d5db5bbd94993cb8f81acdca83db374c99156b8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/865ccd9cabcf2b700230e9c10d5db5bbd94993cb8f81acdca83db374c99156b8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FairExpand: Individual Fairness on Graphs with Partial Similarity Information</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jian Yan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18190</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhou Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18209" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18209</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5b09e099602878faf6cf44441a1e029c64f15985e3d209f1875434cd54da61a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Stable and Efficient Single-Rollout RL for Multimodal Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18215" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18215</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Stable and Efficient Single-Rollout RL for Multimodal Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lichen Yang, Qiang Wang, Zhonghao Yang, Daojing He, Yu Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18228" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18228</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9987a54aec669e601a71ba8b0ee7d5434ba0c73d08a66e20538cf347a09669cd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9987a54aec669e601a71ba8b0ee7d5434ba0c73d08a66e20538cf347a09669cd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AutoSchA: Automatic Hierarchical Music Representations via Multi-Relational Node Isolation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stephen Ni-Hahn, Rico Zhu, Jerry Yin, Yue Jiang, Cynthia Rudin, Simon Mak</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18232" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18232</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea758b7b2303802fc5c9547c032b22177a2accdeac3b36caed4230425fda6efa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea758b7b2303802fc5c9547c032b22177a2accdeac3b36caed4230425fda6efa_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AutoSchA: Automatic Hierarchical Music Representations via Multi-Relational Node Isolation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Offline Behavioral Data Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shiye Lei, Zhihao Cheng, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18246</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02b464fb04b52640bf81b61d9a535a31cd920c00fd8a2dd34cd4b261366adac1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Offline Behavioral Data Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dimensionality Reduction Considered Harmful (Some of the Time)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hyeon Jeon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18230" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18230</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c2d73af1d47933ab3fe41a060a175bd40e436f32af5added065941e07d0688_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c2d73af1d47933ab3fe41a060a175bd40e436f32af5added065941e07d0688_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dimensionality Reduction Considered Harmful (Some of the Time)</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Convergence Rate of LoRA Gradient Descent</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Siqiao Mu, Diego Klabjan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18248" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18248</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8cfafc1ac3ad3a56d892c47d02b17599c178471d68de77c5fdb73874a8fc10_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f8cfafc1ac3ad3a56d892c47d02b17599c178471d68de77c5fdb73874a8fc10_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Convergence Rate of LoRA Gradient Descent</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LeJOT: An Intelligent Job Cost Orchestration Solution for Databricks Platform</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lizhi Ma, Yi-Xiang Hu, Yuke Wang, Yifang Zhao, Yihui Ren, Jian-Xiang Liao, Feng Wu, Xiang-Yang Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18266" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18266</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de0debec5ee9990221746ff49e0aa9313a4766307624a21ded5312ce8127844d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de0debec5ee9990221746ff49e0aa9313a4766307624a21ded5312ce8127844d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LeJOT: An Intelligent Job Cost Orchestration Solution for Databricks Platform</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] FedSUM Family: Efficient Federated Learning Methods under Arbitrary Client Participation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runze You, Shi Pu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18275" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18275</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/075e8765f18ed2a89f21c4b5c0db9ea968dad78f6fb6aca6d0ea6c6135aadcde_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/075e8765f18ed2a89f21c4b5c0db9ea968dad78f6fb6aca6d0ea6c6135aadcde_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedSUM Family: Efficient Federated Learning Methods under Arbitrary Client Participation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xuling Zhang, Jindong Li, Yifei Zhang, Menglin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18295" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18295</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d219b11c5c859da88d8f68475d0f7f0705331024e0e77eb5124bfa1124849df9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AL-GNN: Privacy-Preserving and Replay-Free Continual Graph Learning via Analytic Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Harsh Rathva, Ojas Srivastava, Pruthwik Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18309</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c69f269f400e588bb27a40eea78dc7e63a0f8f1b86f9ab29abf255d7a91b0308_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18317" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18317</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c40f961221ca3df8f5c9388e76d344938990a3d405e09580d23abf68a4da0f57_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18333" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18333</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f5c0778f6eace42568ad8fc221a69e1cf4360df09bb1bb286e34299351febe0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning Position Control of a Quadrotor Using Soft Actor-Critic (SAC)</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A two-stream network with global-local feature fusion for bone age assessment</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qiong Lou, Han Yang, Fang Lu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18331" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18331</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d26c3d7fded2a10e84ebad25bc6bb1810428c48d125c9ad4b3a401fe14ca66d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d26c3d7fded2a10e84ebad25bc6bb1810428c48d125c9ad4b3a401fe14ca66d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A two-stream network with global-local feature fusion for bone age assessment</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Youssef Mahran, Zeyad Gamal, Ayman El-Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18336" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18336</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d046b180bb4bec9247b6bb525bd30b5814a0c5e4673bd03aea3eb64b9797e7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dynamic Entropy Tuning in Reinforcement Learning Low-Level Quadcopter Control: Stochasticity vs Determinism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Towards Guided Descent: Optimization Algorithms for Training Neural Networks At Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ansh Nagwekar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18373" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18373</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a52d6d3b760cd69f9655054febc798829d4e703cf29f84c34244775c0311631_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a52d6d3b760cd69f9655054febc798829d4e703cf29f84c34244775c0311631_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Towards Guided Descent: Optimization Algorithms for Training Neural Networks At Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Neural Proofs for Sound Verification and Control of Complex Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alessandro Abate</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18389" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18389</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d4271cbf46eee03fa72db8edd09dea5b0753448d820460e4c09f1171c7bc8f8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Neural Proofs for Sound Verification and Control of Complex Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Challenger: When Do New Data Sources Justify Switching Machine Learning Models?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vassilis Digalakis Jr, Christophe Pérignon, Sébastien Saurin, Flore Sentenac</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18390" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18390</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97c5a36d8f48f4ca89c4a34600dea33569d95e61a50916599a5cc161e183185a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97c5a36d8f48f4ca89c4a34600dea33569d95e61a50916599a5cc161e183185a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Challenger: When Do New Data Sources Justify Switching Machine Learning Models?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Automated Mosaic Tesserae Segmentation via Deep Learning Techniques</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Charilaos Kapelonis, Marios Antonakakis, Konstantinos Politof, Aristomenis Antoniadis, Michalis Zervakis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18406" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18406</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6893130bacdfd82f19e38a48fe6c1a981e8a6e139face8bc5ca4379fb98ab0c8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6893130bacdfd82f19e38a48fe6c1a981e8a6e139face8bc5ca4379fb98ab0c8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Automated Mosaic Tesserae Segmentation via Deep Learning Techniques</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Why Most Optimism Bandit Algorithms Have the Same Regret Analysis: A Simple Unifying Theorem</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vikram Krishnamurthy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18409" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18409</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb98e65517a8f8628860576c4228301198ae634fca16d11c5f0a252aee09a842_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cb98e65517a8f8628860576c4228301198ae634fca16d11c5f0a252aee09a842_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Why Most Optimism Bandit Algorithms Have the Same Regret Analysis: A Simple Unifying Theorem</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Zero-Shot Inpainting with Decoupled Diffusion Guidance</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Badr Moufad, Navid Bagheri Shouraki, Alain Oliviero Durmus, Thomas Hirtz, Eric Moulines, Jimmy Olsson, Yazid Janati</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18365" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18365</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb10f5246f2791c1a5c5d83727bb85643a1c89da44e041633e646e724bfa1d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2abb10f5246f2791c1a5c5d83727bb85643a1c89da44e041633e646e724bfa1d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Zero-Shot Inpainting with Decoupled Diffusion Guidance</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MoE Pathfinder: Trajectory-driven Expert Pruning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xican Yang, Yuanhe Tian, Yan Song</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18425" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18425</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c828ca8ec3754ef48c892048aa8de845b7afe7c78f324073b3d3bb8afcdfc08_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c828ca8ec3754ef48c892048aa8de845b7afe7c78f324073b3d3bb8afcdfc08_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MoE Pathfinder: Trajectory-driven Expert Pruning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Universality of Transformer Architectures; How Much Attention Is Enough?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Amirreza Abbasi, Mohsen Hooshmand</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18445" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18445</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e732525ad7eeb9bd777c68adaa24b4e1209e8441252397e0784b8ce41a3a00d7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e732525ad7eeb9bd777c68adaa24b4e1209e8441252397e0784b8ce41a3a00d7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Universality of Transformer Architectures; How Much Attention Is Enough?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jayant Lohia</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18453" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18453</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e4686d2a1c44f6a0f1d346c2e5401709f3d974dfd9062781f00cc8eb5d71952_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e4686d2a1c44f6a0f1d346c2e5401709f3d974dfd9062781f00cc8eb5d71952_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Secret mixtures of experts inside your LLM</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Enric Boix-Adsera</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18452" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18452</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7bef90d8febf87f4438ed38a790cb9675b92bf541f58daace4d8c67f4e7b28a1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Secret mixtures of experts inside your LLM</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> David Graber, Victor Armegioiu, Rebecca Buller, Siddhartha Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18454" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18454</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a2eb80d49254700f260ff3967d335e1d51ecb254bd1a0020cef4b670cd5e329_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a2eb80d49254700f260ff3967d335e1d51ecb254bd1a0020cef4b670cd5e329_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Román Jaimes</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18462" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18462</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Oraib Almegdadi, João Marcelino, Sarah Fakhreddine, João Manso, Nuno C. Marques</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18466" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18466</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4bfdf888d3e80d2b65bbc818e6d4aa3a319033086b834ed685478049ddb17232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-organizing maps for water quality assessment in reservoirs and lakes: A systematic literature review</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Geometry of Abstraction: Continual Learning via Recursive Quotienting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xin Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18471" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18471</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/946bc88c1851af1d701b7d19272c910b4e964e6d83ae04fa6fbdbf0f215f6e75_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/946bc88c1851af1d701b7d19272c910b4e964e6d83ae04fa6fbdbf0f215f6e75_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Geometry of Abstraction: Continual Learning via Recursive Quotienting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Research on a hybrid LSTM-CNN-Attention model for text-based web content classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mykola Kuz, Ihor Lazarovych, Mykola Kozlenko, Mykola Pikuliak, Andrii Kvasniuk</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18475" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18475</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d6cee54c1b292cf87f190d497421a3a323bc276532b71bc07f75f60e88c9a5d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d6cee54c1b292cf87f190d497421a3a323bc276532b71bc07f75f60e88c9a5d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Research on a hybrid LSTM-CNN-Attention model for text-based web content classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] APC-GNN++: An Adaptive Patient-Centric GNN with Context-Aware Attention and Mini-Graph Explainability for Diabetes Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Khaled Berkani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18473" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18473</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/917648447e1450eccba6ff12938452166cbb307d588b3036ddd72e80601da793_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/917648447e1450eccba6ff12938452166cbb307d588b3036ddd72e80601da793_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> APC-GNN++: An Adaptive Patient-Centric GNN with Context-Aware Attention and Mini-Graph Explainability for Diabetes Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Santwana Sagnika, Manav Malhotra, Ishtaj Kaur Deol, Soumyajit Roy, Swarnav Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18500" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18500</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a3d3024bb6cf729a0d0827d13bba185e065be8eb34bd4dffa40d58782bc4e5ab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PlantDiseaseNet-RT50: A Fine-tuned ResNet50 Architecture for High-Accuracy Plant Disease Detection Beyond Standard CNNs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] NASTaR: NovaSAR Automated Ship Target Recognition Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Benyamin Hosseiny, Kamirul Kamirul, Odysseas Pappas, Alin Achim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18503" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18503</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4ac29e833bc5eaed0a9881e81dd877d55f600f6bd8722c27c1466b58afc1378_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4ac29e833bc5eaed0a9881e81dd877d55f600f6bd8722c27c1466b58afc1378_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NASTaR: NovaSAR Automated Ship Target Recognition Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hatim M. E. Geli, Islam Omar, Mona Y. Elshinawy, David W. DuBios, Lara Prehodko, Kelly H Smith, Abdel-Hameed A. Badawy</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18522" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18522</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f61621a97ff1a65e5c71fb89cbb1d94dcdecafcb5694c0379f084f31d850ee0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Prediction and Forecast of Short-Term Drought Impacts Using Machine Learning to Support Mitigation and Adaptation Efforts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Feature-Enhanced Graph Neural Networks for Classification of Synthetic Graph Generative Models: A Benchmarking Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Janek Dyer, Jagdeep Ahluwalia, Javad Zarrin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18524" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18524</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08031a1b54db55f30489d768a136dda2ef1e6ae4c24a0e92ea56eefd2fef4532_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08031a1b54db55f30489d768a136dda2ef1e6ae4c24a0e92ea56eefd2fef4532_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Feature-Enhanced Graph Neural Networks for Classification of Synthetic Graph Generative Models: A Benchmarking Study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> S Mahmudul Hasan, Shaily Roy, Akib Jawad Nafis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18533" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18533</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ae98cacefd250f660449f7354216ce0a7f9d0395ed396c825595eada053e771_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ae98cacefd250f660449f7354216ce0a7f9d0395ed396c825595eada053e771_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scaling up Stability: Reinforcement Learning for Distributed Control of Networked Systems in the Space of Stabilizing Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Cao, Luca Furieri</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18540" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18540</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43fe9d2dae8cd7dd8a3ae293cabf5bd434385dd8877da1630a601a47c5dc1a7f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43fe9d2dae8cd7dd8a3ae293cabf5bd434385dd8877da1630a601a47c5dc1a7f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling up Stability: Reinforcement Learning for Distributed Control of Networked Systems in the Space of Stabilizing Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Scott Thornton</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18542" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18542</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Training Superintelligent Software Agents through Self-Play SWE-RL</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18552</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Training Superintelligent Software Agents through Self-Play SWE-RL</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Effiong Blessing, Chiung-Yi Tseng, Somshubhra Roy, Junaid Rehman, Isaac Nkrumah</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18575" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18575</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab099f7e2d96fe21b9b811feaa87d815fe23feb7bea213071f724ebc69a87414_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modality-Dependent Memory Mechanisms in Cross-Modal Neuromorphic Computing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumaiya Ali, Areej Alhothali, Ohoud Alzamzami, Sameera Albasri, Ahmed Abduljabbar, Muhammad Alwazzan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/387c39b67caa5e84daf0327dfb4c7a948d6d72c292a3404e6c7e8a2bcd6db7df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Placenta Accreta Spectrum Detection Using an MRI-based Hybrid CNN-Transformer Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SD2AIL: Adversarial Imitation Learning from Synthetic Demonstrations via Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengcheng Li, Qiang Fang, Tong Zhao, Yixing Lan, Xin Xu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18583" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18583</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fdabaf80e15fc440c53464fb3134095f9121f39b7d6d83850d4cb921dec3fda_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fdabaf80e15fc440c53464fb3134095f9121f39b7d6d83850d4cb921dec3fda_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SD2AIL: Adversarial Imitation Learning from Synthetic Demonstrations via Diffusion Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Comparing Dynamical Models Through Diffeomorphic Vector Field Alignment</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ruiqi Chen, Giacomo Vedovati, Todd Braver, ShiNung Ching</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18566" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18566</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17e1231f344e9051e9a9124b095324f59b3035dd2a93ac7e3bdf19d86c6eec28_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17e1231f344e9051e9a9124b095324f59b3035dd2a93ac7e3bdf19d86c6eec28_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Comparing Dynamical Models Through Diffeomorphic Vector Field Alignment</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] EIA-SEC: Improved Actor-Critic Framework for Multi-UAV Collaborative Control in Smart Agriculture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Quanxi Zhou, Wencan Mao, Yilei Liang, Manabu Tsukada, Yunling Liu, Jon Crowcroft</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18596" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18596</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/856f913f2cb31f98d005287343fc242bd36ba508c56e6d8fbbbb68c073df2a30_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/856f913f2cb31f98d005287343fc242bd36ba508c56e6d8fbbbb68c073df2a30_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EIA-SEC: Improved Actor-Critic Framework for Multi-UAV Collaborative Control in Smart Agriculture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Benchmarking neural surrogates on realistic spatiotemporal multiphysics flows</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runze Mao, Rui Zhang, Xuan Bai, Tianhao Wu, Teng Zhang, Zhenyi Chen, Minqi Lin, Bocheng Zeng, Yangchen Xu, Yingxuan Xiang, Haoze Zhang, Shubham Goswami, Pierre A. Dawe, Yifan Xu, Zhenhua An, Mengtao Yan, Xiaoyi Lu, Yi Wang, Rongbo Bai, Haobu Gao, Xiaohang Fang, Han Li, Hao Sun, Zhi X. Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18595" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18595</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54fa7968484f2312fe5e5490bcb221fdffbad35b3d30834c98660d094a86bdd2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54fa7968484f2312fe5e5490bcb221fdffbad35b3d30834c98660d094a86bdd2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Benchmarking neural surrogates on realistic spatiotemporal multiphysics flows</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wencan Mao, Quanxi Zhou, Tomas Couso Coddou, Manabu Tsukada, Yunling Liu, Yusheng Ji</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18604" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18604</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9df5c14f10e3a4031cb92513653314edaf2d17ccb1f345c4f9e818b04c5c9203_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trajectory Planning for UAV-Based Smart Farming Using Imitation-Based Triple Deep Q-Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rongyao Cai, Yuxi Wan, Kexin Zhang, Ming Jin, Hao Wang, Zhiqiang Ge, Daoyi Dong, Yong Liu, Qingsong Wen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18610" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18610</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a15caebdaadc9b61bcc30ac1fa7534d1efe4cc5ec0d9274e6b2bd1e89b75d13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a15caebdaadc9b61bcc30ac1fa7534d1efe4cc5ec0d9274e6b2bd1e89b75d13_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Huiqi Deng, Qihan Ren, Zhuofan Chen, Zhenyuan Cui, Wen Shen, Peng Zhang, Hongbin Pei, Quanshi Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18607</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30ab53152f4d22782382d142896ab1eaf1182b02d53770517901f257b002cc1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Han-Seul Jeong, Youngjoon Park, Hyungseok Song, Woohyung Lim</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18633" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18633</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/abc675e475f6d219e02688fea9461fecf46d82b6729bd20d29accd9c95cc967f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ARC: Leveraging Compositional Representations for Cross-Problem Learning on VRPs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ryotaro Kawata, Yujin Song, Alberto Bietti, Naoki Nishikawa, Taiji Suzuki, Samuel Vaiter, Denny Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18634" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18634</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e54fb36cb8dc15a87cb11d651f2fd0a36426f91acc811072a8e23c04544cd8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e54fb36cb8dc15a87cb11d651f2fd0a36426f91acc811072a8e23c04544cd8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PMPGuard: Catching Pseudo-Matched Pairs in Remote Sensing Image-Text Retrieval</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengxiang Ouyang, Qing Ma, Zheng Wang, Cong Bai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18660" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18660</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06fe8e37dc2d1d1d6a5d48298128004f86b1be4d6ecbeca32f5c72786b1a535c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/06fe8e37dc2d1d1d6a5d48298128004f86b1be4d6ecbeca32f5c72786b1a535c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PMPGuard: Catching Pseudo-Matched Pairs in Remote Sensing Image-Text Retrieval</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Improving Pattern Recognition of Scheduling Anomalies through Structure-Aware and Semantically-Enhanced Graphs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ning Lyu, Junjie Jiang, Lu Chang, Chihui Shao, Feng Chen, Chong Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18673</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c16637936bf2055d30084813c6afcafc16bc9cf66165235e01a57ad34447eb0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c16637936bf2055d30084813c6afcafc16bc9cf66165235e01a57ad34447eb0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Improving Pattern Recognition of Scheduling Anomalies through Structure-Aware and Semantically-Enhanced Graphs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pengchao Feng, Yao Xiao, Ziyang Ma, Zhikang Niu, Shuai Fan, Yao Li, Sheng Wang, Xie Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18699" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18699</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c759cfdab0e5242e7ed2d8eff42f898cd26dbf0e8845df8e26a3c8936e15_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c759cfdab0e5242e7ed2d8eff42f898cd26dbf0e8845df8e26a3c8936e15_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Task Vector in TTS: Toward Emotionally Expressive Dialectal Speech Synthesis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generating Risky Samples with Conformity Constraints via Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Han Yu, Hao Zou, Xingxuan Zhang, Zhengyi Wang, Yue He, Kehan Li, Peng Cui</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18722</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccd2af87861ffba1a1a1172552bec8a5a2c9fb4db73b173801ff6c5db0f1734b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccd2af87861ffba1a1a1172552bec8a5a2c9fb4db73b173801ff6c5db0f1734b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generating Risky Samples with Conformity Constraints via Diffusion Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xue Yang, Michael Schukat, Junlin Lu, Patrick Mannion, Karl Mason, Enda Howley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18670" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18670</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f001f825ba30968846f540ea46b7c77510d728bd232f6fe2aedc626451956364_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demonstration-Guided Continual Reinforcement Learning in Dynamic Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Theoretical Lens for RL-Tuned Language Models via Energy-Based Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhiquan Tan, Yinrong Hong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18730</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726f00d4aa0c339e8cdaf688c05c28499bf469ac19b055e49f249d532aa40b2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5726f00d4aa0c339e8cdaf688c05c28499bf469ac19b055e49f249d532aa40b2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Theoretical Lens for RL-Tuned Language Models via Energy-Based Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ML Inference Scheduling with Predictable Latency</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haidong Zhao, Nikolaos Georgantas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18725" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18725</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a8d1548e228be441a72232fe96db7a46d1c28ad7f5a73b47e37580f3b42dadf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a8d1548e228be441a72232fe96db7a46d1c28ad7f5a73b47e37580f3b42dadf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ML Inference Scheduling with Predictable Latency</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiangrui Cai, Shaocheng Ma, Lei Cao, Jie Li, Tianyu Liu, Yilin Dong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18689" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18689</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2376b865ddc12cc20f97bb00013197494f3e12cba34f9079248457bb11fb7eab_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fusion of Multiscale Features Via Centralized Sparse-attention Network for EEG Decoding</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zichuan Lin, Xiaokai Huang, Jiate Liu, Yuxuan Han, Jia Chen, Xiapeng Wu, Deheng Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1c6978b6e1b267d6a0dd6bed5b258ad165849282cb8c0a6f4f89c449c2dfc2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PIPCFR: Pseudo-outcome Imputation with Post-treatment Variables for Individual Treatment Effect Estimation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chainarong Amornbunchornvej</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18732</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/971d2a8c016b462ec6480b43e3bb4defeb91225b526df8895e9702f727c64232_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Counterfactual Basis Extension and Representational Geometry: An MDL-Constrained Model of Conceptual Growth</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Is Your Conditional Diffusion Model Actually Denoising?</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel Pfrommer, Zehao Dou, Christopher Scarvelis, Max Simchowitz, Ali Jadbabaie</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18736</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/856ef1fcb2e79aa2ab4b2a022b1c3d13580d56e426a05e9b3d88850160ea2eac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/856ef1fcb2e79aa2ab4b2a022b1c3d13580d56e426a05e9b3d88850160ea2eac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Is Your Conditional Diffusion Model Actually Denoising?</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Gaussian-Mixture-Model Q-Functions for Policy Iteration in Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Minh Vu, Konstantinos Slavakis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18763" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18763</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19f67ca81a26c636db40a8c5fd0bedfcf549bc2e97dbcd90530ca1de4a7f861_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19f67ca81a26c636db40a8c5fd0bedfcf549bc2e97dbcd90530ca1de4a7f861_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gaussian-Mixture-Model Q-Functions for Policy Iteration in Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kaican Li, Lewei Yao, Jiannan Wu, Tiezheng Yu, Jierun Chen, Haoli Bai, Lu Hou, Lanqing Hong, Wei Zhang, Nevin L. Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18745" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18745</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Eff-GRot: Efficient and Generalizable Rotation Estimation with Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fanis Mathioulakis, Gorjan Radevski, Tinne Tuytelaars</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18784" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18784</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe0254e0e9393c18241de33ec503d4cc8d75622e94c6a0d08ec4ee16da3e3b6b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe0254e0e9393c18241de33ec503d4cc8d75622e94c6a0d08ec4ee16da3e3b6b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Eff-GRot: Efficient and Generalizable Rotation Estimation with Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Label-Informed Outlier Detection Based on Granule Density</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Baiyang Chen, Zhong Yuan, Dezhong Peng, Hongmei Chen, Xiaomin Song, Huiming Zheng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18774" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18774</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27f829438adaa9d5eb3ec20d666226593c7dc2a412469b585dd40c6517ab3e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27f829438adaa9d5eb3ec20d666226593c7dc2a412469b585dd40c6517ab3e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Label-Informed Outlier Detection Based on Granule Density</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Souhail Abdelmouaiz Sadat, Mohamed Yacine Touahria Miliani, Khadidja Hab El Hames, Hamida Seba, Mohammed Haddad</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18826" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18826</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1947d93734df64c6e62ffe5a621cdb9199875dcacb08de1203cadabf9bce52e3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John S. Schreck, William E. Chapman, Charlie Becker, David John Gagne II, Dhamma Kimpara, Nihanth Cherukuru, Judith Berner, Kirsten J. Mayer, Negin Sobhani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18815" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18815</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60b40f77d2965a2b21082e13c0dc95074d21866006415db1b08905e24b2234e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Controllable Probabilistic Forecasting with Stochastic Decomposition Layers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Generative Modeling through Spectral Analysis of Koopman Operator</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuanchao Xu, Fengyi Li, Masahiro Fujisawa, Youssef Marzouk, Isao Ishikawa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18837" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18837</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3838b816a163dddae4907465cfe37d64e1f909b2317422f86a8a2c6ad7e98898_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3838b816a163dddae4907465cfe37d64e1f909b2317422f86a8a2c6ad7e98898_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generative Modeling through Spectral Analysis of Koopman Operator</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zijun Gao, Zhikun Xu, Xiao Ye, Ben Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18857" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18857</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bf1013f3c193e706d652fa4c8fdadc0c813c8a361e2efb84151a139cef28420_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CORE: Concept-Oriented Reinforcement for Bridging the Definition-Application Gap in Mathematical Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Application of deep learning approaches for medieval historical documents transcription</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maksym Voloshchuk, Bohdana Zarembovska, Mykola Kozlenko</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18865" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18865</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc697efc3bfd30e66b187f56c365b6a8add07756fb768bc77ba4586f1ab7d205_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc697efc3bfd30e66b187f56c365b6a8add07756fb768bc77ba4586f1ab7d205_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Application of deep learning approaches for medieval historical documents transcription</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gökdeniz Gülmez</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18901" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18901</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8736176cf479e84eb193acab53e62edbdc590a96b0d7bb1adc66a60425d42697_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Ensemble Schr{ö}dinger Bridge filter for Nonlinear Data Assimilation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Feng Bao, Hui Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b1984f127a0ea77e013fd30f9e55a2d1893fc429cb8128fbd4e89c1fefcb6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b1984f127a0ea77e013fd30f9e55a2d1893fc429cb8128fbd4e89c1fefcb6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Ensemble Schr{ö}dinger Bridge filter for Nonlinear Data Assimilation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Merging of Kolmogorov-Arnold networks trained on disjoint datasets</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Andrew Polar, Michael Poluektov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18921" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18921</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e53714df09977ebe2db3d05959d679946262bcbddc4ea0acb1d3d3511f211611_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e53714df09977ebe2db3d05959d679946262bcbddc4ea0acb1d3d3511f211611_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Merging of Kolmogorov-Arnold networks trained on disjoint datasets</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DPSR: Differentially Private Sparse Reconstruction via Multi-Stage Denoising for Recommender Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sarwan Ali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18932" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18932</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c243588ebf5b62b4dd8e1854c41bcdec7ca5861520351edb4b3b12455148d30_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c243588ebf5b62b4dd8e1854c41bcdec7ca5861520351edb4b3b12455148d30_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DPSR: Differentially Private Sparse Reconstruction via Multi-Stage Denoising for Recommender Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Michael S. Zhang, Rishi A. Ruia, Arnav Kewalram, Saathvik Dharmapuram, Utkarsh Sharma, Kevin Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/939264f370dd6741588d1d57c916b73d9735e25a2515f10e5a8042daa9f43a19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18950" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18950</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54c9156f2821c3dd5ccd4cf3168dbf447bac3d5632d167548d6c2ce179747e7d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debamita Ghosh, George K. Atia, Yue Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18957" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18957</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f848ae68e82b8a23f061ffdf3e4e75811fcab48a03fe5070cce95c8a38a027b7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f848ae68e82b8a23f061ffdf3e4e75811fcab48a03fe5070cce95c8a38a027b7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Scaling Online Distributionally Robust Reinforcement Learning: Sample-Efficient Guarantees with General Function Approximation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Through Little Eyes: Attribute Discrimination Beyond Objects</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Patrick Batsell, Tsutsui Satoshi, Bihan Wen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18951" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18951</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e80b7c71db93c26589e4d25cfffe472d3de86a058a86caaabd4d81fb9bc2c38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e80b7c71db93c26589e4d25cfffe472d3de86a058a86caaabd4d81fb9bc2c38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Through Little Eyes: Attribute Discrimination Beyond Objects</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Lag Operator SSMs: A Geometric Framework for Structured State Space Modeling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sutashu Tomonaga, Kenji Doya, Noboru Murata</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18965" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18965</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49d3230921a0fe478c29d46346dffb80acdac27624660b8dd8316094a5be88aa_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49d3230921a0fe478c29d46346dffb80acdac27624660b8dd8316094a5be88aa_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Lag Operator SSMs: A Geometric Framework for Structured State Space Modeling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yizhi Wang, Linan Yue, Min-Ling Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18956" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18956</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5b69c497301f02ef5b3b08cd69d4893f6dad335ed0c12427b7caaaff9655ec68_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Consistency-guided semi-supervised outlier detection in heterogeneous data using fuzzy rough sets</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Baiyang Chen, Zhong Yuan, Dezhong Peng, Xiaoliang Chen, Hongmei Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18977" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18977</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f137793e37d26cff00a3715c8212e2ad3fa2487bcba70f9d1f1f23ec3f06ea9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f137793e37d26cff00a3715c8212e2ad3fa2487bcba70f9d1f1f23ec3f06ea9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Consistency-guided semi-supervised outlier detection in heterogeneous data using fuzzy rough sets</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Baiyang Chen, Zhong Yuan, Zheng Liu, Dezhong Peng, Yongxiang Li, Chang Liu, Guiduo Duan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18978</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58b9c746816307fee96e3cf245632387dbf3ca0eaff52acdf2fdc9465315f8e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58b9c746816307fee96e3cf245632387dbf3ca0eaff52acdf2fdc9465315f8e9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Outlier detection in mixed-attribute data: a semi-supervised approach with fuzzy approximations and relative entropy</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] OPBO: Order-Preserving Bayesian Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wei Peng, Jianchen Hu, Kang Liu, Qiaozhu Zhai</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18980" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18980</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b75b70c8d757c498d035de7add4278dda4866bb8a7052d89525a499956b1847_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b75b70c8d757c498d035de7add4278dda4866bb8a7052d89525a499956b1847_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OPBO: Order-Preserving Bayesian Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kun Zhao, Siyuan Dai, Yingying Zhang, Guodong Liu, Pengfei Gu, Chenghua Lin, Paul M. Thompson, Alex Leow, Heng Huang, Lifang He, Liang Zhan, Haoteng Tang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18986</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5f5fb7daad78ee0192a96724088e699786c824ab6443f02134a66cc416ef822_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> R-GenIMA: Integrating Neuroimaging and Genetics with Interpretable Multimodal AI for Alzheimer&#x27;s Disease Progression</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19011" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19011</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lingjie Zhao, Xue Yu, Yongzhi Qi, Hao Hu, Jianshen Zhang, Yingzheng Ma, Shuyu Han, Wei Qi, Zuo-Jun Max Shen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19001" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19001</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c013ebec66cbd4e8c385c0036349f79e012b2d06eacaaa9dad9601fe1f892d1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Konstantin Kaulen, Tobias Ladner, Stanley Bak, Christopher Brix, Hai Duong, Thomas Flinkow, Taylor T. Johnson, Lukas Koller, Edoardo Manino, ThanhVu H Nguyen, Haoze Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19007</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2150c6a005dd7455c0dea890d81e19545e163edf743950930238707d6b4b29ea_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The 6th International Verification of Neural Networks Competition (VNN-COMP 2025): Summary and Results</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Optimizer Dynamics at the Edge of Stability with Differential Privacy</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ayana Hussain, Ricky Fang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19019" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19019</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe869fb966bc8e432b82a891d4042c2fd2899dd38d8367f5952e66e27a733144_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe869fb966bc8e432b82a891d4042c2fd2899dd38d8367f5952e66e27a733144_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Optimizer Dynamics at the Edge of Stability with Differential Privacy</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CETCAM: Camera-Controllable Video Generation via Consistent and Extensible Tokenization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zelin Zhao, Xinyu Gong, Bangya Liu, Ziyang Song, Jun Zhang, Suhui Wu, Yongxin Chen, Hao Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19020" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19020</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7bd5a2abb18589060985877478ba075c83351c0fe7a3b61f7db28dccf9b3d5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7bd5a2abb18589060985877478ba075c83351c0fe7a3b61f7db28dccf9b3d5b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CETCAM: Camera-Controllable Video Generation via Consistent and Extensible Tokenization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hengrui Jia, Taoran Li, Jonas Guan, Varun Chandrasekaran</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19025" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19025</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d72daaf4e0b704bed60ade2228f84dd6c37332a3588377ebc905b92f9db787ee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Erasure Illusion: Stress-Testing the Generalization of LLM Forgetting Evaluation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Time-series Forecast for Indoor Zone Air Temperature with Long Horizons: A Case Study with Sensor-based Data from a Smart Building</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Liping Sun, Yucheng Guo, Siliang Lu, Zhenzhen Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19038" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19038</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac72029d8bfa1d8aa93562d8cd7cf4c8a3ea568788647c1533d43f1e70bc9335_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac72029d8bfa1d8aa93562d8cd7cf4c8a3ea568788647c1533d43f1e70bc9335_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Time-series Forecast for Indoor Zone Air Temperature with Long Horizons: A Case Study with Sensor-based Data from a Smart Building</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Md Minhazul Islam Munna, Md Mahbubur Rahman, Jaroslav Frnda, Muhammad Shahid Anwar, Alpamis Kutlimuratov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19037" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19037</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f65bbdc2e7a521d46fdaeebb4c5a652347737b90cb0eb72dc48b2bfbbff2789_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2f65bbdc2e7a521d46fdaeebb4c5a652347737b90cb0eb72dc48b2bfbbff2789_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Elevating Intrusion Detection and Security Fortification in Intelligent Networks through Cutting-Edge Machine Learning Paradigms</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Recontextualization Mitigates Specification Gaming without Modifying the Specification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ariana Azarbal, Victor Gillioz, Vladimir Ivanov, Bryce Woodworth, Jacob Drori, Nevan Wichers, Aram Ebtekar, Alex Cloud, Alexander Matt Turner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19027" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19027</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a00743ecd04e88f2319e45c57ea03523b4606221385fae51496a2d85825c258f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Recontextualization Mitigates Specification Gaming without Modifying the Specification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Cost-Aware Sequential Hypothesis Testing with Random Costs and Action Cancellation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> George Vershinin, Asaf Cohen, Omer Gurewitz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19067" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19067</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/395cdf02cbfcdfcb8cd487bcc7bb40a760166e8635105ec2f48357e1a0a09bbb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/395cdf02cbfcdfcb8cd487bcc7bb40a760166e8635105ec2f48357e1a0a09bbb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Cost-Aware Sequential Hypothesis Testing with Random Costs and Action Cancellation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chi Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19061" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19061</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/734faa80116bce116311ee42eb0ce886bb9c7a99f6aa6642df27946ec8624b39_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fraud Detection Through Large-Scale Graph Clustering with Heterogeneous Link Transformation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Auditing Significance, Metric Choice, and Demographic Fairness in Medical AI Challenges</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ariel Lubonja, Pedro R. A. S. Bassi, Wenxuan Li, Hualin Qiao, Randal Burns, Alan L. Yuille, Zongwei Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19091" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19091</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8b75e4c6b7e493a0c6d3b57468d0ae3edcb9efaeaaf9076c00744a6a04c7c6a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8b75e4c6b7e493a0c6d3b57468d0ae3edcb9efaeaaf9076c00744a6a04c7c6a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Auditing Significance, Metric Choice, and Demographic Fairness in Medical AI Challenges</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Personalization of Generative Models via Optimal Experimental Design</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Guy Schacht, Ziyad Sheebaelhamd, Riccardo De Santi, Mojmír Mutný, Andreas Krause</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19057" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19057</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcef3113c71e842238e399994571c9492cf534afd3c06e6241febfcda1354e87_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcef3113c71e842238e399994571c9492cf534afd3c06e6241febfcda1354e87_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Personalization of Generative Models via Optimal Experimental Design</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Dual Model Deep Learning for Alzheimer Prognostication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alireza Moayedikia, Sara Fin, Uffe Kock Wiil</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19099" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19099</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57c6707a8cb9bbf9189cedc3fc04aab23c29bbec6c15b1c12163211decc70869_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57c6707a8cb9bbf9189cedc3fc04aab23c29bbec6c15b1c12163211decc70869_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Dual Model Deep Learning for Alzheimer Prognostication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Timely Parameter Updating in Over-the-Air Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiaqi Zhu, Zhongyuan Zhao, Xiao Li, Ruihao Du, Shi Jin, Howard H.Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19103" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19103</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fc52e9cecab5d074f9763764f769e7c7bd5aaa186ce1d747f2bbd3fa2caf41_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5fc52e9cecab5d074f9763764f769e7c7bd5aaa186ce1d747f2bbd3fa2caf41_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Timely Parameter Updating in Over-the-Air Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Danny Dongyeop Han, Yonghyeon Gwon, Ahhyun Lucy Lee, Taeyang Lee, Seong Jin Lee, Jubin Choi, Sebin Lee, Jihyun Bang, Seungju Lee, David Keetae Park, Shinjae Yoo, Chun Kee Chung, Jiook Cha</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19097" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19097</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c484fa8acc86bbd4f9063aac8ef59f814dfcc288fb23da3663d1be6cbc19ed0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Fang, Fabian Waschkowski, Maximilian Reissmann, Richard D. Sandberg, Takuo Oda, Koichi Tanimoto</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19031" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19031</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6630d808b10ee83956b0b8d3975fc127ddbef17b5014ced381ff234a9441900d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6630d808b10ee83956b0b8d3975fc127ddbef17b5014ced381ff234a9441900d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Surrogate-Augmented Symbolic CFD-Driven Training Framework for Accelerating Multi-objective Physical Model Development</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Composable Channel-Adaptive Architecture for Seizure Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Francesco Carzaniga, Michael Hersche, Kaspar Schindler, Abbas Rahimi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19123" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19123</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80ba764ee64b005cd983a9e6b724f69e3e08628a8e048027385de0b6ea62e65d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/80ba764ee64b005cd983a9e6b724f69e3e08628a8e048027385de0b6ea62e65d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Composable Channel-Adaptive Architecture for Seizure Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] SAP: Syntactic Attention Pruning for Transformer-based Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tzu-Yun Lee, Ding-Yong Hong, Jan-Jan Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19125</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3141b4a53facc55a384f90382f9ca7bbbdeafdff36d3027e35548bc8ba2ea87_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3141b4a53facc55a384f90382f9ca7bbbdeafdff36d3027e35548bc8ba2ea87_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> SAP: Syntactic Attention Pruning for Transformer-based Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Murtaza Rangwala, Richard O. Sinnott, Rajkumar Buyya</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19131" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19131</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5ab0acf932ea7b2d42fac6b935c509aaf0582fb4879eb9fae7e0fe0a8e7f766_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5ab0acf932ea7b2d42fac6b935c509aaf0582fb4879eb9fae7e0fe0a8e7f766_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Evidential Trust-Aware Model Personalization in Decentralized Federated Learning for Wearable IoT</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoyu Jiang, Boan Qu, Junjie Zhu, Fanjie Zeng, Xiaojie Lin, Wei Zhong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19114" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19114</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c9e78435f4153aa973c4506803772e51c588c18e59d73dbebc8e9500306a1a5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HyperLoad: A Cross-Modality Enhanced Large Language Model-Based Framework for Green Data Center Cooling Load Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Coverage</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Francis Bach</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19142" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19142</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4a93fce488552329133c465e13cb55215345c0def3d3e8109e9ab58f1388fad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4a93fce488552329133c465e13cb55215345c0def3d3e8109e9ab58f1388fad_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Convex Loss Function for Set Prediction with Optimal Trade-offs Between Size and Conditional Coverage</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] RP-CATE: Recurrent Perceptron-based Channel Attention Transformer Encoder for Industrial Hybrid Modeling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haoran Yang, Yinan Zhang, Wenjie Zhang, Dongxia Wang, Peiyu Liu, Yuqi Ye, Kexin Chen, Wenhai Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19147" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19147</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d3125cc08ed130beab248cba1a7473ff408ca14e82e124e77351d681c62aec5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d3125cc08ed130beab248cba1a7473ff408ca14e82e124e77351d681c62aec5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RP-CATE: Recurrent Perceptron-based Channel Attention Transformer Encoder for Industrial Hybrid Modeling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Geraud Nangue Tasse, Matthew Riemer, Benjamin Rosman, Tim Klinger</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19154" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19154</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4ae9081ca365a9b3f9fb29e85d33707cb3a2d86edd9ec1d7bbe7736548be8781_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Beyond Sliding Windows: Learning to Manage Memory in Non-Markovian Environments</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19184" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19184</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbd43bd93ed46f19d672704ea24b1558583d71b0931350481c4a5624e10f1e16_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Operator-Based Generalization Bound for Deep Learning: Insights on Multi-Task Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Practical Quantum-Classical Feature Fusion for complex data Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19180" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19180</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3d96db4938c738e58622382a424d90cd1dd10f2608995abac211c8355b017a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Practical Quantum-Classical Feature Fusion for complex data Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Causal Heterogeneous Graph Learning Method for Chronic Obstructive Pulmonary Disease Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Leming Zhou, Zuo Wang, Zhigang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19194" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19194</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6faf26f0cc652e06ad561a1f1b33d9cf5c741015ebbded034f635a578186206_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6faf26f0cc652e06ad561a1f1b33d9cf5c741015ebbded034f635a578186206_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Causal Heterogeneous Graph Learning Method for Chronic Obstructive Pulmonary Disease Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19199</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d39c24b719b177ace6c9761e568136da70723831c6d8b3c90ed420d732d6b409_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PEDESTRIAN: An Egocentric Vision Dataset for Obstacle Detection on Pavements</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marios Thoma, Zenonas Theodosiou, Harris Partaourides, Vassilis Vassiliades, Loizos Michael, Andreas Lanitis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19190" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19190</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a96c05d7294228300f6794f5bbda416f7d11e2b7c58157c93485f6f6ba933ade_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a96c05d7294228300f6794f5bbda416f7d11e2b7c58157c93485f6f6ba933ade_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PEDESTRIAN: An Egocentric Vision Dataset for Obstacle Detection on Pavements</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tao Zhang, Ziqian Zeng, Hao Peng, Huiping Zhuang, Cen Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19206" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19206</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c9e9fce94d780d562e939d0aa6d0aa4602e96ed0f980ba45968a1486b745bc8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anna-Maria Gueorguieva, Aylin Caliskan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19238" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19238</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Phase-space entropy at acquisition reflects downstream learnability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiu-Cheng Wang, Jun-Jie Zhanga, Nan Cheng, Long-Gang Pang, Taijiao Du, Deyu Meng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19223" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19223</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6f7f5d98244f4027de001e9a63b027e02247bcd25714fdcf9483af34b3cbf0c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e6f7f5d98244f4027de001e9a63b027e02247bcd25714fdcf9483af34b3cbf0c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Phase-space entropy at acquisition reflects downstream learnability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Black-Box Tuning to Guided Optimization via Hyperparameters Interaction Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Moncef Garouani, Ayah Barhrhouj</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19246" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19246</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edaee8be894e0b2aabf965adc9c2da7a8499fac8b0b1b7437890bac0428efa6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edaee8be894e0b2aabf965adc9c2da7a8499fac8b0b1b7437890bac0428efa6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Black-Box Tuning to Guided Optimization via Hyperparameters Interaction Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Regression generation adversarial network based on dual data evaluation strategy for industrial application</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zesen Wang, Yonggang Li, Lijuan Lan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19232" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19232</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0ad96ff9f5740075b9f98eecc3bf3e0d3e6ae902f7528d0c14e4cef5572f55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0ad96ff9f5740075b9f98eecc3bf3e0d3e6ae902f7528d0c14e4cef5572f55_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Regression generation adversarial network based on dual data evaluation strategy for industrial application</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Prathamesh Devadiga</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19250" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19250</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9992d696f5e075764c08a2b42f4505f7b8d093d1a3975265c2c2a7716a8fbcbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9992d696f5e075764c08a2b42f4505f7b8d093d1a3975265c2c2a7716a8fbcbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Small Language Models as Compiler Experts: Auto-Parallelization for Heterogeneous Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carla Crivoi, Radu Tudor Ionescu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19253" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19253</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d70a17b56ecda8937a9bd488550e13c9d9833f836ea7a0e16e024c8b5e950c5b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Translating Flow to Policy via Hindsight Online Imitation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yitian Zheng, Zhangchen Ye, Weijun Dong, Shengjie Wang, Yuyang Liu, Chongjie Zhang, Chuan Wen, Yang Gao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19269" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19269</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d1e38857114c4e6bdd80a03e175ccdec39b489a4a7abb23d37f7f4402ba68fc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d1e38857114c4e6bdd80a03e175ccdec39b489a4a7abb23d37f7f4402ba68fc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Translating Flow to Policy via Hindsight Online Imitation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] GShield: Mitigating Poisoning Attacks in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sameera K. M., Serena Nicolazzo, Antonino Nocera, Vinod P., Rafidha Rehiman K. A</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19286" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19286</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c43d719deb3b65a2681b1c10fbb4647b0e73aa0efbe80e20c06d9f27f59d1058_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c43d719deb3b65a2681b1c10fbb4647b0e73aa0efbe80e20c06d9f27f59d1058_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GShield: Mitigating Poisoning Attacks in Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Time-Vertex Machine Learning for Optimal Sensor Placement in Temporal Graph Signals: Applications in Structural Health Monitoring</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Keivan Faghih Niresi, Jun Qing, Mengjie Zhao, Olga Fink</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19309" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19309</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e839b4b1adb5610adcd939ece8fb2b9f58ed8b25b96c321b897b8bac816ca350_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e839b4b1adb5610adcd939ece8fb2b9f58ed8b25b96c321b897b8bac816ca350_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Time-Vertex Machine Learning for Optimal Sensor Placement in Temporal Graph Signals: Applications in Structural Health Monitoring</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Chang Dong, Jianfeng Tao, Chengliang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19280" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19280</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/23dae36b800575da09218251c1aa3582a2ce5ca30c8c9988566be10e83f43e38_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Digital Twin-Driven Zero-Shot Fault Diagnosis of Axial Piston Pumps Using Fluid-Borne Noise Signals</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Alternative positional encoding functions for neural transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ezequiel Lopez-Rubio, Macoris Decena-Gimenez, Rafael Marcos Luque-Baena</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19323" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19323</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09a8d61d0d13038271b6545ad7d265494ffd5b3cce79e03046ec542b879d17a8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Alternative positional encoding functions for neural transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MAGIC: Achieving Superior Model Merging via Magnitude Calibration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19320" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19320</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MAGIC: Achieving Superior Model Merging via Magnitude Calibration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Logical View of GNN-Style Computation and the Role of Activation Functions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Pablo Barceló, Floris Geerts, Matthias Lanzinger, Klara Pakhomenko, Jan Van den Bussche</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19332" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19332</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d6cc724cbd8fd52ec250ad8e7e8c8c76440bef31c5f1eae060dbb796cd6e916_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d6cc724cbd8fd52ec250ad8e7e8c8c76440bef31c5f1eae060dbb796cd6e916_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Logical View of GNN-Style Computation and the Role of Activation Functions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kiril Dichev, Filip Pawlowski, Albert-Jan Yzelman</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19342" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19342</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2babd04ddf70f201df2fa1a003998a91a1e266029f2a3a118314f226a7ce88f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2babd04ddf70f201df2fa1a003998a91a1e266029f2a3a118314f226a7ce88f0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Faster Distributed Inference-Only Recommender Systems via Bounded Lag Synchronous Collectives</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Orthogonal Approximate Message Passing with Optimal Spectral Initializations for Rectangular Spiked Matrix Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haohua Chen, Songbin Liu, Junjie Ma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19334" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19334</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72f86b8d15772f627ff898121603174c39243f416963a0e15e5c8ec2eec03c72_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/72f86b8d15772f627ff898121603174c39243f416963a0e15e5c8ec2eec03c72_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Orthogonal Approximate Message Passing with Optimal Spectral Initializations for Rectangular Spiked Matrix Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> JiaWei Zhu, ZiHeng Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19349" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19349</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a0b686fca34f155b782afa1f7cabe09de9b7bcb967ccfba8215a39405da5ba99_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> VIGOR+: Iterative Confounder Generation and Validation via LLM-CEVAE Feedback Loop</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning General Policies with Policy Gradient Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Ståhlberg, Blai Bonet, Hector Geffner</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19366" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19366</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c0ac6fc8f7779ac0ec6d29400a2e745e9a17133a7ceb22854a52d83825eca4e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning General Policies with Policy Gradient Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Canran Xiao, Jiabao Dou, Zhiming Lin, Zong Ke, Liwei Hou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19363" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19363</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc75c95e9b775b7503c7e61fa819d446488d179c11fba8ca58a1b86470bc4a23_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc75c95e9b775b7503c7e61fa819d446488d179c11fba8ca58a1b86470bc4a23_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Isshaan Singh, Divyansh Chawla, Anshu Garg, Shivin Mangal, Pallavi Gupta, Khushi Agarwal, Nimrat Singh Khalsa, Nandan Patel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19361" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19361</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afec297ffe8c1a2ba4e79439bf065a0920537f7decb882056013d6e7740f8e9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afec297ffe8c1a2ba4e79439bf065a0920537f7decb882056013d6e7740f8e9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Interpretable Hybrid Deep Q-Learning Framework for IoT-Based Food Spoilage Prediction with Synthetic Data Generation and Hardware Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christian Hägg, Kathlén Kohn, Giovanni Luca Marchetti, Boris Shapiro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19367</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa84d344152205d90f463c26b0bb9356b71dde7f412bdd03d7fd7f036a0b845_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Real-Time Machine Learning for Embedded Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Abdelmadjid Benmachiche, Khadija Rais, Hamda Slimi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19383" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19383</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d97ca2384a1b645ebcb761e5a1b2985732f10d8ceeea842160ea8a4c2445fca_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d97ca2384a1b645ebcb761e5a1b2985732f10d8ceeea842160ea8a4c2445fca_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Real-Time Machine Learning for Embedded Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19379" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19379</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1619f2062f011937d18aa7e18ebf2c490f57bd39c04a7d06493e15df8a15ae19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Brain-Grounded Axes for Reading and Steering LLM States</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sandro Andric</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19399" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19399</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01206bf10e0d62a8473930c796f72a63c7683f7ede540cfc495bca18c3dae148_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01206bf10e0d62a8473930c796f72a63c7683f7ede540cfc495bca18c3dae148_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Brain-Grounded Axes for Reading and Steering LLM States</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Research Program: Theory of Learning in Dynamical Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Elad Hazan, Shai Shalev Shwartz, Nathan Srebro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19410" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19410</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/879026bb2ccb2b89c867729f9f077e32888b82173c20d950c0ed5feda6519aa9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Research Program: Theory of Learning in Dynamical Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Symplectic Reservoir Representation of Legendre Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Robert Simon Fong, Gouhei Tanaka, Kazuyuki Aihara</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19409" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19409</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2e2995c2a2a446a77a09ae653f133649b499ee9a5ae92858d90f48c38a521f4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2e2995c2a2a446a77a09ae653f133649b499ee9a5ae92858d90f48c38a521f4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Symplectic Reservoir Representation of Legendre Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Attention Is Not What You Need</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhang Chong</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19428" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19428</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbe1f1a463179312610994fd34a110ca4bfc5b56928e49a6749dd43948421e91_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Attention Is Not What You Need</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rixin Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19439" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19439</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e313ba9b9f91e7572ee520f356be411e0bf445d35d515381b2d04e8c77cfcf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9e313ba9b9f91e7572ee520f356be411e0bf445d35d515381b2d04e8c77cfcf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Inverse Scattering Inspired Fourier Neural Operator for Time-Dependent PDE Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Consolo, Andrea Manno, Edoardo Amaldi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19440" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19440</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7c0b3cd4456cb3f28896dad50578a59f6ee4373475817c1d203ce6b2eda4d60_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7c0b3cd4456cb3f28896dad50578a59f6ee4373475817c1d203ce6b2eda4d60_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Binary Kernel Logistic Regression: a sparsity-inducing formulation and a convergent decomposition training algorithm</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] GLUE: Generative Latent Unification of Expertise-Informed Engineering Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tim Aebersold, Soheyl Massoudi, Mark D. Fuge</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19469" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19469</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e870c1241b521f8cd85e2b95b902b04bfcabd5e890393790f05186cc61348532_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e870c1241b521f8cd85e2b95b902b04bfcabd5e890393790f05186cc61348532_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GLUE: Generative Latent Unification of Expertise-Informed Engineering Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Lorenzo Capelli, Leandro de Souza Rosa, Gianluca Setti, Mauro Mangia, Riccardo Rovatti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19472" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19472</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40e0a2de9bc90f1d512acba9f8178e3caeb11f59b899b803bcea54b876c14e2e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multi-Layer Confidence Scoring for Detection of Out-of-Distribution Samples, Adversarial Attacks, and In-Distribution Misclassifications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nikita Volzhin, Soowhan Yoon</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19494" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19494</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0c1cdb2dc4e7f555b6151e7dd057ebb961c3137ad65952a50508e3d588bb4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Kolmogorov-Arnold Graph Neural Networks Applied to Inorganic Nanomaterials Dataset</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hafsa Benaddi, Mohammed Jouhari, Nouha Laamech, Anas Motii, Khalil Ibrahimi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19488" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19488</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a32520398008c395d68627f40b4f8898b363f28acb9b801f7e86c375bececdb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a32520398008c395d68627f40b4f8898b363f28acb9b801f7e86c375bececdb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Toward Scalable and Valid Conditional Independence Testing with Spectral Representations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alek Frohlich, Vladimir Kostic, Karim Lounici, Daniel Perazzo, Massimiliano Pontil</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19510" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19510</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67736573115d067bb1bcf8e6be20a765add92537af45beed64b6a3f2b096ef5c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67736573115d067bb1bcf8e6be20a765add92537af45beed64b6a3f2b096ef5c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Scalable and Valid Conditional Independence Testing with Spectral Representations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Martí Medina-Hern ández, Janos Kertész, Mihály Fazekas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19491" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19491</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4c4c038ee2a9e249f2f33259b933475235132c1cbefe5a1ac37223ea8fc2367_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4c4c038ee2a9e249f2f33259b933475235132c1cbefe5a1ac37223ea8fc2367_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning from sanctioned government suppliers: A machine learning and network science approach to detecting fraud and corruption in Mexico</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongliang Li, Nong Zhang, Zhewen Xu, Xiang Li, Changzheng Liu, Chongbo Zhao, Jie Wu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19506" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19506</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ab91ff5a253b798aeb4b7fa1cee40fb5a1319f0697a2094d06ad95557270ff9_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DK-STN: A Domain Knowledge Embedded Spatio-Temporal Network Model for MJO Forecast</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xueming Yan, Bo Yin, Yaochu Jin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19516" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19516</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/848324ae33b6180c9af25fd1e9aa4829e0fdb2a0ac2b46da8810accc276774e5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LacaDM: A Latent Causal Diffusion Model for Multiobjective Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Diego Hitzges, Guillaume Sagnol</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19527" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19527</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9be7dc2a227e30f57b54fae513beec5b2448e4823ad54422005ffd50328df87_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9be7dc2a227e30f57b54fae513beec5b2448e4823ad54422005ffd50328df87_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Deep Learning for Unrelated-Machines Scheduling: Handling Variable Dimensions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Hongsheng Xing, Qiuxin Si</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19530" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19530</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a398a1c7e656e700ae7d2e4b360c6e2a84d8a4f125de94406eb2fcbd1174cabf_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning Continuous Solvent Effects from Transient Flow Data: A Graph Neural Network Benchmark on Catechol Rearrangement</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Initialization of a Polyharmonic Cascade, Launch and Testing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuriy N. Bakhvalov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19524" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19524</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8a226c40c413901a8fba890ca183141879ee006dd07d881c31b02c4c795c952_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8a226c40c413901a8fba890ca183141879ee006dd07d881c31b02c4c795c952_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Initialization of a Polyharmonic Cascade, Launch and Testing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19554" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19554</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67ed5402e057af7c1649865e93cc5d4cb278374f1381f91c80951d25ce4f4c0e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] DFORD: Directional Feedback based Online Ordinal Regression Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Naresh Manwani, M Elamparithy, Tanish Taneja</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19550" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19550</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbbc721b57e400a0a633cbed7c7bd41446b344d459c761659f224385919cc0b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbbc721b57e400a0a633cbed7c7bd41446b344d459c761659f224385919cc0b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DFORD: Directional Feedback based Online Ordinal Regression Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kirill Djebko, Tom Baumann, Erik Dilger, Frank Puppe, Sergio Montenegro</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/559c74a4e132b0428b11e1b742ace3b49e9292ec3c666ac9dd536d79ee6c2a1f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LeLaR: The First In-Orbit Demonstration of an AI-Based Satellite Attitude Controller</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eric Zimmermann, Harley Wiltzer, Justin Szeto, David Alvarez-Melis, Lester Mackey</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8876f353bd3b6bc215381979aff16556177f0d7ca7e5b9cf3aa366d3fbd3c21d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8876f353bd3b6bc215381979aff16556177f0d7ca7e5b9cf3aa366d3fbd3c21d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KerJEPA: Kernel Discrepancies for Euclidean Self-Supervised Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rajyasri Roy, Dibyajyoti Nayak, Somdatta Goswami</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19643" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19643</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de5e312b39c5b4c9d5e5ba414dbf1be28f3eefa665a2062af2d2753365d7ba18_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de5e312b39c5b4c9d5e5ba414dbf1be28f3eefa665a2062af2d2753365d7ba18_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Best of Both Worlds: Hybridizing Neural Operators and Solvers for Stable Long-Horizon Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Deep Legendre Transform</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aleksey Minabutdinov, Patrick Cheridito</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19649" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19649</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6556ccc5250396e2d156a9c4ace9606ae9e710cca90dde9ad9a791f5bf821cd7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6556ccc5250396e2d156a9c4ace9606ae9e710cca90dde9ad9a791f5bf821cd7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Deep Legendre Transform</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19673" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19673</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Christopher Regan, Ying Xie</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17923" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17923</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0972c0f33f9a898aad22d9d466edb2d113b1f06ae271519a0310fbe4deb8326_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A curated UK rain radar data set for training and benchmarking nowcasting models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Viv Atureta, Rifki Priansyah Jasin, Stefan Siegert</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17924" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17924</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71fd337b26c3bfd8670295386b9f2b4df184043caa1e2c1b8a39442f6cdb1c15_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/71fd337b26c3bfd8670295386b9f2b4df184043caa1e2c1b8a39442f6cdb1c15_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A curated UK rain radar data set for training and benchmarking nowcasting models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dongdong Yang, Bin Li, Jiguang He, Yicheng Yan, Xiaoyu Zhang, Chongwen Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17928" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17928</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52bfb16cf6da30f529d6affbb7e78493e8d297701e513afd78f81efa7c4804bd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Beamforming Optimization for STAR-RIS-Assisted Communications: A Gradient-Based Meta Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Apoorv Vyas, Heng-Jui Chang, Cheng-Fu Yang, Po-Yao Huang, Luya Gao, Julius Richter, Sanyuan Chen, Matt Le, Piotr Dollár, Christoph Feichtenhofer, Ann Lee, Wei-Ning Hsu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19687" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19687</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3d411e351c730f5a4f6bcbb2b3a9ec59b568b77417127cf865aadf04270b18_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3d411e351c730f5a4f6bcbb2b3a9ec59b568b77417127cf865aadf04270b18_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Pushing the Frontier of Audiovisual Perception with Large-Scale Multimodal Correspondence Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Risk-Aware Financial Forecasting Enhanced by Machine Learning and Intuitionistic Fuzzy Multi-Criteria Decision-Making</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Safiye Turgay, Serkan Erdoğan, Željko Stević, Orhan Emre Elma, Tevfik Eren, Zhiyuan Wang, Mahmut Baydaş</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17936" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17936</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13f5144fba33f969e0e0ef3789e33db059938702b3b5d79afd93befb1670b02b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13f5144fba33f969e0e0ef3789e33db059938702b3b5d79afd93befb1670b02b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Risk-Aware Financial Forecasting Enhanced by Machine Learning and Intuitionistic Fuzzy Multi-Criteria Decision-Making</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sheryl Chen, Tony Wang, Kyle Feinstein</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17929" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17929</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4501ed870b87583df869b8985dc8410b30a47654c96f943771a6c67d4279480c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Disentangled representations via score-based variational autoencoders</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Benjamin S. H. Lyo, Eero P. Simoncelli, Cristina Savin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17127" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17127</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c4fff8035bd7179107df39681970450e10d3f516b687330e2caedbac602c68b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c4fff8035bd7179107df39681970450e10d3f516b687330e2caedbac602c68b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Disentangled representations via score-based variational autoencoders</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] MEGState: Phoneme Decoding from Magnetoencephalography Signals</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuntaro Suzuki, Chia-Chun Dan Hsu, Yu Tsao, Komei Sugiura</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17978" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17978</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82b8623a222c1e415238f07bfd00f186b0fd97345fe3a78288d0e4e33530c69c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/82b8623a222c1e415238f07bfd00f186b0fd97345fe3a78288d0e4e33530c69c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> MEGState: Phoneme Decoding from Magnetoencephalography Signals</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Sampling from multimodal distributions with warm starts: Non-asymptotic bounds for the Reweighted Annealed Leap-Point Sampler</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Holden Lee, Matheau Santana-Gijzen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.17977" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.17977</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb197c6366f5076ec8d83592cce39cf5b5b65c76bc5090ea04ea14c30cdf6873_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb197c6366f5076ec8d83592cce39cf5b5b65c76bc5090ea04ea14c30cdf6873_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sampling from multimodal distributions with warm starts: Non-asymptotic bounds for the Reweighted Annealed Leap-Point Sampler</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Shuttling Compiler for Trapped-Ion Quantum Computers Based on Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Fabian Kreppel, Reza Salkhordeh, Ferdinand Schmidt-Kaler, André Brinkmann</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18021" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18021</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0bdf00e2aa0c745b05913e16f268fd8bf9934eeb7b22056c328f85c5e744b2d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0bdf00e2aa0c745b05913e16f268fd8bf9934eeb7b22056c328f85c5e744b2d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Shuttling Compiler for Trapped-Ion Quantum Computers Based on Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Long-range electrostatics for machine learning interatomic potentials is easier than we thought</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dongjin Kim, Bingqing Cheng</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18029" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18029</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7547e964d0dd16907fbafcc9b548ddcc192b748a763449bd7c5098fb4f79beb3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7547e964d0dd16907fbafcc9b548ddcc192b748a763449bd7c5098fb4f79beb3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Long-range electrostatics for machine learning interatomic potentials is easier than we thought</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Causal Inference as Distribution Adaptation: Optimizing ATE Risk under Propensity Uncertainty</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ashley Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18083" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18083</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9e0e031bdf1e2542517c9521c36614dd83cab06c75d8cba77aef133d3bbf5e4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9e0e031bdf1e2542517c9521c36614dd83cab06c75d8cba77aef133d3bbf5e4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Causal Inference as Distribution Adaptation: Optimizing ATE Risk under Propensity Uncertainty</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Estimating Solvation Free Energies with Boltzmann Generators</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maximilian Schebek, Nikolas M. Froböse, Bettina G. Keller, Jutta Rogal</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18147" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18147</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/be00925063782c2d33d3147328ee4619cc5235ab4e60dcbb70ee97bf3dcb2f8f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/be00925063782c2d33d3147328ee4619cc5235ab4e60dcbb70ee97bf3dcb2f8f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Estimating Solvation Free Energies with Boltzmann Generators</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Exploring polymer classification with a hybrid single-photon quantum approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alexandrina Stoyanova, Bogdan Penkovsky</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18125" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18125</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aacb9f15cccaa0ab48dbf4d0906a45d2c5bb03514111402f33ab0cb75853841_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6aacb9f15cccaa0ab48dbf4d0906a45d2c5bb03514111402f33ab0cb75853841_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploring polymer classification with a hybrid single-photon quantum approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] CrystalFormer-CSP: Thinking Fast and Slow for Crystal Structure Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhendong Cao, Shigang Ou, Lei Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18251" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18251</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8cf6c41ccf7d3886a9f73f6faa6ec65ab26be6a067ce7c99f7b8336c5475e658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8cf6c41ccf7d3886a9f73f6faa6ec65ab26be6a067ce7c99f7b8336c5475e658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CrystalFormer-CSP: Thinking Fast and Slow for Crystal Structure Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] PSI3D: Plug-and-Play 3D Stochastic Inference with Slice-wise Latent Diffusion Prior</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wenhan Guo, Jinglun Yu, Yaning Wang, Jin U. Kang, Yu Sun</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18367" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18367</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98dc2d7a9538276a946338546d48fae623eb87f67d0a306a36ac1560cd23d715_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98dc2d7a9538276a946338546d48fae623eb87f67d0a306a36ac1560cd23d715_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PSI3D: Plug-and-Play 3D Stochastic Inference with Slice-wise Latent Diffusion Prior</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18263" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18263</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TICL+: A Case Study On Speech In-Context Learning for Children&#x27;s Speech Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Pushing the limits of one-dimensional NMR spectroscopy for automated structure elucidation using artificial intelligence</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Frank Hu, Jonathan M. Tubb, Dimitris Argyropoulos, Sergey Golotvin, Mikhail Elyashberg, Grant M. Rotskoff, Matthew W. Kanan, Thomas E. Markland</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18531" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18531</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08aee7a9e45a9f29af6d103a3e940fa95a91c99015126260b7c777d51567ce83_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08aee7a9e45a9f29af6d103a3e940fa95a91c99015126260b7c777d51567ce83_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Pushing the limits of one-dimensional NMR spectroscopy for automated structure elucidation using artificial intelligence</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Unsupervised Feature Selection via Robust Autoencoder and Adaptive Graph Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Feng Yu, MD Saifur Rahman Mazumder, Ying Su, Oscar Contreras Velasco</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18720</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0032f6c7f335886e0c863fb5416f2765511b0ba1ca06f1073d2eab5626b6c3f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d0032f6c7f335886e0c863fb5416f2765511b0ba1ca06f1073d2eab5626b6c3f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unsupervised Feature Selection via Robust Autoencoder and Adaptive Graph Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] RIS-Enabled Smart Wireless Environments: Fundamentals and Distributed Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> George C. Alexandropoulos, Kostantinos D. Katsanos, George Stamatelis, Ioannis Gavras</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18788" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18788</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02ac819b22b566bf908c19d15c96b16e6d173f4f375e5123bcf427c7b9405730_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02ac819b22b566bf908c19d15c96b16e6d173f4f375e5123bcf427c7b9405730_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> RIS-Enabled Smart Wireless Environments: Fundamentals and Distributed Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] On Conditional Stochastic Interpolation for Generative Nonlinear Sufficient Dimension Reduction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shuntuo Xu, Zhou Yu, Jian Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18971" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18971</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7664dca196bdcb61dc392090fb8c53996afeb07a245afa8d3b648e0385bd7f5d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7664dca196bdcb61dc392090fb8c53996afeb07a245afa8d3b648e0385bd7f5d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On Conditional Stochastic Interpolation for Generative Nonlinear Sufficient Dimension Reduction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yucheng Yang, Chiyuan Wang, Andreas Schaab, Benjamin Moll</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.18892" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.18892</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/203cc3fec3a819cdd9dd9fc028622d35f3a4ba54e87d06f53a4c83240df799a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Structural Reinforcement Learning for Heterogeneous Agent Macroeconomics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Finite-sample guarantees for data-driven forward-backward operator methods</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Filippo Fabiani, Barbara Franci</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19172" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19172</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8222a9719b756b6dad7e034a173dde65aa924d9d7b0789fd4e5882f3dfe97b3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b8222a9719b756b6dad7e034a173dde65aa924d9d7b0789fd4e5882f3dfe97b3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Finite-sample guarantees for data-driven forward-backward operator methods</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiaolong Wu, Qifeng Liao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19196" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19196</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3780b800013ebe275e2c8ef8b8f7ba281c86d44d100ae51b95eeb7d19999391_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3780b800013ebe275e2c8ef8b8f7ba281c86d44d100ae51b95eeb7d19999391_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haishan Ye</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19104" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19104</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1de9f54709e8dfd7512b0bf65bde1fbf69bbf9510338a82e721bb9ab43307b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e1de9f54709e8dfd7512b0bf65bde1fbf69bbf9510338a82e721bb9ab43307b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Explicit and Non-asymptotic Query Complexities of Rank-Based Zeroth-order Algorithm on Stochastic Smooth Functions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Cluster-Based Generalized Additive Models Informed by Random Fourier Features</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xin Huang, Jia Li, Jun Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19373" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19373</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f54a5120ec11e3d3fee124d496a72d9ed6944487b104802da2d971b4720063e2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f54a5120ec11e3d3fee124d496a72d9ed6944487b104802da2d971b4720063e2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Cluster-Based Generalized Additive Models Informed by Random Fourier Features</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] A Critical Assessment of Pattern Comparisons Between POD and Autoencoders in Intraventricular Flows</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Eneko Lazpita, Andrés Bell-Navas, Jesús Garicano-Mena, Petros Koumoutsakos, Soledad Le Clainche</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19376" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19376</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed5b488d452940ef72b893f7e49bf3407f54d6a1ce8a3642724d7bf4ddcad601_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed5b488d452940ef72b893f7e49bf3407f54d6a1ce8a3642724d7bf4ddcad601_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Critical Assessment of Pattern Comparisons Between POD and Autoencoders in Intraventricular Flows</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Real-Time Streamable Generative Speech Restoration with Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Simon Welker, Bunlong Lay, Maris Hillemann, Tal Peer, Timo Gerkmann</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19442" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19442</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50f384e81e75842e398563da395c9a42cafd7dfeb79c90bc7c4489b17d033102_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50f384e81e75842e398563da395c9a42cafd7dfeb79c90bc7c4489b17d033102_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Real-Time Streamable Generative Speech Restoration with Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251223] Active Convolved Illumination with Deep Transfer Learning for Complex Beam Transmission through Atmospheric Turbulence</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Adrian A. Moazzam, Anindya Ghoshroy, Breeanne Heusdens, Durdu O. Guney, Roohollah Askari</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19540" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19540</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aefac8efeaa58dab809884787824024dfad8ec6cfb7ca6a8de7663af53c553bc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aefac8efeaa58dab809884787824024dfad8ec6cfb7ca6a8de7663af53c553bc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Active Convolved Illumination with Deep Transfer Learning for Complex Beam Transmission through Atmospheric Turbulence</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-24">2025-12-24<a href="#2025-12-24" class="hash-link" aria-label="Direct link to 2025-12-24" title="Direct link to 2025-12-24" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251224] QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19696" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19696</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b77d355579fa14e02c66f844a9c1cf1fbc3d68fee2d28b38fc709f013395b1a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QoS-Aware Dynamic CU Selection in O-RAN with Graph-Based Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Md Nahid Hasan Shuvo, Moinul Hossain</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19711" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19711</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d516fcc6c3de6b0e65c078e5e3f3dda23bfd77fbb9c5f4abfe2c509c2cb6dfe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxuan Yin, Shengke Zhou, Yunjie Zhang, Ajay Mohindra, Boxun Xu, Peng Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19701</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebe0c6f8e6d98607a87a162a4a1cada21d732348d823658c9451d5ce5608a7d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Large Language Models for EDA Cloud Job Resource and Lifetime Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Behrooz Mamandipoor, Chun-Nan Hsu, Martin Krause, Ulrich H. Schmidt, Rodney A. Gabriel</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19716" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19716</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b80fac6c07719f0fdc3b2a60068a2f3820d61d75d5655632ad18fc7fbee5f80_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Development and external validation of a multimodal artificial intelligence mortality prediction model of critically ill patients using multicenter data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19707" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19707</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Taoran Sheng, Manfred Huber</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19713" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19713</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8069c49480aa4056d903366d9a07ef262001809b60e89caaaab99b1ab6318bb6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8069c49480aa4056d903366d9a07ef262001809b60e89caaaab99b1ab6318bb6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Node-Level Financial Optimization in Demand Forecasting Through Dynamic Cost Asymmetry and Feedback Mechanism</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alessandro Casadei, Clemens Grupp, Sreyoshi Bhaduri, Lu Guo, Wilson Fung, Rohit Malshe, Raj Ratan, Ankush Pole, Arkajit Rakshit</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19722" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19722</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5fc3669c6e3b3729a8ceeab7556b8b190a71237342736f2d91f0e9e99de3dc0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c5fc3669c6e3b3729a8ceeab7556b8b190a71237342736f2d91f0e9e99de3dc0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Node-Level Financial Optimization in Demand Forecasting Through Dynamic Cost Asymmetry and Feedback Mechanism</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Per-Axis Weight Deltas for Frequent Model Updates</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stefan Kuyumdzhiev, Radostin Cholakov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19720" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19720</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fced4b263f86d7aa4d12f96b832ddc3447334c926ee67499537f6d38e8e740d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fced4b263f86d7aa4d12f96b832ddc3447334c926ee67499537f6d38e8e740d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Per-Axis Weight Deltas for Frequent Model Updates</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhan Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19717" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19717</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ee62945031af7f6dac3a6d51384974eec1f8f5db6dd103388502d84eb58bc6a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vineet Yadav</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19721" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19721</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/476a71567ad37a78f3007d1e492eb010eed6a7f8bed8a187d46ae8e80465f4f5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/476a71567ad37a78f3007d1e492eb010eed6a7f8bed8a187d46ae8e80465f4f5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zihao Lv, Siqi Ai, Yanbin Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19719" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19719</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6292853f8fb29c3648a6a9e7a018fcb02691dba13e4d6ce37a63f296f046554_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Multiscale Dual-path Feature Aggregation Network for Remaining Useful Life Prediction of Lithium-Ion Batteries</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Vasileios C. Pezoulas, Nikolaos S. Tachos, Eleni Georga, Kostas Marias, Manolis Tsiknakis, Dimitrios I. Fotiadis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19718" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19718</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/690024688881d156d3131447c4b795c922984c2e3732a32a3b139b183a1be23e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/690024688881d156d3131447c4b795c922984c2e3732a32a3b139b183a1be23e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Synthetic Data Blueprint (SDB): A modular framework for the statistical, structural, and graph-based evaluation of synthetic tabular data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Tiny, On-Device Decision Makers with the MiniConv Library</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Carlos Purves</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19726" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19726</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8fcebc0e7acd2aa33081184298763fb8df6f0a43f23fb341b0e84da9a69d1bd6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Tiny, On-Device Decision Makers with the MiniConv Library</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Srishti Gupta, Riccardo Balia, Daniele Angioni, Fabio Brau, Maura Pintor, Ambra Demontis, Alessandro Sebastian, Salvatore Mario Carta, Fabio Roli, Battista Biggio</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19725" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19725</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a6b157cb48d9bcd740b085c12288bed5c0e95c01a7146a5e7c2e50b7d77787d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a6b157cb48d9bcd740b085c12288bed5c0e95c01a7146a5e7c2e50b7d77787d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Out-of-Distribution Detection for Continual Learning: Design Principles and Benchmarking</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Trend Extrapolation for Technology Forecasting: Leveraging LSTM Neural Networks for Trend Analysis of Space Exploration Vessels</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peng-Hung Tsai, Daniel Berleant</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19727" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19727</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2c9404cbdd59c5c56c246473b4a6996ca55f6051700faa6c654323d6990a290_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2c9404cbdd59c5c56c246473b4a6996ca55f6051700faa6c654323d6990a290_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Trend Extrapolation for Technology Forecasting: Leveraging LSTM Neural Networks for Trend Analysis of Space Exploration Vessels</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Firas Bayram, Bestoun S. Ahmed, Erik Hallin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19723" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19723</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e87a73b8e332e90e3cd2839f1faa8882cdeef6cb35e274b072b141a0cabb8572_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e87a73b8e332e90e3cd2839f1faa8882cdeef6cb35e274b072b141a0cabb8572_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Hard Negative Sample-Augmented DPO Post-Training for Small Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Haocheng Lu, Minjun Zhu, Henry Yu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19728" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19728</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c371de45b1b11fd08dee5a184a8d1c0b7de0a0ff5ecd8c96c44e8fddf3eabedc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c371de45b1b11fd08dee5a184a8d1c0b7de0a0ff5ecd8c96c44e8fddf3eabedc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Hard Negative Sample-Augmented DPO Post-Training for Small Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19730" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19730</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66bbe64f6f3cac5df3dfd69a018806ee7d1973ac071d8af57c13752826c622fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66bbe64f6f3cac5df3dfd69a018806ee7d1973ac071d8af57c13752826c622fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] High-Performance Self-Supervised Learning by Joint Training of Flow Matching</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kosuke Ukita, Tsuyoshi Okita</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19729" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19729</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/269f1eff8cf71b204b6147341b992a81faef6468f33e5edd7a5be137a0ac9100_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> High-Performance Self-Supervised Learning by Joint Training of Flow Matching</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Leakage-Aware Bandgap Prediction on the JARVIS-DFT Dataset: A Phase-Wise Feature Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gaurav Kumar Sharma</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19732" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19732</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53da428992d5e5cae28642416139ec0d148864a5c060b683ac9e143fe97079ee_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53da428992d5e5cae28642416139ec0d148864a5c060b683ac9e143fe97079ee_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Leakage-Aware Bandgap Prediction on the JARVIS-DFT Dataset: A Phase-Wise Feature Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiangzhong Luo, Weichen Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19731" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19731</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c10d82314834148af959284b60a6d6f0fa9e36928106648626f8c43d4f07b79_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c10d82314834148af959284b60a6d6f0fa9e36928106648626f8c43d4f07b79_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wilson Fung, Lu Guo, Drake Hilliard, Alessandro Casadei, Raj Ratan, Sreyoshi Bhaduri, Adi Surve, Nikhil Agarwal, Rohit Malshe, Pavan Mullapudi, Hungjen Wang, Saurabh Doodhwala, Ankush Pole, Arkajit Rakshit</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19738" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19738</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa995500ed323b0099b96191763cdf14300972d797c5bdf631faa22d483ef8d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa995500ed323b0099b96191763cdf14300972d797c5bdf631faa22d483ef8d4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] The Deleuzian Representation Hypothesis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Clément Cornet, Romaric Besançon, Hervé Le Borgne</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19734" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19734</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/877f862cfd6b85ad4699167cc9b9bc17de797ef85a7ede6911637da4967d6121_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/877f862cfd6b85ad4699167cc9b9bc17de797ef85a7ede6911637da4967d6121_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Deleuzian Representation Hypothesis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Clément Elliker, Jesse Read, Sonia Vanier, Albert Bifet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19737" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19737</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a37e9a570297730f5200e5c0dcac9576f29dc77d8856f607f480d2a083088332_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simulation-Driven Railway Delay Prediction: An Imitation Learning Approach</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gongli Xi, Ye Tian, Mengyu Yang, Zhenyu Zhao, Yuchao Zhang, Xiangyang Gong, Xirong Que, Wendong Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19736" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19736</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68578352cc68ad1305abf54d27488dc8db7f857ff2484ef8acd9ab80b0db8641_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> CoPHo: Classifier-guided Conditional Topology Generation with Persistent Homology</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gangxiong Zhang, Yongchao Long</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19735" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19735</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffac075f9a08ac05f63c8e47026ade8aa961ca7bcc7071d314dbbcf27a110f66_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ffac075f9a08ac05f63c8e47026ade8aa961ca7bcc7071d314dbbcf27a110f66_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] EdgeFlex-Transformer: Transformer Inference for Edge Devices</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shoaib Mohammad, Guanqun Song, Ting Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19741" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19741</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a472c5a3779ea5b970e030fee19030719f5db1d085d239de2dc5df41dffd7439_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a472c5a3779ea5b970e030fee19030719f5db1d085d239de2dc5df41dffd7439_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> EdgeFlex-Transformer: Transformer Inference for Edge Devices</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kousar Raza, Faizan Ali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19740" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19740</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f547c21d7d60b5ce4f92522c83aa7c297fc051a77b6eddf69ef405348fda9d8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f547c21d7d60b5ce4f92522c83aa7c297fc051a77b6eddf69ef405348fda9d8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Asia Cup 2025: A Structured T20 Match-Level Dataset and Exploratory Analysis for Cricket Analytics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] On-device Large Multi-modal Agent for Human Activity Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Md Shakhrul Iman Siam, Ishtiaque Ahmed Showmik, Guanqun Song, Ting Zhu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19742" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19742</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f3cc1dde2877d131c87748e2a0e8975b217b5776f2152e724bf632e2fa6532f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f3cc1dde2877d131c87748e2a0e8975b217b5776f2152e724bf632e2fa6532f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> On-device Large Multi-modal Agent for Human Activity Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sasan Sharifipour, Constantino Álvarez Casado, Manuel Lage Cañellas, Miguel Bordallo López</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19743" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19743</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/28b9eb6359f294d9654c6f1fea215bc4726b236c77ba0b6790735d53dbad5ead_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> From Theory to Throughput: CUDA-Optimized APML for Large-Batch 3D Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] OASI: Objective-Aware Surrogate Initialization for Multi-Objective Bayesian Optimization in TinyML Keyword Spotting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Soumen Garai, Suman Samui</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19739" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19739</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9778cadae68709b008dcf5db962164fda68a414cd3d9f0a2847361f564c06bad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9778cadae68709b008dcf5db962164fda68a414cd3d9f0a2847361f564c06bad_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> OASI: Objective-Aware Surrogate Initialization for Multi-Objective Bayesian Optimization in TinyML Keyword Spotting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DeepBridge: A Unified and Production-Ready Framework for Multi-Dimensional Machine Learning Validation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Gustavo Coelho Haase, Paulo Henrique Dourado da Silva</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19744" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19744</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bccd562ab93d21bfa941fe354c60f5ea1f28b2e74751c8d34532405481aeeca_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bccd562ab93d21bfa941fe354c60f5ea1f28b2e74751c8d34532405481aeeca_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DeepBridge: A Unified and Production-Ready Framework for Multi-Dimensional Machine Learning Validation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sumin Park, Noseong Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19765" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19765</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/515767751abfd73b2b6370592d087c270228e210ccda8fa867a672db0ae07a01_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learning to Design City-scale Transit Routes</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Bibek Poudel, Weizi Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19767" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19767</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48f5a0e4652c24c99f21521fcb359e848d25f4d63cc6c81bee61cbd2088a47c6_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning to Design City-scale Transit Routes</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A K-Means, Ward and DBSCAN repeatability study</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anthony Bertrand, Engelbert Mephu Nguifo, Violaine Antoine, David Hill</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19772" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19772</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b606a0690bd58fd61c6e296efa76193ecfe74e0fd82dcf2bd79d638111e3e1d1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A K-Means, Ward and DBSCAN repeatability study</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Deepit Sapru</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19805" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19805</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb04e43886d4319737a1d917f74a55c539bf9fd5290a700f1e160de279d18cef_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bb04e43886d4319737a1d917f74a55c539bf9fd5290a700f1e160de279d18cef_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Guardrailed Uplift Targeting: A Causal Optimization Playbook for Marketing Strategy</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reduced Order Modeling for Tsunami Forecasting with Bayesian Hierarchical Pooling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shane X. Coffing, John Tipton, Arvind T. Mohan, Darren Engwirda</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19804" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19804</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e689d3fa5a81d3d8eba58c25d7cb4a0158b1806b3118990d514118edc1fa566_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e689d3fa5a81d3d8eba58c25d7cb4a0158b1806b3118990d514118edc1fa566_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reduced Order Modeling for Tsunami Forecasting with Bayesian Hierarchical Pooling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] UCCL-EP: Portable Expert-Parallel Communication</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziming Mao, Yihan Zhang, Chihan Cui, Kaichao You, Zhongjie Chen, Zhiying Xu, Scott Shenker, Costin Raiciu, Yang Zhou, Ion Stoica</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19849" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19849</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb2d143c0a9d64bd2c5bdf4142e8e3a096290fd8319372321c00c3c17d53b658_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> UCCL-EP: Portable Expert-Parallel Communication</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fine-Tuned In-Context Learners for Efficient Adaptation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19879" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19879</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31980c4d9f6b1c6d6c1f0f41df293fd637d43c4ea2f2de5d26aa825310d8bdbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fine-Tuned In-Context Learners for Efficient Adaptation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Detecting cyberbullying in Spanish texts through deep learning techniques</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Paúl Cumba-Armijos, Diego Riofrío-Luzcando, Verónica Rodríguez-Arboleda, Joe Carrión-Jumbo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19899" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19899</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2f7ccac215958604ec2bafb628962c08cfada143b59dda8159af7e4af21661_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2f7ccac215958604ec2bafb628962c08cfada143b59dda8159af7e4af21661_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Detecting cyberbullying in Spanish texts through deep learning techniques</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19920" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19920</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/33255a480cb8654f8d9838cb7a634102f7086c3eaac9fb63148c10866248563a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Indranil Halder, Cengiz Pehlevan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19905" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19905</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1e6db0153f278bc11740f6ab7077ed6a29fff1f323057711a5dc1210d6e99fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maxime Lacour, Pu Ren, Rie Nakata, Nori Nakata, Michael Mahoney</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19909" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19909</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e80ac4736f89a1123273e8c6f77a605a941de3087891673a6d7728a3d0998_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] The Seismic Wavefield Common Task Framework</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Alexey Yermakov, Yue Zhao, Marine Denolle, Yiyu Ni, Philippe M. Wyder, Judah Goldfeder, Stefano Riva, Jan Williams, David Zoro, Amy Sara Rude, Matteo Tomasetto, Joe Germany, Joseph Bakarji, Georg Maierhofer, Miles Cranmer, J. Nathan Kutz</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19927" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19927</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b59879c33166ae9f8c44c6fb1768cff1db7963674dc0f8347a443a44df80bf19_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b59879c33166ae9f8c44c6fb1768cff1db7963674dc0f8347a443a44df80bf19_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Seismic Wavefield Common Task Framework</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Samruddhi Baviskar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19935" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19935</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f15b3890b1332bf926501d440f418e2e71c3b0c8c5b3dd19380d13e172c25ac_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Conditional Adversarial Fragility in Financial Machine Learning under Macroeconomic Stress</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Vehicle-centric Perception via Multimodal Structured Pre-training</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Wentao Wu, Xiao Wang, Chenglong Li, Jin Tang, Bin Luo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19934" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19934</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25393280cf5e09ecc25c375a88de26bef6b6904fd90a6775cf7591ed8a615fe1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Vehicle-centric Perception via Multimodal Structured Pre-training</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Block-Recurrent Dynamics in Vision Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19941" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19941</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e10f9b4ab6d210902b2c5092ebfe1fcc82dd7a3d2032bfc97fbfadd16867c2a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Block-Recurrent Dynamics in Vision Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Surya Jayakumar, Kieran Sullivan, John McLaughlin, Christine O&#x27;Meara, Indrakshi Dey</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19970" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19970</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04d93c1a47d24166acae7ed5012d760c9a02de04651f40a319ded305b7aaad13_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/04d93c1a47d24166acae7ed5012d760c9a02de04651f40a319ded305b7aaad13_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Bloom Filter Encoding for Machine Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> John Cartmell, Mihaela Cardei, Ionut Cardei</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19991" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19991</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e677d5a3d466425f205097a14f528d2211f9cb2642b715b0647694a1db34a243_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e677d5a3d466425f205097a14f528d2211f9cb2642b715b0647694a1db34a243_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Bloom Filter Encoding for Machine Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] A Novel CNN Gradient Boosting Ensemble for Guava Disease Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tamim Ahasan Rijon, Yeasin Arafath</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19989" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19989</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7415dab1086d45b2bb6f7a49ab33be753b3da047de23310de552ead99dc2448_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e7415dab1086d45b2bb6f7a49ab33be753b3da047de23310de552ead99dc2448_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> A Novel CNN Gradient Boosting Ensemble for Guava Disease Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19995" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19995</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Schoenfeld&#x27;s Anatomy of Mathematical Reasoning by Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Control Variate Score Matching for Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Khaled Kahouli, Romuald Elie, Klaus-Robert Müller, Quentin Berthet, Oliver T. Unke, Arnaud Doucet</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20003" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20003</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99c1fcd9cfbbb5a241296c106e6f4311b324493691659f27747af21f56a722fe_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99c1fcd9cfbbb5a241296c106e6f4311b324493691659f27747af21f56a722fe_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Control Variate Score Matching for Diffusion Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Sukumar Kishanthan, Asela Hevapathige</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20006" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20006</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/767f4e4dcb2738c000b0ea66f1109ff56b696feb519040f06df4fdd1a29c343a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/767f4e4dcb2738c000b0ea66f1109ff56b696feb519040f06df4fdd1a29c343a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rahul Yumlembam, Biju Issac, Seibu Mary Jacob, Longzhi Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20004" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20004</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea3f077bcaec1c639c8029881602d31bdf125a8cbefc2e15ec9ba3e07c126ee1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jiacheng You, Jingcheng Yang, Yuhang Xie, Zhongxuan Wu, Xiucheng Li, Feng Li, Pengjie Wang, Jian Xu, Bo Zheng, Xinyang Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20002" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20002</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3eef74ab05c46cb25ce1372769f7b8dc5bc12b1c381a6076e807a4bdde96f36_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3eef74ab05c46cb25ce1372769f7b8dc5bc12b1c381a6076e807a4bdde96f36_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuan Gao, Zhenguo Dong, Xuelong Wang, Zhiqiang Wang, Yong Zhang, Shaofan Wang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20028</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a6ada3496efb972d8c3a130ea0af749449dc6804b758999852b9def0e9692a4_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DecoKAN: Interpretable Decomposition for Forecasting Cryptocurrency Market Dynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Deep Eigenspace Network and Its Application to Parametric Non-selfadjoint Eigenvalue Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> H. Li, J. Sun, Z. Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20058" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20058</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f3aee744984f754345f38a1211552354aa6d648480458cd66df06732c2b2624_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f3aee744984f754345f38a1211552354aa6d648480458cd66df06732c2b2624_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Deep Eigenspace Network and Its Application to Parametric Non-selfadjoint Eigenvalue Problems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] An Optimal Policy for Learning Controllable Dynamics by Exploration</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Peter N. Loxley</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20053" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20053</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1955af7668fd6f7c26946b76a3cbf622271164ba70999a4181146562f156fbbc_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> An Optimal Policy for Learning Controllable Dynamics by Exploration</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DS-HGCN: A Dual-Stream Hypergraph Convolutional Network for Predicting Student Engagement via Social Contagion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ziyang Fan, Li Tao, Yi Wang, Jingwei Qu, Ying Wang, Fei Jiang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20059" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20059</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c40788fe60a93cff593d92f44508a7f4d8652aa38e707e2a9892801ec0179a3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c40788fe60a93cff593d92f44508a7f4d8652aa38e707e2a9892801ec0179a3_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DS-HGCN: A Dual-Stream Hypergraph Convolutional Network for Predicting Student Engagement via Social Contagion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mingue Park, Jisung Hwang, Seungwoo Yoo, Kyeongmin Yeo, Minhyuk Sung</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20063" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20063</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1f331573ffd5fdda741a1d0056236e66fefa140bd0c2b8c4b173e3519544061_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d1f331573ffd5fdda741a1d0056236e66fefa140bd0c2b8c4b173e3519544061_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jeehong Kim, Youngseok Hwang, Minchan Kim, Sungho Bae, Hyunwoo Park</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20086" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20086</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/95b1bc86a744c86f68507c2b101c06be33b9804cc84964060682c34e2802c63e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Spatio-Temporal Graphs Beyond Grids: Benchmark for Maritime Anomaly Detection</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yanjie Li, Jian Xu, Xueqing Chen, Lina Yu, Shiming Xiang, Weijun Li, Cheng-lin Liu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20084" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20084</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3ad5d1a3b18c9e1109d65023aa18a9c4b5eaddb7fbf1b86de532c25025f845a7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Jensen-Shannon Divergence Message-Passing for Rich-Text Graph Representation Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zuo Wang, Ye Yuan</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20094" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20094</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d8ebe19b950699158b26962ef207ee20be9d3fd1a9e78b063e5d97cd6c18f0a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2d8ebe19b950699158b26962ef207ee20be9d3fd1a9e78b063e5d97cd6c18f0a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Jensen-Shannon Divergence Message-Passing for Rich-Text Graph Representation Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Information-directed sampling for bandits: a primer</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Annika Hirling, Giorgio Nicoletti, Antonio Celani</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20096" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20096</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bda193cb418441da95d0440f5f59e93b002d7bab9c57780520c427e9d3126c5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2bda193cb418441da95d0440f5f59e93b002d7bab9c57780520c427e9d3126c5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Information-directed sampling for bandits: a primer</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20111" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20111</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuanhao Chen, Qi Liu, Pengbin Chen, Zhongjian Qiao, Yanjie Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20115" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20115</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5c5ab959b1aabba8373388341144fb9d59c759f4a45a536ba853663551ebb84_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5c5ab959b1aabba8373388341144fb9d59c759f4a45a536ba853663551ebb84_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20145" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20145</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Retrieval-augmented Prompt Learning for Pre-trained Foundation Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Learning to Reason in LLMs by Expectation Maximization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Junghyun Lee, Branislav Kveton, Sunav Choudhary, Subhojyoti Mukherjee, Anup Rao, Ryan A. Rossi, Alexa Siu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20169" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20169</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fc3f6af733f26b26d15d5332cff89ae665d865f5359eb651dbf107c200c4794_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fc3f6af733f26b26d15d5332cff89ae665d865f5359eb651dbf107c200c4794_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Learning to Reason in LLMs by Expectation Maximization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Songze Li, Jiameng Cheng, Yiming Li, Xiaojun Jia, Dacheng Tao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20168" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20168</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/12bfaa681af3521489a5c856a7d28bf207a72778a776d4ae80d7e0271f100e3b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] NeuralCrop: Combining physics and machine learning for improved crop yield predictions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yunan Lin, Sebastian Bathiany, Maha Badri, Maximilian Gelbrecht, Philipp Hess, Brian Groenke, Jens Heinke, Christoph Müller, Niklas Boers</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20177" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20177</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b11ac7dee2967ebac7497c5b7c4ac412a47aa4080e36cf0d94605e0611bcf487_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b11ac7dee2967ebac7497c5b7c4ac412a47aa4080e36cf0d94605e0611bcf487_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NeuralCrop: Combining physics and machine learning for improved crop yield predictions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kausthubh Manda, Raghuram Bharadwaj Diddigi</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20220" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20220</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96bb0ad288cee461b985922b13e1446ef6b03b8ee1b5f20f1e908e0e81174e2b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96bb0ad288cee461b985922b13e1446ef6b03b8ee1b5f20f1e908e0e81174e2b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Cost-TrustFL: Cost-Aware Hierarchical Federated Learning with Lightweight Reputation Evaluation across Multi-Cloud</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jixiao Yang, Jinyu Chen, Zixiao Huang, Chengda Xu, Chi Zhang, Sijia Li</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20218" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20218</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfa99879bd1a1c5083fc9e9363cb2903b42568a0726a124b591c9da1ed744c4f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfa99879bd1a1c5083fc9e9363cb2903b42568a0726a124b591c9da1ed744c4f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Cost-TrustFL: Cost-Aware Hierarchical Federated Learning with Lightweight Reputation Evaluation across Multi-Cloud</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Adaptive Multi-task Learning for Probabilistic Load Forecasting</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Onintze Zaballa, Verónica Álvarez, Santiago Mazuelas</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20232" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20232</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f105781b741c5e961d80700aae99a9a5f5491196f3957723a0ad4a9d0ceee4f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f105781b741c5e961d80700aae99a9a5f5491196f3957723a0ad4a9d0ceee4f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Adaptive Multi-task Learning for Probabilistic Load Forecasting</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] How I Met Your Bias: Investigating Bias Amplification in Diffusion Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nathan Roos, Ekaterina Iakovleva, Ani Gjergji, Vito Paolo Pastore, Enzo Tartaglione</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20233" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20233</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c43be0c18a78b4304c027f45372c35a663531d4f9536a15c2b4ca0dbb155b2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c43be0c18a78b4304c027f45372c35a663531d4f9536a15c2b4ca0dbb155b2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> How I Met Your Bias: Investigating Bias Amplification in Diffusion Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xuanyu Hu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20249" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20249</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1c6a732f9a0082b695f01f79b2bcc47f909daa0f9d50a6af4d86a633213b328_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1c6a732f9a0082b695f01f79b2bcc47f909daa0f9d50a6af4d86a633213b328_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuanjian Xu, Yuan Shuai, Jianing Hao, Guang Zhang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20272" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20272</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/336f6868f026371e14a0b1bb308e5d34193071d2aae6293400dd9ee01e404c90_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/336f6868f026371e14a0b1bb308e5d34193071d2aae6293400dd9ee01e404c90_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yuxing Gan, Ziyu Lei</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20291" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20291</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00b419d6d6ce75f3399c7716ea75c97138302ae8a2a1e0c9b1547fa29a97bde7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/00b419d6d6ce75f3399c7716ea75c97138302ae8a2a1e0c9b1547fa29a97bde7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] DeepONet-accelerated Bayesian inversion for moving boundary problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Marco A. Iglesias, Michael. E. Causon, Mikhail Y. Matveev, Andreas Endruweit, Michael .V. Tretyakov</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20268" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20268</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cca57b0bdfa7635748d75eae61d7af10d528a81997788a87eb9ab2703231769b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cca57b0bdfa7635748d75eae61d7af10d528a81997788a87eb9ab2703231769b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> DeepONet-accelerated Bayesian inversion for moving boundary problems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Algorithm for Interpretable Graph Features via Motivic Persistent Cohomology</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yoshihiro Maruyama</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20311" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20311</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862ac961bd55b0b8dc1a2ea1c32580f402c570473c4f0ee0635c937b87e810e8_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862ac961bd55b0b8dc1a2ea1c32580f402c570473c4f0ee0635c937b87e810e8_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Algorithm for Interpretable Graph Features via Motivic Persistent Cohomology</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20312" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20312</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfc9634e9cda6fc809e3b25d9f21b937a2d8630ecb3e8bb9633968f223bb4e2d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mrinmay Sen, Subhrajit Nag</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20329" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20329</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f60b7e61ea92d36b52de81bc3df02c7af567b1cd9eb4626ad016c3ce36765e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f60b7e61ea92d36b52de81bc3df02c7af567b1cd9eb4626ad016c3ce36765e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedDPC : Handling Data Heterogeneity and Partial Client Participation in Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Toward Explaining Large Language Models in Software Engineering Tasks</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20328" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20328</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Toward Explaining Large Language Models in Software Engineering Tasks</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Top-K Exterior Power Persistent Homology: Algorithm, Structure, and Stability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yoshihiro Maruyama</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20325" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20325</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d819bb4159585b74aeaf35355e16ef7a49b64ef54f670ff861804098262da1c5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d819bb4159585b74aeaf35355e16ef7a49b64ef54f670ff861804098262da1c5_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Top-K Exterior Power Persistent Homology: Algorithm, Structure, and Stability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Emilia Majerz, Witold Dzwinel, Jacek Kitowski</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20346" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20346</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d6aa7726e909753c196217ccc3bdf17d07a9339b0fc1d35361587823848df71_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d6aa7726e909753c196217ccc3bdf17d07a9339b0fc1d35361587823848df71_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Inverse Autoregressive Flows for Zero Degree Calorimeter fast simulation</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Physics-guided Neural Network-based Shaft Power Prediction for Vessels</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Dogan Altan, Hamza Haruna Mohammed, Glenn Terje Lines, Dusica Marijan, Arnbjørn Maressa</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20348" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20348</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2fe8932d1c82e06128e6863fee4baaa3d988167af43502e32d83bf972eb356_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2fe8932d1c82e06128e6863fee4baaa3d988167af43502e32d83bf972eb356_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Physics-guided Neural Network-based Shaft Power Prediction for Vessels</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daniel M. Jimenez-Gutierrez, Mehrdad Hassanzadeh, Aris Anagnostopoulos, Ioannis Chatzigiannakis, Andrea Vitaletti</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20363" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20363</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59262adfe1a821db6db6b416af65f0ab7cc67a6943505bf052c9306bf801e87f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Clust-PSI-PFL: A Population Stability Index Approach for Clustered Non-IID Personalized Federated Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Field-Space Attention for Structure-Preserving Earth System Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Maximilian Witte, Johannes Meuer, Étienne Plésiat, Christopher Kadow</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20350" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20350</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8623c14b77fd771294e1b936a58143cff6a715df1b4a5026fe2d59708383e6e2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8623c14b77fd771294e1b936a58143cff6a715df1b4a5026fe2d59708383e6e2_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Field-Space Attention for Structure-Preserving Earth System Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Xuan-An Le, Minh-Nam Tran, Son Nguyen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20403" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20403</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61964964aad2cf8cac29992fe364ccde3a687f3d0e6b42b8148ce3b0f96dee99_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61964964aad2cf8cac29992fe364ccde3a687f3d0e6b42b8148ce3b0f96dee99_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Corey Adams, Rishikesh Ranade, Ram Cherukuri, Sanjay Choudhry</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20399" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20399</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6966b4d62e10f76b2120afc54fcd95e1e717c9aef6840968117642fb0eb9df42_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6966b4d62e10f76b2120afc54fcd95e1e717c9aef6840968117642fb0eb9df42_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GeoTransolver: Learning Physics on Irregumar Domains Using Multi-scale Geometry Aware Physics Attention Transformer</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rajdeep Chatterjee, Sudip Chakrabarty, Trishaani Acharjee, Deepanjali Mishra</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20407" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20407</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e762dea30a9edc887d84deefc367d35dd7c953e636f54a824f1e7f853c9d370f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> AUDRON: A Deep Learning Framework with Fused Acoustic Signatures for Drone Type Recognition</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Simplifying Multi-Task Architectures Through Task-Specific Normalization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mihai Suteu, Ovidiu Serban</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20420" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20420</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d24e6af533166dd44855079b97d7233c65878aa61e02267e65f4e306467d04b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Simplifying Multi-Task Architectures Through Task-Specific Normalization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Machine Learning to Predict Digital Frustration from Clickstream Data</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Jibin Joseph</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20438" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20438</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54b66cbccae694b64cb30bccff552dc3cd9c19b7ad622d4169444f7f1f67fdcb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/54b66cbccae694b64cb30bccff552dc3cd9c19b7ad622d4169444f7f1f67fdcb_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Machine Learning to Predict Digital Frustration from Clickstream Data</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Explainable time-series forecasting with sampling-free SHAP for Transformers</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthias Hertel, Sebastian Pütz, Ralf Mikut, Veit Hagenmeyer, Benjamin Schäfer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20514" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20514</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce0ac2e96e47ae16fe2a238adc470cf7f3968e7b03d41a218d1483b207e0e532_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce0ac2e96e47ae16fe2a238adc470cf7f3968e7b03d41a218d1483b207e0e532_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Explainable time-series forecasting with sampling-free SHAP for Transformers</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Recurrent Off-Policy Deep Reinforcement Learning Doesn&#x27;t Have to be Slow</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Tyler Clark, Christine Evers, Jonathon Hare</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20513" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20513</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfed8377a526fc8b1686b7063bcf7aa6afc36205aa596ab393544501923d4a4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfed8377a526fc8b1686b7063bcf7aa6afc36205aa596ab393544501923d4a4a_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Recurrent Off-Policy Deep Reinforcement Learning Doesn&#x27;t Have to be Slow</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Long Nguyen, Micha Fauth, Bernhard Jaeger, Daniel Dauner, Maximilian Igl, Andreas Geiger, Kashyap Chitta</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20563" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20563</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f62c50da026de5eec286e01930af394650fb8b9c309ff48cd8f733ee9ca220b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Improving ML Training Data with Gold-Standard Quality Metrics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Leslie Barrett, Michael W. Sherman</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20577" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20577</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fcda9dded34420c31f0b16ebfbeec41a79ad04607b8b4862e82f7a5504ae0ad_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fcda9dded34420c31f0b16ebfbeec41a79ad04607b8b4862e82f7a5504ae0ad_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Improving ML Training Data with Gold-Standard Quality Metrics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Performative Policy Gradient: Optimality in Performative Reinforcement Learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Debabrota Basu, Udvas Das, Brahim Driss, Uddalak Mukherjee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20576" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20576</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef3954869c8b30fe77c2caa1356c077d9f6b214d512935393a84011f79c0d20f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Performative Policy Gradient: Optimality in Performative Reinforcement Learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Rui Pan, Zhuofu Chen, Ravi Netravali</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20573" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20573</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab6d51f1421d2f929752b850a0d24b6a7af807b50f1d54c1101b257d175a44f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Relu and softplus neural nets as zero-sum turn-based games</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Stephane Gaubert, Yiannis Vlassopoulos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20582" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20582</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab02d27a8e6adea8ae6003cffa24e9fc6b3b0ee9d8f7ab828d024af5b17df0d7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ab02d27a8e6adea8ae6003cffa24e9fc6b3b0ee9d8f7ab828d024af5b17df0d7_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Relu and softplus neural nets as zero-sum turn-based games</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yedi Zhang, Andrew Saxe, Peter E. Latham</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20607" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20607</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e73c03581900a982dea4784fdd454e704c3d3b120fb84735e5f76640eb67bc86_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e73c03581900a982dea4784fdd454e704c3d3b120fb84735e5f76640eb67bc86_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] FedPOD: the deployable units of training for federated learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Daewoon Kim, Si Young Yie, Jae Sung Lee</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20610" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20610</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e1f095bc0447c82283e16e3fb09acd3ae3773107b9096b3a06a1659a978e0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e8e1f095bc0447c82283e16e3fb09acd3ae3773107b9096b3a06a1659a978e0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> FedPOD: the deployable units of training for federated learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherre, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20605</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e252cb57b3bace513337e4bc66ce47050af3dedc086216816f29d838d083c5f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] LongVideoAgent: Multi-Agent Reasoning with Long Videos</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20618" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20618</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e38fba460d45fac945020bc323269f04211978c3e2e544d86072d5b062f40958_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> LongVideoAgent: Multi-Agent Reasoning with Long Videos</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Siyuan Fu, Xuchen Guo, Mingjun Liu, Hongxiang Li, Boyin Tan, Gongxi Zhu, Xianwei Zhuang, Jinghan Ru, Yuxin Xie, Yuguo Yin</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19703" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19703</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac2c582d6058b0a98adaddd2fc52e7fcb4b2f111f05471b7984fd691dc97aed_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac2c582d6058b0a98adaddd2fc52e7fcb4b2f111f05471b7984fd691dc97aed_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ASK: Adaptive Self-improving Knowledge Framework for Audio Text Retrieval</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] NMIRacle: Multi-modal Generative Molecular Elucidation from IR and NMR Spectra</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Federico Ottomano, Yingzhen Li, Alex M. Ganose</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19733" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19733</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e1b9a0fd1ed2cc7769e92111592f07cc1a8189724bd03924f8083fce8cf7a5b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e1b9a0fd1ed2cc7769e92111592f07cc1a8189724bd03924f8083fce8cf7a5b_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> NMIRacle: Multi-modal Generative Molecular Elucidation from IR and NMR Spectra</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Robust Causal Directionality Inference in Quantum Inference under MNAR Observation and High-Dimensional Noise</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Joonsung Kang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19746" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19746</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e5763bddf883e47ffbd39188c2d91d52b8f64bdca5101b8f91c97d4995c41b17_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e5763bddf883e47ffbd39188c2d91d52b8f64bdca5101b8f91c97d4995c41b17_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Robust Causal Directionality Inference in Quantum Inference under MNAR Observation and High-Dimensional Noise</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Fundamentals of quantum Boltzmann machine learning with visible and hidden units</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mark M. Wilde</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19819" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19819</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/109d3ad52a1d76b25a8f6b53d84a7219f99f5f6c4a1f4d3cfefd214d0a937f8f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/109d3ad52a1d76b25a8f6b53d84a7219f99f5f6c4a1f4d3cfefd214d0a937f8f_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Fundamentals of quantum Boltzmann machine learning with visible and hidden units</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Chemically-Informed Machine Learning Approach for Prediction of Reactivity Ratios in Radical Copolymerization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Habibollah Safari, Mona Bavarian</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19715" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19715</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db0de246828ee3f9ea683f9e4205d984e45250d6966e0c692c62d8ded1fbecb0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/db0de246828ee3f9ea683f9e4205d984e45250d6966e0c692c62d8ded1fbecb0_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Chemically-Informed Machine Learning Approach for Prediction of Reactivity Ratios in Radical Copolymerization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Nikolaos Iliopoulos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19986" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19986</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13f49f51d4e93dfaa76b5d85049c4b769868d3a8661c7cc58b3f721255548f39_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13f49f51d4e93dfaa76b5d85049c4b769868d3a8661c7cc58b3f721255548f39_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Covariance-Aware Simplex Projection for Cardinality-Constrained Portfolio Optimization</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Efficient Learning of Lattice Gauge Theories with Fermions</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shreya Shukla, Yukari Yamauchi, Andrey Y. Lokhov, Scott Lawrence, Abhijith Jayakumar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19891" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19891</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/006eec86d07c59f9bdf92e4095e9b3bdfcd0d6d88a3ff992c9ae1bcaa42efa8d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/006eec86d07c59f9bdf92e4095e9b3bdfcd0d6d88a3ff992c9ae1bcaa42efa8d_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Efficient Learning of Lattice Gauge Theories with Fermions</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Quasiprobabilistic Density Ratio Estimation with a Reverse Engineered Classification Loss Function</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthew Drnevich, Stephen Jiggins, Kyle Cranmer</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19913" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19913</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae42de4f7e707842fef18d1ebed0d4af2b3ff8eda273d229ca4aeaac9e765c90_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae42de4f7e707842fef18d1ebed0d4af2b3ff8eda273d229ca4aeaac9e765c90_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Quasiprobabilistic Density Ratio Estimation with a Reverse Engineered Classification Loss Function</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Semiparametric KSD test: unifying score and distance-based approaches for goodness-of-fit testing</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Zhihan Huang, Ziang Niu</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20007" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20007</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ac47ca7745f3ae745307a996bf9615b4c854438f5673b23f72f2db0c17c0052_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ac47ca7745f3ae745307a996bf9615b4c854438f5673b23f72f2db0c17c0052_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Semiparametric KSD test: unifying score and distance-based approaches for goodness-of-fit testing</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Reliable LLM-Based Edge-Cloud-Expert Cascades for Telecom Knowledge Systems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Qiushuo Hou, Sangwoo Park, Matteo Zecchin, Yunlong Cai, Guanding Yu, Osvaldo Simeone, Tommaso Melodia</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20012" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20012</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9dd4c42fc11f6f1f9e179a396845d6d9c90f18f4b2a0968536d1bbe730aaa182_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9dd4c42fc11f6f1f9e179a396845d6d9c90f18f4b2a0968536d1bbe730aaa182_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Reliable LLM-Based Edge-Cloud-Expert Cascades for Telecom Knowledge Systems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] GIMLET: Generalizable and Interpretable Model Learning through Embedded Thermodynamics</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Suguru Shiratori, Elham Kiyani, Khemraj Shukla, George Em Karniadakis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.19936" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.19936</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/045354376dff81526b71609d7a09c5a83b94cf3ff400ab3fe060114398f02961_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/045354376dff81526b71609d7a09c5a83b94cf3ff400ab3fe060114398f02961_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> GIMLET: Generalizable and Interpretable Model Learning through Embedded Thermodynamics</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Optimal Anytime-Valid Tests for Composite Nulls</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Shubhanshu Shekhar</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20039" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20039</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6951c37e90b9cc41d18c9ac7d45b558a0fb6668f2f64b9527e2985cfe68c8bce_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6951c37e90b9cc41d18c9ac7d45b558a0fb6668f2f64b9527e2985cfe68c8bce_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Optimal Anytime-Valid Tests for Composite Nulls</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Anna R. Flowers, Christopher T. Franck, Robert B. Gramacy, Justin A. Krometis</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20021" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20021</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50cf659ea746173ff874243a1ed23ec74a9a603abf5c8d8333c36a4bf579ec63_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50cf659ea746173ff874243a1ed23ec74a9a603abf5c8d8333c36a4bf579ec63_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Gaussian Process Assisted Meta-learning for Image Classification and Object Detection Models</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Optimality-Informed Neural Networks for Solving Parametric Optimization Problems</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Matthias K. Hoffmann, Amine Othmane, Kathrin Flaßkamp</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20270" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20270</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e060736a8b15ff91b7a61c98f5f036e0acad7f1f487053768b143db60163709_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e060736a8b15ff91b7a61c98f5f036e0acad7f1f487053768b143db60163709_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Optimality-Informed Neural Networks for Solving Parametric Optimization Problems</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Mebin Jose, Jisha Francis, Sudheesh Kumar Kattumannil</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20305" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20305</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f5766a6c4e9984e1a7c6234a1bf0776e7a9fad9ef648cc4ca17ad3ba035698_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f5766a6c4e9984e1a7c6234a1bf0776e7a9fad9ef648cc4ca17ad3ba035698_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> KAN-AFT: An Interpretable Nonlinear Survival Model Integrating Kolmogorov-Arnold Networks with Accelerated Failure Time Analysis</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Samya Praharaj, Koulik Khamaru</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20368" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20368</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/912d43c0875266e42e18f18ddc2bcf11aaf3e8607a61856f82ebf3a2932bf5e1_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/912d43c0875266e42e18f18ddc2bcf11aaf3e8607a61856f82ebf3a2932bf5e1_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] The Aligned Economic Index &amp; The State Switching Model</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Ilias Aarab</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20460" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20460</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac7ffd2530ee7539902991cd05061cc86de381735b4620a6937d0821e9cb5403_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac7ffd2530ee7539902991cd05061cc86de381735b4620a6937d0821e9cb5403_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> The Aligned Economic Index &amp; The State Switching Model</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Masahiro Kato</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20523" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20523</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca45318d031a0b7e00633a6c1f048fa9feead63ea3447f2257acc9011d26b6c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca45318d031a0b7e00633a6c1f048fa9feead63ea3447f2257acc9011d26b6c_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> ScoreMatchingRiesz: Auto-DML with Infinitesimal Classification</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Over-the-Air Goal-Oriented Communications</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Kyriakos Stylianopoulos, Paolo Di Lorenzo, George C. Alexandropoulos</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20533" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20533</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cf38466c85fbc6d90f4a4b0d12601a4d1aa3d13a53fc9c4c997edc35e26a213_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9cf38466c85fbc6d90f4a4b0d12601a4d1aa3d13a53fc9c4c997edc35e26a213_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Over-the-Air Goal-Oriented Communications</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251224] Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Yingzhen Yang</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.20562" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.20562</a></li>
<li class=""><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/126073a8d27aee52f27e9654f39d510e34be1f6aaec1e9c80cd8b6d23342281e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/126073a8d27aee52f27e9654f39d510e34be1f6aaec1e9c80cd8b6d23342281e_w640_q70.webp</a></li>
<li class=""><strong>Simple LLM Summary:</strong> Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-25T03:58:05.000Z" itemprop="dateModified">Dec 25, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/cs_LG/20251215-20251221"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251215-20251221 (cs.LG)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/category/cslo"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.LO</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-22" class="table-of-contents__link toc-highlight">2025-12-22</a></li><li><a href="#2025-12-23" class="table-of-contents__link toc-highlight">2025-12-23</a></li><li><a href="#2025-12-24" class="table-of-contents__link toc-highlight">2025-12-24</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/cslg/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>