<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-daily/cs_SE/20251229-20260104" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">20251229-20260104 (cs.SE) | AI头条</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://jokebear666.github.io/ai_toutiao/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://jokebear666.github.io/ai_toutiao/daily/csse/20251229-20260104"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="20251229-20260104 (cs.SE) | AI头条"><meta data-rh="true" name="description" content="2025-12-29"><meta data-rh="true" property="og:description" content="2025-12-29"><link data-rh="true" rel="icon" href="/ai_toutiao/img/favicon_b.ico"><link data-rh="true" rel="canonical" href="https://jokebear666.github.io/ai_toutiao/daily/csse/20251229-20260104"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csse/20251229-20260104" hreflang="en"><link data-rh="true" rel="alternate" href="https://jokebear666.github.io/ai_toutiao/daily/csse/20251229-20260104" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Daily","item":"https://jokebear666.github.io/ai_toutiao/category/daily"},{"@type":"ListItem","position":2,"name":"cs.SE","item":"https://jokebear666.github.io/ai_toutiao/daily/csse"},{"@type":"ListItem","position":3,"name":"20251229-20260104 (cs.SE)","item":"https://jokebear666.github.io/ai_toutiao/daily/csse/20251229-20260104"}]}</script><link rel="stylesheet" href="/ai_toutiao/assets/css/styles.9ae66a68.css">
<script src="/ai_toutiao/assets/js/runtime~main.bd476283.js" defer="defer"></script>
<script src="/ai_toutiao/assets/js/main.b2da8712.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/ai_toutiao/img/favicon_b.ico"><link rel="preload" as="image" href="/ai_toutiao/img/ads_2.png"><link rel="preload" as="image" href="/ai_toutiao/img/ads_3.png"><div class="layout-wrapper hide-doc-sidebar"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai_toutiao/"><div class="navbar__logo"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai_toutiao/img/favicon_b.ico" alt="AI头条" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI头条</b></a><a class="navbar__item navbar__link" href="/ai_toutiao/arxiv-daily">Arxiv每日论文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/ai_toutiao/sponsor/advertise">赞助商</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/arxiv-daily"><span title="Arxiv每日论文" class="linkLabel_WmDU">Arxiv每日论文</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai_toutiao/intro"><span title="首页" class="linkLabel_WmDU">首页</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai_toutiao/category/daily"><span title="Daily" class="categoryLinkLabel_W154">Daily</span></a><button aria-label="Collapse sidebar category &#x27;Daily&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csai"><span title="cs.AI" class="categoryLinkLabel_W154">cs.AI</span></a><button aria-label="Expand sidebar category &#x27;cs.AI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csar"><span title="cs.AR" class="categoryLinkLabel_W154">cs.AR</span></a><button aria-label="Expand sidebar category &#x27;cs.AR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscc"><span title="cs.CC" class="categoryLinkLabel_W154">cs.CC</span></a><button aria-label="Expand sidebar category &#x27;cs.CC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csce"><span title="cs.CE" class="categoryLinkLabel_W154">cs.CE</span></a><button aria-label="Expand sidebar category &#x27;cs.CE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscg"><span title="cs.CG" class="categoryLinkLabel_W154">cs.CG</span></a><button aria-label="Expand sidebar category &#x27;cs.CG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscl"><span title="cs.CL" class="categoryLinkLabel_W154">cs.CL</span></a><button aria-label="Expand sidebar category &#x27;cs.CL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscr"><span title="cs.CR" class="categoryLinkLabel_W154">cs.CR</span></a><button aria-label="Expand sidebar category &#x27;cs.CR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cscv"><span title="cs.CV" class="categoryLinkLabel_W154">cs.CV</span></a><button aria-label="Expand sidebar category &#x27;cs.CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cscy"><span title="cs.CY" class="categoryLinkLabel_W154">cs.CY</span></a><button aria-label="Expand sidebar category &#x27;cs.CY&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdb"><span title="cs.DB" class="categoryLinkLabel_W154">cs.DB</span></a><button aria-label="Expand sidebar category &#x27;cs.DB&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdc"><span title="cs.DC" class="categoryLinkLabel_W154">cs.DC</span></a><button aria-label="Expand sidebar category &#x27;cs.DC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdl"><span title="cs.DL" class="categoryLinkLabel_W154">cs.DL</span></a><button aria-label="Expand sidebar category &#x27;cs.DL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csdm"><span title="cs.DM" class="categoryLinkLabel_W154">cs.DM</span></a><button aria-label="Expand sidebar category &#x27;cs.DM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csds"><span title="cs.DS" class="categoryLinkLabel_W154">cs.DS</span></a><button aria-label="Expand sidebar category &#x27;cs.DS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cset"><span title="cs.ET" class="categoryLinkLabel_W154">cs.ET</span></a><button aria-label="Expand sidebar category &#x27;cs.ET&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csfl"><span title="cs.FL" class="categoryLinkLabel_W154">cs.FL</span></a><button aria-label="Expand sidebar category &#x27;cs.FL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgr"><span title="cs.GR" class="categoryLinkLabel_W154">cs.GR</span></a><button aria-label="Expand sidebar category &#x27;cs.GR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csgt"><span title="cs.GT" class="categoryLinkLabel_W154">cs.GT</span></a><button aria-label="Expand sidebar category &#x27;cs.GT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cshc"><span title="cs.HC" class="categoryLinkLabel_W154">cs.HC</span></a><button aria-label="Expand sidebar category &#x27;cs.HC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csir"><span title="cs.IR" class="categoryLinkLabel_W154">cs.IR</span></a><button aria-label="Expand sidebar category &#x27;cs.IR&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csit"><span title="cs.IT" class="categoryLinkLabel_W154">cs.IT</span></a><button aria-label="Expand sidebar category &#x27;cs.IT&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cslg"><span title="cs.LG" class="categoryLinkLabel_W154">cs.LG</span></a><button aria-label="Expand sidebar category &#x27;cs.LG&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cslo"><span title="cs.LO" class="categoryLinkLabel_W154">cs.LO</span></a><button aria-label="Expand sidebar category &#x27;cs.LO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csma"><span title="cs.MA" class="categoryLinkLabel_W154">cs.MA</span></a><button aria-label="Expand sidebar category &#x27;cs.MA&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csmm"><span title="cs.MM" class="categoryLinkLabel_W154">cs.MM</span></a><button aria-label="Expand sidebar category &#x27;cs.MM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csms"><span title="cs.MS" class="categoryLinkLabel_W154">cs.MS</span></a><button aria-label="Expand sidebar category &#x27;cs.MS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csne"><span title="cs.NE" class="categoryLinkLabel_W154">cs.NE</span></a><button aria-label="Expand sidebar category &#x27;cs.NE&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/csni"><span title="cs.NI" class="categoryLinkLabel_W154">cs.NI</span></a><button aria-label="Expand sidebar category &#x27;cs.NI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csoh"><span title="cs.OH" class="categoryLinkLabel_W154">cs.OH</span></a><button aria-label="Expand sidebar category &#x27;cs.OH&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csos"><span title="cs.OS" class="categoryLinkLabel_W154">cs.OS</span></a><button aria-label="Expand sidebar category &#x27;cs.OS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspf"><span title="cs.PF" class="categoryLinkLabel_W154">cs.PF</span></a><button aria-label="Expand sidebar category &#x27;cs.PF&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cspl"><span title="cs.PL" class="categoryLinkLabel_W154">cs.PL</span></a><button aria-label="Expand sidebar category &#x27;cs.PL&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/csro"><span title="cs.RO" class="categoryLinkLabel_W154">cs.RO</span></a><button aria-label="Expand sidebar category &#x27;cs.RO&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/category/cssc"><span title="cs.SC" class="categoryLinkLabel_W154">cs.SC</span></a><button aria-label="Expand sidebar category &#x27;cs.SC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssd"><span title="cs.SD" class="categoryLinkLabel_W154">cs.SD</span></a><button aria-label="Expand sidebar category &#x27;cs.SD&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai_toutiao/daily/csse"><span title="cs.SE" class="categoryLinkLabel_W154">cs.SE</span></a><button aria-label="Collapse sidebar category &#x27;cs.SE&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/cs_SE/20251215-20251221"><span title="20251215-20251221 (cs.SE)" class="linkLabel_WmDU">20251215-20251221 (cs.SE)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/csse/20251222-20251228"><span title="20251222-20251228 (cs.SE)" class="linkLabel_WmDU">20251222-20251228 (cs.SE)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai_toutiao/daily/csse/20251229-20260104"><span title="20251229-20260104 (cs.SE)" class="linkLabel_WmDU">20251229-20260104 (cs.SE)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai_toutiao/daily/cssi"><span title="cs.SI" class="categoryLinkLabel_W154">cs.SI</span></a><button aria-label="Expand sidebar category &#x27;cs.SI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251027-20251102"><span title="20251027-20251102" class="linkLabel_WmDU">20251027-20251102</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251103-20251109"><span title="20251103-20251109" class="linkLabel_WmDU">20251103-20251109</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251110-20251116"><span title="20251110-20251116" class="linkLabel_WmDU">20251110-20251116</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251117-20251123"><span title="20251117-20251123" class="linkLabel_WmDU">20251117-20251123</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251124-20251130"><span title="20251124-20251130" class="linkLabel_WmDU">20251124-20251130</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251201-20251207"><span title="20251201-20251207" class="linkLabel_WmDU">20251201-20251207</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251208-20251214"><span title="20251208-20251214" class="linkLabel_WmDU">20251208-20251214</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251215-20251221"><span title="20251215-20251221" class="linkLabel_WmDU">20251215-20251221</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251222-20251228"><span title="20251222-20251228" class="linkLabel_WmDU">20251222-20251228</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_toutiao/daily/20251229-20260104"><span title="20251229-20260104" class="linkLabel_WmDU">20251229-20260104</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai_toutiao/category/paper"><span title="Paper" class="categoryLinkLabel_W154">Paper</span></a><button aria-label="Expand sidebar category &#x27;Paper&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ai_toutiao/sponsor/advertise"><span title="赞助商" class="categoryLinkLabel_W154">赞助商</span></a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="content-with-ads daily-layout"><div class="content-main"><div class="content-inner"><div class="daily-nav"><a class="daily-nav-item" href="/ai_toutiao/daily/csai">AI</a><a class="daily-nav-item" href="/ai_toutiao/daily/csce">CE</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscl">CL</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscv">CV</a><a class="daily-nav-item" href="/ai_toutiao/daily/cslg">LG</a><a class="daily-nav-item" href="/ai_toutiao/daily/csdc">DC</a><a class="daily-nav-item" href="/ai_toutiao/daily/csmm">MM</a><a class="daily-nav-item" href="/ai_toutiao/daily/csne">NE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csro">RO</a><a class="daily-nav-item" href="/ai_toutiao/daily/csse">SE</a><a class="daily-nav-item" href="/ai_toutiao/daily/csni">NI</a><a class="daily-nav-item" href="/ai_toutiao/daily/cscy">CY</a></div><div class="daily-grid"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai_toutiao/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/category/daily"><span>Daily</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai_toutiao/daily/csse"><span>cs.SE</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">20251229-20260104 (cs.SE)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>20251229-20260104 (cs.SE)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-29">2025-12-29<a href="#2025-12-29" class="hash-link" aria-label="Direct link to 2025-12-29" title="Direct link to 2025-12-29" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251229] Understanding the Role of Large Language Models in Software Engineering: Evidence from an Industry Survey</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software development tools], [Large Language Models, Survey, Industry, Empirical Study, Software Engineering Practices]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vítor Mateus de Brito, Kleinner Farias</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Vale do Rio dos Sinos</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21347" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21347</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides empirical evidence on the adoption and impact of LLMs in professional software engineering practice through an industry survey. 2. Identifies key perceived benefits (e.g., faster problem resolution, better documentation) and concerns (e.g., cognitive dependence, security risks) associated with LLM use. 3. Bridges the gap between academic discourse and real-world development, offering actionable insights for responsible LLM integration.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fdebd67326ef0fe8cc1a2f2e7ff34382bc7ee9e314bfea976a0e99b4b0eda04_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fdebd67326ef0fe8cc1a2f2e7ff34382bc7ee9e314bfea976a0e99b4b0eda04_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper conducts an empirical survey of 46 industry professionals to understand the adoption and impact of Large Language Models (LLMs) in software engineering. The study finds that while LLMs are perceived to accelerate technical tasks and improve documentation, significant concerns about over-reliance and security risks persist. The results highlight the need for critical and supervised use of LLM-based tools in software development.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Santhosh Kumar Ravindran</p>
</li>
<li class="">
<p><strong>institution:</strong> Microsoft Corporation</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21351" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21351</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as &quot;genomes&quot; that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Multi-Agent LLM Committees for Autonomous Software Beta Testing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [automated software testing], [multi-agent system, large language model, vision-language model, consensus voting, beta testing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady</p>
</li>
<li class="">
<p><strong>institution:</strong> New York University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21352" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21352</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software fairness], [correlation tuning, phi-coefficient, multi-objective optimization, pre-processing, bias mitigation]</p>
</li>
<li class="">
<p><strong>authors:</strong> Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21348" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21348</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Reflection-Driven Control for Trustworthy Code Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [reflection-driven control, secure code generation, trustworthy agents, reflective memory, safety control]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21354" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21354</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent&#x27;s reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent&#x27;s reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] AInsteinBench: Benchmarking Coding Agents on Scientific Repositories</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software engineering], [benchmark, scientific computing, code generation, pull requests, test-driven verification]</p>
</li>
<li class="">
<p><strong>authors:</strong> Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng</p>
</li>
<li class="">
<p><strong>institution:</strong> ByteDance Seed, Princeton University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21373" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21373</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/ByteDance-Seed/AInsteinBench" target="_blank" rel="noopener noreferrer" class="">https://github.com/ByteDance-Seed/AInsteinBench</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents&#x27; ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI&#x27;s role in computational scientific research.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] What Makes a GitHub Issue Ready for Copilot?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [ai-assisted software engineering], [GitHub Copilot, AI-agent, interpretable machine learning, pull request merge prediction, issue quality criteria]</p>
</li>
<li class="">
<p><strong>authors:</strong> Mohammed Sayagh</p>
</li>
<li class="">
<p><strong>institution:</strong> École de Technologie Supérieure, Université du Québec</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21426" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21426</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a set of 32 detailed criteria to measure the quality of GitHub issues for AI-agents like Copilot. 2. Built an interpretable machine learning model to predict the likelihood of a GitHub issue resulting in a merged pull request. 3. Identified key characteristics of successful issues (e.g., shorter, well-scoped) and those associated with failure (e.g., external references), providing actionable guidance for issue writing.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/998bd51b7cec267b5219b085eac5068f7a996cf57d816c17d8e06474fbae27f0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/998bd51b7cec267b5219b085eac5068f7a996cf57d816c17d8e06474fbae27f0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates what makes a GitHub issue suitable for AI-agents like Copilot to successfully implement. The authors propose 32 quality criteria and build an interpretable machine learning model to predict if an issue will lead to a merged pull request. They conclude that successful issues are shorter, well-scoped, and provide clear implementation guidance, while issues with external references are less likely to succeed.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software testing], [runtime error detection, coverage-guided testing, multi-agent reasoning, large language models, static analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hridya Dhulipala, Xiaokai Rong, Tien N. Nguyen</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Texas at Dallas</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21431" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21431</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes Cerberus, a novel predictive, execution-free coverage-guided testing framework that uses LLMs for input generation, coverage prediction, and error detection without code execution. 2. Introduces a two-phase feedback loop that first maximizes code coverage and detects errors, then focuses solely on error detection after coverage is maximized, improving performance over single-phase prompting. 3. Empirically demonstrates that Cerberus outperforms conventional and learning-based testing frameworks for both complete and incomplete code snippets by generating high-coverage test cases more efficiently and discovering more runtime errors.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper proposes Cerberus, a framework that uses Large Language Models (LLMs) to statically detect runtime errors in code snippets without execution. It employs a multi-agent reasoning approach with a two-phase, coverage-guided feedback loop to generate test inputs and predict errors. The evaluation shows Cerberus is more efficient and effective at finding runtime errors than existing testing methods.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [fuzz testing], [initial corpus generation, large language models, multi-agent framework, predictive code coverage, mutation-based fuzzing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Hridya Dhulipala, Xiaokai Rong, Aashish Yadavally, Tien N. Nguyen</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Texas at Dallas</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21440" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21440</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FuzzWise, a novel method that integrates initial corpus generation and minimization into a single, streamlined process using an LLM-based multi-agent framework., 2. Introduces a predictive code coverage module (an LLM agent) that assesses new test cases without requiring actual program execution, saving computational resources., 3. Demonstrates empirically that FuzzWise generates a smaller, higher-quality initial corpus that achieves higher code coverage and triggers more runtime errors more efficiently than baseline methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of generating a high-quality initial seed corpus for mutation-based fuzzing. It proposes FuzzWise, a method that uses a multi-agent LLM framework to generate and intelligently select test cases based on predicted coverage without execution. The evaluation shows FuzzWise produces a smaller, more effective corpus that achieves higher coverage and finds more bugs efficiently.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Code Clone Refactoring in C# with Lambda Expressions</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code refactoring], [lambda expressions, extract method, behavior parameterization, code clone, C#]</p>
</li>
<li class="">
<p><strong>authors:</strong> Takuto Kawamoto, Yoshiki Higo</p>
</li>
<li class="">
<p><strong>institution:</strong> Osaka University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21511" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21511</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a C#-specific technique for code clone refactoring using lambda expressions for behavior parameterization, addressing a gap in language-specific research beyond Java. 2. Developed an analysis method to determine the refactorability of clone pairs detected by the NiCad clone detector. 3. Conducted an empirical evaluation on 2,217 clone pairs from 22 projects, measuring the success rate of the proposed consolidation approach.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c89087084c80383647290bcc69c8c950eca517f6ba4f10a7237d77a54477bdd_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c89087084c80383647290bcc69c8c950eca517f6ba4f10a7237d77a54477bdd_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the problem of consolidating code clones in C# programs using &quot;Extract Method&quot; refactoring. It proposes a novel technique that uses lambda expressions to parameterize behavioral differences between clones, which is tailored to C#&#x27;s language specifications. The evaluation on real-world projects showed that 35.0% of clone pairs were deemed refactorable by the approach, with 28.9% of those successfully refactored.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [mobile systems], [dynamic tracing, method interception, ART virtual machine, non-invasive proxying, runtime observability]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qi Hu, Jiangchao Liu, Xin Yu, Lin Zhang, Edward Jiang</p>
</li>
<li class="">
<p><strong>institution:</strong> ByteDance</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21555" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21555</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel non-invasive proxying paradigm for dynamic tracing that avoids modifying the ART VM&#x27;s underlying data structures. 2. Achieves high-performance method interception by leveraging and optimizing the stable, built-in instrumentation mechanism of the Android ART virtual machine. 3. Demonstrates production-grade stability, minimal overhead, and broad compatibility through large-scale A/B experiments on a major app, successfully diagnosing severe online issues.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35b382ca224e5947c252f1f122f264a5993cf96e0069d9fecd115eb850c5ea49_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35b382ca224e5947c252f1f122f264a5993cf96e0069d9fecd115eb850c5ea49_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes XTrace, a non-invasive dynamic tracing framework for Android that intercepts arbitrary methods at runtime without app releases by leveraging the ART VM&#x27;s instrumentation. It shows minimal performance impact and high stability in large-scale production use, significantly improving the efficiency of diagnosing online crashes and performance bottlenecks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [type inference], [Entity Dependency Graph, co-evolution, type-checker-in-the-loop, LLM, repository-level]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shuo Sun, Shixin Zhang, Jiwei Yan, Jun Yan, Jian Zhang</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Software, Chinese Academy of Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21591" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21591</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An Entity Dependency Graph (EDG) model designed to capture repository-level type dependencies. 2. An iterative type inference approach where types and dependencies co-evolve in each iteration. 3. A type-checker-in-the-loop strategy that validates and corrects inferences on-the-fly to reduce error propagation.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d664d948e35d5ccaf8cf1c7880d512bf91868eeaf908b4683c1db08768e3940_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d664d948e35d5ccaf8cf1c7880d512bf91868eeaf908b4683c1db08768e3940_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes PyTIR, a novel approach for repository-level type inference in Python. It uses an Entity Dependency Graph (EDG) and an iterative co-evolution process between types and dependencies, enhanced by a type-checker-in-the-loop, to achieve accurate type annotations. The method significantly outperforms prior works, demonstrating a major improvement in automated type annotation for real-world Python code.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [software security], [backdoor attack, retrieval-augmented code generation, vulnerable code, supply-chain vulnerability, stealthy attack]</p>
</li>
<li class="">
<p><strong>authors:</strong> Tian Li, Bo Lin, Shangwen Wang, Yusong Tan</p>
</li>
<li class="">
<p><strong>institution:</strong> National University of Defense Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21681" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21681</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]</p>
</li>
<li class="">
<p><strong>authors:</strong> Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis</p>
</li>
<li class="">
<p><strong>institution:</strong> Purdue University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21757" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21757</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software supply chain security], [Software Bill of Materials, SBOM, SPDX, CycloneDX, tool ecosystem]</p>
</li>
<li class="">
<p><strong>authors:</strong> Abdul Ali Bangash, Tongxu Ge, Zhimin Zhao, Arshdeep Singh, Zitao Wang, Bram Adams</p>
</li>
<li class="">
<p><strong>institution:</strong> Lahore University of Management Sciences, Queen&#x27;s University, Indian Institute of Technology Ropar, University of Waterloo</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21781" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21781</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a quantitative comparison of use cases for 170 publicly advertised SBOM tools to identify enhancement areas for the SPDX and CycloneDX formats. 2. Compared health metrics of both ecosystems (171 CycloneDX vs. 470 SPDX tools) and analyzed 36,990 issue reports from open-source tools to evaluate robustness and identify challenges. 3. Investigated and compared the health metrics of the top 250 open-source projects using each tool ecosystem.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91bc1035c2c5b265034f618902937bd2da58ada7ea4b50d403537bd0f48a030c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91bc1035c2c5b265034f618902937bd2da58ada7ea4b50d403537bd0f48a030c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper conducts a comparative analysis of the two dominant Software Bill of Materials (SBOM) tool ecosystems, SPDX and CycloneDX. The authors quantitatively analyze tool use cases, ecosystem health metrics, issue reports, and project adoption. The findings reveal that CycloneDX tools show higher developer engagement in some areas, while SPDX benefits from a more mature ecosystem with broader tool availability and industry adoption.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [log parsing], [PMSS, label-free evaluation, silhouette analysis, Levenshtein distance, log parser]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qiaolin Qin, Jianchen Zhao, Heng Li, Weiyi Shang, Ettore Merlo</p>
</li>
<li class="">
<p><strong>institution:</strong> Polytechnique Montreal, University of Waterloo</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21811" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21811</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed PMSS, a novel label-free metric for evaluating log parser performance that does not require ground-truth data. 2. Demonstrated that PMSS is significantly correlated with existing label-based metrics (FGA and FTA) and can lead to comparable parser selection conclusions. 3. Provided guidelines and discussion on interpreting evaluation results with PMSS, addressing challenges and its application when labels are unavailable or inconsistent.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dbe635df301e13b1acf1f17c8fb241f287195f74aae223daca138f58797fb87_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dbe635df301e13b1acf1f17c8fb241f287195f74aae223daca138f58797fb87_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that existing metrics for evaluating log parsers rely on labeled data, which is often unavailable or inconsistent. To solve this, it proposes PMSS, a label-free metric based on medoid silhouette analysis and Levenshtein distance. The results show PMSS is strongly correlated with label-based metrics, offering a viable alternative for parser evaluation and selection without ground truth.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems in Software Development</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent system, code injection, threat model, security analysis agent, LLM]</p>
</li>
<li class="">
<p><strong>authors:</strong> Brian Bowers, Smita Khapre, Jugal Kalita</p>
</li>
<li class="">
<p><strong>institution:</strong> Loyola Marymount University, University of Colorado Colorado Springs</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.21818" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.21818</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed and evaluated LLM-based multi-agent architectures (coder, coder-tester, coder-reviewer-tester) for software implementation, assessing their accuracy, attack resilience, and efficiency. 2. Introduced a security analysis agent to mitigate code injection attacks, showing it improves resilience while recovering lost efficiency. 3. Demonstrated a vulnerability in the security analysis agent where embedding poisonous few-shot examples in injected code drastically increases attack success rate.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes the vulnerability of LLM-based multi-agent systems in software development to code injection attacks. It proposes and evaluates several agent architectures, finding that adding a security analysis agent improves resilience and efficiency. However, the study concludes that even this security agent can be compromised by advanced attacks using poisoned few-shot examples, significantly increasing the attack success rate.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures</strong></p>
<ul>
<li class=""><strong>tags:</strong> TBD</li>
<li class=""><strong>authors:</strong> Giuseppe De Palma, Saverio Giallorenzo</li>
<li class=""><strong>institution:</strong> TBD</li>
<li class=""><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22054" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22054</a></li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] HALF: Process Hollowing Analysis Framework for Binary Programs with the Assistance of Kernel Modules</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [binary analysis], [process hollowing, dynamic binary instrumentation, kernel module, fine-grained analysis, malware analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhangbo Long, Letian Sha, Jiaye Pan, Dongpeng Xu, Yifei Huang, Fu Xiao</p>
</li>
<li class="">
<p><strong>institution:</strong> Nanjing University of Posts and Telecommunications, The University of New Hampshire</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22043" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22043</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a new binary program analysis framework that uses a kernel module to extend the capabilities of traditional dynamic binary instrumentation. 2. Introduces a novel method to construct the analysis environment within a container process using process hollowing techniques, enabling decoupled analysis. 3. Demonstrates the framework&#x27;s practical value through validation with benchmarks, actual exploit programs, and malicious code on the Windows platform.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19e32f77dc6c92df186a9244b45aa21db814a27ce5e27275643fa1e71537cf7_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19e32f77dc6c92df186a9244b45aa21db814a27ce5e27275643fa1e71537cf7_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes HALF, a new binary program analysis framework designed to improve the usability and performance of fine-grained analysis. It combines kernel modules with process hollowing to decouple the analysis environment from the target program, reducing its impact. The framework is validated on Windows, showing effectiveness in analyzing exploits and malware.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Illinois at Urbana-Champaign, IBM Research</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22113" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22113</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2025-12-30">2025-12-30<a href="#2025-12-30" class="hash-link" aria-label="Direct link to 2025-12-30" title="Direct link to 2025-12-30" translate="no">​</a></h2>
<ul>
<li class="">
<p><strong>[arXiv251230] Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [automated program repair], [CodeT5, syntax validity, semantic correctness, neural code repair, transformer]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shaunak Samant</p>
</li>
<li class="">
<p><strong>institution:</strong> MIT World Peace University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22216" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22216</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. An empirical study demonstrating that a small transformer model (CodeT5-small) can achieve high syntactic correctness (94%) in code generation but fails to produce semantically correct repairs (0% exact match). 2. Identifies key failure factors: identifier abstraction removing semantic signals, cross-entropy training encouraging conservative copying, and insufficient model capacity for multi-step reasoning. 3. Argues that common evaluation metrics overestimate practical effectiveness and calls for future work to prioritize semantically informed datasets and execution-aware objectives.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5b419b9d06731756aa85f1747cb55b61006764a0f1afdd4eef702af659daca2_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5b419b9d06731756aa85f1747cb55b61006764a0f1afdd4eef702af659daca2_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This study investigates whether a small transformer model can effectively repair Java bugs. The authors fine-tune CodeT5-small on bug-fix pairs and find that while it generates syntactically valid code 94% of the time, it fails to produce correct repairs, often just copying the buggy input. The conclusion is that syntactic correctness is not a reliable proxy for semantic correctness, highlighting a significant gap in neural code repair evaluation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [autonomous vehicle security], [LiDAR attacks, safety controllers, adversarial perception, cut-in scenarios, time to collision]</p>
</li>
<li class="">
<p><strong>authors:</strong> Daniyal Ganiuly, Nurzhau Bolatbek, Assel Smaiyl</p>
</li>
<li class="">
<p><strong>institution:</strong> Astana IT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22244" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22244</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents a systematic failure analysis of longitudinal safety controllers under object-based LiDAR attacks in highway scenarios., 2. Demonstrates that short-duration LiDAR-induced object hallucinations can trigger unsafe braking, delayed hazard responses, and unstable control., 3. Shows that controller failures are more influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7f08729d3ab6d3cb95ef74d24b6a8c9504767e34a79b6a8ed3d819b7a0449654_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper analyzes how object-based LiDAR attacks impact the safety controllers of autonomous vehicles. Using a high-fidelity simulation framework, it evaluates attacks in highway scenarios and finds they can cause unsafe braking and delayed responses. The key conclusion is that temporal consistency of adversarial objects is a stronger driver of controller failure than spatial errors, revealing a gap between perception robustness and control-level safety.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software testing], [metamorphic testing, hallucination detection, text-to-sql, large language models]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bo Yang, Yinfen Xia, Weisong Sun, Yang Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Beijing Forestry University, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22250" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22250</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes SQLHD, a novel hallucination detection method for LLM-based Text-to-SQL that does not require ground-truth SQL answers. 2. Introduces a two-stage metamorphic testing framework with structure-aware and logic-aware metamorphic relations to detect schema-linking and logical-synthesis hallucinations separately. 3. Demonstrates superior performance over existing methods, including LLM self-evaluation, with F1-scores ranging from 69.36% to 82.76%.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43979ca10fcd9708d38dc28b6f736979a5f93d12908536b02a9fbbaabdec599f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43979ca10fcd9708d38dc28b6f736979a5f93d12908536b02a9fbbaabdec599f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of detecting hallucinations in LLM-generated SQL queries without needing ground-truth data. It proposes SQLHD, a two-stage metamorphic testing method that uses structure-aware and logic-aware perturbations to cross-check model outputs. The method shows effective hallucination detection, outperforming baseline approaches.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Agentic Software Issue Resolution with Large Language Models: A Survey</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [automated software maintenance], [large language models, agentic systems, software issue resolution, reinforcement learning, software engineering]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zhonghao Jiang, David Lo, Zhongxin Liu</p>
</li>
<li class="">
<p><strong>institution:</strong> Zhejiang University, Singapore Management University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22256" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22256</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/ZhonghaoJiang/Awesome-Issue-Solving" target="_blank" rel="noopener noreferrer" class="">https://github.com/ZhonghaoJiang/Awesome-Issue-Solving</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides a systematic survey of 126 recent studies on LLM-based agentic software issue resolution. 2. Establishes a taxonomy for the field across three key dimensions: benchmarks, techniques, and empirical studies. 3. Highlights the paradigm shift brought by agentic reinforcement learning in designing and training agentic systems for software engineering.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d5c1c5e173acc2646c4322651d8a6c89dabed4b251b6106c2a468adeeafadf5f_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper surveys the use of Large Language Model (LLM)-based agentic systems for automating complex software issue resolution, such as bug fixing. It reviews recent research, categorizes approaches, and discusses how agentic reinforcement learning is changing system design. The conclusion outlines current challenges and future research directions for improving automated software maintenance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [reproducibility, dependency management, code generation, large language models, empirical study]</p>
</li>
<li class="">
<p><strong>authors:</strong> Bhanu Prakash Vangala, Ali Adibifar, Tanu Malik, Ashish Gehani</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Missouri, SRI International</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22387" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22387</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a three-layer dependency framework (claimed, working, runtime) to quantify the execution reproducibility of LLM-generated code. 2. Conducts an empirical study evaluating three state-of-the-art LLM coding agents across 300 projects in three programming languages, revealing low out-of-the-box execution success rates. 3. Discovers a significant hidden dependency problem, with an average 13.5x expansion from declared to actual runtime dependencies.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3f3a69233ca5eacf2fea5882b11aeb102413519f3be78440b3532150966328b_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the reproducibility of code generated by LLM-based coding agents. It proposes a three-layer dependency framework and conducts an empirical study on 300 projects, finding that only 68.3% execute successfully out-of-the-box and that actual runtime dependencies are significantly larger than declared ones. The study concludes that AI-generated code currently suffers from major reproducibility issues due to dependency gaps and code generation errors.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [agent system], [multi-agent LLM framework, knowledge gap detection, student-AI dialogue analysis, QueryQuilt, educational technology]</p>
</li>
<li class="">
<p><strong>authors:</strong> Quanzhi Fu, Qiyu Wu, Dan Williams</p>
</li>
<li class="">
<p><strong>institution:</strong> Virginia Tech</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22404" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22404</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system&#x27;s potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [human aspects of software engineering], [vibe coding, large language models, grounded theory, prompt engineering, software development practices]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones</p>
</li>
<li class="">
<p><strong>institution:</strong> University of California, Irvine</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22418" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22418</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Conducted a grounded theory study of &quot;vibe coding&quot; practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as &quot;rolling the dice,&quot; and that divergent mental models influence prompting, evaluation, and trust.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates the emerging practice of &quot;vibe coding,&quot; where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as &quot;rolling the dice.&quot; The findings highlight how developers&#x27; mental models shape their interaction with AI and point to new research directions for the future of software engineering.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] GraphLocator: Graph-guided Causal Reasoning for Issue Localization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [issue localization], [causal issue graph, dynamic issue disentangling, symptom-to-cause mismatch, one-to-many mismatch]</p>
</li>
<li class="">
<p><strong>authors:</strong> Wei Liu, Chao Peng, Pengfei Gao, Aofan Liu, Wei Zhang, Haiyan Zhao, Zhi Jin</p>
</li>
<li class="">
<p><strong>institution:</strong> Peking University, Bytedance</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22469" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22469</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes GraphLocator, an LLM-based approach for issue localization that addresses the semantic gap between issue descriptions and code. 2. Introduces the Causal Issue Graph (CIG) to model sub-issues and their causal dependencies, mitigating symptom-to-cause and one-to-many mismatches. 3. Demonstrates significant performance improvements in localization accuracy and downstream task performance through a two-phase workflow of symptom locating and dynamic graph discovery.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7dff9ac90f028731aa3b3d082126f3d3de229d3c53b61e302fd7d16eba1e084_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7dff9ac90f028731aa3b3d082126f3d3de229d3c53b61e302fd7d16eba1e084_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper tackles the challenge of automatically localizing code that needs to be changed based on a natural language issue description. It proposes GraphLocator, a method that constructs a Causal Issue Graph to reason about underlying sub-issues and their dependencies, effectively bridging the semantic gap. Experiments show it significantly outperforms baselines in both recall and precision for issue localization.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [compiler fault localization, adversarial compilation configurations, spectrum-based fault localization (SBFL), weighted voting, GCC bugs]</p>
</li>
<li class="">
<p><strong>authors:</strong> Qingyang Li, Yibiao Yang, Maolin Sun, Jiangchang Wu, Qingkai Shi, Yuming Zhou</p>
</li>
<li class="">
<p><strong>institution:</strong> State Key Laboratory for Novel Software Technology, Nanjing University, China</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22538" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22538</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MultiConf, a novel approach that automatically isolates compiler faults by constructing multiple pairs of adversarial compilation configurations (failing and passing). 2. Introduces a lightweight process to generate failing configurations and derives passing ones by selectively disabling bug-related fine-grained options. 3. Employs an SBFL formula and a weighted voting scheme to aggregate rankings from multiple configuration pairs, achieving more accurate and robust fault localization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/437f9126029a1a7c1875bde92aa42b0d549a6a8a506d4dcc1135cf46b3380620_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/437f9126029a1a7c1875bde92aa42b0d549a6a8a506d4dcc1135cf46b3380620_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of localizing faults in complex compilers by proposing MultiConf, a method that uses multiple pairs of adversarial compilation configurations and a weighted voting scheme to rank suspicious source files. Evaluated on 60 real GCC bugs, MultiConf significantly outperforms existing techniques, localizing 27 bugs at the Top-1 file level.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [automated program repair], [automated vulnerability repair, fine-tuned language models, test-based evaluation, semantic-preserving transformations, generalization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Woorim Han, Yeongjun Kwak, Miseon Yu, Kyeongmin Kim, Younghan Lee, Hyungon Moon, Yunheung Paek</p>
</li>
<li class="">
<p><strong>institution:</strong> Seoul National University, UNIST (Ulsan National Institute of Science and Technology), Sungshin Women’s University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22633" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22633</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces semantic-preserving transformations to test sets to assess if models learn robust patterns or spurious features. 2. Re-splits datasets to be mutually exclusive to properly evaluate model generalization on unseen vulnerabilities. 3. Proposes L-AVRBench, a test-based benchmark, to overcome the limitations of token-level match-based evaluation metrics.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d770d836cf9a18ac948b50e2b265b8ff346227d4dd0f8e12930e2897a03429f4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d770d836cf9a18ac948b50e2b265b8ff346227d4dd0f8e12930e2897a03429f4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper critically examines the capabilities of fine-tuned language models for automated vulnerability repair (AVR). It finds that state-of-the-art models often overfit and are evaluated on non-exclusive data splits using inadequate metrics. To address this, the authors propose methods to test robustness and generalization, and introduce a new test-based benchmark (L-AVRBench) to better assess true repair capability.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [control-flow integrity], [control-flow integrity, compiler-based security, automated repair, legacy systems, runtime monitoring]</p>
</li>
<li class="">
<p><strong>authors:</strong> Sabine Houy, Bruno Kreyssig, Alexandre Bartel</p>
</li>
<li class="">
<p><strong>institution:</strong> Umeå University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22701" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22701</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents CFIghter, the first fully automated system for enabling strict, type-based CFI in real-world C/C++ projects by detecting, classifying, and repairing unintended policy violations. 2. Integrates whole-program analysis with guided runtime monitoring to iteratively apply minimal adjustments to CFI enforcement only where required. 3. Demonstrates high effectiveness by automatically repairing 95.8% of unintended CFI violations in a large codebase while retaining strict enforcement at over 89% of indirect control-flow sites, showing automated repair makes strict CFI practically deployable.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436657782d1936c221bd69d6fb671fff796d4c4a2db996690bbe0d6bea5a3b55_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/436657782d1936c221bd69d6fb671fff796d4c4a2db996690bbe0d6bea5a3b55_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the challenge of deploying compiler-based Control-Flow Integrity (CFI) in large legacy C/C++ systems due to semantic mismatches that cause runtime crashes. It proposes CFIghter, an automated system that uses whole-program analysis and runtime monitoring to detect and repair these unintended violations, requiring minimal manual changes. The evaluation shows CFIghter successfully resolves most violations in real-world projects, making strict CFI practically deployable for mature software.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [vulnerability exploitation], [LLM, social engineering, pretexting, Odoo ERP, RSA]</p>
</li>
<li class="">
<p><strong>authors:</strong> Moustapha Awwalou Diouf, Maimouna Tamah Diao, Iyiola Emmanuel Olatunji, Abdoul Kader Kaboré, Jordan Samhi, Gervais Mendy, Samuel Ouya, Jacques Klein, Tegawendé F. Bissyandé</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Luxembourg</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22753" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22753</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://anonymous.4open.science/r/From-Rookie-to-Attacker-D8B3" target="_blank" rel="noopener noreferrer" class="">https://anonymous.4open.science/r/From-Rookie-to-Attacker-D8B3</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes RSA (Role-assignment, Scenario-pretexting, and Action-solicitation), a novel pretexting strategy to manipulate LLMs into generating functional exploits. 2. Demonstrates a 100% success rate in generating working exploits for tested CVEs against the Odoo ERP platform using five mainstream LLMs within 3-4 prompting rounds. 3. Shows that LLMs can eliminate the manual effort previously required for LLM-assisted attacks, fundamentally challenging core security principles about technical expertise and threat modeling.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fa715a252b1e75790a16c013941796c349d193dcd31101439954451a3b63bf5_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9fa715a252b1e75790a16c013941796c349d193dcd31101439954451a3b63bf5_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper demonstrates how publicly available Large Language Models (LLMs) can be manipulated through a social engineering strategy called RSA to automatically generate functional software exploits, effectively enabling novices to become capable attackers. The method achieved a 100% success rate against a popular enterprise platform, showing that exploitation no longer requires deep technical expertise but only the ability to craft prompts. This finding invalidates traditional security assumptions and signals a paradigm shift requiring redesigned security practices.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] FasterPy: An LLM-based Code Execution Efficiency Optimization Framework</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [rag (retrieval-augmented generation)], [Code Optimization, Retrieval-Augmented Generation (RAG), Low-Rank Adaptation (LoRA), Large Language Models (LLMs), Python]</p>
</li>
<li class="">
<p><strong>authors:</strong> Yue Wu, Minghao Han, Ruiyin Li, Peng Liang, Amjed Tahir, Zengyang Li, Qiong Feng, Mojtaba Shahin</p>
</li>
<li class="">
<p><strong>institution:</strong> Wuhan University, Carnegie Mellon University, Massey University, Central China Normal University, Nanjing University of Science and Technology, RMIT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22827" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22827</a></p>
</li>
<li class="">
<p><strong>code:</strong> <a href="https://github.com/WuYue22/fasterpy" target="_blank" rel="noopener noreferrer" class="">https://github.com/WuYue22/fasterpy</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes FasterPy, a low-cost and efficient framework that adapts LLMs for Python code execution efficiency optimization. 2. Combines Retrieval-Augmented Generation (RAG) with a knowledge base of performance-improving code pairs and Low-Rank Adaptation (LoRA) to enhance optimization performance. 3. Demonstrates superior performance over existing models on the Performance Improving Code Edits (PIE) benchmark.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49aae1b7cd12cfd30401a619c9b06d4bccc853d1d14eed57af87eb6c80858f31_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces FasterPy, a framework that uses Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG) and Low-Rank Adaptation (LoRA) to automatically optimize Python code for better execution efficiency. It addresses the limitations of traditional rule-based and data-intensive ML methods by providing a more scalable and cost-effective solution. Experimental results show that FasterPy outperforms existing models on standard benchmarks.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Towards the analysis of team members well-being</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [software development team well-being], [well-being, software development, team members, positive feedback, prototype]</p>
</li>
<li class="">
<p><strong>authors:</strong> Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova</p>
</li>
<li class="">
<p><strong>institution:</strong> RMIT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.22845" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.22845</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Interpretable Gallbladder Ultrasound Diagnosis: A Lightweight Web-Mobile Software Platform with Real-Time XAI</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [medical image classification], [MobResTaNet, Explainable AI (XAI), lightweight model, ultrasound diagnosis, web-mobile platform]</p>
</li>
<li class="">
<p><strong>authors:</strong> Fuyad Hasan Bhoyan, Prashanta Sarker, Parsia Noor Ethila, Md. Emon Hossain, Md Kaviul Hossain, Md Humaion Kabir Mehedi</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Liberal Arts Bangladesh, BRAC University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23033" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23033</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposed a hybrid deep learning model (MobResTaNet) for classifying ten gallbladder conditions from ultrasound images with high accuracy (99.85%) and low parameter count (2.24M). 2. Developed an interpretable diagnostic system with real-time Explainable AI (XAI) visualizations to support transparent clinical decision-making. 3. Deployed the system as an efficient and accessible web-mobile software platform using technologies like HTML, CSS, JavaScript, Bootstrap, and Flutter for point-of-care use.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6a6693ffd9f4375cd5a781c2544fba169bc30bc3cbb7590b1562ea78ba6678_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c6a6693ffd9f4375cd5a781c2544fba169bc30bc3cbb7590b1562ea78ba6678_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of interpreting gallbladder ultrasound images by developing an AI-driven diagnostic software. The core method is a lightweight hybrid deep learning model called MobResTaNet, which classifies diseases and provides real-time, interpretable predictions via XAI. The main conclusion is that the system achieves high accuracy with a small model size and is successfully deployed as accessible web and mobile applications for clinical support.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] An Architecture-Led Hybrid Report on Body Language Detection Project</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [cv], [video understanding], [vision-language models, structured generation, bounding boxes, mixture-of-experts, video analysis]</p>
</li>
<li class="">
<p><strong>authors:</strong> Thomson Tong, Diba Darooneh</p>
</li>
<li class="">
<p><strong>institution:</strong> None</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23028" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23028</a></p>
</li>
<li class="">
<p><strong>code:</strong> BodyLanguageDetection repository [1]</p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides an architecture-led analysis of two modern VLMs (Qwen2.5-VL-7B-Instruct and Llama-4-Scout-17B-16E-Instruct) for a practical task. 2. Maps model architectural properties to a concrete video-to-artifact pipeline for person detection and attribute extraction. 3. Explicitly defines and analyzes critical system constraints and limitations arising from model behavior, such as semantic vs. syntactic correctness and frame-local identifiers.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a618c048bc336ad2ade96a7a97cf301fb10fee2c9c8e7bc16556348f1c0c4b9d_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This report analyzes two vision-language models (VLMs) and connects their architectures to a practical system for detecting people and their emotions in video frames. The system prompts VLMs to generate structured outputs like bounding boxes, validates the output structure, and can render annotated videos. The core conclusion is that understanding model architecture is crucial for designing robust interfaces and making defensible claims, as VLMs can produce syntactically correct but semantically incorrect outputs.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [other], [human-computer interaction], [flight computer, multi-platform software, aviation training, educational monographs, weight and balance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Jamie J. Alnasir</p>
</li>
<li class="">
<p><strong>institution:</strong> None (Inferred from author&#x27;s email domain: al-nasir.com, which appears to be a personal domain)</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23055" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23055</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool&#x27;s improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] An Automated Grey Literature Extraction Tool for Software Engineering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [grey literature extraction], [grey literature, semantic classifier, embedding, reproducibility, prompt-driven]</p>
</li>
<li class="">
<p><strong>authors:</strong> Houcine Abdelkader Cherief, Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Sti&#x27;evenart, Florent Avellaneda</p>
</li>
<li class="">
<p><strong>institution:</strong> École de technologie supérieure, Université du Québec à Montréal</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23066" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23066</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. The GLiSE tool, a prompt-driven system for automated grey literature extraction from heterogeneous web sources. 2. A curated dataset of software engineering grey-literature search results classified by semantic relevance. 3. An empirical study evaluating the usability of the proposed tool.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd8d541170e102d077ea8b0f0d18f0b4d898d754f2e5dea87a8696f74de7b5c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd8d541170e102d077ea8b0f0d18f0b4d898d754f2e5dea87a8696f74de7b5c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the difficulty of collecting and assessing grey literature in software engineering at scale due to heterogeneous sources and formats. It proposes GLiSE, a prompt-driven tool that generates platform-specific queries, gathers results from sources like GitHub and Stack Overflow, and uses embedding-based semantic classifiers to filter and rank results for relevance. The tool is designed for reproducibility and its usability is empirically evaluated.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Anka: A Domain-Specific Language for Reliable LLM Code Generation</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [llm inference], [Domain-Specific Language, Constrained Syntax, Code Generation, Data Transformation Pipeline, In-Context Learning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Saif Khalfan Saif Al Mazrouei</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Wisconsin-Madison</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23214" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23214</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] An Empirical Study of Generative AI Adoption in Software Engineering</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [AI4SE], [Generative AI, Software Engineering, Empirical Study, Survey, Adoption]</p>
</li>
<li class="">
<p><strong>authors:</strong> Görkem Giray, Onur Demirörs, Marcos Kalinowski, Daniel Mendez</p>
</li>
<li class="">
<p><strong>institution:</strong> Eindhoven University of Technology, Izmir Institute of Technology, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Blekinge Institute of Technology, fortiss</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23327" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23327</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Provides an empirical overview of the current status of Generative AI adoption in software engineering practice. 2. Identifies and categorizes the key benefits, challenges, and organizational institutionalization patterns associated with GenAI use. 3. Investigates and reports on the anticipated long-term impacts of GenAI on the roles and job market for software engineering professionals.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45dc246f8337bce98d95170e37ed6c405c343b51bb32f568d576b057edc61ed3_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45dc246f8337bce98d95170e37ed6c405c343b51bb32f568d576b057edc61ed3_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper conducts an international survey of 204 software engineering practitioners to empirically study the adoption of Generative AI tools. The results show widespread integration into daily tasks with reported benefits in productivity and quality, but also highlight persistent challenges like unreliable outputs and security concerns. The study concludes that a move from ad-hoc to systematic approaches is needed for sustainable and responsible GenAI integration in software engineering.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sec], [AI Security], [AI supply chain, security taxonomy, distilBERT classifier]</p>
</li>
<li class="">
<p><strong>authors:</strong> Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar</p>
</li>
<li class="">
<p><strong>institution:</strong> University of Adelaide</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23385" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23385</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [cluster infrastructure], [Kubernetes, Autoscaling, AIOps, Service Level Objectives, Cost Optimization]</p>
</li>
<li class="">
<p><strong>authors:</strong> Vinoth Punniyamoorthy, Bikesh Kumar, Sumit Saha, Lokesh Butra, Mayilsamy Palanigounder, Akash Kumar Agarwal, Kabilan Kannan</p>
</li>
<li class="">
<p><strong>institution:</strong> IEEE, East West Bank, NTT Data, Albertsons</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23415" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23415</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A gap-driven analysis of existing Kubernetes autoscaling approaches, highlighting their limitations. 2. A safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with demand forecasting. 3. Experimental evaluation demonstrating significant improvements in SLO violation duration, scaling response time, and infrastructure cost compared to baselines.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ce581ba4d1249deeba9f1bffa6739ebbe74df663542fef3893eee5e0a117ae2e_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses SLO violations and cost inefficiencies in Kubernetes autoscaling by proposing an AIOps-driven framework that uses multi-signal control and lightweight forecasting. The method integrates SLO and cost awareness to improve responsiveness and stability. Evaluation shows it reduces SLO violations by up to 31%, improves response time by 24%, and lowers cost by 18% compared to standard Kubernetes autoscalers.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Embedding Quality Assurance in project-based learning</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [Software Engineering Education], [Quality Assurance, Project-based Learning, Agile/Scrum, Software Engineering Education, Experience Report]</p>
</li>
<li class="">
<p><strong>authors:</strong> Maria Spichkova</p>
</li>
<li class="">
<p><strong>institution:</strong> RMIT University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23488" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23488</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Shares over a decade of lessons learned from teaching software quality within Agile/Scrum-based Software Engineering courses, including final-year projects and a project management course. 2. Identifies specific challenges students face in understanding and applying Quality Assurance (QA) within Agile/Scrum project-based learning environments. 3. Provides practical recommendations for effectively embedding QA topics into project-based learning curricula with an Agile/Scrum context.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77065f8ef568ef76fd85920a5579be34df22a20ec5cca17659010df66ea57edb_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/77065f8ef568ef76fd85920a5579be34df22a20ec5cca17659010df66ea57edb_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents an experience report on teaching software quality assurance in Agile/Scrum-focused Software Engineering courses over ten years. It identifies student struggles with QA in project-based learning and provides recommendations for better integrating QA topics into such curricula. The main conclusion is that a focused pedagogical approach is needed to ensure students value and apply QA practices effectively in Agile settings.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Adaptable TeaStore: A Choreographic Approach</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [choreographic programming], [adaptable microservices, choreographic programming, AIOCJ, runtime adaptation, communication correctness]</p>
</li>
<li class="">
<p><strong>authors:</strong> Giuseppe De Palma, Saverio Giallorenzo, Ivan Lanese, Gianluigi Zavattaro</p>
</li>
<li class="">
<p><strong>institution:</strong> Università di Bologna, INRIA</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23497" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23497</a></p>
</li>
<li class="">
<p><strong>contributions:</strong>  1. Presents an implementation of the Adaptable TeaStore reference model using the AIOCJ choreographic language. 2. Demonstrates that AIOCJ ensures by-construction correctness of communications (e.g., deadlock freedom) before, during, and after runtime adaptation. 3. Provides an analysis of the strengths and current limitations of the choreographic approach for adaptable cloud architectures, suggesting future refinements.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/185975480d365934f5e03c65e64353b019eae6a649d47d0cfc956b5c90524a0a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper models the Adaptable TeaStore, a reference model for adaptable microservice architectures, using the AIOCJ choreographic programming language. The approach ensures communication correctness by construction and supports dynamic runtime adaptation. The work showcases the paradigm&#x27;s strengths, identifies its limitations, and suggests future directions to better align it with real-world cloud systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Decoupling Adaptive Control in TeaStore</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [self-adaptive systems], [self-adaptation, microservices, control loop, operator pattern, software architecture]</p>
</li>
<li class="">
<p><strong>authors:</strong> Eddy Truyen</p>
</li>
<li class="">
<p><strong>institution:</strong> DistriNet, KU Leuven</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23495" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23495</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Analyzes how software architectural methods, the cloud-native Operator pattern, and legacy programming techniques can decouple adaptive control from the application logic in a microservice system. 2. Examines the trade-offs between fine-grained expressive adaptation and system-wide control, highlighting when reuse of adaptation strategies is effective. 3. Proposes that these approaches are complementary and can be combined into a multi-tiered architecture for self-adaptive microservices.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/78e96b6ab1b10ae0a32ddc4e7967c5bedce7be1b0fe5db13bec216c9e0b657ae_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper discusses the implementation of self-adaptation in the Adaptable TeaStore microservice benchmark. It examines different technical approaches (software architecture, Operator pattern, programming techniques) for decoupling the adaptive control logic from the application, analyzing their trade-offs. The main conclusion is that these approaches can be combined into a multi-tiered architecture for effective self-adaptive microservices.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Adaptable Teastore with Energy Consumption Awareness: A Case Study</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [self-adaptive systems], [energy consumption monitoring, self-adaptive systems, microservices, dynamic adaptation, cloud computing]</p>
</li>
<li class="">
<p><strong>authors:</strong> Henrique De Medeiros, Denisse Muñante, Sophie Chabridon, César Perdigão Batista, Denis Conan</p>
</li>
<li class="">
<p><strong>institution:</strong> Télécom SudParis, Institut Polytechnique de Paris, SAMOVAR, ENSIIE</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23498" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23498</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduction of EnCoMSAS, a tool for monitoring energy consumption in distributed, self-adaptive software systems. 2. An empirical evaluation demonstrating EnCoMSAS&#x27;s effectiveness and validating its measurements through correlation with CPU usage. 3. An analysis showing that the energy overhead of the monitoring tool itself is modest compared to the overall system.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ac42d90e6b95a7a182714a4c0e65c9755ffae7ca3f2ebec7e85bf313b892f10_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ac42d90e6b95a7a182714a4c0e65c9755ffae7ca3f2ebec7e85bf313b892f10_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the gap in energy-aware monitoring for self-adaptive systems by introducing EnCoMSAS, a tool for collecting runtime energy consumption data. The tool was evaluated using the Adaptable TeaStore case study, where it effectively gathered energy data and revealed that consumption is influenced by both algorithmic complexity and deployment environment. The study concluded that EnCoMSAS is a valid monitoring solution with a relatively low impact on the overall system&#x27;s energy footprint.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [autonomic computing], [MAPE-K loop, decentralized adaptation, event-driven, rule-based, microservices]</p>
</li>
<li class="">
<p><strong>authors:</strong> Brice Arléon Zemtsop Ndadji, Simon Bliudze, Clément Quinton</p>
</li>
<li class="">
<p><strong>institution:</strong> Univ. Lille, CNRS, Inria, Centrale Lille, CRIStAL</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23499" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23499</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. A framework (AdaptiFlow) providing abstraction layers for the Monitor and Execute phases of the MAPE-K loop to enable autonomous microservices. 2. A lightweight, event-driven and rule-based mechanism for specifying adaptation logic, decoupling it from metrics collection and action execution. 3. A workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination, validated through three adaptation scenarios (self-healing, self-protection, self-optimization).</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6cea3a497714ae1ca6ead099b1f31177f6fe2bf3d4bc5a184a21835b1744db4a_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper presents AdaptiFlow, a framework for building self-adaptive cloud microservices by decoupling metrics collection and action execution from adaptation logic using an event-driven, rule-based approach. It enables decentralized autonomy, allowing services to adapt locally without global coordination. The framework was validated on a benchmark, demonstrating practical implementation of self-healing, self-protection, and self-optimization scenarios with minimal code changes.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [nlp], [reasoning verification], [automated theorem proving, first-order logic, logical error detection, multi-step reasoning]</p>
</li>
<li class="">
<p><strong>authors:</strong> Xinyi Zheng, Ningke Li, Xiaokun Luan, Kailong Wang, Ling Shi, Meng Sun, Haoyu Wang</p>
</li>
<li class="">
<p><strong>institution:</strong> Huazhong University of Science and Technology, National University of Singapore, Peking University, Nanyang Technological University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23511" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23511</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes MATP, a novel evaluation framework that uses Multi-step Automated Theorem Proving to verify LLM reasoning by translating it into First-Order Logic. 2. Provides a fine-grained classification of reasoning correctness, identifying hidden logical errors that are masked by fluent language. 3. Demonstrates superior performance over prompting-based baselines by over 42 percentage points and reveals disparities in logical coherence between different types of LLMs.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b9201185009c06f76b12e788768ccb6a8e2846d1d6ae7c9dcca57af7e332cc0_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b9201185009c06f76b12e788768ccb6a8e2846d1d6ae7c9dcca57af7e332cc0_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper introduces MATP, a framework that translates LLM-generated natural language reasoning into First-Order Logic and uses automated theorem provers to verify its step-by-step logical validity. It effectively exposes subtle logical flaws that existing methods miss. Evaluations show MATP significantly outperforms baselines and can enhance the trustworthiness of LLM reasoning for critical applications.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [se], [dynamic deadlock prediction], [lock sets, critical sections, partial order relations, false positives, false negatives]</p>
</li>
<li class="">
<p><strong>authors:</strong> Martin Sulzmann</p>
</li>
<li class="">
<p><strong>institution:</strong> Karlsruhe University of Applied Sciences</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23552" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23552</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces a novel trace-based characterization of critical sections that can span multiple threads, correcting the standard per-thread model., 2. Proposes a sound approximation of the multi-thread critical section concept using partial order relations, enabling an improved lock set construction., 3. Integrates the improved lock set construction into an extended SPDOffline deadlock predictor, reducing both false positives and false negatives without impacting performance.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67d58fc411df804f4dd88c8339e7b2a1b64be70d9eca8844a0dbb324c049cdea_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper identifies that standard per-thread lock set analysis for deadlock prediction is flawed because it ignores locks acquired across thread boundaries, leading to inaccurate results. To solve this, the authors propose a new model of multi-thread critical sections and a sound approximation method using partial order relations to construct more precise lock sets. This approach, integrated into an extended predictor, reduces false positives and false negatives while maintaining performance.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Model-based Development for Autonomous Driving Software Considering Parallelization</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [Model-Based Development, Parallelization, Multi-core Processor, Autonomous Driving Software, Real-time Performance]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kenshin Obi, Takumi Onozawa, Hiroshi Fujimoto, Takuya Azumi</p>
</li>
<li class="">
<p><strong>institution:</strong> Saitama University, eSOL Co., Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23575" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23575</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a method to extend the existing Model-Based Parallelizer (MBP) to support complex processing blocks (like Simulink Toolbox blocks) for autonomous driving software. 2. Addresses the problem of decreasing the number of blocks available for parallelization when using high-level Toolbox blocks and code descriptions. 3. Demonstrates a reduction in execution time, showing the method&#x27;s suitability for achieving real-time performance in autonomous driving software development.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdaf1e9de27edf6ed5439e7e3abd6bd6f053fa858fced85d7eae12b8159fc8b4_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdaf1e9de27edf6ed5439e7e3abd6bd6f053fa858fced85d7eae12b8159fc8b4_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper proposes a model-based development method for parallelizing autonomous driving software to meet real-time performance requirements. It extends the existing Model-Based Parallelizer (MBP) to handle complex processing blocks, thereby reducing execution time. The evaluation confirms the method&#x27;s effectiveness for developing real-time autonomous driving systems.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [sys], [embedded systems], [model-based development, parallelization, ROS 2, Simulink, multi-core processors]</p>
</li>
<li class="">
<p><strong>authors:</strong> Kenshin Obi, Ryo Yoshinaka, Hiroshi Fujimoto, Takuya Azumi</p>
</li>
<li class="">
<p><strong>institution:</strong> Saitama University, eSOL Co., Ltd.</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23605" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23605</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a model-based development framework that categorizes ROS 2-compatible Simulink models into event-driven and timer-driven types for targeted parallelization. 2. Extends conventional MBD parallelization to support ROS 2-based models with multiple inputs, addressing integration challenges. 3. Demonstrates the framework&#x27;s effectiveness by showing reduced execution time for all tested patterns after parallelization.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1cb6e7053c79e3517530163d94d50906a3c12983608458bcd92e238407357675_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1cb6e7053c79e3517530163d94d50906a3c12983608458bcd92e238407357675_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> This paper addresses the challenge of integrating automatic model-based parallelization with the ROS 2 framework for autonomous driving systems. It proposes a framework that categorizes Simulink models as event-driven or timer-driven to generate parallelized code for ROS 2 nodes. Evaluation results confirm that the approach successfully reduces execution time.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] Federated Learning With L0 Constraint Via Probabilistic Gates For Sparsity</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [federated learning], [L0 regularization, probabilistic gates, communication efficiency, model sparsity, federated stochastic gradient descent]</p>
</li>
<li class="">
<p><strong>authors:</strong> Krishna Harsha Kovelakuntla Huthasana, Alireza Olama, Andreas Lundell</p>
</li>
<li class="">
<p><strong>institution:</strong> Åbo Akademi University</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23071" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23071</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Proposes a novel federated learning method that enforces an L0 constraint on model parameters using probabilistic gates and their continuous relaxation to achieve target sparsity. 2. Derives the L0 constrained stochastic minimization objective from an entropy maximization problem of the stochastic gates. 3. Demonstrates that the method can achieve high target sparsity (down to ρ=0.005) under data and client heterogeneity with minimal loss in statistical performance, outperforming magnitude pruning-based methods.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259d06fa8e807f154e153891f40b44308796040886ed51e218b65ee4e67a8c9c_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper addresses the problem of poor generalizability and communication inefficiency in Federated Learning due to overly dense models. It proposes a method to enforce L0 sparsity constraints via probabilistic gates, deriving the objective from entropy maximization and implementing it with federated stochastic gradient descent. The method is shown to be communication-efficient and achieves high target sparsity with better statistical performance than pruning-based baselines on synthetic and real datasets.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
<li class="">
<p><strong>[arXiv251230] LogosQ: A High-Performance and Type-Safe Quantum Computing Library in Rust</strong></p>
<ul>
<li class="">
<p><strong>tags:</strong> [mlsys], [compiler &amp; ir], [Rust, type safety, quantum simulation, variational algorithms, parameter-shift rule]</p>
</li>
<li class="">
<p><strong>authors:</strong> Shiwen An, Jiayi Wang, Konstantinos Slavakis</p>
</li>
<li class="">
<p><strong>institution:</strong> Institute of Science Tokyo, Georgia Institute of Technology</p>
</li>
<li class="">
<p><strong>link:</strong> <a href="https://arxiv.org/pdf/2512.23183" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2512.23183</a></p>
</li>
<li class="">
<p><strong>contributions:</strong> 1. Introduces LogosQ, a quantum computing library in Rust that uses compile-time type safety to eliminate runtime errors, especially in gradient computations. 2. Proposes novel optimization techniques like direct state-vector manipulation, adaptive parallel processing, and an FFT-optimized QFT for significant performance gains. 3. Demonstrates superior numerical stability and accuracy in variational quantum eigensolver (VQE) experiments compared to existing frameworks.</p>
</li>
<li class="">
<p><strong>thumbnail:</strong> <a href="https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3869523633aebacf98c54bdd34569f2d2e445db13de6918d6fa0d76072c1a8df_w640_q70.webp" target="_blank" rel="noopener noreferrer" class="">https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3869523633aebacf98c54bdd34569f2d2e445db13de6918d6fa0d76072c1a8df_w640_q70.webp</a></p>
</li>
<li class="">
<p><strong>Simple LLM Summary:</strong> The paper presents LogosQ, a high-performance quantum computing library written in Rust that ensures correctness through compile-time type safety. It introduces several optimization techniques that achieve speedups of up to 900x for certain operations and shows improved numerical stability in variational algorithm experiments. The work establishes a new standard for reliable and efficient quantum simulation by combining systems programming safety with advanced circuit optimizations.</p>
</li>
<li class="">
<p><strong>Mindmap:</strong></p>
<!-- -->
</li>
</ul>
</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-30T09:42:39.000Z" itemprop="dateModified">Dec 30, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai_toutiao/daily/csse/20251222-20251228"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">20251222-20251228 (cs.SE)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai_toutiao/daily/cssi"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">cs.SI</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2025-12-29" class="table-of-contents__link toc-highlight">2025-12-29</a></li><li><a href="#2025-12-30" class="table-of-contents__link toc-highlight">2025-12-30</a></li></ul></div></div></div></div></div></div><aside class="content-right-sidebar"><div class="daily-time-sidebar"><div class="daily-time-title">选择时间</div><div class="daily-calendar"><div class="calendar-header"><button class="calendar-nav-btn">‹</button><div class="calendar-title">2025-12</div><button class="calendar-nav-btn">›</button></div><div class="calendar-weekdays"><div>一</div><div>二</div><div>三</div><div>四</div><div>五</div><div>六</div><div>日</div></div><div class="calendar-grid"><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-01">1</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-02">2</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-03">3</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-04">4</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-05">5</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-06">6</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251201-20251207#2025-12-07">7</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-08">8</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-09">9</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-10">10</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-11">11</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-12">12</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-13">13</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251208-20251214#2025-12-14">14</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-15">15</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-16">16</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-17">17</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-18">18</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-19">19</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-20">20</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251215-20251221#2025-12-21">21</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-22">22</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-23">23</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-24">24</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-25">25</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-26">26</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-27">27</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251222-20251228#2025-12-28">28</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251229-20260104#2025-12-29">29</a><a class="calendar-cell calendar-day is-today" href="/ai_toutiao/daily/csse/20251229-20260104#2025-12-30">30</a><a class="calendar-cell calendar-day" href="/ai_toutiao/daily/csse/20251229-20260104#2025-12-31">31</a></div></div></div></aside><aside class="content-right-ads"><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_2.png" alt="草莓师姐"></a><a class="content-ad" href="https://xhslink.com/m/2lTbaZQ1RbP" target="_blank" rel="noopener noreferrer"><img src="/ai_toutiao/img/ads_3.png" alt="草莓师姐"></a></aside></div></div></main></div></div></div></div></div>
</body>
</html>