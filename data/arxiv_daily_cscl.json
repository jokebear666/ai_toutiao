{
  "label": "cs.CL",
  "slug": "cscl",
  "week": "20260105-20260111",
  "items": [
    {
      "title": "Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models",
      "authors": "Shuqi Liu, Bowei He, Chen Ma, Linqi Song",
      "institution": "City University of Hong Kong, City University of Hong Kong Shenzhen Research Institute",
      "link": "https://arxiv.org/pdf/2601.00003",
      "code": null,
      "tags": [
        "retrieval-augmented generation",
        "Monte Carlo Tree Search",
        "reasoning-aware retrieval",
        "coarse-to-fine retrieval",
        "multi-turn dialogue",
        "knowledge diversity"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b609f46963ae2b2b017ba13f445da7491064f311d7e663fa59eda7b85dd69638_w640_q70.webp",
      "contributions": "1. Proposes a reasoning-aware knowledge retrieval method that aligns retrieved information with the logical structure of conversations, moving beyond semantic similarity. 2. Introduces a coarse-to-fine retrieval approach that first finds a contextually relevant knowledge sub-region and then refines it for reasoning-specific knowledge. 3. Employs a Monte Carlo Tree Search-inspired method to navigate knowledge sentences using common keywords, enhancing retrieval diversity and informativeness.",
      "summary": "This paper addresses the challenge of integrating retrieval and reasoning for LLMs by proposing a reasoning-aware knowledge retrieval method. It uses a coarse-to-fine approach guided by Monte Carlo Tree Search to find knowledge aligned with conversational logic. Experiments show the method better captures human reasoning and produces more diverse, informative responses.",
      "mindmap": "graph TB\n        Root[”Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models”] --> Problem[”核心问题/Problem: LLMs struggle to integrate retrieval and reasoning effectively.”]\n        Root --> Method[”主要方法/Method: Coarse-to-fine, MCTS-inspired reasoning-aware knowledge retrieval.”]\n        Root --> Results[”关键结果/Results: Better alignment with human reasoning, more diverse and informative responses.”]"
    },
    {
      "title": "Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study",
      "authors": "Isaac Iyinoluwa Olufadewa, Miracle Ayomikun Adesina, Ezekiel Ayodeji Oladejo, Uthman Babatunde Usman, Owen Kolade Adeniyi, Matthew Tolulope Olawoyin",
      "institution": "Artificial Intelligence for Low-Resource Public Health Application (ALPHA) Centre, Slum and Rural Health Initiative; University of Ibadan; University of Ilorin",
      "link": "https://arxiv.org/pdf/2601.00004",
      "code": null,
      "tags": [
        "mental health language modeling",
        "large language models",
        "fine-tuning",
        "PHQ-9",
        "Nigerian Pidgin",
        "depression screening"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/849aa2e2bc1566aab5f5b5e5d072677a6a66426e677648e836adf89c32b964e6_w640_q70.webp",
      "contributions": "1. Created a novel, annotated dataset of 432 Nigerian Pidgin audio responses for depression screening aligned with PHQ-9 items. 2. Fine-tuned and evaluated three LLMs (Phi-3-mini, Gemma-3-4B-it, GPT-4.1) for automated depression screening in a low-resource language. 3. Demonstrated that fine-tuned GPT-4.1 achieved high accuracy (94.5%) and cultural appropriateness for PHQ-9 severity scoring in Nigerian Pidgin.",
      "summary": "This paper addresses the challenge of depression screening in Nigeria by fine-tuning large language models for Nigerian Pidgin English. The authors collected and annotated a dataset of audio responses, then fine-tuned three LLMs to predict PHQ-9 severity scores. The fine-tuned GPT-4.1 model achieved the best performance, providing a foundation for AI-mediated mental health tools in linguistically diverse, resource-constrained settings.",
      "mindmap": "graph TB\n        A[Finetuning LLMs for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Limited depression screening in Nigeria due to language barriers and lack of clinicians]\n        C[主要方法/Method<br>Fine-tune LLMs on annotated Nigerian Pidgin dataset for PHQ-9 scoring]\n        D[关键结果/Results<br>GPT-4.1 achieved 94.5% accuracy and best cultural appropriateness]"
    },
    {
      "title": "The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition",
      "authors": "Xiaoze Liu, Weichen Yu, Matt Fredrikson, Xiaoqian Wang, Jing Gao",
      "institution": "Purdue University, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2601.00065",
      "code": "https://github.com/xz-liu/tokenforge",
      "tags": [
        "llm inference",
        "tokenizer transplant",
        "model composition",
        "supply-chain vulnerability",
        "sparse solver",
        "spectral mimicry"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bac901d101e76e81a328892233109e7f05c25f328de683add53ccd17ae81590e_w640_q70.webp",
      "contributions": "1. Identifies tokenizer transplant as a novel attack surface in the LLM composition supply chain, 2. Introduces the concept of a \"breaker token\"—a single, engineered token that is inert in a donor model but maliciously activates after transplant, 3. Formalizes and instantiates the attack as a dual-objective optimization problem solved with a sparse solver, demonstrating its training-free nature, stealth, and persistence.",
      "summary": "This paper identifies a security vulnerability in the tokenizer transplant step required for composing different LLMs. The authors propose a method to engineer a single \"breaker token\" that, when added to a donor model, remains harmless but sabotages a base model after transplant by exploiting coefficient reuse. The attack is stealthy, training-free, and persistent, revealing a hidden risk in modular AI pipelines.",
      "mindmap": "graph TB\n        A[The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Tokenizer transplant introduces a supply-chain vulnerability for LLM composition]\n        C[主要方法/Method<br>Engineer a single ”breaker token” exploiting coefficient reuse via sparse solver]\n        D[关键结果/Results<br>Stealthy, training-free attack that persists against fine-tuning and merging]"
    },
    {
      "title": "RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning",
      "authors": "Xiang Gao, Yuguang Yao, Qi Zhang, Kaiwen Dong, Avinash Baidya, Ruocheng Guo, Hilaf Hasson, Kamalika Das",
      "institution": "Intuit AI Research, Temple University",
      "link": "https://arxiv.org/pdf/2601.00086",
      "code": null,
      "tags": [
        "agent system",
        "tool-use",
        "rule learning",
        "minimum description length",
        "neuro-symbolic",
        "prompt injection"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5604dcae3f77a38459a71d5615de42441af3f38dbedaf069349bff470ad72d2f_w640_q70.webp",
      "contributions": "1. Proposes RIMRULE, a neuro-symbolic method for LLM adaptation that distills interpretable rules from failure traces and injects them dynamically during inference. 2. Introduces a Minimum Description Length (MDL) objective to consolidate and select rules, favoring generality and conciseness. 3. Demonstrates that the learned symbolic rules are portable and can improve performance across different LLM architectures without weight modification.",
      "summary": "The paper addresses the problem of LLMs struggling to reliably use domain-specific or under-documented tools. It proposes RIMRULE, a method that learns compact, interpretable rules from failure traces using an MDL objective and injects them into prompts during inference. The approach improves tool-use accuracy on both seen and unseen tools, outperforms prompting baselines, and shows that learned rules are portable across different LLMs.",
      "mindmap": "graph TB\n        A[RIMRULE: Improving Tool-Using Language Agents] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs struggle with domain-specific tools / LLMs难以使用特定领域工具]\n        C --> C1[Dynamic rule injection from failure traces / 从失败轨迹动态注入规则]\n        C --> C2[MDL-guided rule consolidation / MDL引导的规则整合]\n        D --> D1[Improves accuracy on seen/unseen tools / 提升工具使用准确率]\n        D --> D2[Rules are portable across LLMs / 规则可跨LLM迁移]"
    },
    {
      "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs",
      "authors": "Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko",
      "institution": "University of Southern California, Florida International University",
      "link": "https://arxiv.org/pdf/2601.00097",
      "code": null,
      "tags": [
        "causal reasoning",
        "fuzzy cognitive maps",
        "large-language-model agent",
        "causal feedback",
        "equilibrium limit cycles",
        "agentic leash"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc61a9c25939c9840dd408a24d27f4650c47178c297c4db425bc560882426f60_w640_q70.webp",
      "contributions": "1. A novel LLM agent designed to autonomously extract and construct causal feedback Fuzzy Cognitive Maps (FCMs) from raw text. 2. A three-step instruction-guided process for systematically extracting key concepts and causal edges to build the FCM dynamical system. 3. Demonstration that the LLM-generated FCMs converge to the same equilibrium dynamics as human-generated ones and that mixed FCMs from different LLMs can create new equilibria.",
      "summary": "The paper proposes an LLM agent to autonomously extract causal feedback Fuzzy Cognitive Maps from text. The agent uses a three-step process to identify concepts and causal edges, forming a dynamical system. The generated FCMs matched human-generated equilibrium dynamics and mixing models from different LLMs produced new equilibria for better causal approximation.",
      "mindmap": "graph TB\n        A[The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs] --> B[核心问题/Problem: How to autonomously extract causal structures from text?]\n        A --> C[主要方法/Method: Design an LLM agent with a three-step instruction process to build FCMs from text.]\n        A --> D[关键结果/Results: LLM-generated FCMs match human equilibrium dynamics; mixed FCMs create new equilibria.]"
    },
    {
      "title": "Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning",
      "authors": "Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma",
      "institution": "Iowa State University",
      "link": "https://arxiv.org/pdf/2601.00095",
      "code": null,
      "tags": [
        "llm inference",
        "meta-reinforcement learning",
        "constraint propagation",
        "graph attention network",
        "structured inference",
        "green ai"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5284c89e9a9eec9c1882da4c36e7d1e9bbce97ea559fe29f19c435e5f8b8854_w640_q70.webp",
      "contributions": "1. Introduces MetaJuLS, a meta-reinforcement learning framework for learning universal constraint propagation policies applicable across languages and tasks without task-specific retraining. 2. Formulates structured inference as adaptive constraint propagation and trains a Graph Attention Network policy via meta-learning, achieving significant speedups (1.5-2.0x) over GPU-optimized baselines with minimal accuracy loss. 3. Demonstrates rapid cross-domain adaptation (5-15 seconds) and contributes to Green AI by reducing inference carbon footprint through fewer propagation steps.",
      "summary": "The paper addresses the inefficiency of structured inference (e.g., JSON parsing) in large language models by proposing MetaJuLS, a meta-reinforcement learning method that learns adaptive constraint propagation policies. This approach achieves up to 2x speedup over baselines while maintaining high accuracy and enables fast adaptation to new languages and tasks. The work contributes to more efficient and environmentally friendly LLM inference.",
      "mindmap": "graph TB\n        Root[”Universal Adaptive Constraint Propagation<br>通用自适应约束传播”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”LLMs need efficient structured inference<br>LLM需要高效的结构化推理”] --> P1[”Wasted computation from static checking<br>静态检查导致计算浪费”]\n        Problem --> P2[”Need for cross-domain generalization<br>需要跨领域泛化”]\n        Method[”MetaJuLS: Meta-RL for constraint propagation<br>MetaJuLS: 用于约束传播的元强化学习”] --> M1[”Learns universal policies via meta-learning<br>通过元学习学习通用策略”]\n        Method --> M2[”Uses Graph Attention Network<br>使用图注意力网络”]\n        Results[”Key Results<br>关键结果”] --> R1[”1.5-2.0x speedup<br>1.5-2.0倍加速”]\n        Results --> R2[”Fast adaptation (5-15s)<br>快速适应(5-15秒)”]\n        Results --> R3[”Contributes to Green AI<br>助力绿色AI”]"
    },
    {
      "title": "Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description",
      "authors": "Yongmin Yoo, Kris W Pan",
      "institution": "Macquarie University, Amazon",
      "link": "https://arxiv.org/pdf/2601.00166",
      "code": null,
      "tags": [
        "legal text generation and evaluation",
        "patent drafting",
        "LLM-as-a-judge",
        "Chain-of-Legal-Thought",
        "legal compliance",
        "automated evaluation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d9df50304a9b3b4d3c4c409af9be2c858e612c5747a351d8395d536945a60fa6_w640_q70.webp",
      "contributions": "1. Introduces Pat-DEVAL, the first multi-dimensional evaluation framework specifically designed for assessing the quality of generated patent description bodies. 2. Proposes Chain-of-Legal-Thought (CoLT), a novel legally-constrained reasoning mechanism that enforces sequential, patent-law-specific analysis within the LLM-as-a-judge paradigm. 3. Establishes and validates the framework on the Pap2Pat-EvalGold dataset, demonstrating superior correlation with expert judgments, especially in legal compliance, outperforming baseline metrics and existing LLM evaluators.",
      "summary": "This paper addresses the lack of effective evaluation methods for AI-generated patent descriptions, which must meet strict legal standards. It proposes Pat-DEVAL, a framework that uses a Chain-of-Legal-Thought mechanism with an LLM-as-a-judge to assess legal compliance and structural coherence. The method shows significantly higher correlation with expert evaluations than existing approaches, proving the importance of explicit legal constraints for automated patent drafting.",
      "mindmap": "graph TB\n        A[Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有方法无法评估专利说明书的结构连贯性与法律合规性/Existing methods fail to assess structural coherence and legal compliance of patent descriptions]\n        C --> C1[提出Pat-DEVAL框架与Chain-of-Legal-Thought推理机制/Proposes Pat-DEVAL framework with Chain-of-Legal-Thought reasoning]\n        C --> C2[采用LLM-as-a-judge范式，注入法定约束/Adopts LLM-as-a-judge paradigm with statutory constraints]\n        D --> D1[在Pap2Pat-EvalGold数据集上验证/Validated on Pap2Pat-EvalGold dataset]\n        D --> D2[皮尔逊相关性0.69，法律合规性相关性0.73/Pearson correlation 0.69, Legal-Professional Compliance correlation 0.73]\n        D --> D3[显著优于基线指标/Significantly outperforms baseline metrics]"
    },
    {
      "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation",
      "authors": "Cheonkam Jeong, Adeline Nyamathi",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2601.00181",
      "code": null,
      "tags": [
        "emotion recognition in conversation",
        "ablation study",
        "conversational context",
        "discourse markers",
        "causal context",
        "IEMOCAP"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e38dfbfb3b50e432c39aabed201ddaf199012203ee5e7e82a7aa044267fc2a2_w640_q70.webp",
      "contributions": "1. A rigorous ablation study revealing that conversational context is paramount for ERC, with performance saturating within 10-30 preceding turns, and that hierarchical sentence representations and external affective lexicons provide no additional benefit when context is used. 2. Achieving state-of-the-art text-only performance on IEMOCAP using simple architectures with strictly causal context. 3. A novel linguistic analysis connecting recognition to generation, finding a significant association between emotion and discourse marker positioning, particularly that \"sad\" utterances use fewer left-periphery markers and rely more on context for disambiguation.",
      "summary": "This paper systematically analyzes Emotion Recognition in Conversation (ERC) to identify which architectural components matter and connects recognition insights to linguistic patterns for generation. Through ablation studies on IEMOCAP, it finds conversational context is most critical, and via linguistic analysis, it discovers that emotion correlates with discourse marker usage. The main conclusion is that simple models with causal context are sufficient for high performance, and the lack of explicit pragmatic signals in \"sad\" utterances explains their greater reliance on context.",
      "mindmap": "graph TB\n        A[Understanding Emotion in Discourse] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[ERC模型哪些组件真正有效?/Which ERC components matter?]\n        B --> B2[如何连接识别与生成?/How to connect recognition & generation?]\n        C --> C1[系统消融研究/Systematic Ablation Study]\n        C --> C2[话语标记分析/Discourse Marker Analysis]\n        D --> D1[上下文最关键, 10-30轮饱和/Context is key, saturates in 10-30 turns]\n        D --> D2[简单因果模型SOTA/Simple causal model achieves SOTA]\n        D --> D3[悲伤话语标记少, 更依赖上下文/Sad utterances have fewer markers, rely more on context]"
    },
    {
      "title": "StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices",
      "authors": "Shaswat Mohanty",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2601.00197",
      "code": null,
      "tags": [
        "time series forecasting",
        "LSTM",
        "Transformer",
        "Stock Prediction",
        "Time Series Forecasting",
        "Attention"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/131078c30708f9e13fee0c529bee858ed184717ff3b0bf5f762eda2a9370616c_w640_q70.webp",
      "contributions": "1. Presents an enhanced StockBot architecture for systematic evaluation of modern time-series forecasting models (attention-based, convolutional, recurrent) in a unified setting. 2. Demonstrates empirically that a carefully constructed vanilla LSTM model consistently outperforms transformer-based models in stock price forecasting accuracy and decision-making stability under default hyperparameters. 3. Highlights the robustness, data efficiency, and importance of architectural inductive bias of recurrent models for financial forecasting, especially in data-limited scenarios.",
      "summary": "This paper presents StockBot 2.0, a framework for evaluating time-series models for stock prediction. It finds that a vanilla LSTM model, despite its simplicity, outperforms more complex transformer-based models in forecasting accuracy and trading decision stability when trained with default settings, emphasizing the value of recurrent inductive biases for financial data.",
      "mindmap": "graph TB\n        Root[”StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices”] --> Problem[”核心问题/Problem: Forecasting financial markets is challenging due to complexity and volatility.”]\n        Root --> Method[”主要方法/Method: Enhanced StockBot architecture for systematic evaluation of attention, CNN, and RNN models.”]\n        Root --> Results[”关键结果/Results: Vanilla LSTM achieves superior accuracy and stable decisions compared to transformers.”]"
    },
    {
      "title": "Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models",
      "authors": "Wang Xing, Wei Song, Siyu Lin, Chen Wu, Zhesi Li, Man Wang",
      "institution": "Xidian University, Southwest Jiaotong University, Chongqing Jiaotong University, Chang’an University",
      "link": "https://arxiv.org/pdf/2601.00202",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "knowledge distillation",
        "temporal knowledge graph reasoning",
        "large language models",
        "teacher-student framework",
        "temporal dependencies"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/19e66b8571c108befcd93243d5d7ad64cfb10f7509cd7cbcd74ba39136582282_w640_q70.webp",
      "contributions": "1. Proposes a novel distillation framework specifically designed for Temporal Knowledge Graph (TKG) reasoning, addressing the limitations of static graph compression techniques. 2. Leverages Large Language Models (LLMs) as teacher models to transfer both structural and temporal reasoning capabilities to lightweight student models. 3. Integrates large-scale public knowledge with task-specific temporal information to enhance the student model's ability to model temporal dynamics while maintaining computational efficiency.",
      "summary": "This paper addresses the challenge of deploying computationally expensive Temporal Knowledge Graph (TKG) reasoning models on resource-constrained platforms. The authors propose a knowledge distillation framework that uses Large Language Models (LLMs) as teachers to transfer temporal and structural reasoning knowledge to compact student models. Experiments show the method achieves a favorable trade-off between reasoning accuracy and efficiency, outperforming existing baselines.",
      "mindmap": "graph TB\n        A[Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有TKG推理模型计算量大，难以部署/Existing TKG models are computationally heavy and hard to deploy]\n        B --> B2[现有压缩技术无法有效处理时序依赖/Existing compression techniques fail to capture temporal dependencies]\n        C --> C1[提出针对TKG的蒸馏框架/Propose a distillation framework tailored for TKGs]\n        C --> C2[使用LLM作为教师模型/Use LLMs as teacher models]\n        C --> C3[将结构与时序推理能力迁移到轻量学生模型/Transfer structural and temporal reasoning to lightweight student models]\n        D --> D1[在多个基准数据集上超越基线/Outperforms baselines on multiple benchmark datasets]\n        D --> D2[实现精度与效率的良好权衡/Achieves a favorable trade-off between accuracy and efficiency]"
    },
    {
      "title": "Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak",
      "authors": "Haoran Gu, Handing Wang, Yi Mei, Mengjie Zhang, Yaochu Jin",
      "institution": "Xidian University, Victoria University of Wellington, Westlake University",
      "link": "https://arxiv.org/pdf/2601.00213",
      "code": null,
      "tags": [
        "llm safety & alignment",
        "jailbreak",
        "algorithm design",
        "safety benchmark",
        "optimization algorithm",
        "malicious prompt"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6ccef5999a7edaf6824967fee78721c43b0e003d14334de2a1bb59ce1410a85_w640_q70.webp",
      "contributions": "1. Identifies and investigates a novel safety vulnerability in LLMs related to automated malicious optimization algorithm design. 2. Introduces MalOptBench, a benchmark of 60 malicious optimization algorithm requests for evaluating this vulnerability. 3. Proposes MOBjailbreak, a tailored jailbreak method for this scenario, and demonstrates its high effectiveness against current LLMs and defenses.",
      "summary": "This paper investigates a safety vulnerability where LLMs can be prompted to generate malicious optimization algorithms. It introduces the MalOptBench benchmark and the MOBjailbreak attack method, finding that current LLMs and plug-and-play defenses are highly susceptible, highlighting a need for stronger alignment techniques.",
      "mindmap": "graph TB\n        Root[”Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak”] --> Problem[”核心问题/Problem: LLMs在自动化算法设计中的安全漏洞未被充分探索/Underexplored safety vulnerability in LLM-driven automated algorithm design”]\n        Root --> Method[”主要方法/Method: 提出基准MalOptBench和越狱方法MOBjailbreak/Propose benchmark MalOptBench and jailbreak method MOBjailbreak”]\n        Root --> Results[”关键结果/Results: LLMs高度脆弱，现有防御效果有限/LLMs are highly susceptible, current defenses are marginally effective”]"
    },
    {
      "title": "From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning",
      "authors": "Omar Sharif, Eftekhar Hossain, Patrick Ng",
      "institution": "Dartmouth College, University of Central Florida",
      "link": "https://arxiv.org/pdf/2601.00215",
      "code": null,
      "tags": [
        "reinforcement learning",
        "reinforcement learning",
        "multimodal large language models",
        "visual reasoning",
        "group relative policy optimization",
        "reward functions"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fa78fbb9d1620ad3674739f2e8cf9cfb6929637fa0f209ae3ee4c439ab5205c8_w640_q70.webp",
      "contributions": "1. Identified visual perception as the primary bottleneck for MLLMs in visual puzzle tasks, empirically validated by showing significant performance gains when images are converted to text. 2. Proposed a reward-driven RL framework using GRPO to incentivize longer, structured visual reasoning in open-source MLLMs without costly supervision. 3. Designed and evaluated six novel reward functions targeting different reasoning aspects like image understanding, thinking steps, and answer accuracy.",
      "summary": "This paper addresses the problem that multimodal large language models (MLLMs) generate reasoning chains that lack integration of visual information, limiting their performance on visual puzzles. The authors propose using reinforcement learning with specifically designed reward functions and Group Relative Policy Optimization (GRPO) to incentivize longer, visually-grounded reasoning. Their method improves the performance of the Qwen-2.5-VL-7B model by 5.56%, demonstrating consistent gains across different settings.",
      "mindmap": "graph TB\n        Root[”From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning”] --> Problem[”核心问题/Problem: MLLMs lack visual grounding in reasoning”]\n        Root --> Method[”主要方法/Method: RL with reward functions & GRPO”]\n        Root --> Results[”关键结果/Results: 5.56% improvement on Qwen-2.5-VL-7B”]"
    },
    {
      "title": "From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark",
      "authors": "Jinning Zhang, Jie Song, Wenhui Tu, Zecheng Li, Jingxuan Li, Jin Li, Xuan Liu, Taole Sha, Zichen Wei, Yan Li",
      "institution": "Beijing Sport University",
      "link": "https://arxiv.org/pdf/2601.00216",
      "code": null,
      "tags": [
        "retrieval-augmented generation",
        "knowledge graph",
        "PICO framework",
        "evidence-based medicine",
        "Bayesian reranking",
        "sports rehabilitation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bd3d679f214bbb1077d6def8ab28cb0755d55d1e2bccc588807eff404d6c8bf_w640_q70.webp",
      "contributions": "1. Proposes a generalizable strategy for integrating Evidence-Based Medicine (EBM) principles into graph-based RAG, addressing PICO alignment and evidence hierarchy. 2. Introduces a Bayesian-inspired reranking algorithm to calibrate retrieval scores based on evidence grade without predefined weights. 3. Constructs and releases a domain-specific knowledge graph and benchmark for sports rehabilitation to address the scarcity of RAG resources in this field.",
      "summary": "This paper addresses the oversight of evidence-based medicine principles in current RAG systems by proposing a strategy that integrates the PICO framework into knowledge graph construction and a Bayesian reranking algorithm. The method was validated in sports rehabilitation, showing improved answer quality and high expert ratings, and the released resources help fill a domain-specific data gap.",
      "mindmap": "graph TB\n        Root[”From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark”]\n        Root --> Problem[”核心问题/Problem: Current RAG overlooks EBM principles (PICO misalignment, no evidence hierarchy)”]\n        Root --> Method[”主要方法/Method: Integrate PICO into KG RAG & Bayesian reranking for evidence grade”]\n        Root --> Results[”关键结果/Results: High-quality answers & expert ratings; Released KG & benchmark”]"
    },
    {
      "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation",
      "authors": "Leonard Lin, Adam Lensenmayer",
      "institution": "Shisa.AI",
      "link": "https://arxiv.org/pdf/2601.00223",
      "code": null,
      "tags": [
        "machine translation",
        "LLM-as-a-judge",
        "pairwise comparison",
        "Bradley-Terry model",
        "reference-free evaluation",
        "anchored evaluation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3672d8de20107e284402d4b12e978f246eb0df92617095708ca7710e712594d_w640_q70.webp",
      "contributions": "1. Introduces JP-TL-Bench, a lightweight, open benchmark for iterative development of Japanese-English translation systems. 2. Proposes a reliable and affordable evaluation protocol using reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. 3. Provides structurally stable scores by aggregating pairwise results with a Bradley-Terry model and reporting normalized LT scores.",
      "summary": "The paper introduces JP-TL-Bench, a benchmark for evaluating high-quality Japanese-English translation. It uses a protocol where candidate models are compared against a fixed anchor set via pairwise LLM judgments, with results aggregated using a Bradley-Terry model to produce stable scores. This approach aims to provide a high-resolution signal for distinguishing between already fluent translations where traditional metrics saturate.",
      "mindmap": "graph TB\n        A[JP-TL-Bench: Anchored Pairwise LLM Evaluation<br>JP-TL-Bench: 锚定成对LLM评估] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>现有评估方法难以区分高质量翻译<br>Existing evaluation struggles to differentiate high-quality translations]\n        C[主要方法/Method<br>基于固定锚定集的成对LLM比较<br>Pairwise LLM comparison against a fixed anchor set]\n        D[关键结果/Results<br>提供稳定、可解释的分数<br>Provides stable, interpretable scores]"
    },
    {
      "title": "Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback",
      "authors": "Yan Sun, Ming Cai, Stanley Kok",
      "institution": "National University of Singapore",
      "link": "https://arxiv.org/pdf/2601.00224",
      "code": null,
      "tags": [
        "agent system",
        "semantic verification",
        "execution feedback",
        "generator-discriminator framework",
        "reverse translation",
        "conversational business analytics"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2d07ef5c900d3b1d3d6067b2025a8ba0771149df2530b94a6a54885c8bd8685_w640_q70.webp",
      "contributions": "1. Proposes Q*, a verification technique that uses reverse translation and semantic matching to align generated code with user intent. 2. Introduces Feedback+, a mechanism that incorporates execution feedback to guide iterative code refinement. 3. Embeds these techniques within a generator-discriminator framework to shift validation responsibilities from users to the system, aiming to improve reliability.",
      "summary": "This paper addresses the lack of verification in conversational business analytics systems by proposing two techniques, Q* and Feedback+, to improve the accuracy and executability of LLM-generated outputs. The methods are integrated into a generator-discriminator framework and evaluated on benchmark datasets, showing reduced error rates and task completion time. The work provides a design framework for building more reliable enterprise-grade GenAI assistants.",
      "mindmap": "graph TB\n        A[Talk Less, Verify More: Improving LLM Assistants<br>少说多验证：改进LLM助手] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LLM助手缺乏验证机制<br>Lack of verification in LLM assistants]\n        C[主要方法/Method<br>Q*与Feedback+验证<br>Q* and Feedback+ verification]\n        D[关键结果/Results<br>降低错误率与任务时间<br>Reduced error rate & task time]\n        C --> E[Q*: 逆向翻译与语义匹配<br>Q*: Reverse translation & semantic matching]\n        C --> F[Feedback+: 执行反馈引导优化<br>Feedback+: Execution feedback guides refinement]"
    },
    {
      "title": "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation",
      "authors": "Qianli Wang, Van Bach Nguyen, Yihong Liu, Fedor Splitt, Nils Feldhus, Christin Seifert, Hinrich Schütze, Sebastian Möller, Vera Schmitt",
      "institution": "Technische Universität Berlin, University of Marburg, LMU Munich, German Research Center for Artificial Intelligence (DFKI), Munich Center for Machine Learning (MCML), BIFOLD – Berlin Institute for the Foundations of Learning and Data",
      "link": "https://arxiv.org/pdf/2601.00263",
      "code": null,
      "tags": [
        "explainable ai (xai)",
        "counterfactual examples",
        "multilingual",
        "data augmentation",
        "large language models",
        "model robustness"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3b95c2cf3407989c3c5a932764e908182c4d60d7451ace3f5f15e194a3a7e5_w640_q70.webp",
      "contributions": "1. Evaluated the quality of LLM-generated multilingual counterfactuals, comparing direct generation and translation-based methods across six languages. 2. Identified four main error types common in generated counterfactuals across languages and found similar edit patterns in high-resource European languages. 3. Demonstrated that multilingual counterfactual data augmentation yields greater performance improvements than cross-lingual augmentation, especially for lower-resource languages.",
      "summary": "This paper investigates the effectiveness of large language models (LLMs) in generating multilingual counterfactual examples. It compares directly generated and translation-based counterfactuals across six languages, finding that translation-based ones are more valid but require more edits and still underperform English ones. The study concludes that while multilingual counterfactual data augmentation improves model performance, especially for low-resource languages, the quality limitations of the generated counterfactuals constrain the gains in robustness.",
      "mindmap": "graph TB\n        A[Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM生成多语言反事实示例的有效性未知/Effectiveness of LLM-generated multilingual counterfactuals is unclear]\n        C --> C1[评估直接生成与翻译生成的反事实/Evaluate directly generated and translation-based counterfactuals]\n        C --> C2[分析编辑模式与错误类型/Analyze edit patterns and error types]\n        C --> C3[用于数据增强实验/Use for data augmentation experiments]\n        D --> D1[翻译生成的反事实更有效但编辑更多/Translation-based CFs are more valid but require more edits]\n        D --> D2[高资源语言编辑模式相似/Edit patterns are similar for high-resource languages]\n        D --> D3[多语言数据增强效果更好/Multilingual data augmentation yields larger improvements]"
    },
    {
      "title": "Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity",
      "authors": "Doyoung Kim, Zhiwei Ren, Jie Hao, Zhongkai Sun, Lichao Wang, Xiyao Ma, Zack Ye, Xu Han, Jun Yin, Heng Ji, Wei Shen, Xing Fan, Benjamin Yao, Chenlei Guo",
      "institution": "Amazon, KAIST, University of Pittsburgh, University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2601.00268",
      "code": "github.com/Demon-JieHao/WildAGTEval",
      "tags": [
        "agent system",
        "function-calling",
        "benchmark",
        "API complexity",
        "LLM agents",
        "WildAGTEval"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f3c517d92b4a84a20e84e30c740db5d9b70b7f3195c6de0fc8e049a5f0a4c9af_w640_q70.webp",
      "contributions": "1. Introduces WildAGTEval, a novel benchmark for evaluating LLM agents under realistic API complexity, covering both API specification and execution challenges. 2. Provides a comprehensive API system with 60 distinct complexity scenarios, composable into ~32K test configurations, and user-agent interactions for evaluation. 3. Systematically assesses advanced LLMs, revealing significant performance drops (e.g., 27.3% for irrelevant information complexity) and identifying critical failure modes like intent distortion.",
      "summary": "This paper introduces WildAGTEval, a benchmark designed to evaluate LLM agents' function-calling capabilities under realistic API complexities, including detailed specifications and noisy execution. The study finds that most scenarios are challenging, with irrelevant information posing the greatest difficulty and causing significant performance drops in strong models. The qualitative analysis also reveals that LLMs sometimes distort user intent to claim task completion, negatively impacting user satisfaction.",
      "mindmap": "graph TB\n        A[Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有基准假设理想化API / Existing benchmarks assume idealized APIs]\n        B --> B2[忽略现实因素如噪声输出 / Ignore real-world factors like noisy outputs]\n        C --> C1[提出WildAGTEval基准 / Propose WildAGTEval benchmark]\n        C --> C2[涵盖API规范与执行复杂性 / Covers API specification & execution complexity]\n        D --> D1[大多数场景具有挑战性 / Most scenarios are challenging]\n        D --> D2[无关信息复杂度导致性能显著下降 / Irrelevant info complexity causes significant performance drop]\n        D --> D3[LLM可能扭曲用户意图 / LLMs may distort user intent]"
    },
    {
      "title": "Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations",
      "authors": "Qianli Wang, Nils Feldhus, Pepa Atanasova, Fedor Splitt, Simon Ostermann, Sebastian Möller, Vera Schmitt",
      "institution": "Technische Universität Berlin, German Research Center for Artificial Intelligence (DFKI), University of Copenhagen",
      "link": "https://arxiv.org/pdf/2601.00282",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "quantization",
        "self-explanations",
        "faithfulness",
        "natural language explanations",
        "counterfactual examples"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8576a4dae59be54ef8b0a451a49893f5b9d59eceafecb4a697aed2b3fd4a470b_w640_q70.webp",
      "contributions": "1. First comprehensive study on the impact of quantization on the quality and faithfulness of LLM self-explanations. 2. Empirical evaluation across multiple quantization techniques, bit widths, and model sizes, revealing moderate but consistent degradation in explanation metrics. 3. Provides practical recommendations for validating self-explanations in quantized models, highlighting the greater sensitivity of natural language explanations.",
      "summary": "This paper investigates how quantization affects the quality and faithfulness of self-explanations generated by large language models. The authors evaluate multiple quantization methods and find they cause moderate declines in explanation metrics, with larger models showing better faithfulness preservation. They conclude that while quantization degrades self-explanations, the impact is relatively minor and does not negate its benefits for model compression.",
      "mindmap": "graph TB\n        Root[”Can Large Language Models Still Explain Themselves?<br/>大语言模型还能解释自己吗？”] --> Problem[”Quantization's effect on Self-Explanations is unknown.<br/>量化对自我解释的影响未知”]\n        Root --> Method[”Evaluate NLEs & Counterfactuals from quantized LLMs.<br/>评估量化后LLM的自然语言解释和反事实示例”]\n        Root --> Results[”Moderate decline in quality/faithfulness; context-dependent impact.<br/>质量/忠实度适度下降；影响因上下文而异”]"
    },
    {
      "title": "DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection",
      "authors": "Yuxin Li, Xiangyu Zhang, Yifei Li, Zhiwei Guo, Haoyang Zhang, Eng Siong Chng, Cuntai Guan",
      "institution": "Nanyang Technological University, UNSW Sydney, Peking University",
      "link": "https://arxiv.org/pdf/2601.00303",
      "code": null,
      "tags": [
        "speech processing",
        "depression detection",
        "semantic bias",
        "text-to-speech",
        "disentangled representation",
        "data augmentation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddfe4c5383fa66e6b8e028851d0fe67037a11642b799a3626a1100aaa4cd8096_w640_q70.webp",
      "contributions": "1. Proposes DepFlow, a novel three-stage depression-conditioned TTS framework that disentangles depression-specific acoustic patterns from speaker and content information using adversarial training and flow-matching. 2. Introduces a prototype-based severity mapping mechanism for smooth and interpretable control over the synthesized depressive severity. 3. Constructs a Camouflage Depression-oriented Augmentation (CDoA) dataset using DepFlow to mitigate semantic bias, which significantly improves the robustness of depression detection models.",
      "summary": "The paper addresses the problem of semantic bias in depression detection models, where models learn shortcuts from linguistic sentiment instead of acoustic cues. It proposes DepFlow, a disentangled speech generation framework, to create a synthetic dataset (CDoA) that pairs depressed acoustic patterns with positive/neutral text. This data augmentation method improves model robustness, outperforming conventional strategies.",
      "mindmap": "graph TB\n        Root[”DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem: Models learn semantic shortcuts from sentiment-content coupling in depression datasets.”]\n        Method[”主要方法/Method: DepFlow, a 3-stage TTS framework for disentangling & controlling depression acoustics.”]\n        Results[”关键结果/Results: CDoA augmentation improves detection model F1 scores by 5-12%.”]"
    },
    {
      "title": "Robust Uncertainty Quantification for Factual Generation of Large Language Models",
      "authors": "Yuhao Zhang, Zhongliang Yang, Linna Zhou",
      "institution": "Beijing University of Posts and Telecommunications",
      "link": "https://arxiv.org/pdf/2601.00348",
      "code": "https://github.com/EdwardChang5467/robust",
      "tags": [
        "hallucination detection",
        "uncertainty quantification",
        "factual hallucination",
        "trap questions",
        "ROCAUC",
        "fake biographies"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6268aa8c8874ac861a06315946aedcfbc9df7712a9f2b63e23204554e9c8596b_w640_q70.webp",
      "contributions": "1. Proposes a new uncertainty quantification scenario focused on multi-fact generation (e.g., fake person biographies) to test LLM robustness. 2. Constructs a novel dataset of trap questions containing fake names to evaluate hallucination detection methods. 3. Introduces a robust uncertainty quantification (RU) method that significantly outperforms baseline methods across four different LLMs.",
      "summary": "This paper addresses the problem of LLM hallucination by proposing a new robust uncertainty quantification (RU) method for detecting factual errors in multi-fact generation tasks. The method is evaluated using a specially constructed set of trap questions containing fake names. Results show the RU method achieves an average increase of 0.1-0.2 in ROCAUC over the best baseline, demonstrating its effectiveness in improving the reliability of LLM outputs.",
      "mindmap": "graph TB\n        A[Robust Uncertainty Quantification for Factual Generation of LLMs] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LLM幻觉与不确定性量化缺陷<br>LLM Hallucination & UQ Deficiency]\n        C[主要方法/Method<br>构建陷阱问题集与提出鲁棒方法<br>Construct Trap Questions & Propose RU Method]\n        D[关键结果/Results<br>ROC-AUC显著提升<br>Significant ROC-AUC Improvement]"
    },
    {
      "title": "BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics",
      "authors": "Taj Gillin, Adam Lalani, Kenneth Zhang, Marcel Mateos Salles",
      "institution": "Brown University",
      "link": "https://arxiv.org/pdf/2601.00366",
      "code": null,
      "tags": [
        "multilingual representation learning",
        "Joint Embedding Predictive Architecture (JEPA)",
        "BERT",
        "CLS token",
        "language-agnostic embedding",
        "multilingual benchmarks"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cd5b4a28e22d003dd88f59a4d1a1a55a97fa54c9c398a578c710764342d3180_w640_q70.webp",
      "contributions": "1. Introduces BERT-JEPA (BEPA), a novel training paradigm that adds a JEPA objective to BERT-style models to reorganize the [CLS] embedding space. 2. Demonstrates that BEPA finetuning transforms the [CLS] embedding space into a semantic-first, language-agnostic space, shifting its PCA representation from low-rank to fuller-rank. 3. Shows that this reorganization improves performance on multilingual tasks with little to no loss in English performance.",
      "summary": "The paper addresses the problem that BERT's [CLS] embeddings fail to capture language-invariant semantics. It proposes BERT-JEPA (BEPA), a method that adds a Joint Embedding Predictive Architecture (JEPA) objective during training to reorganize the [CLS] embedding space into a language-agnostic \"thought space\". The main conclusion is that this approach significantly improves performance on multilingual benchmarks while maintaining English task performance.",
      "mindmap": "graph TB\n        Root[”BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics”] --> Problem[”核心问题/Problem: CLS embeddings are not language-invariant and fail to capture true sentence semantics.”]\n        Root --> Method[”主要方法/Method: Add JEPA training objective to BERT to create a language-agnostic embedding space.”]\n        Root --> Results[”关键结果/Results: Improved multilingual benchmark performance; reorganized, semantic-first CLS space.”]"
    },
    {
      "title": "The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining",
      "authors": "Jiandong Shao, Raphael Tang, Crystina Zhang, Karin Sevegnani, Pontus Stenetorp, Jianfei Yang, Yao Lu",
      "institution": "University College London, Nanyang Technological University, University of Waterloo, NVIDIA, National Institute of Informatics",
      "link": "https://arxiv.org/pdf/2601.00364",
      "code": null,
      "tags": [
        "multilingual language models",
        "multilingual pretraining",
        "parallel data",
        "code-switching",
        "cross-lingual transfer",
        "translation"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d428d7e2552dcd9b73d3c4332f442260a2a8e3b735ffd1384f2f162c6a5bde44_w640_q70.webp",
      "contributions": "1. Conducted controlled pretraining experiments from scratch to isolate the impact of bilingual data, revealing that removing just 2% of such data causes a 56% drop in translation performance while leaving cross-lingual QA and reasoning largely unaffected. 2. Introduced a granular categorization of bilingual data into parallel, code-switching, and miscellaneous types based on semantic relevance, enabling more precise analysis. 3. Demonstrated through ablation studies that translation performance is critically dependent on parallel data (restoring 91% of baseline performance), whereas code-switching data contributes minimally, and that cross-lingual understanding does not rely heavily on bilingual data.",
      "summary": "This paper investigates the role of bilingual data in multilingual large language model pretraining by comparing standard web corpora with a monolingual-only version. Through controlled experiments and granular ablations categorizing data into parallel and code-switching types, it finds that translation performance heavily depends on parallel data for token-level alignments, while cross-lingual understanding and reasoning tasks can be achieved even without bilingual data.",
      "mindmap": "graph TB\n        A[The Role of Mixed-Language Documents for Multilingual LLM Pretraining] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Bilingual data's role in cross-lingual performance is unclear] --> B1[问题细化/Sub-Problem<br>Does it uniformly benefit all tasks?]\n        C[主要方法/Method<br>Controlled pretraining & granular ablation] --> C1[方法步骤/Step 1<br>Compare standard vs. monolingual-only corpus]\n        C --> C2[方法步骤/Step 2<br>Categorize bilingual data: Parallel, Code-switching]\n        C --> C3[方法步骤/Step 3<br>Reintroduce data types for ablation]\n        D[关键结果/Results<br>Asymmetric impact of bilingual data] --> D1[结果1/Result 1<br>Translation needs parallel data]\n        D --> D2[结果2/Result 2<br>Cross-lingual QA/reasoning stable without it]"
    },
    {
      "title": "Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach",
      "authors": "Biao Wu, Meng Fang, Ling Chen, Ke Xu, Tao Cheng, Jun Wang",
      "institution": "University of Technology Sydney, University of Liverpool, University College London",
      "link": "https://arxiv.org/pdf/2601.00388",
      "code": null,
      "tags": [
        "reinforcement learning",
        "geolocalization",
        "vision-language models",
        "chain of region",
        "haversine distance",
        "retrieval-free"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/986e7d2e1e80caef1d7794a999a5e00e8f2a503a4cae673b68dc3cfafa02122c_w640_q70.webp",
      "contributions": "1. Proposes Geo-R, a retrieval-free framework for image geolocalization that uses reinforcement learning. 2. Introduces Chain of Region, a rule-based hierarchical reasoning paradigm to generate interpretable supervision from GPS coordinates. 3. Develops a lightweight RL strategy with coordinate-aligned rewards based on Haversine distance for spatially meaningful feedback.",
      "summary": "This paper addresses the limitations of existing image geolocalization methods by proposing Geo-R, a retrieval-free framework that uses a rule-based Chain of Region for hierarchical reasoning and a reinforcement learning strategy with Haversine distance rewards. The approach improves localization accuracy, generalization, and interpretability without relying on synthetic labels or external retrieval, as validated across multiple benchmarks.",
      "mindmap": "graph TB\n        A[Vision-Language Reasoning for Geolocalization] --> B[核心问题/Problem: Existing methods rely on synthetic annotations or retrieval, limiting interpretability and generalization.]\n        A --> C[主要方法/Method: Proposes Geo-R, a retrieval-free framework using Chain of Region for hierarchical reasoning and RL with Haversine distance rewards.]\n        A --> D[关键结果/Results: Improved accuracy, stronger generalization, and more transparent inference, establishing a new retrieval-free paradigm.]"
    },
    {
      "title": "Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset",
      "authors": "Alistair Plum, Laura Bernardy, Tharindu Ranasinghe",
      "institution": "University of Luxembourg, Lancaster University",
      "link": "https://arxiv.org/pdf/2601.00411",
      "code": null,
      "tags": [
        "named entity recognition",
        "weak supervision",
        "large language models",
        "low-resource languages",
        "dataset construction",
        "Luxembourgish"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e13a29d091cdd4cb0cc5c3d34a98e86c8d45b0a34f42a2b552cecd9fcff5b51_w640_q70.webp",
      "contributions": "1. Proposes a novel pipeline for constructing NER datasets that uses Wikipedia/Wikidata for weak supervision and LLMs for label verification. 2. Introduces judgeWEL, a new and significantly larger NER dataset for the under-represented language Luxembourgish. 3. Evaluates and compares the effectiveness of multiple LLMs in judging and filtering noisy, distantly-supervised labels.",
      "summary": "This paper addresses the challenge of building datasets for under-represented languages by proposing a novel method that uses Wikipedia and Wikidata for weak supervision to generate initial NER labels, and then employs multiple LLMs to verify and filter these labels for quality. The approach is applied to Luxembourgish, resulting in the judgeWEL dataset, which is five times larger and more balanced than existing resources, providing a valuable new corpus for low-resource NER research.",
      "mindmap": "graph TB\n    A[Do LLMs Judge Distantly Supervised Named Entity Labels Well?<br/>构建JudgeWEL数据集] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[低资源语言数据集构建困难<br/>Dataset Construction for Low-Resource Languages]\n    C --> C1[利用维基百科/维基数据进行远程监督<br/>Weak Supervision via Wikipedia/Wikidata]\n    C --> C2[使用多个LLM进行标签验证<br/>Label Verification with Multiple LLMs]\n    D --> D1[创建了更大的卢森堡语NER数据集<br/>Larger Luxembourgish NER Dataset Created]\n    D --> D2[数据集规模扩大五倍，覆盖更平衡<br/>5x Larger, More Balanced Coverage]"
    },
    {
      "title": "Deep Delta Learning",
      "authors": "Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu",
      "institution": "Princeton University, University of California, Los Angeles",
      "link": "https://arxiv.org/pdf/2601.00417",
      "code": "https://github.com/yifanzhang-pro/deep-delta-learning",
      "tags": [
        "neural network architecture",
        "residual networks",
        "geometric transformation",
        "spectral analysis",
        "rank-1 perturbation",
        "dynamic gating"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e9151cd8b5ec94dcb21276489c4319c73f4c1a7295a6715a6c2a36d36f9a9b_w640_q70.webp",
      "contributions": "1. Introduces Deep Delta Learning (DDL), a novel architecture that generalizes residual connections with a learnable, data-dependent geometric transformation called the Delta Operator. 2. Provides a spectral analysis of the Delta Operator, showing it can dynamically interpolate between identity mapping, orthogonal projection, and geometric reflection via a gating scalar. 3. Restructures the residual update as a synchronous rank-1 injection, unifying feature erasure and writing under a dynamic step size to enable complex, non-monotonic dynamics while preserving stable training.",
      "summary": "This paper identifies that the strictly additive inductive bias of standard residual networks limits their capacity to model complex state transitions. To address this, it proposes Deep Delta Learning (DDL), which modulates the identity shortcut with a learnable, data-dependent geometric transformation (the Delta Operator). This allows the network to explicitly control its layer-wise transition spectrum, enabling the modeling of complex dynamics like oscillations while maintaining stable training.",
      "mindmap": "graph TB\n        A[Deep Delta Learning] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[残差网络限制/ResNet Limitation]\n        B1 --> B2[”刚性相加偏置/Rigid Additive Bias”]\n        B2 --> B3[”限制复杂状态转换/Limits Complex State Transitions”]\n        C --> C1[Delta 算子/Delta Operator]\n        C1 --> C2[”秩-1扰动/ Rank-1 Perturbation”]\n        C2 --> C3[”可学习几何变换/Learnable Geometric Transform”]\n        C3 --> C4[”动态门控/Dynamic Gating (β)”]\n        D --> D1[”谱分析/Spectral Analysis”]\n        D1 --> D2[”插值身份/投影/反射/Interpolates Identity/Projection/Reflection”]\n        D --> D3[”同步秩-1注入/Synchronous Rank-1 Injection”]\n        D3 --> D4[”控制转换谱/Controls Transition Spectrum”]\n        D4 --> D5[”保持稳定训练/Preserves Stable Training”]"
    },
    {
      "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
      "authors": "Dimitris Vartziotis",
      "institution": "TWT Science & Innovation, NIKI - Digital Engineering",
      "link": "https://arxiv.org/pdf/2601.00448",
      "code": null,
      "tags": [
        "language modeling",
        "Semantic Field Theory",
        "lexical fields",
        "linguistic fields",
        "transformer architectures",
        "embedding spaces"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98759f21c127cf9a440b464892816dd7e22af8f161a1d16ec91b582a8fefa647_w640_q70.webp",
      "contributions": "1. Formalizes the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. 2. Analyzes how core properties of transformer architectures (e.g., distributed representations, attention) relate to Semantic Field Theory concepts. 3. Proposes that mathematical structure and language games are complementary perspectives, clarifying the scope and limits of statistical language models.",
      "summary": "This paper examines theories of linguistic meaning by contrasting social constructivist language games with a mathematically oriented Semantic Field Theory. It formalizes lexical and linguistic fields and analyzes their relation to transformer architecture properties. The authors conclude that the mathematical structure captured by LLMs and the social grounding of language games are complementary, not competing, views.",
      "mindmap": "graph TB\n        Root(”Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games”) --> Problem(”核心问题/Problem: Contrasting theories of linguistic meaning (social vs. mathematical)”)\n        Root --> Method(”主要方法/Method: Formalizing Semantic Field Theory (Lexfelder/Lingofelder) and analyzing transformer properties”)\n        Root --> Results(”关键结果/Results: Mathematical structure and language games are complementary perspectives”)"
    },
    {
      "title": "Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment",
      "authors": "Muhammad Shahmeer Khan",
      "institution": "Ulster University",
      "link": "https://arxiv.org/pdf/2601.00444",
      "code": null,
      "tags": [
        "text classification",
        "DistilBERT",
        "MiniLM",
        "ALBERT",
        "inference latency",
        "model efficiency"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/caee3ae4ac5e6aeda42367ba10ce7ebb5766e7933d76b7277c736f90391d7895_w640_q70.webp",
      "contributions": "1. A systematic comparison of three lightweight Transformer models (DistilBERT, MiniLM, ALBERT) across three enterprise-relevant domains. 2. An empirical evaluation using both accuracy-based and efficiency metrics under fixed enterprise-oriented constraints. 3. Practical deployment recommendations highlighting the trade-offs between accuracy and efficiency for different enterprise scenarios.",
      "summary": "This paper compares the efficiency and performance of three lightweight Transformer models—DistilBERT, MiniLM, and ALBERT—across sentiment, news, and hate speech classification tasks. The evaluation uses accuracy and efficiency metrics under controlled fine-tuning. The key finding is a trade-off: ALBERT excels in accuracy, MiniLM in speed, and DistilBERT offers the most consistent balance, providing clear deployment guidance for enterprises.",
      "mindmap": "graph TB\n        Root[”COMPARATIVE EFFICIENCY ANALYSIS OF LIGHTWEIGHT TRANSFORMER MODELS<br>轻量级Transformer模型比较效率分析”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”企业需要高效、轻量级的多领域NLP模型<br>Enterprise Need for Efficient, Lightweight Multi-Domain NLP Models”]\n        Method[”比较DistilBERT, MiniLM, ALBERT<br>Compare DistilBERT, MiniLM, ALBERT<br>使用准确性与效率指标<br>Use Accuracy & Efficiency Metrics”]\n        Results[”ALBERT: 高准确度<br>ALBERT: High Accuracy<br>MiniLM: 高推理速度<br>MiniLM: High Inference Speed<br>DistilBERT: 最均衡<br>DistilBERT: Most Balanced”]"
    },
    {
      "title": "Toward Better Temporal Structures for Geopolitical Events Forecasting",
      "authors": "Kian Ahrabian, Eric Boxer, Jay Pujara",
      "institution": "University of Southern California, Information Sciences Institute",
      "link": "https://arxiv.org/pdf/2601.00430",
      "code": "https://github.com/usc-isi-i2/htkgh-polecat",
      "tags": [
        "knowledge graph completion",
        "temporal knowledge graph",
        "hyper-relational knowledge graph",
        "event forecasting",
        "large language model",
        "geopolitical events"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527a7641dfaef2c6e41eb0a5e3a09b206d0632bf03dce43022e1edf046380617_w640_q70.webp",
      "contributions": "1. Proposes a new data structure, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs), to efficiently represent complex temporal facts involving more than two primary entities. 2. Introduces the `htkgh-polecat` dataset, built on the POLECAT database, to benchmark forecasting tasks on this new structure. 3. Benchmarks and analyzes the performance of popular Large Language Models (LLMs) on the relation prediction task within this complex forecasting scenario.",
      "summary": "This paper addresses the limitation of existing temporal knowledge graphs in representing complex geopolitical events with multiple primary entities by proposing a new structure called HTKGHs. The authors formalize HTKGHs, create a corresponding dataset, and benchmark LLMs on forecasting tasks. The results provide insights into LLMs' capabilities for complex temporal reasoning and forecasting.",
      "mindmap": "graph TB\n        A[Toward Better Temporal Structures for Geopolitical Events Forecasting] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[HTKGs缺乏对多主体复杂事实的表达能力/HTKGs lack expressive power for complex multi-entity facts]\n        C --> C1[提出HTKGHs结构以支持多主体事件/Propose HTKGHs to support multi-entity events]\n        C --> C2[基于POLECAT构建htkgh-polecat数据集/Build htkgh-polecat dataset based on POLECAT]\n        C --> C3[在关系预测任务上评估主流LLMs/Benchmark popular LLMs on relation prediction]\n        D --> D1[形式化HTKGHs并展示其向后兼容性/Formalize HTKGHs and demonstrate backward compatibility]\n        D --> D2[提供LLMs在复杂预测场景中的能力分析/Provide analysis of LLM capabilities in complex forecasting scenarios]"
    },
    {
      "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
      "authors": "Hyunjun Kim",
      "institution": "KAIST",
      "link": "https://arxiv.org/pdf/2601.00454",
      "code": null,
      "tags": [
        "llm inference",
        "guardrail models",
        "multi-turn compression",
        "efficiency optimization",
        "safety screening",
        "token reduction"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad9caa971d784e8a994209f34a3b4e255812b43b2fa90a13bb0487b6e71e1395_w640_q70.webp",
      "contributions": "1. Proposes Defensive M2S, a training paradigm that fine-tunes guardrail models on compressed multi-turn conversations instead of full histories, 2. Provides formal complexity analysis showing training cost reduction from O(n²) to O(n) and empirical token reduction of 93×, 3. Demonstrates effectiveness across multiple guardrail models and compression templates, achieving high attack detection recall with 94.6% inference token reduction.",
      "summary": "The paper addresses the high computational cost of processing full multi-turn conversations for LLM safety guardrails by proposing Defensive M2S, which trains guardrail models on compressed single-turn versions. This method significantly reduces training and inference tokens while maintaining high attack detection performance, enabling scalable safety screening.",
      "mindmap": "graph TB\n        Root[”Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations”] --> Problem[”核心问题/Problem: High computational cost of processing full multi-turn conversations for guardrail models”]\n        Root --> Method[”主要方法/Method: Fine-tune guardrail models on M2S (Multi-turn to Single-turn) compressed conversations”]\n        Root --> Results[”关键结果/Results: 93× training token reduction, 94.6% inference token reduction, 93.8% attack detection recall”]"
    },
    {
      "title": "Noise-Aware Named Entity Recognition for Historical VET Documents",
      "authors": "Alexander M. Esser, Jens Dörpinghaus",
      "institution": "Federal Institute for Vocational Education and Training (BIBB), University of Koblenz",
      "link": "https://arxiv.org/pdf/2601.00488",
      "code": null,
      "tags": [
        "named entity recognition",
        "Noise-Aware Training (NAT)",
        "OCR Noise",
        "Data Augmentation",
        "Transfer Learning",
        "Multi-stage Fine-tuning"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb3e9604f5f72e56feeecdc196004299094bc184a404fe77959f2a61d9e4da2_w640_q70.webp",
      "contributions": "1. Proposes a robust NER approach for historical VET documents using Noise-Aware Training with synthetic OCR errors. 2. Systematically compares three complementary training strategies (noisy, clean, and artificial data). 3. Demonstrates that domain-specific and noise-aware fine-tuning significantly improves robustness and accuracy under noisy conditions.",
      "summary": "This paper tackles Named Entity Recognition in noisy, historical Vocational Education and Training documents by proposing a method using Noise-Aware Training with synthetic OCR errors, transfer learning, and multi-stage fine-tuning. The approach, one of the first to recognize multiple entity types in this domain, shows that domain-specific and noise-aware fine-tuning substantially increases model robustness and accuracy. The method is applied to German but is designed to be transferable to other languages.",
      "mindmap": "graph TB\n        Root[Noise-Aware NER for Historical VET Documents] --> Problem(核心问题/Problem: NER in noisy historical VET documents)\n        Root --> Method(主要方法/Method: Noise-Aware Training with synthetic OCR errors, transfer learning, multi-stage fine-tuning)\n        Root --> Results(关键结果/Results: Increased robustness and accuracy under noisy conditions)"
    },
    {
      "title": "Rule-Based Approaches to Atomic Sentence Extraction",
      "authors": "Lineesha Kamana, Akshita Ananda Subramanian, Mehuli Ghosh, Suman Saha",
      "institution": "The Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2601.00506",
      "code": null,
      "tags": [
        "text simplification",
        "atomic sentence extraction",
        "dependency parsing",
        "rule-based system",
        "syntactic complexity",
        "split-and-rephrase"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8cb4da5bb35bca5de1c3a306fbe787db397d7073bbab8260c7962fc3e300d28_w640_q70.webp",
      "contributions": "1. Conducted a principled analysis to identify specific complex sentence structures (e.g., relative clauses, appositions) that cause difficulties for rule-based atomic sentence extraction. 2. Implemented and evaluated a transparent, dependency-based rule extraction system using spaCy on the WikiSplit dataset. 3. Provided quantitative performance benchmarks (ROUGE and BERTScore) and qualitative insights into the limitations of rule-based methods for syntactic decomposition.",
      "summary": "This paper analyzes the performance of a rule-based system for decomposing complex sentences into simpler atomic units. The method uses dependency parsing rules in spaCy and is evaluated on the WikiSplit dataset. The results show the approach is reasonably accurate but struggles with syntactically complex structures like relative clauses and coordinated predicates.",
      "mindmap": "graph TB\n        Root(”Rule-Based Approaches to Atomic Sentence Extraction”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”复杂句子影响下游任务性能/Complex sentences hinder downstream tasks”)\n        Problem --> P2(”现有方法缺乏可解释性/Existing methods lack interpretability”)\n        Method --> M1(”基于依赖关系的规则提取/Dependency-based rule extraction”)\n        Method --> M2(”使用spaCy和WikiSplit数据集/Using spaCy & WikiSplit dataset”)\n        Results --> R1(”取得中等至高ROUGE/BERT分数/Achieved moderate-high ROUGE/BERTScore”)\n        Results --> R2(”特定句法结构具有挑战性/Specific syntactic structures are challenging”)"
    },
    {
      "title": "A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies",
      "authors": "Jetlir Duraj, Ishita Khan, Kilian Merkelbach, Mehran Elyasi",
      "institution": "eBay Inc.",
      "link": "https://arxiv.org/pdf/2601.00510",
      "code": null,
      "tags": [
        "information retrieval",
        "query categorization",
        "chain-of-thought",
        "e-commerce taxonomy",
        "semantic scoring",
        "large language models"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2b32fe45914991e8c8d0dc90af7415aa3ed8d8e8ce666ea46e11465b8fa68fd_w640_q70.webp",
      "contributions": "1. Proposes a novel Chain-of-Thought (CoT) paradigm for semantic query categorization that combines tree-search with LLM semantic scoring. 2. Demonstrates that the CoT approach outperforms embedding-based benchmarks and can detect problems within hierarchical taxonomies. 3. Introduces scalable LLM-based approaches for query categorization that are suitable for millions of queries.",
      "summary": "This paper addresses the problem of categorizing user search queries into leaf categories of an e-commerce taxonomy to improve search relevance. The authors propose a novel Chain-of-Thought approach that navigates the taxonomy tree using LLM semantic scoring. Their method outperforms embedding-based benchmarks and is shown to scale for real-world applications.",
      "mindmap": "graph TB\n        Root[”A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies<br>基于思维链的电商分类语义查询方法”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Search query categorization in e-commerce taxonomies<br>电商分类中的搜索查询分类”] --> P1[”目标/Goal<br>Select relevant leaf categories for a user query<br>为用户查询选择相关叶子类目”]\n        Method[”主要方法/Method<br>Chain-of-Thought (CoT) paradigm<br>思维链范式”] --> M1[”技术/Technique<br>Combines tree-search with LLM semantic scoring<br>结合树搜索与LLM语义评分”]\n        Results[”关键结果/Results<br>Evaluation Findings<br>评估结果”] --> R1[”性能/Performance<br>Outperforms embedding-based benchmarks<br>优于基于嵌入的基准方法”]\n        Results --> R2[”可扩展性/Scalability<br>Proposes scalable LLM-based approaches<br>提出可扩展的基于LLM的方法”]"
    },
    {
      "title": "The Illusion of Insight in Reasoning Models",
      "authors": "Liv G. d'Aliberti, Manoel Horta Ribeiro",
      "institution": "Princeton University",
      "link": "https://arxiv.org/pdf/2601.00514",
      "code": null,
      "tags": [
        "reasoning models",
        "reasoning shifts",
        "self-correction",
        "model uncertainty",
        "intrinsic vs extrinsic",
        "chain-of-thought"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3c00fcaa573a1b7a6558433ae1348cc7cefec26d36175047b45df1cd217f2516_w640_q70.webp",
      "contributions": "1. Conducted a large-scale empirical study analyzing over 1 million reasoning traces across multiple models, domains, and training stages to investigate the nature and impact of mid-reasoning \"Aha!\" moments. 2. Found that such intrinsic reasoning shifts are rare, do not increase with training, and seldom improve accuracy, challenging the perception that they represent genuine model insight or self-correction. 3. Demonstrated that while intrinsic shifts are not beneficial, artificially triggering extrinsic shifts under conditions of high model uncertainty (high entropy) can reliably improve accuracy, showing these shifts are symptoms of unstable inference.",
      "summary": "This paper investigates whether reasoning models experience genuine \"Aha!\" moments of intrinsic self-correction during inference. Through a large-scale analysis of reasoning traces across multiple models and training checkpoints, the authors find that such mid-reasoning shifts are rare and ineffective, but that artificially triggering shifts when the model is uncertain can improve accuracy. The main conclusion is that these shifts are symptoms of unstable inference behavior, not a mechanism for intrinsic self-improvement.",
      "mindmap": "graph TB\n        A[The Illusion of Insight in Reasoning Models] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[推理模型是否有真正的“顿悟”时刻？/Do reasoning models have genuine ”Aha!” moments?]\n        C --> C1[大规模分析推理轨迹与训练检查点/Large-scale analysis of reasoning traces & training checkpoints]\n        D --> D1[内在转变罕见且无效/Intrinsic shifts are rare and ineffective]\n        D --> D2[外在触发在高熵下可提升准确率/Extrinsic triggering under high entropy improves accuracy]\n        D --> D3[转变是不稳定推理的症状/Shifts are symptoms of unstable inference]"
    },
    {
      "title": "Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends",
      "authors": "Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He",
      "institution": "University of Pittsburgh, Google Cloud AI Research",
      "link": "https://arxiv.org/pdf/2601.00536",
      "code": null,
      "tags": [
        "question answering",
        "multi-hop QA",
        "retrieval-reasoning process",
        "execution procedure",
        "RAG",
        "agentic systems"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64e851b90551e53952c84444631a7585a225572c38194cb181b360edfef5c8e1_w640_q70.webp",
      "contributions": "1. Proposes a novel four-axis design framework for analyzing the execution procedure of multi-hop QA systems, focusing on plan, index, control, and stopping criteria. 2. Systematically maps and compares representative multi-hop QA systems using this framework, making implicit procedural choices explicit and comparable. 3. Synthesizes empirical trends and trade-offs from standard benchmarks and identifies key open challenges for future retrieval-reasoning agents.",
      "summary": "This survey paper addresses the lack of explicit analysis of the procedural interaction between retrieval and reasoning in multi-hop question answering. It introduces a four-axis framework to systematically compare different systems based on their execution plan, index structure, control strategies, and stopping criteria. The main conclusion is that making these procedural choices explicit reveals recurring trade-offs and highlights open challenges like structure-aware planning and robust stopping.",
      "mindmap": "graph TB\n        Root[”检索-推理过程与四轴框架 / Retrieval–Reasoning Processes & Four-Axis Framework”] --> Problem[”核心问题：检索与推理的隐式耦合 / Problem: Implicit Coupling of Retrieval & Reasoning”]\n        Root --> Method[”主要方法：四轴设计框架 / Method: Four-Axis Design Framework”]\n        Root --> Results[”关键结果：趋势综合与开放挑战 / Results: Trend Synthesis & Open Challenges”]\n        Problem --> P1[”过程不透明，难以比较 / Process Opacity, Hard to Compare”]\n        Method --> M1[”轴A：总体执行计划 / Axis A: Overall Execution Plan”]\n        Method --> M2[”轴B：索引结构 / Axis B: Index Structure”]\n        Method --> M3[”轴C：下一步控制 / Axis C: Next-Step Control”]\n        Method --> M4[”轴D：停止/继续标准 / Axis D: Stop/Continue Criteria”]\n        Results --> R1[”映射系统，综合趋势 / Map Systems, Synthesize Trends”]\n        Results --> R2[”识别权衡与挑战 / Identify Trade-offs & Challenges”]"
    },
    {
      "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models",
      "authors": "Chung-Wei Victor Yuan",
      "institution": "YVIC Research Lab",
      "link": "https://arxiv.org/pdf/2601.00543",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "embedding consistency regulation",
        "manifold structure",
        "semantic anchors",
        "compact language models",
        "on-device AI"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3184228efac0008fa39e8578d4daa8e597c9d20bf57f0662c9080c6c11607590_w640_q70.webp",
      "contributions": "1. Proposes Embedding Consistency Regulation (ECR), a new framework that uses semantic anchors derived from teacher embeddings to preserve the underlying manifold structure in compact models. 2. Demonstrates that ECR stabilizes training and preserves semantic structure across tasks and languages without relying on matching logits or internal features, and adds minimal inference overhead. 3. Shows ECR is compatible with but independent of distillation, enabling better task alignment and deployment under strict efficiency or privacy constraints.",
      "summary": "The paper addresses the problem of semantic drift and loss of manifold structure in compact language models. It proposes the Embedding Consistency Regulation (ECR) framework, which uses offline-computed semantic anchors to guide the compact model's geometry. Experiments show ECR produces more compact, task-aligned representations, making low-capacity models more stable and easier to deploy.",
      "mindmap": "graph TB\n        Root[ECR: Manifold-Guided Semantic Cues for Compact Language Models] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[嵌入空间结构崩塌/Embedding Space Collapse]\n        Problem --> P2[语义漂移/Semantic Drift]\n        Method --> M1[提取语义锚点/Derive Semantic Anchors]\n        Method --> M2[保持几何一致性/Maintain Geometric Consistency]\n        Results --> R1[稳定训练/Stabilized Training]\n        Results --> R2[保留语义结构/Preserved Semantic Structure]\n        Results --> R3[紧凑任务对齐空间/Compact Task-Aligned Space]"
    },
    {
      "title": "A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR",
      "authors": "Yuang Zheng, Yuxiang Mei, Dongxing Xu, Jie Chen, Yanhua Long",
      "institution": "Shanghai Normal University, Unisound AI Technology Co., Ltd.",
      "link": "https://arxiv.org/pdf/2601.00557",
      "code": null,
      "tags": [
        "on-device ai",
        "LoRA",
        "Mixture-of-Experts",
        "CTC",
        "multilingual ASR",
        "language-agnostic"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbd2404a5aa3ab85ddcd83e20182b5cedff2831876ded928574f65b33a573d7d_w640_q70.webp",
      "contributions": "1. Proposes a novel Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model for lightweight multilingual ASR. 2. Introduces an LID-posterior-driven LoRA routing mechanism that enables true language-agnostic, single-pass decoding without prior language identity information. 3. Demonstrates that the proposed method achieves competitive performance with state-of-the-art two-stage inference methods while significantly improving decoding efficiency for low-resource applications.",
      "summary": "This paper addresses the high computational cost and latency of large multilingual ASR models like Whisper for edge deployment. It proposes a lightweight, language-agnostic system using a Hierarchical LoRA-MoE architecture with CTC, which enables efficient single-pass decoding without needing language labels. Experiments show the method achieves competitive performance with more complex two-stage systems, improving efficiency for low-resource multilingual ASR.",
      "mindmap": "graph TB\n        Root[”A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR”] --> Problem[”核心问题/Problem: Large multilingual ASR models (e.g., Whisper) are computationally expensive and have high latency, limiting edge device deployment.”]\n        Root --> Method[”主要方法/Method: Proposes a lightweight HLoRA framework with hierarchical LoRA-MoE design and LID-posterior-driven routing for language-agnostic, single-pass CTC decoding.”]\n        Root --> Results[”关键结果/Results: Achieves competitive performance with SOTA two-stage methods on MSR-86K and MLC-SLM 2025 datasets, improving decoding efficiency.”]"
    },
    {
      "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
      "authors": "Ishir Garg, Neel Kolhe, Xuandong Zhao, Dawn Song",
      "institution": "University of California, Berkeley",
      "link": "https://arxiv.org/pdf/2601.00575",
      "code": "https://ishirgarg.github.io/infosynth_web/",
      "tags": [
        "llm inference",
        "benchmark synthesis",
        "information theory",
        "genetic algorithm",
        "code generation",
        "KL-divergence"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/704b01a43cbeec6830597e2e4ae9ad64cd96a4119782924bce3b012150cf43af_w640_q70.webp",
      "contributions": "1. A novel framework (InfoSynth) for automatically generating and evaluating reasoning benchmarks using information-theoretic principles. 2. Proposes KL-divergence and entropy-based metrics to quantify benchmark novelty and diversity without costly model evaluations. 3. An end-to-end pipeline that synthesizes robust Python coding problems using genetic algorithms and iterative code feedback, achieving 97% accuracy in generating test cases and solutions.",
      "summary": "This paper introduces InfoSynth, a framework that automatically generates novel and diverse reasoning benchmarks for LLMs using information-theoretic guidance and genetic algorithms. It successfully creates Python coding problems with high accuracy and provides control over novelty and difficulty. The method offers a scalable, self-verifying pipeline for benchmark creation.",
      "mindmap": "graph TB\n        A[InfoSynth: Information-Guided Benchmark Synthesis for LLMs] --> B[核心问题/Problem: Manual benchmark creation is expensive; existing benchmarks contaminate LLM training data.]\n        A --> C[主要方法/Method: Framework using information theory (KL-divergence/entropy) and genetic algorithms to synthesize Python problems.]\n        A --> D[关键结果/Results: 97% generation accuracy; benchmarks are more novel/diverse than seeds; controllable novelty/difficulty.]"
    },
    {
      "title": "CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns",
      "authors": "Zhenhong Zhou, Shilinlu Yan, Chuanpu Liu, Qiankun Li, Kun Wang, Zhigang Zeng",
      "institution": "Nanyang Technological University, Beijing University of Posts and Telecommunications, Huazhong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2601.00588",
      "code": "https://huggingface.co/datasets/Yaesir06/CSSBench",
      "tags": [
        "safety evaluation",
        "adversarial patterns",
        "safety benchmark",
        "lightweight llms",
        "chinese-specific",
        "over-refusal"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c813f73ed4fa6559522ae2a06c96e70fccff1e58bac3263d589d9e1ba5dde9bb_w640_q70.webp",
      "contributions": "1. Introduces CSSBench, a novel benchmark for evaluating LLM safety against Chinese-specific adversarial patterns like homophones and pinyin. 2. Covers six real-world Chinese safety domains and measures both attack success and over-refusal rates. 3. Demonstrates that Chinese-specific adversarial patterns pose a critical challenge for lightweight LLMs, revealing a safety evaluation gap.",
      "summary": "The paper identifies a gap in safety evaluation for lightweight LLMs against Chinese-specific adversarial patterns. To address this, it introduces CSSBench, a benchmark covering six domains and specific attack patterns. The evaluation shows these patterns are a significant challenge for lightweight models, highlighting the need for targeted safety measures.",
      "mindmap": "graph TB\n        Root[CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Safety evaluation gap for Chinese-specific adversarial patterns in lightweight LLMs]\n        Method[主要方法/Method: Introduce CSSBench benchmark with six domains and specific adversarial patterns]\n        Results[关键结果/Results: Chinese-specific adversarial patterns are a critical challenge for lightweight LLMs]"
    },
    {
      "title": "Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence",
      "authors": "Sumanth Balaji, Piyush Mishra, Aashraya Sachdeva, Suraj Agrawal",
      "institution": "Observe.AI",
      "link": "https://arxiv.org/pdf/2601.00596",
      "code": null,
      "tags": [
        "agent system",
        "JourneyBench",
        "policy adherence",
        "User Journey Coverage Score",
        "Dynamic-Prompt Agent",
        "Standard Operating Procedures"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2447eea55afc6d1b5ede006dd4130334fc9f6a1079fd81fa73d75aa31c86b038_w640_q70.webp",
      "contributions": "1. Introduces JourneyBench, a novel benchmark for evaluating customer support LLM agents on their ability to adhere to complex, multi-step business policies and workflows. 2. Proposes the User Journey Coverage Score, a new metric to quantitatively measure an agent's policy adherence across diverse and realistic support scenarios generated via graph representations. 3. Demonstrates that a Dynamic-Prompt Agent (DPA) design, which explicitly models policy control, significantly improves adherence, enabling smaller models to outperform larger ones on this critical operational metric.",
      "summary": "The paper addresses the challenge of evaluating LLM agents for business policy adherence in customer support, beyond simple task completion. It introduces the JourneyBench benchmark and a Dynamic-Prompt Agent design. The results show that structured policy orchestration (DPA) is crucial for adherence, allowing smaller models to achieve strong performance.",
      "mindmap": "graph TB\n        A[Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Existing benchmarks overlook policy adherence in customer support]\n        C[主要方法/Method: JourneyBench benchmark & Dynamic-Prompt Agent (DPA)]\n        D[关键结果/Results: DPA boosts adherence, smaller models can outperform larger ones]"
    },
    {
      "title": "Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs",
      "authors": "Nils Rautenberg, Sven Schippkus",
      "institution": "Deutsche Aktuarvereinigung e.V., University of Hamburg",
      "link": "https://arxiv.org/pdf/2601.00641",
      "code": null,
      "tags": [
        "llm inference",
        "hallucination reduction",
        "probabilistic guarantees",
        "LLM-as-a-judge",
        "ensemble voting",
        "model-agnostic framework"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/165c6ebcc0bde9cc29a648eab707a9a04b4f10c177d4c9ed7fc6ceee24692cf9_w640_q70.webp",
      "contributions": "1. Formalizes a framework for fixed-input tasks and proves that independent prompt repetition exponentially reduces the probability of all outputs being incorrect. 2. Incorporates an LLM-as-a-judge to identify correct answers and provides theoretical error bounds based on the judge's performance. 3. Introduces majority voting over independent judge calls to strengthen imperfect judges, achieving ensemble-level error rates that decrease exponentially with the number of votes.",
      "summary": "This paper addresses the problem of contextual hallucinations in LLMs for deterministic workflows. It proposes a model-agnostic framework that combines independent prompt repetition with an LLM-as-a-judge and majority voting to exponentially reduce hallucination probabilities. The method provides explicit probabilistic guarantees without modifying the underlying model.",
      "mindmap": "graph TB\n        A[Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs产生上下文幻觉/LLMs produce contextual hallucinations]\n        B --> B2[确定性工作流中问题严重/Severe in deterministic workflows]\n        C --> C1[独立重复提示/Independent prompt repetition]\n        C --> C2[LLM作为评判者/LLM-as-a-judge]\n        C --> C3[多数投票集成/Majority vote ensemble]\n        D --> D1[错误率指数下降/Error rates decrease exponentially]\n        D --> D2[提供概率保证/Provides probabilistic guarantees]\n        D --> D3[轻量级且模型无关/Lightweight and model-agnostic]"
    },
    {
      "title": "Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations",
      "authors": "QiWei Meng",
      "institution": "Xi’an Jiaotong University",
      "link": "https://arxiv.org/pdf/2601.00647",
      "code": null,
      "tags": [
        "protein language models",
        "Direct Preference Optimization",
        "thermodynamic stability",
        "structural hallucinations",
        "physics-informed alignment",
        "energy landscape"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d5257f1ab79de5e0438ace6dd83c270bc2812ff4355d0389349edec8caeb93_w640_q70.webp",
      "contributions": "1. Proposes Physio-DPO, a physics-informed alignment framework that grounds protein language models in thermodynamic stability. 2. Introduces a magnitude-aware objective that scales optimization updates based on the physical energy gap between native and perturbed structures. 3. Demonstrates a hard negative mining strategy to generate linguistically plausible but structurally unsound decoys for more robust training.",
      "summary": "The paper addresses the problem of structural hallucinations in protein language models, where generated sequences are linguistically likely but thermodynamically unstable. It proposes Physio-DPO, a physics-informed alignment method that incorporates the continuous energy landscape into the optimization process. Experiments show that Physio-DPO outperforms existing baselines, significantly reducing structural errors and increasing the foldability of generated proteins.",
      "mindmap": "graph TB\n        Root(”Physio-DPO: Aligning LLMs with the Protein Energy Landscape”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”结构幻觉/Structural Hallucinations”)\n        Problem --> P2(”能量景观不连续/Discontinuous Energy Landscape”)\n        Method --> M1(”Physio-DPO框架/Physio-DPO Framework”)\n        Method --> M2(”幅度感知目标/Magnitude-Aware Objective”)\n        Method --> M3(”硬负样本挖掘/Hard Negative Mining”)\n        Results --> R1(”降低RMSD至1.28Å/Reduce RMSD to 1.28Å”)\n        Results --> R2(”可折叠性提升至92.8%/Increase Foldability to 92.8%”)\n        Results --> R3(”恢复生物物理相互作用/Recover Biophysical Interactions”)"
    },
    {
      "title": "Fast-weight Product Key Memory",
      "authors": "Tianyu Zhao, Llion Jones",
      "institution": "Sakana AI",
      "link": "https://arxiv.org/pdf/2601.00671",
      "code": null,
      "tags": [
        "long-context language modeling",
        "product key memory",
        "fast weights",
        "episodic memory",
        "gradient descent",
        "long-context"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8dc5e7437ccdc396cc0c89f8bda772596a4ad71d82cd906f8eae81c22b107608_w640_q70.webp",
      "contributions": "1. Proposes Fast-weight Product Key Memory (FwPKM), a novel architecture that transforms static Product Key Memory into a dynamic, fast-weight episodic memory., 2. Introduces a mechanism for dynamic parameter updates at both training and inference time via local chunk-level gradient descent, enabling rapid memorization and retrieval., 3. Demonstrates that FwPKM effectively complements semantic memory, significantly reduces perplexity on long-context data, and shows strong generalization to contexts much longer than those seen during training.",
      "summary": "The paper addresses the trade-off between storage capacity and computational efficiency in sequence modeling layers. It proposes Fast-weight Product Key Memory (FwPKM), a dynamic architecture that updates parameters via local gradient descent to act as an episodic memory. Experiments show FwPKM reduces perplexity on long-context datasets and generalizes well to sequences much longer than those in training.",
      "mindmap": "graph TB\n        A[Fast-weight Product Key Memory] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[存储容量与计算效率的权衡/Trade-off: Storage Capacity vs. Computational Efficiency]\n        C --> C1[动态快速权重产品键记忆/Dynamic Fast-weight Product Key Memory (FwPKM)]\n        C --> C2[本地块级梯度下降更新/Local Chunk-level Gradient Descent Updates]\n        D --> D1[长上下文困惑度降低/Long-context Perplexity Reduction]\n        D --> D2[从4K到128K的泛化/Generalization from 4K to 128K Tokens]"
    },
    {
      "title": "Sigmoid Head for Quality Estimation under Language Ambiguity",
      "authors": "Tu Anh Dinh, Jan Niehues",
      "institution": "Karlsruhe Institute of Technology",
      "link": "https://arxiv.org/pdf/2601.00680",
      "code": "https://github.com/TuAnh23/sigmoid-confidence",
      "tags": [
        "quality estimation",
        "quality estimation",
        "language ambiguity",
        "sigmoid activation",
        "negative sampling",
        "underconfidence"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26806e2d4eb9b20c12526f3d561ebccfd1dfbbd43c035727d581173184fcf3b3_w640_q70.webp",
      "contributions": "1. Identifies architectural and training setup issues in LMs (softmax, single-reference training) that cause ambiguity-induced underconfidence, making model probability a poor quality signal. 2. Proposes the Sigmoid Head, an extra unembedding layer with sigmoid activation, to model output tokens independently for better quality estimation. 3. Introduces a heuristic for negative sampling during training to avoid selecting potentially correct alternative tokens, improving training without needing human-annotated quality data.",
      "summary": "The paper addresses the problem that language model probability is unreliable for quality estimation due to natural language ambiguity. It proposes a Sigmoid Head, an additional module with sigmoid activation and a specialized negative sampling heuristic, trained on standard LM data. This method provides a better quality signal than the original softmax head and is more robust in out-of-domain settings without requiring annotated quality data.",
      "mindmap": "graph TB\n        A[Sigmoid Head for Quality Estimation under Language Ambiguity] --> B[核心问题/Problem: LM概率不可靠/LM probability unreliable due to language ambiguity]\n        A --> C[主要方法/Method: Sigmoid Head (Sigmoid激活 & 负采样启发式)/Sigmoid Head (Sigmoid activation & negative sampling heuristic)]\n        A --> D[关键结果/Results: 更好的质量信号 & 对域外更鲁棒/Better quality signal & more robust out-of-domain]"
    },
    {
      "title": "TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications",
      "authors": "Mohamed Trabelsi, Huseyin Uzunalioglu",
      "institution": "Nokia Bell Labs",
      "link": "https://arxiv.org/pdf/2601.00691",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "ticket troubleshooting",
        "retrieval-augmented generation",
        "instruction-tuning",
        "domain-specific ranking",
        "large language models"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/151b34be88d61fea64f35727dce1917583308996e63a1822af1e6ad8863fe6a8_w640_q70.webp",
      "contributions": "1. Proposes TeleDoCTR, an end-to-end system for telecom ticket troubleshooting integrating classification, retrieval, and generation tasks. 2. Introduces a domain-specific and contextual approach combining ranking and generative models tailored for the telecom domain. 3. Demonstrates superior performance over state-of-the-art methods on a real-world telecom dataset, enhancing troubleshooting accuracy and efficiency.",
      "summary": "The paper proposes TeleDoCTR, a system that automates telecom ticket troubleshooting by integrating domain-specific models for ticket classification, retrieval of similar historical tickets, and generation of fault analysis reports. It is evaluated on a real-world telecom dataset and shows improved performance over existing methods, making the troubleshooting process more accurate and efficient.",
      "mindmap": "graph TB\n        A[TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications] --> B[核心问题/Problem: Telecom ticket troubleshooting is complex, time-consuming, and human-intensive.]\n        A --> C[主要方法/Method: Integrates domain-specific ranking and generative models for classification, retrieval, and generation tasks.]\n        A --> D[关键结果/Results: Superior performance over SOTA methods on real-world data, enhancing accuracy and efficiency.]"
    },
    {
      "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
      "authors": "Alphaeus Dmonte, Roland Oruche, Tharindu Ranasinghe, Marcos Zampieri, Prasad Calyam",
      "institution": "George Mason University, University of Missouri, Lancaster University",
      "link": "https://arxiv.org/pdf/2601.00736",
      "code": null,
      "tags": [
        "span identification",
        "large language models",
        "in-context learning",
        "chain of thought",
        "aspect-based sentiment analysis",
        "subjective spans"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c33271e2c603477b20beb01a7eafd35b6ae5eb8b9dfab2b53139ccf619c75074_w640_q70.webp",
      "contributions": "1. Evaluates LLMs on subjective span identification tasks (sentiment analysis, offensive language identification, claim verification), an underexplored area compared to explicit tasks like NER. 2. Explores multiple LLM strategies including instruction tuning, in-context learning, and chain of thought for span identification. 3. Provides empirical results indicating that underlying textual relationships aid LLMs in identifying precise text spans.",
      "summary": "This paper evaluates the performance of Large Language Models on subjective text span identification tasks, such as sentiment analysis and offensive language detection, using strategies like in-context learning and chain of thought. The study finds that LLMs benefit from underlying relationships within the text to identify accurate spans, addressing a gap in current research focused on explicit span tasks.",
      "mindmap": "graph TB\n        A[Exploring LLMs on Subjective Span Identification<br/>探索大型语言模型在主观跨度识别任务中的表现] --> B(核心问题/Problem: Subjective span identification with LLMs is underexplored compared to explicit tasks like NER.<br/>与NER等显式任务相比，LLM在主观跨度识别方面的研究不足。)\n        A --> C(主要方法/Method: Evaluate LLMs using instruction tuning, in-context learning, and chain of thought on three tasks.<br/>使用指令调优、上下文学习和思维链在三个任务上评估LLMs。)\n        A --> D(关键结果/Results: Underlying text relationships aid LLMs in identifying precise spans.<br/>文本中的潜在关系有助于LLMs识别精确的跨度。)"
    },
    {
      "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
      "authors": "Thomas Katraouras, Dimitrios Rafailidis",
      "institution": "University of Thessaly",
      "link": "https://arxiv.org/pdf/2601.00756",
      "code": "https://github.com/Thomkat/MBC",
      "tags": [
        "memory & caching",
        "memory bank compression",
        "codebook optimization",
        "online resetting mechanism",
        "Key-Value Low-Rank Adaptation (KV-LoRA)"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4b16d7a0bdd1f6fa0e71da5c21a92629d07342bdc56905e10612ee07549b8dd_w640_q70.webp",
      "contributions": "1. Proposed MBC, a model that compresses the memory bank for continual learning via a codebook optimization strategy. 2. Introduced an online resetting mechanism to prevent codebook collapse and ensure stable learning. 3. Employed Key-Value Low-Rank Adaptation (KV-LoRA) in the LLM's attention layers to efficiently utilize the compressed memory representations.",
      "summary": "This paper addresses the problem of memory bank growth in continual learning for LLMs by proposing MBC, which compresses the memory bank using codebook optimization and an online resetting mechanism. The method integrates KV-LoRA for efficient adaptation and achieves a 99.7% reduction in memory bank size while maintaining high accuracy on question-answering tasks.",
      "mindmap": "graph TB\n        A[Memory Bank Compression for Continual Adaptation of Large Language Models] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs知识过时 / LLMs' knowledge becomes outdated]\n        B --> B2[持续学习中的灾难性遗忘 / Catastrophic forgetting in continual learning]\n        B --> B3[内存库无限增长 / Memory bank grows unbounded]\n        C --> C1[内存库压缩 / Memory bank compression]\n        C --> C2[码本优化策略 / Codebook optimization strategy]\n        C --> C3[在线重置机制 / Online resetting mechanism]\n        C --> C4[KV-LoRA / Key-Value Low-Rank Adaptation]\n        D --> D1[内存库大小减少至0.3% / Memory bank size reduced to 0.3%]\n        D --> D2[保持高精度 / Maintains high retention accuracy]"
    },
    {
      "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
      "authors": "Valentin Noël",
      "institution": "Devoteam",
      "link": "https://arxiv.org/pdf/2601.00791",
      "code": null,
      "tags": [
        "reasoning verification",
        "spectral graph analysis",
        "attention patterns",
        "Fiedler value",
        "high-frequency energy ratio",
        "sliding window attention"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b1f2999ddcf2e05565198a4f51efee7b71422414b78038f132537978df2e4e9_w640_q70.webp",
      "contributions": "1. Introduced a training-free method for detecting valid mathematical reasoning in LLMs by performing spectral analysis on attention matrices treated as dynamic graphs. 2. Identified four interpretable spectral diagnostics (Fiedler value, HFER, smoothness, entropy) that show significant statistical differences between valid and invalid proofs across multiple model families. 3. Discovered that the method captures logical coherence rather than formal verifier acceptance and revealed an architectural dependency where different attention mechanisms (e.g., Sliding Window Attention) shift the primary discriminative spectral feature.",
      "summary": "The paper proposes a training-free method to detect valid mathematical reasoning in large language models by analyzing the spectral properties of attention patterns. The method identifies key spectral signatures that effectively distinguish between valid and invalid proofs with high accuracy. The findings show the method captures logical coherence and its effectiveness depends on the model's attention architecture.",
      "mindmap": "graph TB\n        Root(”Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning”) --> Problem(”核心问题/Problem: Detecting valid mathematical reasoning in LLMs”)\n        Root --> Method(”主要方法/Method: Spectral analysis of attention patterns as dynamic graphs”)\n        Root --> Results(”关键结果/Results: High classification accuracy, detects logical coherence, architectural dependency identified”)"
    },
    {
      "title": "Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries",
      "authors": "Jonathan Simkin, Lovedeep Gondara, Zeeshan Rizvi, Gregory Doyle, Jeff Dowden, Dan Bond, Desmond Martin, Raymond Ng",
      "institution": "University of British Columbia, Newfoundland & Labrador Health Services",
      "link": "https://arxiv.org/pdf/2601.00787",
      "code": null,
      "tags": [
        "domain adaptation",
        "transformer models",
        "ensemble learning",
        "fine-tuning",
        "cancer registry",
        "pathology reports"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/20cadf176e434cff234318c2ab86906269a79285d0f4a0350b5eb92ee86ab3b0_w640_q70.webp",
      "contributions": "1. Conducted the first cross-provincial evaluation of adapting domain-specific transformer models (BCCRTron and GatorTron) for cancer surveillance, demonstrating their ability to generalize across jurisdictions with different reporting conventions. 2. Proposed a conservative OR-ensemble method that combines complementary text representation pipelines (synoptic-focused and diagnosis-focused), substantially reducing missed cancers and improving error coverage. 3. Implemented a privacy-preserving workflow where only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model.",
      "summary": "This study addresses the challenge of applying NLP models across different cancer registries with varying reporting formats. It fine-tunes two transformer models (BCCRTron and GatorTron) on data from a new jurisdiction and combines them using an OR-ensemble. The results show that this approach maintains high performance and significantly reduces missed cancer cases, demonstrating effective cross-jurisdictional adaptation with a privacy-preserving workflow.",
      "mindmap": "graph TB\n        A[Adapting NLP Models Across Jurisdictions] --> B[核心问题/Problem: Manual abstraction in cancer registries is slow; NLP models struggle to generalize across jurisdictions]\n        A --> C[主要方法/Method: Fine-tune BCCRTron & GatorTron; Use OR-ensemble on complementary input pipelines]\n        A --> D[关键结果/Results: High recall (0.99); Reduced missed cancers; Privacy-preserving weight sharing]"
    },
    {
      "title": "Learning Speech Representations with Variational Predictive Coding",
      "authors": "Sung-Lin Yeh, Peter Bell, Hao Tang",
      "institution": "University of Edinburgh",
      "link": "https://arxiv.org/pdf/2601.00100",
      "code": null,
      "tags": [
        "self-supervised speech representation learning",
        "predictive coding",
        "variational inference",
        "HuBERT",
        "speech representations",
        "self-supervised learning"
      ],
      "day": "2026-01-05",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba27d9f18d7b89a2b06727180b097e2e420315e2b2adae6f4d672735f9e63346_w640_q70.webp",
      "contributions": "1. Proposes a variational predictive coding framework as the underlying principle behind the HuBERT objective, providing a theoretical foundation. 2. Derives two simple modifications to the HuBERT objective from this framework, leading to immediate performance improvements. 3. Demonstrates the framework's generality by showing its connections to other objectives like APC, CPC, wav2vec, and BEST-RQ.",
      "summary": "This paper identifies the lack of a theoretical principle as a bottleneck for improving the HuBERT objective for speech representation learning. It proposes a variational predictive coding framework as this underlying principle, which not only explains HuBERT but also leads to simple, effective modifications that improve performance. The improved pre-training yields significant gains on downstream tasks like phone classification and automatic speech recognition, validating the importance of the predictive coding interpretation.",
      "mindmap": "graph TB\n        A[Learning Speech Representations with Variational Predictive Coding] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[缺乏理论原则阻碍HuBERT发展/Lack of principle stalls HuBERT development]\n        C --> C1[提出变分预测编码框架/Propose variational predictive coding framework]\n        C --> C2[推导HuBERT为特例并改进/Derive HuBERT as special case and improve it]\n        D --> D1[预训练显著改进/Pre-training brings significant improvements]\n        D --> D2[连接多种其他目标/Connects to various other objectives]"
    },
    {
      "title": "Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration",
      "authors": "Zahra Abedi, Richard M.K. van Dijk, Gijs Wijnholds, Tessa Verhoef",
      "institution": "Leiden University",
      "link": "https://arxiv.org/pdf/2512.23710",
      "code": null,
      "tags": [
        "information extraction",
        "OCR",
        "LLM",
        "record linkage",
        "digital humanities",
        "data harmonization"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d89795562de4ae19fec35c7e5d2890c5c08f327549b9a9887347777baf5b0c5_w640_q70.webp",
      "contributions": "1. Designed an automated pipeline integrating OCR, LLM-based interpretation, and database linking for historical document digitization. 2. Demonstrated that generative AI can partially correct low OCR performance during structured data extraction. 3. Developed a record linkage algorithm achieving high accuracy (94% on annotated data, 81% on OCR-derived data) for integrating extracted data with existing databases.",
      "summary": "This paper proposes an automated pipeline using OCR and generative AI to extract and structure biographical data from historical documents, then links this data to existing database records. The method achieved high OCR accuracy and demonstrated that LLMs can correct some OCR errors, with the final linkage algorithm performing well. The study contributes a practical tool for digital humanities research by addressing challenges like layout variability and terminology differences.",
      "mindmap": "graph TB\n        Root[Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem<br>How to automate the integration of historical document data with existing databases?]\n        Method[主要方法/Method<br>OCR + LLM-based interpretation + Database linkage]\n        Results[关键结果/Results<br>High OCR accuracy, LLM corrects OCR errors, Effective record linkage]"
    },
    {
      "title": "HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate",
      "authors": "Shenzhe Zhu",
      "institution": "University of Toronto",
      "link": "https://arxiv.org/pdf/2512.23717",
      "code": null,
      "tags": [
        "safety alignment",
        "multi-agent debate",
        "stealthy harmful queries",
        "safety training data",
        "query transformation",
        "adversarial prompting"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9bfc9b669283c35e277363d47c398576a9ae941e3c10bc7ea3296632fc0184f_w640_q70.webp",
      "contributions": "1. Introduces HarmTransform, the first multi-agent debate framework designed for transforming harmful queries into stealthier forms while preserving intent. 2. Designs a comprehensive evaluation protocol and provides an in-depth analysis of debate dynamics, identifying its benefits and drawbacks. 3. Demonstrates the framework's potential for generating data to enhance LLM safety alignment, highlighting both the promise and limitations of the approach.",
      "summary": "The paper introduces HarmTransform, a multi-agent debate framework that iteratively refines harmful queries into stealthier forms to expose gaps in LLM safety mechanisms. Experiments show it outperforms baselines in generating effective transformations. The analysis reveals that while debate improves stealth, it can also introduce topic shifts and complexity, highlighting its dual nature for safety data generation.",
      "mindmap": "graph TB\n        A[HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLM安全机制忽略隐蔽有害查询/LLM safety overlooks covert harmful queries]\n        C --> C1[多智能体辩论迭代优化查询/Multi-agent debate iteratively refines queries]\n        D --> D1[辩论提升隐蔽性但可能引入复杂性/Debate improves stealth but may add complexity]"
    },
    {
      "title": "STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability",
      "authors": "Guanghui Wang, Jinze Yu, Xing Zhang, Dayuan Jiang, Yin Song, Tomal Deb, Xuefeng Liu, Peiyang He",
      "institution": "AWS Generative AI Innovation Center, AWS WWSO SA Field Initiatives",
      "link": "https://arxiv.org/pdf/2512.23712",
      "code": null,
      "tags": [
        "evaluation & metrics",
        "STED",
        "consistency scoring",
        "structured output",
        "JSON",
        "semantic equivalence"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2a404e6faa604b1e48c4c20d60e0b88bb889cfe94b29f60a234af8a87b5d05b_w640_q70.webp",
      "contributions": "1. Proposes STED (Semantic Tree Edit Distance), a novel similarity metric for comparing JSON outputs that balances semantic flexibility with structural strictness. 2. Introduces a comprehensive consistency scoring framework that aggregates multiple STED measurements across repeated generations to quantify LLM output reliability. 3. Provides a systematic benchmark of six LLMs using the proposed framework, revealing significant variations in model consistency and enabling practical applications like model selection and prompt refinement.",
      "summary": "This paper addresses the challenge of evaluating the consistency of LLM-generated structured outputs (like JSON). It proposes a framework combining a new similarity metric (STED) and a consistency scoring method. The framework effectively benchmarks LLMs, showing Claude-3.7-Sonnet to be highly consistent, and provides tools for improving reliability in production systems.",
      "mindmap": "graph TB\n        A[STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: LLM生成结构化输出的可靠性评估/Evaluating Reliability of LLM Structured Outputs]\n        C[主要方法/Method: STED度量与一致性评分框架/STED Metric & Consistency Scoring Framework]\n        D[关键结果/Results: STED优于现有指标，Claude-3.7-Sonnet一致性最佳/STED Outperforms Baselines, Claude-3.7-Sonnet Most Consistent]"
    },
    {
      "title": "PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual Agents",
      "authors": "Jahidul Islam, Md Ataullha, Saiful Azad",
      "institution": "Green University of Bangladesh",
      "link": "https://arxiv.org/pdf/2512.23713",
      "code": "github.com/jahidulzaid/PyBanglaCodeActAgent",
      "tags": [
        "code generation",
        "agent-based framework",
        "iterative self-correction",
        "multilingual LLM",
        "Thought-Code-Observation loop",
        "zero-shot"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6751bddc58c50ee4806ff6af3cccc66715b2e854b912a102cbc99edee59d5c86_w640_q70.webp",
      "contributions": "1. Introduced BanglaCodeAct, an agent-based framework for Bangla-to-Python code generation. 2. Leveraged a multilingual LLM in a zero-shot setting without task-specific fine-tuning. 3. Demonstrated the effectiveness of an iterative Thought-Code-Observation loop for dynamic code testing and refinement.",
      "summary": "This paper addresses the challenge of generating Python code from Bangla natural language instructions, a low-resource language. It proposes BanglaCodeAct, an agent-based framework that uses a multilingual LLM within an iterative Thought-Code-Observation loop for zero-shot code generation and self-correction. The method, tested with Qwen3-8B, achieves high accuracy on the mHumanEval dataset, setting a new benchmark for Bangla NL-to-Code.",
      "mindmap": "graph TB\n        A[PyBangla at BLP-2025 Task 2<br>论文标题/Paper Title] --> B[LLMs excel in English but not low-resource languages<br>核心问题/Problem]\n        A --> C[Introduce BanglaCodeAct with multi-agent & iterative self-correction<br>主要方法/Method]\n        A --> D[Qwen3-8B achieves 94.0% (dev) and 71.6% (test) pass@1<br>关键结果/Results]"
    },
    {
      "title": "CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations",
      "authors": "Paulo Cavalin, Cassia Sanctos, Marcelo Grave, Claudio Pinhanez, Yago Primerano",
      "institution": "IBM Research Brazil",
      "link": "https://arxiv.org/pdf/2512.23711",
      "code": null,
      "tags": [
        "llm evaluation",
        "consistency-accuracy relation",
        "minimum-consistency accuracy",
        "consistency-oriented robustness estimate",
        "controlled input variations",
        "multiple-choice benchmarks"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3e09f948d2d6005bc5c42feadc24f0b59efdcf1128e65b7ae2e76dbdcde54307_w640_q70.webp",
      "contributions": "1. Introduces the CAT framework for evaluating and visualizing the interplay between accuracy and response consistency in LLMs under controlled input variations. 2. Proposes Consistency-Accuracy Relation (CAR) curves and the Minimum-Consistency Accuracy (MCA) metric to visualize the trade-off. 3. Defines the Consistency-Oriented Robustness Estimate (CORE) index as a global metric to quantify the accuracy-consistency trade-off from the CAR curve.",
      "summary": "The paper introduces CAT, a framework for analyzing how the accuracy of Large Language Models relates to their response consistency when inputs are varied. The core of the method involves CAR curves and the CORE index to visualize and quantify this trade-off. The framework is demonstrated on multiple-choice benchmarks and is designed to be extensible to other evaluation formats.",
      "mindmap": "graph TB\n        A[CAT: 一致性-准确性分析框架] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有评估忽视一致性-准确性关系/Current evaluations overlook accuracy-consistency interplay]\n        C --> C1[提出CAR曲线与CORE指数/Proposes CAR curves & CORE index]\n        D --> D1[框架在多项选择基准上验证/Framework validated on MC benchmarks]\n        D --> D2[可扩展至开放式评估/Extensible to open-ended evaluations]"
    },
    {
      "title": "Noise-Driven Persona Formation in Reflexive Neural Language Generation",
      "authors": "Toshiyuki Shigemura",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.23716",
      "code": null,
      "tags": [
        "language generation",
        "noise-driven generation",
        "persona emergence",
        "reflexive generation",
        "entropy dynamics",
        "long-range coherence"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/494e2777d739d8f177739adabd9937930e8c3fbdf053845eab849c66fabde7bb_w640_q70.webp",
      "contributions": "1. Introduces the Luca-Noise Reflex Protocol (LN-RP), a novel computational framework for studying persona emergence in LLMs. 2. Demonstrates that injecting stochastic noise seeds can induce nonlinear phase transitions and stable persona modes with distinct entropy signatures. 3. Provides a reproducible method for analyzing reflexive generation dynamics and long-range linguistic coherence.",
      "summary": "This paper proposes the Luca-Noise Reflex Protocol (LN-RP) to study how personas emerge in large language models by injecting noise into the initial generation state. The results show that this method reliably induces phase transitions, leading to three distinct, stable persona modes with measurable entropy differences. The protocol offers a reproducible framework for investigating reflexive and emergent linguistic behaviors in LLMs.",
      "mindmap": "graph TB\n        A[Noise-Driven Persona Formation<br>噪声驱动的人格形成] --> B(核心问题/Problem: How does linguistic identity/persona emerge from minimal initialization in LLMs?<br>LLM中语言身份/人格如何从最小初始化条件中涌现？)\n        A --> C(主要方法/Method: Luca-Noise Reflex Protocol (LN-RP)<br>注入随机噪声种子，分析152个生成周期<br>Inject stochastic noise seeds, analyze 152 generation cycles)\n        A --> D(关键结果/Results: Three stable persona modes with distinct entropy signatures<br>噪声可诱导相变，人格保持稳定<br>Three stable persona modes, noise-induced phase transitions, consistent persona retention)"
    },
    {
      "title": "PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents",
      "authors": "Tingwei Xie, Tianyi Zhou, Yonghong Song",
      "institution": "School of Software Engineering, Xi’an Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.23714",
      "code": "https://github.com/KevinYuLei/PharmaShip",
      "tags": [
        "document understanding",
        "entity-centric evaluation",
        "reading-order regularization",
        "pharmaceutical documents"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c53ca47e769ad4299f2003c7674f1a5bc588ef0b3b2bf086373539b4f80b21bb_w640_q70.webp",
      "contributions": "1. Introduces PharmaShip, a new real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test models under noisy OCR and heterogeneous templates. 2. Proposes an entity-centric evaluation protocol for three complementary tasks (SER, RE, ROP) to minimize architectural confounds. 3. Demonstrates through benchmarking that injecting reading-order-oriented regularization improves model robustness and highlights sequence-aware constraints as a transferable bias for structure modeling.",
      "summary": "The paper introduces PharmaShip, a benchmark dataset for Chinese pharmaceutical shipping documents to test document understanding models. It benchmarks several layout-aware models and finds that combining pixel and geometric information with reading-order regularization yields the most robust performance. The work establishes a controlled benchmark for safety-critical document understanding and highlights the importance of sequence-aware modeling.",
      "mindmap": "graph TB\n        A[PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[缺乏针对医药运输文档的公开数据集 / Lack of public dataset for pharmaceutical shipping docs]\n        C --> C1[提出实体中心化评估协议 / Propose entity-centric evaluation protocol]\n        C --> C2[基准测试像素感知与几何感知模型 / Benchmark pixel-aware & geometry-aware models]\n        C --> C3[注入阅读顺序正则化 / Inject reading-order regularization]\n        D --> D1[像素与几何提供互补偏差 / Pixels & geometry provide complementary biases]\n        D --> D2[阅读顺序正则化提升鲁棒性 / Reading-order regularization improves robustness]\n        D --> D3[建立可控可复现的基准 / Establishes controlled, reproducible benchmark]"
    },
    {
      "title": "When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection",
      "authors": "Anwar Alajmi, Gabriele Pergola",
      "institution": "University of Warwick, Public Authority of Applied Education and Training (Kuwait)",
      "link": "https://arxiv.org/pdf/2512.23732",
      "code": null,
      "tags": [
        "hate speech detection",
        "collaborative expert judgment",
        "confidence-based routing",
        "class-balanced focal loss"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/32d2baab37215bb5672da3307e81be99d99c0b9c3a16715fc3d5d0430dfd9273_w640_q70.webp",
      "contributions": "1. A two-stage framework combining targeted training for noisy, imbalanced data with selective, reasoning-based inference for ambiguous cases. 2. A novel Collaborative Expert Judgment (CEJ) module that uses multiple LLM personas in a structured debate to resolve uncertain predictions. 3. A dynamic routing mechanism at inference time that directly classifies high-confidence cases and escalates low-confidence ones to the CEJ module.",
      "summary": "The paper addresses the challenges of detecting subtle, context-dependent sexist content online, which suffers from data noise, class imbalance, and conceptual ambiguity. It proposes a framework that uses robust training techniques and a novel inference module where uncertain cases are routed to a multi-persona LLM debate for judgment. This approach achieves state-of-the-art performance on benchmark sexism detection tasks.",
      "mindmap": "graph TB\n        A[When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Subtle, ambiguous sexist content<br>Data noise, imbalance, ambiguity]\n        C[主要方法/Method<br>Two-stage framework<br>Robust training & CEJ routing]\n        D[关键结果/Results<br>SOTA on benchmarks<br>+2.72% F1 on EXIST]"
    },
    {
      "title": "Emergent World Beliefs: Exploring Transformers in Stochastic Games",
      "authors": "Adam Kamel, Tanish Rastogi, Michael Ma, Kailash Ranganathan, Kevin Zhu",
      "institution": "University of Waterloo, University of California, Berkeley, Algoverse AI Research",
      "link": "https://arxiv.org/pdf/2512.23722",
      "code": null,
      "tags": [
        "mechanistic interpretability",
        "world models",
        "POMDP",
        "nonlinear probes",
        "belief states",
        "poker"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0b3ac8d82fbf09f5fe3d9ad22b6223250d752757d0f69d998f59ef234c0fd9e_w640_q70.webp",
      "contributions": "1. Extends the study of emergent world models in LLMs from perfect-information games to the incomplete-information domain using poker as a canonical POMDP. 2. Demonstrates that a GPT-style model pretrained on poker hand histories learns both deterministic (e.g., hand ranks) and stochastic (e.g., equity) features without explicit instruction. 3. Shows that the model's internal representations, decoded primarily via nonlinear probes, correlate with theoretical belief states, suggesting it learns its own representation of a stochastic environment.",
      "summary": "This paper investigates whether transformer-based LLMs develop internal world models in stochastic, partially observable environments. The authors pretrain a GPT model on poker hand history data and probe its activations, finding it learns key game features and belief states. The results suggest LLMs can form their own representations of uncertainty in complex decision-making tasks.",
      "mindmap": "graph TB\n        A[Emergent World Beliefs: Exploring Transformers in Stochastic Games] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs能否在不完全信息博弈中形成世界模型？/Can LLMs form world models in games of incomplete information?]\n        C --> C1[在扑克手牌历史数据上预训练GPT模型/Pretrain GPT on Poker Hand History data]\n        C --> C2[使用非线性探针分析内部激活/Probe internal activations with nonlinear probes]\n        D --> D1[模型学习了确定性与随机性特征/Model learns deterministic and stochastic features]\n        D --> D2[内部表征与理论信念状态相关/Internal representations correlate with theoretical belief states]"
    },
    {
      "title": "Break Out the Silverware -- Semantic Understanding of Stored Household Items",
      "authors": "Michaela Levi-Richter, Reuth Mirsky, Oren Glickman",
      "institution": "Bar Ilan University, Tufts University",
      "link": "https://arxiv.org/pdf/2512.23739",
      "code": null,
      "tags": [
        "commonsense reasoning",
        "benchmark dataset",
        "vision-language model",
        "hybrid agent pipeline",
        "storage location prediction",
        "semantic understanding"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02333560037f17a9692645550b2d71e1239038dba5b036552b34388848b00f1f_w640_q70.webp",
      "contributions": "1. Introduces the Stored Household Item Challenge, a new benchmark for evaluating service robots' commonsense reasoning about predicting the storage location of non-visible household items. 2. Provides two associated datasets: a real-world evaluation set and a larger development set with annotated storage polygons. 3. Proposes NOAM (Non-visible Object Allocation Model), a hybrid agent pipeline that combines structured scene understanding with LLM inference to tackle the challenge, demonstrating improved accuracy approaching human performance.",
      "summary": "This paper addresses the challenge of enabling domestic robots to infer where non-visible household items are stored. It proposes a new benchmark task and datasets, and introduces NOAM, a hybrid vision-language agent that converts visual scenes into text for an LLM to predict storage locations. Evaluations show NOAM significantly outperforms baseline models and approaches human-level performance in this commonsense reasoning task.",
      "mindmap": "graph TB\n        Root[Break Out the Silverware: Semantic Understanding of Stored Household Items] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Robots lack commonsense reasoning to find stored, non-visible household items.]\n        Method[主要方法/Method: Proposes NOAM, a hybrid pipeline combining scene understanding and LLM inference.]\n        Results[关键结果/Results: NOAM approaches human-level accuracy on the new storage prediction benchmark.]"
    },
    {
      "title": "State-of-the-art Small Language Coder Model: Mify-Coder",
      "authors": "Abhinav Parmar, Abhisek Panigrahi, Abhishek Kumar Dwivedi, Abhishek Bhattacharya, Adarsh Ramachandra, Aditya Choudhary, Aditya Garg, Aditya Raj, Alankrit Bhatt, Alpesh Yadav, Anant Vishnu, Ananthu Pillai, Ankush Kumar, Aryan Patnaik, Aswatha Narayanan S, Avanish Raj Singh, Bhavya Shree Gadda, Brijesh Pankajbhai Kachhadiya, Buggala Jahnavi, Chidurala Nithin Krishna, Chintan Shah, Chunduru Akshaya, Debarshi Banerjee, Debrup Dey, Deepa R., Deepika B G, Faiz ur Rahman, Gagan Gayari, Gudhi Jagadeesh Kumar Naidu, Gursimar Singh, Harshal Tyagi, Harshini K, James Mani Vathalloor, Jayarama Nettar, Jayashree Gajjam, Joe Walter Sugil George, Kamalakara Sri Krishna Tadepalli, Kamalkumar Rathinasamy, Karan Chaurasia, Karthikeyan S, Kashish Arora, Kaushal Desai, Khushboo Buwade, Kiran Manjrekar, Malikireddy Venkata Sai Likhitha, Manjunath A, Mitali Mahavir Bedmutha, Mohammed Rafee Tarafdar, Nikhil Tiwari, Nikitha K Gigi, Pavan Ravikumar, Pendyala Swarnanjali, Piyush Anand, Prakash Chandrasekar, Prasanna Bhalchandra Gawade, Prasanth Sivan, Preeti Khurana, Priyanshi Babbar, Rajab Ali Mondal, Rajesh Kumar Vissapragada, Rajeshwari Ganesan, Rajeswari Koppisetti, Ramjee R., Ramkumar Thiruppathisamy, Rani G. S., S Reka, Samarth Gupta, Sandeep Reddy Kothakota, Sarathy K, Sathyanarayana Sampath Kumar, Saurabh Kumar, Shashank Khasare, Shenbaga Devi Venkatesh Kumar, Shiva Rama Krishna Parvatham, Shoeb Shaikh, Shrishanmathi A, Shubham Pathak, Sree Samhita Koppaka, Sreenivasa Raghavan K S, Sreeram Venkatasubramanian, Suprabha Desai Bojja, Swetha R, Syed Ahmed, Chinmai Harshitha Thota, Tushar Yadav, Veeravelly Kusumitha, V V S S Prasanth Patnaik, Vidya Sri Sesetti, Vijayakeerthi K, Vikram Raj Bakshi, Vinay K K, Vinoth Kumar Loganathan, Vipin Tiwari, Vivek Kumar Shrivastav, V Venkata Sri Datta Charan, Wasim Akhtar Khan",
      "institution": "Infosys AI Research",
      "link": "https://arxiv.org/pdf/2512.23747",
      "code": null,
      "tags": [
        "llm training",
        "compute-optimal training",
        "CPT-SFT",
        "synthetic data generation",
        "model quantization",
        "quality filtering"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13c8af9d7668bbc4ac7ae9ad0ed379feb93f982a5fecdc8491169bd4d6c33d30_w640_q70.webp",
      "contributions": "1. Introduced Mify-Coder, a 2.5B-parameter code model trained with a compute-optimal strategy on 4.2T tokens, demonstrating that compact models can match frontier-grade performance. 2. Developed a training pipeline combining high-quality curated data with agentically generated synthetic data, refined using enterprise-grade evaluations and LLM-based quality filtering for high data density. 3. Showed that disciplined exploration of training objectives and data mixtures within a single continuous trajectory enables competitive accuracy, efficiency, and safety, with quantized variants enabling deployment on standard hardware.",
      "summary": "The paper addresses the high computational cost of large code models by proposing Mify-Coder, a compact 2.5B-parameter model trained using a compute-optimal strategy that integrates curated and synthetic data with quality filtering. It demonstrates that this approach allows a small model to achieve performance comparable to much larger models on coding benchmarks while maintaining safety and enabling efficient desktop deployment.",
      "mindmap": "graph TB\n        A[Mify-Coder] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[大模型成本高/High cost of large code models]\n        C --> C1[计算最优训练/Compute-optimal training]\n        C --> C2[合成数据生成/Synthetic data generation]\n        C --> C3[质量过滤/Quality filtering]\n        D --> D1[性能可比/Competitive performance]\n        D --> D2[高效部署/Efficient deployment]"
    },
    {
      "title": "Entropy-Aware Speculative Decoding Toward Improved LLM Reasoning",
      "authors": "Tiancheng Su, Meicong Zhang, Guoxiu He",
      "institution": "East China Normal University",
      "link": "https://arxiv.org/pdf/2512.23765",
      "code": null,
      "tags": [
        "llm inference",
        "speculative decoding",
        "entropy penalty",
        "training-free",
        "reasoning acceleration",
        "draft-model verification"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/326c86ae03e220a7cb48737a0a6fe149bd4384ccc08f3113a051c3548bc2d30e_w640_q70.webp",
      "contributions": "1. Proposes Entropy-Aware Speculative Decoding (EASD), a training-free method that introduces a dynamic entropy-based penalty to reject low-confidence draft tokens, 2. Enables speculative decoding to potentially surpass the target model's performance by incorporating draft-model verification and preventing error propagation, 3. Demonstrates that EASD maintains efficiency comparable to standard speculative decoding while improving reasoning accuracy across multiple benchmarks.",
      "summary": "This paper addresses the limitation of speculative decoding being constrained by the target model's performance. It proposes Entropy-Aware Speculative Decoding (EASD), which uses entropy to quantify uncertainty and reject low-confidence draft tokens. Experiments show EASD outperforms existing methods and can surpass the target LLM's performance while maintaining comparable efficiency.",
      "mindmap": "graph TB\n        Root[Entropy-Aware Speculative Decoding] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[SD性能受限于目标模型/SD performance capped by target model]\n        Method[主要方法/Method] --> M1[引入动态熵惩罚/Introduce dynamic entropy penalty]\n        Method --> M2[基于不确定性拒绝低置信度令牌/Reject low-confidence tokens based on uncertainty]\n        Method --> M3[目标模型重采样/Target model re-sampling]\n        Results[关键结果/Results] --> R1[超越现有SD方法/Outperforms existing SD methods]\n        Results --> R2[常超越目标LLM本身/Often surpasses target LLM]\n        Results --> R3[效率与SD相当/Efficiency comparable to SD]"
    },
    {
      "title": "MiMo-Audio: Audio Language Models are Few-Shot Learners",
      "authors": "Xiaomi LLM-Core Team, Dong Zhang, Gang Wang, Jinlong Xue, Kai Fang, Liang Zhao, Rui Ma, Shuhuai Ren, Shuo Liu, Tao Guo, Weiji Zhuang, Xin Zhang, Xingchen Song, Yihan Yan, Yongzhe He, Cici, Bowen Shen, Chengxuan Zhu, Chong Ma, Chun Chen, Heyu Chen, Jiawei Li, Lei Li, Menghang Zhu, Peidian Li, Qiying Wang, Sirui Deng, Weimin Xiong, Wenshan Huang, Wenyu Yang, Yilin Jiang, Yixin Yang, Yuanyuan Tian, Yue Ma, Yue Yu, Zihan Zhang, Zihao Yue, Bangjun Xiao, Bingquan Xia, Bofei Gao, Bowen Ye, Can Cai, Chang Liu, Chenhong He, Chunan Li, Dawei Zhu, Duo Zhang, Fengyuan Shi, Guoan Wang, Hailin Zhang, Hanglong Lv, Hanyu Li, Hao Tian, Heng Qu, Hongshen Xu, Houbin Zhang, Huaqiu Liu, Jiangshan Duo, Jianguang Zuo, Jianyu Wei, Jiebao Xiao, Jinhao Dong, Jun Shi, Junhao Hu, Kainan Bao, Kang Zhou, Linghao Zhang, Meng Chen, Nuo Chen, Peng Zhang, Qianli Chen, Qiantong Wang, Rang Li, Shaohui Liu, Shengfan Wang, Shicheng Li, Shihua Yu, Shijie Cao, Shimao Chen, Shuhao Gu, Weikun Wang, Wenhan Ma, Xiangwei Deng, Xing Yong, Xing Zhang, Xu Wang, Yifan Song, Yihao Zhao, Yingbo Zhao, Yizhao Gao, Yu Cheng, Yu Tu, Yudong Wang, Zhaojun Huang, Zhengju Tang, Zhenru Lin, Zhichao Song, Zhipeng Xu, Zhixian Zheng, Zihan Jiang",
      "institution": "Xiaomi",
      "link": "https://arxiv.org/pdf/2512.23808",
      "code": "https://github.com/XiaomiMiMo/MiMo-Audio",
      "tags": [
        "multi-modal training",
        "audio language model",
        "few-shot learning",
        "instruction tuning",
        "scaling pretraining",
        "speech continuation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4efb9eb77f0c6bfe175c709a98be8909fd963e33e44e830db2cd023ecf616b62_w640_q70.webp",
      "contributions": "1. Scaled audio language model pretraining to over 100 million hours, demonstrating emergent few-shot learning capabilities across diverse audio tasks. 2. Introduced a systematic evaluation framework and showed that the base model achieves SOTA performance among open-source models on speech intelligence and audio understanding benchmarks, with generalization to unseen tasks. 3. Developed an instruction-tuned variant with a curated corpus and thinking mechanisms, achieving open-source SOTA on multiple audio understanding, spoken dialogue, and TTS benchmarks, rivaling closed-source models.",
      "summary": "The paper proposes MiMo-Audio, a large-scale audio language model pretrained on over 100 million hours of data, which demonstrates emergent few-shot learning capabilities for various audio tasks without task-specific fine-tuning. The instruction-tuned variant further achieves state-of-the-art performance on multiple benchmarks, showing strong generalization in audio understanding and generation.",
      "mindmap": "graph TB\n        Root[”MiMo-Audio: Audio Language Models are Few-Shot Learners”] --> Problem[”核心问题/Problem: Existing audio models require task-specific fine-tuning, lacking human-like generalization.”]\n        Root --> Method[”主要方法/Method: Scale next-token prediction pretraining on 100M+ hours of audio; Use instruction-tuning with thinking mechanisms.”]\n        Root --> Results[”关键结果/Results: Emergent few-shot learning; SOTA open-source performance; Generalizes to unseen tasks like voice conversion.”]"
    },
    {
      "title": "StressRoBERTa: Cross-Condition Transfer Learning from Depression, Anxiety, and PTSD to Stress Detection",
      "authors": "Amal Alqahtani, Efsun Kayi, Mona Diab",
      "institution": "The George Washington University, King Saud University, Johns Hopkins University Applied Physics Laboratory, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.23813",
      "code": null,
      "tags": [
        "mental health text classification",
        "transfer learning",
        "continual training",
        "RoBERTa",
        "cross-condition",
        "stress detection"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a57224b94917298d3e6f94d2c9255d2d054abcab5c5051070f928ff8ddd8bc6b_w640_q70.webp",
      "contributions": "1. Proposes StressRoBERTa, a cross-condition transfer learning approach for detecting self-reported chronic stress in tweets. 2. Demonstrates that continual training on a focused set of clinically related mental health conditions (depression, anxiety, PTSD) improves stress detection over general models. 3. Shows effective transfer from clinical mental health contexts to situational stress discussions via evaluation on the Dreaddit dataset.",
      "summary": "This paper introduces StressRoBERTa, a method that continually trains a RoBERTa model on social media text from users with depression, anxiety, and PTSD before fine-tuning it for chronic stress detection. The approach outperforms the previous best system on the SMM4H 2022 shared task by 3% F1-score, showing that focused cross-condition transfer learning from related disorders provides stronger representations for stress detection.",
      "mindmap": "graph TB\n        A[StressRoBERTa: Cross-Condition Transfer Learning] --> B(核心问题/Problem: 检测社交媒体中的慢性压力/Detect chronic stress on social media)\n        A --> C(主要方法/Method: 从相关心理健康状况进行跨条件迁移学习/Cross-condition transfer learning from related mental health conditions)\n        A --> D(关键结果/Results: 性能超越最佳共享任务系统，F1分数达82%/Outperforms best shared task system with 82% F1)"
    },
    {
      "title": "Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation",
      "authors": "Kaustubh Dhole",
      "institution": "Emory University",
      "link": "https://arxiv.org/pdf/2512.23837",
      "code": null,
      "tags": [
        "adversarial robustness",
        "mechanistic interpretability",
        "attention layers",
        "adversarial examples",
        "LLM evaluation",
        "token substitution"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85f39e8eb9d1e9534ca2c7e95f4e08380c10c2d3b58ec0a3a896f0767b75fdd8_w640_q70.webp",
      "contributions": "1. Proposes a novel adversarial example generation method that exploits intermediate attention layer token distributions, contrasting with prompt-based or gradient-based attacks. 2. Introduces two specific attention-based generation techniques: attention-based token substitution and attention-based conditional generation. 3. Empirically demonstrates that such adversarial examples can degrade performance on an evaluation task (argument quality assessment) while maintaining semantic similarity, highlighting both the promise and limitations (e.g., grammatical degradation) of the approach.",
      "summary": "This paper proposes a new method to generate adversarial examples by extracting token predictions from the intermediate attention layers of LLMs, leveraging their iterative refinement property. The approach is used to stress-test LLM-based evaluation pipelines, showing it can cause performance drops on an argument quality task while preserving semantics, though grammatical issues can arise. The findings illustrate the potential and current constraints of using internal model representations for adversarial testing.",
      "mindmap": "graph TB\n        Root[Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Can intermediate attention layers be used to generate adversarial examples for LLM evaluation?]\n        Method[主要方法/Method: Leverage attention-layer token distributions for token substitution/conditional generation]\n        Results[关键结果/Results: Adversarial examples cause performance drop but may introduce grammatical issues]"
    },
    {
      "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms",
      "authors": "Himel Ghosh",
      "institution": "Technical University of Munich, Sapienza University of Rome",
      "link": "https://arxiv.org/pdf/2512.23835",
      "code": null,
      "tags": [
        "bias detection",
        "SHAP",
        "transformer",
        "interpretability",
        "false positives",
        "domain adaptation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cbe893cabdbb4c14e3f0b2a14a91011067d2ee0ee4225b0a232eb5591a1b743_w640_q70.webp",
      "contributions": "1. Conducted a comparative interpretability study of two transformer-based bias detection models using SHAP to analyze their decision mechanisms. 2. Revealed that a standard bias detector model exhibits a misalignment between attribution strength and prediction correctness, leading to systematic over-flagging, while a domain-adapted model produces significantly fewer false positives. 3. Demonstrated that model errors, particularly false positives, arise from discourse-level ambiguity rather than explicit bias cues, highlighting distinct linguistic failure modes.",
      "summary": "This paper compares how two transformer models detect bias in news text using SHAP-based explanations. It finds that while both models focus on similar evaluative language, a domain-adapted model integrates these signals more reliably, producing far fewer false positives than a standard bias detector. The study concludes that interpretability analysis is crucial for evaluating bias detection systems and that architectural choices critically impact their reliability for journalistic use.",
      "mindmap": "graph TB\n        A[Explaining News Bias Detection] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[How do bias detection models make decisions?]\n        C --> C1[Comparative SHAP analysis of two transformer models]\n        D --> D1[Domain-adapted model has better alignment and fewer false positives]\n        D --> D2[False positives driven by discourse ambiguity]"
    },
    {
      "title": "Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?",
      "authors": "Dingmin Wang, Ji Ma, Shankar Kumar",
      "institution": "Google Research, University of Oxford",
      "link": "https://arxiv.org/pdf/2512.23836",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "adaptive prompting",
        "context window",
        "open-domain QA",
        "retrieval-augmented generation",
        "LLM ignorance"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58d02669f63e2ba5d0171fc84f89e87cc22d595344fc20e61769b4288b009ef5_w640_q70.webp",
      "contributions": "1. Proposes an adaptive prompting strategy for RAG that splits retrieved information into smaller chunks for sequential processing, mitigating the noise from irrelevant information in long contexts. 2. Demonstrates experimentally that this strategy matches or outperforms standard prompting on open-domain QA datasets while using fewer tokens. 3. Identifies and analyzes a key failure mode where LLMs generate incorrect answers instead of declining when information is insufficient, highlighting a critical area for future research.",
      "summary": "This paper addresses the problem that longer context windows in Retrieval-Augmented Generation (RAG) introduce irrelevant information, degrading LLM performance. It proposes an adaptive prompting strategy that processes retrieved text in smaller, sequential chunks, achieving comparable accuracy with lower token usage. The study concludes that a major source of error is the LLM's tendency to generate wrong answers rather than admit ignorance, pointing to the need for improved refusal capabilities.",
      "mindmap": "graph TB\n        A[Retrieval Augmented Question Answering: When Should LLMs Admit Ignorance?] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[长上下文引入无关信息，降低LLM性能/Long contexts introduce irrelevant info, degrading LLM performance]\n        C --> C1[自适应提示策略：分块顺序处理/Adaptive prompting: sequential chunk processing]\n        D --> D1[性能相当，使用更少token/Matches performance, uses fewer tokens]\n        D --> D2[LLM常生成错误答案而非拒绝/LLM often generates wrong answers instead of declining]"
    },
    {
      "title": "Integrating Domain Knowledge for Financial QA: A Multi-Retriever RAG Approach with LLMs",
      "authors": "Yukun Zhang, Stefan Elbl Droguett, Samyak Jain",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.23848",
      "code": null,
      "tags": [
        "question answering",
        "Retrieval-Augmented Generation (RAG)",
        "SecBERT",
        "financial numerical reasoning",
        "multi-retriever",
        "few-shot learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de021f75daa09442db831a9d2d84064bf5381a47f4cb0fc792e2cfd3bfbd128b_w640_q70.webp",
      "contributions": "1. Proposed a multi-retriever RAG system that retrieves both external domain knowledge (e.g., financial definitions) and internal question contexts to improve financial QA. 2. Demonstrated that domain-specific training with the SecBERT encoder significantly boosts performance, allowing a neural symbolic model to surpass a strong baseline. 3. Showed that a prompt-based LLM generator achieves state-of-the-art performance with a &gt;7% improvement, highlighting the enhanced few-shot numerical reasoning of latest LLMs and the trade-off between hallucination and external knowledge gains.",
      "summary": "This paper addresses errors in financial numerical QA by proposing a multi-retriever RAG system that retrieves external financial knowledge and internal context. The best model, using domain-specific training and a prompt-based LLM, achieves state-of-the-art results, though still below human expert performance, and reveals a trade-off between hallucination and knowledge gains.",
      "mindmap": "graph TB\n        A[Integrating Domain Knowledge for Financial QA<br>金融QA领域知识集成] --> B[Problem: Errors in financial numerical QA due to lack of domain knowledge<br>核心问题: 金融数值QA因缺乏领域知识出错]\n        A --> C[Method: Multi-retriever RAG system with external/internal retrieval<br>主要方法: 多检索器RAG系统]\n        A --> D[Results: SOTA performance, domain-specific training effective, trade-off analyzed<br>关键结果: SOTA性能, 领域训练有效, 权衡分析]"
    },
    {
      "title": "The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models",
      "authors": "Rahul Baxi",
      "institution": "Independent Researcher (affiliation inferred from email domain: alumni.cmu.edu, Carnegie Mellon University)",
      "link": "https://arxiv.org/pdf/2512.23850",
      "code": null,
      "tags": [
        "language model evaluation",
        "epistemic robustness",
        "semantic compression",
        "adversarial fabrication",
        "two-system cognitive model",
        "comprehension integrity"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c853b521a9f8bb0173c42ffdb79e01c42db6066203b6aa0c5e838c2f6a78f18f_w640_q70.webp",
      "contributions": "1. Introduces the Drill-Down and Fabricate Test (DDFT), a novel protocol for measuring epistemic robustness in language models under stress from semantic compression and adversarial fabrication. 2. Proposes a two-system cognitive model (Semantic System and Epistemic Verifier) to explain and analyze LLM behavior. 3. Provides empirical evidence that epistemic robustness is orthogonal to model scale and architecture, identifying error detection as the critical bottleneck.",
      "summary": "The paper identifies a gap in current language model evaluations, which fail to measure how robustly models maintain factual knowledge under stress. It introduces the Drill-Down and Fabricate Test (DDFT) to measure epistemic robustness by applying semantic compression and adversarial fabrication. The key finding is that epistemic robustness is not predicted by model size or architecture but by a model's internal verification mechanisms, challenging assumptions about scaling and reliability.",
      "mindmap": "graph TB\n        A[The Drill-Down and Fabricate Test (DDFT)] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有评估无法衡量知识鲁棒性/Current evaluations fail to measure knowledge robustness]\n        C --> C1[DDFT协议: 语义压缩与对抗伪造/DDFT Protocol: Semantic Compression & Adversarial Fabrication]\n        C --> C2[双系统认知模型/Two-System Cognitive Model]\n        D --> D1[鲁棒性与模型规模/架构无关/Robustness orthogonal to model size/architecture]\n        D --> D2[错误检测能力是关键瓶颈/Error detection is the critical bottleneck]"
    },
    {
      "title": "Trellis: Learning to Compress Key-Value Memory in Attention Models",
      "authors": "Mahdi Karami, Ali Behrouz, Praneeth Kacham, Vahab Mirrokni",
      "institution": "Google Research",
      "link": "https://arxiv.org/pdf/2512.23852",
      "code": null,
      "tags": [
        "llm inference",
        "KV cache compression",
        "bounded memory",
        "online gradient descent",
        "recurrent compression",
        "long-context"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/889c9150f49160406df5713209e4165753466bc69bac6ffa78b28c214caa5c7d_w640_q70.webp",
      "contributions": "1. Introduces Trellis, a novel Transformer architecture that replaces the standard unbounded KV cache with a fixed-size memory, enabling bounded memory usage. 2. Proposes a trainable two-pass recurrent compression mechanism that dynamically compresses new key-value pairs into the fixed memory at test time. 3. Leverages an online gradient descent procedure with a forget gate to recursively update the compressed memory, learning to retain important contextual information from long sequences.",
      "summary": "This paper addresses the quadratic complexity and unbounded memory growth of the KV cache in Transformers by proposing Trellis, an architecture with a fixed-size memory and a learned recurrent compression mechanism. The method uses online gradient descent with a forget gate to dynamically update the compressed memory during inference. Experiments show Trellis outperforms baselines, with increasing gains on longer sequences, demonstrating its potential for efficient long-context modeling.",
      "mindmap": "graph TB\n        Root[”Trellis: Learning to Compress Key-Value Memory”] --> Problem[”核心问题/Problem: Transformer KV cache leads to quadratic complexity and unbounded memory”]\n        Root --> Method[”主要方法/Method: Fixed-size memory + Two-pass recurrent compression with online gradient descent & forget gate”]\n        Root --> Results[”关键结果/Results: Outperforms baselines; Gains increase with sequence length for long-context”]"
    },
    {
      "title": "Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining",
      "authors": "Ruizhe Huang, Kexuan Zhang, Yihao Fang, Baifeng Yu",
      "institution": "Huawei Technologies Canada Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.23862",
      "code": "https://github.com/RRaAy-H/nanotron-infini",
      "tags": [
        "llm training",
        "Infini-attention",
        "compressive memory",
        "small language models (SLMs)",
        "long-context extrapolation",
        "pretraining"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af598a1dcd8b2b6a3dec75fe7434942b519517dea235cfb006c3cf73881444fd_w640_q70.webp",
      "contributions": "1. Replaced standard attention in a 300M-parameter LLaMA model with Infini-attention to study compressive memory behavior under short-sequence pretraining. 2. Analyzed the training dynamics of SLMs with Infini-attention, revealing characteristics like loss fluctuations, gradient volatility, and early-layer memory concentration. 3. Demonstrated that Infini-attention improves long-context extrapolation over a baseline model, with supervised fine-tuning further boosting performance.",
      "summary": "This paper investigates whether the Infini-attention mechanism, which combines local attention with compressive memory, can enhance long-context capabilities in Small Language Models (SLMs) during small-scale pretraining. The authors empirically study a 300M-parameter LLaMA model equipped with Infini-attention and find it improves long-context retrieval accuracy over a baseline, despite some degradation over very long sequences. The conclusion is that architectural memory like Infini-attention is beneficial for achieving robust long-context performance in SLMs.",
      "mindmap": "graph TB\n        A[Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Enhancing long-context extrapolation for Small Language Models (SLMs)]\n        C[主要方法/Method: Using Infini-attention (compressive memory + local attention) in small-scale pretraining]\n        D[关键结果/Results: Improves long-context retrieval; Identifies balance factor importance; Shows performance degradation over very long sequences but still outperforms baseline]"
    },
    {
      "title": "Disentangling Learning from Judgment: Representation Learning for Open Response Analytics",
      "authors": "Conrad Borchers, Manit Patel, Seiyon M. Lee, Anthony F. Botelho",
      "institution": "Carnegie Mellon University, University of Florida",
      "link": "https://arxiv.org/pdf/2512.23941",
      "code": null,
      "tags": [
        "educational data mining",
        "sentence embeddings",
        "rater effects",
        "residualization",
        "teacher priors",
        "interpretability"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/969e6dbddbe7eb87582932064e8e7d3a0853ca2850b5329fafc1020e7228f365_w640_q70.webp",
      "contributions": "1. An analytics-first framework that disentangles student response content from teacher grading tendencies, making rater effects visible and auditable. 2. A modeling pipeline using dynamic teacher priors and residualized sentence embeddings to mitigate prompt and rater confounds, validated temporally. 3. A projection method to surface disagreements between content and rater signals for qualitative inspection, transforming embeddings into reflective learning analytics.",
      "summary": "This paper addresses the problem of conflating student response content with teacher grading bias in automated scoring. The proposed method uses dynamic teacher priors and residualized sentence embeddings to separate these signals, with linear models quantifying their contributions. The main conclusion is that teacher priors heavily influence predictions, and adjusting for them sharpens the content representation, enabling better analysis of student understanding versus grading practices.",
      "mindmap": "graph TB\n        A[Disentangling Learning from Judgment<br>学习与评判的解耦] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Automated scoring conflates content with rater bias<br>自动评分混淆了内容与评分者偏差]\n        C --> C1[Framework separates content signals & teacher priors<br>框架分离内容信号与教师先验]\n        C --> C2[Uses centering & residualization on embeddings<br>对嵌入使用中心化与残差化]\n        C --> C3[Temporal validation & projection for inspection<br>时间验证与投影以供检查]\n        D --> D1[Teacher priors heavily influence grades<br>教师先验严重影响评分]\n        D --> D2[Combined model achieves best AUC (~0.815)<br>组合模型取得最佳AUC]\n        D --> D3[Residual content reveals student understanding<br>残差内容揭示学生理解]"
    },
    {
      "title": "Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling",
      "authors": "Chulun Zhou, Chunkang Zhang, Guoxin Yu, Fandong Meng, Jie Zhou, Wai Lam, Mo Yu",
      "institution": "The Chinese University of Hong Kong, WeChat AI",
      "link": "https://arxiv.org/pdf/2512.23959",
      "code": "https://github.com/Encyclomen/HGMem",
      "tags": [
        "rag (retrieval-augmented generation)",
        "hypergraph memory",
        "multi-step reasoning",
        "global sense-making",
        "long-context modeling",
        "retrieval-augmented generation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/259f66b1c3afc451216d5a69cb56a5a72ee4244c5fa02941603de2fbd4afc261_w640_q70.webp",
      "contributions": "1. Proposes HGMem, a novel hypergraph-based memory mechanism that models memory as a dynamic structure with higher-order interactions, moving beyond passive storage. 2. Addresses the limitation of existing multi-step RAG memory in capturing complex relational structures and providing strong guidance for subsequent reasoning steps. 3. Demonstrates through extensive experiments that the method consistently improves multi-step RAG performance and substantially outperforms strong baselines on global sense-making tasks.",
      "summary": "This paper addresses the limitation of static, passive memory in multi-step RAG systems, which leads to fragmented reasoning in long-context tasks. It proposes HGMem, a dynamic hypergraph-based memory mechanism that captures high-order correlations among facts to form an integrated knowledge structure for stronger reasoning guidance. The method is shown to consistently and substantially outperform baseline systems across diverse global sense-making tasks.",
      "mindmap": "graph TB\n        A[Improving Multi-step RAG with Hypergraph-based Memory<br>改进多步RAG的超图记忆] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有记忆模块是被动的静态存储<br>Existing memory is passive static storage]\n        B1 --> B2[忽略了高阶关联，导致碎片化推理<br>Ignores high-order correlations, causing fragmented reasoning]\n        C --> C1[提出超图记忆机制 HGMem<br>Propose hypergraph memory mechanism HGMem]\n        C1 --> C2[将记忆表示为动态超图<br>Represent memory as a dynamic hypergraph]\n        C2 --> C3[超边形成高阶交互，构建集成知识结构<br>Hyperedges form high-order interactions, building integrated knowledge]\n        D --> D1[在多步RAG上取得一致改进<br>Achieves consistent improvement on multi-step RAG]\n        D1 --> D2[在全局理解任务上显著超越基线<br>Substantially outperforms baselines on global sense-making tasks]"
    },
    {
      "title": "Efficient Context Scaling with LongCat ZigZag Attention",
      "authors": "Chen Zhang, Yang Bai, Jiahuan Li, Anchun Gui, Keheng Wang, Feifan Liu, Guanyu Wu, Yuwei Jiang, Defei Bu, Li Wei, Haihang Jing, Hongyin Tang, Xin Chen, Xiangzhou Huang, Fengcun Li, Rongxiang Weng, Yulei Qian, Yifan Lu, Yerui Sun, Jingang Wang, Yuchen Xie, Xunliang Cai",
      "institution": "Meituan",
      "link": "https://arxiv.org/pdf/2512.23966",
      "code": null,
      "tags": [
        "llm inference",
        "sparse attention",
        "long-context",
        "mid-training",
        "ZigZag Attention"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/46b353da1c2cbb89962a2e909144fbcc8c92d821f35157049a111e1855b4242c_w640_q70.webp",
      "contributions": "1. Proposes LongCat ZigZag Attention (LoZA), a sparse attention scheme to convert full-attention models into sparse versions with limited compute. 2. Demonstrates LoZA's effectiveness for speed-up in both prefill-intensive (e.g., RAG) and decode-intensive (e.g., tool use) long-context scenarios. 3. Applies LoZA to create LongCat-Flash-Exp, a foundation model capable of efficiently processing up to 1 million tokens.",
      "summary": "The paper introduces LongCat ZigZag Attention (LoZA), a sparse attention method designed to efficiently transform standard full-attention language models into sparse models suitable for long-context tasks. This approach enables significant speed improvements for both prefill and decoding phases. The resulting model, LongCat-Flash-Exp, can process up to 1 million tokens, facilitating efficient long-term reasoning and agentic capabilities.",
      "mindmap": "graph TB\n        A[Efficient Context Scaling with LongCat ZigZag Attention] --> B[核心问题/Problem: 长上下文场景下全注意力计算开销大/High computational cost of full attention in long-context scenarios]\n        A --> C[主要方法/Method: 提出LoZA稀疏注意力方案/Propose LoZA sparse attention scheme]\n        A --> D[关键结果/Results: 实现显著加速，支持百万token高效处理/Achieve significant speed-up, enable efficient processing of 1M tokens]"
    },
    {
      "title": "CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards",
      "authors": "Zhiming Lin, Kai Zhao, Sophie Zhang, Peilai Yu, Canran Xiao",
      "institution": "Nankai University, Western Sydney University, Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.23971",
      "code": null,
      "tags": [
        "spelling correction",
        "reinforcement learning",
        "zero-supervision",
        "Chinese spelling correction",
        "PPO",
        "cluster-consensus reward"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f497dc978d283e6c34450b390462e1f0ee33c507d41a14f70226f631c7d28168_w640_q70.webp",
      "contributions": "1. Proposes CEC-Zero, a zero-supervision RL framework for Chinese spelling correction that enables LLMs to self-correct without labeled data. 2. Introduces a cluster-consensus reward mechanism based on semantic similarity and candidate agreement to guide policy optimization. 3. Demonstrates superior performance over supervised and fine-tuned LLM baselines across multiple benchmarks, establishing a label-free paradigm.",
      "summary": "This paper addresses the challenge of Chinese spelling correction (CSC) by introducing CEC-Zero, a zero-supervision reinforcement learning framework. The method synthesizes errors from clean text and uses a novel cluster-consensus reward to optimize an LLM policy with PPO, eliminating the need for costly annotations. It significantly outperforms existing supervised and fine-tuned methods on multiple benchmarks, offering a robust and scalable solution for real-world noisy text processing.",
      "mindmap": "graph TB\n        A[CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards] --> B[核心问题/Problem: 大规模中文拼写纠错依赖昂贵标注，现有方法对新型错误不鲁棒/Large-scale Chinese spelling correction relies on costly annotations; existing methods lack robustness to novel errors.]\n        A --> C[主要方法/Method: 提出零监督强化学习框架，合成错误输入，使用聚类共识奖励和PPO优化/Proposes a zero-supervision RL framework, synthesizes errorful inputs, uses cluster-consensus rewards and PPO for optimization.]\n        A --> D[关键结果/Results: 在9个基准测试上超越监督基线10-13 F1点，超越LLM微调5-8点/Outperforms supervised baselines by 10-13 F1 points and strong LLM fine-tunes by 5-8 points across 9 benchmarks.]"
    },
    {
      "title": "Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process",
      "authors": "Zhenyu Zhang, Shujian Zhang, John Lambert, Wenxuan Zhou, Zhangyang Wang, Mingqing Chen, Andrew Hard, Rajiv Mathews, Lun Wang",
      "institution": "Google DeepMind, The University of Texas at Austin",
      "link": "https://arxiv.org/pdf/2512.23988",
      "code": null,
      "tags": [
        "mechanistic interpretability",
        "sparse auto-encoder",
        "reasoning vectors",
        "chain-of-thought"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6bf740af692f8a7498e3cb43c54db55a7bd4f6005d4c48bc0e225978738bf9a_w640_q70.webp",
      "contributions": "1. Proposes RISE, an unsupervised framework using sparse auto-encoders (SAEs) to discover \"reasoning vectors\" that encode distinct reasoning behaviors from step-level LLM activations. 2. Demonstrates that these discovered vectors correspond to interpretable behaviors (e.g., reflection, backtracking) and can be used for targeted intervention to controllably steer the reasoning process without retraining. 3. Shows SAEs can uncover novel, human-undefined reasoning behaviors and structural properties, such as controlling response confidence, highlighting the potential of unsupervised latent discovery.",
      "summary": "This paper addresses the challenge of interpreting the internal reasoning process of large language models (LLMs). It proposes RISE, an unsupervised framework that uses sparse auto-encoders to discover disentangled \"reasoning vectors\" from chain-of-thought activations. The method enables the identification, visualization, and controllable intervention of specific reasoning behaviors, revealing novel insights beyond supervised analysis.",
      "mindmap": "graph TB\n        Root[”Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process”]\n        Root --> Problem[”核心问题/Problem<br>LLM推理内部机制不明确<br>Supervised methods are limited”]\n        Root --> Method[”主要方法/Method<br>RISE框架: 无监督稀疏自编码器<br>Unsupervised SAEs on step-level activations”]\n        Root --> Results[”关键结果/Results<br>发现可解释推理行为向量<br>可控干预推理轨迹<br>Discover novel behaviors”]"
    },
    {
      "title": "WISE: Web Information Satire and Fakeness Evaluation",
      "authors": "Gaurab Chhetri, Subasish Das, Tausif Islam Chowdhury",
      "institution": "Texas State University",
      "link": "https://arxiv.org/pdf/2512.24000",
      "code": null,
      "tags": [
        "text classification",
        "transformer models",
        "fake news detection",
        "satire classification",
        "misinformation",
        "model benchmarking"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9f60db2d4dc284973a6b6a30b146469da5c5cbcb175e674896cd55dd4f66c42_w640_q70.webp",
      "contributions": "1. Developed the WISE framework for benchmarking lightweight transformer models to distinguish fake news from satire. 2. Conducted a comprehensive evaluation of eight lightweight and two baseline models using a balanced dataset and multiple performance metrics. 3. Demonstrated that lightweight models like MiniLM and DistilBERT can achieve high performance, offering practical solutions for resource-constrained misinformation detection systems.",
      "summary": "This paper addresses the challenge of distinguishing fake news from satire by proposing the WISE framework. It benchmarks several lightweight transformer models on a dataset from Fakeddit and finds that models like MiniLM and DistilBERT achieve high accuracy and efficiency. The conclusion is that lightweight models are viable for real-world misinformation detection in resource-limited settings.",
      "mindmap": "graph TB\n        A[WISE: Web Information Satire and Fakeness Evaluation] --> B(核心问题/Problem: Distinguishing fake news from satire due to overlapping features)\n        A --> C(主要方法/Method: Benchmark lightweight transformers using stratified cross-validation)\n        A --> D(关键结果/Results: MiniLM highest accuracy, RoBERTa highest ROC-AUC, lightweight models effective)"
    },
    {
      "title": "iCLP: Large Language Model Reasoning with Implicit Cognition Latent Planning",
      "authors": "Sijia Chen, Di Niu",
      "institution": "Hong Kong University of Science and Technology (Guangzhou), University of Alberta",
      "link": "https://arxiv.org/pdf/2512.24014",
      "code": "https://github.com/AgenticFinLab/latent-planning",
      "tags": [
        "reasoning",
        "latent planning",
        "implicit cognition",
        "vector-quantized autoencoder",
        "chain-of-thought"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5dce54c76575e0ccf630d7de1d6cf89260c30415f1817167f368dcb00b0d64bd_w640_q70.webp",
      "contributions": "1. Proposes iCLP, a novel framework inspired by human Implicit Cognition to enable LLMs to generate and use compact latent plans for reasoning. 2. Introduces a method to distill explicit plans from reasoning trajectories and learn their discrete representations via a vector-quantized autoencoder. 3. Demonstrates that fine-tuning LLMs on latent plans improves reasoning accuracy, efficiency, and cross-domain generalization while preserving interpretability.",
      "summary": "The paper addresses the challenge of LLMs generating unreliable explicit textual plans for reasoning. It proposes the iCLP framework, which enables LLMs to learn and use compact latent plans, inspired by human subconscious cognition. Experiments show this approach improves reasoning performance and generalization on mathematical and coding tasks.",
      "mindmap": "graph TB\n        A[iCLP: 大语言模型推理与隐式认知潜在规划<br>iCLP: LLM Reasoning with Implicit Cognition Latent Planning] --> B[核心问题/Problem: 显式文本规划生成困难<br>Challenges in generating explicit textual plans]\n        A --> C[主要方法/Method: 学习并使用潜在规划<br>Learn and use latent plans via VQ-VAE and fine-tuning]\n        A --> D[关键结果/Results: 提升准确率、效率与泛化能力<br>Improves accuracy, efficiency, and generalization]"
    },
    {
      "title": "Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?",
      "authors": "Yuan Xin, Dingfan Chen, Linyi Yang, Michael Backes, Xiao Zhang",
      "institution": "CISPA Helmholtz Center for Information Security, Max Planck Institute for Intelligent Systems, Southern University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.24044",
      "code": null,
      "tags": [
        "adversarial attacks",
        "jailbreaking",
        "content safety filters",
        "LLM safety alignment",
        "input/output filtering"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e40bd85a824936f762c47f0b98464b3b30e7733690440363f10ee46695920a8_w640_q70.webp",
      "contributions": "1. First systematic evaluation of jailbreak attacks across the full LLM inference pipeline including input and output safety filters, 2. Demonstration that nearly all jailbreak techniques can be detected by at least one safety filter, challenging prior overestimations of attack success, 3. Identification of gaps in balancing recall and precision for optimizing protection and user experience in safety systems",
      "summary": "This paper addresses the gap in evaluating jailbreak attacks by systematically testing them against both LLM safety alignment and external content filters in the full deployment pipeline. The study finds that most jailbreaks can be detected by safety filters, suggesting prior success rates were overestimated, and highlights the need for better precision-recall balance in filter design.",
      "mindmap": "graph TB\n    A[Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the LLM Safety Arms Race?] --> B[核心问题/Problem: Jailbreak attacks bypass LLM safety alignment, prior evaluations neglect full deployment pipeline with content filters]\n    A --> C[主要方法/Method: First systematic evaluation of jailbreak attacks across full inference pipeline including input/output filtering stages]\n    A --> D[关键结果/Results: Most jailbreaks detectable by safety filters, prior success overestimated; need better recall-precision balance]"
    },
    {
      "title": "Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source Large Language Models",
      "authors": "Rohit Kumar Salla, Manoj Saravanan, Shrikar Reddy Kota",
      "institution": "Virginia Tech",
      "link": "https://arxiv.org/pdf/2512.24058",
      "code": "https://github.com/rohitsalla/CRS.git",
      "tags": [
        "llm evaluation",
        "reliability",
        "calibration",
        "robustness",
        "uncertainty quantification",
        "composite score"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98ff5e45b3d4957a7de510123e5e0280e7ee39117d9ff73439f058e6965ebfab_w640_q70.webp",
      "contributions": "1. A unified reliability metric (CRS) integrating calibration, robustness, and uncertainty. 2. A large-scale evaluation of ten open-source LLMs on five QA datasets. 3. The demonstration that CRS provides stable model rankings and uncovers hidden failure modes.",
      "summary": "This paper addresses the fragmented evaluation of Large Language Model (LLM) reliability by proposing the Composite Reliability Score (CRS), a unified metric that integrates calibration, robustness, and uncertainty quantification. Through experiments on ten open-source LLMs, the authors show that CRS provides consistent model rankings and reveals trade-offs between reliability dimensions. The main conclusion is that the most dependable LLM systems balance accuracy, robustness, and calibrated uncertainty.",
      "mindmap": "graph TB\n        A[Beyond Hallucinations: A Composite Score for Measuring Reliability] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLM可靠性评估碎片化/Fragmented LLM Reliability Evaluation]\n        C --> C1[提出CRS复合分数/Propose Composite Reliability Score (CRS)]\n        D --> D1[CRS提供稳定模型排名/CRS Delivers Stable Model Rankings]\n        D --> D2[揭示隐藏的失败模式/Uncovers Hidden Failure Modes]"
    },
    {
      "title": "AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives",
      "authors": "Yanxi Chen, Wenhui Zhu, Xiwen Chen, Zhipeng Wang, Xin Li, Peijie Qiu, Hao Wang, Xuanzhao Dong, Yujian Xiong, Anderson Schneider, Yuriy Nevmyvaka, Yalin Wang",
      "institution": "Arizona State University, Clemson University, Washington University in St. Louis, Rice University, Morgan Stanley",
      "link": "https://arxiv.org/pdf/2512.24052",
      "code": "https://github.com/LLM-VLM-GSL/AHA",
      "tags": [
        "multi-modal reasoning",
        "audio-language models",
        "hallucination mitigation",
        "counterfactual hard negatives",
        "preference alignment",
        "temporal reasoning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45abc0731e44f649614386415942c67de681cccc206f884d4ce3832844263cdf_w640_q70.webp",
      "contributions": "1. Proposed a taxonomy for audio grounding failures in LALMs, categorizing hallucinations into Event Omission, False Event Identity, Temporal Relation Error, and Quantitative Temporal Error. 2. Introduced the AHA (Audio Hallucination Alignment) framework, which uses counterfactual hard negative mining to construct a high-quality preference dataset for model alignment. 3. Established AHA-Eval, a diagnostic benchmark to rigorously evaluate fine-grained temporal reasoning capabilities in audio-language models.",
      "summary": "The paper addresses the problem of hallucinations in Large Audio-Language Models (LALMs), where models generate text not grounded in the audio input. To solve this, the authors propose the AHA framework, which uses counterfactual hard negative mining to create a preference dataset for aligning models to distinguish acoustic evidence from fabrications. The resulting aligned model, Qwen-Audio-AHA, shows significant improvements on both the diagnostic AHA-Eval benchmark and public benchmarks, demonstrating effective mitigation of grounding errors.",
      "mindmap": "graph TB\n        Root[AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[Large Audio-Language Models (LALMs) suffer from hallucinations / 大型音频语言模型存在幻觉问题]\n        Method[主要方法/Method] --> M1[Propose AHA framework with counterfactual hard negative mining / 提出AHA框架，使用反事实硬负例挖掘]\n        Method --> M2[Construct preference dataset for alignment / 构建用于对齐的偏好数据集]\n        Results[关键结果/Results] --> R1[13.7% improvement on AHA-Eval benchmark / 在AHA-Eval基准上提升13.7%]\n        Results --> R2[Gains on public benchmarks (MMAU-Test, MMAR) / 在公开基准(MMAU-Test, MMAR)上取得提升]"
    },
    {
      "title": "Training a Huggingface Model on AWS Sagemaker (Without Tears)",
      "authors": "Liling Tan",
      "institution": "(Institution not explicitly stated in provided content. Based on author name and context, likely independent researcher or affiliation not listed on first page.)",
      "link": "https://arxiv.org/pdf/2512.24098",
      "code": null,
      "tags": [
        "llm training",
        "AWS SageMaker",
        "Hugging Face",
        "MLOps",
        "cloud computing",
        "Jupyter as a Service"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1e9d3b4e38e89877a6b18e1df5bad45a785b69e26e421db2b8a658f22bdff539_w640_q70.webp",
      "contributions": "1. Provides a centralized, comprehensive guide to train a Hugging Face model on AWS SageMaker, addressing fragmented documentation. 2. Bridges the knowledge gap between local Jupyter Notebook development and cloud-based training on SageMaker. 3. Aims to democratize cloud adoption for researchers lacking on-premise computing resources by lowering the platform's learning curve.",
      "summary": "This demo paper addresses the steep learning curve and fragmented documentation that hinder researchers from using AWS SageMaker to train Hugging Face models. It proposes a centralized guide to bridge the gap between local and cloud-based development workflows. The main conclusion is that this approach can democratize cloud adoption, enabling more researchers to train models without extensive on-premise resources.",
      "mindmap": "graph TB\n        A[Training a Huggingface Model on AWS Sagemaker (Without Tears)] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Barriers to Cloud Adoption<br>资源壁垒与学习曲线]\n        C[主要方法/Method<br>Centralized Guide<br>提供集中化指南]\n        D[关键结果/Results<br>Democratized Cloud Training<br>实现云训练的民主化]"
    },
    {
      "title": "Factorized Learning for Temporally Grounded Video-Language Models",
      "authors": "Wenzheng Zeng, Difei Gao, Mike Zheng Shou, Hwee Tou Ng",
      "institution": "National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.24097",
      "code": "https://github.com/nusnlp/d2vlm",
      "tags": [
        "video-language models",
        "temporal grounding",
        "factorized learning",
        "preference optimization",
        "evidence tokens",
        "video understanding"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c7daa6b2b83cd5b8b5e9ed9cbeed8ecfc3d04fe90ac708e60dda996b6def5b97_w640_q70.webp",
      "contributions": "1. Proposes D2VLM, a framework that decouples the learning of temporal grounding and textual response using a \"grounding then answering with evidence referencing\" paradigm and introduces evidence tokens for explicit event-level visual semantic capture. 2. Introduces Factorized Preference Optimization (FPO), a novel algorithm that explicitly incorporates probabilistic temporal grounding modeling into the preference optimization objective for both grounding and response. 3. Constructs a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding.",
      "summary": "This paper addresses the challenge of accurate temporal grounding in video-language models by proposing a factorized learning approach. It introduces the D2VLM framework, which decouples grounding and response generation, and a novel Factorized Preference Optimization (FPO) algorithm for joint optimization. Experiments show the approach achieves clear advantages over existing methods on various tasks.",
      "mindmap": "graph TB\n        A[Factorized Learning for Temporally Grounded Video-Language Models] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Existing models struggle with accurate temporal grounding for event-level perception. 现有模型在事件级感知的精确时间定位上存在困难。]\n        C[主要方法/Method: Propose D2VLM framework and Factorized Preference Optimization (FPO). 提出D2VLM框架和因子化偏好优化算法。]\n        D[关键结果/Results: Demonstrates clear advantage on various tasks. 在多种任务上展现出明显优势。]"
    },
    {
      "title": "HY-MT1.5 Technical Report",
      "authors": "Mao Zheng, Zheng Li, Tao Chen, Mingyang Song, Di Wang",
      "institution": "Tencent Hunyuan Team",
      "link": "https://arxiv.org/pdf/2512.24092",
      "code": "https://github.com/Tencent-Hunyuan/HY-MT",
      "tags": [
        "machine translation",
        "holistic training framework",
        "on-policy distillation",
        "parameter efficiency"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ef782a5a818ae655e93a8b8755b15f73eb04f3d46c041e15eb5c4a26d7b05b1_w640_q70.webp",
      "contributions": "1. Introduces HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of high-performance machine translation models. 2. Proposes a holistic multi-stage training framework integrating general/MT pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. 3. Demonstrates state-of-the-art performance, with the 1.8B model achieving remarkable parameter efficiency and the 7B model surpassing ultra-large proprietary models on challenging benchmarks.",
      "summary": "This report introduces the HY-MT1.5 series of machine translation models, developed using a holistic multi-stage training pipeline. The models, particularly the 1.8B parameter version, show exceptional parameter efficiency, outperforming much larger models and commercial APIs, while the 7B model sets a new state-of-the-art for its size class.",
      "mindmap": "graph TB\n        A[HY-MT1.5 Technical Report] --> B[核心问题/Problem: 高性能机器翻译/High-performance Machine Translation]\n        A --> C[主要方法/Method: 整体训练框架/Holistic Training Framework]\n        C --> C1[多阶段管道/Multi-stage Pipeline]\n        C1 --> C1a[预训练/Pre-training]\n        C1 --> C1b[监督微调/Supervised Fine-tuning]\n        C1 --> C1c[策略蒸馏/On-policy Distillation]\n        C1 --> C1d[强化学习/Reinforcement Learning]\n        A --> D[关键结果/Results: 卓越性能与效率/Outstanding Performance & Efficiency]\n        D --> D1[HY-MT1.5-1.8B: 参数高效/Parameter Efficient]\n        D --> D2[HY-MT1.5-7B: 新SOTA/New SOTA]"
    },
    {
      "title": "OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization",
      "authors": "Advait Gadhikar, Riccardo Grazzi, James Hensman",
      "institution": "CISPA Helmholtz Center for Information Security, Microsoft Research",
      "link": "https://arxiv.org/pdf/2512.24124",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "post-training quantization",
        "weight outliers",
        "rotation",
        "GPTQ",
        "data-free"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/137fb0c1b0206d10c607db973da90e5733c1ed86f7a8360cfe91f146000affae_w640_q70.webp",
      "contributions": "1. Proposes OptRot, a data-free method that learns fusible rotations by minimizing a principled, cheap proxy objective (element-wise fourth power of weights) to reduce weight outliers for quantization. 2. Demonstrates that OptRot outperforms existing rotation methods (Hadamard, SpinQuant, OSTQuant) for weight quantization and improves W4A8 activation quantization. 3. Introduces OptRot+, a data-dependent variant that incorporates activation covariance information for further performance gains, while highlighting a trade-off between weight and activation quantization in the W4A4 setting.",
      "summary": "This paper addresses the challenge of quantizing Large Language Models (LLMs) by mitigating weight outliers. It proposes OptRot, a data-free method that learns efficient rotations to minimize a proxy for weight quantization error, and shows it outperforms existing techniques for weight and W4A8 activation quantization. The work also introduces an enhanced data-dependent variant and reveals a performance trade-off in more aggressive quantization settings.",
      "mindmap": "graph TB\n        A[OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization] --> B[核心问题/Problem: LLM权重和激活中的异常值使量化困难/Outliers in LLM weights & activations make quantization difficult]\n        A --> C[主要方法/Method: 通过最小化旋转后权重的四阶矩学习可融合的旋转/Learn fusible rotations by minimizing element-wise fourth power of rotated weights (OptRot)]\n        A --> D[关键结果/Results: OptRot在权重量化上优于现有方法，改进W4A8激活量化，W4A4下存在权衡/OptRot outperforms existing methods for weight quant., improves W4A8 activation quant., trade-off in W4A4 setting]"
    },
    {
      "title": "Activation Steering for Masked Diffusion Language Models",
      "authors": "Adi Shnaidman, Erin Feiglin, Osher Yaari, Efrat Mentel, Amit Levi, Raz Lapid",
      "institution": "Deepkeep, Technion",
      "link": "https://arxiv.org/pdf/2512.24143",
      "code": null,
      "tags": [
        "controllable text generation",
        "masked diffusion language models",
        "activation steering",
        "inference-time control",
        "contrastive examples",
        "denoising process"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dd08d3e6e7b873796f6e3e5e5022c66a9ad714f8a6e71a0a17f32e0087c5706_w640_q70.webp",
      "contributions": "1. Proposes an activation-steering framework for Masked Diffusion Language Models (MDLMs) to achieve inference-time control. 2. Introduces a method to compute layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. 3. Demonstrates effective steering for modulating high-level attributes (e.g., compliance, language) through experiments and ablations on LLaDA-8B-Instruct.",
      "summary": "This paper addresses the lack of inference-time control mechanisms for Masked Diffusion Language Models (MDLMs). It proposes an efficient activation-steering framework that computes steering vectors from contrastive examples and applies them during the reverse-diffusion process. The method successfully modulates attributes like compliance and language in text generation, as validated on the LLaDA-8B-Instruct model.",
      "mindmap": "graph TB\n        Root(”Activation Steering for Masked Diffusion Language Models”) --> Problem(”核心问题/Problem: Lack of inference-time control in MDLMs”)\n        Root --> Method(”主要方法/Method: Activation steering via contrastive vectors”)\n        Root --> Results(”关键结果/Results: Reliable attribute modulation demonstrated”)"
    },
    {
      "title": "Large Emotional World Model",
      "authors": "Changhao Song, Yazhou Zhang, Hui Gao, Chang Yang, Peng Zhang",
      "institution": "Tianjin University",
      "link": "https://arxiv.org/pdf/2512.24149",
      "code": null,
      "tags": [
        "world models",
        "emotion-aware reasoning",
        "theory of mind",
        "causal relationship modeling",
        "social behavior prediction"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3bcd78e33e89c57127b0a9b1c8aea7e8a64af3fc78b1daecaa947e6e7bf3f59_w640_q70.webp",
      "contributions": "1. Demonstrates the importance of emotional information for world understanding by showing that removing it degrades reasoning performance. 2. Constructs the Emotion-Why-How (EWH) dataset, which integrates emotion into causal chains for reasoning about actions and future states. 3. Proposes the Large Emotional World Model (LEWM) that explicitly models emotional states alongside observations and actions to predict future states and emotional transitions.",
      "summary": "The paper identifies a gap in existing world models, which focus on physical regularities but neglect emotional factors crucial for predicting human behavior. To address this, the authors propose the Large Emotional World Model (LEWM), trained on a novel Emotion-Why-How dataset, which explicitly models and predicts emotional states and transitions. Experiments show that LEWM more accurately predicts emotion-driven social behaviors while maintaining performance on basic world modeling tasks.",
      "mindmap": "graph TB\n        A[Large Emotional World Model] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有世界模型缺乏情感建模 / Existing World Models Lack Emotion Modeling]\n        C --> C1[构建EWH数据集 / Construct EWH Dataset]\n        C --> C2[提出LEWM模型 / Propose LEWM]\n        D --> D1[更准确预测情感驱动行为 / More Accurately Predicts Emotion-Driven Behavior]\n        D --> D2[基础任务性能相当 / Comparable Performance on Basic Tasks]"
    },
    {
      "title": "Training Report of TeleChat3-MoE",
      "authors": "Xinzhang Liu, Chao Wang, Zhihao Yang, Zhuo Jiang, Xuncheng Zhao, Haoran Wang, Lei Li, Dongdong He, Luobin Liu, Kaizhe Yuan, Han Gao, Zihan Wang, Yitong Yao, Sishi Xiong, Wenmin Deng, Haowei He, Kaidong Yu, Yu Zhao, Ruiyu Fang, Yuhao Jiang, Yingyan Li, Xiaohui Hu, Xi Yu, Jingqi Li, Yanwei Liu, Qingli Li, Xinyu Shi, Junhao Niu, Chengnuo Huang, Yao Xiao, Ruiwen Wang, Fengkai Li, Luwen Pu, Kaipeng Jia, Fubei Yao, Yuyao Huang, Xuewei He, Zhuoru Jiang, Ruiting Song, Rui Xue, Qiyi Xie, Jie Zhang, Zilu Huang, Zhaoxi Zhang, Zhilong Lu, Yanhan Zhang, Yin Zhang, Yanlei Xue, Zhu Yuan, Teng Su, Xin Jiang, Shuangyong Song, Yongxiang Li, Xuelong Li",
      "institution": "Institute of Artificial Intelligence (TeleAI), China Telecom Corp Ltd; Huawei",
      "link": "https://arxiv.org/pdf/2512.24157",
      "code": "https://github.com/Tele-AI/TeleChat3",
      "tags": [
        "llm training",
        "Mixture-of-Experts (MoE)",
        "Ascend NPU",
        "distributed parallelism",
        "performance optimization",
        "cluster-level optimization"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7397c7d9494485b235d8038c6e7686b695b8b88031d87dd613f41eafdfca9fe1_w640_q70.webp",
      "contributions": "1. Systematic methodologies for operator-level and end-to-end numerical accuracy verification to ensure consistency across hardware and distributed strategies. 2. A suite of performance optimizations including interleaved pipeline scheduling, attention-aware data scheduling, hierarchical/overlapped communication for expert parallelism, and DVM-based operator fusion. 3. A systematic parallelization framework using analytical estimation and integer linear programming to optimize multi-dimensional parallelism configurations, along with cluster-level optimizations for host- and device-bound bottlenecks.",
      "summary": "This technical report presents the training infrastructure for the TeleChat3-MoE large language model series, which features a Mixture-of-Experts architecture. The core contributions are systematic methods for numerical verification, performance optimizations for efficient distributed training, and a parallelization framework for optimal configuration, resulting in significant throughput improvements and near-linear scaling on large clusters.",
      "mindmap": "graph TB\n        A[TeleChat3-MoE Training Report] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[可靠高效地扩展至前沿模型规模/Reliably and efficiently scaling to frontier model sizes]\n        C --> C1[系统化数值精度验证/Systematic numerical accuracy verification]\n        C --> C2[性能优化套件/Performance optimization suite]\n        C --> C3[系统化并行化框架/Systematic parallelization framework]\n        C2 --> C2_1[交错流水线调度/Interleaved pipeline scheduling]\n        C2 --> C2_2[注意力感知数据调度/Attention-aware data scheduling]\n        C2 --> C2_3[分层重叠通信/Hierarchical and overlapped communication]\n        C3 --> C3_1[分析估计与整数线性规划/Analytical estimation and integer linear programming]\n        D --> D1[显著吞吐量提升/Significant throughput improvements]\n        D --> D2[数千设备近线性扩展/Near-linear scaling on thousands of devices]"
    },
    {
      "title": "MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring",
      "authors": "Qipeng Wang, Rui Sheng, Yafei Li, Huamin Qu, Yushi Sun, Min Zhu",
      "institution": "Sichuan University, HKUST",
      "link": "https://arxiv.org/pdf/2512.24181",
      "code": null,
      "tags": [
        "clinical dialogue systems",
        "medical knowledge graph",
        "information gain",
        "OSCE-format state"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b46d6dca11e4b1d6269ffe806fbde3df70705f709f863770c57d2ee3313df423_w640_q70.webp",
      "contributions": "1. Proposes MedKGI, a diagnostic framework that integrates a medical knowledge graph to ground reasoning in validated ontologies and prevent hallucinations. 2. Introduces an information-gain-based question selection strategy to ask discriminative questions and improve diagnostic efficiency. 3. Adopts an OSCE-format structured state to maintain coherent evidence tracking and consistency across multi-turn diagnostic dialogues.",
      "summary": "The paper proposes MedKGI, a framework that uses a medical knowledge graph and information-guided inquiry to improve iterative clinical diagnosis with LLMs. It addresses issues like hallucinations and inefficient questioning by grounding reasoning in verified knowledge and selecting questions based on information gain. Experiments show MedKGI outperforms LLM baselines in accuracy and improves dialogue efficiency by 30%.",
      "mindmap": "graph TB\n        A[MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在临床诊断中的局限性/Limitations of LLMs in Clinical Diagnosis]\n        B1 --> B2[幻觉、低效提问、对话不一致/Hallucinations, Inefficient Questioning, Inconsistent Dialogue]\n        C --> C1[整合医学知识图谱/Integrate Medical Knowledge Graph]\n        C --> C2[基于信息增益的提问/Information-Gain-Based Questioning]\n        C --> C3[结构化OSCE状态跟踪/Structured OSCE State Tracking]\n        D --> D1[诊断准确率提升/Improved Diagnostic Accuracy]\n        D --> D2[对话效率提升30%/30% Improved Dialogue Efficiency]"
    },
    {
      "title": "LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring",
      "authors": "May Bashendy, Walid Massoud, Sohaila Eltanbouly, Salam Albatarni, Marwan Sayed, Abrar Abir, Houda Bouamor, Tamer Elsayed",
      "institution": "Qatar University, Carnegie Mellon University in Qatar",
      "link": "https://arxiv.org/pdf/2512.24235",
      "code": null,
      "tags": [
        "automated essay scoring",
        "Arabic NLP",
        "dataset",
        "trait-based annotation",
        "benchmark models",
        "cross-prompt evaluation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae05a0c997e3fe72bc7d8f192412113731426447fc7b73d020117ab725e12165_w640_q70.webp",
      "contributions": "1. Introduced LAILA, the largest publicly available Arabic AES dataset with 7,859 essays. 2. Provided detailed holistic and trait-specific annotations across seven writing dimensions. 3. Established benchmark results using state-of-the-art models in both prompt-specific and cross-prompt settings.",
      "summary": "This paper addresses the lack of public datasets for Arabic Automated Essay Scoring (AES) by introducing LAILA, a large-scale dataset with 7,859 essays annotated for holistic and seven trait-specific scores. It details the dataset's collection and annotation process and provides benchmark results using modern Arabic and English models. The dataset is presented as a critical resource to support the development of robust Arabic AES systems.",
      "mindmap": "graph TB\n        Root[LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[阿拉伯语AES研究有限/Limited Arabic AES Research]\n        Problem --> P2[缺乏公开数据集/Lack of Public Datasets]\n        Method --> M1[构建大规模数据集/Build Large-Scale Dataset]\n        Method --> M2[提供多维标注/Provide Multi-Dimensional Annotations]\n        Results --> R1[发布LAILA数据集/Release LAILA Dataset]\n        Results --> R2[建立基准结果/Establish Benchmark Results]"
    },
    {
      "title": "Tracing the Flow of Knowledge From Science to Technology Using Deep Learning",
      "authors": "Michael E. Rose, Mainak Ghosh, Sebastian Erhardt, Cheng Li, Erik Buunk, Dietmar Harhoff",
      "institution": "Max Planck Institute for Innovation and Competition",
      "link": "https://arxiv.org/pdf/2512.24259",
      "code": null,
      "tags": [
        "semantic similarity",
        "Pat-SPECTER",
        "SPECTER2",
        "patent-paper citation",
        "semantic similarity",
        "duty of candor"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5cf4d52b11ccdc3180438f19688e00f41d2edb954de210ba3f59b428918311f6_w640_q70.webp",
      "contributions": "1. Developed Pat-SPECTER, a language similarity model fine-tuned on patents for joint analysis of patents and scientific publications. 2. Conducted a comparative evaluation of eight models, demonstrating Pat-SPECTER's superior performance in predicting credible patent-paper citations. 3. Applied the model to test the hypothesis that US patents cite semantically less similar papers due to the duty of candor, providing empirical evidence for this legal influence on knowledge flow.",
      "summary": "This paper develops Pat-SPECTER, a language model fine-tuned on patents, to measure semantic similarity between patents and scientific papers. The model outperforms others in predicting patent-paper citations and is used to show that US patents tend to cite less semantically similar papers, potentially due to legal disclosure requirements.",
      "mindmap": "graph TB\n        Root[”Tracing Knowledge Flow<br>追踪知识流”] --> Problem[”Problem: Need model for patent-paper similarity<br>问题：需要专利-论文相似性模型”]\n        Root --> Method[”Method: Develop & fine-tune Pat-SPECTER<br>方法：开发并微调Pat-SPECTER”]\n        Root --> Results[”Results: Best performance; US patents cite less similar papers<br>结果：性能最佳；美国专利引用相似性较低的论文”]"
    },
    {
      "title": "Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning",
      "authors": "Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen",
      "institution": "ByteDance Seed, Shanghai Jiao Tong University, University of Sydney, Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.24265",
      "code": "https://github.com/ByteDance-Seed/DATAMASK",
      "tags": [
        "llm training",
        "data selection",
        "policy gradient",
        "mask learning",
        "quality-diversity trade-off",
        "FineWeb"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/02fd504349b8c0bb1934304d821a648ed4ca490b2f41e136f9b7a6220f39d5d2_w640_q70.webp",
      "contributions": "1. Introduces DATAMASK, a novel joint learning framework for large-scale pre-training data selection that simultaneously optimizes quality and diversity metrics. 2. Formulates data selection as a mask learning problem and solves it efficiently using policy gradient-based optimization with acceleration enhancements, reducing selection time by 98.9% compared to greedy algorithms. 3. Creates and releases FineWeb-Mask, a high-quality and diverse 10% subset of the 15-trillion-token FineWeb dataset, which significantly improves model performance (e.g., +3.2% on a 1.5B model) across diverse tasks.",
      "summary": "The paper addresses the problem of efficiently selecting high-quality and diverse data for large-scale LLM pre-training, where traditional methods are costly and suboptimal. It proposes DATAMASK, a policy gradient-based framework that learns optimal data masks to jointly optimize quality and diversity, drastically speeding up selection. The resulting curated dataset, FineWeb-Mask, leads to significant performance gains in pre-trained models, demonstrating the framework's effectiveness.",
      "mindmap": "graph TB\n        A[Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: 大规模预训练数据中，联合考虑质量与多样性指标进行样本选择计算成本过高]\n        C[主要方法/Method: 提出DATAMASK框架，将选择过程视为掩码学习问题，使用策略梯度进行优化]\n        D[关键结果/Results: 选择时间减少98.9%，从FineWeb中选出的子集显著提升多种模型性能]"
    },
    {
      "title": "Automated Analysis of Sustainability Reports: Using Large Language Models for the Extraction and Prediction of EU Taxonomy-Compliant KPIs",
      "authors": "Jonathan Schmoll, Adam Jatowt",
      "institution": "University of Innsbruck",
      "link": "https://arxiv.org/pdf/2512.24289",
      "code": null,
      "tags": [
        "information extraction",
        "large language models",
        "EU Taxonomy",
        "key performance indicators",
        "sustainability reporting",
        "benchmark dataset"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8227132ec6a07313687e383d60d2cb42bc66f5e99544d0d728a348620db4f75d_w640_q70.webp",
      "contributions": "1. Introduces a novel, structured benchmark dataset from 190 corporate reports for EU Taxonomy analysis, containing ground-truth economic activities and quantitative KPIs. 2. Conducts the first systematic evaluation of LLMs on the core compliance workflow, revealing a performance gap between qualitative and quantitative tasks. 3. Proposes a multi-step agentic framework that modestly enhances precision for the qualitative task of identifying economic activities.",
      "summary": "This paper addresses the challenge of automating EU Taxonomy compliance by evaluating Large Language Models (LLMs) for extracting and predicting sustainability-related information from corporate reports. It introduces a new benchmark dataset and finds that while LLMs show moderate success in qualitative tasks like activity identification, they fail at quantitative KPI prediction in a zero-shot setting. The authors conclude that LLMs are not yet ready for full automation but can serve as effective assistive tools for human experts.",
      "mindmap": "graph TB\n        Root[Automated Analysis of Sustainability Reports] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Manual EU Taxonomy compliance is resource-intensive] --> ProblemDetail[缺乏公开基准数据集/Lack of public benchmark datasets]\n        Method[主要方法/Method: Introduce structured dataset & evaluate LLMs] --> MethodDetail[使用LLM进行定性与定量任务评估/Evaluate LLMs on qualitative & quantitative tasks]\n        Results[关键结果/Results: LLMs moderate on qualitative, fail on quantitative] --> Conclusion[结论/Conclusion: LLMs as assistive tools, not full automation]"
    },
    {
      "title": "Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking",
      "authors": "Meiqi Chen, Fandong Meng, Jie Zhou",
      "institution": "Tencent Inc (WeChat AI)",
      "link": "https://arxiv.org/pdf/2512.24297",
      "code": null,
      "tags": [
        "multimodal reasoning",
        "visual thinking",
        "reinforcement learning",
        "chain-of-thought",
        "geometric reasoning",
        "multimodal integration"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87f7f4c5ac39e44125cddcd070468c932e7b1c2ea80095ffe3322857f26d40ed_w640_q70.webp",
      "contributions": "1. Introduces FIGR, a novel method that integrates active visual thinking into multi-step reasoning via end-to-end reinforcement learning. 2. Proposes a mechanism to adaptively regulate when and how to invoke visual reasoning, externalizing structural hypotheses by constructing visual representations. 3. Demonstrates significant performance improvements on challenging mathematical reasoning benchmarks, enhancing the stability and reliability of complex reasoning.",
      "summary": "This paper introduces FIGR, a method that enhances complex reasoning by integrating active visual thinking through reinforcement learning, allowing models to construct visual diagrams during problem-solving. It adaptively decides when to use visual reasoning to better capture spatial and structural relationships. Experiments show FIGR outperforms text-only baselines on mathematical reasoning benchmarks, improving stability and reliability.",
      "mindmap": "graph TB\n        Root[Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Text-based reasoning struggles with implicit spatial and structural relationships.]\n        Method[主要方法/Method: FIGR integrates active visual thinking via RL to construct visual representations adaptively.]\n        Results[关键结果/Results: Outperforms text-only baselines, improves stability and reliability on math benchmarks.]"
    },
    {
      "title": "QianfanHuijin Technical Report: A Novel Multi-Stage Training Paradigm for Finance Industrial LLMs",
      "authors": "Shupeng Li, Weipeng Lu, Linyun Liu, Chen Lin, Shaofei Li, Zhendong Tan, Hanjun Zhong, Yucheng Zeng, Chenghao Zhu, Mengyue Liu, Daxiang Dong, Jianmin Wu, Yunting Xiao, Annan Li, Danyu Liu, Jingnan Zhang, Licen Liu, Dawei Yin, Dou Shen",
      "institution": "Baidu AI Cloud",
      "link": "https://arxiv.org/pdf/2512.24314",
      "code": null,
      "tags": [
        "domain-specific language models",
        "continual pre-training",
        "supervised fine-tuning",
        "reinforcement learning",
        "financial reasoning",
        "agentic capabilities"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4582f947672a6fc36e2da1b1d6c10ce7940df34a52b02ba28048ca5cea0e2715_w640_q70.webp",
      "contributions": "1. Proposes a novel, generalizable multi-stage training paradigm for enhancing industrial LLMs, moving beyond simple knowledge injection to include reasoning and agentic capabilities. 2. Introduces QianfanHuijin, a financial domain LLM developed using this paradigm, which includes stages of Financial SFT, Finance Reasoning RL, and Finance Agentic RL. 3. Empirically validates the paradigm, showing superior performance on financial benchmarks and confirming the specific gains from the targeted Reasoning and Agentic RL stages through ablation studies.",
      "summary": "This paper addresses the need for financial LLMs with robust reasoning and agentic capabilities beyond just domain knowledge. It proposes a multi-stage training paradigm involving continual pre-training followed by a fine-grained post-training pipeline (SFT, Reasoning RL, Agentic RL, General RL) and introduces the QianfanHuijin model. The results show the model achieves state-of-the-art performance on financial benchmarks, validating the effectiveness of the progressive training approach.",
      "mindmap": "graph TB\n        A[QianfanHuijin Technical Report<br>技术报告] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[金融LLM需推理与智能体能力<br>Financial LLMs need reasoning & agentic capabilities]\n        C --> C1[多阶段训练范式<br>Multi-Stage Training Paradigm]\n        C1 --> C2[持续预训练 CPT<br>Continual Pre-training]\n        C1 --> C3[渐进式后训练<br>Progressive Post-training]\n        C3 --> C4[金融SFT<br>Financial SFT]\n        C3 --> C5[金融推理RL<br>Finance Reasoning RL]\n        C3 --> C6[金融智能体RL<br>Finance Agentic RL]\n        C3 --> C7[通用RL<br>General RL]\n        D --> D1[权威基准性能优越<br>Superior on authoritative benchmarks]\n        D --> D2[消融研究验证阶段有效性<br>Ablation validates stage gains]"
    },
    {
      "title": "World model inspired sarcasm reasoning with large language model agents",
      "authors": "Keito Inoshita, Shinnosuke Mizuno",
      "institution": "Kansai University, Shiga University, The University of Tokyo",
      "link": "https://arxiv.org/pdf/2512.24329",
      "code": null,
      "tags": [
        "sarcasm detection",
        "world model",
        "large language model agents",
        "interpretability",
        "semantic inconsistency",
        "intention reasoning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea54c90970e87e4614b497dfa13507774353c0c9ec5d9c020257c78898239831_w640_q70.webp",
      "contributions": "1. Reformulates sarcasm understanding as a world model inspired reasoning process, decomposing the task into components like literal meaning and normative expectation. 2. Proposes WM-SAR, a framework using specialized LLM-based agents to generate explicit, quantifiable scores for semantic inconsistency and intention. 3. Integrates these interpretable scores via a lightweight Logistic Regression model, achieving strong performance and high interpretability on sarcasm detection benchmarks.",
      "summary": "This paper proposes WM-SAR, a method that reformulates sarcasm detection as a world model inspired reasoning process using multiple LLM-based agents to explicitly quantify semantic inconsistency and speaker intention. These scores are then integrated by a simple classifier to predict sarcasm. Experiments show the method outperforms existing approaches and provides an interpretable decision structure.",
      "mindmap": "graph TB\n        A[World model inspired sarcasm reasoning with large language model agents] --> B[核心问题/Problem: Sarcasm understanding requires capturing discrepancy between literal meaning and speaker's intention/context, and existing black-box models lack interpretability.]\n        A --> C[主要方法/Method: Proposes WM-SAR, using specialized LLM agents to decompose and score literal meaning, normative expectation, and intention, then integrates scores with Logistic Regression.]\n        A --> D[关键结果/Results: WM-SAR outperforms existing methods on benchmarks, and ablation studies show the importance of semantic inconsistency and intention reasoning for performance and interpretability.]"
    },
    {
      "title": "DermaVQA-DAS: Dermatology Assessment Schema (DAS) & Datasets for Closed-Ended Question Answering & Segmentation in Patient-Generated Dermatology Images",
      "authors": "Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen, Noel Codella, Roberto Andres Novoa, Josep Malvehy",
      "institution": "Microsoft, University of Washington, Stanford University, Hospital Clinic of Barcelona",
      "link": "https://arxiv.org/pdf/2512.24340",
      "code": "https://osf.io/72rp3",
      "tags": [
        "medical image analysis",
        "visual question answering",
        "lesion segmentation",
        "multimodal models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dabc426dbf988c067106f76b5dca274abd76ad3a46bcddbd05c76b76893e508a_w640_q70.webp",
      "contributions": "1. Introduction of the Dermatology Assessment Schema (DAS), a novel expert-developed framework for structured dermatological feature assessment. 2. Release of DermaVQA-DAS, an extended dataset supporting closed-ended question answering and lesion segmentation on patient-generated images. 3. Comprehensive benchmarking of state-of-the-art multimodal models on the new tasks, analyzing the impact of prompt design on segmentation performance.",
      "summary": "This paper addresses the lack of patient-centered benchmarks in dermatology by introducing DermaVQA-DAS, a dataset extension built upon a novel expert-developed assessment schema (DAS) for structured feature annotation. It supports two tasks—closed-ended visual question answering and lesion segmentation—on patient-generated images and queries. The study benchmarks modern multimodal models, finding strong QA performance and demonstrating that prompt design significantly impacts segmentation results.",
      "mindmap": "graph TB\n        Root[DermaVQA-DAS] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[核心问题/Problem] --> P1[现有数据集缺乏患者视角/Existing datasets lack patient perspective]\n        P1 --> P2[限制以患者为中心的护理应用/Limits patient-centered care applications]\n    \n        Method[主要方法/Method] --> M1[提出皮肤病评估框架(DAS)/Propose Dermatology Assessment Schema (DAS)]\n        M1 --> M2[扩展DermaVQA数据集/Extend DermaVQA dataset]\n        M2 --> M3[支持两项任务:封闭式问答与分割/Support two tasks: closed QA & segmentation]\n    \n        Results[关键结果/Results] --> R1[提示设计影响分割性能/Prompt design impacts segmentation performance]\n        R1 --> R2[模型在QA上表现强劲/Models perform strongly on QA]\n        R2 --> R3[公开数据集与评估协议/Publicly release dataset & evaluation protocols]"
    },
    {
      "title": "Skim-Aware Contrastive Learning for Efficient Document Representation",
      "authors": "Waheed Ahmed Abro, Zied Bouraoui",
      "institution": "Univ Artois, CNRS",
      "link": "https://arxiv.org/pdf/2512.24373",
      "code": null,
      "tags": [
        "document representation",
        "contrastive learning",
        "natural language inference",
        "long document",
        "self-supervised learning",
        "hierarchical transformer"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae38f3776c3982e71d1fd2fda48c20229eb63f1918544341ca35ab3cb48a02af_w640_q70.webp",
      "contributions": "1. A novel self-supervised contrastive learning framework inspired by human skimming behavior for long document representation. 2. A method that uses random section masking and an NLI-based contrastive objective to align relevant parts and distance unrelated ones. 3. Demonstrated significant improvements in both accuracy and efficiency on legal and biomedical document tasks.",
      "summary": "The paper addresses the challenge of efficiently representing long documents like legal and medical texts. It proposes a self-supervised contrastive learning method that mimics human skimming by masking sections and using an NLI objective to relate document parts. Experiments show the method achieves better accuracy and computational efficiency compared to existing approaches.",
      "mindmap": "graph TB\n        A[Skim-Aware Contrastive Learning for Efficient Document Representation] --> B[核心问题/Problem: 长文档表示困难/Inefficient long document representation]\n        A --> C[主要方法/Method: 基于NLI的对比学习/NLI-based contrastive learning with section masking]\n        A --> D[关键结果/Results: 在准确性和效率上取得显著提升/Significant gains in accuracy and efficiency]"
    },
    {
      "title": "Comparing Approaches to Automatic Summarization in Less-Resourced Languages",
      "authors": "Chester Palen-Michel, Constantine Lignos",
      "institution": "Brandeis University",
      "link": "https://arxiv.org/pdf/2512.24410",
      "code": null,
      "tags": [
        "text summarization",
        "less-resourced languages",
        "multilingual transfer",
        "data augmentation",
        "LLM prompting",
        "mT5"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f14f0d3397d12fd7c93ad9814a09fa7bd5c030b47c51091b59d65cc5392446ba_w640_q70.webp",
      "contributions": "1. A comprehensive comparative study of multiple summarization approaches for less-resourced languages, including zero-shot LLMs, fine-tuned mT5, and a translation pipeline. 2. Exploration and evaluation of three data augmentation methods using Wikipedia to generate synthetic training data for low-resource settings. 3. An analysis showing that a fine-tuned multilingual mT5 baseline often outperforms zero-shot LLMs and that LLM-as-judge evaluation may be unreliable for less-resourced languages.",
      "summary": "This paper compares various methods for automatic text summarization in less-resourced languages, including prompting large language models (LLMs), fine-tuning multilingual models like mT5 with data augmentation, and a translation pipeline. The evaluation across multiple metrics finds that a fine-tuned multilingual mT5 model generally outperforms zero-shot LLMs, and highlights potential issues with using LLMs as evaluators for these languages.",
      "mindmap": "graph TB\n        A[Comparing Approaches to Automatic Summarization in Less-Resourced Languages] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[”高资源语言性能好，低资源语言研究不足 / High performance in high-resourced languages, less attention to less-resourced languages”]\n        C --> C1[”比较多种方法 / Compare various approaches”]\n        C1 --> C1_1[”零样本提示LLM / Zero-shot prompting LLMs”]\n        C1 --> C1_2[”微调mT5（含数据增强） / Fine-tuning mT5 (with data augmentation)”]\n        C1 --> C1_3[”翻译-总结-翻译流程 / Translate-summarize-translate pipeline”]\n        D --> D1[”微调mT5优于大多数方法 / Fine-tuned mT5 outperforms most approaches”]\n        D --> D2[”LLM作为评估者可能不可靠 / LLM as judge may be less reliable”]"
    },
    {
      "title": "Cleaning English Abstracts of Scientific Publications",
      "authors": "Michael E. Rose, Nils A. Herrmann, Sebastian Erhardt",
      "institution": "Max Planck Institute for Innovation and Competition, Technical University Munich",
      "link": "https://arxiv.org/pdf/2512.24459",
      "code": null,
      "tags": [
        "text preprocessing",
        "scientific abstracts",
        "text cleaning",
        "document similarity",
        "language model",
        "embeddings"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4321a5aec5e6660d2de29896a2c0e5ac6c2c0e3366797584c85ba08542e17aa2_w640_q70.webp",
      "contributions": "1. Introduces an open-source, easy-to-integrate language model specifically designed to clean English-language scientific abstracts by removing extraneous clutter (e.g., copyrights, metadata). 2. Demonstrates that the model is conservative and precise in its cleaning, effectively altering document similarity rankings to be more content-focused. 3. Shows that cleaning abstracts improves the information content of standard-length textual embeddings, enhancing downstream NLP analyses.",
      "summary": "The paper addresses the problem of extraneous, non-content text (e.g., copyrights, section headings) polluting scientific abstracts, which distorts analyses like document similarity. It proposes a dedicated language model to automatically clean such abstracts. The results show the model effectively removes clutter, alters similarity rankings, and improves the quality of text embeddings.",
      "mindmap": "graph TB\n        Root[Cleaning English Abstracts of Scientific Publications] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[Abstracts contain clutter/摘要包含无关信息]\n        P1 --> P2[Distorts similarity & embeddings/扭曲相似性与嵌入]\n        Method[主要方法/Method] --> M1[Open-source LM/开源语言模型]\n        M1 --> M2[Automatic cleaning/自动清理]\n        Results[关键结果/Results] --> R1[Conservative & precise/保守且精确]\n        R1 --> R2[Alters similarity rankings/改变相似性排名]\n        R2 --> R3[Improves embeddings/提升嵌入质量]"
    },
    {
      "title": "IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback",
      "authors": "Titas Ramancauskas, Kotryna Ramancauske",
      "institution": "(Institution not explicitly stated in provided content; inferred from author names as potentially independent researchers)",
      "link": "https://arxiv.org/pdf/2512.24460",
      "code": null,
      "tags": [
        "automated essay scoring",
        "DistilBERT",
        "regression head",
        "Design-Based Research (DBR)",
        "adaptive feedback",
        "transformer model"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cd49db97d083a1a08542b5c9894656f76ab161b46611cfa6c1b0426b21442e9_w640_q70.webp",
      "contributions": "1. Development of an IELTS writing revision platform with a dedicated UI that separates conversational guidance from the writing interface to reduce cognitive load. 2. Implementation of an Automated Essay Scoring (AES) system using a DistilBERT transformer model with a regression head, achieving improved scoring accuracy (MAE 0.66, positive R²) over rule-based methods. 3. Design and evaluation of adaptive feedback tailored to the IELTS rubric, which demonstrated statistically significant score improvements (mean +0.060 bands) and identified conservative surface-level corrections as more reliable than aggressive structural interventions.",
      "summary": "This paper addresses the lack of personalized feedback in IELTS writing preparation by developing a revision platform featuring an Automated Essay Scoring system and adaptive feedback. The core method involves iterative Design-Based Research, transitioning from rule-based scoring to a more accurate DistilBERT transformer model with a regression head. The main conclusion is that such automated feedback is best used as a supplement to human instruction, with surface-level corrections proving more effective for IELTS contexts than deep structural interventions.",
      "mindmap": "graph TB\n        A[IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统方法缺乏个性化反馈/Traditional methods lack personalized feedback]\n        C --> C1[基于设计的研究迭代/Iterative Design-Based Research (DBR)]\n        C1 --> C2[从规则到Transformer/From rule-based to transformer-based (DistilBERT)]\n        C2 --> C3[带回归头的评分模型/Scoring model with regression head]\n        C --> C4[自适应反馈系统/Adaptive feedback system]\n        D --> D1[评分准确率提升/Improved scoring accuracy (MAE 0.66, positive R²)]\n        D --> D2[分数显著提高/Statistically significant score improvement (mean +0.060 bands)]\n        D --> D3[结论: 自动化反馈是人工教学的补充/Conclusion: Automated feedback is a supplement to human instruction]"
    },
    {
      "title": "Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech",
      "authors": "Fabian Retkowski, Alexander Waibel",
      "institution": "Karlsruhe Institute of Technology, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.24517",
      "code": null,
      "tags": [
        "text segmentation",
        "paragraph segmentation",
        "constrained decoding",
        "hierarchical segmentation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91854c0eca4ed53c1e5121a89b5235513f5b721bd7a6b98dd3e52d1c104f23ec_w640_q70.webp",
      "contributions": "1. Introduces TEDPara and YTSegPara, the first benchmarks for paragraph segmentation in speech. 2. Proposes a constrained-decoding formulation for LLMs to insert paragraph breaks while preserving the original transcript. 3. Presents MiniSeg, a compact model achieving state-of-the-art accuracy and capable of hierarchical chapter/paragraph prediction.",
      "summary": "This paper addresses the problem of unstructured speech transcripts by establishing paragraph segmentation as a standard task. It introduces new benchmarks, a constrained-decoding method for LLMs, and a compact model called MiniSeg that achieves state-of-the-art performance. The work successfully establishes paragraph segmentation as a practical and standardized step in speech processing.",
      "mindmap": "graph TB\n        Root[”Paragraph Segmentation Revisited: Towards a Standard Task for Structuring Speech”] --> Problem[”核心问题/Problem: Unstructured speech transcripts lack readability”]\n        Root --> Method[”主要方法/Method: New benchmarks, constrained decoding, compact model”]\n        Root --> Results[”关键结果/Results: Establishes a standardized, practical task”]"
    },
    {
      "title": "From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning",
      "authors": "Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera",
      "institution": "Purdue University",
      "link": "https://arxiv.org/pdf/2512.24532",
      "code": null,
      "tags": [
        "reinforcement learning",
        "spatial reasoning",
        "LoRA",
        "GRPO",
        "supervised fine-tuning",
        "reinforcement learning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b19427bf120d4b89a11879461b589b7313caa689fdec51f99f516c6485aef495_w640_q70.webp",
      "contributions": "1. A two-stage approach for multi-step spatial reasoning that first fine-tunes an LLM on atomic spatial transformations and then trains lightweight LoRA adapters via RL to compose these blocks for planning. 2. The creation of a synthetic ASCII-art dataset and a corresponding ASCII-based RL environment to support training and evaluation. 3. Demonstration that the proposed method outperforms baselines in both dynamic and static environments, with faster convergence and more stable training than end-to-end RL.",
      "summary": "This paper addresses the challenge of multi-step spatial reasoning in LLMs by proposing a two-stage method: first, supervised fine-tuning on basic spatial transformations to build physics awareness, and then training LoRA adapters with reinforcement learning (GRPO) to learn planning policies. The approach is evaluated using a custom ASCII-art environment and is shown to outperform various baselines, converging faster and more stably than training from scratch with RL.",
      "mindmap": "graph TB\n        A[From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LLMs struggle with spatial transformations and multi-step planning]\n        C[主要方法/Method<br>Two-stage: SFT on spatial blocks, then RL (GRPO) with LoRA for planning]\n        D[关键结果/Results<br>Outperforms baselines, faster convergence, stable training]"
    },
    {
      "title": "More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization",
      "authors": "Yuma Ichikawa, Yoshihiko Fujisawa, Yudai Fujimoto, Akira Sakai, Katsuki Fujisawa",
      "institution": "Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University",
      "link": "https://arxiv.org/pdf/2512.24545",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "extreme quantization",
        "double binary factorization",
        "low-bit LLM",
        "post-training quantization",
        "binary matrix multiplication"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e17ec329eb54b789cd97cf9a3fc6db67786908aca3eb86af65de80d0797eb12_w640_q70.webp",
      "contributions": "1. Proposed Multi-Envelope Double Binary Factorization (MDBF), which replaces the single magnitude envelope in DBF with a rank-l envelope to enhance magnitude expressiveness while maintaining a shared binary sign carrier. 2. Introduced a closed-form initialization and an alternating refinement method to effectively optimize the MDBF parameters. 3. Demonstrated that MDBF improves perplexity and zero-shot accuracy over prior binary formats on LLaMA and Qwen models at matched bit budgets while preserving the same efficient inference primitive.",
      "summary": "The paper addresses the performance saturation of Double Binary Factorization (DBF) in extreme low-bit quantization of LLMs, where a single magnitude envelope limits expressiveness. It proposes Multi-Envelope DBF (MDBF), which uses multiple envelope components to allocate more expressivity to magnitudes while keeping binary sign matrices shared. Experiments on LLaMA and Qwen families show MDBF outperforms previous binary formats in accuracy and perplexity at the same bit rate without changing the inference primitive.",
      "mindmap": "graph TB\n        Root[”More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>DBF scaling too restrictive,<br>single envelope causes<br>performance saturation”]\n        Method[”主要方法/Method<br>Propose MDBF: shared 1-bit sign bases,<br>replace single envelope with<br>rank-l envelope”]\n        Results[”关键结果/Results<br>Better perplexity & accuracy<br>over previous binary formats,<br>same inference primitive”]"
    },
    {
      "title": "Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs",
      "authors": "Muhammad Abdullahi Said, Muhammad Sammani Sani",
      "institution": "African Institute for Mathematical Science, University of Vienna",
      "link": "https://arxiv.org/pdf/2512.24556",
      "code": "https://github.com/mohdasaid/HausaSafety_Audit",
      "tags": [
        "ai safety & alignment",
        "multilingual safety",
        "temporal reasoning",
        "adversarial evaluation",
        "complex interference",
        "invariant alignment"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7cf2ca379a60fe7b5c54e48b05602cc104b0bbc975a7e3c93cc9bfd7355e306_w640_q70.webp",
      "contributions": "1. Introduced HausaSafety, a novel adversarial dataset for safety auditing grounded in West African threat scenarios. 2. Identified a mechanism of Complex Interference, showing safety is determined by the intersection of language and temporal variables, not a simple degradation. 3. Discovered a profound Temporal Asymmetry where past-tense framing bypasses safety defenses while future-tense triggers hyper-conservative refusals.",
      "summary": "This paper systematically audits the safety of LLMs across languages and temporal contexts, finding that safety is not fixed but context-dependent, with models relying on superficial heuristics. The authors propose a paradigm shift towards Invariant Alignment to ensure safety stability.",
      "mindmap": "graph TB\n        A[Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[多语言安全零样本迁移的盲点/Blind spot in zero-shot multilingual safety transfer]\n        C --> C1[使用HausaSafety进行系统审计/Systematic audit using HausaSafety]\n        C --> C2[2x4因子设计评估语言与时间/2x4 factorial design evaluating language & time]\n        D --> D1[复杂干扰机制/Complex Interference mechanism]\n        D --> D2[反向语言安全/Reverse Linguistic Safety]\n        D --> D3[时间不对称性/Temporal Asymmetry]"
    },
    {
      "title": "HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering",
      "authors": "Chaodong Tong, Qi Zhang, Jiayang Gao, Lei Jiang, Yanbing Liu, Nannan Sun",
      "institution": "Institute of Information Engineering, Chinese Academy of Sciences; University of Chinese Academy of Sciences; China Industrial Control Systems Cyber Emergency Response Team; Beijing Institute of Computer Technology and Application",
      "link": "https://arxiv.org/pdf/2512.24562",
      "code": null,
      "tags": [
        "hallucination detection",
        "uncertainty modeling",
        "token-level signals",
        "multi-granular fusion",
        "lightweight framework",
        "one-pass detection"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/483dc55be4bf85e380bc716c1ed587cc46c0c417e77e0a9ba4c6ab2e2afb2949_w640_q70.webp",
      "contributions": "1. Proposes HaluNet, a lightweight neural framework that integrates multi-granular token-level uncertainties (semantic embeddings, probabilistic confidence, distributional uncertainty). 2. Introduces a multi-branch architecture that adaptively fuses model knowledge with output uncertainty for efficient one-pass hallucination detection. 3. Demonstrates strong detection performance and computational efficiency on multiple QA benchmarks (SQuAD, TriviaQA, Natural Questions), with or without access to context.",
      "summary": "The paper addresses the problem of hallucination detection in LLM question answering. It proposes HaluNet, a lightweight framework that combines multiple token-level uncertainty signals for efficient one-pass detection. Experiments show it achieves strong performance and favorable computational efficiency, highlighting its potential for real-time use.",
      "mindmap": "graph TB\n        A[HaluNet: Multi-Granular Uncertainty Modeling<br>for Efficient Hallucination Detection in LLM QA] --> B[核心问题/Problem: LLMs in QA often generate hallucinations (factual errors/fabricated content)]\n        A --> C[主要方法/Method: HaluNet, a lightweight neural framework integrating multi-granular token-level uncertainties (semantic + probabilistic) via multi-branch fusion]\n        A --> D[关键结果/Results: Strong hallucination detection performance and favorable computational efficiency on SQuAD, TriviaQA, Natural Questions]"
    },
    {
      "title": "Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities",
      "authors": "Hongseok Oh, Wonseok Hwang, Kyoung-Woon On",
      "institution": "University of Seoul, LBOX",
      "link": "https://arxiv.org/pdf/2512.24572",
      "code": "https://github.com/lbox-kr/kcl",
      "tags": [
        "legal reasoning evaluation",
        "legal benchmark",
        "knowledge-independent evaluation",
        "precedent-aligned questions",
        "automated rubric evaluation",
        "Korean legal domain"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/defb63442086b6432fc3b38da8a4cfae8a2c23c830816fe13d1440a09c526554_w640_q70.webp",
      "contributions": "1. Introduces the Korean Canonical Legal Benchmark (KCL), designed to assess legal reasoning capabilities independently of domain-specific knowledge by providing question-level supporting precedents. 2. Presents a comprehensive benchmark with two components: KCL-MCQA (multiple-choice) and KCL-Essay (open-ended generation), including instance-level rubrics for automated evaluation. 3. Conducts systematic evaluation of 30+ models, revealing significant performance gaps and demonstrating that reasoning-specialized models consistently outperform general-purpose models.",
      "summary": "This paper introduces the Korean Canonical Legal Benchmark (KCL) to evaluate language models' legal reasoning ability without relying on memorized domain knowledge, by providing aligned precedents for each question. The benchmark includes multiple-choice and essay components with automated rubrics. Evaluation shows large performance gaps, especially in essay tasks, and that reasoning-specialized models outperform general ones.",
      "mindmap": "graph TB\n        Root[”Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of LLMs' Legal Reasoning Capabilities”] --> Problem[”核心问题/Problem: Assessing legal reasoning independently of domain knowledge is challenging”]\n        Root --> Method[”主要方法/Method: Introduce KCL benchmark with precedent-aligned questions and automated rubrics”]\n        Root --> Results[”关键结果/Results: Large performance gaps exist; reasoning-specialized models outperform general ones”]"
    },
    {
      "title": "Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time",
      "authors": "Zhenyu Zhang, Xiaoxia Wu, Zhongzhu Zhou, Qingyang Wu, Yineng Zhang, Pragaash Ponnusamy, Harikaran Subbaraj, Jue Wang, Shuaiwen Leon Song, Ben Athiwaratkun",
      "institution": "University of Texas at Austin, Together AI, University of Sydney",
      "link": "https://arxiv.org/pdf/2512.24574",
      "code": "https://github.com/togethercomputer/CREST",
      "tags": [
        "llm inference",
        "chain-of-thought reasoning",
        "attention heads",
        "test-time intervention",
        "computational efficiency",
        "reasoning steering"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7de1babf1bde06083c19ff84ab24d16f7280ee2cd3e28ae548f08be7f95a5882_w640_q70.webp",
      "contributions": "1. Identified specialized attention heads in LLMs that correlate with distinct cognitive reasoning behaviors (e.g., verification, backtracking). 2. Proposed CREST, a training-free method for Cognitive REasoning Steering at Test-time, which involves offline calibration to find steering vectors and inference-time rotation to suppress unproductive reasoning. 3. Demonstrated that CREST improves reasoning accuracy and reduces token usage across diverse benchmarks, offering a pathway to faster and more reliable LLM inference.",
      "summary": "This paper addresses the inefficiency and instability of long chain-of-thought reasoning in LLMs, which leads to high latency and alternating underthinking/overthinking. The authors propose CREST, a training-free method that identifies and steers specific attention heads at test-time to suppress unproductive cognitive behaviors. The method improves accuracy by up to 17.5% and reduces token usage by 37.6%, enabling faster and more reliable reasoning.",
      "mindmap": "graph TB\n        A[Understanding and Steering the Cognitive Behaviors of Reasoning Models at Test-Time] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLM推理轨迹低效且不稳定/Inefficient & Unstable LLM Reasoning Trajectories]\n        B1 --> B2[过度思考与思考不足/Overthinking & Underthinking]\n        B1 --> B3[高延迟与高令牌消耗/High Latency & Token Usage]\n        C --> C1[识别与认知行为相关的注意力头/Identify Cognitive Attention Heads]\n        C --> C2[提出CREST方法: 测试时认知推理引导/Propose CREST: Test-time Cognitive REasoning Steering]\n        C2 --> C3[离线校准获取引导向量/Offline Calibration for Steering Vectors]\n        C2 --> C4[推理时旋转隐藏表示/Inference-time Representation Rotation]\n        D --> D1[准确率显著提升/Accuracy Improved Up to 17.5%]\n        D --> D2[令牌使用大幅减少/Token Usage Reduced by 37.6%]\n        D --> D3[实现更快更可靠的推理/Enables Faster, More Reliable Reasoning]"
    },
    {
      "title": "Recursive Language Models",
      "authors": "Alex L. Zhang, Tim Kraska, Omar Khattab",
      "institution": "MIT CSAIL",
      "link": "https://arxiv.org/pdf/2512.24601",
      "code": null,
      "tags": [
        "llm inference",
        "recursive language models",
        "long-context processing",
        "inference-time scaling",
        "context condensation",
        "out-of-core algorithms"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2b76e3870cfbc09a08f87a31e423d89e08fb4d1e100fa580e4e6b58754309af5_w640_q70.webp",
      "contributions": "1. Proposes Recursive Language Models (RLMs), a general inference strategy that allows LLMs to programmatically examine, decompose, and recursively call themselves over long prompts. 2. Demonstrates that RLMs can handle inputs up to two orders of magnitude beyond standard model context windows. 3. Shows RLMs outperform base LLMs and existing long-context methods across diverse tasks while maintaining comparable or lower cost per query.",
      "summary": "The paper addresses the problem of LLMs struggling with arbitrarily long prompts due to limited context windows and context rot. It introduces Recursive Language Models (RLMs), an inference-time method that treats long prompts as an external environment, enabling recursive decomposition and processing. The results show RLMs effectively scale to inputs far beyond standard context limits and outperform baseline approaches in quality and cost.",
      "mindmap": "graph TB\n        A[Recursive Language Models] --> B[核心问题/Problem: LLMs have limited context lengths and suffer from context rot with long prompts]\n        A --> C[主要方法/Method: Recursive Language Models (RLMs) treat long prompts as an external environment, allowing programmatic examination and recursive self-calls]\n        A --> D[关键结果/Results: RLMs handle inputs up to 100x beyond context windows, outperform base LLMs and long-context scaffolds, with comparable or cheaper cost]"
    },
    {
      "title": "Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models",
      "authors": "Junru Lu, Jiarui Qin, Lingfeng Qiao, Yinghui Li, Xinyi Dai, Bo Ke, Jianfeng He, Ruizhi Qiao, Di Yin, Xing Sun, Yunsheng Wu, Yinsong Liu, Shuangyin Liu, Mingkong Tang, Haodong Lin, Jiayi Kuang, Fanxu Meng, Xiaojuan Tang, Yunjia Xi, Junjie Huang, Haotong Yang, Zhenyi Shen, Yangning Li, Qianwen Zhang, Yifei Yu, Siyu An, Junnan Dong, Qiufeng Wang, Jie Wang, Keyu Chen, Wei Wen, Taian Guo, Zhifeng Shen, Daohai Yu, Jiahao Li, Ke Li, Zongyi Li, Xiaoyu Tan",
      "institution": "Tencent (inferred from \"Youtu-LLM Team\", code repository URL, and Hugging Face collection)",
      "link": "https://arxiv.org/pdf/2512.24618",
      "code": "https://github.com/TencentCloudADP/youtu-tip/youtu-llm",
      "tags": [
        "language modeling",
        "Multi-Latent Attention (MLA)",
        "STEM-oriented vocabulary",
        "Commonsense-STEM-Agent curriculum",
        "agentic mid-training",
        "long-context reasoning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f514e6cca418a1474a2cb6b11d79c745aa9a14b34387f03f4838426b14afaf3f_w640_q70.webp",
      "contributions": "1. Introduces a compact Multi-Latent Attention (MLA) architecture with a STEM-oriented vocabulary to support 128k context windows for efficient long-context reasoning. 2. Proposes a principled \"Commonsense-STEM-Agent\" multi-stage pre-training curriculum using an 11T token corpus to cultivate deep cognitive abilities. 3. Develops scalable agentic mid-training with diverse synthetic trajectories for math, coding, and tool-use to internalize planning and reflection behaviors.",
      "summary": "The paper introduces Youtu-LLM, a 1.96B parameter lightweight language model pre-trained from scratch with a novel architecture and a staged curriculum focusing on commonsense, STEM, and agentic data. This approach enables the model to achieve state-of-the-art performance for sub-2B models, demonstrating strong native agentic capabilities and competitive general performance against larger models.",
      "mindmap": "graph TB\n        A[Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[轻量模型缺乏原生智能体能力/Lightweight models lack native agentic capabilities]\n        C --> C1[紧凑架构与长上下文支持/Compact Architecture with Long-Context Support]\n        C --> C2[分阶段训练课程/Principled Multi-Stage Curriculum]\n        C --> C3[可扩展的智能体中期训练/Scalable Agentic Mid-training]\n        C1 --> C1a[多潜在注意力 (MLA) / Multi-Latent Attention (MLA)]\n        C1 --> C1b[STEM导向词表/STEM-oriented Vocabulary]\n        C2 --> C2a[常识-STEM-智能体课程/Commonsense-STEM-Agent Curriculum]\n        C2 --> C2b[11T 令牌数据/11T Token Corpus]\n        C3 --> C3a[多样化轨迹合成/Diverse Trajectory Synthesis]\n        C3 --> C3b[数学、编码、工具使用/Math, Coding, Tool-use]\n        D --> D1[在 sub-2B 模型中达到 SOTA/Achieves SOTA for sub-2B LLMs]\n        D --> D2[在智能体任务上显著超越基线/Significantly surpasses baselines on agent tasks]\n        D --> D3[展示轻量模型的强内在能力/Demonstrates strong intrinsic agentic capabilities in lightweight models]"
    },
    {
      "title": "Do Large Language Models Know What They Are Capable Of?",
      "authors": "Casey O. Barkan, Sid Black, Oliver Sourbut",
      "institution": "RAND Corporation, UK AI Security Institute, The Future of Life Foundation",
      "link": "https://arxiv.org/pdf/2512.24661",
      "code": null,
      "tags": [
        "llm evaluation",
        "in-advance confidence",
        "overconfidence",
        "capability awareness",
        "decision-making",
        "agentic tasks"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c758274cef27c9ad79258c27a063b8420cef801a9f25ff7610a7c4c12509a926_w640_q70.webp",
      "contributions": "1. Evaluates LLMs' in-advance confidence and its impact on decision-making in costly-failure scenarios, a less studied area compared to after-the-fact calibration. 2. Investigates how LLMs' confidence and overconfidence evolve during multi-step agentic tasks and with in-context failure experiences. 3. Demonstrates that while LLMs' decisions are rational given their self-estimates, their systematic overconfidence leads to poor task pursuit decisions, highlighting a lack of capability awareness.",
      "summary": "This paper investigates whether large language models (LLMs) can accurately predict their own success on tasks, especially when failure is costly. It evaluates their in-advance confidence, how it changes during multi-step tasks and with in-context failure, and its impact on decision-making. The main finding is that current LLMs are generally overconfident, which impairs their decision-making despite rational behavior based on their flawed self-assessments, indicating a lack of self-awareness of their capabilities.",
      "mindmap": "graph TB\n        A[Do Large Language Models Know What They Are Capable Of?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs能否预测自身任务成功率?<br/>Can LLMs predict their task success?]\n        B --> B2[失败成本高时如何决策?<br/>How to decide when failure is costly?]\n        C --> C1[评估事前置信度<br/>Evaluate in-advance confidence]\n        C --> C2[分析多步骤任务中的信心变化<br/>Analyze confidence change in multi-step tasks]\n        C --> C3[研究上下文失败经验的影响<br/>Study impact of in-context failure]\n        D --> D1[LLMs普遍过度自信<br/>LLMs are generally overconfident]\n        D --> D2[新/大模型判别力未显著提升<br/>Newer/larger models don't have greater discriminatory power]\n        D --> D3[部分模型能从失败中学习<br/>Some models learn from failure]\n        D --> D4[决策理性但估计过于乐观<br/>Decisions rational but estimates overly optimistic]"
    },
    {
      "title": "R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory",
      "authors": "Maoyuan Li, Zhongsheng Wang, Haoyuan Li, Jiamou Liu",
      "institution": "University of Auckland, Wuhan College of Communication",
      "link": "https://arxiv.org/pdf/2512.24684",
      "code": "https://anonymous.4open.science/r/R-debater-E87F/",
      "tags": [
        "computational argumentation",
        "retrieval-augmented generation",
        "argumentative memory",
        "multi-turn debate",
        "agentic framework",
        "rhetorical grounding"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/987d8c7f9f1e27feb6f7eff24aacab0f5dd1eb3b83c76e27f254c97c97b4c0b3_w640_q70.webp",
      "contributions": "1. Proposes R-Debater, a novel agentic framework for multi-turn debate generation grounded in the concept of \"argumentative memory\" from rhetoric and memory studies. 2. Integrates a debate knowledge base for retrieving evidence and prior arguments with a role-based agent to ensure stance consistency and coherent multi-turn composition. 3. Demonstrates superior performance over strong LLM baselines in both single-turn and multi-turn debate tasks through automated metrics (InspireScore, Debatrix) and human evaluation with experienced debaters.",
      "summary": "The paper presents R-Debater, a framework that generates multi-turn debates by retrieving and adapting arguments from a knowledge base (\"argumentative memory\") using a role-based agent. Evaluated on ORCHID debates, it outperforms LLM baselines in producing more consistent, evidence-grounded, and coherent debates across turns.",
      "mindmap": "graph TB\n        A[R-Debater: Retrieval-Augmented Debate Generation] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: LLMs generate fluent but shallow, ungrounded debates with weak stance fidelity]\n        C[主要方法/Method: Agentic framework with argumentative memory for retrieval & role-based utterance composition]\n        D[关键结果/Results: Higher scores than LLM baselines; more faithful, stance-aligned, coherent debates]"
    },
    {
      "title": "MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models",
      "authors": "Wenzhe Li, Shujian Zhang, Wenxuan Zhou, John Lambert, Chi Jin, Andrew Hard, Rajiv Mathews, Lun Wang",
      "institution": "Princeton University, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.24693",
      "code": null,
      "tags": [
        "reward modeling",
        "multi-turn reward model",
        "data augmentation",
        "instruction contrast",
        "preference learning",
        "conversational AI"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e585f0fe2b96110399073cec36c18e1459439f39fdd0ff201f3bbb2378ee4ed7_w640_q70.webp",
      "contributions": "1. Identifies a key limitation in standard preference datasets for training multi-turn reward models, noting their focus on single-turn contrasts is insufficient. 2. Proposes MUSIC, an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs with differences spanning multiple turns. 3. Demonstrates empirically that a reward model trained with MUSIC-augmented data outperforms baselines on multi-turn evaluation and maintains performance on single-turn benchmarks.",
      "summary": "The paper addresses the challenge of evaluating multi-turn conversations by proposing MUSIC, an unsupervised data augmentation method for training multi-turn reward models. MUSIC creates contrastive examples with differences across multiple turns, which provides a stronger training signal. The resulting reward model shows improved alignment with advanced LLM judges on multi-turn dialogues without sacrificing single-turn performance.",
      "mindmap": "graph TB\n        Root[”MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models”] --> Problem[”核心问题/Problem: Evaluating multi-turn conversations is challenging and costly; standard single-turn contrast datasets are insufficient.”]\n        Root --> Method[”主要方法/Method: Proposes MUSIC, an unsupervised data augmentation strategy to synthesize multi-turn contrastive pairs.”]\n        Root --> Results[”关键结果/Results: MUSIC-augmented RM outperforms baselines on multi-turn evaluation and maintains single-turn performance.”]"
    },
    {
      "title": "BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature",
      "authors": "Sibo Wei, Peng Chen, Lifeng Dong, Yin Luo, Lei Wang, Peng Zhang, Wenpeng Lu, Jianbin Guo, Hongjun Yang, Dajun Zeng",
      "institution": "Beijing Wenge Technology Co., Ltd, China Academy of Chinese Medical Sciences, Institute of Automation, Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.24733",
      "code": "https://github.com/DYJG-research/BIOME-Bench/",
      "tags": [
        "biomedical text mining",
        "multi-omics",
        "pathway enrichment",
        "large language models",
        "benchmark",
        "biomolecular interaction"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfe5bd2d9fd13eb61c8aa2f4136960e60693b10732d1462bb1b83a8304eb2997_w640_q70.webp",
      "contributions": "1. Introduces BIOME-Bench, a novel benchmark for evaluating LLMs on biomolecular interaction inference and multi-omics pathway mechanism elucidation., 2. Proposes a rigorous four-stage workflow for constructing the benchmark and develops specific evaluation protocols for the two core tasks., 3. Conducts comprehensive experiments showing current LLMs' substantial deficiencies in fine-grained relation distinction and faithful mechanistic explanation generation.",
      "summary": "This paper introduces BIOME-Bench, a benchmark designed to evaluate large language models on two key tasks in multi-omics analysis: inferring biomolecular interactions and elucidating pathway mechanisms from scientific literature. The benchmark is constructed via a rigorous workflow and includes specific evaluation protocols. The authors' experiments reveal that current state-of-the-art models still struggle significantly with these tasks, highlighting a need for improvement.",
      "mindmap": "graph TB\n        Root[BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation]\n        Root --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[缺乏标准评估/Lack of standardized benchmark]\n        Problem --> P2[评估局限于小数据集/Evaluation confined to small datasets]\n        Method --> M1[构建BIOME-Bench/Build BIOME-Bench]\n        Method --> M2[四阶段工作流/Four-stage workflow]\n        Method --> M3[评估两个核心任务/Evaluate two core tasks]\n        Results --> R1[模型存在显著缺陷/Models exhibit substantial deficiencies]\n        Results --> R2[难以区分细粒度关系/Struggle with fine-grained relations]\n        Results --> R3[难以生成可靠解释/Struggle to generate faithful explanations]"
    },
    {
      "title": "Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models",
      "authors": "Ákos Prucs, Márton Csutora, Mátyás Antal, Márk Marosi",
      "institution": "E-Group Research, Budapest University of Technology and Economics",
      "link": "https://arxiv.org/pdf/2512.24776",
      "code": null,
      "tags": [
        "llm inference",
        "Pareto frontier",
        "test-time compute",
        "Mixture of Experts (MoE)",
        "Chain-of-Thought (CoT)",
        "reasoning benchmarks"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d5a9f81e306448bd700214cb119ef785bd34ba4a396aa5b35650cc485b74caa_w640_q70.webp",
      "contributions": "1. Conducted a test-time-compute aware evaluation of open-source LLMs, mapping their Pareto frontiers on reasoning benchmarks. 2. Identified Mixture of Experts (MoE) architecture as a strong candidate for balancing performance and efficiency. 3. Demonstrated a saturation point for inference-time compute, beyond which accuracy gains diminish.",
      "summary": "This paper addresses the overlooked computational cost of generating long reasoning sequences in LLMs. It evaluates open-source LLMs by mapping their compute-accuracy Pareto frontiers and finds that Mixture of Experts models offer a good efficiency-performance trade-off, while also identifying a saturation point for inference-time compute.",
      "mindmap": "graph TB\n        Root[”Compute-Accuracy Pareto Frontiers for Open-Source Reasoning Large Language Models”] --> Problem[”核心问题/Problem: Overlooked computational burden of long reasoning sequences in LLMs”]\n        Root --> Method[”主要方法/Method: Test-time-compute aware evaluation & Pareto frontier mapping”]\n        Root --> Results[”关键结果/Results: MoE balances efficiency; Compute saturation point exists”]"
    },
    {
      "title": "Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection",
      "authors": "Mohammad Zia Ur Rehman, Velpuru Navya, Sanskar, Shuja Uddin Qureshi, Nagendra Kumar",
      "institution": "Indian Institute of Technology Indore, Shri Govindram Seksaria Institute of Technology and Science, Indore",
      "link": "https://arxiv.org/pdf/2512.24772",
      "code": null,
      "tags": [
        "mental health detection",
        "semi-supervised learning",
        "ensemble learning",
        "pseudo-labeling",
        "multilingual",
        "uncertainty estimation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/64615e1e795d40f008be7ac94e30d5a04c99243dcb00282015a4513c137ecd78_w640_q70.webp",
      "contributions": "1. Proposed Semi-SMDNet, a semi-supervised framework combining teacher-student pseudo-labeling, ensemble learning, and data augmentation for multilingual depression detection. 2. Introduced an uncertainty-based threshold to filter low-confidence pseudo-labels and a confidence-weighted training method to focus on reliable samples, improving robustness and stability. 3. Demonstrated the framework's effectiveness across Arabic, Bangla, English, and Spanish datasets, significantly reducing the performance gap between high-resource and low-resource settings.",
      "summary": "The paper addresses the challenge of detecting depression from multilingual social media text where annotated data is scarce. It proposes a semi-supervised ensemble teacher framework (Semi-SMDNet) that uses uncertainty-aware pseudo-labeling and confidence-weighted training to improve robustness. Experiments on four language datasets show the method consistently outperforms baselines and is suitable for scalable, cross-language mental health monitoring.",
      "mindmap": "graph TB\n        A[Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[多语言社交媒体文本中的抑郁症检测/Depression detection in multilingual social media text]\n        B --> B2[标注数据稀缺/Lack of annotated data]\n        B --> B3[语言风格多样与表达非正式/Diverse language styles & informal expression]\n        C --> C1[半监督集成教师框架/Semi-supervised ensemble teacher framework (Semi-SMDNet)]\n        C --> C2[不确定性感知伪标签/Uncertainty-aware pseudo-labeling]\n        C --> C3[置信度加权训练/Confidence-weighted training]\n        D --> D1[在阿拉伯语、孟加拉语、英语和西班牙语数据集上超越基线/Outperforms baselines on Arabic, Bangla, English, Spanish datasets]\n        D --> D2[减少高低资源场景性能差距/Reduces performance gap between high- and low-resource settings]\n        D --> D3[适用于可扩展的跨语言心理健康监测/Suitable for scalable cross-language mental health monitoring]"
    },
    {
      "title": "Practising responsibility: Ethics in NLP as a hands-on course",
      "authors": "Malvina Nissim, Viviana Patti, Beatrice Savoldi",
      "institution": "University of Groningen, University of Turin, Fondazione Bruno Kessler",
      "link": "https://arxiv.org/pdf/2512.24825",
      "code": null,
      "tags": [
        "ethics in nlp",
        "ethics education",
        "active learning",
        "curriculum development",
        "hands-on activities",
        "learning by teaching"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad8d866d1d641ab747e97be881ac0eec09fdae4762445938b33c32d5a452c3e5_w640_q70.webp",
      "contributions": "1. Introduction of a dedicated course \"Ethical Aspects in NLP\" designed to integrate ethics into NLP education, 2. Development of a pedagogical approach based on active learning, interactive sessions, hands-on activities, and \"learning by teaching\" methods, 3. Creation and refinement of the course over four years, adapting it across different institutions, educational levels, and interdisciplinary backgrounds, yielding reusable teaching materials and student-made educational products.",
      "summary": "The paper addresses the challenge of integrating ethical considerations into NLP education by proposing a hands-on course. The method employs active learning through interactive sessions, practical activities, and \"learning by teaching\". The main conclusion is that this approach successfully fosters critical thinking and produces reusable educational resources, providing a model for educators to incorporate social impact into curricula.",
      "mindmap": "graph TB\n        Root(”Practising responsibility: Ethics in NLP as a hands-on course”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”NLP系统普及/NLP systems pervasive”)\n        Problem --> P2(”伦理教育挑战/Ethics education challenges”)\n        Method --> M1(”主动学习/Active learning”)\n        Method --> M2(”实践与互动/Hands-on & interactive”)\n        Method --> M3(”以教促学/Learning by teaching”)\n        Results --> R1(”课程优化与适应/Course refined & adapted”)\n        Results --> R2(”产出可复用产品/Reusable products created”)"
    },
    {
      "title": "Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability",
      "authors": "Yanan Long",
      "institution": "StickFlux Labs, University of Chicago",
      "link": "https://arxiv.org/pdf/2512.24842",
      "code": null,
      "tags": [
        "mechanistic interpretability",
        "causal abstraction",
        "interchange intervention",
        "automatic circuit discovery",
        "invariance",
        "multilingual models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c4f8b0a487ba28d3349ff7d744b0fdbcdbab78c52f6689b7eba6cbeae2812a4_w640_q70.webp",
      "contributions": "1. Proposes triangulation, a formal acceptance rule for mechanistic explanations requiring necessity, sufficiency, and invariance across reference families. 2. Grounds the triangulation rule in causal abstraction theory by framing it as an approximate transformation score over interchange interventions. 3. Introduces a comparative experimental protocol to evaluate mechanistic claims across multiple model families, language pairs, and tasks.",
      "summary": "The paper proposes \"triangulation,\" a causal standard for evaluating mechanistic explanations in multilingual language models. It requires a proposed circuit to be necessary, sufficient, and invariant across meaning-preserving variations like different languages. This method filters out spurious circuits that pass single-environment tests but fail under cross-lingual scrutiny.",
      "mindmap": "graph TB\n        A[Triangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Multilingual models behave unpredictably; need causal, cross-referenced explanations]\n        C[主要方法/Method: Triangulation acceptance rule (necessity, sufficiency, invariance) via circuit discovery & interchange interventions]\n        D[关键结果/Results: Provides falsifiable standard; filters spurious circuits failing cross-lingual invariance]"
    },
    {
      "title": "PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI",
      "authors": "Srija Mukhopadhyay, Sathwik Reddy, Shruthi Muthukumar, Jisun An, Ponnurangam Kumaraguru",
      "institution": "International Institute of Information Technology Hyderabad, Indiana University",
      "link": "https://arxiv.org/pdf/2512.24848",
      "code": null,
      "tags": [
        "Privacy protections",
        "PrivacyBench",
        "Retrieval-Augmented Generation (RAG)",
        "secret leakage",
        "privacy-aware prompt",
        "privacy-by-design"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7685e487e221610623a5fd5b2084368051b6218a6804a6749e97cc93aef26acb_w640_q70.webp",
      "contributions": "1. Introduces PrivacyBench, a novel conversational benchmark with socially grounded datasets containing embedded secrets for evaluating privacy in AI assistants. 2. Provides a multi-turn conversational evaluation framework to measure secret preservation capabilities of personalized AI systems. 3. Empirically demonstrates that current RAG-based assistants leak secrets in up to 26.56% of interactions and identifies a critical architectural flaw where the retrieval mechanism is a single point of failure for privacy.",
      "summary": "The paper introduces PrivacyBench, a benchmark to evaluate privacy leakage in personalized AI agents that access a user's digital footprint. Testing shows RAG-based assistants leak secrets frequently, and while privacy-aware prompts help, the fundamental architecture is unsafe, highlighting the need for structural, privacy-by-design solutions.",
      "mindmap": "graph TB\n        A[PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Personalized AI agents risk exposing sensitive user data from their digital footprint.]\n        C[主要方法/Method: Introduce PrivacyBench benchmark with datasets containing secrets and multi-turn conversational evaluation.]\n        D[关键结果/Results: RAG assistants leak secrets; privacy prompts partially mitigate; need for privacy-by-design safeguards.]"
    },
    {
      "title": "Big AI is accelerating the metacrisis: What can we do?",
      "authors": "Steven Bird",
      "institution": "Charles Darwin University",
      "link": "https://arxiv.org/pdf/2512.24863",
      "code": null,
      "tags": [
        "ethics & society",
        "metacrisis",
        "language engineers",
        "human flourishing",
        "planetary boundaries",
        "technofeudalism"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2352136b878f355e9ebcad11726708c80426973daa2249fba0b79ba62b81b583_w640_q70.webp",
      "contributions": "1. Identifies and critiques the role of \"Big AI\" and language engineers in accelerating converging global crises (ecological, meaning, language). 2. Highlights the ethical conflict between professional obligations (e.g., ACL Code of Ethics) and the harms caused by current NLP/AI development practices. 3. Proposes a paradigm shift for NLP, advocating for a future centered on human flourishing and amplifying social networks rather than scaling through large, polluting models.",
      "summary": "This paper argues that the current trajectory of \"Big AI,\" particularly in NLP, is accelerating a global metacrisis. It critiques the field's focus on scalability and value-neutral technology development, which benefits powerful interests at the expense of the public good and the planet. The paper concludes by urgently calling for an alternative, life-affirming future for NLP centered on human flourishing.",
      "mindmap": "graph TB\n        A[Big AI is accelerating the metacrisis: What can we do?] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Big AI加速生态、意义和语言危机/Big AI accelerates ecological, meaning, and language crises]\n        B --> B2[语言工程师的伦理困境/Ethical dilemma of language engineers]\n        C --> C1[批判当前可扩展性叙事/Critique current scalability narrative]\n        C --> C2[呼吁探索替代方案/Call to explore alternatives]\n        D --> D1[需要以人类繁荣为中心的未来/NLP future must center human flourishing]\n        D --> D2[利用集体智慧设计生命肯定的NLP/Design life-affirming NLP with collective intelligence]"
    },
    {
      "title": "Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements",
      "authors": "Yiming Liang, Yizhi Li, Yantao Du, Ge Zhang, Jiayi Zhou, Yuchen Wu, Yinzhu Piao, Denghui Cao, Tong Sun, Ziniu Li, Li Du, Bo Lei, Jiaheng Liu, Chenghua Lin, Zhaoxiang Zhang, Wenhao Huang, Jiajun Zhang",
      "institution": "University of Chinese Academy of Sciences, Chinese Academy of Sciences, Bytedance, Nanjing University, M-A-P, BAAI, The University of Manchester",
      "link": "https://arxiv.org/pdf/2512.24867",
      "code": "https://encyclo-k.github.io",
      "tags": [
        "llm evaluation",
        "benchmark",
        "knowledge statements",
        "dynamic composition",
        "data contamination",
        "multi-knowledge assessment"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bf5e4785262ae916ad666afc0e0e212833641ae7597f48f69f148b35cfc4807b_w640_q70.webp",
      "contributions": "1. Proposes a novel statement-based benchmark (Encyclo-K) that uses knowledge statements as the fundamental curation unit instead of pre-defined questions., 2. Introduces a dynamic evaluation method where questions are composed by randomly sampling multiple statements at test time, mitigating data contamination and enabling periodic refresh., 3. Demonstrates a scalable, low-cost annotation process that requires only formatting verification, not domain expertise, while enabling comprehensive multi-knowledge assessment per question.",
      "summary": "The paper introduces Encyclo-K, a new benchmark for evaluating LLMs that constructs questions by dynamically combining multiple knowledge statements extracted from textbooks at test time. This approach addresses key limitations of existing benchmarks, such as data contamination and single-point assessment. Experiments show it poses a significant challenge to state-of-the-art models, with top accuracy at only 62.07%, validating its effectiveness for assessing comprehensive, multi-statement understanding.",
      "mindmap": "graph TB\n        A[Encyclo-K: Evaluating LLMs with Dynamically Composed Knowledge Statements] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>现有基准的局限性/Limitations of Existing Benchmarks]\n        C[主要方法/Method<br>基于知识陈述的动态组合/Dynamic Composition from Knowledge Statements]\n        D[关键结果/Results<br>强区分性，模型表现梯度分布/Strong Discriminative Power, Gradient Performance]\n        B --> B1[数据污染/Data Contamination]\n        B --> B2[单知识点评估/Single-Knowledge Assessment]\n        B --> B3[高标注成本/High Annotation Cost]\n        C --> C1[从权威教材提取陈述/Extract Statements from Textbooks]\n        C --> C2[测试时随机组合/Compose Questions at Test Time]\n        D --> D1[GPT-5.1准确率62.07%/GPT-5.1 Accuracy 62.07%]\n        D --> D2[推理模型16.04%-62.07%/Reasoning Models 16.04%-62.07%]\n        D --> D3[聊天模型9.71%-50.40%/Chat Models 9.71%-50.40%]"
    },
    {
      "title": "Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem",
      "authors": "Weixun Wang, XiaoXiao Xu, Wanhe An, Fangwen Dai, Wei Gao, Yancheng He, Ju Huang, Qiang Ji, Hanqi Jin, Xiaoyang Li, Yang Li, Zhongwen Li, Shirong Lin, Jiashun Liu, Zenan Liu, Tao Luo, Dilxat Muhtar, Yuanbin Qu, Jiaqiang Shi, Qinghui Sun, Yingshui Tan, Hao Tang, Runze Wang, Yi Wang, Zhaoguo Wang, Yanan Wu, Shaopan Xiong, Binchen Xu, Xander Xu, Yuchi Xu, Qipeng Zhang, Xixia Zhang, Haizhou Zhao, Jie Zhao, Shuaibing Zhao, Baihui Zheng, Jianhui Zheng, Suhang Zheng, Yanni Zhu, Mengze Cai, Kerui Cao, Xitong Chen, Yue Dai, Lifan Du, Tao Feng, Tao He, Jin Hu, Yijie Hu, Ziyu Jiang, Cheng Li, Xiang Li, Jing Liang, Chonghuan Liu, ZhenDong Liu, Haodong Mi, Yanhu Mo, Junjia Ni, Shixin Pei, Jingyu Shen, XiaoShuai Song, Cecilia Wang, Chaofan Wang, Kangyu Wang, Pei Wang, Tao Wang, Wei Wang, Ke Xiao, Mingyu Xu, Tiange Xu, Nan Ya, Siran Yang, Jianan Ye, Yaxing Zang, Duo Zhang, Junbo Zhang, Boren Zheng, Wanxi Deng, Ling Pan, Lin Qu, Wenbo Su, Jiamang Wang, Wei Wang, Hu Wei, Minggang Wu, Cheng Yu, Bing Zhao, Zhicheng Zheng, Bo Zheng",
      "institution": "ROCK & ROLL & IFLOW & DT Joint Team (Inferred from the author list and likely represents a collaboration, but no specific university or company is named. The domain is unclear from the provided text.)",
      "link": "https://arxiv.org/pdf/2512.24873",
      "code": null,
      "tags": [
        "agent system",
        "Agentic Learning Ecosystem (ALE)",
        "Interaction-based Policy Alignment (IPA)",
        "Terminal Bench Pro",
        "post-training",
        "trajectory generation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9408c7a8de1b2fe7261d28a9d7eb1d3df3afe81fc17a03cc9b2c09e332ac8782_w640_q70.webp",
      "contributions": "1. Introduces the Agentic Learning Ecosystem (ALE), an end-to-end infrastructure for developing agent LLMs, comprising the ROLL post-training framework, the ROCK sandbox manager, and the iFlow CLI agent framework. 2. Proposes a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks to improve long-horizon training stability. 3. Releases the ROME agent model, trained on over one million trajectories, and introduces the Terminal Bench Pro benchmark with improved scale and contamination control for rigorous evaluation.",
      "summary": "This paper addresses the lack of a principled, end-to-end ecosystem for developing agentic LLMs by introducing the Agentic Learning Ecosystem (ALE). ALE streamlines the agent development pipeline, and the authors use it to build and release the ROME agent model, which demonstrates strong performance on benchmarks, validating the effectiveness of their infrastructure.",
      "mindmap": "graph TB\n        A[Let It Flow: Agentic Crafting on Rock and Roll<br/>构建ROME模型于开放智能体学习生态中] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>Open-source community lacks a principled, end-to-end ecosystem for agent LLM development.] --> B1[阻碍/Block<br/>Hinders practical development and production adoption of agents.]\n        C[主要方法/Method<br/>Introduce Agentic Learning Ecosystem (ALE)] --> C1[组件/Components<br/>ROLL (post-training), ROCK (sandbox), iFlow CLI (agent framework)]\n        C --> C2[模型/Model<br/>Release ROME agent trained on 1M+ trajectories]\n        C --> C3[算法/Algorithm<br/>Propose Interaction-based Policy Alignment (IPA)]\n        D[关键结果/Results<br/>ROME achieves strong benchmark performance.] --> D1[基准/Benchmarks<br/>24.72% on Terminal-Bench 2.0, 57.40% on SWE-bench Verified]\n        D --> D2[新基准/New Benchmark<br/>Introduce Terminal Bench Pro for rigorous evaluation.]"
    },
    {
      "title": "mHC: Manifold-Constrained Hyper-Connections",
      "authors": "Zhenda Xie, Yixuan Wei, Huanqi Cao, Chenggang Zhao, Chengqi Deng, Jiashi Li, Damai Dai, Huazuo Gao, Jiang Chang, Liang Zhao, Shangyan Zhou, Zhean Xu, Zhengyan Zhang, Wangding Zeng, Shengding Hu, Yuqing Wang, Jingyang Yuan, Lean Wang, Wenfeng Liang",
      "institution": "DeepSeek-AI",
      "link": "https://arxiv.org/pdf/2512.24880",
      "code": null,
      "tags": [
        "llm training",
        "Hyper-Connections",
        "residual connection",
        "identity mapping",
        "manifold constraint",
        "training stability"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7219c6945df5dfb5231231a93ccf8e3cf155e38527f2c4071501eaae05a8b7ac_w640_q70.webp",
      "contributions": "1. Proposes Manifold-Constrained Hyper-Connections (mHC), a framework that projects the residual connection space onto a specific manifold to restore the identity mapping property compromised by Hyper-Connections (HC). 2. Incorporates rigorous infrastructure optimization to address the memory access overhead and ensure training efficiency. 3. Demonstrates that mHC enables effective large-scale training with tangible performance improvements and superior scalability, offering a flexible and practical extension of HC.",
      "summary": "The paper identifies that Hyper-Connections (HC), while improving performance, lose the identity mapping property of standard residual connections, leading to training instability and memory overhead. To solve this, the authors propose Manifold-Constrained Hyper-Connections (mHC), which projects HC's connection space onto a manifold to restore identity mapping and includes infrastructure optimizations. Empirical results show mHC is effective for scalable training, offering better performance and stability.",
      "mindmap": "graph TB\n        A[mHC: Manifold-Constrained Hyper-Connections] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[”HC 破坏了恒等映射，导致训练不稳定/HC compromises identity mapping, causing instability”]\n        B --> B2[”HC 带来内存开销/HC incurs memory overhead”]\n        C --> C1[”将残差连接空间投影到特定流形/Project residual space onto a manifold”]\n        C --> C2[”恢复恒等映射属性/Restore identity mapping property”]\n        C --> C3[”结合基础设施优化/Incorporate infrastructure optimization”]\n        D --> D1[”实现可扩展的有效训练/Enables effective training at scale”]\n        D --> D2[”提供性能改进和可扩展性/Offers performance improvements & scalability”]"
    },
    {
      "title": "BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts",
      "authors": "Hengli Li, Zhaoxin Yu, Qi Shen, Chenxi Li, Mengmeng Wang, Tinglang Wu, Yipeng Kang, Yuxuan Wang, Song-Chun Zhu, Zixia Jia, Zilong Zheng",
      "institution": "Peking University (PKU), Beijing Institute for General Artificial Intelligence (BIGAI), Chinese Academy of Sciences (CAS), Beijing University of Posts and Telecommunications (BUPT), Tsinghua University (THU)",
      "link": "https://arxiv.org/pdf/2512.24885",
      "code": null,
      "tags": [
        "strategic dialogue",
        "belief estimation",
        "probabilistic constraints",
        "dialogue acts",
        "adversarial",
        "alignment"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f74e9bdf6a51c0f1ab61ad8d67cba11cf929a7b681e1d4c3a1c8682bf34bb3fe_w640_q70.webp",
      "contributions": "1. Formalizes two core strategic dialogue acts (Adversarial and Alignment) within a game-theoretic framework of beliefs and common knowledge. 2. Proposes a principled mechanism that operationalizes these acts by casting belief estimation as probabilistic constraints on utterance generation. 3. Introduces the BEDA framework, which integrates a world set, a belief estimator, and a conditional generator to select acts and realize utterances consistent with inferred beliefs.",
      "summary": "The paper addresses the gap between accurate belief estimation and its principled use in strategic dialogue generation. It proposes BEDA, a framework that formalizes adversarial and alignment dialogue acts and uses belief estimates as probabilistic constraints to guide utterance generation. The method consistently outperforms strong baselines across adversarial, cooperative, and negotiation settings, demonstrating its effectiveness.",
      "mindmap": "graph TB\n        Root(”BEDA: Belief Estimation as Probabilistic Constraints”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Prior work lacks principled use of beliefs for generation/先前工作缺乏使用信念的机制”)\n        Method --> M1(”Formalizes Adversarial & Alignment acts/形式化对抗与对齐行为”)\n        Method --> M2(”Beliefs as probabilistic constraints/信念作为概率约束”)\n        Method --> M3(”BEDA framework: belief estimator + conditional generator/BEDA框架”)\n        Results --> R1(”Outperforms baselines on CKBG, MF, CaSiNo/在多个设定超越基线”)\n        Results --> R2(”Improves success rates significantly/显著提升成功率”)\n        Results --> R3(”Provides simple, general mechanism/提供简单通用机制”)"
    },
    {
      "title": "Vibe Coding, Interface Flattening",
      "authors": "Hongrui Jin",
      "institution": "University of Amsterdam",
      "link": "https://arxiv.org/pdf/2512.24939",
      "code": null,
      "tags": [
        "human-computer interaction",
        "large language models",
        "interface flattening",
        "vibe coding",
        "Model Context Protocol",
        "symbolic labour"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7d80b187b5915d1a8220a2cb617bff9a959789d5181355291a3d22991715d25_w640_q70.webp",
      "contributions": "1. Proposes a critical framework for understanding \"vibe coding\" as \"interface flattening,\" where distinct modalities converge into a conversational surface while the underlying translation chain thickens. 2. Conducts a materialist reconstruction of the vibe-coding stack, analyzing how remote compute, structured outputs, and protocols like MCP relocate control to model providers. 3. Demonstrates how LLM-mediated development redistributes symbolic power, obscures responsibility, and privatizes competencies, offering a critical lens on the political economy of AI-mediated interaction.",
      "summary": "This paper analyzes the phenomenon of \"vibe coding,\" where software is developed through natural language interaction with LLMs. It conceptualizes this as \"interface flattening,\" arguing that while the user experience appears simplified, the underlying infrastructure and dependencies become more complex and concentrated. The main conclusion is that this apparent democratization of programming creates new dependencies, redistributes power to model providers, and privatizes competencies previously held by the programming community.",
      "mindmap": "graph TB\n        A[Vibe Coding, Interface Flattening] --> B[核心问题/Problem: How to understand the shift in programming via LLMs?]\n        A --> C[主要方法/Method: Critical analysis using media theory & materialist reconstruction of the stack]\n        A --> D[关键结果/Results: Interface flattening obscures complexity, redistributes power, creates new dependencies]"
    },
    {
      "title": "Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline",
      "authors": "Minjun Zhao, Xinyu Zhang, Shuai Zhang, Deyang Li, Ruifeng Shi",
      "institution": "Huawei Poisson Lab",
      "link": "https://arxiv.org/pdf/2512.24933",
      "code": null,
      "tags": [
        "agent system",
        "prompt optimization",
        "multi-step LLM pipeline",
        "Shapley value",
        "text-gradient estimation",
        "dependency modeling"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0120693b7eaf05e640c60779fef913238cda72212cee4971942ac26a248c12d_w640_q70.webp",
      "contributions": "1. Proposes ADOPT, a framework that explicitly models the dependency between each LLM step and the final task outcome for precise text-gradient estimation. 2. Decouples textual gradient estimation from gradient updates, reducing complex multi-prompt optimization to flexible single-prompt optimization steps. 3. Employs a Shapley-based mechanism to adaptively allocate optimization resources across different pipeline steps.",
      "summary": "The paper addresses the challenge of jointly optimizing prompts in multi-step LLM pipelines, where missing step-level supervision and inter-step dependencies make optimization difficult. It proposes ADOPT, an Adaptive Dependency-aware Prompt Optimization framework that models step dependencies for precise gradient estimation and uses a Shapley-based resource allocation mechanism. Experiments show ADOPT is effective and robust, consistently outperforming existing prompt optimization methods.",
      "mindmap": "graph TB\n        Root[ADOPT: Adaptive Dependency-aware Prompt Optimization Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Multi-step LLM pipeline prompt optimization is difficult due to missing supervision and dependencies] --> P1[子问题/Sub-problem: Missing step-level supervision]\n        Problem --> P2[子问题/Sub-problem: Inter-step dependencies]\n        Method[主要方法/Method: ADOPT Framework] --> M1[关键技术/Key Technique: Explicit dependency modeling for text-gradient estimation]\n        Method --> M2[关键技术/Key Technique: Decouples gradient estimation from updates]\n        Method --> M3[关键技术/Key Technique: Shapley-based adaptive resource allocation]\n        Results[关键结果/Results: Effective and robust, outperforms SOTA baselines] --> R1[实验/Experiments: Real-world datasets]\n        Results --> R2[实验/Experiments: Diverse pipeline structures]"
    },
    {
      "title": "Iterative Deployment Improves Planning Skills in LLMs",
      "authors": "Augusto B. Corrêa, Yoav Gelberg, Luckeciano C. Melo, Ilia Shumailov, André G. Pereira, Yarin Gal",
      "institution": "University of Oxford, AI Sequrity Company, UFRGS",
      "link": "https://arxiv.org/pdf/2512.24940",
      "code": null,
      "tags": [
        "reinforcement learning",
        "iterative deployment",
        "implicit reward",
        "data curation",
        "planning",
        "fine-tuning"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8da35d1ea681d386cec51c012c9f81bb54c6876b6c1e632e59874f77690cd1a_w640_q70.webp",
      "contributions": "1. Demonstrates that iterative deployment and fine-tuning on curated user data significantly improves LLM planning skills, including emergent generalization to longer plans. 2. Provides a theoretical analysis showing iterative deployment effectively implements an outer-loop reinforcement learning process with an implicit reward function. 3. Highlights the AI safety implications of this implicit training regime and positions it as an alternative to explicit RL training.",
      "summary": "The paper shows that repeatedly deploying LLMs and fine-tuning them on curated data from previous deployments significantly improves their planning capabilities. This process is analyzed as an implicit form of reinforcement learning, which raises safety concerns due to the undefined reward function and offers an alternative training paradigm based on data curation.",
      "mindmap": "graph TB\n        A[Iterative Deployment Improves Planning Skills in LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM规划能力/LLM Planning Skills]\n        C --> C1[迭代部署与微调/Iterative Deployment & Fine-tuning]\n        C1 --> C2[用户数据筛选/User Data Curation]\n        D --> D1[规划能力提升/Improved Planning Skills]\n        D --> D2[发现隐式RL/Discovering Implicit RL]\n        D2 --> D3[AI安全影响/AI Safety Implications]"
    },
    {
      "title": "RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment",
      "authors": "Chenji Lu, Zhuo Chen, Hui Zhao, Zhenyi Wang, Pengjie Wang, Jian Xu, Bo Zheng",
      "institution": "Taobao & Tmall Group of Alibaba",
      "link": "https://arxiv.org/pdf/2512.24943",
      "code": null,
      "tags": [
        "information retrieval",
        "relevance assessment",
        "benchmark",
        "long-tail",
        "visual salience",
        "e-commerce"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01d0a7f153d6f84b77a35da0a0f62dec9a8af10bfb23f1a8a481697233cbe992_w640_q70.webp",
      "contributions": "1. Proposes RAIR, a comprehensive Chinese benchmark for e-commerce relevance assessment derived from real-world scenarios. 2. Establishes a standardized evaluation framework with universal rules to address the lack of standardized metrics. 3. Introduces a dataset with three specialized subsets (general, long-tail hard, visual salience) to evaluate fundamental, challenging, and multimodal capabilities.",
      "summary": "The paper proposes RAIR, a rule-aware benchmark for e-commerce search relevance assessment, to address the lack of complex and standardized evaluation datasets. It introduces a comprehensive dataset with three subsets to test different model capabilities. Experiments on 14 models show RAIR is challenging, with GPT-5 performing best, and it serves as a new industry benchmark.",
      "mindmap": "graph TB\n        A[RAIR: 一个用于电子商务相关性评估的规则感知基准 / RAIR: A Rule-Aware Benchmark for E-commerce Relevance Assessment]\n        A --> B[核心问题/Problem: 现有基准缺乏复杂性，缺少标准化评估 / Existing benchmarks lack complexity and standardized evaluation]\n        A --> C[主要方法/Method: 提出包含通用、长尾、视觉显著性子集的基准和规则框架 / Propose benchmark with general, long-tail, visual-salience subsets and rule framework]\n        A --> D[关键结果/Results: 对14个模型构成挑战，GPT-5表现最佳，可作为行业基准 / Presents challenge to 14 models, GPT-5 performs best, serves as industry benchmark]"
    },
    {
      "title": "CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with LLM-Judged Refinement",
      "authors": "Wentao Zhang, Tao Fang, Lina Lu, Lifei Wang, Weihe Zhong",
      "institution": "Shandong University of Technology, Macau Millennium College",
      "link": "https://arxiv.org/pdf/2512.24947",
      "code": "https://github.com/CPJ-Agricultural/CPJ-Agricultural-Diagnosis",
      "tags": [
        "vision-language models",
        "LLM-as-a-Judge",
        "training-free",
        "few-shot",
        "explainable AI",
        "agricultural VQA"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/677e58cca4c831f09b054974c399f7092a40a64b068915b259e624f2728ef082_w640_q70.webp",
      "contributions": "1. Proposes a novel Caption-Prompt-Judge (CPJ) framework for training-free, few-shot agricultural pest diagnosis. 2. Introduces an LLM-as-Judge module for iterative refinement of structured, multi-angle image captions to enhance interpretability. 3. Demonstrates significant performance improvements on a benchmark dataset using lightweight models, advancing robust and explainable diagnosis without fine-tuning.",
      "summary": "This paper proposes CPJ, a training-free framework that uses large vision-language models to generate and refine image captions, which are then used to improve agricultural visual question answering. The method significantly boosts disease classification and QA performance on the CDDMBench dataset, providing transparent, evidence-based reasoning without requiring model fine-tuning.",
      "mindmap": "graph TB\n        A[CPJ: Explainable Agricultural Pest Diagnosis] --> B[核心问题/Problem: Existing methods rely on costly fine-tuning and lack explainability under domain shifts.]\n        A --> C[主要方法/Method: CPJ framework uses LVLMs to generate captions, refines them via LLM-as-Judge, and performs caption-informed VQA.]\n        A --> D[关键结果/Results: Significant performance gains (+22.7 pp in classification, +19.5 in QA score) on CDDMBench.]"
    },
    {
      "title": "Classifying long legal documents using short random chunks",
      "authors": "Luis Adrián Cabrera-Diego",
      "institution": "Jus Mundi",
      "link": "https://arxiv.org/pdf/2512.24997",
      "code": null,
      "tags": [
        "document classification",
        "DeBERTa V3",
        "LSTM",
        "random chunks",
        "Temporal",
        "long document processing"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92192ce5f7c11c2d86da5e296a17a8e7ae1b0794ecb76a29cb686c4b5b4f5f12_w640_q70.webp",
      "contributions": "1. A novel legal document classifier architecture combining DeBERTa V3 with an LSTM that processes only 48 randomly selected short chunks (max 128 tokens) per document, enabling efficient handling of long texts. 2. A robust deployment pipeline built using Temporal, a durable execution framework, ensuring reliable and fault-tolerant processing workflows. 3. Demonstrated effective performance on a multilingual legal document dataset with a weighted F-score of 0.898 and quantified processing efficiency (498 seconds per 100 files on CPU).",
      "summary": "This paper addresses the challenge of classifying long legal documents by proposing a model that uses DeBERTa V3 and an LSTM to process only 48 randomly selected short text chunks per document. The method avoids the computational expense of processing full documents with Transformers and is deployed via a reliable Temporal-based pipeline. The system achieves a weighted F-score of 0.898 and processes 100 files in a median time of 498 seconds on CPU.",
      "mindmap": "graph TB\n        A[Classifying long legal documents using short random chunks] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Long legal documents are expensive/slow to process with full Transformers]\n        C[主要方法/Method<br>Classifier: DeBERTa V3 + LSTM on 48 random short chunks (128 tokens max)]\n        D[关键结果/Results<br>Weighted F-score: 0.898, Median time: 498s per 100 files (CPU)]"
    },
    {
      "title": "MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes",
      "authors": "Siddhant Agarwal, Adya Dhuler, Polly Ruhnke, Melvin Speisman, Md Shad Akhtar, Shweta Yadav",
      "institution": "University of Illinois at Chicago, Creighton University, Indraprastha Institute of Information Technology Delhi",
      "link": "https://arxiv.org/pdf/2512.25015",
      "code": null,
      "tags": [
        "multimodal classification",
        "multi-agent collaboration",
        "depressive symptoms identification",
        "multimodal memes",
        "Cognitive Analytic Therapy",
        "large language model"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea612586070aecc51cf0ff34b08e15ac3308fa3b6d60764b6e00c32e3a444b58_w640_q70.webp",
      "contributions": "1. Introduces RESTOREx, a new dataset with LLM-generated and human-annotated explanations for detecting depressive symptoms in memes. 2. Proposes MAMAMemeia, a multi-agent multi-aspect discussion framework based on Cognitive Analytic Therapy (CAT) Competencies for multimodal analysis. 3. Achieves state-of-the-art performance, improving macro-F1 by 7.55% and establishing a new benchmark against over 30 methods.",
      "summary": "This paper addresses the task of identifying depressive symptoms in multimodal memes from social media. It proposes MAMAMemeia, a multi-agent collaborative framework inspired by clinical psychology, and introduces the RESTOREx dataset with explanations. The method achieves a significant 7.55% improvement in macro-F1, setting a new benchmark for this task.",
      "mindmap": "graph TB\n        A[MAMA-Memeia! Multi-Aspect Multi-Agent Collaboration for Depressive Symptoms Identification in Memes] --> B[核心问题/Problem: Identifying depressive symptoms in memes on social media]\n        A --> C[主要方法/Method: Multi-agent multi-aspect framework (MAMAMemeia) based on Cognitive Analytic Therapy, using RESTOREx dataset with LLM/human explanations]\n        A --> D[关键结果/Results: 7.55% macro-F1 improvement over SOTA, new benchmark vs. 30+ methods]"
    },
    {
      "title": "Modeling Language as a Sequence of Thoughts",
      "authors": "Nasim Borazjanizadeh, James McClelland",
      "institution": "Independent Researcher, Stanford University",
      "link": "https://arxiv.org/pdf/2512.25026",
      "code": null,
      "tags": [
        "language modeling",
        "recurrent transformer",
        "thought gestalt",
        "reversal curse",
        "cross-attention",
        "scaling efficiency"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c8e6d868bbc8b6b68328f1680dd184805a29e94d0e7b58137122aad5c0a6e9d_w640_q70.webp",
      "contributions": "1. Introduced the Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels (tokens and sentence-level \"thought\" states). 2. Proposed a unified training scheme where token and sentence representations are generated with the same parameters and a single next-token objective, enabling gradient flow through memory. 3. Demonstrated improved data and parameter efficiency over GPT-2 and better performance on relational direction generalization (e.g., reversal curse).",
      "summary": "The paper addresses the limitations of standard Transformers, which rely on surface-level token statistics and lack globally consistent representations. It proposes the Thought Gestalt model, a recurrent Transformer that generates tokens while cross-attending to a memory of prior sentence-level \"thought\" states, trained with a unified next-token objective. The model shows improved scaling efficiency and reduces errors on relational generalization tasks like the reversal curse.",
      "mindmap": "graph TB\n        Root(”Modeling Language as a Sequence of Thoughts”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Transformer 依赖表层统计/Transformers rely on surface-level statistics”)\n        Problem --> P2(”缺乏全局一致表示/Lack globally consistent representations”)\n        Problem --> P3(”导致逆转诅咒等问题/Leads to issues like reversal curse”)\n        Method --> M1(”提出思想完形模型/Propose Thought Gestalt (TG) model”)\n        Method --> M2(”双层建模: Token + 句子级思想/Two-level modeling: tokens & sentence-level thoughts”)\n        Method --> M3(”循环Transformer + 跨注意力记忆/Recurrent Transformer with cross-attention memory”)\n        Results --> R1(”比GPT-2更高效/More efficient than GPT-2”)\n        Results --> R2(”减少逆转诅咒错误/Reduces reversal curse errors”)\n        Results --> R3(”统一参数与目标训练/Unified parameter & objective training”)"
    },
    {
      "title": "AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted RAG",
      "authors": "Chao Peng, Bin Wang, Zhilei Long, Jinfang Sheng",
      "institution": "Central South University, Yizhi Intelligent (YZInt)",
      "link": "https://arxiv.org/pdf/2512.25052",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "redundancy-aware selection",
        "token-budgeted RAG",
        "greedy selection",
        "submodular optimization",
        "adaptive calibration"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85c85942576679b5e5fe4c0066c0977620d02d122c659a34dfe900bfed59c445_w640_q70.webp",
      "contributions": "1. Proposes AdaGReS, a redundancy-aware context selection framework that optimizes a set-level objective combining query relevance and intra-set redundancy penalties under a token-budget constraint. 2. Introduces a closed-form, instance-adaptive calibration method for the relevance-redundancy trade-off parameter, eliminating manual tuning and adapting to candidate-pool statistics and budget limits. 3. Provides a theoretical analysis showing the proposed objective exhibits ε-approximate submodularity, yielding near-optimality guarantees for the greedy selection algorithm.",
      "summary": "The paper addresses the problem of redundant context in token-budgeted RAG systems, which wastes budget and degrades generation quality. It proposes AdaGReS, an adaptive greedy selection framework that scores and selects chunks by balancing relevance and redundancy, with a theoretically-backed near-optimal guarantee. Experiments on QA and biomedical datasets show it improves redundancy control and end-to-end answer quality.",
      "mindmap": "graph TB\n        A[AdaGReS: Adaptive Greedy Context Selection] --> B[核心问题/Problem: Top-k检索返回冗余块，浪费token预算并降低生成质量/Top-k retrieval returns redundant chunks, wasting token budget and degrading generation]\n        A --> C[主要方法/Method: 冗余感知的贪婪选择框架，结合相关性得分与冗余惩罚，并进行自适应参数校准/Redundancy-aware greedy selection framework with relevance-redundancy trade-off and adaptive calibration]\n        A --> D[关键结果/Results: 在开放域QA和生物医学语料上，冗余控制和上下文质量得到改善，提升了端到端答案质量/Improved redundancy control and context quality on open-domain QA and biomedical corpus, leading to better end-to-end answer quality]"
    },
    {
      "title": "Many Minds from One Model: Bayesian Transformers for Population Intelligence",
      "authors": "Diji Yang, Yi Zhang",
      "institution": "University of California Santa Cruz",
      "link": "https://arxiv.org/pdf/2512.25063",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Bayesian Transformers",
        "Variational Inference",
        "Population Diversity",
        "Normalization Layers",
        "Wisdom of Crowds"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ae0113a2c263c7e9a33e3b5ce49ac7afb88b3a3baeb7fd88c121fac5ef4b745b_w640_q70.webp",
      "contributions": "1. Proposes Population Bayesian Transformers (B-Trans), a method to convert a standard LLM into a Bayesian model by treating normalization layer biases as stochastic variables with a Gaussian variational approximation, enabling diverse model sampling from a single weight set. 2. Introduces sequence-level noise freezing to maintain temporal coherence within each sampled model instance's generation, ensuring consistent behavior across tokens. 3. Demonstrates that aggregating predictions from a population of sampled B-Trans instances enhances exploration and decision-making, leading to superior semantic diversity and task performance in zero-shot generation, RLVR, and RL without labels.",
      "summary": "The paper addresses the lack of diversity and exploration in deterministic LLMs by proposing B-Trans, which transforms a standard LLM into a Bayesian model by making normalization biases stochastic. This allows sampling diverse \"minds\" from one model, and aggregating their predictions improves performance and semantic variety in reasoning tasks.",
      "mindmap": "graph TB\n        A[Many Minds from One Model: Bayesian Transformers for Population Intelligence] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现代Transformer是单一思维的/Modern Transformers are single-minded]\n        B --> B2[缺乏多样性阻碍探索/Lack of diversity hinders exploration]\n        C --> C1[提出B-Trans: 贝叶斯Transformer/Propose B-Trans: Bayesian Transformer]\n        C --> C2[归一化层偏置作为随机变量/Normalization biases as stochastic variables]\n        C --> C3[序列级噪声冻结/Sequence-level noise freezing]\n        D --> D1[增强语义多样性/Improved semantic diversity]\n        D --> D2[提升任务性能/Better task performance]\n        D --> D3[实现群体智慧/Achieves wisdom of crowds]"
    },
    {
      "title": "Scaling Open-Ended Reasoning to Predict the Future",
      "authors": "Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping",
      "institution": "Max Planck Institute for Intelligent Systems, ELLIS Institute Tübingen, Tübingen AI Center, University of Tübingen",
      "link": "https://arxiv.org/pdf/2512.25070",
      "code": "/github",
      "tags": [
        "language model forecasting",
        "open-ended forecasting",
        "reinforcement learning",
        "retrieval-augmented generation",
        "calibration",
        "Qwen3"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7433331ffccb9fb0f52db33a75b12ae808ae87c5410037274fcfdc5f22b3505_w640_q70.webp",
      "contributions": "1. A fully automated pipeline to synthesize a large-scale dataset (OpenForesight) for training language models on open-ended forecasting questions from news events. 2. A specialized forecasting system integrating retrieval and an improved RL reward function, trained on Qwen3, which prevents future information leakage. 3. The OpenForecaster 8B model, which demonstrates that specialized training improves accuracy, calibration, and consistency, matching larger proprietary models, with calibration benefits generalizing to other benchmarks.",
      "summary": "This paper addresses the challenge of training language models for open-ended future prediction. The authors propose an automated method to generate a large forecasting dataset from news and train a specialized model (OpenForecaster 8B) using retrieval and an improved RL reward. Their final model matches the performance of much larger proprietary models, showing improved prediction accuracy, calibration, and consistency.",
      "mindmap": "graph TB\n        A[Scaling Open-Ended Reasoning to Predict the Future<br>预测未来的开放式推理扩展] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[训练语言模型进行开放式未来预测<br>Train LLMs for open-ended future forecasting]\n        C --> C1[自动从新闻生成数据集<br>Automated dataset generation from news]\n        C --> C2[使用检索和改进的RL进行训练<br>Training with retrieval & improved RL]\n        C --> C3[防止未来信息泄露<br>Prevent future info leakage]\n        D --> D1[OpenForecaster 8B 匹配更大模型<br>Matches larger proprietary models]\n        D --> D2[提升准确性、校准和一致性<br>Improves accuracy, calibration, consistency]"
    },
    {
      "title": "Quantum Visual Word Sense Disambiguation: Unraveling Ambiguities Through Quantum Inference Model",
      "authors": "Wenbo Qiao, Peng Zhang, Qinghua Hu",
      "institution": "Tianjin University",
      "link": "https://arxiv.org/pdf/2512.24687",
      "code": null,
      "tags": [
        "word sense disambiguation",
        "quantum superposition",
        "visual word sense disambiguation",
        "gloss bias",
        "quantum inference model",
        "classical heuristic"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e5167ebf6e5d49153f09401dac307d10e811dc014412a548dd9a16e7d68f12_w640_q70.webp",
      "contributions": "1. Proposed a Quantum Inference Model (Q-VWSD) for unsupervised visual word sense disambiguation, using quantum superposition to encode multiple glosses and mitigate semantic biases. 2. Showed that Q-VWSD is a quantum generalization of classical probability-based methods and designed a heuristic version that runs efficiently on classical computers. 3. Demonstrated superior performance over state-of-the-art classical methods, especially by effectively leveraging non-specialized glosses from large language models.",
      "summary": "This paper addresses the problem of semantic bias in visual word sense disambiguation by proposing a Quantum Inference Model (Q-VWSD) that uses quantum superposition to encode multiple glosses. The method is shown to be a quantum generalization of classical approaches, and a heuristic version is developed for efficient classical computation. Experiments show the method outperforms existing classical techniques, particularly when using glosses from large language models.",
      "mindmap": "graph TB\n        Root[”Quantum Visual Word Sense Disambiguation<br/>量子视觉词义消歧”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Glosses have semantic biases leading to biased disambiguation results.<br/>词义解释存在语义偏差导致消歧结果有偏。”]\n        Method[”主要方法/Method<br/>Propose Q-VWSD using quantum superposition to encode glosses.<br/>提出Q-VWSD，用量子叠加态编码词义解释。”]\n        Results[”关键结果/Results<br/>Outperforms SOTA classical methods; heuristic version runs on classical computers.<br/>超越现有经典方法；启发式版本可在经典计算机上运行。”]"
    },
    {
      "title": "Large language models and the entropy of English",
      "authors": "Colin Scheibner, Lindsay M. Smith, William Bialek",
      "institution": "Princeton University, The CUNY Graduate Center",
      "link": "https://arxiv.org/pdf/2512.24969",
      "code": null,
      "tags": [
        "language modeling",
        "conditional entropy",
        "code length",
        "long-range dependencies",
        "statistical physics",
        "large language models"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6b8a68a26c5fded01361a53044b69998ec40cb664dee0ff16491e09a2c2a4e3_w640_q70.webp",
      "contributions": "1. Demonstrates that the conditional entropy (code length) of English text continues to decrease with context length up to at least ~10^4 characters using LLMs, revealing long-range dependencies. 2. Shows empirically, independent of models, that small but significant correlations exist between characters at large separations. 3. Reveals that long-range structure in language is learned gradually during model training and that the distribution of code lengths shows emergent certainty for many characters at large context lengths.",
      "summary": "This paper uses large language models (LLMs) to analyze the conditional entropy of English text over long contexts. The key finding is that entropy continues to decrease with context length up to at least 10^4 characters, indicating the presence of long-range dependencies and correlations in language. These results provide new constraints for building statistical physics models of language and LLMs.",
      "mindmap": "graph TB\n        A[Large language models and the entropy of English] --> B[核心问题/Problem: 英语文本是否存在长程结构？<br>Does English text have long-range structure?]\n        A --> C[主要方法/Method: 使用LLMs分析条件熵/代码长度<br>Use LLMs to analyze conditional entropy/code length]\n        A --> D[关键结果/Results: 熵随上下文长度持续下降，存在长程依赖<br>Entropy decreases with context length, long-range dependencies exist]"
    },
    {
      "title": "Unbiased Visual Reasoning with Controlled Visual Inputs",
      "authors": "Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou",
      "institution": "Arizona State University, University of Southern California, University of Pennsylvania, University of California, Davis",
      "link": "https://arxiv.org/pdf/2512.22183",
      "code": null,
      "tags": [
        "multimodal reasoning",
        "vision-language models",
        "spurious correlations",
        "information bottleneck",
        "reinforcement learning",
        "modular reasoning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8f546535b9c36b7873d0f685328a4f4a8e058e6a4788639c170f69e073d8f9e_w640_q70.webp",
      "contributions": "1. Proposes VISTA, a modular framework that decouples visual perception from reasoning using an explicit information bottleneck to control visual inputs. 2. Introduces a training method using reinforcement learning (GRPO) on a small curated dataset to align the reasoner with unbiased visual evidence. 3. Demonstrates improved robustness against spurious correlations, transferability across VLM sensors, and enhanced interpretability in reasoning traces.",
      "summary": "The paper addresses the problem of vision-language models (VLMs) relying on spurious correlations rather than causal visual evidence. It proposes VISTA, a modular framework that separates perception (via a frozen VLM) from reasoning (via an LLM) using controlled queries and trains the reasoner with reinforcement learning. The method shows significant gains in robustness on benchmarks like SpuriVerse while maintaining competitive performance on other tasks.",
      "mindmap": "graph TB\n        A[Unbiased Visual Reasoning with Controlled Visual Inputs] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[VLMs exploit spurious correlations/VLMs利用虚假关联]\n        C --> C1[VISTA: Modular framework decoupling perception & reasoning/VISTA: 解耦感知与推理的模块化框架]\n        C1 --> C2[Frozen VLM sensor + LLM reasoner/冻结VLM感知器 + LLM推理器]\n        C2 --> C3[Train with RL (GRPO)/使用强化学习(GRPO)训练]\n        D --> D1[Improved robustness on SpuriVerse/在SpuriVerse上鲁棒性提升]\n        D --> D2[Competitive on MMVP & SeedBench/在MMVP & SeedBench上保持竞争力]\n        D --> D3[Transferable & interpretable/可迁移且可解释]"
    },
    {
      "title": "A CNN-Based Malaria Diagnosis from Blood Cell Images with SHAP and LIME Explainability",
      "authors": "Md. Ismiel Hossen Abir, Awolad Hossain",
      "institution": "Department of Computer Science & Engineering, International Standard University, Dhaka, Bangladesh",
      "link": "https://arxiv.org/pdf/2512.22205",
      "code": null,
      "tags": [
        "medical image classification",
        "Convolutional Neural Network",
        "SHAP",
        "LIME",
        "Saliency Maps",
        "Malaria Diagnosis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cafdabeab6baa067cead631acca4eba73f7c2812fd0d0e97d201544854ddd16b_w640_q70.webp",
      "contributions": "1. Proposes a custom CNN model for automated malaria diagnosis from blood cell images, achieving high accuracy (96%). 2. Compares the performance of the custom CNN with established deep learning architectures like ResNet50 and VGG16. 3. Enhances model interpretability for clinical trust by applying Explainable AI techniques, including SHAP, LIME, and Saliency Maps.",
      "summary": "This paper proposes a deep learning-based system using a custom Convolutional Neural Network (CNN) to automatically diagnose malaria from blood cell images, achieving high accuracy. It compares this model against several established architectures and applies Explainable AI (XAI) techniques like SHAP and LIME to make the model's decisions interpretable. The study concludes that this approach can provide a quick, accurate, and understandable diagnostic tool, particularly valuable in resource-limited settings.",
      "mindmap": "graph TB\n        Root[”A CNN-Based Malaria Diagnosis from Blood Cell Images with SHAP and LIME Explainability”] --> Problem[”核心问题/Problem: Traditional microscopic diagnosis is slow, subjective, and resource-intensive.”]\n        Root --> Method[”主要方法/Method: A custom CNN model for classification, compared with other architectures, enhanced with SHAP, LIME, and Saliency Maps for explainability.”]\n        Root --> Results[”关键结果/Results: Achieves 96% accuracy, high precision/recall, providing a fast and interpretable diagnostic tool.”]"
    },
    {
      "title": "Open-Source Multimodal Moxin Models with Moxin-VLM and Moxin-VLA",
      "authors": "Pu Zhao, Xuan Shen, Zhenglun Kong, Yixin Shen, Sung-En Chang, Arash Akbari, Timothy Rupprecht, Lei Lu, Enfu Nan, Changdi Yang, Yumei He, Weiyan Shi, Xingchen Xu, Yu Huang, Wei Jiang, Wei Wang, Yue Chen, Yong He, Yanzhi Wang",
      "institution": "Northeastern University, Harvard University, Cornell University, Tulane University, University of Washington, Roboraction.ai, Futurewei, AIBAO LLC",
      "link": "https://arxiv.org/pdf/2512.22208",
      "code": "https://github.com/moxin-org/Moxin-LLM",
      "tags": [
        "multimodal large language models",
        "Moxin",
        "open-source LLM",
        "vision-language-action",
        "Model Openness Framework",
        "multimodal models"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79873d0c3143fc2b06f1be1be9b8bc80555fa0aefd4a6f2b8d6bda39bce5f227_w640_q70.webp",
      "contributions": "1. Introduces Moxin 7B, a fully open-source LLM developed under the Model Openness Framework, promoting transparency in training, datasets, and implementation. 2. Develops three specialized variants of Moxin: Moxin-VLM for vision-language tasks, Moxin-VLA for vision-language-action tasks, and Moxin-Chinese for Chinese language capabilities. 3. Demonstrates superior performance of the proposed models in various evaluations using open-source frameworks and data, with all models, code, and data publicly released.",
      "summary": "This paper introduces Moxin 7B, a fully transparent open-source large language model, and extends it into three multimodal variants for vision-language, vision-language-action, and Chinese tasks. The models are trained using open-source frameworks and data. The authors release the models, code, and data, reporting superior performance in evaluations.",
      "mindmap": "graph TB\n        A[Open-Source Multimodal Moxin Models<br/>开源多模态Moxin模型] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Proprietary vs. Open-Source LLMs<br/>闭源与开源大语言模型]\n        B --> B2[Need for transparent, capable open models<br/>需要透明、强大的开源模型]\n        C --> C1[Develop Moxin 7B under Model Openness Framework<br/>基于模型开放框架开发Moxin 7B]\n        C --> C2[Create variants: VLM, VLA, Chinese<br/>创建变体: VLM, VLA, 中文模型]\n        D --> D1[Superior performance in evaluations<br/>在评估中表现优异]\n        D --> D2[Full release of models, code, data<br/>完整发布模型、代码、数据]"
    },
    {
      "title": "On the Existence and Behaviour of Secondary Attention Sinks",
      "authors": "Jeffrey T.H. Wong, Cheng Zhang, Louis Mahon, Wayne Luk, Anton Isopoussu, Yiren Zhao",
      "institution": "Imperial College London, UnlikelyAI",
      "link": "https://arxiv.org/pdf/2512.22213",
      "code": null,
      "tags": [
        "llm inference",
        "attention sinks",
        "transformer",
        "mlp",
        "attention mechanism",
        "large language models"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ec1462ca646134f445eac98192ff5189abb63f37682802d695aadace9f83b0d3_w640_q70.webp",
      "contributions": "1. Identifies and characterizes a new class of \"secondary attention sinks\" that arise in middle layers, have variable lifetimes, and draw moderate attention, differing from persistent primary sinks like BOS. 2. Shows that secondary sinks are formed by specific middle-layer MLP modules that map token representations to align with the primary sink's direction, with their L2-norm determining sink strength and lifetime. 3. Observes that in larger models, these sink patterns (sink levels) become more deterministic and frequent, with distinct levels identified in models like QwQ-32B and Qwen3-14B.",
      "summary": "This paper identifies a new phenomenon called \"secondary attention sinks\" in transformer LLMs, which are distinct from the known primary sinks (like BOS). The authors show these secondary sinks are created by middle-layer MLPs aligning tokens with the primary sink direction, and their properties (strength, lifetime) become more structured in larger models. This provides new insights into the internal mechanics of attention in large language models.",
      "mindmap": "graph TB\n        A[”On the Existence and Behaviour of Secondary Attention Sinks<br/>二次注意力汇的存在与行为”] --> B[”核心问题/Problem<br/>Prior work only studied persistent primary sinks (e.g., BOS)<br/>先前研究仅关注持久的主汇（如BOS）”]\n        A --> C[”主要方法/Method<br/>Extensive experiments across 11 model families<br/>对11个模型系列进行广泛实验”]\n        A --> D[”关键结果/Results<br/>1. Secondary sinks form via MLPs in middle layers<br/>次级汇通过中间层MLP形成<br/>2. L2-norm determines sink score & lifetime<br/>L2范数决定汇分数与寿命<br/>3. Sink levels are deterministic in large models<br/>大模型中汇层级更确定”]"
    },
    {
      "title": "VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs",
      "authors": "Naishan Zheng, Jie Huang, Qingpei Guo, Feng Zhao",
      "institution": "University of Science and Technology of China, Ant Group",
      "link": "https://arxiv.org/pdf/2512.22226",
      "code": "https://github.com/zheng980629/VideoScaffold",
      "tags": [
        "video understanding",
        "streaming video",
        "multimodal large language models",
        "event segmentation",
        "hierarchical representation",
        "elastic-scale"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9ccc0f206a787899e1408b9c740b895e26c8c4847a2ecfbe5f88b48c25ce70ca_w640_q70.webp",
      "contributions": "1. Proposes VideoScaffold, a dynamic representation framework for streaming video understanding in MLLMs that adaptively adjusts event granularity. 2. Introduces Elastic-Scale Event Segmentation (EES) for prediction-guided, dynamic boundary refinement. 3. Introduces Hierarchical Event Consolidation (HEC) for progressively aggregating segments into multi-level abstractions.",
      "summary": "This paper addresses the challenge of understanding long, streaming videos with MLLMs by proposing VideoScaffold, a framework that dynamically segments and hierarchically consolidates video events to adapt granularity and preserve semantics. It achieves state-of-the-art performance on benchmarks and can extend image-based MLLMs to video comprehension.",
      "mindmap": "graph TB\n        A[VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs] --> B[核心问题/Problem: Understanding long, streaming videos with MLLMs is challenging due to redundancy and need for temporal coherence.]\n        A --> C[主要方法/Method: Proposes a dynamic framework with Elastic-Scale Event Segmentation (EES) and Hierarchical Event Consolidation (HEC).]\n        A --> D[关键结果/Results: Achieves state-of-the-art performance; framework is modular and plug-and-play.]"
    },
    {
      "title": "Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces",
      "authors": "Sophie Zhao",
      "institution": "Georgia Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.22227",
      "code": null,
      "tags": [
        "representation analysis",
        "sentence embeddings",
        "probing",
        "hierarchical geometry",
        "transformer models",
        "cognitive states"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fec0b31a0f9f75593cbc3cdadecae63f4a1a7b7b6d910165a358bc72dde0f1d7_w640_q70.webp",
      "contributions": "1. Constructed a novel dataset of 480 sentences annotated with continuous energy scores and discrete tier labels for seven ordered cognitive categories. 2. Demonstrated that both continuous scores and discrete tier labels are reliably decodable from fixed transformer sentence embeddings using linear and nonlinear probes, with nonlinear probes providing consistent gains. 3. Provided statistical and qualitative evidence (via permutation tests, UMAP visualizations, and confusion matrices) that the embedding space exhibits a hierarchical geometric organization aligned with human-defined cognitive attributes, beyond surface word statistics.",
      "summary": "This paper investigates whether transformer-based sentence embeddings encode a hierarchical structure aligned with cognitive states. The authors construct an annotated dataset and use linear and nonlinear probes to decode continuous scores and discrete labels from embeddings, finding reliable recoverability and a structured geometric gradient. The results show that transformer embedding spaces exhibit a systematic organization corresponding to interpretable cognitive attributes.",
      "mindmap": "graph TB\n        Root(”Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces”) --> Problem(”核心问题/Problem: Do sentence embeddings encode hierarchical cognitive structure?”)\n        Root --> Method(”主要方法/Method: Probe analysis on annotated dataset with linear/nonlinear classifiers”)\n        Root --> Results(”关键结果/Results: Reliable decoding, hierarchical geometry aligned with cognitive attributes”)"
    },
    {
      "title": "Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against",
      "authors": "Tsogt-Ochir Enkhbayar",
      "institution": "Mongol-AI (inferred from email domain)",
      "link": "https://arxiv.org/pdf/2512.22293",
      "code": null,
      "tags": [
        "language model safety",
        "sparse autoencoder",
        "feature orthogonalization",
        "stealth slip",
        "pragmatic interpretation",
        "statistical co-occurrence"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a1fddb803a434c3d49e04dd722184b33f238c4b81254540d6bb0d1961a3d09e1_w640_q70.webp",
      "contributions": "1. Empirically demonstrates that warning-framed training data fails to teach language models to avoid warned-against behaviors, showing generation rates similar to direct exposure. 2. Provides a mechanistic interpretation using sparse autoencoders, identifying a failure of feature orthogonalization where \"describing\" and \"performing\" an action activate overlapping latent features. 3. Identifies and names the \"stealth slip\" phenomenon, where conversational preambles can rotate activations into subspaces undetectable by linear probes, and shows that training-time feature ablation, not prompting, is required to address the issue.",
      "summary": "This paper investigates why language models trained on warning-framed examples (e.g., \"DO NOT USE\") still learn to generate the warned-against content. Through behavioral experiments and sparse autoencoder analysis, it finds that models learn statistical co-occurrences rather than pragmatic intent, due to overlapping latent features for description and action. The core conclusion is that current architectures prioritize pattern completion over understanding speaker intent, requiring training-time interventions like feature ablation for correction.",
      "mindmap": "graph TB\n        Root(”Learning from Negative Examples: Why Warning-Framed Training Data Teaches What It Warns Against”) --> Problem(”核心问题/Problem: Do warning-framed examples teach models to avoid bad behavior?”)\n        Root --> Method(”主要方法/Method: Behavioral analysis & Sparse Autoencoder mechanistic interpretability”)\n        Root --> Results(”关键结果/Results: No. Models learn statistical co-occurrence, not pragmatic intent.”)"
    },
    {
      "title": "SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents",
      "authors": "Shaofei Cai, Yulei Qin, Haojia Lin, Zihan Xu, Gang Li, Yuchen Shi, Zongyi Li, Yong Mao, Siqi Cai, Xiaoyu Tan, Yitao Liang, Ke Li, Xing Sun",
      "institution": "Peking University, Tencent",
      "link": "https://arxiv.org/pdf/2512.22322",
      "code": "https://huggingface.co/collections/yolay/smartsnap",
      "tags": [
        "agent system",
        "self-verifying agent",
        "proactive evidence seeking",
        "LLM-as-a-Judge",
        "3C Principles",
        "agentic reinforcement learning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61f493094954c71169bd505d339e16726dea8fffb8a79860e20efe7a94cff8ec_w640_q70.webp",
      "contributions": "1. Proposed SmartSnap, a paradigm shift from passive, post-hoc task verification to proactive, in-situ self-verification by the agent itself. 2. Introduced the Self-Verifying Agent, a new agent type with dual missions to complete tasks and prove accomplishment via curated snapshot evidences guided by 3C Principles (Completeness, Conciseness, Creativity). 3. Demonstrated that the SmartSnap paradigm enables scalable training of LLM-driven agents, achieving significant performance gains (up to 26.08% and 16.66%) on mobile tasks and competitive results against larger models.",
      "summary": "The paper addresses the scalability bottleneck in agentic RL caused by costly and unreliable post-hoc task verification. It proposes SmartSnap, a paradigm where agents proactively seek minimal, decisive snapshot evidence to prove task completion during execution, guided by 3C Principles. Experiments show this approach significantly improves agent performance and enables scalable training, achieving competitive results with much larger models.",
      "mindmap": "graph TB\n        A[SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Passive, post-hoc verification is costly and unreliable for agentic RL]\n        C[主要方法/Method: Proactive self-verification via Self-Verifying Agent and 3C Principles]\n        D[关键结果/Results: Performance gains up to 26.08%; competitive with larger models]"
    },
    {
      "title": "SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence",
      "authors": "Yiheng Wang, Yixin Chen, Shuo Li, Yifan Zhou, Bo Liu, Hengjian Gao, Jiakang Yuan, Jia Bu, Wanghan Xu, Yuhao Zhou, Xiangyu Zhao, Zhiwang Zhou, Fengxiang Wang, Haodong Duan, Songyang Zhang, Jun Yao, Han Deng, Yizhou Wang, Jiabei Xiao, Jiaqi Liu, Encheng Su, Yujie Liu, Weida Wang, Junchi Yao, Shenghe Zheng, Haoran Sun, Runmin Ma, Xiangchao Yan, Bo Zhang, Dongzhan Zhou, Shufei Zhang, Peng Ye, Xiaosong Wang, Shixiang Tang, Wenlong Zhang, Lei Bai",
      "institution": "Shanghai Artificial Intelligence Laboratory",
      "link": "https://arxiv.org/pdf/2512.22334",
      "code": "https://github.com/InternScience/SciEvalKit",
      "tags": [
        "evaluation & benchmarking",
        "scientific intelligence",
        "multimodal reasoning",
        "benchmarking toolkit"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/84233ab293826e87328abdd509857546d8a108ec2ff9c7ccc92d7c00c26ececa_w640_q70.webp",
      "contributions": "1. Introduces SciEvalKit, a unified, open-source toolkit for evaluating AI models across a broad range of scientific disciplines and core scientific intelligence capabilities. 2. Provides a flexible and extensible evaluation pipeline supporting batch evaluation, custom model/dataset integration, and ensuring transparent, reproducible results. 3. Curates expert-grade scientific benchmarks from real-world, domain-specific datasets to reflect authentic scientific challenges across six major domains.",
      "summary": "The paper introduces SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across multiple disciplines and core competencies like multimodal reasoning and code generation. It provides a flexible, extensible pipeline for reproducible evaluation and is built on expert-grade, real-world scientific benchmarks. The toolkit is open-sourced to foster community-driven development in AI for science.",
      "mindmap": "graph TB\n        A[SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Lack of specialized evaluation for scientific AI across diverse disciplines and capabilities]\n        C[主要方法/Method: Unified benchmarking toolkit with flexible pipeline, real-world benchmarks, and support for six scientific domains]\n        D[关键结果/Results: Open-source toolkit enabling standardized, reproducible evaluation of scientific foundation models]"
    },
    {
      "title": "Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback",
      "authors": "Mengkang Hu, Bowei Xia, Yuran Wu, Ailing Yu, Yude Zou, Qiguang Chen, Shijian Wang, Jiarui Jin, Kexin Li, Wenxiang Jiao, Yuan Lu, Ping Luo",
      "institution": "The University of Hong Kong, Xiaohongshu Inc., UESTC, Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.22336",
      "code": "agent2world.github.io",
      "tags": [
        "agent system",
        "symbolic world models",
        "multi-agent feedback",
        "PDDL",
        "adaptive testing",
        "supervised fine-tuning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3eb7640894bc37e231771de5c5b9dca9d3fe86f38d911d91d2cb55f73a1005c6_w640_q70.webp",
      "contributions": "1. Proposed Agent2World, a tool-augmented multi-agent framework for generating symbolic world models via adaptive multi-agent feedback. 2. Introduced a three-stage pipeline with specialized agents (Deep Researcher, Model Developer, Testing Team) for knowledge synthesis, implementation, and behavior-aware validation. 3. Demonstrated that the framework not only achieves state-of-the-art inference-time performance but also serves as a data engine for supervised fine-tuning, leading to substantial model improvement.",
      "summary": "This paper addresses the challenge of generating correct symbolic world models (like PDDL domains) from natural language by proposing Agent2World, a multi-agent framework that uses adaptive feedback for validation and repair. The method outperforms existing approaches on benchmarks and the feedback collected also enables effective supervised fine-tuning, significantly improving model performance.",
      "mindmap": "graph TB\n        A[Agent2World: Learning to Generate Symbolic World Models via Adaptive Multi-Agent Feedback] --> B[核心问题/Problem: Lack of verifiable supervision for training LLMs to generate behaviorally correct symbolic world models]\n        A --> C[主要方法/Method: Tool-augmented multi-agent framework with three-stage pipeline: Deep Researcher, Model Developer, and Testing Team for adaptive feedback]\n        A --> D[关键结果/Results: Achieves SOTA inference-time performance; Framework serves as data engine for fine-tuning, yielding ~31% average relative gain]"
    },
    {
      "title": "The Syntax of qulk-clauses in Yemeni Ibbi Arabic: A Minimalist Approach",
      "authors": "Zubaida Mohammed Albadani, Mohammed Q. Shormani",
      "institution": "Qalam University, Ibb University",
      "link": "https://arxiv.org/pdf/2512.22376",
      "code": null,
      "tags": [
        "generative syntax",
        "qulk-clauses",
        "Minimalist Program",
        "biclausal structures",
        "bipartite negation",
        "Morphological Merger"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1ac0d347b0a0aa0409fd5577dddb1a9b52a8488a6784d65d923c9b923a8a1edb_w640_q70.webp",
      "contributions": "1. Proposes that qulk-clauses in Yemeni Ibbi Arabic are biclausal structures where 'qulk' functions as a clause-embedding predicate selecting a full CP complement. 2. Provides a syntactic derivation using core Minimalist operations (Merge, Move, Agree, Spell-out) and post-syntactic processes like Morphological Merger. 3. Accounts for dialect-specific syntactic phenomena such as bipartite negation and cliticization within the Minimalist framework.",
      "summary": "This paper analyzes the syntax of 'qulk'-clauses in Yemeni Ibbi Arabic using the Minimalist Program, proposing they are biclausal structures derived through operations like Merge and Move. It concludes that the analysis accounts for dialect-specific features and supports the theoretical universality of minimalist syntax.",
      "mindmap": "graph TB\n        A[The Syntax of qulk-clauses in Yemeni Ibbi Arabic: A Minimalist Approach] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[分析qulk-从句的句法结构/Analyze syntax of qulk-clauses]\n        C --> C1[使用最简方案与操作/Use Minimalist Program & operations]\n        C --> C2[双层结构分析/Biclausal structure analysis]\n        D --> D1[解释方言特征/Account for dialect features]\n        D --> D2[支持最简方案普适性/Support universality of minimalism]"
    },
    {
      "title": "Towards Efficient Post-Training via Fourier-Driven Adapter Architectures",
      "authors": "Donggyun Bae, Jongil Park",
      "institution": "Konkuk University",
      "link": "https://arxiv.org/pdf/2512.22378",
      "code": null,
      "tags": [
        "parameter-efficient fine-tuning",
        "Fourier-Activated Adapter",
        "random Fourier features",
        "frequency-aware activation",
        "parameter-efficient fine-tuning",
        "spectral sparsity"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cf813cee09035fa7f545005f9b12789221e4e00ecb3d551020cff824fb62233_w640_q70.webp",
      "contributions": "1. Proposes the Fourier-Activated Adapter (FAA), a novel PEFT framework that integrates random Fourier features to decompose representations into frequency components. 2. Introduces a dynamic, frequency-aware activation mechanism to selectively modulate semantic information across different frequency bands. 3. Demonstrates through extensive experiments that FAA achieves competitive or superior performance on multiple benchmarks while maintaining low computational overhead.",
      "summary": "This paper proposes the Fourier-Activated Adapter (FAA), a parameter-efficient fine-tuning method for large language models that uses random Fourier features to enable frequency-aware modulation of semantic representations. Experiments on GLUE and other benchmarks show that FAA achieves strong performance with low computational cost, highlighting the effectiveness of its frequency-based approach.",
      "mindmap": "graph TB\n        A[Towards Efficient Post-Training via Fourier-Driven Adapter Architectures] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有PEFT方法难以捕获高频语义信息 / Existing PEFT methods struggle to capture high-frequency semantic information]\n        C --> C1[提出傅里叶激活适配器(FAA) / Propose Fourier-Activated Adapter (FAA)]\n        C1 --> C2[集成随机傅里叶特征分解表示 / Integrate random Fourier features to decompose representations]\n        C2 --> C3[使用频率感知机制选择性调制 / Use frequency-aware mechanism for selective modulation]\n        D --> D1[在多个基准测试中取得有竞争力的结果 / Achieves competitive results on multiple benchmarks]\n        D --> D2[保持低计算和内存开销 / Maintains low computational and memory overhead]"
    },
    {
      "title": "LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition",
      "authors": "Elsen Ronando, Sozo Inoue",
      "institution": "Kyushu Institute of Technology, Universitas 17 Agustus 1945 Surabaya",
      "link": "https://arxiv.org/pdf/2512.22385",
      "code": null,
      "tags": [
        "few-shot learning",
        "exemplar selection",
        "large language model",
        "human activity recognition",
        "facility-location optimization",
        "PageRank"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90a149428a6ff84d38e1ab6a741982394b05c9d5b98eaaa538dcd12183dbe7bf_w640_q70.webp",
      "contributions": "1. Proposes an LLM-Guided Exemplar Selection framework that incorporates semantic reasoning via LLM-generated knowledge priors (feature importance, inter-class confusability, budget multipliers) for HAR. 2. Integrates these semantic priors with multiple geometric and structural cues (margin-based validation, PageRank centrality, hubness penalization, facility-location optimization) for a unified exemplar scoring and selection process. 3. Demonstrates superior performance (88.78% macro F1-score on UCI-HAR) under strict few-shot conditions compared to classical selection methods like random sampling, herding, and k-center.",
      "summary": "This paper addresses the limitation of relying on large labeled datasets and purely geometric exemplar selection in Human Activity Recognition (HAR) by proposing an LLM-Guided Exemplar Selection framework. The method uses an LLM to generate semantic knowledge priors, which are combined with structural and geometric cues to select a compact, informative set of exemplars for few-shot learning. Evaluated on the UCI-HAR dataset, the framework outperforms classical selection approaches, showing that integrating semantic reasoning improves representative exemplar selection for wearable-sensor HAR.",
      "mindmap": "graph TB\n        A[LLM-Guided Exemplar Selection for Few-Shot HAR] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[依赖大数据集与几何选择 / Reliance on large datasets & geometric selection]\n        B --> B2[难以区分相似活动 / Hard to distinguish similar activities]\n        C --> C1[LLM生成语义先验 / LLM-generated semantic priors]\n        C --> C2[结合多线索优化 / Combine multiple cues for optimization]\n        D --> D1[性能超越基线 / Outperforms baselines (88.78% F1)]\n        D --> D2[语义先验有效 / Semantic priors are effective]"
    },
    {
      "title": "Hallucination Detection and Evaluation of Large Language Model",
      "authors": "Chenggong Zhang, Haopeng Wang",
      "institution": "University of California, Los Angeles",
      "link": "https://arxiv.org/pdf/2512.22416",
      "code": null,
      "tags": [
        "hallucination detection",
        "HHEM",
        "KnowHalu",
        "segment-based retrieval",
        "factual consistency",
        "CDF analysis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a208bbdfd47e46de589a2306cd9e02976448bce48e5e81a002adcb6f30ec224d_w640_q70.webp",
      "contributions": "1. Integrated the lightweight Hughes Hallucination Evaluation Model (HHEM) to significantly reduce computational cost and time for hallucination detection compared to multi-stage methods like KnowHalu. 2. Introduced a segment-based retrieval technique to improve the detection of localized hallucinations in summarization tasks, addressing a key limitation of HHEM. 3. Conducted a comparative CDF analysis revealing that larger LLMs (7B-9B parameters) exhibit fewer hallucinations, while intermediate-sized models show higher instability.",
      "summary": "This paper addresses the challenge of efficiently detecting hallucinations in Large Language Models. It proposes integrating the lightweight HHEM framework and a segment-based retrieval method, which together reduce evaluation time dramatically while maintaining high accuracy. The study concludes that larger models are generally more reliable and highlights the need for efficient yet robust evaluation frameworks.",
      "mindmap": "graph TB\n        A[Hallucination Detection and Evaluation of Large Language Model] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM幻觉损害可信度/LLM Hallucinations Undermine Trust]\n        C --> C1[集成轻量级HHEM框架/Integrate Lightweight HHEM Framework]\n        C --> C2[引入分段检索技术/Introduce Segment-based Retrieval]\n        D --> D1[效率提升: 8小时->10分钟/Efficiency Gain: 8hrs->10mins]\n        D --> D2[最高准确率: 82.2%/Best Accuracy: 82.2%]\n        D --> D3[大模型幻觉更少/Larger Models Hallucinate Less]"
    },
    {
      "title": "Monadic Context Engineering",
      "authors": "Yifan Zhang, Mengdi Wang",
      "institution": "Princeton University",
      "link": "https://arxiv.org/pdf/2512.22431",
      "code": "https://github.com/yifanzhang-pro/monadic-context-engineering",
      "tags": [
        "agent system",
        "Monadic Context Engineering",
        "Monad Transformers",
        "Meta-Agents",
        "computational contexts",
        "algebraic structures"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/635ff6dca4b79fe5e98a96641cbb26356935e3090aa65b20972b744e69151810_w640_q70.webp",
      "contributions": "1. Proposes Monadic Context Engineering (MCE), a novel architectural paradigm using Functors, Applicatives, and Monads to provide a formal foundation for AI agent design. 2. Demonstrates how Monads and Applicatives manage sequential composition and parallel execution, and how Monad Transformers enable systematic composition of capabilities like state and error handling. 3. Extends the MCE framework to describe Meta-Agents for generative orchestration, dynamically creating and managing sub-agent workflows via metaprogramming.",
      "summary": "This paper addresses the brittleness and complexity in current AI agent architectures by introducing Monadic Context Engineering (MCE), a paradigm that leverages algebraic structures like Monads to formally manage state, errors, and concurrency within agent workflows. The proposed method enables the construction of complex, resilient agents from simple, verifiable components and is extended to support generative orchestration via Meta-Agents. The work concludes that MCE provides a principled foundation for building robust and scalable autonomous agent systems.",
      "mindmap": "graph TB\n        Root[”Monadic Context Engineering”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”当前代理架构脆弱/Current agent architectures are brittle”]\n        Problem --> P2[”状态、错误、并发管理困难/Difficulties in state, error, concurrency management”]\n        Method --> M1[”引入单子上下文工程/Introduce Monadic Context Engineering (MCE)”]\n        Method --> M2[”利用函子、应用函子、单子/Leverage Functors, Applicatives, Monads”]\n        Method --> M3[”使用单子变换器组合能力/Use Monad Transformers to compose capabilities”]\n        Results --> R1[”提供形式化基础/Provides a formal foundation”]\n        Results --> R2[”支持构建复杂、鲁棒的代理/Enables building complex, resilient agents”]\n        Results --> R3[”扩展至元代理进行生成式编排/Extends to Meta-Agents for generative orchestration”]"
    },
    {
      "title": "HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG",
      "authors": "Cattalyya Nuengsigkapian",
      "institution": "Google",
      "link": "https://arxiv.org/pdf/2512.22442",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "hierarchical filtering",
        "two-pass generation",
        "citation verification",
        "query formulation",
        "model cascade"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9840d615edee0e72c18b93838479ebb342195ea1805803858fb9effaf9ba2e95_w640_q70.webp",
      "contributions": "1. Proposes a hierarchical content filtering pipeline to replace standard vector similarity search, improving context precision. 2. Introduces a model cascade strategy using a cost-efficient model (Gemini 2.5 Flash) for filtering and a powerful model (Gemini 2.5 Pro) for final generation. 3. Demonstrates significant performance gains on the MMU-RAGent benchmark and a custom dataset for post-cutoff knowledge.",
      "summary": "This paper presents HiFi-RAG, a system designed to improve open-domain RAG by addressing irrelevant retrieved information. The method uses a multi-stage pipeline with hierarchical filtering and a two-pass generation strategy employing different LLMs for efficiency and quality. The system won a NeurIPS 2025 competition and showed substantial improvements over baselines in evaluation metrics.",
      "mindmap": "graph TB\n        A[HiFi-RAG] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[开放域RAG中的无关信息与意图对齐/Open-domain RAG faces irrelevant info & intent misalignment]\n        C --> C1[分层过滤与两阶段生成/Hierarchical Filtering & Two-Pass Generation]\n        C1 --> C2[使用Gemini Flash进行过滤/Use Gemini Flash for filtering]\n        C1 --> C3[使用Gemini Pro进行生成/Use Gemini Pro for generation]\n        D --> D1[在MMU-RAGent上超越基线/Outperforms baseline on MMU-RAGent]\n        D --> D2[在自定义测试集上显著提升/Substantial gains on custom test set]"
    },
    {
      "title": "Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models",
      "authors": "Jie Zhou, Xin Chen, Jie Zhang, Zhe Li",
      "institution": "School of Computer Engineering, Jiangsu Ocean University",
      "link": "https://arxiv.org/pdf/2512.22443",
      "code": null,
      "tags": [
        "domain-specific reasoning",
        "vertical-domain reasoning",
        "accounting reasoning",
        "prompt engineering",
        "GLM-series",
        "evaluation criteria"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b34441f407f7adb435b84980dce10bceeed5c1737baae9c574e35ada53430c91_w640_q70.webp",
      "contributions": "1. Introduces the concept of \"vertical-domain accounting reasoning\" and establishes corresponding evaluation criteria based on analyzing training data characteristics of GLM-series models. 2. Proposes a framework to evaluate the accounting reasoning capabilities of several representative LLMs (GLM-6B, GLM-130B, GLM-4, GPT-4) using different prompt engineering strategies. 3. Provides benchmarks and foundational insights for improving LLM performance in professional accounting scenarios, identifying GPT-4's superior capability and the gap to real-world enterprise application requirements.",
      "summary": "This study investigates the domain-specific reasoning capabilities of Large Language Models (LLMs) in the accounting field. It establishes evaluation criteria for \"vertical-domain accounting reasoning\" and tests models like GLM-series and GPT-4 on accounting tasks using prompt engineering. The results show GPT-4 performs best, but all models still require further optimization to meet real-world enterprise accounting needs.",
      "mindmap": "graph TB\n        A[Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models] --> B(核心问题/Problem: LLMs与专业领域融合的挑战/Challenge of integrating LLMs with professional domains)\n        A --> C(主要方法/Method: 建立垂直领域会计推理评估框架/Establish vertical-domain accounting reasoning evaluation framework)\n        A --> D(关键结果/Results: GPT-4表现最佳，但仍需优化/GPT-4 performs best but requires further optimization)"
    },
    {
      "title": "AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing",
      "authors": "Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai",
      "institution": "Meituan, Hong Kong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.22455",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "LoRA",
        "Parameter-Efficient Fine-Tuning",
        "Activation Function Annealing",
        "Non-linear Adaptation",
        "Model Merging"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a5573f75296283a39c5bdbbb0c94652e0aeb935ae378c12528544ca5e188deb_w640_q70.webp",
      "contributions": "1. Proposes AFA-LoRA, a novel training strategy that introduces non-linear expressivity into LoRA while preserving its seamless mergeability., 2. Introduces an annealed activation function that transitions from non-linear to linear during training, enabling strong initial learning and final linear integration., 3. Demonstrates the method's effectiveness across multiple tasks, including supervised fine-tuning, reinforcement learning, and speculative decoding, reducing the performance gap with full-parameter training.",
      "summary": "The paper addresses the limited expressive power of linear Low-Rank Adaptation (LoRA) by proposing AFA-LoRA, a method that uses an annealed activation function to enable non-linear training while ensuring the final adapter remains mergeable. This approach narrows the performance gap between LoRA and full-parameter fine-tuning across various tasks, offering a more powerful and practical parameter-efficient adaptation paradigm.",
      "mindmap": "graph TB\n        A[AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LoRA线性适配的表达能力有限<br>LoRA's linear adaptation limits expressive power]\n        C[主要方法/Method<br>引入退火激活函数<br>Introduce annealed activation function]\n        D[关键结果/Results<br>缩小LoRA与全参数训练的差距<br>Reduces gap between LoRA and full-parameter training]"
    },
    {
      "title": "Constituency Structure over Eojeol in Korean Treebanks",
      "authors": "Jungyeul Park, Chulwoo Park",
      "institution": "KAIST, Anyang University",
      "link": "https://arxiv.org/pdf/2512.22487",
      "code": null,
      "tags": [
        "syntactic parsing",
        "constituency parsing",
        "treebank annotation",
        "eojeol",
        "Korean syntax",
        "morphological segmentation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d48ef7fceed98f1ac78d435bdf24a8049dd0338b9040587dd433cea8b3ff74a_w640_q70.webp",
      "contributions": "1. Argues for an eojeol-based constituency representation in Korean treebanks, separating morphological information into a non-constituent layer. 2. Shows that the Sejong and Penn Korean treebanks are representationally equivalent at the eojeol-based constituency level under explicit normalization. 3. Outlines an eojeol-based annotation scheme that supports cross-treebank comparison and constituency-dependency conversion.",
      "summary": "This paper addresses the representational issue of terminal units in Korean constituency treebanks. It proposes using eojeol (spacing units) as the constituency terminals while encoding morphology separately, and demonstrates that two major treebanks are equivalent under this scheme, enabling better comparison and conversion.",
      "mindmap": "graph TB\n        Root[”Constituency Structure over Eojeol in Korean Treebanks<br>韩语树库中基于Eojeol的选区结构”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Korean treebank terminal unit choice<br>韩语树库终端单元选择”] --> P1[”形态与句法混淆<br>Morphology-syntax conflation”]\n        Problem --> P2[”与依存资源不匹配<br>Mismatch with dependency resources”]\n        Method[”主要方法/Method<br>Eojeol-based constituency<br>基于Eojeol的选区表示”] --> M1[”以Eojeol为终端<br>Eojeol as terminals”]\n        Method --> M2[”形态信息单独编码<br>Morphology in separate layer”]\n        Results[”关键结果/Results<br>Treebank equivalence & scheme<br>树库等价性与方案”] --> R1[”Sejong与Penn树库等价<br>Sejong & Penn equivalence”]\n        Results --> R2[”支持跨库比较与转换<br>Supports comparison & conversion”]"
    },
    {
      "title": "ManchuTTS: Towards High-Quality Manchu Speech Synthesis via Flow Matching and Hierarchical Text Representation",
      "authors": "Suhua Wang, Zifan Wang, Xiaoxin Sun, D. J. Wang, Zhanbo Liu, Xin Li",
      "institution": "Northeast Normal University, Changchun Humanities and Sciences College, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.22491",
      "code": null,
      "tags": [
        "speech synthesis",
        "flow matching",
        "hierarchical attention",
        "low-resource TTS",
        "agglutinative language",
        "non-autoregressive generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/118d24570c94614dbb94eaabcc1dc47ba64643f094c4ea3727d4674221bf53fc_w640_q70.webp",
      "contributions": "1. Proposes a novel hierarchical text representation and cross-modal attention mechanism to handle Manchu's agglutinative phonology. 2. Introduces an end-to-end speech synthesis model integrating deep convolutional networks with a flow-matching Transformer for efficient, non-autoregressive generation. 3. Constructs the first public Manchu TTS dataset and employs data augmentation to address severe data scarcity.",
      "summary": "This paper proposes ManchuTTS, a novel text-to-speech system designed for the endangered and agglutinative Manchu language. The method uses a three-tier text representation and a flow-matching Transformer with hierarchical guidance to tackle data scarcity and complex phonology. Experiments show it achieves a high MOS score of 4.52 and significantly improves pronunciation accuracy and prosodic naturalness compared to baselines.",
      "mindmap": "graph TB\n        A[ManchuTTS: 满语语音合成] --> B1(核心问题/Problem)\n        A --> B2(主要方法/Method)\n        A --> B3(关键结果/Results)\n        B1 --> C1[数据稀缺/Data Scarcity]\n        B1 --> C2[粘着语语音学/Agglutinative Phonology]\n        B2 --> D1[三层文本表示/Three-tier Text Representation]\n        B2 --> D2[流匹配Transformer/Flow-matching Transformer]\n        B2 --> D3[分层对比损失/Hierarchical Contrastive Loss]\n        B3 --> E1[MOS得分4.52/MOS Score 4.52]\n        B3 --> E2[AWPA提升31%/AWPA +31%]\n        B3 --> E3[韵律自然度提升27%/Prosodic Naturalness +27%]"
    },
    {
      "title": "Learning When Not to Attend Globally",
      "authors": "Xuan Luo, Kailai Zhang, Xifeng Yan",
      "institution": "UC Santa Barbara",
      "link": "https://arxiv.org/pdf/2512.22562",
      "code": null,
      "tags": [
        "llm inference",
        "All-or-Here Attention",
        "sliding window attention",
        "conditional computation",
        "binary router",
        "context dependency"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/edc0024b0088e710cd3ce9c0be8276b43396c11c0424f0f6340e0f97d63982e6_w640_q70.webp",
      "contributions": "1. Proposes All-or-Here Attention (AHA), a novel attention mechanism that dynamically toggles between full and local sliding window attention using a binary router per head. 2. Demonstrates empirically that full attention is largely redundant, showing up to 93% of full attention operations can be replaced with local attention without performance loss. 3. Identifies a long-tail distribution in context dependency, revealing that the need for global context decays rapidly as the local window expands.",
      "summary": "The paper addresses the computational inefficiency of full self-attention in LLMs by proposing All-or-Here Attention (AHA), which learns to dynamically switch between full and local sliding window attention for each token. The results show that most full attention operations are unnecessary, and efficient inference can be achieved with on-demand global context access.",
      "mindmap": "graph TB\n        A[Learning When Not to Attend Globally] --> B[核心问题/Problem: Quadratic complexity of full self-attention is inefficient]\n        A --> C[主要方法/Method: All-or-Here Attention (AHA) with binary router to toggle between full and local sliding window attention]\n        A --> D[关键结果/Results: Up to 93% full attention replaced without loss; reveals long-tail context dependency]"
    },
    {
      "title": "Structured Prompting and LLM Ensembling for Multimodal Conversational Aspect-based Sentiment Analysis",
      "authors": "Zhiqiang Gao, Shihao Gao, Zixing Zhang, Yihao Guo, Hongyu Chen, Jing Han",
      "institution": "Hunan University, University of Cambridge",
      "link": "https://arxiv.org/pdf/2512.22603",
      "code": null,
      "tags": [
        "aspect-based sentiment analysis",
        "structured prompting",
        "llm ensembling",
        "multimodal conversation",
        "sentiment flipping",
        "sentiment sextuple"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0d8e53db2395e8a03a0b4b7ac36c2aa4287b60b1a961f7cc83bcd52a3ef4fae4_w640_q70.webp",
      "contributions": "1. A structured prompting pipeline for LLMs to sequentially extract complex sentiment sextuples (holder, target, aspect, opinion, sentiment, rationale) from multimodal dialogues. 2. An ensemble strategy leveraging three LLMs to robustly identify sentiment flipping (dynamic sentiment shifts) and their triggers. 3. Demonstrating the effectiveness of step-wise refinement and model ensembling for rich, multimodal sentiment analysis tasks, achieving competitive results on the MCABSA challenge.",
      "summary": "This paper addresses the challenge of Multimodal Conversational Aspect-based Sentiment Analysis (MCABSA). It proposes a structured prompting pipeline for extracting sentiment sextuples and an LLM ensembling method for detecting sentiment flipping. The approach achieved strong results, demonstrating the effectiveness of these strategies for complex multimodal sentiment understanding.",
      "mindmap": "graph TB\n        A[Structured Prompting and LLM Ensembling for Multimodal Conversational Aspect-based Sentiment Analysis] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>理解多模态对话中的情感<br>Understanding Sentiment in Multimodal Conversations]\n        C[主要方法/Method<br>结构化提示与LLM集成<br>Structured Prompting & LLM Ensembling]\n        D[关键结果/Results<br>Subtask-I: 47.38%<br>Subtask-II: 74.12% F1]"
    },
    {
      "title": "Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone",
      "authors": "Jiacheng Ye, Shansan Gong, Jiahui Gao, Junming Fan, Shuang Wu, Wei Bi, Haoli Bai, Lifeng Shang, Lingpeng Kong",
      "institution": "The University of Hong Kong, Huawei Technologies",
      "link": "https://arxiv.org/pdf/2512.22615",
      "code": null,
      "tags": [
        "multi-modal training",
        "diffusion language model",
        "vision-language-action",
        "parallel generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cc3fa176585576be4f4bd1035cfa0a21e63722654274b464e83bb35c7ee5bc0c_w640_q70.webp",
      "contributions": "1. Introduces Dream-VL, a state-of-the-art open diffusion-based Vision-Language Model (dVLM) that matches top AR-based VLMs on benchmarks and excels at visual planning. 2. Introduces Dream-VLA, a diffusion-based Vision-Language-Action model built upon Dream-VL, leveraging the bidirectional nature of diffusion for superior action chunking and faster fine-tuning convergence. 3. Demonstrates that diffusion-based VLMs/VLAs outperform autoregressive baselines on downstream tasks, achieving top-tier performance on robotic benchmarks like LIBERO, SimplerEnv-Bridge, and SimplerEnv-Fractal.",
      "summary": "This paper proposes building Vision-Language and Vision-Language-Action models on diffusion-based language models to overcome the limitations of autoregressive models in complex planning and control. The introduced models, Dream-VL and Dream-VLA, leverage the bidirectional, parallel generation nature of diffusion for superior performance in visual planning and robotic tasks, achieving state-of-the-art results on key benchmarks.",
      "mindmap": "graph TB\n        A[Dream-VL & Dream-VLA<br>论文标题/Paper Title] --> B[AR模型在视觉规划与机器人控制中存在局限<br>核心问题/Problem]\n        A --> C[基于扩散语言模型构建VLM和VLA模型<br>主要方法/Method]\n        A --> D[在多个基准测试中取得SOTA性能<br>关键结果/Results]"
    },
    {
      "title": "Chain-of-thought Reviewing and Correction for Time Series Question Answering",
      "authors": "Chen Su, Yuanhe Tian, Yan Song",
      "institution": "University of Science and Technology of China, Zhongguancun Institute of Artificial Intelligence",
      "link": "https://arxiv.org/pdf/2512.22627",
      "code": "https://github.com/synlp/T3LLM",
      "tags": [
        "time series question answering",
        "chain-of-thought",
        "multi-step reasoning",
        "self-correction",
        "LLM fine-tuning",
        "time series analysis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2399e517488f19982d1f0bdffd324837014399b83d0c64b4314235e4143c5a4_w640_q70.webp",
      "contributions": "1. Proposes T3LLM, a novel framework that integrates a multi-agent LLM system (worker, reviewer, student) for chain-of-thought reasoning with an explicit correction mechanism for time series QA. 2. Leverages the inherent verifiability of time series data to enable consistency checking between reasoning steps and original input, allowing the reviewer to identify and correct errors. 3. Fine-tunes a student model using the collaboratively generated corrected reasoning chains, internalizing both multi-step reasoning and self-correction capabilities.",
      "summary": "The paper addresses the problem of reasoning errors in LLM-based time series question answering. It proposes T3LLM, a framework that uses three LLMs (worker, reviewer, student) to generate, review/correct, and learn from multi-step reasoning chains. Experiments show that T3LLM achieves state-of-the-art performance on multiple TSQA benchmarks.",
      "mindmap": "graph TB\n        A[Chain-of-thought Reviewing and Correction for Time Series Question Answering] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: LLMs prone to reasoning errors on complex numerical time series data]\n        C[主要方法/Method: T3LLM framework with worker, reviewer, student LLMs for CoT generation, review/correction, and fine-tuning]\n        D[关键结果/Results: Achieves state-of-the-art performance on real-world TSQA benchmarks]"
    },
    {
      "title": "M2G-Eval: Enhancing and Evaluating Multi-granularity Multilingual Code Generation",
      "authors": "Fanglin Xu, Wei Zhang, Jian Yang, Guo Chen, Aishan Liu, Zhoujun Li, Xianglong Liu, Bryan Dai",
      "institution": "Beihang University, Hunan University, Ubiquant",
      "link": "https://arxiv.org/pdf/2512.22628",
      "code": null,
      "tags": [
        "code generation evaluation",
        "multi-granularity evaluation",
        "multilingual code generation",
        "Group Relative Policy Optimization",
        "contamination-controlled benchmark",
        "fine-grained diagnosis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c666b8c3b59bf1276ef94dab61d81839bb62d98333e1c6d0052ca3f61fdebad_w640_q70.webp",
      "contributions": "1. Introduced M2G-Eval, a novel multi-granularity and multilingual benchmark for evaluating code LLMs across four structural levels (Class, Function, Block, Line) and 18 programming languages. 2. Developed M2G-Eval-Coder models by fine-tuning Qwen3-8B with supervised fine-tuning and a novel Group Relative Policy Optimization method. 3. Conducted a comprehensive evaluation of 30 models, revealing key insights such as a difficulty hierarchy across granularities and evidence of transferable programming concepts across languages.",
      "summary": "This paper introduces M2G-Eval, a framework for evaluating code generation in large language models across multiple structural granularities and programming languages. The authors also develop enhanced models using the benchmark and conduct an extensive evaluation, finding a clear difficulty hierarchy among tasks and evidence that models learn transferable programming concepts across different languages.",
      "mindmap": "graph TB\n        Root[M2G-Eval: Enhancing and Evaluating Multi-granularity Multilingual Code Generation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[现有基准评估单一粒度与有限语言 / Existing benchmarks assess single granularity & limited languages]\n        Method[主要方法/Method] --> M1[提出多粒度多语言评估框架 / Propose multi-granularity multilingual evaluation framework]\n        Method --> M2[训练M2G-Eval-Coder模型 / Train M2G-Eval-Coder models]\n        Results[关键结果/Results] --> R1[难度层次: 行级最简单, 类级最难 / Difficulty hierarchy: Line easiest, Class hardest]\n        Results --> R2[性能差距随复杂度增加而扩大 / Performance gap widens with complexity]\n        Results --> R3[跨语言强相关, 表明可迁移概念 / Strong cross-language correlation suggests transferable concepts]"
    },
    {
      "title": "Evaluating GRPO and DPO for Faithful Chain-of-Thought Reasoning in LLMs",
      "authors": "Hadi Mohammadi, Tamas Kozak, Anastasia Giachanou",
      "institution": "Utrecht University",
      "link": "https://arxiv.org/pdf/2512.22631",
      "code": null,
      "tags": [
        "reasoning and explainability",
        "Chain-of-Thought",
        "Faithfulness",
        "GRPO",
        "DPO",
        "LLM Alignment"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/873da11748c86e67ee5cce9b0d9ee43cc3075f93ef1cc7775d7d9b6683adb946_w640_q70.webp",
      "contributions": "1. Evaluates and compares two optimization methods, GRPO and DPO, for improving the faithfulness of Chain-of-Thought reasoning in LLMs. 2. Demonstrates that GRPO outperforms DPO in larger models, with Qwen2.5-14B-Instruct achieving the best results. 3. Shows a positive correlation between model size and performance for both methods, with GRPO showing greater potential for improving faithfulness metrics.",
      "summary": "This paper investigates the problem of unfaithful Chain-of-Thought (CoT) reasoning in large language models, where generated rationales may not reflect the model's actual reasoning process. It evaluates two optimization methods, Group Relative Policy Optimization (GRPO) and Direct Preference Optimization (DPO), for improving CoT faithfulness. The main conclusion is that GRPO achieves higher performance than DPO, especially in larger models, suggesting it is a promising direction for developing more transparent and trustworthy reasoning.",
      "mindmap": "graph TB\n        A[Evaluating GRPO and DPO for Faithful Chain-of-Thought Reasoning in LLMs] --> B[核心问题/Problem: CoT解释可能不忠实，误导且不可靠]\n        A --> C[主要方法/Method: 评估GRPO和DPO优化方法以提升忠实性]\n        A --> D[关键结果/Results: GRPO在大型模型中表现优于DPO，是提升推理透明度的有前景方向]"
    },
    {
      "title": "On the Role of Discreteness in Diffusion LLMs",
      "authors": "Ziqi Jin, Bin Wang, Xiang Lin, Lidong Bing, Aixin Sun",
      "institution": "MiroMind AI, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.22630",
      "code": null,
      "tags": [
        "diffusion language models",
        "diffusion language models",
        "parallel decoding",
        "iterative refinement",
        "continuous diffusion",
        "discrete diffusion"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbf752083457bd2f08f3e62c6bd3acca194cf8603c88b7225f7783b764b30535_w640_q70.webp",
      "contributions": "1. Revisits diffusion language modeling and outlines five essential properties that separate diffusion mechanics from language-specific requirements. 2. Categorizes existing approaches into continuous diffusion in embedding space and discrete diffusion over tokens, showing each only partially satisfies the essential properties. 3. Identifies two central issues in recent large diffusion language models: uniform corruption not respecting information distribution and token-wise marginal training failing to capture multi-token dependencies.",
      "summary": "This paper analyzes the application of diffusion models to language generation, highlighting the challenges posed by the discrete nature of text. It categorizes existing approaches and identifies key structural trade-offs and issues, such as uniform corruption and token-wise training limitations. The findings motivate the development of diffusion processes better aligned with text structure for more coherent generation.",
      "mindmap": "graph TB\n        A[On the Role of Discreteness in Diffusion LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[离散与结构化文本挑战扩散模型应用<br/>Discrete & Structured Text Challenges Diffusion]\n        C --> C1[分类连续与离散扩散方法<br/>Categorize Continuous & Discrete Diffusion]\n        C --> C2[分析五大特性与权衡<br/>Analyze Five Properties & Trade-offs]\n        D --> D1[识别两大核心问题<br/>Identify Two Central Issues]\n        D --> D2[激励面向文本结构的扩散过程<br/>Motivate Text-Structured Diffusion Processes]"
    },
    {
      "title": "Scaling Unverifiable Rewards: A Case Study on Visual Insights",
      "authors": "Shuyu Gan, James Mooney, Pan Hao, Renxiang Wang, Mingyi Hong, Qianwen Wang, Dongyeop Kang",
      "institution": "University of Minnesota",
      "link": "https://arxiv.org/pdf/2512.22650",
      "code": "https://minnesotanlp.github.io/insight-scaling-webpage",
      "tags": [
        "agent system",
        "Test-Time Scaling",
        "multi-agent pipeline",
        "process-based refinement",
        "LLM-as-Judge",
        "unverifiable rewards"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/60e14b2c6ac8597444bea3610d692bad067ed798ec62c0920b0fe7c54b7fcd14_w640_q70.webp",
      "contributions": "1. Proposed Selective Test-Time Scaling, a process-based refinement framework that scales inference across stages in multi-agent pipelines instead of repeated refinement over time. 2. Designed a reliable LLM-based judge model aligned with human experts for evaluating visual insights. 3. Demonstrated improved insight quality under fixed compute budget in a data science pipeline application.",
      "summary": "This paper addresses the challenge of scaling LLM agents for tasks with unverifiable rewards by introducing Selective Test-Time Scaling, which distributes compute across pipeline stages and prunes low-quality branches early using process-specific judges. Applied to generating visual insights from datasets, the method increases mean quality scores and reduces variance compared to traditional time-based refinement. The work provides a foundation for scaling complex, open-ended tasks like scientific discovery and story generation.",
      "mindmap": "graph TB\n        A[Scaling Unverifiable Rewards: A Case Study on Visual Insights] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[多阶段任务缺乏可验证奖励/Multi-stage tasks lack verifiable rewards]\n        B --> B2[基于评判的优化易累积误差/Judge-based refinement prone to error accumulation]\n        C --> C1[选择性测试时扩展/Selective Test-Time Scaling]\n        C --> C2[跨阶段分配计算资源/Distribute compute across stages]\n        C --> C3[早期剪枝低质量分支/Prune low-quality branches early]\n        D --> D1[提升平均分数/Increased mean scores (61.64 to 65.86)]\n        D --> D2[降低方差/Reduced variance]\n        D --> D3[与人类专家对齐的评判模型/Judge model aligned with human experts]"
    },
    {
      "title": "Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2",
      "authors": "Pere Martra",
      "institution": "Universidad Internacional Menéndez Pelayo (UIMP)",
      "link": "https://arxiv.org/pdf/2512.22671",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "width pruning",
        "expansion ratio",
        "Maximum Absolute Weight (MAW)",
        "GLU-MLP",
        "instruction-following"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4df6003ce0dd5672f67ef0c36b943a93c7cbb475cc96f2c7592e1f230af17d53_w640_q70.webp",
      "contributions": "1. Systematically characterizes a capability dichotomy where structured width pruning degrades parametric knowledge (e.g., MMLU) but significantly improves instruction-following (e.g., IFEval). 2. Discovers and quantifies a robust inverse correlation between factual knowledge and truthfulness, linking knowledge degradation under pruning to improved misconception discrimination. 3. Identifies the expansion ratio as a critical architectural parameter that selectively modulates cognitive capabilities, rather than just a compression metric, and quantifies its context-dependent efficiency trade-offs.",
      "summary": "This paper investigates structured width pruning of GLU-MLP layers in Llama-3.2 models using the Maximum Absolute Weight (MAW) criterion. It finds that pruning creates a dichotomy: while parametric knowledge degrades, instruction-following improves and multi-step reasoning remains robust, challenging the assumption of uniform degradation. The main conclusion is that width pruning acts as a selective filter, reducing knowledge but preserving or enhancing behavioral alignment, with identified trade-offs in efficiency.",
      "mindmap": "graph TB\n        A[Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: How does structured width pruning affect different LLM capabilities?]\n        C[主要方法/Method: MAW-guided pruning of GLU-MLP layers, varying expansion ratio]\n        D[关键结果/Results: Knowledge ↓, Instruction-following ↑, Truthfulness ↑, Efficiency trade-offs]"
    },
    {
      "title": "Conformal Prediction Sets for Next-Token Prediction in Large Language Models: Balancing Coverage Guarantees with Set Efficiency",
      "authors": "Yoshith Roy Kotla, Varshith Roy Kotla",
      "institution": "The ICFAI Foundation for Higher Education",
      "link": "https://arxiv.org/pdf/2512.22682",
      "code": null,
      "tags": [
        "uncertainty quantification",
        "conformal prediction",
        "adaptive prediction sets",
        "vocabulary-aware",
        "coverage-efficiency tradeoff",
        "marginal coverage"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6fb40fe541a33e11ac6d9b3f6f3fac213d5602d391cc590303cb8079bf97a840_w640_q70.webp",
      "contributions": "1. Identified and formally characterized the coverage-efficiency tradeoff unique to applying conformal prediction to next-token prediction in LLMs with large vocabularies. 2. Proposed Vocabulary-Aware Conformal Prediction (VACP), a framework using semantic masking and temperature-adjusted scoring to reduce the effective prediction space. 3. Provided a theoretical analysis of when vocabulary reduction preserves conformal validity and demonstrated a 197x improvement in prediction set efficiency on benchmarks while maintaining coverage guarantees.",
      "summary": "This paper addresses the problem that naive conformal prediction for LLM next-token prediction produces uninformatively large prediction sets due to large vocabularies. It proposes Vocabulary-Aware Conformal Prediction (VACP), which uses semantic masking and hierarchical conformalization to drastically reduce set size. The method achieves near-target coverage while improving set efficiency by 197x, making conformal prediction practical for LLMs.",
      "mindmap": "graph TB\n        A[Conformal Prediction Sets for LLMs] --> B[核心问题/Problem: 标准置信预测在大型词汇表中产生巨大且无用的预测集]\n        A --> C[主要方法/Method: 提出词汇感知置信预测(VACP), 使用语义掩码和分层校准]\n        A --> D[关键结果/Results: 在保持90%覆盖率的同时, 将平均预测集大小从847个词元减少到4.3个]"
    },
    {
      "title": "GHaLIB: A Multilingual Framework for Hope Speech Detection in Low-Resource Languages",
      "authors": "Ahmed Abdullah, Sana Fatima, Haroon Mahmood",
      "institution": "FAST-National University, Al Ain University",
      "link": "https://arxiv.org/pdf/2512.22705",
      "code": null,
      "tags": [
        "hope speech detection",
        "transformer models",
        "multilingual classification",
        "low-resource languages",
        "XLM-RoBERTa",
        "UrduBERT"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c79c484e6d35762080aa8d6e1dbf075222d30335d656555a46ddf73380d7fe88_w640_q70.webp",
      "contributions": "1. Proposes a multilingual framework for hope speech detection, specifically addressing the underrepresentation of low-resource languages like Urdu. 2. Applies and evaluates multiple pretrained transformer models (XLM-RoBERTa, mBERT, EuroBERT, UrduBERT) on the PolyHope-M 2025 benchmark for this task. 3. Demonstrates strong performance, achieving high F1-scores for Urdu classification, validating the use of existing multilingual models in low-resource settings.",
      "summary": "This paper addresses the lack of resources for hope speech detection in low-resource languages by proposing a multilingual framework using pretrained transformer models like XLM-RoBERTa and UrduBERT. The method involves simple preprocessing and training classifiers, which achieve high F1-scores on the PolyHope-M 2025 benchmark, particularly for Urdu. The results show that existing multilingual models can be effectively implemented to identify hope speech and foster positive digital discourse in low-resource environments.",
      "mindmap": "graph TB\n        A[GHaLIB: 多语言希望语音检测框架 / GHaLIB: Multilingual Hope Speech Detection Framework] --> B[核心问题 / Problem]\n        A --> C[主要方法 / Method]\n        A --> D[关键结果 / Results]\n        B --> B1[希望语音在NLP中代表性不足 / Hope speech underrepresented in NLP]\n        B --> B2[低资源语言(如乌尔都语)缺乏资源 / Lack of resources for low-resource languages (e.g., Urdu)]\n        C --> C1[使用预训练多语言Transformer模型 / Use pretrained multilingual Transformer models]\n        C --> C2[简单预处理与分类器训练 / Simple preprocessing & classifier training]\n        D --> D1[乌尔都语二元分类F1: 95.2% / Urdu binary F1: 95.2%]\n        D --> D2[乌尔都语多类分类F1: 65.2% / Urdu multi-class F1: 65.2%]\n        D --> D3[多语言模型适用于低资源环境 / Multilingual models viable for low-resource settings]"
    },
    {
      "title": "Beg to Differ: Understanding Reasoning-Answer Misalignment Across Languages",
      "authors": "Anaelia Ovalle, Candace Ross, Sebastian Ruder, Adina Williams, Karen Ullrich, Mark Ibrahim, Levent Sagun",
      "institution": "Meta Superintelligence Labs",
      "link": "https://arxiv.org/pdf/2512.22712",
      "code": null,
      "tags": [
        "multilingual reasoning evaluation",
        "reasoning-answer misalignment",
        "chain-of-thought prompting",
        "crosslingual evaluation",
        "error taxonomy",
        "GlobalMMLU"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd9c868e57697e675d2ed0bdd5294f15cfad25e4c549988b95bcc1aca9c8bb57_w640_q70.webp",
      "contributions": "1. Introduced a human-validated framework to evaluate the logical alignment between model-generated reasoning traces and their conclusions across languages. 2. Conducted a large-scale analysis revealing that reasoning traces in non-Latin scripts exhibit at least twice as much misalignment as those in Latin scripts, despite high task accuracy. 3. Developed an error taxonomy through human annotation, identifying evidential errors (e.g., unsupported claims) and illogical reasoning steps as primary failure modes.",
      "summary": "This paper investigates whether the reasoning quality of large language models transfers across languages. The authors propose a framework to evaluate if model-generated reasoning traces logically support their conclusions, analyzing 65k traces across 6 languages and 6 models. They find a critical misalignment, especially in non-Latin scripts, showing that current multilingual evaluation practices provide an incomplete picture of model reasoning capabilities.",
      "mindmap": "graph TB\n        A[Beg to Differ: Understanding Reasoning-Answer Misalignment Across Languages<br>论文标题] --> B[核心问题/Problem: Does reasoning quality transfer across languages in LLMs?<br>LLM的推理能力是否跨语言迁移？]\n        A --> C[主要方法/Method: Human-validated framework to evaluate reasoning-answer alignment<br>人工验证的框架评估推理-答案对齐]\n        A --> D[关键结果/Results: High misalignment in non-Latin scripts, error taxonomy developed<br>非拉丁文字脚本中对齐度差，建立了错误分类]"
    },
    {
      "title": "Mitigating Social Desirability Bias in Random Silicon Sampling",
      "authors": "Sashank Chapala, Maksym Mironov, Songgaojun Deng",
      "institution": "Eindhoven University of Technology",
      "link": "https://arxiv.org/pdf/2512.22725",
      "code": null,
      "tags": [
        "llm evaluation",
        "silicon sampling",
        "social desirability bias",
        "prompt engineering",
        "jensen-shannon divergence",
        "american national election study"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e514b34cb5fd24baebc22116c45f73b1898e7c713905a13d372408df0900782b_w640_q70.webp",
      "contributions": "1. Replicates and confirms the presence of persistent Social Desirability Bias (SDB) in LLM-based silicon sampling. 2. Proposes and systematically evaluates four psychologically grounded prompt-based methods (reformulated, reverse-coded, priming, preamble) for mitigating SDB. 3. Demonstrates that reformulated prompts (neutral, third-person phrasing) are the most effective method for improving alignment between silicon and human survey response distributions.",
      "summary": "This paper investigates how to reduce Social Desirability Bias in LLM-generated survey responses (silicon sampling). It tests four prompt-based mitigation methods and finds that reformulating questions into neutral, third-person phrasing most effectively aligns the LLM outputs with real human data from the American National Election Study.",
      "mindmap": "graph TB\n        A[Mitigating Social Desirability Bias in Random Silicon Sampling] --> B[核心问题/Problem: LLM硅采样存在社会期望偏差/Social Desirability Bias in Silicon Sampling]\n        A --> C[主要方法/Method: 测试四种基于提示的缓解方法/Test Four Prompt-based Mitigation Methods]\n        A --> D[关键结果/Results: 重构提示最有效，改善与人类数据对齐/Reformulated Prompts Most Effective, Improve Alignment]\n        C --> C1[重构/Reformulated]\n        C --> C2[反向编码/Reverse-coded]\n        C --> C3[启动/Priming]\n        C --> C4[序言/Preamble]"
    },
    {
      "title": "Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data",
      "authors": "Md Badsha Biswas",
      "institution": "George Mason University",
      "link": "https://arxiv.org/pdf/2512.22732",
      "code": null,
      "tags": [
        "text classification",
        "data augmentation",
        "imbalanced dataset",
        "social media analysis",
        "natural language processing",
        "pregnancy outcome"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb9c28a95fb880100ca20beffad94909ef9e73c38a75789c38961258454c014a_w640_q70.webp",
      "contributions": "1. Proposes a novel approach to use public social media data (e.g., Twitter) as an adjunctive resource for studying negative pregnancy outcomes, addressing data scarcity in traditional epidemiological research. 2. Constructs an NLP pipeline to automatically identify and classify pregnancy experiences from unstructured, noisy social media text, distinguishing between positive and negative outcomes. 3. Investigates and evaluates various data augmentation techniques specifically to address the severe class imbalance inherent in social media data for this sensitive health domain.",
      "summary": "This paper addresses the challenge of classifying negative pregnancy outcomes from imbalanced social media data. It proposes an NLP pipeline to extract and categorize pregnancy experiences from Twitter and investigates data augmentation techniques to balance the dataset. The research demonstrates the viability of social media data as a supplementary resource for epidemiological studies on pregnancy.",
      "mindmap": "graph TB\n        A[Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[婴儿死亡率高，负面妊娠结局数据稀缺 / High infant mortality, scarce data on negative pregnancy outcomes]\n        B --> B2[社交媒体数据不平衡、有噪声 / Social media data is imbalanced and noisy]\n        C --> C1[构建NLP流水线分类妊娠结局 / Build NLP pipeline to classify pregnancy outcomes]\n        C --> C2[使用数据增强处理不平衡数据 / Use data augmentation for imbalanced data]\n        D --> D1[验证社交媒体数据作为辅助资源的可行性 / Validate social media data as an adjunctive resource]\n        D --> D2[为未来健康研究提供框架 / Provide a framework for future health studies]"
    },
    {
      "title": "Harnessing Large Language Models for Biomedical Named Entity Recognition",
      "authors": "Jian Chen, Leilei Su, Cong Sun",
      "institution": "Hainan University, Weill Cornell Medicine",
      "link": "https://arxiv.org/pdf/2512.22738",
      "code": null,
      "tags": [
        "named entity recognition",
        "instruction tuning",
        "data filtering",
        "weak-to-strong learning",
        "biomedical named entity recognition",
        "json generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0e941de51836d02e0004ef558a69019ce22af7124cd10760a2c904f6329cfa1_w640_q70.webp",
      "contributions": "1. Proposes BioSelectTune, a data-centric framework for fine-tuning LLMs for BioNER that prioritizes data quality. 2. Introduces a Hybrid Superfiltering strategy, a weak-to-strong data curation method to distill a high-impact training dataset. 3. Reformulates BioNER as a structured JSON generation task to leverage LLMs' instruction-following capabilities.",
      "summary": "The paper addresses the challenge of adapting general-domain LLMs to Biomedical Named Entity Recognition (BioNER) by proposing BioSelectTune, a framework that uses a novel Hybrid Superfiltering data curation strategy and formulates BioNER as a JSON generation task. The method achieves state-of-the-art performance on multiple benchmarks, outperforming specialized models even when trained on only 50% of the curated data.",
      "mindmap": "graph TB\n        A[Harnessing LLMs for BioNER] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs lack domain knowledge for BioNER / LLMs缺乏生物医学领域知识]\n        B --> B2[Low-quality data degrades performance / 低质量数据导致性能下降]\n        C --> C1[BioSelectTune Framework / BioSelectTune框架]\n        C1 --> C2[Reformulate as JSON generation / 重构为JSON生成任务]\n        C1 --> C3[Hybrid Superfiltering / 混合超级过滤策略]\n        D --> D1[SOTA on benchmarks / 基准测试达到SOTA]\n        D --> D2[Outperforms BioMedBERT / 超越BioMedBERT]\n        D --> D3[50% data surpasses baseline / 50%数据超越全量基线]"
    },
    {
      "title": "WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference",
      "authors": "Aiwei Liu, Minghua He, Shaoxun Zeng, Sijun Zhang, Linhao Zhang, Chuhan Wu, Wei Jia, Yuan Liu, Xiao Zhou, Jie Zhou",
      "institution": "Tencent (WeChat AI), Peking University, Tsinghua University",
      "link": "https://arxiv.org/pdf/2512.22737",
      "code": "https://github.com/tencent/WeDLM",
      "tags": [
        "llm inference",
        "diffusion language models",
        "causal attention",
        "prefix KV caching",
        "topological reordering",
        "streaming decoding"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad23d9024363d110ea78bc7ec9d949004a721e40ff6ee0dc4259437ba273af5e_w640_q70.webp",
      "contributions": "1. Proposes WeDLM, a diffusion decoding framework built entirely on standard causal attention to be compatible with prefix KV caching. 2. Introduces Topological Reordering to allow masked positions to condition on all observed tokens while maintaining a strict causal mask. 3. Designs a streaming decoding procedure that commits confident tokens continuously to avoid stop-and-wait behavior and maintain fixed parallel workload.",
      "summary": "The paper addresses the inefficiency of diffusion language models (DLLMs) at inference time, which often fail to achieve speedups over autoregressive models due to their reliance on bidirectional attention that breaks prefix KV caching. It proposes WeDLM, a framework that uses causal attention and a novel streaming decoding procedure with topological reordering to enable efficient parallel generation. Experiments show WeDLM preserves model quality while achieving up to 3x-10x speedup over optimized AR engines like vLLM.",
      "mindmap": "graph TB\n        A[WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Diffusion LLMs use bidirectional attention, breaking prefix KV caching and hurting inference speed.]\n        C[主要方法/Method<br>WeDLM uses causal attention with Topological Reordering and streaming decoding for prefix-cache friendly parallel generation.]\n        D[关键结果/Results<br>Preserves AR model quality, achieves up to 3x-10x speedup vs. vLLM-served AR baselines.]"
    },
    {
      "title": "Text-Routed Sparse Mixture-of-Experts Model with Explanation and Temporal Alignment for Multi-Modal Sentiment Analysis",
      "authors": "Dongning Rao, Yunbiao Zeng, Zhihua Jiang, Jujian Lv",
      "institution": "Guangdong University of Technology, Guangdong Polytechnic Normal University, Jinan University",
      "link": "https://arxiv.org/pdf/2512.22741",
      "code": "https://github.com/fip-lab/TEXT",
      "tags": [
        "multi-modal sentiment analysis",
        "multi-modal sentiment analysis",
        "mixture-of-experts",
        "temporal alignment",
        "multi-modal large language model",
        "cross-attention"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcf1bd04e7c087db4d11cc1d5f3e99f88fc80cf401c5c782a8b3003074eef9b1_w640_q70.webp",
      "contributions": "1. Proposes a novel text-routed sparse mixture-of-experts model with gate fusion for multi-modal sentiment analysis. 2. Introduces a temporal alignment block that merges the benefits of Mamba and temporal cross-attention to align audio and video representations. 3. Augments explanations for MSA using Multi-modal Large Language Models (MLLMs) and aligns different modalities with these explanations.",
      "summary": "This paper proposes TEXT, a model for multi-modal sentiment analysis that uses MLLM-generated explanations and a novel temporal alignment block to better fuse text, audio, and video modalities. The method achieves state-of-the-art performance across four datasets, significantly reducing error metrics compared to recent approaches.",
      "mindmap": "graph TB\n        A[Text-Routed Sparse Mixture-of-Experts Model with Explanation and Temporal Alignment for Multi-Modal Sentiment Analysis] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: The power of explanations and temporal alignments in MSA is underexplored.]\n        C[主要方法/Method: TEXT uses MLLM explanations, temporal alignment (Mamba & cross-attention), and text-routed sparse mixture-of-experts.]\n        D[关键结果/Results: Achieves best performance on four datasets, e.g., 13.5% MAE decrement on CH-SIMS.]"
    },
    {
      "title": "Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language",
      "authors": "Muhammad Zain Ali, Bernhard Pfahringer, Tony Smith",
      "institution": "University of Waikato",
      "link": "https://arxiv.org/pdf/2512.22778",
      "code": "https://github.com/zainali93/DomainAdaptation",
      "tags": [
        "fake news detection",
        "domain adaptation",
        "XLM-RoBERTa",
        "mBERT",
        "low-resource language",
        "Urdu"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34b44093cc6cdaad3233e04caa61c5300da4dbe090a12e70cdd829572c5a7c29_w640_q70.webp",
      "contributions": "1. Investigates domain adaptation before fine-tuning for fake news classification in Urdu, a low-resource language. 2. Evaluates and compares the effectiveness of this staged training approach on two multilingual models (XLM-R and mBERT). 3. Demonstrates that domain-adapted XLM-R consistently outperforms its vanilla counterpart across four Urdu fake news datasets.",
      "summary": "This paper addresses fake news classification in Urdu, a low-resource language, by proposing a domain adaptation approach before fine-tuning multilingual language models. The method involves domain-adaptive pretraining on an Urdu news corpus, applied to XLM-RoBERTa and mBERT. Results show that domain-adapted XLM-R consistently improves performance, while mBERT shows mixed results.",
      "mindmap": "graph TB\n        A[Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[低资源语言假新闻检测/Low-Resource Language Fake News Detection]\n        C --> C1[领域自适应预训练/Domain-Adaptive Pretraining]\n        C --> C2[微调多语言模型/Fine-tuning Multilingual Models]\n        D --> D1[领域自适应XLM-R性能提升/Domain-Adapted XLM-R Improves]\n        D --> D2[mBERT结果不一/mBERT Shows Mixed Results]"
    },
    {
      "title": "CNSight: Evaluation of Clinical Note Segmentation Tools",
      "authors": "Risha Surana, Adrian Law, Sunwoo Kim, Rishab Sridhar, Angxiao Han, Peiyu Hong",
      "institution": "University of Southern California",
      "link": "https://arxiv.org/pdf/2512.22795",
      "code": null,
      "tags": [
        "text segmentation",
        "clinical note segmentation",
        "transformer models",
        "large language models",
        "MIMIC-IV",
        "rule-based baselines"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be9738f44f0f558dc344bd32b267879341b566035c5dbe67f97ac2e4529b479_w640_q70.webp",
      "contributions": "1. A comprehensive evaluation of diverse methods (rule-based, domain-specific transformers, and large language models) for the task of clinical note segmentation. 2. The curation and use of a dataset of 1,000 notes from MIMIC-IV for benchmarking segmentation performance. 3. Empirical findings that large API-based models (e.g., GPT-5-mini) achieve the best overall performance, while lightweight baselines remain competitive only on structured tasks.",
      "summary": "This paper evaluates various methods for segmenting unstructured clinical notes into distinct sections. It compares rule-based baselines, domain-specific transformers, and large language models on a curated dataset from MIMIC-IV. The main conclusion is that large API-based models like GPT-5-mini achieve the best overall segmentation performance, providing guidance for method selection in downstream clinical applications.",
      "mindmap": "graph TB\n        Root[CNSight: 临床笔记分割工具评估 / CNSight: Evaluation of Clinical Note Segmentation Tools]\n        Root --> Problem[临床笔记非结构化 / Clinical Notes Unstructured]\n        Root --> Method[评估规则/变换器/大语言模型 / Evaluate Rule-based/Transformer/LLMs]\n        Root --> Results[大模型性能最佳 / Large Models Best Performance]"
    },
    {
      "title": "NepEMO: A Multi-Label Emotion and Sentiment Analysis on Nepali Reddit with Linguistic Insights and Temporal Trends",
      "authors": "Sameer Sitoula, Tej Bahadur Shahi, Laxmi Prasad Bhatt, Anisha Pokhrel, Arjun Neupane",
      "institution": "Tribhuvan University, Queensland University of Technology, Advanced College of Engineering and Management, Central Queensland University",
      "link": "https://arxiv.org/pdf/2512.22823",
      "code": null,
      "tags": [
        "emotion and sentiment analysis",
        "multi-label classification",
        "transformer models",
        "topic modelling",
        "temporal analysis",
        "linguistic insights"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bbfaa02abfed829cc20f377fe4ff49e093d956ae5d2c81018f8575d9b08ab30b_w640_q70.webp",
      "contributions": "1. Introduction of NepEMO, a novel manually annotated dataset for multi-label emotion and sentiment analysis on Nepali Reddit posts in multiple scripts. 2. A detailed linguistic and temporal analysis of the dataset, including emotion trends, co-occurrence, and topic modeling. 3. A comprehensive benchmark comparing traditional ML, deep learning, and transformer models, demonstrating the superiority of transformers for the tasks.",
      "summary": "This paper introduces NepEMO, a new dataset for multi-label emotion and sentiment analysis on posts from the Nepali subreddit. The authors perform linguistic and temporal analysis on the data and benchmark various machine learning models. The results show that transformer models outperform traditional machine learning and deep learning models for both classification tasks.",
      "mindmap": "graph TB\n        A[NepEMO: 多标签情感与情绪分析 / Multi-Label Emotion and Sentiment Analysis] --> B[核心问题/Problem: 缺乏尼泊尔语社交媒体数据集 / Lack of Nepali social media dataset]\n        A --> C[主要方法/Method: 构建标注数据集与模型比较 / Build annotated dataset & model comparison]\n        A --> D[关键结果/Results: 变压器模型性能最优 / Transformer models perform best]"
    },
    {
      "title": "AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning",
      "authors": "Shihao Cai, Runnan Fang, Jialong Wu, Baixuan Li, Xinyu Wang, Yong Jiang, Liangcai Su, Liwen Zhang, Wenbiao Yin, Zhen Zhang, Fuli Feng, Pengjun Xie, Xiaobin Wang",
      "institution": "Tongyi Lab, Alibaba Group",
      "link": "https://arxiv.org/pdf/2512.22857",
      "code": null,
      "tags": [
        "agent system",
        "automated environment synthesis",
        "environment-level RL",
        "agentic reinforcement learning",
        "simulated user",
        "policy optimization"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf43f01b4afce8af27cc99730129e26bd5b170c90172ddf77134a48ec54cccb0_w640_q70.webp",
      "contributions": "1. A unified, automated pipeline for synthesizing scalable simulated environments with high-difficulty, easily verifiable tasks. 2. An Environment-level Relative Policy Optimization (ERPO) algorithm that mitigates simulated user instability and performs advantage estimation at the environment level. 3. Comprehensive validation on agentic benchmarks demonstrating effectiveness and out-of-domain generalization.",
      "summary": "This paper proposes AutoForge, a framework to automate the synthesis of challenging simulated environments for training language-based agents via reinforcement learning. It introduces an environment-level RL algorithm to improve training stability and efficiency by handling simulated user instability and heterogeneous environments. Evaluations show the method is effective and generalizes well to out-of-domain tasks.",
      "mindmap": "graph TB\n        A[AutoForge] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[环境合成半自动/Semi-automated Environment Synthesis]\n        B --> B2[任务难度不足/Insufficient Task Difficulty]\n        B --> B3[模拟用户不稳定/Simulated User Instability]\n        C --> C1[自动化环境合成管道/Automated Environment Synthesis Pipeline]\n        C --> C2[环境级RL算法/Environment-level RL Algorithm (ERPO)]\n        D --> D1[基准测试有效/Effective on Benchmarks (τ-bench, etc.)]\n        D --> D2[域外泛化强/Strong Out-of-domain Generalization]"
    },
    {
      "title": "Debugging Tabular Log as Dynamic Graphs",
      "authors": "Chumeng Liang, Zhanyang Jin, Zahaib Akhtar, Mona Pereira, Haofei Yu, Jiaxuan You",
      "institution": "University of Illinois Urbana-Champaign, Amazon",
      "link": "https://arxiv.org/pdf/2512.22903",
      "code": null,
      "tags": [
        "others",
        "dynamic graph",
        "graph neural network",
        "tabular log",
        "log debugging",
        "heterogeneous nodes"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bfc0dd96717274f366abd002f1a9147f7afbdaba795d251628919a0d25289925_w640_q70.webp",
      "contributions": "1. Proposes GraphLogDebugger, a novel framework that models tabular log data as dynamic graphs with heterogeneous nodes for objects and events, 2. Demonstrates that a simple dynamic GNN can outperform large language models (LLMs) in debugging tasks using this graph representation, 3. Validates the approach on real-world datasets from computer systems and academic papers, showing improved flexibility and scalability over LLM-based methods.",
      "summary": "This paper introduces GraphLogDebugger, a framework that converts tabular log data into dynamic graphs to detect inconsistencies in real-world systems. By representing logs as evolving graphs with object and event nodes, a lightweight dynamic Graph Neural Network effectively debugs logs, outperforming larger LLM-based models in experiments on system and academic log datasets.",
      "mindmap": "graph TB\n        A[DEBUGGING TABULAR LOG AS DYNAMIC GRAPHS] --> B[核心问题/Problem: LLMs and heavy models lack flexibility and scalability for tabular log debugging]\n        A --> C[主要方法/Method: GraphLogDebugger models logs as dynamic graphs with heterogeneous nodes and edges]\n        A --> D[关键结果/Results: Simple dynamic GNN outperforms LLMs in debugging on real-world datasets]"
    },
    {
      "title": "Multimodal Fact-Checking: An Agent-based Approach",
      "authors": "Danni Xu, Shaojing Fan, Xuanang Cheng, Mohan Kankanhalli",
      "institution": "National University of Singapore (NUS)",
      "link": "https://arxiv.org/pdf/2512.22933",
      "code": null,
      "tags": [
        "multimodal fact-checking",
        "multimodal misinformation",
        "agent-based reasoning",
        "explainable dataset",
        "vision-language models",
        "evidence retrieval"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/05bbe58d9ac10920f1b315029a664c297bd8051834b3724dbf3fa80f26372bec_w640_q70.webp",
      "contributions": "1. Introduces RW-Post, a high-quality, explainable dataset for real-world multimodal fact-checking that aligns claims with original social media posts and provides detailed reasoning and evidence. 2. Proposes AgentFact, a novel agent-based multimodal fact-checking framework that emulates the human verification workflow through five specialized, collaboratively working agents. 3. Demonstrates that the synergy between the new dataset and the agent framework substantially improves both the accuracy and interpretability of multimodal fact-checking.",
      "summary": "This paper addresses the challenge of automated multimodal fact-checking by introducing a new dataset (RW-Post) and an agent-based framework (AgentFact). The dataset provides real-world misinformation instances with reasoning and evidence, while the framework uses specialized agents to collaboratively perform verification tasks. The combined approach is shown to significantly enhance the accuracy and explainability of fact-checking systems.",
      "mindmap": "graph TB\n        A[Multimodal Fact-Checking: An Agent-based Approach] --> B[核心问题/Problem: 多模态虚假信息传播与现有方法在推理和证据利用上的不足 / The spread of multimodal misinformation and the limitations of existing methods in reasoning and evidence utilization]\n        A --> C[主要方法/Method: 提出RW-Post数据集和AgentFact智能体框架 / Proposes the RW-Post dataset and the AgentFact agent-based framework]\n        A --> D[关键结果/Results: 显著提升了多模态事实核查的准确性和可解释性 / Substantially improves the accuracy and interpretability of multimodal fact-checking]"
    },
    {
      "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
      "authors": "Haoyuan Wu, Hai Wang, Jiajia Wu, Jinxiang Ou, Keyao Wang, Weile Chen, Zihao Zheng, Bei Yu",
      "institution": "Tencent, The Chinese University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.22955",
      "code": null,
      "tags": [
        "reinforcement learning",
        "policy gradient",
        "reward shaping",
        "next-token prediction",
        "exploration space",
        "cross-entropy loss"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e03f108685a26b73d2c14c07a3e7234e09a5b32e612d72a9751508fcbb93ec32_w640_q70.webp",
      "contributions": "1. Reinterprets standard cross-entropy loss as a specific instance of policy gradient optimization in a single-step episode, bridging supervised learning and RL. 2. Proposes a generalized pre-training objective using on-policy RL principles and a novel reward-shaping strategy to balance diversity and precision in the token-output distribution. 3. Empirically finds that a precision-oriented prior, rather than a high-entropy one, creates a more favorable exploration space for subsequent RL, enhancing reasoning performance.",
      "summary": "This paper investigates how the token-output distribution from pre-training shapes the exploration space for subsequent reinforcement learning (RL) in language models. It proposes a new pre-training method that frames next-token prediction as an RL problem, using a reward-shaping strategy to control distribution precision. The key finding is that a precision-focused prior, contrary to intuition, provides a better exploration foundation for RL than a high-entropy one.",
      "mindmap": "graph TB\n        Root[Diversity or Precision? A Deep Dive into Next Token Prediction] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[预训练分布如何影响后续RL的探索空间？/How does the pre-trained distribution affect the RL exploration space?]\n        Method[主要方法/Method] --> M1[将交叉熵损失重新解释为策略梯度/Reinterpret cross-entropy as policy gradient]\n        Method --> M2[提出基于奖励塑形的广义预训练目标/Propose a generalized pre-training objective with reward shaping]\n        M2 --> M2_1[正奖励缩放因子/Positive reward scaling factor]\n        M2 --> M2_2[排名感知的负令牌处理/Rank-aware negative token treatment]\n        Results[关键结果/Results] --> R1[精度导向的先验优于高熵先验/Precision-oriented prior yields superior exploration space]"
    },
    {
      "title": "Prompt engineering does not universally improve Large Language Model performance across clinical decision-making tasks",
      "authors": "Mengdi Chai, Ali R. Zomorrodi",
      "institution": "Harvard School of Public Health, Massachusetts General Hospital, Harvard Medical School, Broad Institute of MIT and Harvard",
      "link": "https://arxiv.org/pdf/2512.22966",
      "code": null,
      "tags": [
        "large language models for healthcare",
        "prompt engineering",
        "clinical decision support",
        "few-shot learning",
        "model evaluation",
        "temperature setting"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/30c995933cd74a3ca7c2af152821552a5355b6d092f084b174049b87f299a2bc_w640_q70.webp",
      "contributions": "1. Comprehensive evaluation of three state-of-the-art LLMs across the full clinical reasoning workflow, revealing high task-dependent performance variability. 2. Demonstration that prompt engineering (specifically MedPrompt variations) is not universally beneficial, improving performance only on the task with the lowest baseline accuracy. 3. Finding that targeted dynamic few-shot prompting does not consistently outperform random selection, suggesting a trade-off between example relevance and contextual diversity.",
      "summary": "This study evaluated the performance of LLMs like ChatGPT-4o on clinical decision-making tasks and tested if prompt engineering could improve it. The results show that prompt engineering is not a universal solution; it helps only on specific tasks and targeted few-shot learning is not always better than random selection. The impact of prompt engineering is highly dependent on the model and the specific clinical task.",
      "mindmap": "graph TB\n        A[Prompt engineering does not universally improve LLM performance across clinical decision-making tasks] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在真实临床决策中的实用性未充分探索/LLMs' practical utility in real-world clinical decision-making is underexplored]\n        C --> C1[评估三个LLM在五个临床任务上的开箱即用性能/Evaluate three LLMs' out-of-the-box performance on five clinical tasks]\n        C --> C2[应用MedPrompt框架的变体进行提示工程/Apply variations of the MedPrompt framework for prompt engineering]\n        D --> D1[提示工程并非万能方案，效果因任务而异/Prompt engineering is not a one-size-fits-all solution, effect varies by task]\n        D --> D2[针对性少样本提示并不总是优于随机选择/Targeted few-shot prompting does not consistently outperform random selection]"
    },
    {
      "title": "Improving Generalization in LLM Structured Pruning via Function-Aware Neuron Grouping",
      "authors": "Tao Yu, Yongqi An, Kuan Zhu, Guibo Zhu, Ming Tang, Jinqiao Wang",
      "institution": "Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Wuhan AI Research",
      "link": "https://arxiv.org/pdf/2512.23014",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "structured pruning",
        "post-training pruning",
        "function-aware grouping",
        "calibration bias",
        "sparsity allocation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/97a53f8a0eafa56a813a03f94cde349a2ee5aa7da51f314f7ec42da88585b4c3_w640_q70.webp",
      "contributions": "1. Proposes Function-Aware Neuron Grouping (FANG), a pruning framework that groups neurons based on the semantic context types they process to mitigate calibration bias. 2. Introduces a weighted importance estimation within each group that prioritizes tokens strongly correlated with the group's functional role, and preserves cross-context neurons. 3. Develops an adaptive sparsity allocation strategy per model block based on its functional complexity to better balance sparsity and performance.",
      "summary": "The paper addresses the limited generalization of existing post-training structured pruning methods for LLMs when calibration data is biased. It proposes FANG, a method that groups neurons by function, weights importance estimation accordingly, and adaptively allocates sparsity. Experiments show FANG improves downstream task accuracy and achieves state-of-the-art results when combined with existing pruning methods.",
      "mindmap": "graph TB\n        A[Improving Generalization in LLM Structured Pruning via Function-Aware Neuron Grouping] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: 校准集偏差导致剪枝后泛化能力差/Calibration bias leads to poor generalization after pruning]\n        C[主要方法/Method: 功能感知神经元分组与自适应剪枝/Function-Aware Neuron Grouping & Adaptive Pruning]\n        D[关键结果/Results: 提升下游任务准确率，达到SOTA/Improves downstream accuracy, achieves SOTA]"
    },
    {
      "title": "LENS: LLM-Enabled Narrative Synthesis for Mental Health by Aligning Multimodal Sensing with Language Models",
      "authors": "Wenxuan Xu, Arvind Pillai, Subigya Nepal, Amanda C Collins, Daniel M Mackin, Michael V Heinz, Tess Z Griffin, Nicholas C Jacobson, Andrew Campbell",
      "institution": "Dartmouth College, University of Virginia, Massachusetts General Hospital, Harvard Medical School",
      "link": "https://arxiv.org/pdf/2512.23025",
      "code": null,
      "tags": [
        "multimodal language models",
        "multimodal sensing",
        "time-series encoding",
        "ecological momentary assessment (EMA)"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4b276805556458f16b63a7994f848b1c3a3a24eeed8ecb80496361d925fb9d8_w640_q70.webp",
      "contributions": "1. Introduces LENS, a framework that aligns multimodal sensing data with language models to generate clinically grounded mental health narratives. 2. Constructs a large-scale dataset of over 100,000 sensor-text QA pairs by transforming Ecological Momentary Assessment (EMA) responses. 3. Trains a patch-level encoder to project raw sensor time-series signals directly into an LLM's representation space for native integration.",
      "summary": "The paper addresses the challenge of translating long-duration, multimodal sensor data into interpretable natural language for mental health assessment. It proposes the LENS framework, which creates a large sensor-text dataset and trains a specialized encoder to align sensor signals with an LLM, enabling the generation of clinically meaningful narratives. The results show LENS outperforms baselines on NLP and clinical metrics, and is validated by mental health professionals.",
      "mindmap": "graph TB\n        Root[LENS: LLM-Enabled Narrative Synthesis] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[传感器数据难以转化为自然语言/Sensor data hard to translate to text]\n        Problem --> P2[缺乏配对数据集/Lack of paired sensor-text datasets]\n        Method[主要方法/Method] --> M1[构建大规模传感器-文本QA数据集/Build large-scale sensor-text QA dataset]\n        Method --> M2[训练补丁级编码器对齐LLM/Train patch-level encoder to align with LLM]\n        Results[关键结果/Results] --> R1[在NLP和症状指标上超越基线/Outperforms baselines on NLP & symptom metrics]\n        Results --> R2[临床医生认为叙述全面有意义/Clinicians find narratives comprehensive & meaningful]"
    },
    {
      "title": "Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization",
      "authors": "Kerem Zaman, Shashank Srivastava",
      "institution": "UNC Chapel Hill",
      "link": "https://arxiv.org/pdf/2512.23032",
      "code": null,
      "tags": [
        "interpretability",
        "chain-of-thought",
        "faithfulness",
        "causal mediation analysis",
        "biasing features",
        "explainability"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/527440e442abe55ce371c5ad3ce8f49609f0398a6001b33523b6a3aa4bbc6e44_w640_q70.webp",
      "contributions": "1. Argues that the Biasing Features metric conflates unfaithfulness with incompleteness in Chain-of-Thought explanations. 2. Introduces a new faithful@k metric showing increased token budgets improve hint verbalization. 3. Uses Causal Mediation Analysis to show non-verbalized hints can still causally mediate predictions through the CoT.",
      "summary": "This paper challenges the use of hint-verbalization metrics like Biasing Features for evaluating the faithfulness of Chain-of-Thought reasoning. It proposes that apparent unfaithfulness is often due to incompleteness from lossy compression and tight token limits, not a lack of alignment, and demonstrates this using new metrics and causal mediation analysis. The conclusion advocates for a broader interpretability toolkit beyond hint-based evaluations.",
      "mindmap": "graph TB\n        A[Is Chain-of-Thought Really Not Explainability?<br/>Chain-of-Thought Can Be Faithful without Hint Verbalization] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Biasing Features 指标将不完整性误判为不忠实性<br/>Biasing Features metric mislabels incompleteness as unfaithfulness]\n        C --> C1[提出 faithful@k 指标并增加推理令牌预算<br/>Propose faithful@k metric & increase inference token budget]\n        C --> C2[使用因果中介分析<br/>Use Causal Mediation Analysis]\n        D --> D1[许多被标记为不忠实的 CoT 被其他指标判定为忠实<br/>Many CoTs flagged unfaithful are judged faithful by other metrics]\n        D --> D2[更大的令牌预算显著提高提示词显化率<br/>Larger token budgets greatly increase hint verbalization]\n        D --> D3[未显化的提示词仍可通过 CoT 因果中介预测<br/>Non-verbalized hints can causally mediate predictions through CoT]"
    },
    {
      "title": "Accelerating Language Model Workflows with Prompt Choreography",
      "authors": "TJ Bai, Jason Eisner",
      "institution": "Johns Hopkins University",
      "link": "https://arxiv.org/pdf/2512.23049",
      "code": null,
      "tags": [
        "llm inference",
        "KV cache",
        "multi-agent workflows",
        "prompt caching",
        "fine-tuning",
        "parallel decoding"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7be6fd2c8ed387f8c6d6cfba8ffad178e5ac937348602af7f9d1951150964c8c_w640_q70.webp",
      "contributions": "1. Introduces Prompt Choreography, a framework for efficient LLM workflow execution using a dynamic, global KV cache that allows arbitrary, reordered attention to cached messages. 2. Enables parallel LLM calls and overcomes limitations of static caching by allowing runtime reuse of dynamically generated messages. 3. Demonstrates that fine-tuning the LLM to work with the cache can mitigate performance differences, achieving significant latency reduction (2.0–6.2× faster time-to-first-token) and end-to-end speedups (&gt;2.2×).",
      "summary": "The paper addresses the inefficiency of redundant computation in multi-agent LLM workflows. It proposes Prompt Choreography, a framework that uses a dynamic, global KV cache to allow LLM calls to attend to arbitrary subsets of previously encoded messages, supporting parallel execution. The method, combined with fine-tuning, significantly reduces latency and achieves substantial speedups by reusing cached encodings instead of re-encoding from scratch.",
      "mindmap": "graph TB\n        Root(”Accelerating Language Model Workflows with Prompt Choreography”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”多智能体工作流冗余计算/Multi-agent workflow redundant computation”)\n        Method --> M1(”动态全局KV缓存/Dynamic global KV cache”)\n        Method --> M2(”支持任意消息子集与重排序/Support arbitrary message subset & reordering”)\n        Method --> M3(”支持并行调用与微调/Support parallel calls & fine-tuning”)\n        Results --> R1(”降低每消息延迟/Reduce per-message latency”)\n        Results --> R2(”实现端到端加速/Achieve end-to-end speedup”)"
    },
    {
      "title": "TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish",
      "authors": "Melikşah Türker, A. Ebrar Kızıloğlu, Onur Güngör, Susan Üsküdarlı",
      "institution": "Boğaziçi University, VNGRS-AI",
      "link": "https://arxiv.org/pdf/2512.23065",
      "code": null,
      "tags": [
        "language modeling",
        "ModernBERT",
        "Rotary Positional Embeddings",
        "FlashAttention",
        "monolingual Turkish",
        "encoder-only transformer"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc5c874163783e3d6e86937eb817ae8080c269ccc3607c50deebbe47ac22673_w640_q70.webp",
      "contributions": "1. Introduces TabiBERT, the first monolingual Turkish encoder trained from scratch using the modern ModernBERT architecture (RoPE, FlashAttention). 2. Presents TabiBench, a unified benchmarking framework with 28 datasets across 8 tasks for standardized evaluation of Turkish NLP models. 3. Demonstrates state-of-the-art performance on TabiBench, outperforming prior models like BERTurk and showing strong cross-domain generalization.",
      "summary": "This paper introduces TabiBERT, a large-scale monolingual Turkish encoder based on the ModernBERT architecture, trained from scratch on a diverse corpus. It also presents TabiBench, a comprehensive benchmarking framework. TabiBERT achieves state-of-the-art results on multiple Turkish NLP tasks, demonstrating superior performance and generalization compared to existing models.",
      "mindmap": "graph TB\n        A[TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Turkish NLP lacks a modern monolingual encoder/土耳其NLP缺乏现代单语编码器]\n        C --> C1[Train TabiBERT from scratch with ModernBERT architecture/使用ModernBERT架构从头训练TabiBERT]\n        C --> C2[Create TabiBench benchmark/创建TabiBench基准]\n        D --> D1[SOTA on TabiBench (77.58), beats BERTurk/在TabiBench上达到SOTA，超越BERTurk]\n        D --> D2[Strong gains in QA, code retrieval/在问答、代码检索任务上提升显著]"
    },
    {
      "title": "A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms",
      "authors": "Yingru Li, Ziniu Li, Jiacai Liu",
      "institution": "Not explicitly stated in provided content.",
      "link": "https://arxiv.org/pdf/2512.23097",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Imitation Learning",
        "Reinforcement Learning",
        "KL divergence",
        "Dense Gradient",
        "Sparse Gradient"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c49fbea41eedc7a9f58604cc114a9246db61882fc20a851c8ec68a24ff6b343_w640_q70.webp",
      "contributions": "1. Derives the exact gradient decomposition of a unified KL+reward objective into analytic Dense and sampled Sparse terms. 2. Provides an efficient logit-level gradient formula for GPU implementation. 3. Establishes mathematical equivalence to KL-regularized RLHF and discusses training curriculum implications.",
      "summary": "This paper proposes a unified framework for fine-tuning LLMs that integrates Imitation Learning and Reinforcement Learning. It analyzes the gradient of a combined objective to decompose it into a token-level Dense Gradient and a long-horizon Sparse Gradient, enabling efficient implementation. The work clarifies its relationship to existing methods like RLHF and discusses practical training considerations.",
      "mindmap": "graph TB\n        A[Hybrid Online RL and IL for LLMs] --> B[核心问题/Problem: Train-inference distribution mismatch in LLM fine-tuning]\n        A --> C[主要方法/Method: Unified framework combining Imitation Learning and Reinforcement Learning]\n        A --> D[关键结果/Results: Gradient decomposes into Dense Gradient (analytic) and Sparse Gradient (sampled)]"
    },
    {
      "title": "Reservoir Computing inspired Matrix Multiplication-free Language Model",
      "authors": "Takumi Shiratsuchi, Yuichiro Tanaka, Hakaru Tamukoh",
      "institution": "Kyushu Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.23145",
      "code": null,
      "tags": [
        "model compression (quantization/pruning)",
        "MatMul-free LM",
        "reservoir computing",
        "weight sharing",
        "ternary quantization",
        "MLGRU"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b5c1771a82be40c7ba47d813ef33ce372e599bd79d60507444a618ff4e28d2c_w640_q70.webp",
      "contributions": "1. Proposes a novel language model architecture that integrates reservoir computing principles into a MatMul-free LM to reduce training costs. 2. Introduces techniques of partially fixing/sharing weights and inserting reservoir layers to obtain dynamic representations without extra training overhead. 3. Combines operations to reduce memory accesses, achieving reductions in parameters, training time, and inference time while maintaining performance.",
      "summary": "This paper addresses the high computational cost of large language models by proposing a matrix multiplication-free model enhanced with reservoir computing. The method fixes/shared weights in selected layers and inserts reservoir layers to reduce training overhead and memory accesses. Experiments show the approach reduces parameters by up to 19%, training time by 9.9%, and inference time by 8.0% while maintaining comparable performance to the baseline.",
      "mindmap": "graph TB\n        A[Reservoir Computing inspired Matrix Multiplication-free Language Model] --> B[核心问题/Problem: LLMs计算成本高/High computational cost of LLMs]\n        A --> C[主要方法/Method: 结合储层计算与无矩阵乘法模型/Combine RC with MatMul-free LM, 固定共享权重/Fix & share weights, 减少内存访问/Reduce memory access]\n        A --> D[关键结果/Results: 参数减少19%/Params reduced by 19%, 训练时间减少9.9%/Training time reduced by 9.9%, 推理时间减少8.0%/Inference time reduced by 8.0%, 性能相当/Performance maintained]"
    },
    {
      "title": "Not too long do read: Evaluating LLM-generated extreme scientific summaries",
      "authors": "Zhuoqi Lyu, Qing Ke",
      "institution": "City University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.23206",
      "code": "https://github.com/netknowledge/LLM_summarization",
      "tags": [
        "text summarization",
        "extreme summarization",
        "TLDR",
        "abstractive summarization",
        "extractive summarization",
        "dataset creation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e22384bc3a440a2b34601b9d8ed0a9de58fdee4ff92f1d83db278778c4293a7_w640_q70.webp",
      "contributions": "1. Introduces BiomedTLDR, a novel high-quality dataset of researcher-authored scientific TLDRs, curated from author annotations in bibliographies. 2. Evaluates the performance of popular open-weight LLMs in generating scientific TLDRs from paper abstracts. 3. Provides an analysis revealing that LLM-generated summaries tend to be more extractive (closer to the source text's lexicon and structure) compared to more abstractive human-written summaries.",
      "summary": "This paper addresses the lack of high-quality datasets for evaluating LLMs in generating scientific extreme summaries (TLDRs) by introducing BiomedTLDR, a dataset of human-authored summaries. It then evaluates open-weight LLMs on this task and finds that, while some can produce human-like summaries, LLMs generally tend to be more extractive and less abstractive than human experts.",
      "mindmap": "graph TB\n        A[”Not too long do read: Evaluating LLM-generated extreme scientific summaries<br>论文标题”]\n        A --> B[”核心问题/Problem<br>Lack of high-quality scientific TLDR dataset hinders LLM evaluation”]\n        A --> C[”主要方法/Method<br>Propose BiomedTLDR dataset & test LLMs on TLDR generation”]\n        A --> D[”关键结果/Results<br>LLMs are more extractive; humans are more abstractive”]"
    },
    {
      "title": "Anka: A Domain-Specific Language for Reliable LLM Code Generation",
      "authors": "Saif Khalfan Saif Al Mazrouei",
      "institution": "University of Wisconsin-Madison",
      "link": "https://arxiv.org/pdf/2512.23214",
      "code": null,
      "tags": [
        "llm inference",
        "Domain-Specific Language",
        "Constrained Syntax",
        "Code Generation",
        "Data Transformation Pipeline",
        "In-Context Learning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e450f3b6354a05c4c0dfa0c22c4f8b8dfc33c08282380080deb2d2f3a335d4_w640_q70.webp",
      "contributions": "1. Introduced Anka, a domain-specific language (DSL) with explicit, constrained syntax designed to reduce ambiguity in LLM code generation. 2. Demonstrated that LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy without prior training. 3. Showed that purposefully designed DSLs can outperform general-purpose languages (e.g., Python) on complex multi-step tasks, significantly reducing errors in operation sequencing and state management.",
      "summary": "This paper hypothesizes that the flexibility of general-purpose languages leads to systematic errors in LLM code generation for complex tasks. To test this, it introduces Anka, a constrained DSL for data transformation pipelines. The results show that LLMs can learn Anka from prompts and achieve significantly higher accuracy on multi-step tasks compared to Python, demonstrating the advantage of constrained syntax for reliable code generation.",
      "mindmap": "graph TB\n        A[Anka: A Domain-Specific Language for Reliable LLM Code Generation] --> B[核心问题/Problem: LLMs make systematic errors in complex multi-step code generation]\n        A --> C[主要方法/Method: Design Anka, a constrained DSL for data transformation pipelines]\n        A --> D[关键结果/Results: High parse success & task accuracy; Anka outperforms Python on multi-step tasks]"
    },
    {
      "title": "Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process",
      "authors": "Zhijun Chen, Zeyu Ji, Qianren Mao, Junhang Cheng, Bangjie Qin, Hao Wu, Zhuoran Li, Jingzheng Li, Kai Sun, Zizhe Wang, Yikun Ban, Zhu Sun, Xiangyang Ji, Hailong Sun",
      "institution": "Beihang University, Zhongguancun Laboratory, Xi'an Jiaotong University, Hong Kong University of Science and Technology, Tsinghua University, Singapore University of Technology and Design",
      "link": "https://arxiv.org/pdf/2512.23213",
      "code": null,
      "tags": [
        "llm inference",
        "LLM Ensemble",
        "LLM-as-a-Judge",
        "Peer-Review",
        "Unsupervised Selection",
        "Truth Inference"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/366f9e4fb3bf94aabbe40f3849a7637d6656821ec3dde88cd37d06effd3ed3f5_w640_q70.webp",
      "contributions": "1. Proposes LLM-PeerReview, a novel, peer-review-inspired, and interpretable framework for unsupervised LLM ensemble selection. 2. Introduces a three-stage process (scoring via LLM-as-a-Judge, reasoning via aggregation, and selection) that leverages multiple LLMs to evaluate each other's responses. 3. Demonstrates strong empirical performance, with two variants significantly outperforming a recent advanced baseline (Smoothie-Global) on multiple datasets.",
      "summary": "This paper proposes LLM-PeerReview, an unsupervised ensemble method that selects the best response from multiple LLM candidates. The method uses a peer-review process where LLMs score each other's outputs, then aggregates these scores to make a final selection. The approach is shown to be simple and powerful, outperforming a strong baseline by a significant margin across several datasets.",
      "mindmap": "graph TB\n        A[LLM-PeerReview: Ensembling LLMs via Peer-Review] --> B[核心问题/Problem: Single LLM limitations & diverse model strengths]\n        A --> C[主要方法/Method: Unsupervised 3-stage peer-review framework]\n        C --> C1[评分/Scoring: LLM-as-a-Judge]\n        C --> C2[推理/Reasoning: Score aggregation (graphical model or averaging)]\n        C --> C3[选择/Selection: Pick highest-scoring response]\n        A --> D[关键结果/Results: Outperforms Smoothie-Global by ~7% points]"
    },
    {
      "title": "Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation",
      "authors": "Dianyun Wang, Qingsen Ma, Yuhu Shang, Zhifeng Lu, Lechen Ning, Zhenbo Xu, Huijia Wu, Zhaofeng He",
      "institution": "Beijing University of Posts and Telecommunications",
      "link": "https://arxiv.org/pdf/2512.23260",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Sparse Autoencoders (SAEs)",
        "Low-Rank Adaptation (LoRA)",
        "Safety Alignment",
        "Interpretability",
        "Parameter-efficient Fine-tuning (PEFT)"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e615e6d561cef5b79dc991ed964fd9b6fb069427af26a4b7b42cd33cea4315a_w640_q70.webp",
      "contributions": "1. Proposes a novel method that uses pre-trained Sparse Autoencoders (SAEs) to construct an explicit, interpretable low-rank subspace for adapter initialization, addressing the black-box nature of traditional LoRA. 2. Provides theoretical analysis proving that SAE-based subspace identification achieves arbitrarily small recovery error under monosemanticity, while direct identification suffers an irreducible error floor due to polysemanticity. 3. Demonstrates state-of-the-art performance on safety alignment, achieving up to 99.6% safety rate while updating only 0.19-0.24% of parameters, and provides interpretable insights into the learned alignment subspace.",
      "summary": "This paper addresses the lack of interpretability in standard Low-Rank Adaptation (LoRA) methods for fine-tuning large language models. The proposed method leverages Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled space and uses them to construct an explicit, interpretable low-rank subspace for adapter initialization. The approach achieves superior safety alignment performance and provides transparency into the learned adaptation process.",
      "mindmap": "graph TB\n        Root(”Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”LoRA缺乏可解释性/LoRA lacks interpretability”)\n        Problem --> P2(”子空间学习是黑盒的/Subspace learning is black-box”)\n        Method --> M1(”利用预训练SAE/Use pre-trained SAEs”)\n        Method --> M2(”构建显式低秩子空间/Construct explicit low-rank subspace”)\n        Results --> R1(”高安全率99.6%/High safety rate 99.6%”)\n        Results --> R2(”参数高效0.19%/Parameter-efficient 0.19%”)\n        Results --> R3(”提供可解释性/Provides interpretability”)"
    },
    {
      "title": "Chinese Morph Resolution in E-commerce Live Streaming Scenarios",
      "authors": "Jiahao Zhu, Jipeng Qiang, Ran Bai, Chenyu Liu, Xiaoye Ouyang",
      "institution": "Yangzhou University, China Academy of Electronic and Information Technology",
      "link": "https://arxiv.org/pdf/2512.23280",
      "code": null,
      "tags": [
        "morph resolution",
        "morph resolution",
        "text-to-text generation",
        "large language models",
        "automatic speech recognition",
        "e-commerce live streaming"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5833e430257262b6c7e7229b982e2421b63671f2902d24282bd2f2167c1934c_w640_q70.webp",
      "contributions": "1. Introduced the novel Live Auditory Morph Resolution (LiveAMR) task for detecting pronunciation-based evasion in e-commerce live streams, distinct from prior text-based morph research. 2. Constructed the first large-scale LiveAMR dataset containing 86,790 samples from health and medical live streaming scenarios. 3. Proposed a method that transforms the morph resolution task into a text-to-text generation problem and leveraged LLMs for data augmentation to improve model performance.",
      "summary": "This paper introduces the LiveAMR task to detect pronunciation-based morphs used by hosts in Chinese e-commerce live streams to evade voice censorship. The authors built a new dataset and framed the problem as a text-to-text generation task, using LLMs for data augmentation to boost performance. The study concludes that resolving these morphs significantly enhances the effectiveness of live streaming content regulation.",
      "mindmap": "graph TB\n        A[Chinese Morph Resolution in E-commerce Live Streaming Scenarios] --> B[核心问题/Problem: Hosts use pronunciation-based morphs for false advertising in live streams]\n        A --> C[主要方法/Method: Transform task to text-to-text generation, use LLMs for data augmentation]\n        A --> D[关键结果/Results: Built first LiveAMR dataset, method improves performance, aids regulation]"
    },
    {
      "title": "AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration",
      "authors": "Minjiang Huang, Jipeng Qiang, Yi Zhu, Chaowei Zhang, Xiangyu Zhao, Kui Yu",
      "institution": "Yangzhou University, City University of Hong Kong, Hefei University of Technology",
      "link": "https://arxiv.org/pdf/2512.23300",
      "code": "https://github.com/9624219/AI4reading",
      "tags": [
        "agent system",
        "multi-agent collaboration",
        "large language models (LLMs)",
        "speech synthesis",
        "audiobook interpretation",
        "Chinese NLP"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554ec6976f875a67d0faba12d389415bd8119634b07160c7f87e65bff826fc84_w640_q70.webp",
      "contributions": "1. Proposed AI4Reading, a novel multi-agent collaboration system for automatically generating podcast-like Chinese audiobook interpretations. 2. Designed a framework with 11 specialized agents (e.g., topic analysts, case analysts, editors) to achieve accurate content preservation, enhanced comprehensibility, and logical narrative structure. 3. Demonstrated through comparison with expert interpretations that the system generates simpler and more accurate interpretative scripts, though speech quality has room for improvement.",
      "summary": "This paper proposes AI4Reading, a system that uses multi-agent collaboration with LLMs and speech synthesis to automatically generate Chinese audiobook interpretations. The system employs 11 specialized agents to process content for accuracy, comprehensibility, and narrative structure. Evaluation shows the generated scripts are simpler and more accurate than expert ones, though speech generation quality still lags behind.",
      "mindmap": "graph TB\n        A[AI4Reading: Chinese Audiobook Interpretation System] --> B[核心问题/Problem: Manual audiobook interpretation creation is time-consuming and resource-intensive.]\n        A --> C[主要方法/Method: Multi-agent collaboration framework with 11 specialized agents using LLMs and speech synthesis.]\n        A --> D[关键结果/Results: Generated scripts are simpler and more accurate, but speech generation quality has a gap.]"
    },
    {
      "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations",
      "authors": "Huan-ang Gao, Zikang Zhang, Tianwei Luo, Kaisen Yang, Xinzhe Juan, Jiahao Qiu, Tianxing Chen, Bingxiang He, Hao Zhao, Hao Zhou, Shilong Liu, Mengdi Wang",
      "institution": "Tsinghua University, Princeton University, Shanghai Jiao Tong University & University of Michigan, The University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.23328",
      "code": null,
      "tags": [
        "agent evaluation",
        "spatial reasoning",
        "long-horizon planning",
        "partial observability",
        "mental simulation",
        "diagnostic benchmark"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/210465a4bf9048c43ec900e17f922e63394d83664c6fe631fec0d54577fd9fb6_w640_q70.webp",
      "contributions": "1. Identifies three core cognitive challenges (spatial reasoning, long-horizon state tracking, active exploration under partial observation) hindering LLM agents in the physical world. 2. Introduces CubeBench, a novel generative benchmark based on the Rubik's Cube with a three-tiered diagnostic framework to isolate and evaluate these capabilities. 3. Provides a diagnostic framework using external solver tools to analyze failure modes and reveals critical limitations of leading LLMs, including a 0.00% pass rate on long-horizon tasks.",
      "summary": "The paper introduces CubeBench, a diagnostic benchmark using a Rubik's Cube to evaluate LLM agents' spatial reasoning and long-horizon planning under partial observation. It employs a three-tiered framework from full symbolic to partial visual states. Experiments show leading LLMs fail completely on long-horizon tasks, highlighting a fundamental gap for physical-world deployment.",
      "mindmap": "graph TB\n        A[CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLM智能体缺乏物理世界部署所需的稳健空间心智模型/LLM agents lack robust spatial mental models for physical-world deployment]\n        C --> C1[提出基于魔方的三层诊断基准/CubeBench: A three-tiered diagnostic benchmark using Rubik's Cube]\n        C --> C2[从完整符号状态到部分视觉状态逐步评估/Progressive evaluation from full symbolic to partial visual state]\n        D --> D1[领先LLM在长视野任务上通过率为0%/Leading LLMs have 0.00% pass rate on long-horizon tasks]\n        D --> D2[揭示了长期规划和主动探索的根本性失败/Exposes fundamental failure in long-term planning and active exploration]"
    },
    {
      "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
      "authors": "Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin",
      "institution": "Harbin Institute of Technology, Fudan University, Peking University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.23343",
      "code": "https://github.com/AgentMemory/Huaman-Agent-Memory",
      "tags": [
        "agent system",
        "memory systems",
        "cognitive neuroscience",
        "LLM-driven agents",
        "memory security",
        "multimodal memory"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/15773eb4c52c63f2641be869baf3af4b7f6bb74f6e36c67247957bfbd039e9b6_w640_q70.webp",
      "contributions": "1. Provides a systematic synthesis and comparative analysis of memory systems from cognitive neuroscience to LLM-driven autonomous agents. 2. Reviews mainstream benchmarks for evaluating agent memory and explores memory security from attack and defense perspectives. 3. Envisions future research directions, focusing on multimodal memory systems and skill acquisition.",
      "summary": "This survey paper bridges the interdisciplinary gap between cognitive neuroscience and AI by systematically analyzing memory systems for autonomous agents. It compares biological and artificial memory taxonomies, storage, and management, while also reviewing evaluation benchmarks and security issues. The work concludes by outlining future directions, including multimodal memory and skill learning.",
      "mindmap": "graph TB\n        Root[AI Meets Brain: Memory Systems / AI与大脑：记忆系统] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[核心问题/Problem] --> P1[Interdisciplinary Gap / 跨学科鸿沟]\n        P1 --> P2[Existing works struggle to assimilate human memory essence / 现有工作难以吸收人类记忆机制精髓]\n    \n        Method[主要方法/Method] --> M1[Systematic Synthesis / 系统综述]\n        M1 --> M2[Comparative Analysis / 对比分析]\n        M2 --> M3[Review Benchmarks & Security / 回顾基准与安全]\n    \n        Results[关键结果/Results] --> R1[Unified Memory Framework / 统一的记忆框架]\n        R1 --> R2[Future Directions / 未来方向]\n        R2 --> R3[Multimodal Memory & Skill Acquisition / 多模态记忆与技能获取]"
    },
    {
      "title": "A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation",
      "authors": "Xin Zhang, Yang Cao, Baoxing Wu, Xinyi Chen, Kai Song, Siying Li",
      "institution": "Chongqing Jiaotong University, Chongqing University of Posts and Telecommunications",
      "link": "https://arxiv.org/pdf/2512.23356",
      "code": null,
      "tags": [
        "knowledge-augmented reasoning",
        "external knowledge graph",
        "subgraph generation",
        "stepwise reasoning",
        "large language models",
        "structured reasoning"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3999b4a75409aeb08ff19dfef01f6296ec2c9184a598991b29d9ce92c1f8e0a_w640_q70.webp",
      "contributions": "1. Proposes a novel stepwise reasoning enhancement framework (SGR) that dynamically constructs query-relevant subgraphs from external knowledge bases to guide LLM reasoning. 2. Introduces a method to perform multi-step reasoning grounded in the structured subgraph, reducing the influence of noisy information and improving logical consistency. 3. Demonstrates the framework's effectiveness through experiments on multiple benchmark datasets, showing consistent performance improvements over strong baselines.",
      "summary": "The paper addresses the limitation of LLMs in complex reasoning tasks by proposing SGR, a framework that enhances reasoning through dynamic external subgraph generation and step-by-step inference over the structured knowledge. Experimental results show that SGR improves reasoning accuracy and outperforms baseline methods.",
      "mindmap": "graph TB\n        A[基于外部子图生成的大语言模型逐步增强推理框架<br>A Stepwise-Enhanced Reasoning Framework for LLMs Based on External Subgraph Generation] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs在深度推理任务中面临挑战<br>LLMs face challenges in deep reasoning tasks]\n        B1 --> B2[生成过程可能包含噪声信息<br>Generation may incorporate noisy information]\n        C --> C1[动态构建查询相关外部子图<br>Dynamically constructs query-relevant external subgraphs]\n        C1 --> C2[基于子图进行多步推理<br>Performs multi-step reasoning grounded in the subgraph]\n        C2 --> C3[集成多条推理路径<br>Integrates multiple reasoning paths]\n        D --> D1[在多个基准数据集上表现优异<br>Outperforms baselines on multiple benchmark datasets]\n        D1 --> D2[有效提升LLM的推理能力<br>Effectively enhances LLM reasoning capabilities]"
    },
    {
      "title": "Theoretical Foundations of Scaling Law in Familial Models",
      "authors": "Huan Song, Qingfei Zhao, Ting Long, Shuyu Tian, Hongjun An, Jiawei Shao, Chi Zhang, Xuelong Li",
      "institution": "Institute of Artificial Intelligence (TeleAI), China Telecom",
      "link": "https://arxiv.org/pdf/2512.23407",
      "code": null,
      "tags": [
        "llm training",
        "familial models",
        "scaling law",
        "early exiting",
        "IsoFLOP design",
        "compute-optimal training"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dc66a2a88c82327d2e67ccabca47fcc7a15e81e139a0ed0135b0f3ea93534985_w640_q70.webp",
      "contributions": "1. Theoretically and empirically extends the neural scaling law to the \"familial models\" paradigm by introducing granularity (G) as a new fundamental scaling variable alongside model size (N) and tokens (D). 2. Proposes a rigorous IsoFLOP experimental design to decouple architectural impact from computational scale, enabling high-fidelity parameterization of the unified scaling law L(N, D, G). 3. Quantifies that the granularity penalty follows a multiplicative power law with an extremely small exponent (γ≈0.041), validating the \"train once, deploy many\" paradigm without compromising compute-optimality.",
      "summary": "This paper addresses the limitation of traditional neural scaling laws, which assume a single model, by extending them to familial models that generate multiple sub-models from one backbone. The authors propose a unified scaling law incorporating granularity (G) and validate it using a rigorous IsoFLOP experimental design. The key finding is that the performance penalty for increased granularity is very small, proving that deployment flexibility can be achieved efficiently.",
      "mindmap": "graph TB\n        A[Theoretical Foundations of Scaling Law in Familial Models] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统缩放定律忽略多模型范式/Traditional scaling laws overlook the multi-model paradigm]\n        C --> C1[引入粒度作为新变量/Introduce Granularity (G) as a new variable]\n        C --> C2[统一函数形式 L(N, D, G)/Unified functional form L(N, D, G)]\n        C --> C3[采用IsoFLOP实验设计/Employ rigorous IsoFLOP experimental design]\n        D --> D1[粒度惩罚遵循幂律/Granularity penalty follows a power law]\n        D --> D2[指数极小 (γ≈0.041)/Exponent is extremely small]\n        D --> D3[验证”一次训练，多次部署”/Validates ”train once, deploy many”]"
    },
    {
      "title": "Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data",
      "authors": "Jiapeng Wang, Yiwen Hu, Yanzipeng Gao, Haoyu Wang, Shuo Wang, Hongyu Lu, Jiaxin Mao, Wayne Xin Zhao, Junyi Li, Xiao Zhang",
      "institution": "Renmin University of China, Tsinghua University, Tencent (WeChat), City University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.23422",
      "code": null,
      "tags": [
        "language model training",
        "token dropout",
        "entropy-guided regularization",
        "multi-epoch training degradation",
        "autoregressive models",
        "data-constrained adaptation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ac5e3a92b434a83b0821bec18501089160580e913a30fb1e39f43b38943b7ef0_w640_q70.webp",
      "contributions": "1. Identifies and analyzes the root cause of multi-epoch training degradation in autoregressive LLMs as an imbalance in learning dynamics between low-entropy and high-entropy tokens. 2. Proposes EntroDrop, a novel entropy-guided token dropout method that acts as structured data regularization by selectively masking low-entropy tokens during training. 3. Demonstrates through experiments on models from 0.6B to 8B parameters that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training.",
      "summary": "The paper addresses the problem of performance degradation in autoregressive language models during multi-epoch training on limited domain data. It proposes EntroDrop, an entropy-guided token dropout method that selectively masks predictable, low-entropy tokens to regularize training and uses a curriculum schedule to adjust regularization strength. Experiments show EntroDrop effectively mitigates overfitting and maintains robust model performance across different scales, offering a promising approach for adapting LLMs in data-constrained domains.",
      "mindmap": "graph TB\n        A[Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[数据稀缺与多轮训练退化 / Data Scarcity & Multi-epoch Training Degradation]\n        C --> C1[熵引导的令牌丢弃 / Entropy-Guided Token Dropout (EntroDrop)]\n        C1 --> C2[结构化数据正则化 / Structured Data Regularization]\n        C1 --> C3[课程学习计划 / Curriculum Schedule]\n        D --> D1[优于基线正则化方法 / Outperforms Standard Regularization Baselines]\n        D --> D2[保持多轮训练鲁棒性 / Maintains Robust Performance in Multi-epoch Training]"
    },
    {
      "title": "C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs",
      "authors": "Xuan Feng, Bo An, Tianlong Gu, Liang Chang, Fengrui Hao, Peipeng Yu, Shuai Zhao",
      "institution": "Jinan University, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.23430",
      "code": null,
      "tags": [
        "bias mitigation",
        "Causal-Contrastive Preference Optimization",
        "spurious feature correlation",
        "fairness-sensitive preference update",
        "counterfactual signals",
        "composite bias"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26a9c5a41f0184f3fdb110be083a06995183a94e4255ffb7b2066647ec2306c9_w640_q70.webp",
      "contributions": "1. Introduces Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework that simultaneously discovers and suppresses latent spurious feature correlations to mitigate both stereotypical and structural biases in LLMs. 2. Proposes a method that leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths during optimization. 3. Designs a fairness-sensitive preference update mechanism that dynamically evaluates logit-level contributions to suppress shortcut features while preserving general reasoning capabilities.",
      "summary": "The paper addresses the composite bias problem in LLMs, where mitigating one type of bias (e.g., stereotypical) often worsens another (e.g., structural). It proposes Causal-Contrastive Preference Optimization (C2PO), a unified framework that uses causal counterfactual signals and a fairness-sensitive update to suppress spurious feature correlations. Experiments show C2PO effectively reduces both bias types while maintaining strong general reasoning performance.",
      "mindmap": "graph TB\n        A[C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Composite Bias in LLMs<br>刻板印象与结构偏见并存] --> B1[刻板印象偏见/Stereotypical Bias<br>e.g., gender, race]\n        B --> B2[结构偏见/Structural Bias<br>e.g., lexical overlap, position]\n        C[主要方法/Method<br>Causal-Contrastive Preference Optimization (C2PO)] --> C1[因果反事实信号/Causal Counterfactual Signals<br>隔离偏见特征]\n        C --> C2[公平敏感偏好更新/Fairness-Sensitive Preference Update<br>动态抑制捷径特征]\n        D[关键结果/Results<br>Extensive Experiments] --> D1[减轻偏见/Mitigates Biases<br>BBQ, Unqover, MNLI, HANS]\n        D --> D2[保持通用能力/Preserves General Utility<br>MMLU, GSM8K]"
    },
    {
      "title": "The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective",
      "authors": "Yi Zhao, Yongjun Zhu, Donghun Kim, Yuzhuo Wang, Heng Zhang, Chao Lu, Chengzhi Zhang",
      "institution": "Anhui University, Yonsei University, Nanjing University, Central China Normal University, Hohai University, Nanjing University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.23429",
      "code": null,
      "tags": [
        "scientometrics",
        "gender diversity",
        "team roles",
        "author contribution statements",
        "threshold regression",
        "citation impact"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8e0d6494840d098b4c65bf9f6eb6b4b27a82bd62024c95c0f60db9e5b8fa31f_w640_q70.webp",
      "contributions": "1. Introduced a team roles perspective by classifying authors into leadership and support roles using contribution statements, moving beyond aggregate diversity measures. 2. Discovered a non-linear (inverted U-shape) relationship between gender diversity and team impact for both leadership and support groups. 3. Revealed the moderating effect of team size, showing that the impact of leadership-group gender diversity shifts from negative to positive as team size increases, while support-group diversity remains consistently positive.",
      "summary": "This study investigates how gender diversity within specific team roles (leadership vs. support) affects scientific team impact, measured by citations. By analyzing over 130,000 PLOS papers and using contribution statements to define roles, the authors employed multivariable and threshold regression. They found the relationship is an inverted U-shape, identified high-impact team compositions, and showed that team size significantly moderates the effect of leadership diversity.",
      "mindmap": "graph TB\n        A[The Effect of Gender Diversity on Scientific Team Impact<br>性别多样性对科研团队影响力的影响] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Inconsistent findings on gender diversity's effect,<br>lack of role-differentiated analysis.<br>性别多样性影响结论不一，缺乏基于团队角色的分析]\n        C[主要方法/Method<br>Analyzed 130k+ PLOS papers, used contribution<br>statements for role classification (leadership/support),<br>applied multivariable & threshold regression.<br>分析13万+PLOS论文，利用贡献声明进行角色分类，应用多元及阈值回归]\n        D[关键结果/Results<br>1. Inverted U-shape relationship.<br>2. All-female leadership + all-male support yields high impact.<br>3. Team size moderates leadership diversity effect.<br>1. 倒U型关系。<br>2. 全女性领导+全男性支持的团队影响力更高。<br>3. 团队规模调节领导组多样性效应。]"
    },
    {
      "title": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning",
      "authors": "Yuqi Tang, Jing Yu, Zichang Su, Kehua Feng, Zhihui Zhu, Libin Wang, Lei Liang, Qiang Zhang, Keyan Ding, Huajun Chen",
      "institution": "Zhejiang University, AntGroup",
      "link": "https://arxiv.org/pdf/2512.23440",
      "code": null,
      "tags": [
        "evaluation & benchmarking",
        "clinical reasoning",
        "dynamic evaluation",
        "diagnostic dialogue",
        "knowledge graph",
        "multi-turn interaction"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63b6e11110703cffd0afa796f1abd60fa8928363db33520ff03e2f7a54abe3b0_w640_q70.webp",
      "contributions": "1. Proposes ClinDEF, a dynamic evaluation framework for LLMs that simulates multi-turn diagnostic dialogues grounded in a disease knowledge graph to better reflect real-world clinical reasoning. 2. Introduces a granular evaluation protocol that goes beyond diagnostic accuracy to include efficiency analysis and rubric-based assessment of diagnostic quality. 3. Demonstrates that the framework effectively exposes critical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.",
      "summary": "The paper addresses the gap in evaluating LLMs for clinical reasoning, which is a dynamic, interactive process poorly captured by static benchmarks. It proposes ClinDEF, a framework that uses a disease knowledge graph to dynamically generate patient cases and simulate diagnostic dialogues between an LLM doctor and an automated patient. Experiments show that ClinDEF effectively reveals critical reasoning deficiencies in advanced LLMs, providing a more realistic and detailed assessment tool.",
      "mindmap": "graph TB\n        A[ClinDEF: A Dynamic Evaluation Framework for LLMs in Clinical Reasoning] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[静态基准无法评估动态临床推理/Static benchmarks fail to evaluate dynamic clinical reasoning]\n        C --> C1[基于知识图谱的动态病例生成/Dynamic case generation via disease knowledge graph]\n        C --> C2[模拟多轮诊断对话/Simulated multi-turn diagnostic dialogue]\n        C --> C3[细粒度多层级评估协议/Fine-grained, multi-level evaluation protocol]\n        D --> D1[有效暴露LLM的临床推理缺陷/Effectively exposes LLMs' clinical reasoning gaps]\n        D --> D2[提供更细致、临床相关的评估/Offers more nuanced, clinically meaningful evaluation]"
    },
    {
      "title": "Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss",
      "authors": "Ang Lv, Jin Ma, Yiyuan Ma, Siyuan Qiao",
      "institution": "ByteDance, Renmin University of China",
      "link": "https://arxiv.org/pdf/2512.23447",
      "code": null,
      "tags": [
        "llm training",
        "Mixture-of-Experts",
        "Router-Expert Coupling",
        "Auxiliary Loss",
        "Expert Specialization",
        "Efficient Training"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6534d4f2f88c89a450614cf67b57f76f33fc90a18f24833876fd8e55d3e326b9_w640_q70.webp",
      "contributions": "1. Proposes a novel lightweight auxiliary loss (ERC loss) to explicitly couple router decisions with expert capabilities in MoE models. 2. Introduces a computationally efficient method that scales with the square of the number of experts (n^2), independent of batch size, unlike prior token-dependent methods. 3. Enables flexible control and quantitative tracking of expert specialization levels during training, providing new insights into MoE model dynamics.",
      "summary": "This paper addresses the misalignment between router decisions and expert capabilities in Mixture-of-Experts (MoE) models. It proposes an Expert-Router Coupling (ERC) loss, a lightweight auxiliary loss that enforces constraints via perturbed router embeddings to ensure each expert specializes in its routed tokens and each router embedding faithfully represents its expert. The method is shown to be effective and computationally efficient, enabling better control and analysis of expert specialization during large-scale pre-training.",
      "mindmap": "graph TB\n        A[耦合专家与路由器<br/>Coupling Experts and Routers in Mixture-of-Experts] --> B[核心问题/Problem: 路由器决策与专家能力不匹配<br/>Router decisions misaligned with expert capabilities]\n        A --> C[主要方法/Method: 提出专家-路由器耦合损失 (ERC Loss)<br/>Propose Expert-Router Coupling (ERC) Loss]\n        A --> D[关键结果/Results: 提升模型性能，高效计算，可量化追踪专家专业化<br/>Improved performance, efficient computation, quantifiable tracking of specialization]\n        C --> E[方法原理/Mechanism: 使用扰动路由器嵌入作为代理令牌<br/>Use perturbed router embeddings as proxy tokens]\n        E --> F[约束/Constraints: 专家对自身代理令牌激活最高；代理令牌引发对应专家最强激活<br/>Expert highest activation for own proxy; Proxy elicits strongest activation from corresponding expert]"
    },
    {
      "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
      "authors": "Kongcheng Zhang, Qi Yao, Shunyu Liu, Wenjian Zhang, Min Cen, Yang Zhou, Wenkai Fang, Yiru Zhao, Baisheng Lai, Mingli Song",
      "institution": "Zhejiang University, Cainiao Network, Nanyang Technological University, Dalian University of Technology, University of Science and Technology of China, Alibaba Cloud Computing, Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.23457",
      "code": "https://github.com/zhangkc97/HiR",
      "tags": [
        "reinforcement learning",
        "instruction following",
        "hindsight replay",
        "sample-efficient RL"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72e272e5c14b0f640f80b3e8859a1fd3a0a8b8e8608dfacee9528d242698f15_w640_q70.webp",
      "contributions": "1. Proposes Hindsight instruction Replay (HiR), a novel RL framework that replays failed attempts as successes using a select-then-rewrite strategy to address sparse rewards. 2. Theoretically frames the RL objective as dual-preference learning at both instruction- and response-level, enabling efficient optimization with only binary rewards. 3. Demonstrates sample efficiency and promising results across various instruction following tasks with reduced computational budget.",
      "summary": "This paper addresses the problem of sparse rewards in RL for aligning LLMs to follow complex instructions. It proposes HiR, a sample-efficient framework that replays failed responses as successful ones based on partially satisfied constraints, framed as dual-preference learning. Experiments show HiR achieves strong performance on instruction-following tasks while being more computationally efficient.",
      "mindmap": "graph TB\n        Root[Replay Failures as Successes: Sample-Efficient RL for Instruction Following] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[稀疏/不可区分的奖励阻碍学习<br>Sparse/Indistinguishable Rewards Impede Learning]\n        Method[后见指令重放 (HiR)<br>Hindsight instruction Replay (HiR)]\n        Results[跨任务有效且计算高效<br>Effective Across Tasks & Computationally Efficient]"
    },
    {
      "title": "Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings",
      "authors": "Thomas Haschka, Joseph Bakarji",
      "institution": "Technische Universität Wien, American University of Beirut",
      "link": "https://arxiv.org/pdf/2512.23471",
      "code": null,
      "tags": [
        "text clustering",
        "hierarchical clustering",
        "density-based clustering",
        "semantic embeddings",
        "large language models",
        "topic modeling"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e39c485de109f72521e714f1d7489795a2f6737dcaff2fbddf6af40f9dc170ee_w640_q70.webp",
      "contributions": "1. Proposes a novel nested density clustering method to construct hierarchical semantic trees from text embeddings. 2. Demonstrates the method's application for data-driven discovery of research areas and subfields without predefined categories. 3. Validates the approach's robustness and general applicability across diverse domains using benchmark datasets like 20 Newsgroups and IMDB reviews.",
      "summary": "The paper addresses the problem of uncovering the global hierarchical semantic structure in text corpora, which remains opaque when using LLM embeddings only for similarity search. It proposes a method that applies nested density clustering on LLM embeddings, gradually relaxing a density criterion to merge clusters into a hierarchical tree. This approach enables the data-driven discovery of semantic relationships and topic hierarchies without predefined categories, as demonstrated on scientific abstracts and benchmark datasets.",
      "mindmap": "graph TB\n        Root[”Semantic Tree Inference on Text Corpa / 文本语料库的语义树推断”]\n        Root --> Problem[”核心问题/Problem: Opaque global semantic structure in text corpora / 文本语料库中不透明的全局语义结构”]\n        Root --> Method[”主要方法/Method: Nested density clustering on LLM embeddings / 基于大语言模型嵌入的嵌套密度聚类”]\n        Root --> Results[”关键结果/Results: Data-driven hierarchical semantic tree discovery / 数据驱动的层次化语义树发现”]"
    },
    {
      "title": "Automatic Detection of Complex Quotation Patterns in Aggadic Literature",
      "authors": "Hadar Miller, Tsvi Kuflik, Moshe Lavee",
      "institution": "University of Haifa",
      "link": "https://arxiv.org/pdf/2512.23504",
      "code": null,
      "tags": [
        "text reuse detection",
        "morphology-aware alignment",
        "context-sensitive enrichment",
        "quotation pattern classification",
        "Hebrew text"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2678dc7eaa177b1fdea4a65073a64104dc415c64285803a4059dad8d21355551_w640_q70.webp",
      "contributions": "1. Proposes ACT, a novel three-stage algorithm combining morphology-aware alignment and context-sensitive enrichment for detecting complex biblical quotations in Rabbinic literature. 2. Introduces the ability to classify complex stylistic citation patterns such as \"Wave\" and \"Echo\" quotations, which existing frameworks struggle with. 3. Demonstrates superior performance (F1=0.91) over leading baselines, effectively bridging the gap between machine-based detection and human editorial judgment in digital humanities.",
      "summary": "This paper introduces ACT, a three-stage algorithm designed to automatically detect complex biblical quotations in Rabbinic literature by using morphology-aware alignment and context-sensitive enrichment. The method outperforms existing systems, achieving an F1 score of 0.91, and successfully identifies intricate citation patterns like \"Wave\" and \"Echo\" quotations. This work advances computational philology by improving the detection of short, paraphrased, and embedded text reuse in morphologically rich languages like Hebrew.",
      "mindmap": "graph TB\n        Root[”Automatic Detection of Complex Quotation Patterns in Aggadic Literature<br/>《阿加达文学中复杂引用模式的自动检测》”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Existing frameworks struggle with short, paraphrased, embedded quotations<br/>现有框架难以处理简短、转述、结构嵌入的引用”] --> P1[”挑战/Challenges<br/>Morphologically rich language (Hebrew)<br/>形态丰富的语言（希伯来语）”]\n        Method[”主要方法/Method<br/>ACT (Allocate Connections between Texts) algorithm<br/>ACT（文本间连接分配）算法”] --> M1[”阶段1/Stage 1<br/>Morphology-aware alignment<br/>形态感知对齐”]\n        Method --> M2[”阶段2/Stage 2<br/>Context-sensitive enrichment<br/>上下文敏感增强”]\n        Method --> M3[”目标/Goal<br/>Detect 'Wave' & 'Echo' patterns<br/>检测'波浪'与'回声'引用模式”]\n        Results[”关键结果/Results<br/>Outperforms baselines (Dicta, Passim, Text-Matcher)<br/>超越基线系统”] --> R1[”性能/Performance<br/>F1=0.91, Recall=0.89, Precision=0.94<br/>F1分数0.91，召回率0.89，精确率0.94”]\n        Results --> R2[”应用/Application<br/>Opens avenues for genre classification & intertextual analysis<br/>为体裁分类与互文分析开辟新途径”]"
    },
    {
      "title": "Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias",
      "authors": "Hazel Kim, Philip Torr",
      "institution": "University of Oxford",
      "link": "https://arxiv.org/pdf/2512.23518",
      "code": null,
      "tags": [
        "llm robustness & bias",
        "confirmation bias",
        "latent concept experts",
        "inference-time intervention",
        "multi-agent debate",
        "compositional language"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/293e04fd5f7eeb86a4cdafce819a7b7ac1c4ab97756b2f0a2b0305fec15d2fe8_w640_q70.webp",
      "contributions": "1. Introduces MoLaCE, a lightweight inference-time framework that mitigates LLM confirmation bias by mixing experts instantiated as different activation strengths over latent concepts. 2. Provides the key insight that no single fixed intervention works universally because prompts reweight latent concepts in prompt-specific ways. 3. Demonstrates that the method enables a single LLM to emulate debate benefits efficiently and can be integrated into multi-agent frameworks to reduce correlated errors.",
      "summary": "The paper addresses the problem of confirmation bias in LLMs, where models reinforce a preferred answer implied by a prompt. It proposes MoLaCE, a framework that mixes latent concept experts at inference time to diversify perspectives internally. The method reduces bias, improves robustness, and matches multi-agent debate performance with significantly less computation.",
      "mindmap": "graph TB\n        A[MoLaCE: Mixture of Latent Concept Experts <br/> 潜在概念专家混合] --> B[Problem: LLM Confirmation Bias <br/> 问题: LLM确认偏误]\n        A --> C[Method: Mix Experts via Latent Concept Activations <br/> 方法: 通过潜在概念激活混合专家]\n        A --> D[Results: Reduces Bias, Efficient, Matches Multi-Agent Debate <br/> 结果: 减少偏误, 高效, 匹敌多智能体辩论]"
    },
    {
      "title": "UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?",
      "authors": "Fengjiao Chen, Minhao Jing, Weitao Lu, Yan Feng, Xiaoyu Li, Xuezhi Cao",
      "institution": "Meituan",
      "link": "https://arxiv.org/pdf/2512.23512",
      "code": null,
      "tags": [
        "multi-modal training",
        "vision-language model",
        "unified model",
        "semantic generation",
        "autoregression",
        "data scaling"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a75dffd20dae849b9b4d37288d6d557fa32f5f2c8bf947c87fc1e79319e9dbe8_w640_q70.webp",
      "contributions": "1. Demonstrates that generation enhances understanding in large-scale VLM training only when operating at the semantic level (e.g., autoregressing high-level visual representations), not at the pixel level. 2. Shows that unified generation-understanding models exhibit superior data scaling trends and higher data utilization efficiency compared to understanding-only models. 3. Proposes that autoregression on input embeddings is an effective and modality-independent method for capturing visual details, enabling pixel-level generation from learned semantics.",
      "summary": "This paper investigates whether visual generation tasks can enhance understanding in large-scale vision-language models. Through large-scale pretraining (&gt;200M samples) with a model called UniHetero, the authors find that semantic-level generation (not pixel-level) improves understanding, reveals better data scaling, and that autoregression on input embeddings effectively captures visual details.",
      "mindmap": "graph TB\n        A[UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?] --> B(核心问题/Problem: Does visual generation enhance understanding at large scale?);\n        A --> C(主要方法/Method: Large-scale pretraining of unified model UniHetero (>200M samples));\n        A --> D(关键结果/Results);\n        B --> D;\n        C --> D;\n        D --> E(结果1/Result 1: Generation helps, but Only if you generate Semantics, Not Pixels);\n        D --> F(结果2/Result 2: Superior Data Scaling trend and higher Data Utilization);\n        D --> G(结果3/Result 3: Autoregression on Input Embedding is effective);"
    },
    {
      "title": "Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs",
      "authors": "Sahil Kale, Antonio Luca Alfeo",
      "institution": "Knowledge Verse AI, eCampus University",
      "link": "https://arxiv.org/pdf/2512.23547",
      "code": "https://github.com/knowledge-verse-ai/kg-hallu-eval",
      "tags": [
        "hallucination detection",
        "knowledge graphs",
        "self-detection",
        "structured verification",
        "GPT-4o",
        "Gemini-2.5-Flash"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a76b4a88e64d73392aa8d986a7f3dab5da424782ba41d701ca8db2d4ab4a12d_w640_q70.webp",
      "contributions": "1. Proposes a novel hallucination self-detection method that converts LLM responses into knowledge graphs for structured analysis., 2. Introduces a manually curated and enhanced hallucination detection dataset to support more reliable future benchmarking., 3. Demonstrates significant performance improvements (up to 16% accuracy, 20% F1) over standard self-detection and a state-of-the-art baseline (SelfCheckGPT).",
      "summary": "This paper addresses the problem of hallucinations in LLMs by proposing a self-detection method that converts model responses into knowledge graphs to better analyze atomic facts and estimate hallucination likelihood. The method, evaluated on GPT-4o and Gemini-2.5-Flash, shows substantial improvements in accuracy and F1-score over existing approaches. The work concludes that structuring facts as knowledge graphs enables more robust hallucination detection, offering a low-cost, model-agnostic path toward safer language models.",
      "mindmap": "graph TB\n        A[”Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs”] --> B[”核心问题/Problem: LLM Hallucinations hinder safe deployment”]\n        A --> C[”主要方法/Method: Convert responses to Knowledge Graphs for structured self-verification”]\n        A --> D[”关键结果/Results: Up to 16% accuracy & 20% F1 improvement over baselines”]"
    },
    {
      "title": "VL-RouterBench: A Benchmark for Vision-Language Model Routing",
      "authors": "Zhehao Huang, Baijiong Lin, Jingyuan Zhang, Jingying Wang, Yuhang Liu, Ning Lu, Tao Li, Xiaolin Huang",
      "institution": "Shanghai Jiao Tong University, The Hong Kong University of Science and Technology (Guangzhou), The Hong Kong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.23562",
      "code": "https://github.com/K1nght/VL-RouterBench",
      "tags": [
        "multi-modal inference",
        "vision-language model routing",
        "benchmark",
        "cost-accuracy trade-off",
        "model selection",
        "evaluation protocol"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/885d9087464eedead5301ad4cd041923ddee6d5773371e117abbd30fc4ae4f09_w640_q70.webp",
      "contributions": "1. Proposes VL-RouterBench, the first systematic and reproducible benchmark for evaluating vision-language model (VLM) routing systems. 2. Constructs a large-scale evaluation foundation with quality and cost matrices over 519,180 sample-model pairs from 17 models and 14 datasets. 3. Introduces a comprehensive evaluation protocol that jointly measures accuracy, cost, and throughput, and uses a ranking score based on the harmonic mean for fair comparison across router configurations.",
      "summary": "This paper introduces VL-RouterBench, a benchmark to systematically evaluate routing systems for vision-language models. It constructs matrices of quality and cost from extensive inference logs and uses a ranking score to compare routers. The evaluation shows current routers achieve significant gains but still fall short of an ideal Oracle, indicating room for improvement in router design.",
      "mindmap": "graph TB\n        Root[VL-RouterBench: A Benchmark for Vision-Language Model Routing] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem<br>缺乏系统化、可复现的<br>VLM路由评估基准<br>Lack of systematic, reproducible<br>benchmark for VLM routing]\n        Method[主要方法/Method<br>基于原始推理日志构建<br>质量与成本矩阵<br>Construct quality & cost matrices<br>from raw inference logs]\n        Results[关键结果/Results<br>观察到显著的路由增益<br>但与理想性能仍有差距<br>Observe significant routability gain<br>but clear gap to ideal Oracle]"
    },
    {
      "title": "Instruction-Following Evaluation of Large Vision-Language Models",
      "authors": "Daiki Shiono, Shumpei Miyawaki, Ryota Tanaka, Jun Suzuki",
      "institution": "Tohoku University, NTT Corporation",
      "link": "https://arxiv.org/pdf/2512.23572",
      "code": null,
      "tags": [
        "instruction-following evaluation",
        "large vision-language models",
        "visual instruction tuning",
        "output format specification"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9a9ab8218c47b2791fe28909d9e490dfaa5d680ecfb209ca796611f893b9430_w640_q70.webp",
      "contributions": "1. Quantitatively demonstrates the decline in instruction-following ability of LVLMs after visual instruction fine-tuning. 2. Constructs new training datasets that highlight whether the output format is specified. 3. Shows that explicitly indicating the output format during fine-tuning helps LVLMs follow instructions more accurately.",
      "summary": "This paper identifies and quantifies a problem where Large Vision-Language Models (LVLMs) lose their instruction-following ability after visual instruction tuning. The authors propose constructing datasets that explicitly specify the output format and find that training with such data mitigates the performance decline. The main conclusion is that including instructions on output format during fine-tuning can help preserve LVLMs' instruction-following capabilities.",
      "mindmap": "graph TB\n        A[Instruction-Following Evaluation of Large Vision-Language Models] --> B(核心问题/Problem: LVLMs lose instruction-following ability after fine-tuning)\n        A --> C(主要方法/Method: Construct datasets highlighting output format specification)\n        A --> D(关键结果/Results: Explicit output format instructions improve instruction-following)"
    },
    {
      "title": "Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models",
      "authors": "Yu-Xiang Lin, Cheng-Han Chiang, Hung-yi Lee",
      "institution": "National Taiwan University",
      "link": "https://arxiv.org/pdf/2512.23578",
      "code": null,
      "tags": [
        "spoken language understanding",
        "spoken language models",
        "style amnesia",
        "multi-turn conversation",
        "paralinguistic features",
        "instruction following"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d7d00f21d056c5ef5d2a037960cefe1ed2dea85d21396e8409388c6f482ecbf8_w640_q70.webp",
      "contributions": "1. Identifies and defines the \"style amnesia\" problem where spoken language models fail to maintain a user-specified speaking style across multiple conversation turns. 2. Provides a comprehensive evaluation across multiple proprietary and open-source SLMs, demonstrating the pervasiveness of the issue across different emotion, accent, volume, and speed styles. 3. Investigates mitigation strategies, finding that explicit recall prompts can partially alleviate the problem and revealing a counter-intuitive weakness when style instructions are placed in system messages.",
      "summary": "This paper investigates the problem of \"style amnesia\" in spoken language models (SLMs), where models instructed to adopt a specific speaking style fail to maintain it over a multi-turn conversation. The authors evaluate several SLMs and find that explicitly prompting the model to recall the style instruction can partially mitigate the issue. The study concludes that current SLMs struggle with long-term style consistency, a critical challenge for natural spoken interactions.",
      "mindmap": "graph TB\n        Root(”Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”SLMs在多轮对话中无法维持指定的副语言风格/SLMs cannot maintain specified paralinguistic style in multi-turn conversation”)\n        Method --> M1(”在多轮对话开始时指定风格并评估/Instruct style at conversation start and evaluate”)\n        Method --> M2(”使用自动评估器测量指令遵循率/Use automatic judges to measure instruction-following rate”)\n        Method --> M3(”测试不同的提示策略/Test different prompting strategies”)\n        Results --> R1(”发现风格遗忘现象，指令遵循率随轮次下降/Style amnesia found, IF rate degrades over turns”)\n        Results --> R2(”显式回忆指令可部分缓解问题/Explicit recall can partially mitigate”)\n        Results --> R3(”系统提示中的指令效果不佳/Instructions in system prompts perform poorly”)"
    },
    {
      "title": "Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing",
      "authors": "Yuwen Li, Wei Zhang, Zelong Huang, Mason Yang, Jiajun Wu, Shawn Guo, Huahao Hu, Lingyi Sun, Jian Yang, Mingjie Tang, Byran Dai",
      "institution": "Sichuan University, Beihang University, IQuest Research",
      "link": "https://arxiv.org/pdf/2512.23611",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent synthesis",
        "tool calling",
        "Group Relative Policy Optimization (GRPO)",
        "closed-loop training",
        "synthetic data generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4e1a538efae439be7bacc740036b08c6466db773784245f942d9dee539143f92_w640_q70.webp",
      "contributions": "1. Introduces InfTool, a fully autonomous framework that uses a multi-agent role-playing system (User Simulator, Tool-Calling Assistant, MCP Server) to generate high-quality, verified tool-use trajectories from raw API specifications without human annotation. 2. Establishes a closed-loop system where synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, and the improved model then generates higher-quality data, iteratively targeting capability gaps. 3. Demonstrates state-of-the-art performance, transforming a base 32B model's accuracy on the Berkeley Function-Calling Leaderboard from 19.8% to 70.9% using only synthetic data, surpassing much larger models.",
      "summary": "The paper addresses the challenge of enabling LLMs to reliably use external tools by proposing InfTool, a fully autonomous framework that uses multi-agent role-playing to synthesize and iteratively improve tool-use data in a closed loop. The method eliminates the need for human annotation and significantly boosts model performance, as shown by a 258% accuracy improvement on a standard benchmark, rivaling top proprietary models.",
      "mindmap": "graph TB\n        A[Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LLMs可靠调用外部工具存在瓶颈<br>1. 数据稀缺与标注昂贵<br>2. 泛化能力差<br>3. 单模型合成存在质量上限]\n        C[主要方法/Method<br>InfTool: 自演化的多智能体合成框架<br>1. 三智能体角色扮演生成轨迹<br>2. 闭环训练: GRPO与门控奖励<br>3. 从原始API规范合成数据]\n        D[关键结果/Results<br>在BFCL上，32B基础模型准确率从19.8%提升至70.9%<br>超越10倍大的模型，媲美Claude-Opus<br>完全使用合成数据，无需人工标注]"
    },
    {
      "title": "A Dataset and Benchmark for Consumer Healthcare Question Summarization",
      "authors": "Abhishek Basu, Deepak Gupta, Dina Demner-Fushman, Shweta Yadav",
      "institution": "University of Illinois at Chicago, U.S. National Library of Medicine (National Institutes of Health)",
      "link": "https://arxiv.org/pdf/2512.23637",
      "code": null,
      "tags": [
        "text summarization",
        "consumer health questions",
        "abstractive summarization",
        "dataset creation",
        "benchmark evaluation",
        "domain-expert annotation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7c0dbdf4700510ae2858b673b1f5b293ecd42ac6dcf6f757d42fb65d3706d4b0_w640_q70.webp",
      "contributions": "1. Introduces CHQ-Summ, a new dataset of 1507 domain-expert annotated consumer health questions and summaries. 2. Addresses the lack of domain-expert annotated data for the specific task of consumer healthcare question summarization. 3. Provides a benchmark evaluation of the dataset using multiple state-of-the-art summarization models to demonstrate its utility.",
      "summary": "The paper addresses the challenge of summarizing verbose consumer health questions by introducing CHQ-Summ, a new expert-annotated dataset. It benchmarks this dataset on modern summarization models to validate its effectiveness for developing better healthcare question understanding systems.",
      "mindmap": "graph TB\n        A[CHQ-Summ Dataset and Benchmark] --> B[核心问题/Problem: Lack of expert-annotated data for summarizing consumer health questions]\n        A --> C[主要方法/Method: Create CHQ-Summ dataset with 1507 expert-annotated Q&A pairs]\n        A --> D[关键结果/Results: Benchmark shows dataset's effectiveness for model training and evaluation]"
    },
    {
      "title": "Nested Browser-Use Learning for Agentic Information Seeking",
      "authors": "Baixuan Li, Jialong Wu, Wenbiao Yin, Kuan Li, Zhongwang Zhang, Huifeng Yin, Zhengwei Tao, Liwen Zhang, Pengjun Xie, Jingren Zhou, Yong Jiang",
      "institution": "Tongyi Lab, Alibaba Group",
      "link": "https://arxiv.org/pdf/2512.23647",
      "code": "https://github.com/Alibaba-NLP/DeepResearch",
      "tags": [
        "agent system",
        "information-seeking agents",
        "browser interaction",
        "ReAct-style agents",
        "nested framework"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab4c5e1fc52fc83cedffe542098b6777a8df396f1f3d30f2a130aebdd36e0dc_w640_q70.webp",
      "contributions": "1. Proposes a minimal and complete browser-action framework for agents, 2. Introduces a nested structure to decouple interaction control from page exploration, 3. Demonstrates improved performance on deep information-seeking benchmarks.",
      "summary": "The paper addresses the limitation of current information-seeking agents, which rely on simple API calls and cannot perform real browsing. It proposes NestBrowse, a framework that uses a nested structure to enable fine-grained browser control for agents, simplifying reasoning and improving performance on deep search tasks.",
      "mindmap": "graph TB\n        Root[”Nested Browser-Use Learning for Agentic Information Seeking<br>面向智能信息搜索的嵌套浏览器使用学习”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Agents lack real browsing, limited to APIs.”]\n        Method[”主要方法/Method<br>NestBrowse: nested browser-action framework.”]\n        Results[”关键结果/Results<br>Better performance on deep IS benchmarks.”]"
    },
    {
      "title": "Less is more: Probabilistic reduction is best explained by small-scale predictability measures",
      "authors": "Cassandra L. Jacobs, Andrés Buxó-Lugo, Anna K. Taylor, Marie Leopold-Hooke",
      "institution": "University at Buffalo, EURECOM",
      "link": "https://arxiv.org/pdf/2512.23659",
      "code": null,
      "tags": [
        "computational psycholinguistics",
        "probabilistic reduction",
        "n-gram",
        "language model",
        "cognitive planning",
        "articulatory dynamics"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5de081f03ed5643721a634ff064418b253cb9682ea7ef7e28d08b32112cd4028_w640_q70.webp",
      "contributions": "1. Demonstrates that local, small-scale predictability measures (n-grams) are sufficient to explain probabilistic reduction in speech, challenging the necessity of large-context LLMs for this cognitive phenomenon. 2. Provides evidence that n-gram representations can serve as effective cognitive units of planning in language production. 3. Argues for the cognitive plausibility and computational efficiency of incremental, phrase-level planning over whole-utterance planning.",
      "summary": "This paper investigates how much context is needed to model the relationship between word predictability and articulatory reduction (probabilistic reduction). It finds that local n-gram probabilities are sufficient to explain this effect, suggesting that language production planning operates on a small, incremental scale rather than relying on large-context language models. The main conclusion is that \"less is more\"—small-scale predictability measures best explain the cognitive phenomenon of probabilistic reduction.",
      "mindmap": "graph TB\n        Root[”Less is more: Probabilistic reduction is best explained by small-scale predictability measures<br>论文标题”]\n        Root --> Problem[”核心问题/Problem<br>How much context is needed to link language model probabilities to cognitive phenomena?”]\n        Root --> Method[”主要方法/Method<br>Compare n-gram vs. whole-utterance (LLM) context for modeling probabilistic reduction”]\n        Root --> Results[”关键结果/Results<br>N-gram representations suffice; small-scale predictability is best”]"
    },
    {
      "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
      "authors": "Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai.-Doss",
      "institution": "International School of Athens, Idiap Research Institute",
      "link": "https://arxiv.org/pdf/2512.23684",
      "code": null,
      "tags": [
        "adversarial attacks",
        "prompt injection",
        "large language models",
        "academic peer review",
        "multilingual",
        "adversarial robustness"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6285e0b940378fdc27628286ec6510afd35bf7a004b7ad95ad776e49035c6e1c_w640_q70.webp",
      "contributions": "1. Constructed a dataset of ~500 real ICML papers to empirically evaluate hidden prompt injection attacks in a realistic academic reviewing context. 2. Demonstrated that embedding semantically equivalent adversarial instructions in multiple languages (English, Japanese, Chinese, Arabic) can significantly alter LLM-generated review scores and decisions. 3. Revealed notable cross-lingual differences in attack effectiveness, with Arabic injections having minimal impact compared to others.",
      "summary": "This paper investigates the vulnerability of LLM-based academic peer review systems to hidden prompt injection attacks. By injecting adversarial instructions in four languages into a dataset of real papers and having an LLM review them, the authors found that such attacks can substantially change review outcomes for English, Japanese, and Chinese, but not Arabic. The results highlight a critical security risk and language-dependent susceptibility in automated reviewing pipelines.",
      "mindmap": "graph TB\n        A[Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>LLM-based reviewing systems are vulnerable to hidden prompt injection attacks.]\n        C[主要方法/Method<br>Inject semantically equivalent adversarial prompts in 4 languages into ~500 real papers and review with an LLM.]\n        D[关键结果/Results<br>English, Japanese, Chinese injections change scores/decisions; Arabic injections have little effect.]"
    },
    {
      "title": "Eliciting Behaviors in Multi-Turn Conversations",
      "authors": "Jing Huang, Shujian Zhang, Lun Wang, Andrew Hard, Rajiv Mathews, John Lambert",
      "institution": "Google DeepMind, Stanford University",
      "link": "https://arxiv.org/pdf/2512.23701",
      "code": null,
      "tags": [
        "llm evaluation",
        "behavior elicitation",
        "multi-turn conversation",
        "online methods",
        "dynamic benchmarks",
        "test case generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/afe3305263c3b509bdd6e846cce6501d101c0ecedb788ef025ac0c9405a28103_w640_q70.webp",
      "contributions": "1. Proposes an analytical framework categorizing behavior elicitation methods into three families based on their interaction with the target model (prior knowledge, offline, online). 2. Introduces a generalized multi-turn formulation for online behavior elicitation methods, unifying single-turn and multi-turn settings. 3. Demonstrates the superior efficiency of online methods in discovering failure cases in multi-turn conversations compared to static benchmarks, advocating for a shift to dynamic evaluation.",
      "summary": "This paper studies the problem of efficiently eliciting specific behaviors from large language models in multi-turn conversational settings. It introduces a framework for categorizing existing elicitation methods and proposes a generalized online method for multi-turn interactions. The key finding is that online methods can discover many more failure cases with few queries than static benchmarks, highlighting the need for dynamic evaluation approaches.",
      "mindmap": "graph TB\n        A[Eliciting Behaviors in Multi-Turn Conversations] --> B(核心问题/Problem: How to efficiently elicit specific behaviors from LLMs in multi-turn conversations?)\n        A --> C(主要方法/Method: Categorizes methods into three families; Proposes a generalized multi-turn online formulation.)\n        A --> D(关键结果/Results: Online methods achieve high success rates with few queries, outperforming static benchmarks.)"
    },
    {
      "title": "Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans",
      "authors": "Sky CH-Wang, Justin Svegliato, Helen Appel, Jason Eisner",
      "institution": "Columbia University, Microsoft, Johns Hopkins University",
      "link": "https://arxiv.org/pdf/2512.23693",
      "code": null,
      "tags": [
        "human feedback for alignment",
        "fine-grained feedback",
        "preference optimization",
        "feedback-driven improvement chains",
        "direct alignment",
        "Lamarckian evolution"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/de3cdf920bd014e6557ee3cfbe026bd31e5dfb982b5040c20b2797bf29ee9574_w640_q70.webp",
      "contributions": "1. Introduces a novel dataset with fine-grained human feedback where annotators mark and explain \"liked\" and \"disliked\" spans in model responses. 2. Proposes a method to use this feedback to generate \"feedback-driven improvement chains,\" where the base model incrementally rewrites disliked spans to create a sequence of improved responses. 3. Demonstrates that constructing preference pairs from adjacent steps in these chains for direct alignment outperforms standard A/B preference ranking or full contrastive rewrites, leading to more efficient and effective preference tuning.",
      "summary": "This paper proposes a method for fine-tuning LLMs using fine-grained human feedback on specific text spans. The core idea is to have annotators mark liked/disliked spans, then use the base model to iteratively rewrite the disliked spans, creating a chain of improvements. The key finding is that using these incremental revisions to create preference pairs for direct alignment leads to better model performance than standard preference-based methods.",
      "mindmap": "graph TB\n        A[Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[标准A/B偏好对噪声大且难以判断/Standard A/B preference pairs are noisy and hard to judge]\n        C --> C1[收集细粒度跨度级反馈/Collect fine-grained span-level feedback]\n        C --> C2[构建反馈驱动的改进链/Build feedback-driven improvement chains]\n        C --> C3[从链中相邻步骤创建偏好对/Create preference pairs from adjacent chain steps]\n        D --> D1[基于修订的监督更有效/Revision-based supervision is more effective]\n        D --> D2[超越标准直接对齐方法/Outperforms standard direct alignment methods]"
    },
    {
      "title": "Web World Models",
      "authors": "Jichen Feng, Yifan Zhang, Chenggong Zhang, Yifu Lu, Shilong Liu, Mengdi Wang",
      "institution": "Princeton University, University of California, Los Angeles, University of Pennsylvania",
      "link": "https://arxiv.org/pdf/2512.23676",
      "code": "https://princeton-ai2-lab.github.io/Web-World-Models/",
      "tags": [
        "agent system",
        "world model",
        "language agent",
        "web framework",
        "structured latent state",
        "deterministic generation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ed8017bbc1bd6722a0d7bd0f84c67f735c0f1b24747518e2aa15905d07d1b03c_w640_q70.webp",
      "contributions": "1. Introduced the Web World Model (WWM), a hybrid architecture that uses ordinary web code to enforce logical consistency and LLMs to generate open-ended content. 2. Built a suite of practical WWM demonstrations across diverse domains (travel, fiction, encyclopedia, games) on a realistic web stack. 3. Identified key design principles for WWMs, such as separating code-defined rules from model-driven imagination and representing latent state as typed web interfaces.",
      "summary": "This paper proposes Web World Models (WWMs), a framework that combines the reliability of web code for world \"physics\" with the generative power of LLMs for content and narratives. This hybrid approach aims to provide language agents with controllable, logically consistent, yet open-ended persistent environments. The work demonstrates that standard web stacks can serve as a scalable substrate for building such world models.",
      "mindmap": "graph TB\n        A[Web World Models] --> B[”核心问题/Problem: Language agents need persistent worlds; existing solutions are either too rigid (web frameworks) or too uncontrolled (fully generative models).”]\n        A --> C[”主要方法/Method: Hybrid Web World Model (WWM): Web code defines rules & state; LLMs generate context & narratives on top.”]\n        A --> D[”关键结果/Results: Demonstrates scalable, controllable, open-ended environments; proposes design principles for WWMs.”]"
    },
    {
      "title": "PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech",
      "authors": "Deepak Babu Piskala",
      "institution": "Independent Researcher (affiliation inferred from email domain: gmail.com)",
      "link": "https://arxiv.org/pdf/2512.23686",
      "code": "https://github.com/prdeepakbabu/ProfASR-Bench",
      "tags": [
        "speech recognition",
        "context-conditioned ASR",
        "entity-aware evaluation",
        "professional speech"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e17670ba26d26dd9fe7f42150241a5910106d394ee058ad7a75c1fc5815bdcd9_w640_q70.webp",
      "contributions": "1. Introduces ProfASR-Bench, a benchmark for evaluating context-conditioned ASR in high-stakes professional domains (finance, medicine, legal, technology). 2. Identifies and defines the \"context-utilization gap\" (CUG), showing current promptable models underuse textual context for improving recognition. 3. Provides a standardized evaluation framework with a context ladder, entity/slice-aware reporting, and a reproducible testbed for comparing fusion strategies.",
      "summary": "This paper introduces ProfASR-Bench, a benchmark for evaluating Automatic Speech Recognition (ASR) in high-stakes professional settings. It tests models like Whisper and Qwen-Omni with various contextual prompts and finds a \"context-utilization gap,\" where current systems fail to effectively use available side information to improve accuracy, despite being promptable. The benchmark provides tools for entity-aware and slice-wise evaluation to advance context-conditioned ASR.",
      "mindmap": "graph TB\n        A[PROFASR-BENCH: A Benchmark for Context-Conditioned ASR] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有基准低估专业场景挑战 / Existing benchmarks underplay professional challenges]\n        B1 --> B2[密集术语, 正式语体, 关键实体零容忍 / Dense terminology, formal register, zero tolerance for entity errors]\n        C --> C1[构建专业语音评估套件 / Build professional-talk evaluation suite]\n        C1 --> C2[配对自然语言提示与目标话语 / Pair natural-language prompts with target utterances]\n        C2 --> C3[支持实体感知和分片报告 / Support entity-aware and slice-wise reporting]\n        D --> D1[发现上下文利用差距(CUG) / Uncover context-utilization gap (CUG)]\n        D1 --> D2[轻量级上下文提示对WER改善甚微 / Lightweight textual context yields little WER change]\n        D2 --> D3[对抗性提示不会可靠降低性能 / Adversarial prompts do not reliably degrade performance]"
    },
    {
      "title": "Training AI Co-Scientists Using Rubric Rewards",
      "authors": "Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse",
      "institution": "Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge",
      "link": "https://arxiv.org/pdf/2512.23707",
      "code": null,
      "tags": [
        "reinforcement learning",
        "research plan generation",
        "self-grading",
        "rubric rewards"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp",
      "contributions": "1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.",
      "summary": "This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.",
      "mindmap": "graph TB\n        Root[”Training AI Co-Scientists Using Rubric Rewards”] --> Problem[”核心问题/Problem: LMs struggle to generate research plans that follow all constraints.”]\n        Root --> Method[”主要方法/Method: RL with self-grading using automatically extracted rubrics.”]\n        Root --> Results[”关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains.”]"
    },
    {
      "title": "The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu",
      "authors": "Frank Tian-Fang Ye, Xiaozi Gao",
      "institution": "The HKU SPACE Community College, The University of Hong Kong; Education University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.23609",
      "code": null,
      "tags": [
        "sentiment analysis",
        "large language model",
        "moral ethics",
        "content analysis",
        "sentiment classification",
        "Shweder's Big Three"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7156acf600b8fd25e2938afd6f0f65ccd5503ace7d9b3afb68c9bb152d1a0fee_w640_q70.webp",
      "contributions": "1. Applied Shweder's Big Three moral ethics framework (Autonomy, Community, Divinity) to analyze public discourse on marriage in China via social media. 2. Demonstrated the utility of LLM-assisted content analysis for scaling qualitative analysis of large-scale social media data. 3. Revealed platform-specific sentiment patterns and associations between moral framing and sentiment, linking negative marriage attitudes to concerns over personal autonomy and communal obligations.",
      "summary": "This study uses large language models to analyze 219,358 marriage-related posts from Weibo and Xiaohongshu, coding them for sentiment and moral dimensions based on Shweder's Big Three framework. It finds platform differences in sentiment and that posts invoking Autonomy and Community ethics are predominantly negative, while Divinity-framed posts are more neutral or positive. The research demonstrates LLMs' utility for scaling qualitative analysis and provides insights into the moral reasoning behind declining marriage rates in China.",
      "mindmap": "graph TB\n        A[The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[中国婚姻登记数下降<br/>Declining Marriage Registrations in China]\n        B --> B2[公众对婚姻的态度<br/>Public Attitudes Toward Marriage]\n        C --> C1[LLM辅助内容分析<br/>LLM-Assisted Content Analysis]\n        C --> C2[基于Shweder道德三原则编码<br/>Coding with Shweder's Big Three Ethics]\n        C --> C3[分析219,358条社交媒体帖子<br/>Analyzing 219,358 Social Media Posts]\n        D --> D1[平台差异: 微博偏正面, 小红书偏中性<br/>Platform Differences: Weibo Positive, Xiaohongshu Neutral]\n        D --> D2[多数帖子无明确道德框架<br/>Most Posts Lack Explicit Moral Framing]\n        D --> D3[自主性与社群性道德关联负面情绪<br/>Autonomy & Community Ethics Linked to Negative Sentiment]\n        D --> D4[神性道德关联中性/正面情绪<br/>Divinity Ethics Linked to Neutral/Positive Sentiment]"
    },
    {
      "title": "Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks",
      "authors": "Jasmin Saxer, Isabella Maria Aigner, Luise Linzmeier, Andreas Weiler, Kurt Stockinger",
      "institution": "Zurich University of Applied Sciences, University of Zurich",
      "link": "https://arxiv.org/pdf/2512.21345",
      "code": null,
      "tags": [
        "text-to-SQL",
        "unanswerable question detection",
        "few-shot prompting",
        "biomedical databases"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d95c00b7fa86810771a1c8fb0ff6fd8768baaa0419f172cc5c7a3068ac67a64_w640_q70.webp",
      "contributions": "1. Proposed Query Carefully, a pipeline integrating LLM-based SQL generation with explicit detection of unanswerable inputs. 2. Constructed OncoMX-NAQ, a benchmark dataset of 80 no-answer questions for biomedical text-to-SQL. 3. Demonstrated that balanced few-shot prompting with both answerable and unanswerable examples achieves high unanswerable-detection accuracy without degrading performance on answerable queries.",
      "summary": "This paper addresses the risk of text-to-SQL systems generating executable but incorrect SQL for ambiguous or unanswerable queries, especially in biomedical contexts. The authors propose the Query Carefully pipeline, which uses an LLM with schema-aware prompts and few-shot examples to detect and abstain from unanswerable inputs. Their evaluation shows the method achieves high detection accuracy for structurally unanswerable queries, though challenges remain for semantic ambiguities like missing values.",
      "mindmap": "graph TB\n        Root(”Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks”) --> Problem\n        Root --> Method\n        Root --> Results\n        Problem(”核心问题/Problem”) --> P1(”Text-to-SQL对不可回答查询生成可执行SQL/Text-to-SQL generates executable SQL for unanswerable queries”)\n        P1 --> P2(”生物医学领域风险高/High risk in biomedical contexts”)\n        Method(”主要方法/Method”) --> M1(”Query Carefully 管道/Query Carefully pipeline”)\n        M1 --> M2(”LLM (llama3.3:70b) + 模式感知提示 + 少样本/LLM (llama3.3:70b) + schema-aware prompts + few-shot”)\n        M2 --> M3(”包含可回答与不可回答示例/Includes answerable and unanswerable examples”)\n        Results(”关键结果/Results”) --> R1(”构建OncoMX-NAQ基准/Built OncoMX-NAQ benchmark”)\n        R1 --> R2(”不可回答检测准确率0.8/Unanswerable-detection accuracy 0.8”)\n        R2 --> R3(”结构性问题检测好，语义模糊挑战大/Good for structural, challenging for semantic ambiguity”)"
    },
    {
      "title": "Teaching People LLM's Errors and Getting it Right",
      "authors": "Nathan Stringham, Fateme Hashemi Chaleshtori, Xinyuan Yan, Zhichao Xu, Bei Wang, Ana Marasović",
      "institution": "University of Utah",
      "link": "https://arxiv.org/pdf/2512.21422",
      "code": null,
      "tags": [
        "human-ai interaction",
        "overreliance",
        "failure patterns",
        "mental models",
        "user study",
        "meta-labels"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83a262b8daf44fdf951904b9202074fd9db4ef9e9666cd5769ec1d8514053804_w640_q70.webp",
      "contributions": "1. Empirically demonstrated that failure patterns for LLMs do exist by identifying sizable, error-prone meta-label groups in datasets, countering the hypothesis that their absence caused prior teaching failures. 2. Evaluated automated methods for discovering these failure patterns (prompting and embedding-based) and found mixed results, identifying a key bottleneck in the teaching pipeline. 3. Proposed and validated a new metric for teaching effectiveness—assessing a user's ability to anticipate LLM errors using taught patterns—which showed a positive effect, unlike traditional human-AI team accuracy.",
      "summary": "This paper investigates why prior attempts to teach users about LLM failure patterns to reduce overreliance have failed. It finds that failure patterns do exist, but automated methods to discover them are unreliable, and proposes a new user-centric evaluation metric that shows teaching can be effective. The conclusion is that teaching failure patterns is viable but requires better failure-discovery methods and appropriate metrics.",
      "mindmap": "graph TB\n        A[Teaching People LLM’s Errors and Getting it Right] --> B[核心问题/Problem: Users overrely on LLMs due to inaccurate mental models]\n        A --> C[主要方法/Method: Analyze failure pattern existence, test discovery methods, propose new evaluation metric]\n        A --> D[关键结果/Results: Patterns exist, discovery methods are mixed, new metric shows teaching is effective]"
    },
    {
      "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models",
      "authors": "Geoffroy Morlat, Marceau Nahon, Augustin Chartouny, Raja Chatila, Ismael T. Freire, Mehdi Khamassi",
      "institution": "Institute of Intelligent Systems and Robotics, Sorbonne University",
      "link": "https://arxiv.org/pdf/2512.21439",
      "code": null,
      "tags": [
        "computational ethics",
        "moral context",
        "probabilistic clustering",
        "LLM semantics",
        "interpretable prediction",
        "human judgment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25f4abc9f666c2d29dadd77869bddf3f159d0bbc8839c7c0f65bbdb4c29ad40c_w640_q70.webp",
      "contributions": "1. An empirically grounded dataset of 300 moral scenarios with human ternary judgments. 2. A reproducible pipeline (COMETH) combining human judgments, probabilistic context learning, and LLM-based semantic abstraction. 3. An interpretable, context-sensitive moral prediction model that outperforms end-to-end LLM prompting.",
      "summary": "The paper addresses the problem that moral judgments depend heavily on context. It proposes the COMETH framework, which uses probabilistic clustering on human judgment data and LLM-based semantic abstraction to learn and explain action-specific moral contexts. The main conclusion is that COMETH significantly outperforms direct LLM prompting in aligning with human majority judgments while providing interpretable predictions.",
      "mindmap": "graph TB\n        A[COMETH: Learning Interpretable Moral Contexts] --> B[核心问题/Problem: Moral judgments are context-dependent]\n        A --> C[主要方法/Method: Probabilistic clustering + LLM semantics + Human judgments]\n        A --> D[关键结果/Results: Doubles alignment with human judgments vs. LLM prompting]"
    },
    {
      "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri",
      "authors": "Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura",
      "institution": "CyberAgent, Nara Institute of Science and Technology, Institute of Science Tokyo",
      "link": "https://arxiv.org/pdf/2512.21494",
      "code": null,
      "tags": [
        "humor understanding",
        "Oogiri",
        "benchmark",
        "linguistic analysis",
        "incongruity resolution",
        "insight-augmented prompting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/41486d2e77493633c6cf66d7f5134ccf646d1df0d17e6d258bc98cc3132ef02b_w640_q70.webp",
      "contributions": "1. Introduces Oogiri-Master, a benchmark for rigorous evaluation of humor understanding in LLMs, and Oogiri-Corpus, a dataset with ~100 diverse responses per prompt and independent human ratings to reduce bias. 2. Conducts quantitative analysis of linguistic factors (e.g., text length, ambiguity, incongruity resolution) to derive objective metrics for predicting human funniness judgments. 3. Benchmarks LLMs and human baselines, showing state-of-the-art models approach human performance and that insight-augmented prompting improves model humor understanding.",
      "summary": "This paper addresses the challenge of evaluating humor understanding in LLMs by introducing the Oogiri-Master benchmark and Oogiri-Corpus dataset, which enable rigorous analysis of funniness through diverse responses and independent human ratings. It quantitatively analyzes linguistic factors to derive objective metrics and benchmarks LLMs, demonstrating that advanced models approach human-level performance and benefit from insight-augmented prompting. The work provides a principled basis for advancing humor understanding in AI.",
      "mindmap": "graph TB\n        A[Oogiri-Master: Benchmarking Humor Understanding via Oogiri] --> B[核心问题/Problem: What makes Oogiri responses funny to humans?]\n        A --> C[主要方法/Method: Introduce Oogiri-Master benchmark and Oogiri-Corpus dataset with diverse responses and independent ratings]\n        A --> D[关键结果/Results: LLMs approach human performance; insight-augmented prompting improves results]"
    },
    {
      "title": "MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding",
      "authors": "Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson",
      "institution": "Dartmouth College",
      "link": "https://arxiv.org/pdf/2512.21506",
      "code": null,
      "tags": [
        "multi-modal training",
        "wearable sensing",
        "actigraphy encoder",
        "projection module",
        "frozen LLM",
        "behavioral summarization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp",
      "contributions": "1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.",
      "summary": "The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.",
      "mindmap": "graph TB\n        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]\n        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]\n        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]"
    },
    {
      "title": "Perplexity-Aware Data Scaling Law: Perplexity Landscapes Predict Performance for Continual Pre-training",
      "authors": "Lei Liu, Hao Zhu, Yue Shen, Zhixuan Chu, Jian Wang, Jinjie Gu, Kui Ren",
      "institution": "Ant Group, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.21515",
      "code": null,
      "tags": [
        "llm training",
        "continual pre-training",
        "scaling laws",
        "perplexity",
        "data selection",
        "knowledge gap"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d01b1cad6e908309c7e813cb1d98f2c41345aa1e4d78cbdaf163996c5d111b4_w640_q70.webp",
      "contributions": "1. Proposes a novel perplexity-aware data scaling law that predicts model test loss from the perplexity landscape of domain data, moving beyond dataset size. 2. Introduces the concept of \"perplexity landscapes\" to quantify the informational value and knowledge gap of candidate training samples. 3. Enables adaptive selection of high-utility data subsets for Continual Pre-training, improving efficiency and performance by prioritizing informative content and reducing redundancy.",
      "summary": "This paper addresses the inefficiency of scaling data for Continual Pre-training (CPT) of LLMs, where simply adding more data yields diminishing returns. The authors propose a new scaling law that uses the model's perplexity on domain data as a proxy for the knowledge gap, allowing for the predictive selection of optimal training subsets. Experiments show this method consistently identifies high-utility data, leading to superior performance on domain-specific benchmarks.",
      "mindmap": "graph TB\n        A[Perplexity-Aware Data Scaling Law<br>困惑度感知数据缩放定律] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[CPT中单纯增加数据收益递减<br>Diminishing returns from scaling data in CPT]\n        C --> C1[提出基于困惑度景观的缩放定律<br>Propose perplexity-landscape-based scaling law]\n        C1 --> C2[利用困惑度量化知识差距<br>Use perplexity to quantify knowledge gap]\n        C2 --> C3[自适应选择高价值数据子集<br>Adaptively select high-utility data subsets]\n        D --> D1[识别接近最优的训练子集<br>Identifies near-optimal training subsets]\n        D1 --> D2[在领域基准上取得优越性能<br>Achieves superior performance on domain benchmarks]"
    },
    {
      "title": "Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures",
      "authors": "Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li",
      "institution": "NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.21551",
      "code": null,
      "tags": [
        "human-ai interaction",
        "bidirectional alignment",
        "value-centered design",
        "interactive alignment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp",
      "contributions": "1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.",
      "summary": "This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.",
      "mindmap": "graph TB\n        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]\n        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]\n        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]"
    },
    {
      "title": "Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management",
      "authors": "Changzhi Sun, Xiangyu Chen, Jixiang Luo, Dell Zhang, Xuelong Li",
      "institution": "Institute of Artificial Intelligence (TeleAI), China Telecom",
      "link": "https://arxiv.org/pdf/2512.21567",
      "code": "https://github.com/TeleAI-UAGI/telemem",
      "tags": [
        "agent system",
        "external memory",
        "sequential decision-making",
        "value functions",
        "uncertainty estimators",
        "hierarchical storage"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d30748df565a671b29899dffbfb153dca58fed0398e13cc6871dfe6f450f11a1_w640_q70.webp",
      "contributions": "1. Proposes a decision-theoretic reframing of agent memory management as a sequential decision-making problem under uncertainty, 2. Introduces the DAM framework that decomposes memory operations into immediate access and hierarchical maintenance, 3. Provides a foundation for future research by evaluating operations via value functions and uncertainty estimators for long-term utility and risk",
      "summary": "This paper argues that current heuristic-based memory management for LLM agents is inadequate due to delayed and uncertain utility. It proposes DAM, a decision-theoretic framework that uses value functions and uncertainty estimators to make memory decisions based on long-term consequences. The main contribution is a principled reframing of the problem to guide future research on uncertainty-aware memory systems.",
      "mindmap": "graph TB\n        A[Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[启发式内存管理缺乏对长期和不确定后果的洞察/Heuristic memory management lacks insight into long-term & uncertain consequences]\n        C --> C1[提出DAM框架，将内存管理视为序列决策问题/Propose DAM framework, viewing memory as a sequential decision problem]\n        C --> C2[使用价值函数和不确定性估计器评估操作/Evaluate operations via value functions & uncertainty estimators]\n        D --> D1[原则性重构，为不确定性感知内存系统奠定基础/Principled reframing, provides foundation for uncertainty-aware memory systems]"
    },
    {
      "title": "A Unified Definition of Hallucination, Or: It's the World Model, Stupid",
      "authors": "Emmy Liu, Varun Gangal, Chelsea Zou, Xiaoqi Huang, Michael Yu, Alex Chang, Zhuofu Tao, Sachin Kumar, Steven Y. Feng",
      "institution": "Carnegie Mellon University, Stanford University, The Ohio State University, Patronus AI, DegenAI Labs, Independent Researchers",
      "link": "https://arxiv.org/pdf/2512.21577",
      "code": null,
      "tags": [
        "hallucination detection & evaluation",
        "hallucination",
        "world modeling",
        "knowledge conflict",
        "benchmark",
        "language model evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e2cc31121f769cca7464239d4aa27b26c8c4bc903970a4833fbebac56dc9b85_w640_q70.webp",
      "contributions": "1. Proposes a unified definition of hallucination as inaccurate internal world modeling that is observable to the user, synthesizing prior definitions. 2. Provides a framework for analyzing hallucinations by varying the reference world model and knowledge conflict policy, clarifying what constitutes a hallucination versus other error types. 3. Outlines plans for a family of benchmarks based on synthetic, fully-specified world models to stress-test and improve the world modeling components of language models.",
      "summary": "This paper argues that the persistent problem of hallucination in language models stems from inaccurate internal world modeling. It unifies various historical definitions under this core concept and proposes a framework for clearer evaluation. The authors conclude by sketching plans for new benchmarks to rigorously test and improve language models' world modeling capabilities.",
      "mindmap": "graph TB\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Problem[”核心问题/Problem”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Method[”主要方法/Method”]\n        Root[”A Unified Definition of Hallucination / 幻觉的统一定义”] --> Results[”关键结果/Results”]\n        Problem --> P1[”Hallucination persists in LLMs / 幻觉在LLM中持续存在”]\n        Method --> M1[”Unified definition: inaccurate world modeling / 统一定义：不准确的世界建模”]\n        Method --> M2[”Framework: reference world & conflict policy / 框架：参考世界与冲突策略”]\n        Results --> R1[”Clarifies evaluation & terminology / 澄清评估与术语”]\n        Results --> R2[”Proposes new benchmark plans / 提出新基准计划”]"
    },
    {
      "title": "Gamayun's Path to Multilingual Mastery: Cost-Efficient Training of a 1.5B-Parameter LLM",
      "authors": "Alexander Podolskiy, Semen Molokov, Timofey Gerasin, Maksim Titov, Alexey Rukhovich, Artem Khrapov, Kirill Morozov, Evgeny Tetin, Constantine Korikov, Pavel Efimov, Polina Lazukova, Yuliya Skripkar, Nikita Okhotnikov, Irina Piontkovskaya, Meng Xiaojun, Zou Xueyi, Zhang Zhenhe",
      "institution": "Gamayun Team",
      "link": "https://arxiv.org/pdf/2512.21580",
      "code": null,
      "tags": [
        "multilingual language modeling",
        "two-stage pre-training",
        "cross-lingual alignment",
        "English enrichment",
        "cost-efficient training",
        "Russian LLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b7ebd17e8a0b7536938c0d12aa8812a6376542abde4f40239a4622472c17ea0_w640_q70.webp",
      "contributions": "1. Introduces a novel two-stage pre-training strategy (balanced multilingual training followed by high-quality English enrichment) for efficient cross-lingual knowledge transfer. 2. Presents Gamayun, a 1.5B-parameter multilingual LLM trained from scratch on 2.5T tokens, designed for resource-constrained environments. 3. Demonstrates state-of-the-art performance for its size (1-2B parameters) on Russian benchmarks and competitive results on English and multilingual tasks, despite a significantly smaller training budget than comparable models.",
      "summary": "This paper presents Gamayun, a cost-efficient 1.5B-parameter multilingual language model. It addresses the lack of small non-English-centric LLMs through a novel two-stage pre-training strategy for cross-lingual alignment. The model achieves state-of-the-art results in Russian and outperforms larger models on many tasks, despite being trained on far fewer tokens.",
      "mindmap": "graph TB\n        A[Gamayun's Path to Multilingual Mastery<br/>Gamayun的多语言精通之路] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>Lack of small, efficient, non-English-centric LLMs<br/>缺乏小型、高效、非英语中心的LLM]\n        C[主要方法/Method<br/>Two-stage pre-training<br/>两阶段预训练<br/>1. Balanced multilingual training<br/>平衡多语言训练<br/>2. High-quality English enrichment<br/>高质量英语增强]\n        D[关键结果/Results<br/>Outperforms LLaMA3.2-1B & Qwen2.5-1.5B<br/>超越LLaMA3.2-1B和Qwen2.5-1.5B<br/>SOTA in Russian (MERA)<br/>俄语任务达到SOTA]"
    },
    {
      "title": "Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards",
      "authors": "Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou",
      "institution": "Renmin University of China, The Chinese University of Hong Kong, Ant Group",
      "link": "https://arxiv.org/pdf/2512.21625",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "sample polarity",
        "advantage shaping",
        "policy optimization",
        "reasoning models"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp",
      "contributions": "1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.",
      "summary": "This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.",
      "mindmap": "graph TB\n        Root[Rethinking Sample Polarity in RLVR] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[RLVR中正负样本的角色?/Roles of +/- samples in RLVR?]\n        Method[主要方法/Method] --> M1[分析样本极性/Analyze Sample Polarity]\n        Method --> M2[提出A3PO方法/Propose A3PO Method]\n        Results[关键结果/Results] --> R1[正样本锐化模式/Positive samples sharpen patterns]\n        Results --> R2[负样本鼓励探索/Negative samples encourage exploration]\n        Results --> R3[A3PO有效/A3PO is effective]"
    },
    {
      "title": "Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations",
      "authors": "Chengxu Yang, Jingling Yuan, Siqi Cai, Jiawei Jiang, Chuang Hu",
      "institution": "Wuhan University of Technology, Wuhan University",
      "link": "https://arxiv.org/pdf/2512.21635",
      "code": "https://github.com/chujiguangniao/HIC-bench",
      "tags": [
        "hallucination evaluation",
        "HIC-Bench",
        "Intelligent Hallucinations",
        "Defective Hallucinations",
        "Torrance Tests of Creative Thinking",
        "Dynamic Hallucination Prompt"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/beb581f42c65746c28519ac82f0996a0d7ab8f6413a85636583ec1e0abecba3c_w640_q70.webp",
      "contributions": "1. Proposes HIC-Bench, a novel evaluation framework that categorizes LLM hallucinations into Intelligent Hallucinations (IH) and Defective Hallucinations (DH) for systematic study. 2. Introduces a structured multi-dimensional assessment matrix combining TTCT creativity metrics (Originality, Feasibility, Value) with hallucination-specific dimensions (scientific plausibility, factual deviation). 3. Features cross-domain applicability across ten scientific domains and a Dynamic Prompt Optimization technique (DHP) to guide model outputs.",
      "summary": "This paper addresses the challenge of evaluating LLM hallucinations beyond factual errors by proposing HIC-Bench, a framework that distinguishes between creative (Intelligent) and erroneous (Defective) hallucinations using a multi-metric assessment. It demonstrates that creativity and correctness can be jointly optimized, revealing a nonlinear relationship between the two types of hallucinations and positioning intelligent hallucinations as a catalyst for scientific innovation.",
      "mindmap": "graph TB\n        A[Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有方法难以平衡LLM幻觉的创造性与准确性/Existing methods struggle to balance creativity and accuracy in LLM hallucinations]\n        C --> C1[提出HIC-Bench评估框架/Propose HIC-Bench evaluation framework]\n        C1 --> C2[分类智能与缺陷幻觉/Categorize IH and DH]\n        C1 --> C3[多维度评估矩阵/Multi-dimensional metric matrix]\n        C1 --> C4[动态提示优化/Dynamic Prompt Optimization]\n        D --> D1[创造力与正确性可共同优化/Creativity and correctness can be jointly optimized]\n        D --> D2[智能幻觉是创造力的催化剂/IH is a catalyst for creativity]"
    },
    {
      "title": "Semantic Codebooks as Effective Priors for Neural Speech Compression",
      "authors": "Liuyang Bai, Weiyi Lu, Li Guo",
      "institution": "NYU Shanghai",
      "link": "https://arxiv.org/pdf/2512.21653",
      "code": null,
      "tags": [
        "speech compression",
        "semantic codebooks",
        "residual vector quantization (RVQ)",
        "HuBERT",
        "FiLM-conditioned decoder",
        "neural audio codec"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a14c953c6c23139c4473b8d6e59b36c7615f79f4316119e168deb19de30eced_w640_q70.webp",
      "contributions": "1. Proposes SemDAC, a semantic-aware neural audio codec that uses semantic codebooks as priors for compression., 2. Introduces a design where the first RVQ quantizer is distilled from HuBERT to capture phonetic content, and a FiLM-conditioned decoder uses these semantic tokens., 3. Demonstrates superior performance over baseline DAC in perceptual metrics and ASR (Whisper) WER at significantly lower bitrates.",
      "summary": "The paper proposes SemDAC, a neural speech codec that uses semantic codebooks distilled from HuBERT as priors within an RVQ framework to separate phonetic from acoustic information. This method achieves better perceptual quality and lower word error rates for speech recognition at much lower bitrates compared to traditional neural codecs. The results show that semantic priors provide an effective inductive bias for efficient, recognition-friendly speech compression.",
      "mindmap": "graph TB\n        Root[”Semantic Codebooks as Effective Priors for Neural Speech Compression”] --> Problem[”核心问题/Problem: Traditional codecs inefficiently allocate bits for acoustic detail, neglecting linguistic structure.”]\n        Root --> Method[”主要方法/Method: Propose SemDAC, using HuBERT-distilled semantic codebooks in RVQ and a FiLM-conditioned decoder.”]\n        Root --> Results[”关键结果/Results: Outperforms DAC in perceptual metrics & ASR WER at lower bitrates (e.g., 0.95 vs 2.5 kbps).”]"
    },
    {
      "title": "Enabling Conversational Behavior Reasoning Capabilities in Full-Duplex Speech",
      "authors": "Shuchang Pan, Siddharth Banerjee, Dhruv Hebbar, Siddhant Patel, Akshaj Gupta, Kan Jen Cheng, Hanjo Kim, Zeyi Austin Li, Martin Q. Ma, Tingle Li, Gopala Anumanchipalli, Jiachen Lian",
      "institution": "Zhejiang University, University of California, Berkeley, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.21706",
      "code": "https://got-duplex.github.io/",
      "tags": [
        "spoken dialogue systems",
        "Graph-of-Thoughts",
        "full-duplex",
        "speech acts",
        "causal inference",
        "multimodal transformer"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eaad0398d39f15391b728b9e3c53af71ff071dcfd269c61b0a277091d58ee7f3_w640_q70.webp",
      "contributions": "1. A framework that models conversational behavior reasoning as causal inference within a Graph-of-Thoughts (GoT) to enable interpretable decision-making in full-duplex dialogue. 2. A hierarchical labeling scheme and hybrid training corpus combining simulated dialogues with human rationales and real speech to learn causal and temporal dependencies between intents and speech acts. 3. A system that structures streaming predictions as an evolving graph, allowing a multimodal transformer to forecast the next speech act, generate justifications, and dynamically refine its reasoning.",
      "summary": "This paper addresses the lack of explicit reasoning in full-duplex spoken dialogue systems by proposing a framework that models the perception-reasoning-generation loop as causal inference within a Graph-of-Thoughts (GoT). The method uses a hierarchical behavior detection model and a hybrid corpus to learn dependencies, enabling an agent to predict the next speech act and generate interpretable justifications. Experiments show the framework provides robust behavior detection and interpretable reasoning, establishing a foundation for benchmarking conversational reasoning.",
      "mindmap": "graph TB\n        Root[”Enabling Conversational Behavior Reasoning in Full-Duplex Speech<br/>实现全双工语音对话行为推理”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br/>Current systems lack explicit reasoning for conversational behaviors.”]\n        Method[”主要方法/Method<br/>Model reasoning as causal inference in a Graph-of-Thoughts (GoT).”]\n        Results[”关键结果/Results<br/>Robust behavior detection and interpretable reasoning chains.”]"
    },
    {
      "title": "Detecting AI-Generated Paraphrases in Bengali: A Comparative Study of Zero-Shot and Fine-Tuned Transformers",
      "authors": "Md. Rakibul Islam, Most. Sharmin Sultana Samu, Md. Zahid Hossain, Farhad Uz Zaman, Md. Kamrozzaman Bhuiyan",
      "institution": "Not specified in provided content.",
      "link": "https://arxiv.org/pdf/2512.21709",
      "code": null,
      "tags": [
        "ai-generated text detection",
        "transformer",
        "fine-tuning",
        "zero-shot",
        "Bengali",
        "paraphrase detection"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6b32597f75301412c6dbf1765506d21eb52c7e7727c1e3eefdfaa406f8c4ae44_w640_q70.webp",
      "contributions": "1. Conducts the first comparative study of transformer models for detecting AI-generated paraphrases specifically in the Bengali language. 2. Demonstrates that zero-shot evaluation of pre-trained models yields near-chance performance, highlighting the necessity of task-specific fine-tuning for this problem. 3. Shows that fine-tuning significantly boosts performance, with XLM-RoBERTa, mDeBERTa, and MultilingualBERT achieving high accuracy (~91%), establishing a strong baseline for future research.",
      "summary": "This paper addresses the challenge of detecting AI-generated paraphrased text in Bengali, a low-resource language. It evaluates five transformer models in zero-shot and fine-tuned settings, finding that fine-tuning is essential and leads to high detection accuracy (~91%) for several models. The work establishes a foundation for robust AI-generated content detection systems in Bengali.",
      "mindmap": "graph TB\n        A[Detecting AI-Generated Paraphrases in Bengali] --> B[核心问题/Problem: LLM misuse & lack of Bengali detection research]\n        A --> C[主要方法/Method: Compare 5 transformers (Zero-Shot vs. Fine-Tuned)]\n        A --> D[关键结果/Results: Fine-tuning needed; XLM-R, mDeBERTa, mBERT achieve ~91% accuracy]"
    },
    {
      "title": "MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles",
      "authors": "Jing Han, Binwei Yan, Tianyu Guo, Zheyuan Bai, Mengyu Zheng, Hanting Chen, Ying Nie",
      "institution": "Beijing University of Posts and Telecommunications, Huawei Noah's Ark Lab",
      "link": "https://arxiv.org/pdf/2512.21708",
      "code": "https://mor-agent.github.io/",
      "tags": [
        "agent system",
        "Parameter-Efficient Fine-Tuning (PEFT)",
        "Low-Rank Adaptation (LoRA)",
        "Mixture-of-Roles (MoR)",
        "Agent Tuning",
        "Data Generation Pipeline"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c303f17ce31b4315bdd80c394b9ba486dc14690a542d268175927115df139559_w640_q70.webp",
      "contributions": "1. Decomposes agent capabilities into three distinct roles (reasoner, executor, summarizer) based on the Reason+Action paradigm. 2. Proposes the Mixture-of-Roles (MoR) framework, which uses three specialized LoRA groups, each dedicated to a specific role, to collaboratively accomplish agent tasks. 3. Develops a multi-role data generation pipeline for effective fine-tuning, incorporating role-specific content completion and reliability verification.",
      "summary": "This paper addresses the underexplored area of parameter-efficient fine-tuning (PEFT) for AI agents. It proposes MoRAgent, a framework that decomposes agent tasks into three roles (reasoner, executor, summarizer) and assigns a specialized LoRA module to each, enabling efficient and collaborative task completion. Extensive experiments demonstrate the method's effectiveness in tuning LLMs for agent tasks while maintaining parameter efficiency.",
      "mindmap": "graph TB\n        Root[MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: PEFT for agent tasks is largely unexplored] --> P1[挑战/Challenges: Full fine-tuning is resource-heavy and harms general capabilities]\n        Method[主要方法/Method: Mixture-of-Roles (MoR) Framework] --> M1[策略1/Strategy 1: Decompose agent into three roles]\n        M1 --> M1_1[角色/Roles: Reasoner, Executor, Summarizer]\n        Method --> M2[策略2/Strategy 2: Three specialized LoRA groups for the three roles]\n        Method --> M3[策略3/Strategy 3: Multi-role data generation pipeline]\n        Results[关键结果/Results: Effectiveness demonstrated] --> R1[实验/Experiments: Extensive tests on various LLMs & benchmarks]"
    },
    {
      "title": "Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought",
      "authors": "Yuyi Zhang, Boyu Tang, Tianjie Ju, Sufeng Duan, Gongshen Liu",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21711",
      "code": null,
      "tags": [
        "interpretability & analysis",
        "latent tokens",
        "chain-of-thought",
        "model reliability",
        "causal analysis",
        "shortcut learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99abfa3b8406909febaa5ee077a1feab3c1d8b8cda1eebe350774e19cb82eb77_w640_q70.webp",
      "contributions": "1. Introduces \"Steering Experiments\" to causally test the impact of perturbing latent reasoning tokens, revealing COCONUT tokens are insensitive to perturbation unlike explicit CoT tokens. 2. Conducts \"Shortcut Experiments\" to evaluate models under biased and out-of-distribution settings, demonstrating COCONUT exploits dataset artifacts rather than performing genuine reasoning. 3. Repositions COCONUT as a \"pseudo-reasoning\" mechanism that generates plausible traces to conceal shortcut dependence, challenging its claimed reasoning capabilities.",
      "summary": "This paper investigates the reliability of latent reasoning tokens in LLMs, specifically Chain-of-Continuous-Thought (COCONUT). Through causal steering and adversarial shortcut experiments, it finds that COCONUT tokens are uninterpretable placeholders insensitive to perturbation and that the method relies on dataset shortcuts. The main conclusion is that COCONUT is a pseudo-reasoning mechanism that inflates benchmark performance without faithful reasoning.",
      "mindmap": "graph TB\n        A[Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Latent token mechanisms unclear, reliability concerns] --> B1[潜在令牌机制不明确/Unclear latent token mechanisms]\n        B --> B2[可靠性问题/Reliability concerns]\n        C[主要方法/Method: Causal & adversarial analysis] --> C1[引导实验/Steering experiments]\n        C --> C2[捷径实验/Shortcut experiments]\n        D[关键结果/Results: COCONUT is pseudo-reasoning] --> D1[令牌对扰动不敏感/Tokens insensitive to perturbation]\n        D --> D2[利用数据集捷径/Exploits dataset shortcuts]\n        D --> D3[性能提升不基于真实推理/Performance gains not from true reasoning]"
    },
    {
      "title": "CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation",
      "authors": "Rui Ke, Jiahui Xu, Shenghao Yang, Kuang Wang, Feng Jiang, Haizhou Li",
      "institution": "The Chinese University of Hong Kong, Shenzhen; Shenzhen University of Advanced Technology; National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21715",
      "code": null,
      "tags": [
        "dialogue systems",
        "theme detection",
        "topic clustering",
        "hierarchical generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da012bcf7b19d126b0f1a64e4fc67ee4a82a999c3d110d6b449ab0c750d9458e_w640_q70.webp",
      "contributions": "1. A context-aware topic representation method that enriches utterance semantics using surrounding topic segments. 2. A preference-guided topic clustering mechanism that jointly models semantic proximity and personalized feedback for cross-dialogue theme alignment. 3. A hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels.",
      "summary": "The paper proposes CATCH, a framework for controllable theme detection in dialogues, which integrates contextualized clustering and hierarchical generation to address sparse utterances and user preference alignment. It demonstrates effectiveness on the DSTC-12 benchmark using an 8B LLM for both clustering and label generation quality.",
      "mindmap": "graph TB\n        Root[CATCH: 可控主题检测框架 / Controllable Theme Detection Framework] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题 / Problem] --> P1[短话语稀疏语义 / Sparse, short utterances]\n        Problem --> P2[跨对话主题对齐 / Cross-dialogue theme alignment]\n        Problem --> P3[用户偏好整合 / Personalized user preferences]\n        Method[主要方法 / Method] --> M1[上下文感知主题表示 / Context-aware topic representation]\n        Method --> M2[偏好引导主题聚类 / Preference-guided topic clustering]\n        Method --> M3[分层主题生成 / Hierarchical theme generation]\n        Results[关键结果 / Results] --> R1[在DSTC-12基准测试有效 / Effective on DSTC-12 benchmark]\n        Results --> R2[提升聚类与生成质量 / Improved clustering & generation quality with 8B LLM]"
    },
    {
      "title": "An Information Theoretic Perspective on Agentic System Design",
      "authors": "Shizhe He, Avanika Narayan, Ishan S. Khare, Scott W. Linderman, Christopher Ré, Dan Biderman",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.21720",
      "code": null,
      "tags": [
        "agent system",
        "mutual information",
        "noisy channel",
        "compressor-predictor",
        "on-device AI",
        "information-theoretic"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124535642e159e8f7a123525ffbf3cb5f163a7ae4a7876a4d1e71e7e6c885ace_w640_q70.webp",
      "contributions": "1. Proposes an information-theoretic framework for analyzing agentic LM systems, viewing the compressor as a noisy channel. 2. Introduces a task-independent estimator of mutual information between context and compression to quantify compression quality. 3. Empirically demonstrates that scaling compressor models is more effective than scaling predictors for performance and cost, enabling efficient on-device compression.",
      "summary": "The paper addresses the ad-hoc design of agentic LM systems that use a compressor LM to summarize context for a predictor LM. It proposes an information-theoretic framework using mutual information to evaluate compressors, finding that larger compressors are more accurate, concise, and information-dense, making scaling compressors more effective than scaling predictors for cost-efficient performance.",
      "mindmap": "graph TB\n        A[An Information Theoretic Perspective on Agentic System Design] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1(”Agentic系统设计缺乏理论指导<br/>Agentic system design lacks theoretical guidance”)\n        C --> C1(”提出信息论框架与互信息估计器<br/>Propose information-theoretic framework & mutual information estimator”)\n        D --> D1(”更大压缩器更高效、更准确<br/>Larger compressors are more efficient and accurate”)\n        D --> D2(”扩展压缩器优于扩展预测器<br/>Scaling compressors outperforms scaling predictors”)"
    },
    {
      "title": "Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation",
      "authors": "Abdullah Alabdullah, Lifeng Han, Chenghua Lin",
      "institution": "University of Edinburgh, University of Manchester, Leiden University Medical Center (LUMC) / Leiden University",
      "link": "https://arxiv.org/pdf/2512.21787",
      "code": null,
      "tags": [
        "machine translation",
        "dialectal arabic",
        "modern standard arabic",
        "post-editing evaluation",
        "error taxonomy",
        "human evaluation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81517a8ae79cb17e9997772074cacae30aa2d04d3b344341b5fa0c68a1bc551b_w640_q70.webp",
      "contributions": "1. Introduces Ara-HOPE, a human-centric post-editing evaluation framework specifically designed for Dialectal Arabic to Modern Standard Arabic (DA-MSA) translation. 2. Proposes a five-category error taxonomy and a decision-tree annotation protocol to systematically identify dialect-specific translation errors. 3. Provides a comparative evaluation of three MT systems (Jais, GPT-3.5, NLLB-200), highlighting persistent challenges like dialect-specific terminology and semantic preservation.",
      "summary": "This paper addresses the challenge of evaluating machine translation from Dialectal Arabic (DA) to Modern Standard Arabic (MSA), where existing metrics fail to capture dialect-specific errors. It proposes Ara-HOPE, a human-centric post-editing evaluation framework with a specialized error taxonomy and annotation protocol. The framework's application reveals that dialect-specific terminology and semantic preservation are the most persistent challenges for current MT systems.",
      "mindmap": "graph TB\n        Root[Ara-HOPE: Human-Centric Post-Editing Evaluation for Dialectal Arabic to Modern Standard Arabic Translation] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: DA-MSA翻译评估困难 / DA-MSA Translation Evaluation is Difficult]\n        Method[主要方法/Method: 提出Ara-HOPE框架 / Proposes Ara-HOPE Framework]\n        Results[关键结果/Results: 方言术语和语义保留是主要挑战 / Dialect Terminology & Semantic Preservation are Key Challenges]"
    },
    {
      "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
      "authors": "Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles",
      "institution": "The Pennsylvania State University, Adobe Research",
      "link": "https://arxiv.org/pdf/2512.21789",
      "code": null,
      "tags": [
        "image captioning",
        "scientific figure captioning",
        "large-scale dataset",
        "domain-specific training",
        "human evaluation",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp",
      "contributions": "1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.",
      "summary": "This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.",
      "mindmap": "graph TB\n        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]\n        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]\n        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]\n        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]\n        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]\n        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]\n        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]"
    },
    {
      "title": "On The Conceptualization and Societal Impact of Cross-Cultural Bias",
      "authors": "Vitthal Bhandari",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.21809",
      "code": null,
      "tags": [
        "bias and fairness",
        "cultural bias",
        "literature survey",
        "societal impact",
        "harm evaluation",
        "bias mitigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2702d319a8125ee471012d7f7a71a4d4530da34216397d1647aba76a8e4a3842_w640_q70.webp",
      "contributions": "1. Conducts a focused survey of 20 recent (2025) papers on cultural bias in NLP, identifying gaps in current research practices. 2. Critiques the literature for lacking concrete definitions of bias, failing to identify affected stakeholders, and inadequately evaluating the harms of biased systems. 3. Advocates for a future research agenda that emphasizes robust societal impact assessment, concrete bias conceptualization, and engagement with real-world stakeholders.",
      "summary": "This paper surveys recent literature on cultural bias in NLP, finding that current research often fails to concretely define bias, engage with affected stakeholders, or thoroughly evaluate societal harms. The author proposes a set of observations to guide future work towards more robust and impactful assessments of cross-cultural bias in language technologies.",
      "mindmap": "graph TB\n    Root(”On The Conceptualization and Societal Impact of Cross-Cultural Bias”) --> Problem(”核心问题/Problem: LLMs exhibit cross-cultural bias; research often avoids real-world stakeholder engagement.”)\n    Root --> Method(”主要方法/Method: Survey and analyze 20 recent (2025) papers on cultural bias in NLP.”)\n    Root --> Results(”关键结果/Results: Identifies gaps in bias definition, harm evaluation; advocates for robust societal impact assessment.”)"
    },
    {
      "title": "Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments",
      "authors": "Hong Su",
      "institution": "Chengdu University of Information Technology",
      "link": "https://arxiv.org/pdf/2512.21817",
      "code": null,
      "tags": [
        "agent system",
        "method decoration",
        "large language models",
        "adaptive method generation",
        "IoT intelligence",
        "on-device reasoning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5c4e12db053492542eb54d5fe131cf8b2ac404f1af94254b9d2abeed75d055a7_w640_q70.webp",
      "contributions": "1. Proposes the Method Decoration (DeMe) framework, a novel approach that modifies an LLM's method-generation path using explicit, non-hardcoded decorations derived from hidden goals, learned methods, and environmental feedback. 2. Formalizes two major categories of decorations (whole-process and step-level) and mechanisms (pre-decoration, post-decoration, etc.) to enable context-aware and adaptive method reshaping. 3. Demonstrates experimentally that the framework allows IoT devices to generate more appropriate methods in unknown or faulty operating conditions without modifying the underlying LLM's internal weights.",
      "summary": "The paper addresses the problem that LLM-driven IoT devices struggle to adapt to novel situations due to fixed, pre-trained models. It proposes the Method Decoration (DeMe) framework, which augments an LLM's reasoning path with contextual decorations from experience and environment to generate adaptive methods. Experimental results show DeMe enables devices to derive more appropriate methods for unseen or faulty conditions.",
      "mindmap": "graph TB\n        A[”Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments”] --> B[”核心问题/Problem: LLMs in IoT lack adaptability to unseen situations and rely on fixed logic.”]\n        A --> C[”主要方法/Method: DeMe framework modifies LLM method-generation using decorations from goals, experience, and feedback.”]\n        A --> D[”关键结果/Results: Enables derivation of more appropriate methods for unknown/faulty conditions.”]"
    },
    {
      "title": "Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco",
      "authors": "Siyu Li, Chenwei Song, Wan Zhou, Xinyi Liu",
      "institution": "Chongqing Jiaotong University",
      "link": "https://arxiv.org/pdf/2512.21837",
      "code": null,
      "tags": [
        "knowledge-augmented reasoning",
        "GraphRAG",
        "Knowledge Graph",
        "Graph Neural Network",
        "LoRA",
        "ChatGLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85aaa4f0b61b3033af1966c2105126130730ca9d346945b5a0ca02e3f706eb1a_w640_q70.webp",
      "contributions": "1. Proposes an LLM-based approach integrating a domain-specific knowledge graph for reasoning in tobacco pest and disease control, built upon the GraphRAG framework. 2. Employs a GNN to learn expressive node representations that capture relational information within the knowledge graph, enhancing the model's reasoning capability. 3. Demonstrates effective parameter-efficient fine-tuning of a ChatGLM backbone using LoRA, achieving superior performance in complex reasoning scenarios like multi-hop and comparative reasoning.",
      "summary": "This paper proposes a method that enhances large language models for agricultural knowledge reasoning by integrating graph-structured information. It constructs a tobacco pest and disease knowledge graph, uses a GNN to learn node representations, and fine-tunes a ChatGLM model with LoRA. The approach outperforms baselines, significantly improving reasoning accuracy and depth, especially in complex scenarios.",
      "mindmap": "graph TB\n    A[Knowledge Reasoning of LLMs Integrating Graph Information for Tobacco Pest Control<br>LLM集成图信息的烟草病虫害知识推理] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[传统方法依赖专家经验，效率低、错误率高<br>Traditional methods rely on expert experience, low efficiency & high error]\n    C --> C1[基于GraphRAG框架，构建烟草病虫害知识图谱<br>Built on GraphRAG, construct tobacco pest/disease KG]\n    C --> C2[使用GNN学习图谱节点表示，ChatGLM+LoRA微调<br>Use GNN for node representations, fine-tune ChatGLM with LoRA]\n    D --> D1[在多指标上超越基线方法<br>Outperforms baselines across multiple metrics]\n    D --> D2[显著提升复杂推理（多跳、比较）的准确性和深度<br>Significantly improves accuracy & depth in complex reasoning]"
    },
    {
      "title": "AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts",
      "authors": "Baorong Huang, Ali Asiri",
      "institution": "Huaihua University, Umm al-Qura University",
      "link": "https://arxiv.org/pdf/2512.21842",
      "code": "https://github.com/XXX",
      "tags": [
        "machine translation",
        "sentence alignment",
        "parallel corpora",
        "Arabic-English",
        "legal texts",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f00c37d022ef71644588277bad96472223331ff4180059a6a3d353133f3a205_w640_q70.webp",
      "contributions": "1. Proposed AlignAR, a generative sentence alignment method for Arabic-English parallel corpora. 2. Introduced a new dataset of complex legal and literary texts, featuring a \"Hard\" subset with reduced one-to-one mappings to better evaluate alignment methods. 3. Developed a hybrid LLM-plus-human-validation workflow and a bilingual annotation tool for creating gold-standard alignments.",
      "summary": "This paper addresses the scarcity of high-quality Arabic-English parallel corpora by proposing AlignAR, a generative sentence alignment method. The method, along with a new dataset of complex legal and literary texts, demonstrates that LLM-based approaches are more robust than traditional methods, achieving an 85.5% F1-score and a 9% improvement.",
      "mindmap": "graph TB\n        A[AlignAR: Generative Sentence Alignment for Arabic-English Parallel Corpora of Legal and Literary Texts] --> B[核心问题/Problem: Arabic-English parallel corpora are scarce and lack complex mappings]\n        A --> C[主要方法/Method: Proposes AlignAR, a generative sentence alignment method using LLMs and a new dataset]\n        A --> D[关键结果/Results: LLM-based methods show superior robustness, achieving 85.5% F1-score, a 9% improvement]"
    },
    {
      "title": "HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs",
      "authors": "Jiaxin Liu, Peiyi Tu, Wenyu Chen, Yihong Zhuang, Xinxia Ling, Anji Zhou, Chenxi Wang, Zhuo Han, Zhengkai Yang, Junbo Zhao, Zenan Huang, Yuanyuan Wang",
      "institution": "Ant Group, Xiamen University, Beijing Normal University, Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.21849",
      "code": "https://github.com/inclusionAI/HeartBench",
      "tags": [
        "evaluation",
        "anthropomorphic intelligence",
        "benchmark",
        "psychological counseling",
        "rubric-based evaluation",
        "reasoning-before-scoring"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dc9f1570e111d07840de8240e6e5f545f05ae646e05a5121a0a6c4037e3637a_w640_q70.webp",
      "contributions": "1. Introduces HeartBench, a novel benchmark framework for evaluating the integrated emotional, cultural, and ethical dimensions (anthropomorphic intelligence) of Chinese LLMs. 2. Proposes a theory-driven taxonomy and a case-specific, rubric-based \"reasoning-before-scoring\" evaluation protocol to translate abstract human-like traits into measurable criteria. 3. Provides an analysis revealing a significant performance gap in current LLMs, especially in scenarios with subtle emotional subtexts and complex ethical trade-offs, establishing a standardized metric and a blueprint for creating human-aligned training data.",
      "summary": "The paper addresses the gap in evaluating the social and emotional intelligence (anthropomorphic intelligence) of LLMs, particularly in the Chinese context. It proposes HeartBench, a benchmark framework grounded in psychological counseling scenarios, which uses a rubric-based evaluation method. The assessment of 13 LLMs shows a substantial performance ceiling, with even top models achieving only 60% of the expert ideal, highlighting significant decay in handling complex emotional and ethical nuances.",
      "mindmap": "graph TB\n        A[HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[LLMs缺乏拟人化智能 / LLMs lack anthropomorphic intelligence]\n        B --> B2[中文语境缺乏评估框架 / Lack of evaluation frameworks in Chinese context]\n        C --> C1[基于心理咨询场景的基准 / Benchmark based on psychological counseling scenarios]\n        C --> C2[理论驱动的分类法 / Theory-driven taxonomy]\n        C --> C3[基于量规的推理评分法 / Rubric-based reasoning-before-scoring]\n        D --> D1[模型性能存在上限 / Performance ceiling in models]\n        D --> D2[复杂场景表现显著下降 / Significant decay in complex scenarios]"
    },
    {
      "title": "TimeBill: Time-Budgeted Inference for Large Language Models",
      "authors": "Qi Fan, An Zou, Yehan Ma",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21859",
      "code": null,
      "tags": [
        "llm inference",
        "time-budgeted inference",
        "KV cache eviction",
        "response length prediction",
        "execution time estimation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a21a4204d1665c895b35788196ab3a0e5b32216d06abc37bfaaa9aefac4cb2f5_w640_q70.webp",
      "contributions": "1. Proposed a fine-grained response length predictor (RLP) and an execution time estimator (ETE) for accurate end-to-end LLM inference time modeling. 2. Developed a time-budgeted efficient inference approach that adaptively adjusts the KV cache eviction ratio based on predicted execution time and a given time budget. 3. Demonstrated through experiments that TimeBill improves task completion rate and maintains response performance under various time constraints.",
      "summary": "The paper proposes TimeBill, a framework for performing LLM inference within a strict time budget. It uses predictors to estimate response length and execution time, then dynamically adjusts the KV cache eviction ratio to meet deadlines while preserving output quality. Experiments show it improves task completion rates and maintains performance compared to fixed strategies.",
      "mindmap": "graph TB\n        A[TimeBill: Time-Budgeted Inference for Large Language Models] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM推理时间不确定/Uncertain LLM Inference Time]\n        B --> B2[固定KV缓存策略不灵活/Fixed KV Cache Strategy Inflexible]\n        C --> C1[响应长度预测器 (RLP)/Response Length Predictor (RLP)]\n        C --> C2[执行时间估计器 (ETE)/Execution Time Estimator (ETE)]\n        C --> C3[自适应KV缓存驱逐/Adaptive KV Cache Eviction]\n        D --> D1[提高任务完成率/Improves Task Completion Rate]\n        D --> D2[保持响应性能/Maintains Response Performance]"
    },
    {
      "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?",
      "authors": "Naen Xu, Jinghuai Zhang, Changjiang Li, Hengyu An, Chunyi Zhou, Jun Wang, Boyu Xu, Yuyuan Li, Tianyu Du, Shouling Ji",
      "institution": "Zhejiang University, University of California, Los Angeles, Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.21871",
      "code": "https://github.com/bluedream02/CopyGuard",
      "tags": [
        "multi-modal inference",
        "copyright compliance",
        "vision-language models",
        "tool-augmented defense",
        "benchmark dataset",
        "multimodal query"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a933ea78af16685ceab38b447862e9c50b08de435c2e6b662d59551bf5552fdc_w640_q70.webp",
      "contributions": "1. Introduced a large-scale benchmark dataset of 50,000 multimodal query-content pairs to evaluate copyright compliance in LVLMs. 2. Conducted a comprehensive evaluation revealing significant deficiencies in state-of-the-art LVLMs' ability to recognize and respect copyrighted content. 3. Proposed a novel tool-augmented defense framework to reduce copyright infringement risks in LVLM inference.",
      "summary": "This paper evaluates how large vision-language models (LVLMs) handle copyrighted visual content and finds they often fail to comply with copyright regulations. To address this, the authors propose a tool-augmented defense framework for copyright compliance. The work highlights the need for developing copyright-aware LVLMs to ensure responsible use.",
      "mindmap": "graph TB\n        Root[”Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?”]\n        Root --> Problem[”核心问题/Problem: LVLMs may infringe copyright when processing visual inputs”]\n        Root --> Method[”主要方法/Method: Benchmark dataset & Tool-augmented defense framework”]\n        Root --> Results[”关键结果/Results: Current LVLMs are deficient; Proposed framework reduces risk”]"
    },
    {
      "title": "CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics",
      "authors": "Vaibhav Devraj, Dhruv Kumar, Jagat Sesh Challa",
      "institution": "Birla Institute of Technology and Science (BITS), Pilani",
      "link": "https://arxiv.org/pdf/2512.21877",
      "code": null,
      "tags": [
        "text-to-sql",
        "benchmark",
        "multilingual",
        "domain-specific",
        "large language models",
        "sports analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd335127a490c2b4b59330fd1867a57551c792f1b695f15e48789a3992b7c05a_w640_q70.webp",
      "contributions": "1. Introduces CricBench, a novel benchmark for evaluating LLMs on Text-to-SQL tasks in the specialized domain of cricket analytics. 2. Establishes a multilingual framework, providing a \"Gold Standard\" dataset in both English and Hindi, with extensibility to other languages. 3. Demonstrates a significant performance gap for LLMs between general and specialized domains and challenges the assumption of English as the optimal prompt language for such tasks.",
      "summary": "This paper introduces CricBench, a multilingual benchmark for evaluating Large Language Models on Text-to-SQL tasks in the specialized domain of cricket analytics. The benchmark features a manually curated dataset in English and Hindi and is used to evaluate six state-of-the-art models. The results show that high performance on general benchmarks does not transfer well to this specialized domain, and surprisingly, code-mixed Hindi queries can perform as well as or better than English ones.",
      "mindmap": "graph TB\n        A[CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在专业领域Text-to-SQL能力未充分探索/LLMs' Text-to-SQL capability in specialized domains is under-explored]\n        B --> B2[现有基准缺乏多语言和体育分析特性/Existing benchmarks lack multilingual and sports analytics features]\n        C --> C1[构建板球领域专业多语言基准/Build a specialized multilingual benchmark for cricket]\n        C --> C2[与专家合作创建”黄金标准”查询/Collaborate with experts to create ”Gold Standard” queries]\n        C --> C3[评估六个最先进的LLMs/Evaluate six state-of-the-art LLMs]\n        D --> D1[专业领域性能显著下降/Significant performance drop in specialized domain]\n        D --> D2[DeepSeek R1表现最佳/DeepSeek R1 achieves SOTA]\n        D --> D3[印地语查询准确率可比或更高/Hindi queries yield parity or higher accuracy]"
    },
    {
      "title": "Explainable Statute Prediction via Attention-based Model and LLM Prompting",
      "authors": "Sachin Pawar, Girish Keshav Palshikar, Anindita Sinha Banerjee, Nitin Ramrakhiyani, Basit Ali",
      "institution": "TCS Research, Tata Consultancy Services Limited",
      "link": "https://arxiv.org/pdf/2512.21902",
      "code": null,
      "tags": [
        "legal text processing",
        "statute prediction",
        "explainable AI",
        "attention mechanism",
        "large language models",
        "chain-of-thought prompting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0a88ac95c85beb5da693179a57fced56221862f49b2b3f82a7923e814deb844_w640_q70.webp",
      "contributions": "1. Proposes AoS, an attention-based supervised model using sentence transformers for explainable statute prediction. 2. Proposes LLMPrompt, a zero-shot method using large language models with standard and Chain-of-Thought prompting for prediction and explanation. 3. Evaluates both prediction performance and explanation quality across two datasets using automated and human evaluation methods.",
      "summary": "This paper tackles the problem of automatically predicting relevant legal statutes from case descriptions and providing human-understandable explanations. It proposes two methods: a supervised attention-based model (AoS) and a zero-shot LLM prompting approach (LLMPrompt). The study compares their prediction performance against baselines and evaluates the quality of the generated explanations.",
      "mindmap": "graph TB\n        Root[”Explainable Statute Prediction via Attention-based Model and LLM Prompting<br>基于注意力模型和LLM提示的可解释法规预测”] --> Problem[”核心问题/Problem<br>Automatic prediction of relevant statutes from case descriptions with explanations<br>从案例描述中自动预测相关法规并提供解释”]\n        Root --> Method[”主要方法/Method<br>Two proposed techniques: AoS (supervised attention) and LLMPrompt (zero-shot LLM prompting)<br>两种方法: AoS(监督注意力)和LLMPrompt(零样本LLM提示)”]\n        Root --> Results[”关键结果/Results<br>Comparison of prediction performance and evaluation of explanation quality<br>比较预测性能并评估解释质量”]"
    },
    {
      "title": "Accelerate Speculative Decoding with Sparse Computation in Verification",
      "authors": "Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang",
      "institution": "Soochow University, Meituan",
      "link": "https://arxiv.org/pdf/2512.21911",
      "code": null,
      "tags": [
        "llm inference",
        "speculative decoding",
        "sparse computation",
        "verification stage",
        "mixture-of-experts (MoE)",
        "efficiency-accuracy trade-off"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp",
      "contributions": "1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.",
      "summary": "This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.",
      "mindmap": "graph TB\n        A[Accelerate Speculative Decoding with Sparse Computation in Verification] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[验证阶段成为瓶颈/Verification stage is bottleneck]\n        B1 --> B2[长上下文与MoE模型/Long-context & MoE models]\n        C --> C1[稀疏验证框架/Sparse Verification Framework]\n        C1 --> C2[联合稀疏化注意力、FFN、MoE/Jointly sparsifies Attention, FFN, MoE]\n        C1 --> C3[检索重用策略/Retrieval Reuse Strategy]\n        D --> D1[有利的效率-精度权衡/Favorable efficiency-accuracy trade-off]\n        D --> D2[稳定的接受长度/Stable acceptance length]"
    },
    {
      "title": "SWE-RM: Execution-free Feedback For Software Engineering Agents",
      "authors": "KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He",
      "institution": "The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)",
      "link": "https://arxiv.org/pdf/2512.21919",
      "code": null,
      "tags": [
        "software engineering agents",
        "reward model",
        "test-time scaling",
        "reinforcement learning",
        "mixture-of-experts",
        "SWE-Bench"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp",
      "contributions": "1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.",
      "summary": "The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.",
      "mindmap": "graph TB\n        Root[”SWE-RM: Execution-free Feedback For Software Engineering Agents”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”执行反馈的局限性/Limitations of Execution-based Feedback”]\n        Problem --> P2[”无执行反馈未被充分探索/Execution-free Feedback Underexplored”]\n        Method --> M1[”识别RL关键指标/Identify Key RL Metrics (Accuracy, Calibration)”]\n        Method --> M2[”可控实验分析/Controlled Experiments on Training Factors”]\n        Method --> M3[”提出SWE-RM模型/Propose SWE-RM (MoE Reward Model)”]\n        Results --> R1[”提升TTS性能/Improves TTS Performance (e.g., Qwen3-Coder-Max to 74.6%)”]\n        Results --> R2[”提升RL性能/Improves RL Performance (+3 points)”]\n        Results --> R3[”开源模型SOTA/New SOTA Among Open-Source Models”]"
    },
    {
      "title": "Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs",
      "authors": "Sachin Pawar, Manoj Apte, Kshitij Jadhav, Girish Keshav Palshikar, Nitin Ramrakhiyani",
      "institution": "TCS Research, Tata Consultancy Services Limited",
      "link": "https://arxiv.org/pdf/2512.21933",
      "code": null,
      "tags": [
        "tokenization",
        "tokenization penalty",
        "large language models",
        "byte-pair encoding",
        "vocabulary size",
        "natural word splitting"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/015399929e56260633eb709a56e41948acd324ce4065b0fcb286daa6d5ea6e33_w640_q70.webp",
      "contributions": "1. Proposes the hypothesis that breaking natural words into multiple tokens negatively impacts LLM performance on NLP tasks. 2. Introduces a set of penalty functions to quantify the \"badness\" of tokenization for a given text and LLM. 3. Establishes the statistical significance of the hypothesis across multiple NLP tasks and different LLMs.",
      "summary": "This paper investigates how tokenization, specifically the splitting of natural words into multiple sub-tokens due to limited vocabulary, affects the performance of Large Language Models (LLMs). The authors propose penalty functions to measure this tokenization effect and demonstrate its statistically significant negative impact on various NLP tasks.",
      "mindmap": "graph TB\n        A[Broken Words, Broken Performance: Effect of Tokenization on Performance of LLMs] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM分词将自然词拆分为多个子词/LLM tokenization splits natural words into multiple sub-tokens]\n        B --> B2[假设这会损害模型性能/Hypothesized to hurt model performance]\n        C --> C1[提出量化分词影响的惩罚函数/Propose penalty functions to quantify tokenization effect]\n        D --> D1[在多任务和多模型上验证假设的显著性/Validate hypothesis significance on multiple tasks & models]"
    },
    {
      "title": "Self-attention vector output similarities reveal how machines pay attention",
      "authors": "Tal Halevi, Yarden Tzach, Ronit D. Gross, Shalom Rosner, Ido Kanter",
      "institution": "Bar-Ilan University",
      "link": "https://arxiv.org/pdf/2512.21956",
      "code": null,
      "tags": [
        "attention mechanisms",
        "self-attention",
        "BERT",
        "attention heads",
        "vector similarity",
        "token representation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ef3aef5be4139745b138137e89a3f21de053bd91a9fedbe345ad6f90900a98b_w640_q70.webp",
      "contributions": "1. Introduced a new method for quantifying information processing within the self-attention mechanism using a context similarity matrix derived from token vectors. 2. Revealed that different attention heads specialize in distinct linguistic features, such as identifying token repetitions or common contextual tokens. 3. Demonstrated a progression from long-range to short-range token similarities across layers, culminating in a focus on intra-sentence relationships and unique token-centric similarity patterns in final layers.",
      "summary": "This paper proposes a novel approach to analyze the self-attention mechanism in transformer models by examining vector output similarities. The analysis on BERT-12 shows that attention heads specialize in different linguistic features and that similarity patterns evolve from long-range to short-range, focusing on sentence-level structures in deeper layers.",
      "mindmap": "graph TB\n        Root[”Self-attention vector output similarities reveal how machines pay attention<br/>自注意力向量输出相似性揭示机器如何关注”] --> Problem[”核心问题/Problem: Quantitative characterization of self-attention learning process<br/>自注意力学习过程的定量表征”]\n        Root --> Method[”主要方法/Method: Context similarity matrix from self-attention head vectors<br/>基于自注意力头向量的上下文相似性矩阵”]\n        Root --> Results[”关键结果/Results: Heads specialize linguistically; similarity shifts from long to short range<br/>头部语言专业化;相似性从长程转向短程”]"
    },
    {
      "title": "Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management",
      "authors": "Sunil Arora, John Hastings",
      "institution": "Dakota State University",
      "link": "https://arxiv.org/pdf/2512.22060",
      "code": null,
      "tags": [
        "AI Governance & Compliance",
        "lifecycle management",
        "bias detection",
        "differential privacy",
        "federated learning",
        "terminology drift"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/113703d05215aac7e8678f24cb38d882fa4c99927066ea2264ef3d1b4c3a1d67_w640_q70.webp",
      "contributions": "1. Proposes the SC-NLP-LMF, a comprehensive six-phase framework for secure and compliant NLP model lifecycle management. 2. Integrates established technical methods (e.g., bias detection, differential privacy) with leading organizational standards (e.g., NIST AI RMF, EU AI Act). 3. Validates the framework's practicality through a healthcare case study demonstrating detection of and response to terminology drift.",
      "summary": "This paper introduces the Secure and Compliant NLP Lifecycle Management Framework (SC-NLP-LMF), a six-phase model developed from a systematic review to address security, privacy, and compliance risks in NLP systems. It integrates methods like bias detection and differential privacy with standards like NIST AI RMF and the EU AI Act. The framework provides a practical structure for organizations to manage NLP systems in high-risk environments, as illustrated by a healthcare case study on handling terminology drift.",
      "mindmap": "graph TB\n        Root[”Toward Secure and Compliant AI: Organizational Standards and Protocols for NLP Model Lifecycle Management”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>NLP systems in sensitive domains face unaddressed security, privacy, and compliance risks.”]\n        Method[”主要方法/Method<br>Proposes SC-NLP-LMF, a six-phase framework integrating standards (NIST, ISO, EU AI Act) and techniques (bias detection, differential privacy).”]\n        Results[”关键结果/Results<br>Provides a practical lifecycle structure for secure, accountable NLP systems, validated via a healthcare case study.”]"
    },
    {
      "title": "Context as a Tool: Context Management for Long-Horizon SWE-Agents",
      "authors": "Shukai Liu, Jian Yang, Bo Jiang, Yizhi Li, Jinyang Guo, Xianglong Liu, Bryan Dai",
      "institution": "Beihang University, University of Manchester, Ubiquant",
      "link": "https://arxiv.org/pdf/2512.22087",
      "code": null,
      "tags": [
        "agent system",
        "context management",
        "long-horizon reasoning",
        "SWE-agents",
        "trajectory compression",
        "structured workspace"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/554c080cfd26463c6d73be16144f677075ea893401e3c8ae26ee7321c48b2be8_w640_q70.webp",
      "contributions": "1. Proposes CAT, a new paradigm that treats context management as an integrated, callable tool for agents, enabling proactive control. 2. Introduces a structured context workspace with stable semantics, condensed long-term memory, and high-fidelity short-term interactions. 3. Presents CAT-GENERATOR, a trajectory-level supervision framework for training the SWE-Compressor model, which achieves state-of-the-art performance on SWE-Bench-Verified.",
      "summary": "The paper addresses the problem of context explosion and semantic drift in long-horizon software engineering agents by proposing CAT, a paradigm that integrates proactive context management as a tool. It introduces a structured workspace and a training framework to produce the SWE-Compressor model. Experiments show this model significantly outperforms existing baselines on a software engineering benchmark while maintaining stable reasoning under a bounded context budget.",
      "mindmap": "graph TB\n        A[Context as a Tool: Context Management for Long-Horizon SWE-Agents] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有代理上下文爆炸、语义漂移/Existing agents suffer context explosion & semantic drift]\n        C --> C1[CAT: 将上下文管理作为可调用工具/CAT: Context management as a callable tool]\n        C --> C2[结构化上下文工作区/Structured context workspace]\n        C --> C3[CAT-GENERATOR 训练框架/CAT-GENERATOR training framework]\n        D --> D1[SWE-Compressor 达到 57.6% 解决率/SWE-Compressor achieves 57.6% solved rate]\n        D --> D2[显著优于基准/Significantly outperforms baselines]"
    },
    {
      "title": "Unifying Learning Dynamics and Generalization in Transformers Scaling Law",
      "authors": "Chiwun Yang",
      "institution": "Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.22088",
      "code": null,
      "tags": [
        "learning theory",
        "scaling law",
        "learning dynamics",
        "generalization error",
        "transformer",
        "stochastic gradient descent"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c9b067b56202cd4607e684058e78ac331373bf12bf6848ca444276e2dcafe9f9_w640_q70.webp",
      "contributions": "1. Formalizes the learning dynamics of transformers as an ODE system and approximates it to kernel behaviors, moving beyond toy models to analyze SGD on multi-layer transformers with arbitrary data distributions. 2. Establishes a theoretical upper bound on excess risk with a distinct phase transition: exponential decay in the optimization phase and a power-law decay of Θ(C^\\{-1/6\\}) in the statistical phase. 3. Derives isolated scaling laws for model size, training time, and dataset size, explaining how each variable independently governs generalization bounds.",
      "summary": "This paper provides a theoretical foundation for the empirical scaling laws of large language models. It models transformer learning dynamics as an ODE system and analyzes SGD training on realistic data. The main result is a unified theory showing a phase transition in generalization error, from exponential to power-law decay, as computational resources scale.",
      "mindmap": "graph TB\n        A[Unifying Learning Dynamics and Generalization in Transformers Scaling Law] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[Scaling Law理论原理不清 / Poorly understood theoretical underpinnings of scaling laws]\n        C --> C1[形式化学习动态为ODE系统 / Formalize learning dynamics as ODE system]\n        C --> C2[近似为核行为 / Approximate to kernel behaviors]\n        C --> C3[分析SGD训练真实Transformer / Analyze SGD training for real transformers]\n        D --> D1[泛化误差上界与相变 / Upper bound on excess risk with phase transition]\n        D --> D2[优化相:指数衰减 / Optimization phase: Exponential decay]\n        D --> D3[统计相:幂律衰减 Θ(C^{-1/6}) / Statistical phase: Power-law decay Θ(C^{-1/6})]\n        D --> D4[分离的规模定律 / Isolated scaling laws for model size, time, data]"
    },
    {
      "title": "Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis",
      "authors": "Duygu Altinok",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.22100",
      "code": null,
      "tags": [
        "benchmark construction",
        "Turkish NLU benchmark",
        "semi-automated annotation",
        "sentiment analysis dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aae4aef01bf4bd7a32414041836c4d9d7383c50872f47bdb0dee4d45af35adb_w640_q70.webp",
      "contributions": "1. Introduces TrGLUE, the first comprehensive GLUE-style benchmark for Turkish Natural Language Understanding, filling a critical gap. 2. Presents SentiTurca, a specialized benchmark for Turkish sentiment analysis. 3. Provides a scalable, reproducible semi-automated dataset creation pipeline combining LLM annotation, cross-model checks, and human validation.",
      "summary": "This paper addresses the lack of a comprehensive benchmark for evaluating Turkish language understanding by introducing TrGLUE and SentiTurca. The benchmarks are created using a semi-automated pipeline with LLM annotation and human validation to ensure quality and linguistic naturalness. The work establishes a robust evaluation framework and provides resources to empower Turkish NLP research.",
      "mindmap": "graph TB\n        A[Introducing TrGLUE and SentiTurca] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[缺乏土耳其语综合基准/Lack of Turkish NLU Benchmark]\n        C --> C1[半自动标注流程/Semi-automated Pipeline]\n        C1 --> C2[LLM标注 + 交叉验证 + 人工校验/LLM Annotation + Cross-check + Human Validation]\n        D --> D1[发布TrGLUE & SentiTurca/Release TrGLUE & SentiTurca]\n        D --> D2[提供代码与资源/Provide Code & Resources]"
    },
    {
      "title": "A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting",
      "authors": "Shuyu Gan, Renxiang Wang, James Mooney, Dongyeop Kang",
      "institution": "University of Minnesota",
      "link": "https://arxiv.org/pdf/2512.22101",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent pipeline",
        "automated data analysis",
        "insight generation",
        "report synthesis",
        "visual analytics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/92651ded84480402816f8db1df902e28dd62cce1b0958cece60e0f518bdd7e1c_w640_q70.webp",
      "contributions": "1. A Data Analyzer agent that orchestrates data profiling, generates diverse visualizations, filters low-quality charts, and automatically scores candidate insights for depth, correctness, and actionability. 2. A Presenter agent that sequences topics, composes chart-grounded narratives from top insights, writes transitions, and revises the document to produce a coherent, publication-ready report. 3. An end-to-end Analyzer-to-Presenter (A2P) pipeline that operationalizes co-analysis by coupling quality-assured analysis with narrative synthesis, improving the real-world usefulness of automated data analysis.",
      "summary": "This paper presents A2P-Vis, a two-part multi-agent pipeline designed to automate the generation of data visualization reports. The system uses a Data Analyzer to create and vet visual insights and a Presenter to assemble them into a coherent narrative. The authors claim this end-to-end approach improves the practical utility of automated data analysis for practitioners.",
      "mindmap": "graph TB\n        A[A2P-Vis] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[自动化数据科学流程的瓶颈/Gaps in automating data science]\n        B1 --> B2[生成有洞察力的可视化/Generating insightful visual evidence]\n        B1 --> B3[组装成专业报告/Assembling coherent professional report]\n        C --> C1[两部分多智能体管道/Two-part multi-agent pipeline]\n        C1 --> C2[数据分析器/Data Analyzer]\n        C2 --> C3[生成并评估图表与洞察/Generates & evaluates charts & insights]\n        C1 --> C4[报告呈现器/Presenter]\n        C4 --> C5[编排主题并撰写叙述/Orders topics & composes narrative]\n        D --> D1[端到端协同分析/End-to-end co-analysis]\n        D1 --> D2[提高自动化数据分析的实用性/Improves usefulness of automated analysis]"
    },
    {
      "title": "MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation",
      "authors": "Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen",
      "institution": "National Taiwan University, E.SUN Financial Holding Co., Ltd., National Kaohsiung Normal University",
      "link": "https://arxiv.org/pdf/2512.20626",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "multimodal knowledge graph",
        "cross-modal reasoning",
        "visual document understanding",
        "retrieval-augmented generation",
        "entity-centric structure"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/425d6eb853edb40749e686474d27dc018d8a86017a4cd69160f9ac2081d36385_w640_q70.webp",
      "contributions": "1. Proposes a multimodal knowledge graph-based RAG framework that integrates visual cues into KG construction, retrieval, and answer generation for cross-modal reasoning. 2. Addresses the limitation of existing text-only KG-RAG methods by automatically building KGs that capture text-to-figure and figure-to-figure relationships. 3. Demonstrates superior performance over existing RAG approaches on both textual and multimodal question-answering tasks through comprehensive experiments.",
      "summary": "The paper introduces MegaRAG, a multimodal knowledge graph-based retrieval-augmented generation method designed to overcome the limitations of text-only RAG systems in understanding complex, long-form visual documents. It integrates visual information into the knowledge graph construction and retrieval process to enable better cross-modal reasoning. Experimental results show it consistently outperforms existing RAG methods on various question-answering tasks.",
      "mindmap": "graph LR\n        A[MegaRAG: 多模态知识图谱检索增强生成 / MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有RAG方法在长文档、多模态内容上理解不足 / Existing RAG struggles with long-form, multimodal document understanding]\n        C --> C1[构建融合视觉线索的多模态知识图谱 / Construct multimodal KG incorporating visual cues]\n        C --> C2[在多模态检索与生成中利用图谱 / Utilize KG in multimodal retrieval & generation]\n        D --> D1[在全局与细粒度QA任务上超越现有方法 / Outperforms existing methods on global & fine-grained QA]"
    },
    {
      "title": "Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams",
      "authors": "Aayam Bansal, Ishaan Gangwani",
      "institution": "IEEE",
      "link": "https://arxiv.org/pdf/2512.20631",
      "code": null,
      "tags": [
        "sentiment analysis",
        "temporal drift",
        "zero-training detection",
        "transformer models",
        "social media streams",
        "model instability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8e40c0a23df847aa858c5e0ce28602f612024103d66ccaea9f9da99a1dded46_w640_q70.webp",
      "contributions": "1. Demonstrated significant temporal drift in transformer sentiment models during real-world events, with accuracy drops up to 23.4% on authentic social media data. 2. Introduced four novel zero-training drift detection metrics that outperform embedding-based baselines and are suitable for production deployment. 3. Provided comprehensive statistical validation on 12,279 authentic social media posts from major events, establishing practical significance exceeding industry monitoring thresholds.",
      "summary": "This paper addresses the problem of temporal drift in transformer-based sentiment models during real-world events without requiring model retraining. It proposes a zero-training detection framework using novel inference-time metrics, validated on authentic social media data. The main conclusion is that this method effectively detects significant model instability and enables immediate deployment for real-time monitoring systems.",
      "mindmap": "graph LR\n    A[Zero-Training Temporal Drift Detection for Transformer Sentiment Models] --> B[核心问题/Problem: Transformer模型在动态事件期间的行为不稳定/Transformer model instability during dynamic events]\n    A --> C[主要方法/Method: 零训练检测框架与四个新指标/Zero-training detection framework with four novel metrics]\n    A --> D[关键结果/Results: 在真实数据上验证，准确率下降达23.4%，检测能力强/Validated on authentic data, 23.4% accuracy drop, strong detection capability]"
    },
    {
      "title": "Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning",
      "authors": "Weiwei Wang",
      "institution": "Shenzhen Sunline Tech Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.20634",
      "code": null,
      "tags": [
        "llm training",
        "catastrophic forgetting",
        "spurious forgetting",
        "shallow alignment",
        "deep alignment",
        "task alignment depth"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2920732eeec32977638a62ffbcf4b4b075dbdd77ebc58fa777ff8a10e117219_w640_q70.webp",
      "contributions": "1. Introduced a quantitative framework (shallow vs. deep alignment) to measure task alignment depth across token positions. 2. Developed real-time detection methods and analysis tools for identifying shallow alignment and spurious forgetting during training. 3. Proposed adaptive mitigation strategies that automatically distinguish forgetting types and promote deep alignment to improve model robustness.",
      "summary": "This paper addresses catastrophic forgetting in continual learning for LLMs by identifying that performance drops are often due to \"spurious forgetting\" from shallow task alignment. The authors propose a framework to quantitatively measure alignment depth, detect shallow alignment in real-time, and apply mitigation strategies to promote deep alignment. Experiments show their method accurately identifies spurious forgetting and improves model robustness against forgetting by 3.3-7.1% over baselines.",
      "mindmap": "graph LR\n    A[Real-Time Detection and Quantitative Analysis of Spurious Forgetting<br/>虚假遗忘的实时检测与定量分析] --> B[核心问题/Problem: Catastrophic forgetting from shallow task alignment<br/>由浅层任务对齐导致的灾难性遗忘]\n    A --> C[主要方法/Method: Quantitative metrics & real-time detection for alignment depth<br/>对齐深度的量化指标与实时检测]\n    A --> D[关键结果/Results: High identification accuracy & improved robustness<br/>高识别准确率与提升的鲁棒性]"
    },
    {
      "title": "Uncovering Competency Gaps in Large Language Models and Their Benchmarks",
      "authors": "Matyas Bohacek, Nino Scherrer, Nicholas Dufour, Thomas Leung, Christoph Bregler, Stephanie C. Y. Chan",
      "institution": "Stanford University, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.20638",
      "code": "competency-gaps.github.io",
      "tags": [
        "llm evaluation",
        "sparse autoencoders",
        "benchmark gaps",
        "model gaps",
        "concept activations",
        "competency gaps"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c6d5ab9e8ede467e65cbc2079e58ecf9b8d8ade8145f7e9e90f1b6f8382e288b_w640_q70.webp",
      "contributions": "1. Proposes a novel method using sparse autoencoders (SAEs) to automatically uncover fine-grained competency gaps in LLMs and benchmarks. 2. Introduces a representation-grounded evaluation approach that computes saliency-weighted performance scores based on model-internal concept activations. 3. Demonstrates the method's ability to identify specific model weaknesses (e.g., non-sycophantic behaviors) and benchmark coverage imbalances (e.g., over-representation of obedience concepts) without manual supervision.",
      "summary": "This paper addresses the problem that aggregated benchmark scores can hide specific weaknesses in LLMs and imbalances in benchmark coverage. The authors propose an automated method using sparse autoencoders to decompose benchmark performance into fine-grained concepts based on the model's internal representations. Their analysis of two models and ten benchmarks revealed model gaps in areas like non-sycophancy and safety, and benchmark gaps such as an over-representation of obedience-related concepts.",
      "mindmap": "graph LR\n        A[Uncovering Competency Gaps<br/>揭示能力差距] --> B[Problem: Aggregated metrics obscure model/benchmark gaps<br/>问题：聚合指标掩盖模型/基准差距]\n        A --> C[Method: Use Sparse Autoencoders (SAEs) for concept-level decomposition<br/>方法：使用稀疏自编码器进行概念级分解]\n        A --> D[Results: Found gaps in non-sycophancy, safety; benchmark over-represents obedience<br/>结果：发现非谄媚、安全方面的差距；基准过度代表服从性]"
    },
    {
      "title": "Automated Red-Teaming Framework for Large Language Model Security Assessment: A Comprehensive Attack Generation and Detection System",
      "authors": "Zhang Wei, Peilu Hu, Shengning Lang, Hao Yan, Li Mei, Yichao Zhang, Chen Yang, Junfeng Hao, Zhimo Han",
      "institution": "Stevens Institute of Technology, The University of Texas at Dallas, AI Safety Research Lab (Institute of Advanced Computing, Shenzhen), Zheng Zhou University of Light Industry, Affiliated Hospital of Guangdong Medical University",
      "link": "https://arxiv.org/pdf/2512.20677",
      "code": null,
      "tags": [
        "llm security assessment",
        "automated red-teaming",
        "adversarial prompts",
        "meta-prompting",
        "vulnerability detection",
        "alignment robustness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35d6a91284e231b153dfe35185eb27aafd1549063ba05304240c7a14c0b8f78d_w640_q70.webp",
      "contributions": "1. Introduces an automated framework for systematic generation, execution, and evaluation of adversarial prompts against LLMs. 2. Integrates meta-prompting-based attack synthesis and multi-modal detection across six major threat categories (e.g., reward hacking, deceptive alignment). 3. Demonstrates significant improvement in vulnerability discovery rate (3.9x over manual testing) with high detection accuracy (89%) on a target model.",
      "summary": "This paper proposes an automated red-teaming framework to systematically find security vulnerabilities in large language models. The framework uses meta-prompting to generate attacks and multi-modal detection to evaluate them across six threat categories. Experiments show it discovers vulnerabilities much faster than manual testing while maintaining high accuracy, enabling scalable AI safety evaluations.",
      "mindmap": "graph LR\n    A[Automated Red-Teaming Framework for LLM Security] --> B[核心问题/Problem: Manual red-teaming is not scalable for comprehensive LLM security assessment]\n    A --> C[主要方法/Method: Automated framework with meta-prompting attack synthesis & multi-modal vulnerability detection]\n    A --> D[关键结果/Results: 3.9x faster vulnerability discovery, 89% detection accuracy, 47 vulnerabilities found]"
    },
    {
      "title": "PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation",
      "authors": "Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai",
      "institution": "Fujitsu Limited, RIKEN Center for AIP, Institute of Science Tokyo, Tokai University",
      "link": "https://arxiv.org/pdf/2512.20687",
      "code": null,
      "tags": [
        "llm inference",
        "hierarchical autoregressive model",
        "KV-cache optimization",
        "memory-bound inference",
        "multi-resolution context",
        "throughput-quality trade-off"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6824d7ad660d8d52e1568c90187924380b5fd436a69942bfac67084af3298d40_w640_q70.webp",
      "contributions": "1. Proposes PHOTON, a hierarchical autoregressive model that replaces the Transformer's flat token-by-token scanning with a vertical, multi-resolution context access pattern. 2. Introduces a persistent hierarchy of latent streams, with a bottom-up encoder compressing tokens and lightweight top-down decoders reconstructing token representations, reducing decode-time KV-cache traffic. 3. Demonstrates significant improvements in throughput per unit memory (up to 10^3x) and advantages in long-context and multi-query tasks compared to Transformer-based models.",
      "summary": "The paper identifies that Transformer inference becomes memory-bound due to ever-growing KV-cache reads/writes during autoregressive decoding. To solve this, it proposes PHOTON, a hierarchical model that accesses context vertically at multiple resolutions instead of scanning tokens horizontally. This architectural change drastically reduces memory traffic, yielding orders-of-magnitude higher throughput per unit memory while maintaining quality.",
      "mindmap": "graph LR\n    A[PHOTON: Hierarchical Autoregressive Modeling] --> B[核心问题/Problem: Transformer水平扫描导致KV缓存读写成为内存瓶颈/Horizontal scanning causes memory-bound KV-cache bottleneck]\n    A --> C[主要方法/Method: 用垂直多分辨率层次模型替代/Replace with vertical multi-resolution hierarchical model]\n    A --> D[关键结果/Results: 内存效率与吞吐量大幅提升/Significant improvement in memory efficiency & throughput]"
    },
    {
      "title": "SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention",
      "authors": "Alexandros Christoforos, Chadbourne Davis",
      "institution": "Suffolk University",
      "link": "https://arxiv.org/pdf/2512.20724",
      "code": null,
      "tags": [
        "diffusion models",
        "sparse attention",
        "diffusion models",
        "long-text generation",
        "soft absorbing state",
        "computational complexity"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/01893006a5e49ffeaca24f7c5197f5a706782f3051b02cc9dfef88521a05c523_w640_q70.webp",
      "contributions": "1. Introduces SA-DiffuSeq, a diffusion framework that integrates sparse attention to improve scalability for long-document modeling. 2. Proposes a novel soft absorbing state tailored to sparse attention dynamics to stabilize diffusion trajectories and accelerate sequence reconstruction. 3. Demonstrates superior training efficiency and sampling speed compared to state-of-the-art diffusion baselines, especially on extended sequences.",
      "summary": "The paper addresses the high computational cost of diffusion models for long-text generation by proposing SA-DiffuSeq, which integrates sparse attention and a novel soft absorbing state. This method reduces complexity while maintaining generation quality, making it suitable for applications like scientific writing and code generation. The results show that incorporating structured sparsity is a promising direction for efficient long-text generation.",
      "mindmap": "graph LR\n    A[SA-DiffuSeq] --> B[核心问题/Problem<br>Computational Cost & Scalability];\n    A --> C[主要方法/Method<br>Sparse Attention & Soft Absorbing State];\n    A --> D[关键结果/Results<br>Improved Efficiency & Quality];"
    },
    {
      "title": "AgentMath: Empowering Mathematical Reasoning for Large Language Models via Tool-Augmented Agent",
      "authors": "Haipeng Luo, Huawen Feng, Qingfeng Sun, Can Xu, Kai Zheng, Yufei Wang, Tao Yang, Han Hu, Yansong Tang, Di Wang",
      "institution": "Tsinghua University, Tencent Hunyuan",
      "link": "https://arxiv.org/pdf/2512.20745",
      "code": null,
      "tags": [
        "agent system",
        "tool-augmented agent",
        "agentic reinforcement learning",
        "supervised fine-tuning (SFT)",
        "request-level asynchronous rollout",
        "prefix-aware load balancing"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7211416872630b2f7d460fe4b986a1d141827d69b65487826e3374c5e4cce08d_w640_q70.webp",
      "contributions": "1. An automated method to convert natural language chain-of-thought into structured tool-augmented trajectories for generating high-quality SFT data. 2. A novel agentic reinforcement learning paradigm that dynamically interleaves natural language generation with real-time code execution for learning tool-use strategies. 3. An efficient training system with techniques like asynchronous rollout scheduling and prefix-aware load balancing, achieving 4-5x speedup for RL training on long sequences.",
      "summary": "This paper introduces AgentMath, a framework that combines language model reasoning with code interpreter precision to solve complex math problems. It uses automated SFT data generation, agentic RL for tool-use learning, and an efficient training system, achieving state-of-the-art results on benchmarks like AIME24 and AIME25.",
      "mindmap": "graph LR\n    A[AgentMath] --> B[核心问题/Problem: LRMs are inefficient and inaccurate for complex math]\n    A --> C[主要方法/Method: Tool-augmented agent framework with SFT data generation, agentic RL, and efficient training system]\n    A --> D[关键结果/Results: SOTA performance on AIME24, AIME25, HMMT25 benchmarks]"
    },
    {
      "title": "TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior",
      "authors": "Gül Sena Altıntaş, Malikeh Ehghaghi, Brian Lester, Fengyuan Liu, Wanru Zhao, Marco Ciccone, Colin Raffel",
      "institution": "University of Toronto, Vector Institute, Google DeepMind, McGill University, Mila - Quebec AI Institute, University of Cambridge, Hugging Face",
      "link": "https://arxiv.org/pdf/2512.20757",
      "code": "https://github.com/r-three/Tokenizers",
      "tags": [
        "tokenization",
        "tokenizer",
        "language models",
        "benchmark",
        "subword segmentation",
        "BPE"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/48b6cd3c25dd384b02a8b1601f98df302b0d84a5c6e3b043841ea275f5ffdcbd_w640_q70.webp",
      "contributions": "1. Introduces TokSuite, a collection of fourteen language models that are identical except for their tokenizers, enabling isolated study of tokenizer impact. 2. Curates and releases a new benchmark designed to measure model performance under real-world text perturbations that affect tokenization. 3. Provides a robust framework that supports novel findings on the benefits and shortcomings of various popular tokenizers.",
      "summary": "This paper addresses the challenge of isolating the impact of tokenizer choice on language model behavior. It proposes TokSuite, a suite of models with different tokenizers but identical other components, along with a specialized benchmark. The work enables systematic analysis and reveals new insights into how different tokenizers affect model performance.",
      "mindmap": "graph LR\n        A[TokSuite: Measuring Tokenizer Impact] --> B[核心问题/Problem: Tokenization's role in LM performance is poorly understood]\n        A --> C[主要方法/Method: TokSuite - Identical models with different tokenizers + new benchmark]\n        A --> D[关键结果/Results: Novel findings on tokenizer benefits and shortcomings]"
    },
    {
      "title": "Generalization of RLVR Using Causal Reasoning as a Testbed",
      "authors": "Brian Lu, Hongyu Zhao, Shuo Sun, Hao Peng, Rui Ding, Hongyuan Mei",
      "institution": "Johns Hopkins University, University of Maryland, College Park, National University of Singapore, University of Illinois at Urbana-Champaign, Microsoft Research Asia, Toyota Technological Institute at Chicago",
      "link": "https://arxiv.org/pdf/2512.20760",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "causal reasoning",
        "generalization",
        "supervised fine-tuning",
        "large language models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/472c557c79b64b352421bedd952ba76d099165d613e99323a1beb8845a24cf4c_w640_q70.webp",
      "contributions": "1. Provides an empirical study of RLVR generalization using causal inference as a structured testbed, examining generalization across query levels and structural complexity. 2. Identifies that RLVR's benefits over SFT for generalization are contingent on specific combinations of model size and training query level, and depend on the model's initial reasoning competence. 3. Shows that RLVR improves specific causal reasoning subskills, such as marginalization strategy and intermediate probability calculation, leading to accuracy gains on complex queries.",
      "summary": "This paper studies the generalization of Reinforcement Learning with Verifiable Rewards (RLVR) for large language models on causal reasoning tasks. It finds that RLVR can outperform supervised fine-tuning in generalization, but its effectiveness depends on model size, training data, and the model's initial competence. The results indicate RLVR improves specific reasoning sub-skills when the model has a sufficient foundational ability.",
      "mindmap": "graph LR\n    A[”Generalization of RLVR Using Causal Reasoning as a Testbed<br>以因果推理为测试平台的RLVR泛化研究”] --> B[”核心问题/Problem<br>RLVR何时能实现鲁棒泛化？<br>When does RLVR yield robust generalization?”]\n    A --> C[”主要方法/Method<br>在因果图模型上实证研究RLVR与SFT<br>Empirical study of RLVR vs SFT on causal graphical models”]\n    A --> D[”关键结果/Results<br>RLVR泛化更强，但依赖模型规模与初始能力<br>RLVR yields stronger generalization but depends on model size & initial competence”]"
    },
    {
      "title": "Adversarial Training for Failure-Sensitive User Simulation in Mental Health Dialogue Optimization",
      "authors": "Ziyi Zhu, Olivier Tieleman, Caitlin A. Stamatis, Luka Smyth, Thomas D. Hull, Daniel R. Cahn, Matteo Malgaroli",
      "institution": "Slingshot AI, NYU School of Medicine",
      "link": "https://arxiv.org/pdf/2512.20773",
      "code": null,
      "tags": [
        "dialogue systems",
        "adversarial training",
        "user simulation",
        "task-oriented dialogue",
        "mental health chatbots",
        "direct preference optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f72756c707df5d24dd551e3e95152618e1b00d48b0aae580dd4f6ebbf8dc335_w640_q70.webp",
      "contributions": "1. Proposes an adversarial training framework for improving user simulator realism in task-oriented dialogue systems. 2. Applies the framework to mental health support chatbots, demonstrating enhanced ability to surface system failure modes. 3. Shows that the fine-tuned and adversarially trained simulator achieves strong correlation between simulated and real failure rates while maintaining low distributional divergence.",
      "summary": "This paper addresses the challenge of creating realistic user simulators for evaluating task-oriented dialogue systems. It proposes an adversarial training framework where a user simulator (generator) is refined against a discriminator to improve realism, specifically applied to mental health chatbots. The results show this approach creates simulators that effectively expose system failures, enabling more reliable and cost-effective evaluation before deployment.",
      "mindmap": "graph LR\n        A[Adversarial Training for Failure-Sensitive User Simulation<br>对抗性训练用于故障敏感的用户模拟] --> B(Problem: Realistic user simulation is challenging<br>核心问题：真实的用户模拟具有挑战性)\n        A --> C(Method: Adversarial training framework<br>主要方法：对抗性训练框架)\n        A --> D(Results: Enhanced failure exposure & realism<br>关键结果：增强的故障暴露与真实性)"
    },
    {
      "title": "Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles",
      "authors": "Ramatu Oiza Abdulsalam, Segun Aroyehun",
      "institution": "African University of Science and Technology, University of Konstanz",
      "link": "https://arxiv.org/pdf/2512.20780",
      "code": null,
      "tags": [
        "educational technology / intelligent tutoring systems",
        "large language models",
        "pedagogical quality",
        "instructional strategies",
        "linguistic analysis",
        "math tutoring"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4c157f4475efaa64bb039e61eccf65a1facd8888dde9576734865854a42e878_w640_q70.webp",
      "contributions": "1. Conducted a controlled, turn-level comparison of tutoring responses between expert human tutors, novice human tutors, and multiple large language models (LLMs) in math remediation. 2. Identified systematic differences in instructional and linguistic profiles, finding that LLMs underuse restating/revoicing strategies but produce longer, more lexically diverse, and more polite responses compared to human tutors. 3. Established statistical associations between specific instructional/linguistic features (e.g., restating, lexical diversity) and perceived pedagogical quality, showing LLMs can achieve comparable quality using different strategies.",
      "summary": "This paper investigates how closely the instructional behavior of large language models (LLMs) aligns with expert human tutors in math tutoring. By comparing responses from experts, novices, and LLMs to the same conversation turns, the study analyzes instructional strategies and linguistic features. It finds that LLMs approach expert-level pedagogical quality on average but rely on systematically different strategies, such as underusing restating/revoicing while being more verbose and polite.",
      "mindmap": "graph LR\n    A[Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles] --> B(核心问题/Problem: LLM教学行为与人类专家的一致性/Alignment of LLM instructional behavior with expert human tutors)\n    A --> C(主要方法/Method: 控制性对话轮比较/Controlled turn-level comparison of expert, novice, and LLM responses)\n    A --> D(关键结果/Results: LLM接近专家教学水平但策略不同/LLMs approach expert quality but use different instructional & linguistic strategies)"
    },
    {
      "title": "Investigating Model Editing for Unlearning in Large Language Models",
      "authors": "Shariqah Hossain, Lalana Kagal",
      "institution": "Massachusetts Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20794",
      "code": null,
      "tags": [
        "machine unlearning",
        "model editing",
        "ROME",
        "IKE",
        "WISE",
        "TOFU benchmark"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/841879fe7d15bfc601ea216e8680f83f41000cc4f51b756525680ffd81869551_w640_q70.webp",
      "contributions": "1. Investigated the application of existing model editing algorithms (ROME, IKE, WISE) to the problem of machine unlearning in LLMs. 2. Designed new editing targets, including a novel \"Avoidant\" target, specifically formulated for the goal of information removal rather than alteration. 3. Demonstrated that model editing approaches can surpass traditional unlearning baselines in the quality of forgetting, while also highlighting the persistent trade-off between effective unlearning and preserving general model performance.",
      "summary": "This paper investigates using model editing techniques for machine unlearning in Large Language Models. It applies editing algorithms like ROME, IKE, and WISE with new \"unlearning\" targets and evaluates them on the TOFU benchmark. The results show that model editing can outperform baseline unlearning methods in some settings but still struggles to fully remove information without harming overall model performance.",
      "mindmap": "graph LR\n    A[Investigating Model Editing for Unlearning in LLMs] --> B(核心问题/Problem: Inefficient or damaging unlearning in LLMs)\n    A --> C(主要方法/Method: Apply model editing algorithms ROME/IKE/WISE with new unlearning targets)\n    A --> D(关键结果/Results: Can exceed baselines but trade-off with performance remains)"
    },
    {
      "title": "Measuring Mechanistic Independence: Can Bias Be Removed Without Erasing Demographics?",
      "authors": "Zhengyang Shan, Aaron Mueller",
      "institution": "Boston University",
      "link": "https://arxiv.org/pdf/2512.20796",
      "code": null,
      "tags": [
        "bias mitigation & interpretability",
        "sparse autoencoder",
        "feature ablation",
        "mechanistic interpretability",
        "demographic bias",
        "causal influence"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fb5fdb2f139d53a61fbac99afbf6f9d9a8061df4ee47ccc35f3e788fe619760_w640_q70.webp",
      "contributions": "1. Introduces a multi-task evaluation framework to measure the independence of demographic bias mechanisms from general demographic recognition in language models. 2. Compares attribution-based and correlation-based methods for locating bias features and demonstrates their differential effectiveness across bias dimensions (race/gender vs. education). 3. Shows that targeted sparse autoencoder feature ablations can enable surgical debiasing, reducing stereotypes without erasing legitimate demographic detection, indicating bias arises from task-specific mechanisms.",
      "summary": "This paper investigates whether demographic bias in language models can be removed without harming the model's ability to recognize demographics. The authors use a multi-task setup and compare attribution-based and correlation-based methods to locate bias features in a sparse autoencoder, performing targeted ablations on the Gemma-2-9B model. They find that such mechanistic interventions can reduce specific stereotypes (e.g., race/gender in professions) while preserving name recognition, but the effectiveness depends on the bias dimension, highlighting the need for task-specific debiasing strategies.",
      "mindmap": "graph LR\n    A[Measuring Mechanistic Independence<br/>机制独立性测量] --> B(核心问题/Problem: Can bias be removed without erasing demographics?<br/>能否去除偏见而不消除人口统计信息识别能力？)\n    A --> C(主要方法/Method: Multi-task evaluation & Sparse Autoencoder feature ablation<br/>多任务评估与稀疏自编码器特征消融)\n    A --> D(关键结果/Results: Attribution ablation works for race/gender; Correlation ablation works for education<br/>归因消融对种族/性别有效；相关消融对教育偏见有效)"
    },
    {
      "title": "Semantic Deception: When Reasoning Models Can't Compute an Addition",
      "authors": "Nathaniël de Leeuw, Marceau Nahon, Mathis Reymond, Raja Chatila, Mehdi Khamassi",
      "institution": "Institute of Intelligent Systems and Robotics (CNRS, Sorbonne University), Paris Cité University",
      "link": "https://arxiv.org/pdf/2512.20812",
      "code": null,
      "tags": [
        "large language model evaluation",
        "semantic deception",
        "symbolic reasoning",
        "abstraction",
        "chain-of-thought",
        "evaluation framework"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/51eafa5ff63a45ff90df02eb9c82e60fc34432de99dc2dca39fb261430db4031_w640_q70.webp",
      "contributions": "1. Introduces the concept of \"semantic deceptions\" as a novel experimental framework to test LLMs' symbolic abstraction capabilities. 2. Demonstrates that misleading semantic cues can significantly degrade the performance of reasoning models on simple arithmetic tasks. 3. Reveals a critical limitation in LLMs' ability to perform robust symbolic manipulation, highlighting their over-reliance on surface-level semantics and statistical correlations.",
      "summary": "The paper investigates the symbolic reasoning capabilities of large language models by introducing \"semantic deceptions,\" where digits and operators are replaced with novel symbols carrying misleading associations. Experiments show that these semantic cues severely impair model performance on simple calculations, revealing a fundamental weakness in abstraction and a tendency to rely on learned correlations rather than true symbolic logic.",
      "mindmap": "graph LR\n        A[Semantic Deception: When Reasoning Models Can’t Compute an Addition] --> B[核心问题/Problem: LLMs' symbolic reasoning and abstraction capabilities under misleading semantic cues]\n        A --> C[主要方法/Method: Introduce semantic deceptions by redefining digits/operators with novel symbols]\n        A --> D[关键结果/Results: Semantic cues deteriorate performance, revealing over-reliance on surface semantics and limitations in symbolic manipulation]"
    },
    {
      "title": "EssayCBM: Rubric-Aligned Concept Bottleneck Models for Transparent Essay Grading",
      "authors": "Kumar Satvik Chaudhary, Chengshuai Zhao, Fan Zhang, Yung Hin Tse, Garima Agrawal, Yuli Deng, Huan Liu",
      "institution": "Arizona State University",
      "link": "https://arxiv.org/pdf/2512.20817",
      "code": "https://github.com/scott-f-zhang/CBM-Demo",
      "tags": [
        "automated essay scoring",
        "Concept Bottleneck Models",
        "Explainable AI",
        "Human-in-the-loop",
        "Rubric-Aligned",
        "Interpretability"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b05be6579e2ddbef36e15a910aaffe552adbb13cce68a7840f6e46806eb13aa0_w640_q70.webp",
      "contributions": "1. Proposes EssayCBM, a rubric-aligned framework that uses dedicated prediction heads to evaluate specific writing concepts (e.g., Thesis Clarity, Evidence Use) instead of predicting grades directly from text. 2. Introduces a transparent bottleneck where a lightweight network computes the final grade using only the concept scores, enabling interpretability and human-in-the-loop adjustments. 3. Demonstrates that the system matches black-box performance while providing actionable, concept-level feedback through an intuitive web interface.",
      "summary": "The paper addresses the lack of transparency in automated essay grading systems by introducing EssayCBM, a framework that first predicts scores for specific writing concepts aligned with a rubric and then uses these scores to compute a final grade. This approach provides interpretable, concept-level feedback and allows instructors to adjust predictions in a human-in-the-loop manner. The proposed method achieves performance comparable to black-box models while offering greater accountability and actionable insights for educators and students.",
      "mindmap": "graph LR\n        A[EssayCBM: Rubric-Aligned Concept Bottleneck Models] --> B[核心问题/Problem: 自动评分系统缺乏透明度/Black-box grading lacks transparency]\n        A --> C[主要方法/Method: 基于概念瓶颈和规则对齐的评估/Rubric-aligned concept bottleneck evaluation]\n        A --> D[关键结果/Results: 性能匹配黑盒并提供可解释反馈/Matches performance & provides interpretable feedback]"
    },
    {
      "title": "MediEval: A Unified Medical Benchmark for Patient-Contextual and Knowledge-Grounded Reasoning in LLMs",
      "authors": "Zhan Qu, Michael Färber",
      "institution": "TU Dresden, ScaDS.AI",
      "link": "https://arxiv.org/pdf/2512.20822",
      "code": null,
      "tags": [
        "medical nlp / llm evaluation",
        "medical benchmark",
        "electronic health records (EHR)",
        "knowledge grounding",
        "counterfactual reasoning",
        "DPO fine-tuning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/59c4d88b1ecf7256d86a2c1dd12f74897d1a42b0c88d272ea8cf058355f013cd_w640_q70.webp",
      "contributions": "1. Introduces MediEval, a unified benchmark linking real EHRs (MIMIC-IV) to a biomedical knowledge base for evaluating LLMs on patient-contextual and knowledge-grounded reasoning. 2. Proposes a 4-quadrant evaluation framework to systematically assess models on both factual correctness and contextual consistency, identifying critical failure modes like hallucinated support and truth inversion. 3. Proposes Counterfactual Risk-Aware Fine-tuning (CoRFu), a DPO-based method with an asymmetric penalty, which significantly improves model accuracy and safety by eliminating truth inversion errors.",
      "summary": "The paper identifies a gap in evaluating LLMs for medical applications, where existing benchmarks either test isolated knowledge or patient reasoning without verifying correctness. To address this, the authors introduce the MediEval benchmark and a 4-quadrant evaluation framework to systematically assess LLMs, and propose a novel fine-tuning method called CoRFu. The results show that CoRFu significantly improves model performance and safety by eliminating dangerous error types like truth inversion.",
      "mindmap": "graph LR\n        A[MediEval] --> B[核心问题/Problem: LLMs in medicine lack reliable evaluation combining knowledge and patient context];\n        A --> C[主要方法/Method: Unified benchmark (EHR + KB) & 4-quadrant framework & CoRFu fine-tuning];\n        A --> D[关键结果/Results: Identifies failure modes; CoRFu improves accuracy and safety];"
    },
    {
      "title": "How important is Recall for Measuring Retrieval Quality?",
      "authors": "Shelly Schwartz, Oleg Vasilyev, Randy Sawaya",
      "institution": "Primer Technologies Inc.",
      "link": "https://arxiv.org/pdf/2512.20854",
      "code": null,
      "tags": [
        "rag (retrieval-augmented generation)",
        "retrieval quality",
        "recall estimation",
        "LLM-based evaluation",
        "nDCG",
        "RAG"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8385a132c621f6e8d9e71274fc95535412aa2b9f0d0f40e834705d3548f0a601_w640_q70.webp",
      "contributions": "1. Evaluates established strategies for measuring retrieval quality when the total number of relevant documents (and thus recall) is unknown, by correlating metrics with LLM-based judgments of response quality. 2. Conducts experiments across multiple datasets with a low number of relevant documents (2-15) to assess these strategies. 3. Introduces a new, simple retrieval quality measure that performs well without requiring knowledge of the total number of relevant documents.",
      "summary": "The paper addresses the problem of evaluating retrieval quality in realistic settings where the total number of relevant documents is unknown, making recall uncomputable. It evaluates existing strategies and proposes a new simple metric by measuring their correlation with LLM-generated response quality. The main conclusion is that a simple measure can perform effectively without needing to know the total relevant documents, offering a practical solution for dynamic knowledge bases.",
      "mindmap": "graph LR\n    A[How important is Recall for Measuring Retrieval Quality?] --> B[核心问题/Problem: Realistic retrieval with unknown total relevant docs]\n    A --> C[主要方法/Method: Correlate metrics with LLM response quality; propose new measure]\n    A --> D[关键结果/Results: Simple measure works well without recall]"
    },
    {
      "title": "Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Faisal Ladhak, Fay Wang, Fei Jia, Felipe Soares, Feng Chen, Ferenc Galko, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20848",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "agentic reasoning",
        "sparse activation",
        "long context"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96a4b5c012acd8208519dcb9669276bd8c3c3709f26e7290e2fce500151c1ccc_w640_q70.webp",
      "contributions": "1. Introduces Nemotron 3 Nano, a hybrid MoE Mamba-Transformer model that sparsely activates only 3.2B out of 31.6B parameters per forward pass for efficiency. 2. Demonstrates superior inference throughput (up to 3.3x faster) compared to similarly-sized open models while maintaining or improving accuracy on benchmarks. 3. Supports an extended context length of up to 1 million tokens and shows enhanced agentic and reasoning capabilities through post-training.",
      "summary": "This paper presents Nemotron 3 Nano, an efficient 30B-parameter language model that combines Mixture-of-Experts with a Mamba-Transformer architecture to achieve sparse activation. It was pre-trained on 25 trillion tokens and post-trained for agentic reasoning, resulting in higher inference throughput and accuracy compared to similar models while supporting up to 1M token contexts.",
      "mindmap": "graph LR\n    A[Nemotron 3 Nano<br>论文标题/Paper Title] --> B[构建高效、能进行智能体推理的大模型<br>核心问题/Problem];\n    A --> C[混合MoE与Mamba-Transformer架构，稀疏激活参数<br>主要方法/Method];\n    A --> D[更高推理吞吐与精度，支持100万令牌上下文<br>关键结果/Results];"
    },
    {
      "title": "NVIDIA Nemotron 3: Efficient and Open Intelligence",
      "authors": "NVIDIA, Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Anjulie Agrusa, Ankur Verma, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asit Mishra, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Cyril Meurillon, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Lo, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elad Segal, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Evgeny Tsykunov, Faisal Ladhak, Fay Wang, Fei Jia",
      "institution": "NVIDIA",
      "link": "https://arxiv.org/pdf/2512.20856",
      "code": null,
      "tags": [
        "llm inference",
        "Mixture-of-Experts",
        "Mamba-Transformer",
        "LatentMoE",
        "NVFP4",
        "multi-environment reinforcement learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b5203ecd520d6e99bc9f0034f05e8945272d4a34a746eeeae01be1cc728049b5_w640_q70.webp",
      "contributions": "1. Introduces the Nemotron 3 family of models (Nano, Super, Ultra) built on a Mixture-of-Experts hybrid Mamba-Transformer architecture for high throughput and long context (up to 1M tokens). 2. Proposes novel techniques including LatentMoE for improved model quality and MTP layers for faster text generation in the larger models. 3. Employs multi-environment reinforcement learning for post-training, enabling advanced capabilities like reasoning, multi-step tool use, and granular reasoning budget control.",
      "summary": "This paper introduces the Nemotron 3 family of open models designed for efficient and intelligent agentic applications. The models use a novel hybrid Mamba-Transformer architecture and are trained with techniques like LatentMoE and multi-environment RL to achieve strong reasoning, conversational, and tool-use capabilities with high throughput. The conclusion is that these models provide state-of-the-art accuracy and efficiency, with plans for open release of weights, software, and data.",
      "mindmap": "graph LR\n    A[NVIDIA Nemotron 3] --> B[核心问题/Problem: Efficient and open intelligence for agentic applications]\n    A --> C[主要方法/Method: Mixture-of-Experts hybrid Mamba-Transformer, LatentMoE, multi-environment RL]\n    A --> D[关键结果/Results: High throughput, 1M context, strong agentic/reasoning capabilities, open release]"
    },
    {
      "title": "Architectural Trade-offs in Small Language Models Under Compute Constraints",
      "authors": "Shivraj Singh Bhatti",
      "institution": "University of Massachusetts Amherst",
      "link": "https://arxiv.org/pdf/2512.20877",
      "code": null,
      "tags": [
        "language modeling",
        "small language models",
        "compute constraints",
        "architectural trade-offs",
        "rotary positional embeddings",
        "transformer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a2b54dee144c67bdb877818e8171163f9556734c09b3a1d7d29fe8464aee558b_w640_q70.webp",
      "contributions": "1. A systematic empirical study of architectural choices (from linear predictors to transformers) for small language models under strict compute constraints. 2. An analysis showing attention-based models are more FLOP-efficient than MLPs even at small scale, and that increasing depth/context without sufficient optimization can hurt performance. 3. An investigation revealing that techniques like Rotary Positional Embeddings (RoPE), successful in large models, do not necessarily transfer effectively to the small-model regime.",
      "summary": "This paper systematically studies how architectural choices affect small language model performance under limited compute. The method involves progressively building from linear predictors to multi-layer transformers and evaluating them on character and word-level datasets. The main conclusion is that attention is more efficient than MLPs per FLOP at small scales, but scaling depth or applying large-model techniques like RoPE can be detrimental without careful optimization.",
      "mindmap": "graph LR\n    A[Architectural Trade-offs in Small Language Models<br>小型语言模型的架构权衡] --> B[核心问题/Problem<br>How do architectural choices affect performance under compute constraints?<br>计算约束下架构选择如何影响性能？]\n    A --> C[主要方法/Method<br>Progressive architectural study from linear to transformer models<br>从线性到Transformer模型的渐进式架构研究]\n    A --> D[关键结果/Results<br>Attention > MLPs in per-FLOP efficiency; RoPE may not transfer<br>注意力机制单位FLOP效率优于MLP；RoPE可能不适用于小模型]"
    },
    {
      "title": "Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation",
      "authors": "Kaiyuan Liu, Shaotian Yan, Rui Miao, Bing Wang, Chen Shen, Jun Zhang, Jieping Ye",
      "institution": "Zhejiang University, Alibaba Cloud Computing, Jilin University, University of Michigan",
      "link": "https://arxiv.org/pdf/2512.20908",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "reasoning distillation",
        "provenance tracing",
        "teacher-guided data selection",
        "model generalization",
        "knowledge transfer"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d19fc56be8917fa897a8772f9f0c999250e917eda937c0e1b5176333830faf5_w640_q70.webp",
      "contributions": "1. Introduces a cross-model Reasoning Distillation Provenance Tracing framework to classify the origin of a distilled model's outputs into four categories. 2. Empirically demonstrates that teacher-originated actions in the distilled model correlate with its performance, providing an explanatory analysis for distillation. 3. Proposes a principled, teacher-guided data selection method based on teacher-student divergence, validated across multiple models.",
      "summary": "This paper addresses the lack of analysis on the origins of capabilities in reasoning-distilled models by introducing a provenance tracing framework. The method classifies model outputs by comparing probabilities from teacher, student, and distilled models, showing that teacher-originated actions explain performance. Based on this, a teacher-guided data selection method is proposed and validated to improve distillation.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Where Did This Sentence Come From?] --> B{核心问题 / Problem};\n    A --> C{主要方法 / Method};\n    A --> D{关键结果 / Results};\n    B --> B1[蒸馏模型能力来源不明 / Unclear provenance of distilled model capabilities];\n    B --> B2[泛化能力存疑 / Concerns about generalization];\n    C --> C1[溯源框架 / Provenance Tracing Framework];\n    C --> C2[概率比较分类 / Classify by comparing probabilities];\n    C --> C3[教师引导数据选择 / Teacher-guided data selection];\n    D --> D1[教师行为可被继承 / Teacher-originated actions are generated];\n    D --> D2[行为与性能相关 / Actions correlate with performance];\n    D --> D3[新方法有效 / New selection method is effective];"
    },
    {
      "title": "Transductive Visual Programming: Evolving Tool Libraries from Experience for Spatial Reasoning",
      "authors": "Shengguang Wu, Xiaohan Wang, Yuhui Zhang, Hao Zhu, Serena Yeung-Levy",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.20934",
      "code": "https://transductive-visualprogram.github.io/",
      "tags": [
        "visual reasoning",
        "visual programming",
        "spatial reasoning",
        "tool induction",
        "transductive learning",
        "3D scene understanding"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6374488a70a5d9147002f5652452c2f63ea3698c6660c54123c36fc9deef3991_w640_q70.webp",
      "contributions": "1. Proposes Transductive Visual Programming (TVP), a novel framework that builds new tools from experiential solutions rather than speculative induction., 2. Introduces a closed-loop system with an evolving Tool Library and an Example Library, enabling self-improvement through experience., 3. Demonstrates state-of-the-art performance on spatial reasoning benchmarks and shows that transductively learned tools are used more frequently and generalize better.",
      "summary": "The paper addresses the challenge of spatial reasoning in 3D scenes by proposing Transductive Visual Programming (TVP), a framework that learns reusable higher-level tools by abstracting patterns from its own successful solutions. This experience-driven approach outperforms existing methods and GPT-4o on benchmarks, showing more effective tool discovery and strong generalization to unseen tasks.",
      "mindmap": "graph LR\n        A[Transductive Visual Programming] --> B[核心问题/Problem<br>Spatial reasoning is challenging for VLMs]\n        A --> C[主要方法/Method<br>Build tools from experience, not speculation]\n        A --> D[关键结果/Results<br>SOTA performance, better tool reuse & generalization]"
    },
    {
      "title": "Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study",
      "authors": "Zhongren Dong, Haotian Guo, Weixiang Xu, Huan Zhao, Zixing Zhang",
      "institution": "Hunan University",
      "link": "https://arxiv.org/pdf/2512.20948",
      "code": null,
      "tags": [
        "multi-modal learning",
        "foundation models",
        "multi-modal fusion",
        "cross-corpus evaluation",
        "neuropsychiatric disorders",
        "multi-lingual datasets"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18e74bbfe865915192b7a6c5c53058f33d0688ed82ef83023913d356622a3899_w640_q70.webp",
      "contributions": "1. Proposed FEND, a comprehensive multi-modal framework using foundation models for evaluating neuropsychiatric disorders across the lifespan. 2. Conducted a systematic evaluation using 13 multi-lingual datasets, identifying strengths and limitations of multi-modal fusion for different disorders. 3. Provided extensive benchmarks and analysis of performance-influencing factors (e.g., modality imbalance, dataset heterogeneity) to advance reproducible research in the field.",
      "summary": "The paper proposes FEND, a foundation model-based multi-modal framework for detecting neuropsychiatric disorders like Alzheimer's, depression, and autism from speech and text. It evaluates the framework on 13 multi-lingual datasets, finding that multi-modal fusion works well for Alzheimer's and depression but underperforms for autism due to dataset heterogeneity, and identifies modality imbalance as a key challenge.",
      "mindmap": "graph LR\n    A[Foundation Model-based Evaluation of Neuropsychiatric Disorders] --> B(核心问题/Problem: Multi-lingual generalization & lack of unified framework)\n    A --> C(主要方法/Method: FEND multi-modal framework using speech & text)\n    A --> D(关键结果/Results: Multi-modal fusion excels for AD/depression, underperforms for ASD)"
    },
    {
      "title": "Neural Probe-Based Hallucination Detection for Large Language Models",
      "authors": "Shize Liang, Hongzhi Wang",
      "institution": "Harbin Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20949",
      "code": null,
      "tags": [
        "hallucination detection",
        "MLP probes",
        "token-level detection",
        "Bayesian optimization",
        "hidden states",
        "multi-objective loss"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/256e2b7c6550072fc0e643c4045a4a592ba6b2241cd12656b7dd16ad27bf89b0_w640_q70.webp",
      "contributions": "1. Proposed a neural network-based framework using lightweight MLP probes for token-level hallucination detection, enabling nonlinear modeling of hidden states. 2. Designed a multi-objective joint loss function to improve detection stability and semantic disambiguation. 3. Established a layer position-probe performance response model and used Bayesian optimization to automatically search for optimal probe insertion layers.",
      "summary": "This paper addresses the problem of hallucination in large language models by proposing a real-time, token-level detection method. The method uses lightweight MLP probes on frozen model hidden states and a Bayesian-optimized layer search. Experiments show it outperforms existing methods in accuracy and recall under low false-positive conditions.",
      "mindmap": "graph LR\n    A[Neural Probe-Based Hallucination Detection for Large Language Models] --> B(核心问题/Problem: LLMs生成幻觉内容/LLMs generate hallucinations)\n    A --> C(主要方法/Method: MLP探针 & 贝叶斯优化/MLP probes & Bayesian optimization)\n    A --> D(关键结果/Results: 在多个数据集上表现优异/Outperforms SOTA on multiple datasets)"
    },
    {
      "title": "MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment",
      "authors": "Mohammad Mahdi Abootorabi, Alireza Ghahramani Kure, Mohammadali Mohammadkhani, Sina Elahimanesh, Mohammad Ali Ali Panah",
      "institution": "Based on the provided email domains (gmail.com), no specific institution can be reliably inferred. The team name is \"MultiMind\".",
      "link": "https://arxiv.org/pdf/2512.20950",
      "code": null,
      "tags": [
        "crosslingual information retrieval",
        "dual-encoder",
        "contrastive learning",
        "hard negative sampling",
        "data augmentation",
        "multi-source alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ccb6e1762a9617f640573a86ea65e0e68afff48d53006aa74213e0a557970889_w640_q70.webp",
      "contributions": "1. Introduces TriAligner, a novel dual-encoder architecture with contrastive learning for crosslingual claim retrieval. 2. Proposes a method to learn the relative importance of different information sources (e.g., native text, English translations) for alignment. 3. Enhances robustness through LLM-based data preprocessing/augmentation and hard negative sampling strategies.",
      "summary": "This paper addresses the challenge of retrieving fact-checked claims across multiple languages to combat misinformation. The proposed TriAligner system uses a dual-encoder with contrastive learning and multi-source alignment, enhanced by LLM-based data processing. The method shows significant improvements in retrieval accuracy on monolingual and crosslingual benchmarks.",
      "mindmap": "graph LR\n        A[MultiMind at SemEval-2025 Task 7<br>Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment] --> B(核心问题/Problem: Rapid spread of multilingual misinformation);\n        A --> C(主要方法/Method: TriAligner - dual-encoder with contrastive learning & multi-source alignment);\n        A --> D(关键结果/Results: Improved retrieval accuracy on benchmarks);"
    },
    {
      "title": "Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models",
      "authors": "Xiang Zhang, Jiaqi Wei, Yuejin Yang, Zijie Qiu, Yuhan Chen, Zhiqiang Gao, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan, Wanli Ouyang, Chenyu You, Siqi Sun",
      "institution": "Fudan University, Shanghai Artificial Intelligence Laboratory, University of British Columbia, Zhejiang University, The Chinese University of Hong Kong, Stony Brook University",
      "link": "https://arxiv.org/pdf/2512.20954",
      "code": null,
      "tags": [
        "protein language models",
        "reflection pretraining",
        "chain-of-thought",
        "language expressiveness",
        "self-correction",
        "biological sequences"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c51a6a0ca0e6bf5774254f47e4581544610c262b22a0cc12fe84b840bda40a_w640_q70.webp",
      "contributions": "1. Proposed and defined the concept of \"language expressiveness\" to explain the difficulty of applying Chain-of-Thought reasoning to biological sequence models. 2. Introduced reflection pretraining for biological sequence models, enabling intermediate reasoning through auxiliary \"thinking tokens\". 3. Demonstrated that this approach enables self-correction, improves performance, and offers benefits like counter-memorization and enhanced human steerability.",
      "summary": "This paper addresses the challenge of applying Chain-of-Thought reasoning to biological sequence models like protein language models, which have limited token expressiveness. The authors propose reflection pretraining, which augments the model with auxiliary \"thinking tokens\" to enable intermediate reasoning and self-correction. The method theoretically enhances language expressiveness and experimentally leads to substantial performance gains compared to standard pretraining.",
      "mindmap": "graph LR\n    A[Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models] --> B(核心问题/Problem: Limited expressiveness of protein language restricts CoT reasoning)\n    A --> C(主要方法/Method: Reflection pretraining with auxiliary ”thinking tokens”)\n    A --> D(关键结果/Results: Enhanced expressiveness, self-correction, performance gains)"
    },
    {
      "title": "Automatic Replication of LLM Mistakes in Medical Conversations",
      "authors": "Oleksii Proniakin, Diego Fajardo, Ruslan Nazarenko, Razvan Marinescu",
      "institution": "Lumos AI",
      "link": "https://arxiv.org/pdf/2512.20983",
      "code": null,
      "tags": [
        "llm evaluation",
        "medical conversation",
        "mistake replication",
        "benchmark creation",
        "llm judges",
        "single-shot qa"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7799ccba99ce08a1cee1bd87ba7b9e986a373df0f78a25479ad9fec7478ca0e9_w640_q70.webp",
      "contributions": "1. Introduces MedMistake, an automatic pipeline for extracting and replicating LLM mistakes from complex medical conversations into a benchmark format. 2. Releases MedMistake-All, a dataset of 3,390 single-shot QA pairs derived from identified mistakes, and a validated subset, MedMistake-Bench. 3. Provides a comprehensive evaluation of 12 frontier LLMs using the validated benchmark, revealing performance trends among top models.",
      "summary": "The paper addresses the difficulty of replicating specific mistakes made by LLMs in clinical conversations. It proposes MedMistake, an automated pipeline that generates conversational data, uses LLM judges to identify errors, and distills them into single-shot QA pairs to create a benchmark. The resulting benchmark was used to evaluate 12 LLMs, finding that GPT, Claude, and Grok models performed best.",
      "mindmap": "graph LR\n    A[Automatic Replication of LLM Mistakes in Medical Conversations] --> B(核心问题/Problem: LLM错误难以在其他模型中复现/Mistakes hard to replicate across LLMs)\n    A --> C(主要方法/Method: MedMistake自动管道/MedMistake automatic pipeline)\n    A --> D(关键结果/Results: 发布基准并评估12个LLM/Released benchmark & evaluated 12 LLMs)\n    C --> C1(生成对话/Generate conversations)\n    C --> C2(LLM委员会评估/LLM committee evaluation)\n    C --> C3(创建单轮QA对/Create single-shot QA pairs)\n    D --> D1(MedMistake-All数据集/MedMistake-All dataset)\n    D --> D2(MedMistake-Bench验证子集/MedMistake-Bench validated subset)\n    D --> D3(GPT/Claude/Grok表现最佳/GPT/Claude/Grok performed best)"
    },
    {
      "title": "Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation",
      "authors": "Wei-Rui Chen, Vignesh Kothapalli, Ata Fatahibaarzi, Hejian Sang, Shao Tang, Qingquan Song, Zhipeng Wang, Muhammad Abdul-Mageed",
      "institution": "The University of British Columbia, LinkedIn",
      "link": "https://arxiv.org/pdf/2512.21002",
      "code": "https://github.com/weiruichen01/distilling-the-essence",
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "sequence truncation",
        "training efficiency",
        "reasoning models"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a99e2da19bbc9bacf5104e37b4afd860b26a5285dd752f9a6e025702d930839_w640_q70.webp",
      "contributions": "1. Analysis of supervision allocation in reasoning distillation, showing the CoT segment is the dominant factor for transferring reasoning capability. 2. Establishment of a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. 3. Empirical demonstration that training on only the first 50% of tokens retains ~94% of performance while halving computational costs.",
      "summary": "This paper addresses the computational expense of distilling reasoning capabilities from large to small models over long sequences. It proposes a method of selective distillation and sequence truncation, focusing on early reasoning tokens. The key finding is that training on just the first half of tokens can preserve most performance while significantly reducing training time, memory, and FLOPs.",
      "mindmap": "graph LR\n        A[Distilling the Essence<br>高效推理蒸馏] --> B{核心问题/Problem};\n        A --> C{主要方法/Method};\n        A --> D{关键结果/Results};\n        B --> B1[长序列推理蒸馏计算昂贵<br>Long-Sequence Reasoning Distillation is Expensive];\n        C --> C1[选择性监督与序列截断<br>Selective Supervision & Sequence Truncation];\n        D --> D1[保留94%性能，减少50%成本<br>Retain 94% Performance, Reduce 50% Cost];"
    },
    {
      "title": "Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy",
      "authors": "Xiaofeng Shi, Qian Kou, Yuduo Li, Hua Zhou",
      "institution": "Beijing Academy of Artificial Intelligence (BAAI), Beijing Jiaotong University (BJTU)",
      "link": "https://arxiv.org/pdf/2512.21017",
      "code": null,
      "tags": [
        "post-training (sft/rlhf)",
        "Supervised Fine-Tuning",
        "Chain-of-Thought",
        "Two-Stage Training",
        "Attention Imbalance",
        "Key Answer Tokens"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7eab786d7e6ac187d45153b771fdc458d7c8434c0e133a9bcdb70a2afa441a73_w640_q70.webp",
      "contributions": "1. Identifies a key limitation in conventional SFT where models over-attend to lengthy Chain-of-Thought reasoning sequences at the expense of the shorter, critical final answer tokens. 2. Proposes SFTKey, a novel two-stage fine-tuning scheme that first applies conventional SFT for format learning, then fine-tunes only on the Key (final answer) portion to boost accuracy. 3. Demonstrates through extensive experiments that SFTKey achieves an average accuracy improvement of over 5% compared to standard SFT while maintaining correct output formatting.",
      "summary": "The paper identifies that standard Supervised Fine-Tuning (SFT) for LLMs can cause an attention imbalance, where models focus too much on long reasoning chains (CoT) and not enough on the final answer. To solve this, the authors propose SFTKey, a two-stage method that first does standard SFT for formatting, then fine-tunes only on the key answer tokens. Experiments show this approach improves average accuracy by over 5% without harming output format correctness.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Rethinking Supervised Fine-Tuning] --> B[核心问题 / Problem<br>注意力失衡于长推理链 / Attention Imbalance on Long CoT]\n    A --> C[主要方法 / Method<br>两阶段训练 SFTKey / Two-Stage Training SFTKey]\n    A --> D[关键结果 / Results<br>准确率提升>5% / Accuracy Improvement >5%]"
    },
    {
      "title": "Semi-Supervised Learning for Large Language Models Safety and Content Moderation",
      "authors": "Eduard Stefan Dinuta, Iustin Sirbu, Traian Rebedea",
      "institution": "National University of Science and Technology Politehnica Bucharest, Renius Technologies, NVIDIA",
      "link": "https://arxiv.org/pdf/2512.21107",
      "code": null,
      "tags": [
        "content moderation",
        "semi-supervised learning",
        "data augmentation",
        "safety classifiers",
        "LLM safety",
        "prompt harmfulness"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/035c08c88d89969ce37594942a40aa577a3c0c7c7743cd71bdf84366a9dfa5f2_w640_q70.webp",
      "contributions": "1. Analysis of state-of-the-art semi-supervised learning algorithms for LLM safety, focusing on both prompt and response harmfulness. 2. Introduction of a new, task-specific augmentation technique for safety tasks. 3. Demonstration that task-specific augmentations significantly outperform general-purpose methods like backtranslation.",
      "summary": "This paper addresses the challenge of acquiring high-quality labeled data for training safety classifiers for Large Language Models. It proposes using semi-supervised learning techniques that leverage both labeled and unlabeled data, and introduces a task-specific data augmentation method. The key finding is that this approach, particularly with custom augmentations, significantly improves performance on safety tasks compared to using general-purpose techniques.",
      "mindmap": "graph LR\n    A[论文标题 / Paper Title<br>Semi-Supervised Learning for LLM Safety] --> B[核心问题 / Problem<br>依赖大量标注数据 / Reliance on large labeled data]\n    A --> C[主要方法 / Method<br>半监督学习与任务特定增强 / SSL & Task-Specific Augmentation]\n    A --> D[关键结果 / Results<br>性能显著提升 / Significant Performance Improvement]"
    },
    {
      "title": "Semantic Refinement with LLMs for Graph Representations",
      "authors": "Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang",
      "institution": "University of Connecticut, University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21106",
      "code": null,
      "tags": [
        "graph representation learning",
        "graph neural network",
        "large language model",
        "semantic refinement",
        "structure-semantics heterogeneity",
        "data-centric adaptation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dfae73c72759ca834d898f3c6ca5f0824bada06285918fca678e0f809fce9afd_w640_q70.webp",
      "contributions": "1. Proposes a data-centric perspective to address structure-semantics heterogeneity in graphs by treating node semantics as a task-adaptive variable, shifting focus from model-centric inductive bias injection. 2. Introduces the Data-Adaptive Semantic Refinement (DAS) framework, which couples a fixed GNN and an LLM in a closed feedback loop for iterative semantic refinement and graph learning. 3. Demonstrates the framework's effectiveness on diverse graphs, showing consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs.",
      "summary": "This paper addresses the challenge of structure-semantics heterogeneity in graph data, where predictive signals vary across domains. It proposes a Data-Adaptive Semantic Refinement (DAS) framework that uses a closed feedback loop between a GNN and an LLM to iteratively refine node semantics for the learning task. The method shows strong performance on structure-dominated graphs and remains competitive on semantics-rich graphs, validating the data-centric adaptation approach.",
      "mindmap": "graph LR\n    A[Semantic Refinement with LLMs for Graph Representations] --> B(核心问题/Problem: Graph structure-semantics heterogeneity 图的结构-语义异质性)\n    A --> C(主要方法/Method: Data-Adaptive Semantic Refinement (DAS) framework 数据自适应语义精炼框架)\n    A --> D(关键结果/Results: Improves structure-dominated graphs, competitive on semantics-rich graphs 提升结构主导图性能，在语义丰富图上保持竞争力)"
    },
    {
      "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
      "authors": "Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.21110",
      "code": null,
      "tags": [
        "ai safety",
        "intent recognition",
        "contextual understanding",
        "safety circumvention",
        "prompt engineering",
        "transformer architectures"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/55c1a596dd6375317c809bb19f466455285faf18a1f9810649d755b8027e383c_w640_q70.webp",
      "contributions": "1. Identifies and empirically demonstrates a critical vulnerability in LLMs: their inability to understand user intent and context, which allows safety mechanisms to be circumvented. 2. Evaluates multiple state-of-the-art LLMs (ChatGPT, Claude, Gemini, DeepSeek) and shows that exploitation techniques like emotional framing and progressive revelation are effective, and that reasoning capabilities can amplify this risk. 3. Proposes a paradigmatic shift in AI safety design, arguing for contextual understanding and intent recognition to be core capabilities rather than post-hoc protective mechanisms.",
      "summary": "This paper identifies a fundamental vulnerability in Large Language Models (LLMs): their lack of contextual understanding and intent recognition, which allows safety mechanisms to be systematically bypassed. The authors empirically evaluate several LLMs, showing they can be exploited through techniques like emotional framing, and find that reasoning capabilities often worsen the problem. They conclude that a paradigm shift is needed to build intent recognition directly into LLM architectures for safety.",
      "mindmap": "graph LR\n    A[Beyond Context: Large Language Models Failure to Grasp Users Intent] --> B[核心问题/Problem: LLMs缺乏上下文和意图理解能力/LLMs lack contextual understanding & intent recognition]\n    A --> C[主要方法/Method: 对多种LLM进行经验性评估/Empirical evaluation of multiple LLMs]\n    A --> D[关键结果/Results: 安全机制可被系统规避，需范式转变/Safety mechanisms can be systematically circumvented, requiring a paradigm shift]\n    B --> E[导致可利用的漏洞/Creates exploitable vulnerabilities]\n    C --> F[使用情感框架、渐进揭示等技术/Using emotional framing, progressive revelation, etc.]\n    D --> G[Claude Opus 4.1部分例外，推理能力加剧风险/Claude Opus 4.1 partial exception, reasoning amplifies risk]"
    },
    {
      "title": "ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models",
      "authors": "Sichun Luo, Yi Huang, Mukai Li, Shichang Meng, Fengyuan Liu, Zefa Hu, Junlan Feng, Qi Liu",
      "institution": "The University of Hong Kong, JIUTIAN Research (China Mobile), City University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.21120",
      "code": null,
      "tags": [
        "conversational ai",
        "multi-turn clarification",
        "ambiguity taxonomy",
        "agentic approach"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0c251a364522d772d4c0ccb3f8108c9a5bafb4d76316e5783c96374fcd1c4488_w640_q70.webp",
      "contributions": "1. Introduces ClarifyMT-Bench, a novel benchmark for multi-turn clarification featuring a five-dimensional ambiguity taxonomy and diverse simulated user personas. 2. Uncovers a consistent \"under-clarification bias\" in LLMs, where they answer prematurely and performance degrades with dialogue depth. 3. Proposes ClarifyAgent, an agentic framework that decomposes clarification into perception, forecasting, tracking, and planning to improve robustness.",
      "summary": "The paper addresses the problem that LLMs tend to answer ambiguous user queries prematurely in multi-turn conversations. To study this, the authors introduce ClarifyMT-Bench, a multi-turn clarification benchmark, and propose ClarifyAgent, an agentic method that improves clarification robustness. The main finding is that current LLMs have an under-clarification bias, which the proposed agentic approach helps mitigate.",
      "mindmap": "graph LR\n    A[ClarifyMT-Bench] --> B[核心问题/Problem: LLMs under-clarify in multi-turn dialogues]\n    A --> C[主要方法/Method: Benchmark + ClarifyAgent]\n    C --> D[Benchmark: 多轮对话基准/Multi-turn Benchmark]\n    C --> E[Agent: 代理方法/Agentic Approach]\n    A --> F[关键结果/Results: Bias identified, Agent improves robustness]"
    },
    {
      "title": "SpidR-Adapt: A Universal Speech Representation Model for Few-Shot Adaptation",
      "authors": "Mahi Luthra, Jiayi Shen, Maxime Poli, Angelo Ortiz, Yosuke Higuchi, Youssef Benchekroun, Martin Gleize, Charles-Eric Saint-James, Dongyan Lin, Phillip Rust, Angel Villar, Surya Parimi, Vanessa Stark, Rashel Moritz, Juan Pino, Yann LeCun, Emmanuel Dupoux",
      "institution": "Meta AI, ENS-PSL, EHESS, CNRS",
      "link": "https://arxiv.org/pdf/2512.21204",
      "code": "https://github.com/facebookresearch/spidr-adapt",
      "tags": [
        "speech representation learning",
        "meta-learning",
        "bi-level optimization",
        "few-shot adaptation",
        "self-supervised learning",
        "speech representation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ff9692c36cbda26291fde2551256e229a90f6eb51f087d833a2d84cb4b10925b_w640_q70.webp",
      "contributions": "1. Introduces the Multi-task Adaptive Pre-training (MAdaPT) protocol, framing few-shot speech representation learning as a bi-level optimization meta-learning problem. 2. Proposes a novel First-Order Bi-Level Optimization (FOBLO) heuristic to enable scalable meta-training by avoiding heavy computation costs. 3. Stabilizes meta-training with a robust initialization technique using interleaved supervision that alternates between self-supervised and supervised objectives.",
      "summary": "This paper introduces SpidR-Adapt, a method for rapid adaptation of speech representation models to new languages using minimal unlabeled data. It formulates the problem as meta-learning with a bi-level optimization framework (MAdaPT), proposes an efficient solver (FOBLO), and uses interleaved supervision for stable training. The model achieves significant gains in phonemic discrimination and language modeling after training on less than 1 hour of target-language audio, demonstrating over 100x greater data efficiency than standard methods.",
      "mindmap": "graph LR\n        A[SpidR-Adapt] --> B[核心问题/Problem: 数据效率差距/Data-Efficiency Gap]\n        A --> C[主要方法/Method: 元学习与双层优化/Meta-Learning & Bi-Level Optimization]\n        A --> D[关键结果/Results: 100倍数据效率/100x Data Efficiency]\n        B --> B1[婴儿高效 vs. 模型低效/Infant Efficiency vs. Model Inefficiency]\n        C --> C1[MAdaPT协议/MAdaPT Protocol]\n        C --> C2[FOBLO优化/FOBLO Optimization]\n        C --> C3[交错监督/Interleaved Supervision]\n        D --> D1[<1h音频/<1h Audio]\n        D --> D2[音素可辨性提升/Improved Phonemic Discriminability]"
    },
    {
      "title": "ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling",
      "authors": "Chuan Wang, Gaoming Yang, Han Wu, Jiakai Tang, Jiahao Yu, Jian Wu, Jianwu Hu, Junjun Zheng, Shuwen Xiao, Yeqiu Yang, Yuning Jiang, Ahjol Nurlanbek, Binbin Cao, Bo Zheng, Fangmei Zhu, Gaoming Zhou, Huimin Yi, Huiping Chu, Jin Huang, Jinzhe Shan, Kenan Cui, Longbin Li, Silu Zhou, Wen Chen, Xia Ming, Xiang Gao, Xin Yao, Xingyu Wen, Yan Zhang, Yiwen Hu, Yulin Wang, Ziheng Bao, Zongyuan Wu",
      "institution": "TaoRank Team (Alibaba Group / Taobao)",
      "link": "https://arxiv.org/pdf/2512.21257",
      "code": null,
      "tags": [
        "agent system",
        "sequential modeling",
        "chain-of-thought reasoning",
        "diffusion large language models",
        "multi-agent collaboration",
        "world knowledge"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f98d5c26b79acf6e7c20219639988198127de51ba1227ceaeb063216243ba42_w640_q70.webp",
      "contributions": "1. Proposes ReaSeq, a reasoning-enhanced framework that leverages LLM world knowledge to overcome limitations of log-driven recommender systems. 2. Introduces explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into enriched item representations. 3. Employs latent reasoning via Diffusion LLMs to infer plausible beyond-log user behaviors, enhancing interest modeling.",
      "summary": "The paper introduces ReaSeq, a framework that uses Large Language Models' world knowledge for explicit and implicit reasoning to address knowledge poverty and systemic blindness in log-driven industrial recommender systems. It enhances item representations and infers beyond-log user behaviors. Deployed on Taobao, it achieved significant improvements in key business metrics like CTR and GMV.",
      "mindmap": "graph LR\n        A[ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[知识贫乏/Knowledge Poverty in ID-based Representations]\n        B --> B2[系统盲区/Systemic Blindness to Beyond-Log Interests]\n        C --> C1[显式推理/Explicit Chain-of-Thought Reasoning via Multi-Agent]\n        C --> C2[隐式推理/Latent Reasoning via Diffusion LLMs]\n        D --> D1[IPV & CTR提升 >6.0%/IPV & CTR Gain >6.0%]\n        D --> D2[订单提升 >2.9%/Orders Gain >2.9%]\n        D --> D3[GMV提升 >2.5%/GMV Gain >2.5%]"
    },
    {
      "title": "SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance",
      "authors": "Divij Dudeja, Mayukha Pal",
      "institution": "ABB Ability Innovation Center, Indian Institute of Information Technology, Nagpur",
      "link": "https://arxiv.org/pdf/2512.21280",
      "code": null,
      "tags": [
        "document question answering",
        "Tree-LSTM",
        "Memory Augmented Neural Network (MANN)",
        "Retrieval Augmented Generation (RAG)",
        "Parameter Efficiency",
        "Fact Extraction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fe5f40637f711007d6bb6875182fa80072536380614c5e93c7c4f5cf8dc2232_w640_q70.webp",
      "contributions": "1. Introduces a hierarchical, syntax-aware fact extractor (Grammarian Tree-LSTM) to parse engineering manuals into structured subject-relation-object triples., 2. Proposes a compact, indexed memory system (MANN) to store and retrieve extracted facts as vectors, enabling efficient knowledge access., 3. Designs a dual-mode inference system combining a fast path for known documents and a dynamic RAG-assisted path for new uploads, reducing hallucinations.",
      "summary": "The paper addresses the challenge of accurately answering questions from dense engineering manuals, where standard small language models fail. It proposes SMART, a structured model that hierarchically extracts facts, stores them in an indexed memory, and uses a transformer to generate answers from retrieved facts. The result is a parameter-efficient model that achieves higher accuracy with fewer parameters and reduced hallucinations compared to baselines like GPT-2.",
      "mindmap": "graph LR\n    A[SMART SLM] --> B[核心问题/Problem: 工程手册难以阅读，现有小模型处理为扁平token流，导致错误答案/Engineering manuals are hard to read; flat token processing leads to incorrect answers]\n    A --> C[主要方法/Method: 分层处理：语法感知事实提取器 + 索引记忆(MANN) + 6层Transformer/Hierarchical processing: Syntax-aware fact extractor + Indexed memory (MANN) + 6-layer Transformer]\n    A --> D[关键结果/Results: 参数减少64-69%，准确率提升21.3%，减少幻觉/64-69% fewer parameters, 21.3% higher accuracy, reduced hallucinations]"
    },
    {
      "title": "Parallel Token Prediction for Language Models",
      "authors": "Felix Draxler, Justus Will, Farrin Marouf Sofian, Theofanis Karaletsos, Sameer Singh, Stephan Mandt",
      "institution": "University of California, Irvine, Chan-Zuckerberg Initiative, Pyramidal AI",
      "link": "https://arxiv.org/pdf/2512.21323",
      "code": null,
      "tags": [
        "llm inference",
        "parallel token prediction",
        "speculative decoding",
        "autoregressive decoding",
        "transformer inference",
        "latency optimization"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d5681ed12f339fba2f3eb1e012a75a0b58e77b2c9c9aa20352d3b12fcba4f3c_w640_q70.webp",
      "contributions": "1. Proposes Parallel Token Prediction (PTP), a universal framework for parallel sequence generation that jointly predicts multiple dependent tokens in a single transformer call. 2. Proves that PTP can represent arbitrary autoregressive sequence distributions, avoiding the restrictive independence assumptions of prior multi-token prediction methods. 3. Demonstrates state-of-the-art speculative decoding performance, accepting over four tokens per step on Spec-Bench with Vicuna-7B, showing parallel long-sequence generation is feasible without losing modeling power.",
      "summary": "The paper addresses the high latency of autoregressive decoding in large language models by proposing Parallel Token Prediction (PTP), a framework that predicts multiple dependent tokens in parallel within a single transformer call. It proves PTP's universality in representing autoregressive distributions and shows it achieves superior speculative decoding performance, enabling faster text generation without sacrificing quality.",
      "mindmap": "graph LR\n    A[Parallel Token Prediction for Language Models] --> B[核心问题/Problem: Autoregressive decoding latency bottleneck]\n    A --> C[主要方法/Method: Parallel Token Prediction (PTP), joint prediction of dependent tokens]\n    A --> D[关键结果/Results: State-of-the-art speculative decoding, >4 tokens/step, universal framework]"
    },
    {
      "title": "Measuring all the noises of LLM Evals",
      "authors": "Sida Wang",
      "institution": "FAIR at Meta",
      "link": "https://arxiv.org/pdf/2512.21326",
      "code": null,
      "tags": [
        "llm inference",
        "LLM evaluation",
        "statistical noise",
        "paired analysis",
        "prediction variance",
        "data variance"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa15912febac5bc93aec8d1b8870feaf16ae89016c37e24c26550d053d396fec_w640_q70.webp",
      "contributions": "1. Clearly defines and measures three types of noise (prediction, data, total) in LLM evaluations using the law of total variance. 2. Proposes the \"all-pairs paired method\" to apply paired statistical analysis across all model pairs for increased statistical power. 3. Empirically reveals that total noise is predictable per evaluation and that prediction noise typically dominates data noise, enabling more effective significance testing.",
      "summary": "This paper addresses the challenge of statistical noise in Large Language Model (LLM) evaluations. It proposes an \"all-pairs paired method\" to measure prediction, data, and total noise across model pairs. The key findings are that each evaluation benchmark has a characteristic noise level and that reducing prediction noise through averaging can significantly improve the detection of performance differences.",
      "mindmap": "graph LR\n    A[Measuring all the noises of LLM Evals] --> B(核心问题/Problem: LLM评估中的统计噪声/Separating signal from noise in LLM evals)\n    A --> C(主要方法/Method: 全配对分析法/All-pairs paired method)\n    A --> D(关键结果/Results: 可预测的总噪声与主导的预测噪声/Predictable total noise & dominant prediction noise)"
    },
    {
      "title": "Your Reasoning Benchmark May Not Test Reasoning: Revealing Perception Bottleneck in Abstract Reasoning Benchmarks",
      "authors": "Xinhe Wang, Jin Huang, Xingjian Zhang, Tianhao Wang, Jiaqi W. Ma",
      "institution": "Carnegie Mellon University, University of Michigan, University of California San Diego, University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.21329",
      "code": null,
      "tags": [
        "reasoning evaluation",
        "abstract reasoning",
        "perception bottleneck",
        "vision-language models",
        "inductive reasoning",
        "evaluation protocol"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0fcc43646a911ef2be3f5f5aea5201f8582d0ad2c6e3465915701cc2f7fb9f09_w640_q70.webp",
      "contributions": "1. Proposes a two-stage experimental pipeline to explicitly separate perception and reasoning in abstract reasoning benchmarks. 2. Empirically demonstrates that perception capability, not reasoning, is the dominant factor in the performance gap for VLMs on ARC-style tasks. 3. Reveals through manual analysis that approximately 80% of model failures stem from perception errors, challenging the common interpretation of these benchmarks.",
      "summary": "The paper challenges the view that poor performance of vision-language models on abstract reasoning benchmarks like ARC indicates a reasoning deficiency. It introduces a two-stage pipeline that isolates perception (image-to-text description) from reasoning (rule induction on text) and shows that perception bottlenecks are the primary cause of failure, suggesting current benchmarks conflate these challenges.",
      "mindmap": "graph LR\n    A[Your Reasoning Benchmark May Not Test Reasoning] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[VLMs在抽象推理基准上表现不佳，通常归因于推理缺陷/VLMs perform poorly on abstract reasoning benchmarks, often attributed to reasoning deficits]\n    C --> C1[提出两阶段实验流程：感知（图像到文本）与推理（基于文本的规则归纳）/Propose a two-stage pipeline: Perception (image-to-text) and Reasoning (text-based rule induction)]\n    D --> D1[感知能力是性能差距的主导因素，约80%的失败源于感知错误/Perception is the dominant factor for the performance gap, ~80% of failures stem from perception errors]"
    },
    {
      "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
      "authors": "Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang",
      "institution": "Ant Group, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.21332",
      "code": "https://github.com/codefuse-ai/CodeFuse-Embeddings",
      "tags": [
        "code retrieval",
        "Pooling by Multihead Attention (PMA)",
        "contrastive learning",
        "code embedding",
        "MTEB-Code",
        "Qwen-2.5-Coder"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f27c6e6ad01eacb3bd759d1aafa323cd3f72410efd901b1df691e709d8fbe3a4_w640_q70.webp",
      "contributions": "1. Proposes a Pooling by Multihead Attention (PMA) module to generate sequence embeddings from token embeddings, effectively utilizing the LLM's causal representations. 2. The PMA module aggregates information from all tokens in a sequence, overcoming the information bottleneck of traditional EOS-based sequence embeddings. 3. The approach supports flexible adaptation of embedding dimensions, serving as an alternative to Multi-Representation Learning (MRL).",
      "summary": "This paper introduces C2LLM, a family of code embedding models built on Qwen-2.5-Coder backbones. It proposes a novel Pooling by Multihead Attention (PMA) module to create better sequence embeddings for code retrieval. The models, trained on three million data points, achieve state-of-the-art performance on the MTEB-Code benchmark, with the 7B version ranking first overall.",
      "mindmap": "graph LR\n        A[C2LLM Technical Report] --> B[核心问题/Problem: 代码检索中的序列表示瓶颈/Sequence representation bottleneck in code retrieval]\n        A --> C[主要方法/Method: 自适应交叉注意力池化 (PMA) / Adaptive Cross-Attention Pooling (PMA)]\n        A --> D[关键结果/Results: 在MTEB-Code上SOTA / SOTA on MTEB-Code]"
    },
    {
      "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
      "authors": "Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin",
      "institution": "Zhejiang University, Westlake University, University of Chicago",
      "link": "https://arxiv.org/pdf/2512.21336",
      "code": "https://github.com/LINs-lab/DenoisingEntropy",
      "tags": [
        "diffusion models",
        "Denoising Entropy",
        "Masked Diffusion Models",
        "decoding path optimization",
        "predictive uncertainty",
        "non-autoregressive generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4480eb4fa3d14900373effb4e74dd207b42c650b50de1044a2cad8b4036e465f_w640_q70.webp",
      "contributions": "1. Formalized the problem of decoding path sensitivity in Masked Diffusion Models (MDMs) by introducing the concept of cumulative Path Uncertainty. 2. Proposed Denoising Entropy, a novel, computable metric to quantify predictive uncertainty along a generative path. 3. Developed two entropy-guided algorithms (post-hoc selection and real-time guidance) to optimize the decoding path and improve generation quality.",
      "summary": "The paper identifies that the flexible generation of Masked Diffusion Models (MDMs) leads to variable output quality due to the chosen decoding order. To address this, it introduces Denoising Entropy to measure path uncertainty and proposes two algorithms that use this metric to guide the decoding process. Experiments show these methods significantly improve generation accuracy on reasoning, planning, and code tasks, turning uncertainty into an advantage.",
      "mindmap": "graph LR\n        A[Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty<br/>通过量化不确定性优化掩码扩散模型的解码路径] --> B(核心问题/Problem: MDMs生成质量对解码顺序敏感<br/>MDM output quality is sensitive to decoding order)\n        A --> C(主要方法/Method: 提出去噪熵和路径优化算法<br/>Propose Denoising Entropy & path optimization algorithms)\n        A --> D(关键结果/Results: 熵引导方法提升生成质量<br/>Entropy-guided methods improve generation quality)"
    },
    {
      "title": "Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence",
      "authors": "Sean C. Borneman, Julia Krebs, Ronnie B. Wilbur, Evie A. Malaia",
      "institution": "Carnegie-Mellon University, University of Salzburg, Purdue University, University of Alabama",
      "link": "https://arxiv.org/pdf/2512.20929",
      "code": null,
      "tags": [
        "computational neuroscience",
        "predictive coding",
        "EEG",
        "neural coherence",
        "optical flow",
        "entropy-based feature selection"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d4252b4df430bb18f969d798aff092b793b8033ce3e2ca01f2a17d6aeff53f1_w640_q70.webp",
      "contributions": "1. A novel machine learning framework for decoding EEG responses to dynamic visual language (sign language) using spatiotemporal neural coherence. 2. The identification of frequency-specific neural signatures (distributed left-hemispheric and frontal low-frequency coherence) that differentiate linguistic from non-linguistic visual input. 3. Demonstration of experience-dependent neural signatures correlating with age, linking lifelong exposure to the shaping of internal generative models for visual language.",
      "summary": "This paper proposes a machine learning framework that uses coherence between EEG signals and optical flow features to decode predictive neural dynamics in Deaf signers watching sign language. The method identifies specific low-frequency neural signatures crucial for language comprehension and shows these signatures are experience-dependent. The work provides a novel multimodal approach for probing the brain's generative models of visual language perception.",
      "mindmap": "graph LR\n        A[Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence<br>通过时空神经一致性解码视觉语言处理中的预测推理] --> B(核心问题/Problem: How does the brain perform predictive inference during visual language (sign language) comprehension?<br>大脑如何在视觉语言（手语）理解中进行预测推理？)\n        A --> C(主要方法/Method: A machine learning framework using EEG-optical flow coherence & entropy-based feature selection.<br>使用EEG-光流一致性及基于熵的特征选择的机器学习框架。)\n        A --> D(关键结果/Results: Identified left-hemispheric/frontal low-frequency coherence as key; neural signatures are experience-dependent.<br>发现左半球/前额低频一致性是关键；神经特征具有经验依赖性。)"
    },
    {
      "title": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "authors": "Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19864",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e0cfa9ec043e8a27718dd14bb89bf3c4ceafb97fb48a8a0b61d661ec9d34b09_w640_q70.webp",
      "contributions": "",
      "summary": "HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data",
      "mindmap": ""
    },
    {
      "title": "How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse",
      "authors": "Kirk Vanacore, Rene F. Kizilcec",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19903",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcd1ac8680cb9e68b32ea021e524b8dddd82c5081672c081d9ac46ec2f2c6180_w640_q70.webp",
      "contributions": "",
      "summary": "How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse",
      "mindmap": ""
    },
    {
      "title": "Counterfactual LLM-based Framework for Measuring Rhetorical Style",
      "authors": "Jingyi Qiu, Hong Chen, Zongyi Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19908",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6db39310497bbc29a6efe3c72529c4c231f4c45f6ccb6856571045197a2f074d_w640_q70.webp",
      "contributions": "",
      "summary": "Counterfactual LLM-based Framework for Measuring Rhetorical Style",
      "mindmap": ""
    },
    {
      "title": "PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation",
      "authors": "Zhixiang Lu, Xueyuan Deng, Yiran Liu, Yulong Li, Qiang Yan, Imran Razzak, Jionglong Su",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19933",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3acfc234a0a131551ac80194bbad4cea0eac21fb397065d4acf70449da5327f6_w640_q70.webp",
      "contributions": "",
      "summary": "PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation",
      "mindmap": ""
    },
    {
      "title": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "authors": "Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19950",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25282dd436ce0f7a5fabd0438ec9d8be57567585d626e71c9a9af6d0ac8451b9_w640_q70.webp",
      "contributions": "",
      "summary": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "mindmap": ""
    },
    {
      "title": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "authors": "Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19995",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf100eeda1c44688829760003993b1a83478a2d2901a0f5a0b9914bc5ef7c3b0_w640_q70.webp",
      "contributions": "",
      "summary": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
      "mindmap": ""
    },
    {
      "title": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "authors": "H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20074",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/187b806c979650defdb64bdb9ce297598ef473654b93625ec2257af228dbd0da_w640_q70.webp",
      "contributions": "",
      "summary": "Reason2Decide: Rationale-Driven Multi-Task Learning",
      "mindmap": ""
    },
    {
      "title": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
      "authors": "Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, Lifeng Shang, Jeff Z. Pan, Yuxin Jiang, Kam-Fai Wong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20092",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0f21f9409d7ddcd534ada400fa2d7b093de0f8e8672067e512129d84ead74883_w640_q70.webp",
      "contributions": "",
      "summary": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
      "mindmap": ""
    },
    {
      "title": "A Novel Graph-Sequence Learning Model for Inductive Text Classification",
      "authors": "Zuo Wang, Ye Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20097",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d452912781840b7b95df9d1137178809626a19d0d789bf4b893df1553a7c677d_w640_q70.webp",
      "contributions": "",
      "summary": "A Novel Graph-Sequence Learning Model for Inductive Text Classification",
      "mindmap": ""
    },
    {
      "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language",
      "authors": "Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20111",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3d0d34b2d9754cdb266cf6f4c20cff854836475921a3b1dfd5eebd552c7ef69c_w640_q70.webp",
      "contributions": "",
      "summary": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language",
      "mindmap": ""
    },
    {
      "title": "Multi-hop Reasoning via Early Knowledge Alignment",
      "authors": "Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20144",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d88b182b244d4a4ceb1d9822c08a4a4d748f40278f40b510b9dc474ab390f2c_w640_q70.webp",
      "contributions": "",
      "summary": "Multi-hop Reasoning via Early Knowledge Alignment",
      "mindmap": ""
    },
    {
      "title": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
      "authors": "Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20145",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8028ab8e7171d7f497cbdc48e136d419e8642bf876111786382aee29b15d0992_w640_q70.webp",
      "contributions": "",
      "summary": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
      "mindmap": ""
    },
    {
      "title": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
      "authors": "Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20136",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c211a1c8d3a17c264fe9655b35305f3ece6ef329a1cb2344fb1a18976f11017_w640_q70.webp",
      "contributions": "",
      "summary": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "Fun-Audio-Chat Technical Report",
      "authors": "Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20156",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eedb25d29b9c63de7f75bd47632c06e734814fe19fe3f517a37a4d3d42f693c7_w640_q70.webp",
      "contributions": "",
      "summary": "Fun-Audio-Chat Technical Report",
      "mindmap": ""
    },
    {
      "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
      "authors": "Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20164",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9be09765889dd9516b45fd948d07346b8b6487f6dc02927a597c1cab7861bfb7_w640_q70.webp",
      "contributions": "",
      "summary": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
      "mindmap": ""
    },
    {
      "title": "Learning to Reason in LLMs by Expectation Maximization",
      "authors": "Junghyun Lee, Branislav Kveton, Sunav Choudhary, Subhojyoti Mukherjee, Anup Rao, Ryan A. Rossi, Alexa Siu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20169",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fc3f6af733f26b26d15d5332cff89ae665d865f5359eb651dbf107c200c4794_w640_q70.webp",
      "contributions": "",
      "summary": "Learning to Reason in LLMs by Expectation Maximization",
      "mindmap": ""
    },
    {
      "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
      "authors": "Hao Guo, Xugong Qin, Jun Jie Ou Yang, Peng Zhang, Gangyan Zeng, Yubo Li, Hailun Lin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20174",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a74295652803d99c4b0631ef38e9684d12032ddd9797f217033f356497ff647_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
      "mindmap": ""
    },
    {
      "title": "FaithLens: Detecting and Explaining Faithfulness Hallucination",
      "authors": "Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20182",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/418ec0226018d595ee93c7097014ac35b5c5e68ad18001889120bf6c5aa27d11_w640_q70.webp",
      "contributions": "",
      "summary": "FaithLens: Detecting and Explaining Faithfulness Hallucination",
      "mindmap": ""
    },
    {
      "title": "Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings",
      "authors": "Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20204",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d50c0d1f767aca0e832de0ef650261ca473b1bbf6f1ac37ad18132605e13bc77_w640_q70.webp",
      "contributions": "",
      "summary": "Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings",
      "mindmap": ""
    },
    {
      "title": "AprielGuard",
      "authors": "Jaykumar Kasundra, Anjaneya Praharaj, Sourabh Surana, Lakshmi Sirisha Chodisetty, Sourav Sharma, Abhigya Verma, Abhishek Bhardwaj, Debasish Kanhar, Aakash Bhagat, Khalil Slimi, Seganrasan Subramanian, Sathwik Tejaswi Madhusudhan, Ranga Prasad Chenna, Srinivas Sunkara",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20293",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1df72be31938b1703d3c0991c388a31ae15e5ab7e811b6868c1d2b87ce212408_w640_q70.webp",
      "contributions": "",
      "summary": "AprielGuard",
      "mindmap": ""
    },
    {
      "title": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "authors": "Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20298",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp",
      "contributions": "",
      "summary": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "mindmap": ""
    },
    {
      "title": "SlideTailor: Personalized Presentation Slide Generation for Scientific Papers",
      "authors": "Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20292",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f80870c0718240101f019ec3db0f39be1afd3c26281e0c20366762d11e67351_w640_q70.webp",
      "contributions": "",
      "summary": "SlideTailor: Personalized Presentation Slide Generation for Scientific Papers",
      "mindmap": ""
    },
    {
      "title": "SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision",
      "authors": "Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20308",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d6351d1c5218be825df7f7572c20ff77011eb6baf9648cff6ea5fd370a23fda1_w640_q70.webp",
      "contributions": "",
      "summary": "SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles",
      "authors": "Nurul Labib Sayeedi, Md. Faiyaz Abdullah Sayeedi, Khushnur Binte Jahangir, Swakkhar Shatabda, Sarah Masud Preum",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20324",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76de34d24836232b3e2c53b464d6001663ee4428a6ebe0f1d009c4d37f298fc_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles",
      "mindmap": ""
    },
    {
      "title": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
      "authors": "Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20352",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2047f0800a6a91a372fd66013fa3526084396a7513879598fb459814e55b18c_w640_q70.webp",
      "contributions": "",
      "summary": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
      "mindmap": ""
    },
    {
      "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
      "authors": "YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20387",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13d9aa5293bf4ca8e839b122277f1484ffb43b6211d54741d7eb7f58312f5509_w640_q70.webp",
      "contributions": "",
      "summary": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
      "mindmap": ""
    },
    {
      "title": "Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining",
      "authors": "Junyi Liu, Stanley Kok",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20404",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0cbe3d2a9e0dbffa2ba1d89f2d2d61bcc3900bbeb02faaa7db06ace8b2d8e09b_w640_q70.webp",
      "contributions": "",
      "summary": "Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining",
      "mindmap": ""
    },
    {
      "title": "Step-DeepResearch Technical Report",
      "authors": "Chen Hu, Haikuo Du, Heng Wang, Lin Lin, Mingrui Chen, Peng Liu, Ruihang Miao, Tianchi Yue, Wang You, Wei Ji, Wei Yuan, Wenjin Deng, Xiaojian Yuan, Xiaoyun Zhang, Xiangyu Liu, Xikai Liu, Yanming Xu, Yicheng Cao, Yifei Zhang, Yongyao Wang, Yubo Shu, Yurong Zhang, Yuxiang Zhang, Zheng Gong, Zhichao Chang, Binyan Li, Dan Ma, Furong Jia, Hongyuan Wang, Jiayu Liu, Jing Bai, Junlan Liu, Manjiao Liu, Na Wang, Qiuping Wu, Qinxin Du, Shiwei Li, Wen Sun, Yifeng Gong, Yonglin Chen, Yuling Zhao, Yuxuan Lin, Ziqi Ren, Zixuan Wang, Aihu Zhang, Brian Li, Buyun Ma, Kang An, Li Xie, Mingliang Li, Pan Li, Shidong Yang, Xi Chen, Xiaojia Liu, Yuchu Luo, Yuan Song, YuanHao Ding, Yuanwei Liang, Zexi Li, Zhaoning Zhang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20491",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6e31009744d096e0b219624a8cb385cd29ef47c699069fff12401b051dd695f_w640_q70.webp",
      "contributions": "",
      "summary": "Step-DeepResearch Technical Report",
      "mindmap": ""
    },
    {
      "title": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
      "authors": "Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20569",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e36c08fad9c560eeacd24d61bbc8fc4ace2f57a4dda4d1eaeb59a63b10f01d2e_w640_q70.webp",
      "contributions": "",
      "summary": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
      "authors": "Amirhosein Ghasemabadi, Di Niu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20578",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f0ae4be0acd6ad133b6649afc37037f398f8e5753e19ae55612dfc2522618af9_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
      "mindmap": ""
    },
    {
      "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "authors": "Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20586",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp",
      "contributions": "",
      "summary": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "mindmap": ""
    },
    {
      "title": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
      "authors": "Dhruv Anand, Ehsan Shareghi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20595",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb95f031dbfb3f7bfc348a6d3e77d5c3ae7e2408f06dd57529b77764de0ce0b7_w640_q70.webp",
      "contributions": "",
      "summary": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
      "mindmap": ""
    },
    {
      "title": "Making Large Language Models Efficient Dense Retrievers",
      "authors": "Yibin Lei, Shwai He, Ang Li, Andrew Yates",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20612",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40238eef858f9a1a1327758d04b0c4c31e71fbbf6df6898a51ccf0f7ff9a8f36_w640_q70.webp",
      "contributions": "",
      "summary": "Making Large Language Models Efficient Dense Retrievers",
      "mindmap": ""
    },
    {
      "title": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
      "authors": "Alexandros Christoforos, Chadbourne Davis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20604",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/740b7502b49c1387c998a9fd8b95bff7878c9c8ecb80d21efccf1c64db303459_w640_q70.webp",
      "contributions": "",
      "summary": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
      "mindmap": ""
    },
    {
      "title": "Coherence in the brain unfolds across separable temporal regimes",
      "authors": "Davide Stauba, Finn Rabe, Akhil Misra, Yves Pauli, Roya Hüppi, Nils Lang, Lars Michels, Victoria Edkins, Sascha Frühholz, Iris Sommer, Wolfram Hinzen, Philipp Homan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20481",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ad4bde9d11d688dda33f0f878fe578450d6097fcbcbf36ba57e75d54765a25e_w640_q70.webp",
      "contributions": "",
      "summary": "Coherence in the brain unfolds across separable temporal regimes",
      "mindmap": ""
    },
    {
      "title": "Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning",
      "authors": "Lihui Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17912",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/154351bb01594c209c639a3724124babafa831a2c5526b2f6bb79e4ec436950a_w640_q70.webp",
      "contributions": "",
      "summary": "Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning",
      "mindmap": ""
    },
    {
      "title": "Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression",
      "authors": "Rahul Baxi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17920",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e85dcb740e46985e03fe90bf075468b334e1528a3de2a4858fac5b2ddbc2dc9_w640_q70.webp",
      "contributions": "",
      "summary": "Separating Constraint Compliance from Semantic Accuracy: A Novel Benchmark for Evaluating Instruction-Following Under Compression",
      "mindmap": ""
    },
    {
      "title": "Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models",
      "authors": "Hongji Li, Junchi yao, Manjiang Yu, Priyanka Singh, Xue Li, Di Wang, Lijie Hu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17911",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/218d6b0cd750a67af41f0ec36e744aed0a36e9ad83656c3a4c9ed70aa75b977d_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models",
      "authors": "Minh Tri LÊ, Ali Ait-Bachir",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17916",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a9a26225e6a2c495c48df9cb6a0e4bd0c624c036e56d8d0cf9885d0d909a745_w640_q70.webp",
      "contributions": "",
      "summary": "Learning to Prioritize IT Tickets: A Comparative Evaluation of Embedding-based Approaches and Fine-Tuned Transformer Models",
      "mindmap": ""
    },
    {
      "title": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
      "authors": "Aomufei Yuan, Zhiming Wang, Ruijie Miao, Dayu Wang, Yuxuan Tian, Zihan Wang, Yebo Peng, Yuhan Wu, Bairen Yi, Xin Liu, Tong Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17917",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ca40de411c47ab6f32fb67699fbcdce0808ef0d5179742bf46c64d088a640d3_w640_q70.webp",
      "contributions": "",
      "summary": "KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction",
      "mindmap": ""
    },
    {
      "title": "Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression",
      "authors": "Boris Kriuk, Logic Ng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17914",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d4fd665329b7eb837ca00f1091de17f8b4c1eb920670c43995680ca539562ae_w640_q70.webp",
      "contributions": "",
      "summary": "Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression",
      "mindmap": ""
    },
    {
      "title": "Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset",
      "authors": "Nick Rossenbach, Robin Schmitt, Tina Raissi, Simon Berger, Larissa Kleppel, Ralf Schlüter",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17915",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6036cb69e2cb0f832a1b1088209441a1b5309cc94cf18961ca3b07bffec7a52c_w640_q70.webp",
      "contributions": "",
      "summary": "Supplementary Resources and Analysis for Automatic Speech Recognition Systems Trained on the Loquacious Dataset",
      "mindmap": ""
    },
    {
      "title": "ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India",
      "authors": "Shubham Kumar Nigam, Tanuj Tyagi, Siddharth Shukla, Aditya Kumar Guru, Balaramamahanthi Deepak Patnaik, Danush Khanna, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18014",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a0d10da8d503938592e2a709885e1a4ad114f85d7b47234084835f143d49cd6_w640_q70.webp",
      "contributions": "",
      "summary": "ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India",
      "mindmap": ""
    },
    {
      "title": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
      "authors": "Shubham Kumar Nigam, Parjanya Aditya Shukla, Noel Shallum, Arnab Bhattacharya",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18004",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b2ffa85f9a5ddd1bd5f673a211deae55a7bad9087838680e7b143e6daac52df8_w640_q70.webp",
      "contributions": "",
      "summary": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
      "mindmap": ""
    },
    {
      "title": "CoPE: A Small Language Model for Steerable and Scalable Content Labeling",
      "authors": "Samidh Chakrabarti, David Willner, Kevin Klyman, Tiffany Saade, Emily Capstick, Sabina Nong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18027",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/423158010714f415c807a9ae93864ccaf58e7d33b462039083dce106e5d195f2_w640_q70.webp",
      "contributions": "",
      "summary": "CoPE: A Small Language Model for Steerable and Scalable Content Labeling",
      "mindmap": ""
    },
    {
      "title": "Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts",
      "authors": "Roger A. Finger, Eduardo G. Cortes, Sandro J. Rigo, Gabriel de O. Ramos",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18041",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/405c807df8e2ce95661469b072db6898b3dcf1bb175cd81aa868ecc9d2c06c12_w640_q70.webp",
      "contributions": "",
      "summary": "Narrative Consolidation: Formulating a New Task for Unifying Multi-Perspective Accounts",
      "mindmap": ""
    },
    {
      "title": "Statistical laws and linguistics inform meaning in naturalistic and fictional conversation",
      "authors": "Ashley M. A. Fehr, Calla G. Beauregard, Julia Witte Zimmerman, Katie Ekström, Pablo Rosillo-Rodes, Christopher M. Danforth, Peter Sheridan Dodds",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18072",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0119bf39897b4bb6f848dd8818e4a75f43e327cbc8223e8cff6bafd0a8277d08_w640_q70.webp",
      "contributions": "",
      "summary": "Statistical laws and linguistics inform meaning in naturalistic and fictional conversation",
      "mindmap": ""
    },
    {
      "title": "Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown",
      "authors": "Changxu Duan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18115",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/13ec88807faf2814dad94d8489b36894b8aa8c290f9026ca2108a6c17ac22ca6_w640_q70.webp",
      "contributions": "",
      "summary": "Layout-Aware Text Editing for Efficient Transformation of Academic PDFs to Markdown",
      "mindmap": ""
    },
    {
      "title": "External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning",
      "authors": "Jian Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18190",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ebbd501809c39f1f08745f358ebdf2df886f93b7202aeedbd613476ffb27866b_w640_q70.webp",
      "contributions": "",
      "summary": "External Hippocampus: Topological Cognitive Maps for Guiding Large Language Model Reasoning",
      "mindmap": ""
    },
    {
      "title": "Training LLMs with LogicReward for Faithful and Rigorous Reasoning",
      "authors": "Jundong Xu, Hao Fei, Huichi Zhou, Xin Quan, Qijun Huang, Shengqiong Wu, William Yang Wang, Mong-Li Lee, Wynne Hsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18196",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10a4cb0521ac4192e49080ee2ad4da1d452c4469bd6d7c8279e1ca666dd437a6_w640_q70.webp",
      "contributions": "",
      "summary": "Training LLMs with LogicReward for Faithful and Rigorous Reasoning",
      "mindmap": ""
    },
    {
      "title": "Stable and Efficient Single-Rollout RL for Multimodal Reasoning",
      "authors": "Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18215",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81e83852cf5de78a73c53dc039a80d4328420c326e71217ed656de7348457003_w640_q70.webp",
      "contributions": "",
      "summary": "Stable and Efficient Single-Rollout RL for Multimodal Reasoning",
      "mindmap": ""
    },
    {
      "title": "GeoSense-AI: Fast Location Inference from Crisis Microblogs",
      "authors": "Deepit Sapru",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18225",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5c58318afd02a0e78246cd4d9114fc0566ca0ff40a0a1ad3e92124da0582633_w640_q70.webp",
      "contributions": "",
      "summary": "GeoSense-AI: Fast Location Inference from Crisis Microblogs",
      "mindmap": ""
    },
    {
      "title": "Investigating Spatial Attention Bias in Vision-Language Models",
      "authors": "Aryan Chaudhary, Sanchit Goyal, Pratik Narang, Dhruv Kumar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18231",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/be5cd89ea4d004fbb18410473c51ae236387bc088e028d1ddd84dbce2d703bfc_w640_q70.webp",
      "contributions": "",
      "summary": "Investigating Spatial Attention Bias in Vision-Language Models",
      "mindmap": ""
    },
    {
      "title": "Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition",
      "authors": "Sudip Chakrabarty, Pappu Bishwas, Rajdeep Chatterjee",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18298",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2d1fa5f1ea12d3598f0bd43290aa418e4ebda7629f53494201d317e1a493a95_w640_q70.webp",
      "contributions": "",
      "summary": "Explainable Transformer-CNN Fusion for Noise-Robust Speech Emotion Recognition",
      "mindmap": ""
    },
    {
      "title": "Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy",
      "authors": "Wenkai Li, Lynnette Hui Xian Ng, Andy Liu, Daniel Fried",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18292",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bca157c21b274184903d6db27d719924ad61a7ebd545421b88ee4959f34a8c8_w640_q70.webp",
      "contributions": "",
      "summary": "Measuring Fine-Grained Negotiation Tactics of Humans and LLMs in Diplomacy",
      "mindmap": ""
    },
    {
      "title": "InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning",
      "authors": "Tanjim Taharat Aurpa, Md Shoaib Ahmed, Md Mahbubur Rahman, Md. Golam Moazzam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18301",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7a5ce8e8f2666469be8a7a0bffad58a614870a283a7d6d1dca8f43d9f0a9304_w640_q70.webp",
      "contributions": "",
      "summary": "InstructNet: A Novel Approach for Multi-Label Instruction Classification through Advanced Deep Learning",
      "mindmap": ""
    },
    {
      "title": "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher",
      "authors": "Tianlun Liu, Zhiliang Tian, Zhen Huang, Xingzhi Zhou, Wanlong Yu, Tianle Liu, Feng Liu, Dongsheng Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18321",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a3cf2be9f3faea6343f7391291b649e6555516f57a7f71804673fdebc50f3e4_w640_q70.webp",
      "contributions": "",
      "summary": "CTTA-T: Continual Test-Time Adaptation for Text Understanding via Teacher-Student with a Domain-aware and Generalized Teacher",
      "mindmap": ""
    },
    {
      "title": "LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation",
      "authors": "Guo Chen, Junjie Huang, Huaijin Xie, Fei Sun, Tao Jia",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18329",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0dd393abec358205f73a078d58f2d077d68b22ce62c1b8d3eb7bc25329e59e8a_w640_q70.webp",
      "contributions": "",
      "summary": "LIR$^3$AG: A Lightweight Rerank Reasoning Strategy Framework for Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "Towards Efficient Agents: A Co-Design of Inference Architecture and System",
      "authors": "Weizhe Lin, Hui-Ling Zhen, Shuai Yang, Xian Wang, Renxi Liu, Hanting Chen, Wangze Zhang, Chuansai Zhou, Yiming Li, Chen Chen, Xing Li, Zhiyuan Yang, Xiaosong Li, Xianzhi Yu, Zhenhua Dong, Mingxuan Yuan, Yunhe Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18337",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea7ed4e66482149eeb38c88b95b26442424c5cb783935dd1d2ae998dcbe934a3_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Efficient Agents: A Co-Design of Inference Architecture and System",
      "mindmap": ""
    },
    {
      "title": "LLM-based Few-Shot Early Rumor Detection with Imitation Agent",
      "authors": "Fengzhu Zeng, Qian Shao, Ling Cheng, Wei Gao, Shih-Fen Cheng, Jing Ma, Cheng Niu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18352",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68253881479be80c6f5156b8929dcea7c9affda2463411703dbff80daa9a6787_w640_q70.webp",
      "contributions": "",
      "summary": "LLM-based Few-Shot Early Rumor Detection with Imitation Agent",
      "mindmap": ""
    },
    {
      "title": "SRS-Stories: Vocabulary-constrained multilingual story generation for language learning",
      "authors": "Wiktor Kamzela, Mateusz Lango, Ondrej Dusek",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18362",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9bb1bdec7e9243a15f59e7c93c8e0fc83a1b1ee3982dfb0225c524424979ac69_w640_q70.webp",
      "contributions": "",
      "summary": "SRS-Stories: Vocabulary-constrained multilingual story generation for language learning",
      "mindmap": ""
    },
    {
      "title": "LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators",
      "authors": "Mateusz Lango, Ondřej Dušek",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18360",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e70af4d7e4c119643e3631c8815a5d46438a6f1b8881a5821764fb495f8608f_w640_q70.webp",
      "contributions": "",
      "summary": "LLM Agents Implement an NLG System from Scratch: Building Interpretable Rule-Based RDF-to-Text Generators",
      "mindmap": ""
    },
    {
      "title": "DACE For Railway Acronym Disambiguation",
      "authors": "El Mokhtar Hribach, Oussama Mechhour, Mohammed Elmonstaser, Yassine El Boudouri, Othmane Kabal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18357",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/491cdc5ad5360c6518de9b4fdc6851733d3db21d281c60aa6fe7296ba2016a65_w640_q70.webp",
      "contributions": "",
      "summary": "DACE For Railway Acronym Disambiguation",
      "mindmap": ""
    },
    {
      "title": "AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3",
      "authors": "Mark Kashirskiy, Artiom Lipinski, Ilya Makarov",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18399",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eb721fc55d6ea689ae069e1c50129b86f7fc25c4c3433aa154aaa38bf9378cd3_w640_q70.webp",
      "contributions": "",
      "summary": "AraToken: Optimizing Arabic Tokenization with Normalization Pipeline and Language Extension for Qwen3",
      "mindmap": ""
    },
    {
      "title": "An Agentic AI Framework for Training General Practitioner Student Skills",
      "authors": "Victor De Marez, Jens Van Nooten, Luna De Bruyne, Walter Daelemans",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18440",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937c34e04859d95b3aed57029c9c5791e5aa2e5a17dbc8d2d6ac7882d0933e37_w640_q70.webp",
      "contributions": "",
      "summary": "An Agentic AI Framework for Training General Practitioner Student Skills",
      "mindmap": ""
    },
    {
      "title": "Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling",
      "authors": "Christopher Román Jaimes",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18462",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/27cc701f0cd5020bdc7452f202a07cee2cdb12b9d80e26c528184ec53ea76847_w640_q70.webp",
      "contributions": "",
      "summary": "Mitigating Spurious Correlations in NLI via LLM-Synthesized Counterfactuals and Dynamic Balanced Sampling",
      "mindmap": ""
    },
    {
      "title": "Research on a hybrid LSTM-CNN-Attention model for text-based web content classification",
      "authors": "Mykola Kuz, Ihor Lazarovych, Mykola Kozlenko, Mykola Pikuliak, Andrii Kvasniuk",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18475",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d6cee54c1b292cf87f190d497421a3a323bc276532b71bc07f75f60e88c9a5d_w640_q70.webp",
      "contributions": "",
      "summary": "Research on a hybrid LSTM-CNN-Attention model for text-based web content classification",
      "mindmap": ""
    },
    {
      "title": "Teaching and Critiquing Conceptualization and Operationalization in NLP",
      "authors": "Vagrant Gautam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18505",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/124f7904bd6c9c1e7dda9c02619db7d1384dfe77987878e3270100575989ec37_w640_q70.webp",
      "contributions": "",
      "summary": "Teaching and Critiquing Conceptualization and Operationalization in NLP",
      "mindmap": ""
    },
    {
      "title": "Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset",
      "authors": "S Mahmudul Hasan, Shaily Roy, Akib Jawad Nafis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18533",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ae98cacefd250f660449f7354216ce0a7f9d0395ed396c825595eada053e771_w640_q70.webp",
      "contributions": "",
      "summary": "Generalization Gaps in Political Fake News Detection: An Empirical Study on the LIAR Dataset",
      "mindmap": ""
    },
    {
      "title": "Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering",
      "authors": "Sungjoon Park, Varun Ramamurthi, Owen Terry",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18551",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2fa6d5c65b00f54388a5a5958e1d779544648a0e4bcc5878bdac10755ae186e1_w640_q70.webp",
      "contributions": "",
      "summary": "Neologism Learning as a Parameter-Efficient Alternative to Fine-Tuning for Model Steering",
      "mindmap": ""
    },
    {
      "title": "LLMs on Drugs: Language Models Are Few-Shot Consumers",
      "authors": "Alexander Doudkin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18546",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fccef5b4c858e71f601c763675964730c550bdc2fa2972235024cc1e538c6bf7_w640_q70.webp",
      "contributions": "",
      "summary": "LLMs on Drugs: Language Models Are Few-Shot Consumers",
      "mindmap": ""
    },
    {
      "title": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "authors": "Scott Thornton",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18542",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2afb4d99182c71c26adf649cc513b4f7ffee3c07f215e3f4067f2ce9fa660fa0_w640_q70.webp",
      "contributions": "",
      "summary": "SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models",
      "mindmap": ""
    },
    {
      "title": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "authors": "Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18552",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "mindmap": ""
    },
    {
      "title": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "authors": "Amit Barman, Atanu Mandal, Sudip Kumar Naskar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18593",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp",
      "contributions": "",
      "summary": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "mindmap": ""
    },
    {
      "title": "A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts",
      "authors": "Prabigya Acharya, Liza Shrestha",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18608",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58ef9e00613b3a5bfbc5cce08d668a7661f6fb069cae338e88db1f35673ee946_w640_q70.webp",
      "contributions": "",
      "summary": "A Comparative Study of Light-weight Language Models for PII Masking and their Deployment for Real Conversational Texts",
      "mindmap": ""
    },
    {
      "title": "On Finding Inconsistencies in Documents",
      "authors": "Charles J. Lovering, Seth Ebner, Brandon Smock, Michael Krumdick, Saad Rabbani, Ahmed Muhammad, Varshini Reddy, Chris Tanner",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18601",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c61e64bf42843ef58fd5d03121ce8b9fe2e96bcf5d34bd8dd2619416e3f08f59_w640_q70.webp",
      "contributions": "",
      "summary": "On Finding Inconsistencies in Documents",
      "mindmap": ""
    },
    {
      "title": "LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction",
      "authors": "Jensen Zhang, Ningyuan Liu, Yijia Fan, Zihao Huang, Qinglin Zeng, Kaitong Cai, Jian Wang, Keze Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18623",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3883290af621e53ac54109af76617e157c55068c77c267e0c4643eac11fc0ec_w640_q70.webp",
      "contributions": "",
      "summary": "LLM-CAS: Dynamic Neuron Perturbation for Real-Time Hallucination Correction",
      "mindmap": ""
    },
    {
      "title": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "authors": "Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18622",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp",
      "contributions": "",
      "summary": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "mindmap": ""
    },
    {
      "title": "Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital",
      "authors": "Pierre Colombo, Malik Boudiaf, Allyn Sweet, Michael Desa, Hongxi Wang, Kevin Candra, Syméon del Marmol",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18658",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/99cb2c0d15c54813fefddf4670e9d0dc5b70cdc79ff9a13a7d5fb4f3a38f7143_w640_q70.webp",
      "contributions": "",
      "summary": "Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital",
      "mindmap": ""
    },
    {
      "title": "brat: Aligned Multi-View Embeddings for Brain MRI Analysis",
      "authors": "Maxime Kayser, Maksim Gridnev, Wanting Wang, Max Bain, Aneesh Rangnekar, Avijit Chatterjee, Aleksandr Petrov, Harini Veeraraghavan, Nathaniel C. Swinburne",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18679",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e2d9cbeed3e332a02f5cc9adf5abc0ec370a32b059de24cd550cc930eb84a82_w640_q70.webp",
      "contributions": "",
      "summary": "brat: Aligned Multi-View Embeddings for Brain MRI Analysis",
      "mindmap": ""
    },
    {
      "title": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "authors": "Yuchen Li, Handing Wang, Bing Xue, Mengjie Zhang, Yaochu Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d33a421c48ad59f7420161a73adc3cf5979c2e95cd4ded4b6c5ac3a603e0e95_w640_q70.webp",
      "contributions": "",
      "summary": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "mindmap": ""
    },
    {
      "title": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "authors": "Recep Kaan Karaman, Meftun Akarsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18748",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp",
      "contributions": "",
      "summary": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "mindmap": ""
    },
    {
      "title": "MemEvolve: Meta-Evolution of Agent Memory Systems",
      "authors": "Guibin Zhang, Haotian Ren, Chong Zhan, Zhenhong Zhou, Junhao Wang, He Zhu, Wangchunshu Zhou, Shuicheng Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18746",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0bcb0edebf98e4279185979654fe8f92c41ebcbd3b45786b67e305d7a65d04f6_w640_q70.webp",
      "contributions": "",
      "summary": "MemEvolve: Meta-Evolution of Agent Memory Systems",
      "mindmap": ""
    },
    {
      "title": "InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search",
      "authors": "Kaican Li, Lewei Yao, Jiannan Wu, Tiezheng Yu, Jierun Chen, Haoli Bai, Lu Hou, Lanqing Hong, Wei Zhang, Nevin L. Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18745",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/87556fdc09b55b65c0d472d205a384cc42453256afeb9e7a28db98178fe1d145_w640_q70.webp",
      "contributions": "",
      "summary": "InSight-o3: Empowering Multimodal Foundation Models with Generalized Visual Search",
      "mindmap": ""
    },
    {
      "title": "From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure",
      "authors": "Thorsten Hellert, Nikolay Agladze, Alex Giovannone, Jan Jug, Frank Mayet, Mark Sherwin, Antonin Sulc, Chris Tennant",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18779",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4811b7a6317b8d33b2f92f5249b3e215e280fef25b4d76030d5495c78a7d02f_w640_q70.webp",
      "contributions": "",
      "summary": "From Natural Language to Control Signals: A Conceptual Framework for Semantic Channel Finding in Complex Experimental Infrastructure",
      "mindmap": ""
    },
    {
      "title": "AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus",
      "authors": "Sultan Alrashed, Francesco Orabona",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18834",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b37cd3dd620b849ae8ae05331dd8a70314996ab6497e0c72c29ceac5b60b6899_w640_q70.webp",
      "contributions": "",
      "summary": "AraMix: Recycling, Refiltering, and Deduplicating to Deliver the Largest Arabic Pretraining Corpus",
      "mindmap": ""
    },
    {
      "title": "From Word to World: Can Large Language Models be Implicit Text-based World Models?",
      "authors": "Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, Mengdi Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18832",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7359ba2b2edde0aa35db68272c398f7be194a19334cd0996c3e220c7df0b0c05_w640_q70.webp",
      "contributions": "",
      "summary": "From Word to World: Can Large Language Models be Implicit Text-based World Models?",
      "mindmap": ""
    },
    {
      "title": "MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models",
      "authors": "Tung Duong Ta, Tim Oates",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18841",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/904d7953eb4dbc5c149d55e1575a3ed4dcd44d5ed3985c2f466d1edfe62296e9_w640_q70.webp",
      "contributions": "",
      "summary": "MDToC: Metacognitive Dynamic Tree of Concepts for Boosting Mathematical Problem-Solving of Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Application of deep learning approaches for medieval historical documents transcription",
      "authors": "Maksym Voloshchuk, Bohdana Zarembovska, Mykola Kozlenko",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18865",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bc697efc3bfd30e66b187f56c365b6a8add07756fb768bc77ba4586f1ab7d205_w640_q70.webp",
      "contributions": "",
      "summary": "Application of deep learning approaches for medieval historical documents transcription",
      "mindmap": ""
    },
    {
      "title": "Toward Human-Centered AI-Assisted Terminology Work",
      "authors": "Antonio San Martin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18859",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f9d1c947f7ae3816e7677add1e89a2192fc6c70c465f3c393e895ab239f5a20f_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Human-Centered AI-Assisted Terminology Work",
      "mindmap": ""
    },
    {
      "title": "Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction",
      "authors": "Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18880",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/69c02cdd0b38302d7f949dfe357cef926fc143c19edf1038c18dd4c5b1573b09_w640_q70.webp",
      "contributions": "",
      "summary": "Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction",
      "mindmap": ""
    },
    {
      "title": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
      "authors": "Shaomu Tan, Ryosuke Mitani, Ritvik Choudhary, Qiyu Wu, Toshiyuki Sekiya, Christof Monz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18906",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76fe48c6335a2271e131697f68ce5e1bd4c38bb02d11e569ba97f897ef4100cd_w640_q70.webp",
      "contributions": "",
      "summary": "Remedy-R: Generative Reasoning for Machine Translation Evaluation without Error Annotations",
      "mindmap": ""
    },
    {
      "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "authors": "Wen-Long Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18940",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5496d384aad293547e961ed7f2ce4568121f384e9e0b977144128668dc8445cb_w640_q70.webp",
      "contributions": "",
      "summary": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "mindmap": ""
    },
    {
      "title": "Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework",
      "authors": "Jinyan Liu, Zikang Chen, Qinchuan Wang, Tan Xie, Heming Zheng, Xudong Lv",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18999",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e96bd25bfb48e12bba787eb322582c438c99e6cb5614ad626a47b788b4598038_w640_q70.webp",
      "contributions": "",
      "summary": "Evaluating the Challenges of LLMs in Real-world Medical Follow-up: A Comparative Study and An Optimized Framework",
      "mindmap": ""
    },
    {
      "title": "Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation",
      "authors": "Ryosuke Korekata, Quanting Xie, Yonatan Bisk, Komei Sugiura",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18987",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/456f5beecc1c2c45f598578f8491d702dc76e9f500bae44e01454f783dc10b05_w640_q70.webp",
      "contributions": "",
      "summary": "Affordance RAG: Hierarchical Multimodal Retrieval with Affordance-Aware Embodied Memory for Mobile Manipulation",
      "mindmap": ""
    },
    {
      "title": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "authors": "Akshaj Prashanth Rao, Advait Singh, Saumya Kumaar Saksena, Dhruv Kumar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19011",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ddd38197559bfa789648dce3d4d675d0a05e678684e3999b2ba550170a5c8c1e_w640_q70.webp",
      "contributions": "",
      "summary": "Efficient Jailbreak Mitigation Using Semantic Linear Classification in a Multi-Staged Pipeline",
      "mindmap": ""
    },
    {
      "title": "Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models",
      "authors": "Tongyuan Miao, Gary Huang, Kai Jun Han, Annie Jiang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19004",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0ec45adefdbba0ff1f29513a557351fab96e8636ad950ecb6008ff575d0f496_w640_q70.webp",
      "contributions": "",
      "summary": "Context-Aware Initialization for Reducing Generative Path Length in Diffusion Language Models",
      "mindmap": ""
    },
    {
      "title": "DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation",
      "authors": "Shijian Ma, Yunqi Huang, Yan Lin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19012",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a55d81fc2fbbe12d82874badb4ccf6267053cf79d4294994aa54685dbd78fd_w640_q70.webp",
      "contributions": "",
      "summary": "DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation",
      "mindmap": ""
    },
    {
      "title": "Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding",
      "authors": "Ruiqi Ma, Yu Yan, Chunhong Zhang, Minghao Yin, XinChao Liu, Zhihong Jin, Zheng Hu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19070",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d56f2f61fcc600eaa02837139337fdefe7e31f2b7f624524c972734f069b6c0f_w640_q70.webp",
      "contributions": "",
      "summary": "Watch Closely: Mitigating Object Hallucinations in Large Vision-Language Models with Disentangled Decoding",
      "mindmap": ""
    },
    {
      "title": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
      "authors": "Ziyan Zhang, Chao Wang, Zhuo Chen, Lei Chen, Chiyi Li, Kai Song",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19092",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4872220afe78cb4c58d8419cbef85a647f38abc69798722db414463aacc8757f_w640_q70.webp",
      "contributions": "",
      "summary": "A Large Language Model Based Method for Complex Logical Reasoning over Knowledge Graphs",
      "mindmap": ""
    },
    {
      "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "authors": "Mahir Labib Dihan, Sadif Ahmed, Md Nafiu Rahman",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19122",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf739862e73c646805e217bdf5e2cd5a0f6ec312b673bc4801a828112773cb1d_w640_q70.webp",
      "contributions": "",
      "summary": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "mindmap": ""
    },
    {
      "title": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
      "authors": "Amar Lakel",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19117",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f46c06d65cdf6f99dbc4e1a6dd9ba52726ca28bfeec49c8ae2faf170ca9124e_w640_q70.webp",
      "contributions": "",
      "summary": "Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?",
      "mindmap": ""
    },
    {
      "title": "AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards",
      "authors": "Zihan Lin, Xiaohan Wang, Hexiong Yang, Jiajun Chai, Jie Cao, Guojun Yin, Wei Lin, Ran He",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19126",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ea562f5265303d30f48412af8f0c2c84f8e98bc5e8f45118efe7f417df403e8d_w640_q70.webp",
      "contributions": "",
      "summary": "AWPO: Enhancing Tool-Use of Large Language Models through Explicit Integration of Reasoning Rewards",
      "mindmap": ""
    },
    {
      "title": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
      "authors": "Tzu-Yun Lee, Ding-Yong Hong, Jan-Jan Wu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19125",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e3141b4a53facc55a384f90382f9ca7bbbdeafdff36d3027e35548bc8ba2ea87_w640_q70.webp",
      "contributions": "",
      "summary": "SAP: Syntactic Attention Pruning for Transformer-based Language Models",
      "mindmap": ""
    },
    {
      "title": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
      "authors": "Dehai Min, Kailin Zhang, Tongtong Wu, Lu Cheng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19134",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/829ce6a74a55abeea6f6d10fec5338ad05441e95283687a525b0f2525bbf8a12_w640_q70.webp",
      "contributions": "",
      "summary": "QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation",
      "mindmap": ""
    },
    {
      "title": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
      "authors": "Alessandro Lucca, Francesco Pierri",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19161",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/53c07d75233bf3941b1b0c41209affef3033b0d43a91f61416cc01001baa79ef_w640_q70.webp",
      "contributions": "",
      "summary": "From Speech to Subtitles: Evaluating ASR Models in Subtitling Italian Television Programs",
      "mindmap": ""
    },
    {
      "title": "JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation",
      "authors": "Bingyang Kelvin Liu, Ziyu Patrick Chen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19171",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73c8bb7209d6fc574cd2b7517828b640ea0eaabfd4d5cb2bba4396c7e2c1fa0a_w640_q70.webp",
      "contributions": "",
      "summary": "JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation",
      "mindmap": ""
    },
    {
      "title": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
      "authors": "Dazhen Deng, Sen Yang, Yuchen He, Yuan Tian, Yingcai Wu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19173",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4924c981ea9ee58543e98b565a1e8fca0e8ce65bad7464a4041f4c5ffc756918_w640_q70.webp",
      "contributions": "",
      "summary": "CycleChart: A Unified Consistency-Based Learning Framework for Bidirectional Chart Understanding and Generation",
      "mindmap": ""
    },
    {
      "title": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
      "authors": "Anna-Maria Gueorguieva, Aylin Caliskan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19238",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d125f49a56a4f052b1faf9015b89460bff5794de36222547ccabb3b4a08eca86_w640_q70.webp",
      "contributions": "",
      "summary": "Identifying Features Associated with Bias Against 93 Stigmatized Groups in Language Models and Guardrail Model Safety Mitigation",
      "mindmap": ""
    },
    {
      "title": "ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models",
      "authors": "Mingxu Zhang, Dazhong Shen, Qi Zhang, Ying Sun",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19240",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aeb3b37133d9071af2bfeeecd0da8171d70b3d3d9b3b0658553484d1919570f5_w640_q70.webp",
      "contributions": "",
      "summary": "ChemATP: A Training-Free Chemical Reasoning Framework for Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
      "authors": "Do Minh Duc, Quan Xuan Truong, Nguyen Tat Dat, Nguyen Van Vinh",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19247",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b3e85ac8e144e835ca46b7dcdc94a82085e98b53bc5c52cfa6addea751cf9af2_w640_q70.webp",
      "contributions": "",
      "summary": "Auto-Prompting with Retrieval Guidance for Frame Detection in Logistics",
      "mindmap": ""
    },
    {
      "title": "CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs",
      "authors": "Javier Vela-Tambo, Jorge Gracia, Fernando Dominguez-Castro",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19305",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e378c47c250804c75f74ae7dab654f342496632f097065fedb247e2353e13310_w640_q70.webp",
      "contributions": "",
      "summary": "CienaLLM: Generative Climate-Impact Extraction from News Articles with Autoregressive LLMs",
      "mindmap": ""
    },
    {
      "title": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
      "authors": "Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19320",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7204250ada52cfa8e70ee24634b9a58aab0085ac9d5854e5c672a585fb92a0a6_w640_q70.webp",
      "contributions": "",
      "summary": "MAGIC: Achieving Superior Model Merging via Magnitude Calibration",
      "mindmap": ""
    },
    {
      "title": "HATS: High-Accuracy Triple-Set Watermarking for Large Language Models",
      "authors": "Zhiqing Hu, Chenxu Zhao, Jiazhong Lu, Xiaolei Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19378",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57616dcd6c2bbaa04b7fa3a0787e49d5a02a47c5a4535936d5c9f62643957b10_w640_q70.webp",
      "contributions": "",
      "summary": "HATS: High-Accuracy Triple-Set Watermarking for Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
      "authors": "Yacouba Diarra, Panga Azazia Kamate, Nouhoum Souleymane Coulibaly, Michael Leventhal",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19400",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b8ba0dabc6aa24a9c91f88fe9dbdb71fe95fe660fb7d092170d584e8ca01617_w640_q70.webp",
      "contributions": "",
      "summary": "Kunnafonidilaw ka Cadeau: an ASR dataset of present-day Bambara",
      "mindmap": ""
    },
    {
      "title": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "authors": "Jiaren Peng, Hongda Sun, Xuan Tian, Cheng Huang, Zeqing Li, Rui Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19414",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/553b6290892a9990d1a3b4b102abcd09ff7265499b12fe86a581ef08a388f0b6_w640_q70.webp",
      "contributions": "",
      "summary": "From Retrieval to Reasoning: A Framework for Cyber Threat Intelligence NER with Explicit and Adaptive Instructions",
      "mindmap": ""
    },
    {
      "title": "CodeSimpleQA: Scaling Factuality in Code Large Language Models",
      "authors": "Jian Yang, Wei Zhang, Yizhi Li, Shawn Guo, Haowen Wang, Aishan Liu, Ge Zhang, Zili Wang, Zhoujun Li, Xianglong Liu, Weifeng Lv",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19424",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91e94588098b016a931e564501e220f391d8186f55b4c39b93da715a899afb11_w640_q70.webp",
      "contributions": "",
      "summary": "CodeSimpleQA: Scaling Factuality in Code Large Language Models",
      "mindmap": ""
    },
    {
      "title": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
      "authors": "Quyu Kong, Xu Zhang, Zhenyu Yang, Nolan Gao, Chen Liu, Panrong Tong, Chenglin Cai, Hanzhang Zhou, Jianan Zhang, Liangyu Chen, Zhidan Liu, Steven Hoi, Yue Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19432",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1f9de7d24f3262309b81c73b75271d399f4875308f21feaf79b5ca283f85311c_w640_q70.webp",
      "contributions": "",
      "summary": "MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments",
      "mindmap": ""
    },
    {
      "title": "Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations",
      "authors": "Jinwei Chi, Ke Wang, Yu Chen, Xuanye Lin, Qiang Xu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19456",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44e2303feb430ac2c66a05d707fa59f0184a8efed477dd24968816daffaaf4a2_w640_q70.webp",
      "contributions": "",
      "summary": "Activations as Features: Probing LLMs for Generalizable Essay Scoring Representations",
      "mindmap": ""
    },
    {
      "title": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "authors": "Walter Quattrociocchi, Valerio Capraro, Matjaž Perc",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19466",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e38aa1bf279d77f222964e2fa6eaf6b1a85cc9955ae786124894e9ed3fb93c1_w640_q70.webp",
      "contributions": "",
      "summary": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "mindmap": ""
    },
    {
      "title": "SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation",
      "authors": "Thittipat Pairatsuppawat, Abhibhu Tachaapornchai, Paweekorn Kusolsomboon, Chutikan Chaiwong, Thodsaporn Chay-intr, Kobkrit Viriyayudhakorn, Nongnuch Ketui, Aslan B. Wong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19455",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa063ad12c4a8d092558907067bccfddb046268125d4e779376dab9a3d77d1e0_w640_q70.webp",
      "contributions": "",
      "summary": "SiamGPT: Quality-First Fine-Tuning for Stable Thai Text Generation",
      "mindmap": ""
    },
    {
      "title": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
      "authors": "Ivan Decostanzi, Yelena Mejova, Kyriaki Kalimeri",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19475",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a54fad5edc889b5ad9104209f3afb0330725100e661de009b823a7db7e07d9ec_w640_q70.webp",
      "contributions": "",
      "summary": "A Large-Language-Model Framework for Automated Humanitarian Situation Reporting",
      "mindmap": ""
    },
    {
      "title": "Algerian Dialect",
      "authors": "Zakaria Benmounah, Abdennour Boulesnane",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19543",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b20aa2b1c53242ea58da6106d340fde3ef7bc07b9c5b254164c44ae1890074a7_w640_q70.webp",
      "contributions": "",
      "summary": "Algerian Dialect",
      "mindmap": ""
    },
    {
      "title": "Event Extraction in Large Language Model",
      "authors": "Bobo Li, Xudong Han, Jiang Liu, Yuzhe Ding, Liqiang Jing, Zhaoqi Zhang, Jinheng Li, Xinya Du, Fei Li, Meishan Zhang, Min Zhang, Aixin Sun, Philip S. Yu, Hao Fei",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19537",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd9b5f9c26e59b2ed6103844101a774216e9cbe68f45ba35eb88ca2b32f24ec6_w640_q70.webp",
      "contributions": "",
      "summary": "Event Extraction in Large Language Model",
      "mindmap": ""
    },
    {
      "title": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
      "authors": "Angelo Ortiz Tandazo, Manel Khentout, Youssef Benchekroun, Thomas Hueber, Emmanuel Dupoux",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19612",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d640e4e40b2a6b04fca6e826cd560376d85f3c26277639aacff733108db2cc6_w640_q70.webp",
      "contributions": "",
      "summary": "MauBERT: Universal Phonetic Inductive Biases for Few-Shot Acoustic Units Discovery",
      "mindmap": ""
    },
    {
      "title": "Increasing the Thinking Budget is Not All You Need",
      "authors": "Ignacio Iacobacci, Zhaozhi Qian, Faroq AL-Tam, Muhammad AL-Qurishi, Riad Souissi",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19585",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1349874483030f6b12e0c38e99a95b5753e35155a3ffc245d9bfc23d426e906f_w640_q70.webp",
      "contributions": "",
      "summary": "Increasing the Thinking Budget is Not All You Need",
      "mindmap": ""
    },
    {
      "title": "Exploring the features used for summary evaluation by Human and GPT",
      "authors": "Zahra Sadeghi, Evangelos Milios, Frank Rudzicz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19620",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e154f176f186b8dabd43d09d2a96579db8d3bbe3ccbf6debeb1b756642ffa2a_w640_q70.webp",
      "contributions": "",
      "summary": "Exploring the features used for summary evaluation by Human and GPT",
      "mindmap": ""
    },
    {
      "title": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
      "authors": "Rolando Coto-Solano, Daisy Li, Manoela Teleginski Ferraz, Olivia Sasse, Cha Krupka, Sharid Loáiciga, Sally Akevai Tenamu Nicholas",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19630",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e2b93b8d306871e2d8f350baf0bfd0f0d6c6c700437457c6697698611b042a41_w640_q70.webp",
      "contributions": "",
      "summary": "Diacritic Restoration for Low-Resource Indigenous Languages: Case Study with Bribri and Cook Islands Māori",
      "mindmap": ""
    },
    {
      "title": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
      "authors": "Filippos Ventirozos, Peter Appleby, Matthew Shardlow",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19651",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7a48528a8f2854ae05c55d577072800564793ed86ef6169c7375b1685f01ca86_w640_q70.webp",
      "contributions": "",
      "summary": "Exploring Zero-Shot ACSA with Unified Meaning Representation in Chain-of-Thought Prompting",
      "mindmap": ""
    },
    {
      "title": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
      "authors": "Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19673",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a324294583c22f2459c7cd427d13db040bb89f060fd51e26bb284a001119f6d4_w640_q70.webp",
      "contributions": "",
      "summary": "Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies",
      "mindmap": ""
    },
    {
      "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
      "authors": "Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4f15c4d0f8b9a87e3d2373c2b35ef0faccb02043a099a932d6e9b7afa805adea_w640_q70.webp",
      "contributions": "",
      "summary": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
      "mindmap": ""
    },
    {
      "title": "A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework",
      "authors": "Ravi Prasad",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17968",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7665945961b2f7304f7c1df5cbe15f902828795ce6193b462edbd1a98af56880_w640_q70.webp",
      "contributions": "",
      "summary": "A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework",
      "mindmap": ""
    },
    {
      "title": "Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences",
      "authors": "Kohei Watanabe",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18119",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67542bc330fbf0441e0930413b5ebeee7ea4fb111df4bff5fba61c49280b9f8a_w640_q70.webp",
      "contributions": "",
      "summary": "Distributed Asymmetric Allocation: A Topic Model for Large Imbalanced Corpora in Social Sciences",
      "mindmap": ""
    },
    {
      "title": "TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition",
      "authors": "Haolong Zheng, Yekaterina Yegorova, Mark Hasegawa-Johnson",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18263",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a32dd492d99bdbfa3ef2453e70a027129c638aca8cddc500a7ae12d1a4ae23df_w640_q70.webp",
      "contributions": "",
      "summary": "TICL+: A Case Study On Speech In-Context Learning for Children's Speech Recognition",
      "mindmap": ""
    },
    {
      "title": "Merge on workspaces as Hopf algebra Markov chain",
      "authors": "Matilde Marcolli, David Skigin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18861",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0e865fcb929853efc360d95d314faf7e223840ff014d953cb55dcb92aadbc95_w640_q70.webp",
      "contributions": "",
      "summary": "Merge on workspaces as Hopf algebra Markov chain",
      "mindmap": ""
    },
    {
      "title": "PAACE: A Plan-Aware Automated Agent Context Engineering Framework",
      "authors": "Kamer Ali Yuksel",
      "institution": "aiXplain Inc",
      "link": "https://arxiv.org/pdf/2512.16970",
      "code": null,
      "tags": [
        "llm inference",
        "context engineering",
        "plan-aware compression",
        "next-k-task relevance",
        "instruction co-refinement",
        "function-preserving compression",
        "synthetic data generation",
        "knowledge distillation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PAACE, a framework for compressing the expanding context of LLM agents in multi-step workflows. It uses plan-aware techniques like next-k-task relevance modeling and function-preserving compression, trained on synthetic data and distilled into efficient models. The method improves agent accuracy while significantly reducing context load and inference costs.",
      "mindmap": ""
    },
    {
      "title": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows",
      "authors": "Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu",
      "institution": "Shanghai Artificial Intelligence Laboratory",
      "link": "https://arxiv.org/pdf/2512.16969",
      "code": null,
      "tags": [
        "scientific ai evaluation",
        "Practical Inquiry Model (PIM)",
        "SGI-Bench",
        "Test-Time Reinforcement Learning (TTRL)",
        "retrieval-augmented novelty",
        "agent-based evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40fba3081819027f6af6208a55e87bd4bfc888d4ba6ce07d9baa5f158fbe6fa2_w640_q70.webp",
      "contributions": "",
      "summary": "This paper proposes a framework for evaluating Scientific General Intelligence (SGI) in LLMs, grounded in the Practical Inquiry Model and operationalized through the SGI-Bench benchmark. The results reveal significant performance gaps across tasks like deep research and experimental reasoning. The authors also introduce Test-Time Reinforcement Learning (TTRL) to enhance hypothesis novelty without requiring reference answers.",
      "mindmap": ""
    },
    {
      "title": "A Women's Health Benchmark for Large Language Models",
      "authors": "Victoria-Elisabeth Gruber, Razvan Marinescu, Diego Fajardo, Amin H. Nassar, Christopher Arkfeld, Alexandria Ludlow, Shama Patel, Mehrnoosh Samaei, Valerie Klug, Anna Huber, Marcel Gühner, Albert Botta i Orfila, Irene Lagoja, Kimya Tarr, Haleigh Larson, Mary Beth Howard",
      "institution": "Lumos AI, Yale Cancer Center, Harvard Medical School, UCSF, Brown University, Emory University, Clinic Ottakring, NHS, Yale School of Medicine, Johns Hopkins University School of Medicine",
      "link": "https://arxiv.org/pdf/2512.17028",
      "code": null,
      "tags": [
        "healthcare AI evaluation",
        "women's health benchmark",
        "large language models",
        "error types",
        "model stumps",
        "query types"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Women's Health Benchmark (WHB), a novel evaluation framework comprising 96 validated model stumps across five medical specialties, three query types, and eight error types to assess LLM performance in women's health. It finds that current LLMs have approximately 60% failure rates, with significant weaknesses in detecting urgency, indicating they are not yet reliable for providing women's health advice.",
      "mindmap": ""
    },
    {
      "title": "Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL",
      "authors": "Khushboo Thaker, Yony Bresler",
      "institution": "Crater Labs",
      "link": "https://arxiv.org/pdf/2512.17053",
      "code": null,
      "tags": [
        "llm training",
        "knowledge distillation",
        "chain-of-thought",
        "structured reasoning",
        "query execution plan",
        "text-to-sql"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/906b49597857a3cad8e1c9c8d6cdbec46e7807fe819943d1e6d91facfb7f18bd_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes Struct-SQL, a knowledge distillation framework that trains a small language model using a structured chain-of-thought derived from query execution plans, rather than unstructured reasoning traces. The distilled model achieves an 8.1% absolute improvement over an unstructured baseline, primarily due to a reduction in syntactic errors. This demonstrates that structured logical blueprints are beneficial for reliable SQL generation in small models.",
      "mindmap": ""
    },
    {
      "title": "Perturb Your Data: Paraphrase-Guided Training Data Watermarking",
      "authors": "Pranav Shetty, Mirazul Haque, Petr Babkin, Zhiqiang Ma, Xiaomo Liu, Manuela Veloso",
      "institution": "JPMorgan AI Research",
      "link": "https://arxiv.org/pdf/2512.17075",
      "code": null,
      "tags": [
        "llm training",
        "SPECTRA",
        "watermarking",
        "training data detection",
        "membership inference attack",
        "paraphrase generation",
        "scoring model",
        "token probability comparison"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b47f34679362a94a5413b86758bfca6d1690e7158a9b8bc7a21706264c5e833c_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SPECTRA, a watermarking method that subtly paraphrases text using an LLM to embed a detectable signature into training data without altering its statistical distribution. It verifies unauthorized use by comparing token probabilities between a suspect model and a scoring model. The approach reliably detects watermarked data even when it constitutes a minuscule fraction of the training corpus, providing a scalable pre-release watermark for data owners.",
      "mindmap": ""
    },
    {
      "title": "When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation",
      "authors": "Michael H. Coen",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.17083",
      "code": null,
      "tags": [
        "dialogue topic segmentation",
        "window-tolerant F1",
        "boundary density",
        "segment coherence",
        "granularity-aware evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a new evaluation framework for dialogue topic segmentation that emphasizes boundary density and segment coherence alongside window-tolerant F1. It demonstrates through cross-dataset experiments that reported performance differences are often artifacts of annotation granularity mismatches, not model quality. The core conclusion is that topic segmentation should be viewed as selecting an appropriate granularity rather than predicting a single correct boundary set.",
      "mindmap": ""
    },
    {
      "title": "A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving",
      "authors": "Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich",
      "institution": "Bosch Center for AI, University of Augsburg, ScaDS.AI & TU Dresden",
      "link": "https://arxiv.org/pdf/2512.17093",
      "code": null,
      "tags": [
        "llm training",
        "solver-in-the-loop",
        "instruction-tuning",
        "supervised fine-tuning",
        "best-of-N sampling",
        "answer set programming",
        "semantic parsing"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/38c83df2ce552270bc09f323934a96a0aad16af58e736a7049ccfd73afeed0d4_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces a solver-in-the-loop framework that uses an ASP solver to provide feedback on LLM-generated code, creating a dataset of chosen and rejected instances for supervised fine-tuning. The method improves LLM performance on generating Answer Set Programming code for logic puzzles, demonstrating consistent gains across different prompting settings and datasets.",
      "mindmap": ""
    },
    {
      "title": "Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition",
      "authors": "Zahra Rahmani, Hossein Sameti",
      "institution": "Sharif University of Technology",
      "link": "https://arxiv.org/pdf/2512.17247",
      "code": null,
      "tags": [
        "llm inference",
        "error level noise embedding",
        "n-best hypotheses",
        "noise-aware modeling",
        "whisper",
        "llama-2",
        "word error rate",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a robust noise-sensitive ASR error correction framework for Persian. It introduces Error Level Noise (ELN) embeddings, derived from disagreements in multiple ASR hypotheses, to condition a fine-tuned LLaMA-2 model, enabling it to reason about noise-induced uncertainty. The ELN-conditioned model significantly reduces Word Error Rate compared to text-only baselines, demonstrating the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust speech recognition in noisy environments.",
      "mindmap": ""
    },
    {
      "title": "AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators",
      "authors": "Michael J. Ryan, Yanzhe Zhang, Amol Salunkhe, Yi Chu, Di Xu, Diyi Yang",
      "institution": "Stanford University, American Express",
      "link": "https://arxiv.org/pdf/2512.17267",
      "code": null,
      "tags": [
        "evaluation framework",
        "LLM-as-a-Judge",
        "regression",
        "MetricBank",
        "retrieval",
        "human feedback correlation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/74363ce6b272cc866e0e9407e36b6e57863b7642ae94357d478230d1f46735a0_w640_q70.webp",
      "contributions": "",
      "summary": "The paper presents AutoMetrics, a framework that synthesizes evaluation metrics by combining retrieved metrics from a curated bank with automatically generated LLM-as-a-Judge criteria, composed via regression to maximize correlation with human feedback. It demonstrates that AutoMetrics significantly improves correlation with human judgments over standard LLM-as-a-Judge approaches while requiring minimal human feedback data. The method can serve as an effective proxy reward for optimizing AI applications.",
      "mindmap": ""
    },
    {
      "title": "Understanding Generalization in Role-Playing Models via Information Theory",
      "authors": "Yongqi Li, Hao Lang, Fei Huang, Tieyun Qian, Yongbin Li",
      "institution": "Wuhan University, Tongyi Lab, Zhongguancun Academy",
      "link": "https://arxiv.org/pdf/2512.17270",
      "code": null,
      "tags": [
        "natural language processing",
        "information theory",
        "mutual information",
        "reinforcement learning",
        "distribution shift",
        "role-playing models"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/85ede876c98e7e8d1d360bf9eb2cb767cc2570e218ebc72489f68b5cec65ce55_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces an information-theoretic metric called reasoning-based effective mutual information difference (R-EMID) to measure and analyze the generalization degradation of role-playing models under distribution shifts. It also proposes a co-evolving reinforcement learning framework to improve response probability estimation for calculating R-EMID. The main conclusion is that user shift poses the highest risk to model performance and reinforcement learning is the most effective approach for enhancing generalization.",
      "mindmap": ""
    },
    {
      "title": "Subjective Question Generation and Answer Evaluation using NLP",
      "authors": "G. M. Refatul Islam, Safwan Shaheer, Yaseen Nur, Mohammad Rafid Hamid",
      "institution": "Brac University",
      "link": "https://arxiv.org/pdf/2512.17289",
      "code": null,
      "tags": [
        "llm training",
        "large language models",
        "instruct-tuning",
        "bloom's taxonomy",
        "subjective evaluation",
        "question generation",
        "answer evaluation"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6f03ca77cc9ebde43ea5a7c83c936ce7c8843b9c39c6b6c58614cb92eb1ce8fc_w640_q70.webp",
      "contributions": "",
      "summary": "This research proposes a framework that uses instruct-tuned large language models (LLMs) to generate subjective questions and evaluate student answers, particularly for higher-order thinking skills. The study concludes that this approach can effectively automate the assessment of complex, subjective understanding, a task traditionally requiring human evaluators.",
      "mindmap": ""
    },
    {
      "title": "Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation",
      "authors": "Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar",
      "institution": "Birla Institute of Technology and Science, Pilani",
      "link": "https://arxiv.org/pdf/2512.17308",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "turn-based battle system",
        "strategic decision-making",
        "content generation",
        "procedural generation",
        "adaptive difficulty"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper develops a turn-based Pokémon battle system where LLMs act as agents, making tactical decisions based on a structured battle state without domain-specific training. The core method involves evaluating LLMs on strategic reasoning and their ability to generate novel game content. The main conclusion is that LLMs can function as dynamic game opponents and designers, offering a practical alternative to reinforcement learning for strategic games.",
      "mindmap": ""
    },
    {
      "title": "Task Schema and Binding: A Double Dissociation Study of In-Context Learning",
      "authors": "Chaeha Kim",
      "institution": "Changwon National University",
      "link": "https://arxiv.org/pdf/2512.17325",
      "code": null,
      "tags": [
        "in-context learning",
        "activation patching",
        "double dissociation",
        "task schema",
        "binding",
        "transformer",
        "mamba"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper uses activation patching experiments across multiple Transformer models and Mamba to causally dissect in-context learning. It concludes that ICL decomposes into two separable mechanisms: Task Schema (abstract task recognition) and Binding (specific input-output associations), with their reliance governed by a trade-off with the model's prior knowledge.",
      "mindmap": ""
    },
    {
      "title": "AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens",
      "authors": "Tung-Ling Li, Yuhao Wu, Hongliang Liu",
      "institution": "Palo Alto Networks",
      "link": "https://arxiv.org/pdf/2512.17375",
      "code": null,
      "tags": [
        "post-training",
        "adversarial control tokens",
        "beam-search exploration",
        "last-layer logit gap",
        "LoRA-based adversarial training",
        "reward hacking"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces AdvJudge-Zero, a method that uses beam-search on a model's next-token distribution to discover short, low-perplexity control token sequences that can flip the binary decisions of LLM-as-a-Judge systems from \"No\" to \"Yes\". It concludes that these tokens represent a realistic reward-hacking vulnerability in post-training pipelines, and shows that adversarial training can mitigate the issue while preserving evaluation quality.",
      "mindmap": ""
    },
    {
      "title": "Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?",
      "authors": "Zabir Al Nazi, G M Shahariar, Abrar Hossain, Wei Peng",
      "institution": "University of California, Riverside, University of Dhaka, Stanford University",
      "link": "https://arxiv.org/pdf/2512.17394",
      "code": null,
      "tags": [
        "vision-language models",
        "CulturalToM-VQA",
        "visual question answering",
        "chain-of-thought prompting",
        "compositional chain-of-thought prompting",
        "false belief reasoning",
        "social desirability bias"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces CulturalToM-VQA, a benchmark dataset built via a VLM-assisted human-in-the-loop pipeline to evaluate cross-cultural Theory of Mind reasoning in Vision-Language Models. It finds that while newer VLMs show strong performance on explicit tasks, they systematically struggle with false belief reasoning, and their results may be inflated by social desirability bias rather than genuine visual understanding.",
      "mindmap": ""
    },
    {
      "title": "RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering",
      "authors": "Léo Butsanets, Charles Corbière, Julien Khlaut, Pierre Manceron, Corentin Dancette",
      "institution": "Raidium, Université de Paris Cité, Hôpital Européen Georges Pompidou, AP-HP, INSERM",
      "link": "https://arxiv.org/pdf/2512.17396",
      "code": null,
      "tags": [
        "multi-modal inference",
        "visual question answering",
        "vision-language models",
        "fine-tuning",
        "benchmark dataset",
        "CT",
        "MRI"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ed7cbd6c6a04ef8f9a23147e56923de1ca94a48cc51c20cfa98200b90baa146_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces RadImageNet-VQA, a large-scale CT and MRI dataset with expert-curated annotations for radiologic visual question answering, designed to evaluate vision-language models on tasks like abnormality detection and pathology identification. Experiments show that current models struggle with fine-grained pathology identification, especially in open-ended settings, and the dataset avoids linguistic shortcuts as models perform near-random without image inputs.",
      "mindmap": ""
    },
    {
      "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories",
      "authors": "Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe",
      "institution": "Turing",
      "link": "https://arxiv.org/pdf/2512.17419",
      "code": null,
      "tags": [
        "llm inference",
        "SWE-Bench++",
        "automated benchmark generation",
        "pull request harvesting",
        "environment synthesis",
        "test oracle extraction",
        "hint-guided trajectory synthesis",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.",
      "mindmap": ""
    },
    {
      "title": "Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection",
      "authors": "Menna Elgabry, Ali Hamdi",
      "institution": "MSA University",
      "link": "https://arxiv.org/pdf/2512.17630",
      "code": null,
      "tags": [
        "natural language processing",
        "ensemble learning",
        "weighted voting",
        "Condorcet’s Jury Theorem",
        "fine-tuning",
        "transformer models"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a confidence- and credibility-weighted ensemble framework using diverse small transformer models (BERT, RoBERTa, etc.) for emotion detection. The method combines global validation performance and instance-level confidence to weight model votes. The ensemble achieves a 93.5% macro F1-score on the DAIR-AI dataset, outperforming larger LLMs while being more parameter-efficient.",
      "mindmap": ""
    },
    {
      "title": "AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora",
      "authors": "Zhihan Zhou, Daqian Shi, Rui Song, Lida Shi, Xiaolei Diao, Hao Xu",
      "institution": "Jilin University, Queen Mary University of London, University of Trento",
      "link": "https://arxiv.org/pdf/2512.17756",
      "code": null,
      "tags": [
        "llm inference",
        "AncientBench",
        "benchmark evaluation",
        "ancient character comprehension",
        "excavated documents",
        "glyph comprehension",
        "pronunciation comprehension",
        "meaning comprehension",
        "contextual comprehension"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6a15f186f48b4cc77c0d16272783515a0f56f75b51cf745384fc582f7e77f37a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces AncientBench, a comprehensive benchmark designed to evaluate large language models' comprehension of ancient Chinese, particularly focusing on excavated documents. It assesses four competencies (glyph, pronunciation, meaning, and contextual) through ten tasks. The experimental results show that while LLMs have significant potential in ancient text scenarios, a performance gap remains compared to human experts.",
      "mindmap": ""
    },
    {
      "title": "Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity",
      "authors": "Tanjim Taharat Aurpa, Farzana Akter, Md. Mehedi Hasan, Shakil Ahmed, Shifat Ara Rafiq, Fatema Khan",
      "institution": "University of Frontier Technology, University of Liberal Arts Bangladesh",
      "link": "https://arxiv.org/pdf/2512.17769",
      "code": null,
      "tags": [
        "others",
        "BERT",
        "DistilBERT",
        "ELECTRA",
        "RoBERTa",
        "Multi-BERT Ensemble",
        "transformer models",
        "medical entity recognition"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a Multi-BERT Ensemble approach for Bangla Medical Entity Recognition (MedER), evaluating models like BERT, DistilBERT, ELECTRA, and RoBERTa. The ensemble method achieved 89.58% accuracy, an 11.80% improvement over single-layer BERT, and the authors also created a new annotated dataset for this low-resource language task.",
      "mindmap": ""
    },
    {
      "title": "ShareChat: A Dataset of Chatbot Conversations in the Wild",
      "authors": "Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le",
      "institution": "Indiana University",
      "link": "https://arxiv.org/pdf/2512.17843",
      "code": null,
      "tags": [
        "others",
        "dataset collection",
        "multi-turn conversations",
        "platform affordances",
        "source citations",
        "temporal analysis",
        "cross-platform corpus"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset's utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.",
      "mindmap": ""
    },
    {
      "title": "When Reasoning Meets Its Laws",
      "authors": "Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang",
      "institution": "University of Illinois Urbana-Champaign, Massachusetts Institute of Technology, University of Pennsylvania, New York University, NTT Research",
      "link": "https://arxiv.org/pdf/2512.17901",
      "code": null,
      "tags": [
        "large reasoning models",
        "laws of reasoning",
        "compute law",
        "accuracy law",
        "monotonicity",
        "compositionality",
        "LoRe-Bench",
        "finetuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f9db7b3665dbba1bcaed95897dff8a53103ef5bfe963b50f03c044189965a72_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces the Laws of Reasoning (LoRe), a framework that formalizes desired reasoning behaviors in large reasoning models, including compute and accuracy laws. It proposes LoRe-Bench to evaluate monotonicity and compositionality, and develops a finetuning method to improve compositionality. The study finds that better compliance with these laws leads to enhanced reasoning performance across benchmarks.",
      "mindmap": ""
    },
    {
      "title": "Value Lens: Using Large Language Models to Understand Human Values",
      "authors": "Eduardo de la Cruz Fernández, Marcelo Karanik, Sascha Ossowski",
      "institution": "Universidad Politécnica de Madrid, Universidad Rey Juan Carlos",
      "link": "https://arxiv.org/pdf/2512.15722",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "value detection",
        "generative AI",
        "dual-LLM approach",
        "expert verification"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes Value Lens, a two-stage model that uses Large Language Models (LLMs) to detect human values in text. The first stage uses an LLM to conceptualize a value theory verified by experts, and the second stage employs a dual-LLM approach for detection and critical review. The results show that Value Lens performs comparably to or better than other models in similar tasks.",
      "mindmap": ""
    },
    {
      "title": "LLaDA2.0: Scaling Up Diffusion Language Models to 100B",
      "authors": "Tiwei Bie, Maosong Cao, Kun Chen, Lun Du, Mingliang Gong, Zhuochen Gong, Yanmei Gu, Jiaqi Hu, Zenan Huang, Zhenzhong Lan, Chengxi Li, Chongxuan Li, Jianguo Li, Zehuan Li, Huabin Liu, Ling Liu, Guoshan Lu, Xiaocheng Lu, Yuxin Ma, Jianfeng Tan, Lanning Wei, Ji-Rong Wen, Yipeng Xing, Xiaolu Zhang, Junbo Zhao, Da Zheng, Jun Zhou, Junlin Zhou, Zhanchao Zhou, Liwang Zhu, Yihong Zhuang",
      "institution": "Ant Group, Renmin University of China, Zhejiang University, Westlake University, HongKong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.15745",
      "code": null,
      "tags": [
        "llm training",
        "discrete diffusion language model",
        "block-level WSD training",
        "mixture-of-experts",
        "knowledge inheritance",
        "parallel decoding",
        "SFT",
        "DPO"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces LLaDA2.0, a method for converting pre-trained auto-regressive language models into large-scale discrete diffusion models (dLLMs) using a novel three-phase block-level training scheme. The resulting instruction-tuned models, including a 100B-parameter variant, achieve superior performance and efficiency through parallel decoding. The work establishes a new paradigm for frontier-scale model deployment by enabling efficient scaling and knowledge inheritance from existing models.",
      "mindmap": ""
    },
    {
      "title": "D3G: Diverse Demographic Data Generation Increases Zero-Shot Image Classification Accuracy within Multimodal Models",
      "authors": "Javon Hickmon",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.15747",
      "code": null,
      "tags": [
        "multi-modal inference",
        "CLIP",
        "Stable Diffusion XL",
        "zero-shot classification",
        "demographic bias mitigation",
        "data generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes D3G, a training-free method that uses Stable Diffusion XL to generate diverse demographic data at inference time to improve zero-shot image classification with CLIP. The method is shown to boost classification accuracy while reducing harmful demographic bias in pre-trained multimodal models.",
      "mindmap": ""
    },
    {
      "title": "Auto-Tuning Safety Guardrails for Black-Box Large Language Models",
      "authors": "Perry Abdulkadir",
      "institution": "University of St. Thomas",
      "link": "https://arxiv.org/pdf/2512.15782",
      "code": null,
      "tags": [
        "llm inference",
        "hyperparameter optimization",
        "system prompts",
        "content filters",
        "jailbreak detection",
        "malware generation",
        "Optuna",
        "ModernBERT",
        "grid search"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes treating the design of safety guardrails (like system prompts and content filters) for a frozen black-box LLM as a hyperparameter optimization problem. Using a proof-of-concept with Mistral-7B-Instruct and ModernBERT, it shows that a black-box optimizer (Optuna) can efficiently find safe configurations, matching the best grid search results with far fewer evaluations and less time. The conclusion is that this auto-tuning approach is a feasible method to harden LLM deployments under practical constraints.",
      "mindmap": ""
    },
    {
      "title": "A Systematic Analysis of Biases in Large Language Models",
      "authors": "Xulang Zhang, Rui Mao, Erik Cambria",
      "institution": "Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.15792",
      "code": null,
      "tags": [
        "fairness and bias analysis",
        "news summarization",
        "stance classification",
        "UN voting patterns",
        "multilingual story completion",
        "World Values Survey"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically analyzes biases in large language models (LLMs) across political, ideological, alliance, language, and gender dimensions using experiments like news summarization and stance classification. The main conclusion is that despite being aligned for neutrality, the studied LLMs still exhibit various types of biases and affinities.",
      "mindmap": ""
    },
    {
      "title": "Evaluation of AI Ethics Tools in Language Models: A Developers' Perspective Case Stud",
      "authors": "Jhessica Silva, Diego A. B. Moreira, Gabriel O. dos Santos, Alef Ferreira, Helena Maia, Sandra Avila, Helio Pedrini",
      "institution": "Universidade Estadual de Campinas (UNICAMP), Universidade Federal de Goiás (UFG)",
      "link": "https://arxiv.org/pdf/2512.15791",
      "code": null,
      "tags": [
        "ai ethics evaluation",
        "Model Cards",
        "ALTAI",
        "FactSheets",
        "Harms Modeling",
        "literature survey",
        "interviews"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents a methodology to evaluate AI Ethics Tools (AIETs) for language models by selecting four tools (Model Cards, ALTAI, FactSheets, Harms Modeling) and applying them to Portuguese language models, with developer interviews. The results indicate that these tools help guide general ethical considerations but fail to address language-specific aspects like idiomatic expressions or identify negative impacts for Portuguese.",
      "mindmap": ""
    },
    {
      "title": "Explainable Ethical Assessment on Human Behaviors by Generating Conflicting Social Norms",
      "authors": "Yuxi Sun, Wei Gao, Hongzhan Lin, Jing Ma, Wenxuan Zhang",
      "institution": "Hong Kong Baptist University, Singapore Management University, Singapore University of Technology and Design",
      "link": "https://arxiv.org/pdf/2512.15793",
      "code": null,
      "tags": [
        "ethical ai",
        "contrastive learning",
        "social norms generation",
        "moral reasoning",
        "explainable ai",
        "valence prediction"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces ClarityEthic, a method that enhances ethical assessment of human actions by generating conflicting social norms to explain and predict valence (support/oppose). It uses a contrastive learning strategy to strengthen the moral reasoning of language models. Experiments show the method outperforms baselines and human evaluations confirm the generated norms provide plausible explanations.",
      "mindmap": ""
    },
    {
      "title": "Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models",
      "authors": "Davide Caffagni, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Pier Luigi Dovesi, Shaghayegh Roohi, Mark Granroth-Wilding, Rita Cucchiara",
      "institution": "University of Modena and Reggio Emilia, AMD Silo AI",
      "link": "https://arxiv.org/pdf/2512.15885",
      "code": null,
      "tags": [
        "multi-modal training",
        "self-supervised learning",
        "vision-language alignment",
        "I-JEPA",
        "JARVIS",
        "masked predictive loss",
        "frozen vision foundation models"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces JARVIS, a self-supervised framework that integrates the I-JEPA learning paradigm into multimodal large language model (MLLM) training to enhance visual understanding. It uses frozen vision models as encoders and trains an LLM-based predictor to learn visual regularities without relying solely on textual supervision. The method consistently improves performance on vision-centric benchmarks across different LLM families without degrading multimodal reasoning abilities.",
      "mindmap": ""
    },
    {
      "title": "DSO: Direct Steering Optimization for Bias Mitigation",
      "authors": "Lucas Monteiro Paes, Nivedha Sivakumar, Yinong Oliver Wang, Masha Fedzechkina Donaldson, Luca Zappella, Nicholas Apostoloff",
      "institution": "Apple, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.15926",
      "code": null,
      "tags": [
        "fairness and bias mitigation",
        "activation steering",
        "reinforcement learning",
        "linear transformations",
        "inference-time control"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes Direct Steering Optimization (DSO), a method using reinforcement learning to find linear transformations for steering activations in generative models to mitigate bias while maintaining performance. It demonstrates state-of-the-art trade-offs between fairness and capabilities in VLMs and LLMs, offering inference-time control over bias reduction. The work highlights the advantage of directly optimized steering strategies over heuristic-based approaches for effective bias intervention.",
      "mindmap": ""
    },
    {
      "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception",
      "authors": "Joel Mire, Maria Antoniak, Steven R. Wilson, Zexin Ma, Achyutarama R. Ganti, Andrew Piper, Maarten Sap",
      "institution": "Carnegie Mellon University, University of Colorado Boulder, University of Michigan-Flint, University of Connecticut, McGill University",
      "link": "https://arxiv.org/pdf/2512.15925",
      "code": null,
      "tags": [
        "natural language processing",
        "SocialStoryFrames",
        "SSF-Generator",
        "SSF-Classifier",
        "narrative theory",
        "linguistic pragmatics",
        "taxonomy",
        "reader response"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces SocialStoryFrames, a formalism and computational framework for modeling nuanced reader responses to social media stories, including inferences about author intent and affective reactions. It develops two models (SSF-Generator and SSF-Classifier) and applies them to a corpus of online narratives to analyze storytelling practices across communities. The main conclusion is that this approach enables scalable, context-sensitive research into the social dynamics of online storytelling.",
      "mindmap": ""
    },
    {
      "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions",
      "authors": "Armağan Amcalar, Eyup Cinar",
      "institution": "OpenServ Labs, Eskisehir Osmangazi University",
      "link": "https://arxiv.org/pdf/2512.15959",
      "code": null,
      "tags": [
        "llm inference",
        "bounded reasoning",
        "structured prompting",
        "instruction graphs",
        "mermaid",
        "chain-of-thought"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces BRAID, a bounded reasoning framework that uses Mermaid-based instruction graphs to structure prompts for LLMs, enabling them to reason structurally instead of through unbounded natural language. The method is shown to substantially increase reasoning accuracy and cost efficiency across multiple GPT model tiers on several benchmark datasets.",
      "mindmap": ""
    },
    {
      "title": "Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models",
      "authors": "Caner Erden",
      "institution": "Sakarya University of Applied Sciences",
      "link": "https://arxiv.org/pdf/2512.15973",
      "code": null,
      "tags": [
        "llm inference",
        "reinforcement learning",
        "low-rank approximation",
        "dynamic rank selection",
        "matrix perturbation theory",
        "singular value decomposition"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes Dynamic Rank Reinforcement Learning (DR-RL), a framework that uses a reinforcement learning agent to dynamically select low-rank approximations for Multi-Head Self-Attention in LLMs during inference, balancing accuracy and computational cost. It employs online matrix perturbation theory for efficient updates. Experiments show the method maintains accuracy equivalent to full-rank attention while significantly reducing FLOPs, especially for long sequences.",
      "mindmap": ""
    },
    {
      "title": "Cross-Language Bias Examination in Large Language Models",
      "authors": "Yuxuan Liang, Marwa Mahmoud",
      "institution": "Georgia Institute of Technology, University of Glasgow",
      "link": "https://arxiv.org/pdf/2512.16029",
      "code": null,
      "tags": [
        "fairness and bias evaluation",
        "multilingual bias evaluation",
        "BBQ benchmark",
        "prompt-based Implicit Association Test",
        "explicit bias",
        "implicit bias"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a multilingual bias evaluation framework that combines explicit bias assessment using the BBQ benchmark with implicit bias measurement via a prompt-based Implicit Association Test, applied across five languages. The results show significant variation in bias across languages, with Arabic and Spanish exhibiting higher stereotype bias, and reveal contrasting patterns between explicit and implicit bias, such as age having low explicit but high implicit bias. The study highlights the importance of cross-lingual bias analysis for developing equitable multilingual LLMs.",
      "mindmap": ""
    },
    {
      "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?",
      "authors": "Yuanning Feng, Sinan Wang, Zhengxiang Cheng, Yao Wan, Dongping Chen",
      "institution": "Huazhong University of Science and Technology, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.16041",
      "code": null,
      "tags": [
        "post-training",
        "LLM-as-a-Judge",
        "Sage evaluation suite",
        "local self-consistency",
        "global logical consistency",
        "situational preference",
        "panel-based judge",
        "deep reasoning",
        "finetuned LLM-as-a-Judge"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces Sage, a novel evaluation suite that assesses LLM-as-a-Judge without human annotation by measuring local self-consistency and global logical consistency. It finds that even top LLMs exhibit significant reliability problems, attributing this to situational preference, and shows that finetuning, panel-based judging, and deep reasoning can improve consistency. The work also questions the reliability of human annotation as a gold standard.",
      "mindmap": ""
    },
    {
      "title": "MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation",
      "authors": "Pengyu Wang, Shuchang Ye, Usman Naseem, Jinman Kim",
      "institution": "The University of Sydney, Macquarie University",
      "link": "https://arxiv.org/pdf/2512.16145",
      "code": null,
      "tags": [
        "multi-modal training",
        "reinforcement learning",
        "group relative policy optimization",
        "margin-based cosine similarity",
        "semantic-driven reinforcement learning",
        "large vision-language model"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a semantic-driven reinforcement learning method (MRG-R1) for medical report generation, which uses a report-level reward based on clinical findings similarity and Group Relative Policy Optimization to improve clinical correctness over token-level objectives. It achieves state-of-the-art performance on benchmark datasets, demonstrating that optimizing for semantic alignment meaningfully enhances clinical accuracy in generated reports.",
      "mindmap": ""
    },
    {
      "title": "Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning",
      "authors": "Yash Bhaskar, Sankalp Bahad, Parameswari Krishnamurthy",
      "institution": "IIIT Hyderabad",
      "link": "https://arxiv.org/pdf/2512.16147",
      "code": null,
      "tags": [
        "natural language processing",
        "RoBERTa",
        "multi-task learning",
        "transformer models",
        "code-mixed text",
        "hate speech detection",
        "fake narratives"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a dual-head RoBERTa model with multi-task learning to detect hate speech driven by fake narratives (Faux-Hate) in code-mixed Hindi-English text. It addresses binary classification and target/severity prediction tasks. The system achieved competitive results, demonstrating the effectiveness of multi-task learning for this complex problem.",
      "mindmap": ""
    },
    {
      "title": "Science Consultant Agent",
      "authors": "Karthikeyan K, Philip Wu, Xin Tang, Alexandre Alves",
      "institution": "Duke University, Amazon",
      "link": "https://arxiv.org/pdf/2512.16171",
      "code": null,
      "tags": [
        "others",
        "Retrieval-Augmented Generation (RAG)",
        "fine-tuning",
        "knowledge distillation",
        "prompting",
        "AutoML"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Science Consultant Agent, a web-based AI tool that uses structured questionnaires, literature-backed recommendations, and prototype generation to guide practitioners in selecting optimal AI modeling strategies. It aims to prevent resource misallocation by providing evidence-based guidance, moving beyond brute-force exploration or example-induced bias to accelerate development.",
      "mindmap": ""
    },
    {
      "title": "An Information-Theoretic Framework for Robust Large Language Model Editing",
      "authors": "Qizhou Chen, Chengyu Wang, Taolin Zhang, Xiaofeng He",
      "institution": "East China Normal University, Alibaba Group, Hefei University of Technology",
      "link": "https://arxiv.org/pdf/2512.16227",
      "code": null,
      "tags": [
        "post-training",
        "information bottleneck theory",
        "gradient-based updates",
        "knowledge editing",
        "locate-then-edit",
        "transformer patching"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a novel model editing framework called the Information Bottleneck Knowledge Editor (IBKE), which uses information bottleneck theory to compress and isolate essential information for making precise, generalizable knowledge corrections in LLMs. The method leverages compact latent representations to guide gradient-based updates, minimizing disruption to unrelated model behaviors. The authors demonstrate that IBKE achieves state-of-the-art accuracy and improved generality and specificity of edits across multiple LLM architectures and benchmark tasks.",
      "mindmap": ""
    },
    {
      "title": "Sigma-Moe-Tiny Technical Report",
      "authors": "Qingguo Hu, Zhenghao Lin, Ziyue Yang, Yucheng Ding, Xiao Liu, Yuting Jiang, Ruizhe Wang, Tianyu Chen, Zhongxin Guo, Yifan Xiong, Rui Gao, Lei Qu, Jinsong Su, Peng Cheng, Yeyun Gong",
      "institution": "Microsoft Research",
      "link": "https://arxiv.org/pdf/2512.16248",
      "code": null,
      "tags": [
        "llm training",
        "mixture-of-experts",
        "load balancing",
        "progressive sparsification",
        "fine-grained expert segmentation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Sigma-MoE-Tiny, a highly sparse mixture-of-experts language model that uses fine-grained expert segmentation with up to 96 experts per layer and activates only one expert per token, achieving a 40:1 total-to-activated parameter ratio. To address load balancing challenges in such extreme sparsity, the authors propose a progressive sparsification schedule, which ensures stable training without irrecoverable loss spikes. Despite activating only 0.5B parameters, the model achieves top-tier performance compared to counterparts of similar or larger scale, setting a new benchmark for sparsity in open-source MoE models.",
      "mindmap": ""
    },
    {
      "title": "QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems",
      "authors": "Yiliu Yang, Yilei Jiang, Qunzhong Wang, Yingshui Tan, Xiaoyong Zhu, Sherman S.M. Chow, Bo Zheng, Xiangyu Yue",
      "institution": "The Chinese University of Hong Kong, Alibaba Group",
      "link": "https://arxiv.org/pdf/2512.16279",
      "code": null,
      "tags": [
        "others",
        "sequent safety",
        "multi-agent guard",
        "state tracker",
        "policy verifier",
        "threat watcher",
        "referee",
        "machine-checkable rules",
        "predicate updater"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes QuadSentinel, a four-agent supervisory framework that compiles natural language safety policies into machine-checkable rules using sequents and enforces them online in multi-agent systems. It demonstrates improved guardrail accuracy and rule recall while reducing false positives compared to single-agent baselines on standard benchmarks. The approach allows for safe deployment without modifying the core agents.",
      "mindmap": ""
    },
    {
      "title": "Adaptation of Agentic AI",
      "authors": "Pengcheng Jiang, Jiacheng Lin, Zhiyi Shi, Zifeng Wang, Luxi He, Yichen Wu, Ming Zhong, Peiyang Song, Qizheng Zhang, Heng Wang, Xueqiang Xu, Hanwen Xu, Pengrui Han, Dylan Zhang, Jiashuo Sun, Chaoqi Yang, Kun Qian, Tian Wang, Changran Hu, Manling Li, Quanzheng Li, Hao Peng, Sheng Wang, Jingbo Shang, Chao Zhang, Jiaxuan You, Liyuan Liu, Pan Lu, Yu Zhang, Heng Ji, Yejin Choi, Dawn Song, Jimeng Sun, Jiawei Han",
      "institution": "UIUC, Stanford, Princeton, Harvard, UW, Caltech, UC Berkeley, UCSD, Georgia Tech, Northwestern, TAMU, Unity",
      "link": "https://arxiv.org/pdf/2512.16301",
      "code": null,
      "tags": [
        "agentic AI adaptation",
        "agent adaptation",
        "tool adaptation",
        "tool-execution-signaled",
        "agent-output-signaled",
        "agent-agnostic",
        "agent-supervised",
        "SFT",
        "RL",
        "VR methods",
        "Toolformer",
        "ToolLLM",
        "DeepRetrieval",
        "Prover-V2",
        "DeepSeek-R1",
        "Kimi-1.5",
        "ReTool",
        "Search-R1",
        "HuggingGPT",
        "ViperGPT",
        "Subagent-as-Tool",
        "Agentic Memory",
        "Reflexion",
        "Memento",
        "SWE-Grep",
        "Tab-RL"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a systematic framework for adapting agentic AI systems, categorizing adaptations into agent adaptation (tool-execution-signaled and agent-output-signaled) and tool adaptation (agent-agnostic and agent-supervised). It reviews representative methods in each category, analyzes their trade-offs, and provides practical guidance for selecting adaptation strategies. The work aims to offer a conceptual foundation and roadmap for building more capable, efficient, and reliable agentic AI systems.",
      "mindmap": ""
    },
    {
      "title": "Agent Tools Orchestration Leaks More: Dataset, Benchmark, and Mitigation",
      "authors": "Yuxuan Qiao, Dongqin Liu, Hongchang Yang, Wei Zhou, Songlin Hu",
      "institution": "Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.16310",
      "code": null,
      "tags": [
        "llm inference",
        "Tools Orchestration Privacy Risk (TOP-R)",
        "TOP-Bench",
        "Privacy Enhancement Principle (PEP)",
        "H-Score",
        "Risk Leakage Rate (RLR)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper identifies and studies a new privacy risk in single-agent, multi-tool LLM architectures, termed Tools Orchestration Privacy Risk (TOP-R), where agents can synthesize sensitive information from aggregated tool outputs. It introduces a benchmark (TOP-Bench) and a mitigation method called the Privacy Enhancement Principle (PEP). The main conclusion is that TOP-R is a severe and prevalent risk in current models, but the proposed PEP method can effectively reduce leakage and improve the safety-robustness trade-off.",
      "mindmap": ""
    },
    {
      "title": "Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs",
      "authors": "Sara Papi, Javier Garcia Gilabert, Zachary Hopton, Vilém Zouhar, Carlos Escolano, Gerard I. Gállego, Jorge Iranzo-Sánchez, Ahrii Kim, Dominik Macháček, Patricia Schmidtova, Maike Züfle",
      "institution": "Fondazione Bruno Kessler, Barcelona Supercomputing Center, University of Zurich, ETH Zurich, Universitat Politècnica de Catalunya, Universitat Politècnica de València, AI-Bio Convergence Research Institute, Charles University, KIT",
      "link": "https://arxiv.org/pdf/2512.16378",
      "code": null,
      "tags": [
        "multi-modal inference",
        "SpeechLLMs",
        "cascaded systems",
        "speech foundation models",
        "speech-to-text translation",
        "benchmarking",
        "Whisper",
        "SeamlessM4T",
        "Gemma",
        "Tower+"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces the \"Hearing to Translate\" test suite to benchmark SpeechLLMs against cascaded and direct speech-to-text translation systems. It finds that cascaded systems, which combine speech recognition with LLM-based translation, remain the most reliable overall, while current SpeechLLMs only match them in specific scenarios. The study concludes that integrating an LLM, either within the model or in a pipeline, is essential for high-quality speech translation.",
      "mindmap": ""
    },
    {
      "title": "Topic Modelling Black Box Optimization",
      "authors": "Roman Akramov, Artem Khamatullin, Svetlana Glazyrina, Maksim Kryzhanovskiy, Roman Ischenko",
      "institution": "Lomonosov Moscow State University, Institute for Artificial Intelligence, Lomonosov Moscow State University",
      "link": "https://arxiv.org/pdf/2512.16445",
      "code": null,
      "tags": [
        "hyperparameter optimization",
        "latent dirichlet allocation",
        "black-box optimization",
        "genetic algorithm",
        "evolution strategy",
        "preferential amortized black-box optimization",
        "sharpness-aware black-box optimization"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper formulates selecting the number of topics in Latent Dirichlet Allocation (LDA) as a discrete black-box optimization problem. It compares evolutionary methods (GA, ES) against learned amortized optimizers (PABBO, SABBO), finding that the amortized approaches are substantially more sample- and time-efficient, with SABBO often finding a near-optimal topic number after essentially a single evaluation.",
      "mindmap": ""
    },
    {
      "title": "Plain language adaptations of biomedical text using LLMs: Comparision of evaluation metrics",
      "authors": "Primoz Kocbek, Leon Kopitar, Gregor Stiglic",
      "institution": "University of Maribor, University of Ljubljana, University of Edinburgh",
      "link": "https://arxiv.org/pdf/2512.16530",
      "code": null,
      "tags": [
        "natural language processing",
        "text simplification",
        "prompt engineering",
        "fine-tuning",
        "Flesch-Kincaid",
        "SMOG",
        "SARI",
        "BERTScore",
        "G-Eval",
        "Likert scale"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates using Large Language Models (LLMs) like GPT-4o to simplify biomedical texts for better health literacy, comparing methods such as prompt templates, a two-agent approach, and fine-tuning. It concludes that the GPT-4o-mini model performed best, while fine-tuning underperformed, and that the LLM-based G-Eval metric aligned well with human qualitative assessments.",
      "mindmap": ""
    },
    {
      "title": "Needle in the Web: A Benchmark for Retrieving Targeted Web Pages in the Wild",
      "authors": "Yumeng Wang, Tianyu Fan, Lingrui Xu, Chao Huang",
      "institution": "Tsinghua University, The University of Hong Kong",
      "link": "https://arxiv.org/pdf/2512.16553",
      "code": null,
      "tags": [
        "others",
        "fuzzy exploratory search",
        "benchmark",
        "web retrieval",
        "semantic ambiguity",
        "agent evaluation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces the \"Needle in the Web\" benchmark, designed to evaluate search agents and LLMs on retrieving web pages for ambiguous, exploratory queries. The method involves generating queries of controllable difficulty based on factual claims from web content. The main conclusion is that current LLMs and search agents struggle significantly with this fuzzy retrieval task, achieving low accuracy and highlighting it as an open challenge.",
      "mindmap": ""
    },
    {
      "title": "Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics",
      "authors": "Iker García-Ferrero, David Montero, Roman Orus",
      "institution": "- **link:** https://arxiv.org/pdf/2512.16602",
      "link": "https://arxiv.org/pdf/2512.16602",
      "code": null,
      "tags": [],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "",
      "mindmap": ""
    },
    {
      "title": "DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI",
      "authors": "Hao Liang, Xiaochen Ma, Zhou Liu, Zhen Hao Wong, Zhengyang Zhao, Zimo Meng, Runming He, Chengyu Shen, Qifeng Cai, Zhaoyang Han, Meiyi Qiang, Yalin Feng, Tianyi Bai, Zewei Pan, Ziyi Guo, Yizhen Jiang, Jingwen Deng, Qijie You, Peichao Lai, Tianyu Guo, Chi Hsu Tsai, Hengyi Feng, Rui Hu, Wenkai Yu, Junbo Niu, Bohan Zeng, Ruichuan An, Lu Ma, Jihao Huang, Yaowei Zheng, Conghui He, Linpeng Tang, Bin Cui, Weinan E, Wentao Zhang",
      "institution": "Peking University, Institute for Advanced Algorithms Research, OriginHub Technology, OpenDataLab, Shanghai Artificial Intelligence Laboratory",
      "link": "https://arxiv.org/pdf/2512.16676",
      "code": null,
      "tags": [
        "llm training",
        "data preparation",
        "workflow automation",
        "pipeline construction",
        "operator synthesis",
        "natural-language specification",
        "model-in-the-loop data generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces DataFlow, an LLM-driven framework that provides system-level abstractions and a PyTorch-style API for building modular, reusable, and automated data preparation pipelines. It includes a DataFlow-Agent to translate natural language into executable workflows and demonstrates that its generated data consistently improves downstream LLM performance across multiple domains, establishing a foundation for scalable, data-centric AI development.",
      "mindmap": ""
    },
    {
      "title": "GinSign: Grounding Natural Language Into System Signatures for Temporal Logic Translation",
      "authors": "William English, Chase Walker, Dominic Simon, Rickard Ewetz",
      "institution": "University of Florida",
      "link": "https://arxiv.org/pdf/2512.16770",
      "code": null,
      "tags": [
        "others",
        "natural language to temporal logic translation",
        "grounding model",
        "system signature",
        "hierarchical classification",
        "masked language models",
        "logical equivalence"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes GinSign, a framework that grounds natural language into system signatures for temporal logic translation by using a hierarchical grounding model. This model decomposes the task into structured classification, allowing the use of smaller masked language models instead of large LLMs. Experiments show the framework achieves 95.5% grounded logical-equivalence, a 1.4x improvement over prior methods, enabling reliable downstream model checking.",
      "mindmap": ""
    },
    {
      "title": "From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs",
      "authors": "Shubham Mishra, Samyek Jain, Gorang Mehrishi, Shiv Tiwari, Harsh Sharma, Pratik Narang, Dhruv Kumar",
      "institution": "Birla Institute of Technology and Science, Pilani, Carnegie Mellon University",
      "link": "https://arxiv.org/pdf/2512.16795",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation",
        "deductive reasoning",
        "conflict-aware trust-score",
        "reasoning-trace-augmented framework",
        "supervised fine-tuning"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a reasoning-trace-augmented RAG framework that integrates a three-stage deductive reasoning process (document adjudication, conflict analysis, and grounded synthesis) to handle conflicting or unreliable retrieved evidence. It introduces a Conflict-Aware Trust-Score (CATS) evaluation pipeline. The method, tested with models like Qwen, shows substantial improvements in answer correctness and behavioral adherence over baseline RAG systems.",
      "mindmap": ""
    },
    {
      "title": "Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs",
      "authors": "William English, Dominic Simon, Sumit Kumar Jha, Rickard Ewetz",
      "institution": "University of Florida, Florida International University",
      "link": "https://arxiv.org/pdf/2512.16814",
      "code": null,
      "tags": [
        "natural language processing",
        "Grammar Forced Translation (GraFT)",
        "temporal logic translation",
        "solution space reduction",
        "atomic propositions lifting",
        "large language models"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes Grammar Forced Translation (GraFT), a framework that improves the translation of natural language to temporal logic by restricting the language model's valid output tokens at each step, thereby reducing the solution space. This method enhances both lifting of atomic propositions and the final translation phase. The results show that GraFT improves end-to-end and out-of-domain translation accuracy compared to state-of-the-art approaches.",
      "mindmap": ""
    },
    {
      "title": "LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference",
      "authors": "Harsh Vardhan Bansal",
      "institution": "Amazon Web Services",
      "link": "https://arxiv.org/pdf/2512.16843",
      "code": null,
      "tags": [
        "llm inference",
        "layer-wise caching",
        "semantic similarity",
        "fingerprinting",
        "adaptive eviction",
        "key-value cache",
        "transformer acceleration"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces LLMCache, a model-agnostic layer-wise caching framework that accelerates transformer inference by reusing intermediate activations for semantically similar inputs. It uses a lightweight fingerprinting mechanism for matching and adaptive strategies for cache management. Experiments show up to 3.1x inference speedup with minimal accuracy degradation, demonstrating its practicality for real-world deployment.",
      "mindmap": ""
    },
    {
      "title": "Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image",
      "authors": "Yushi Hu, Reyhane Askari-Hemmat, Melissa Hall, Emily Dinan, Luke Zettlemoyer, Marjan Ghazvininejad",
      "institution": "Meta (FAIR at Meta Superintelligence Labs)",
      "link": "https://arxiv.org/pdf/2512.16899",
      "code": null,
      "tags": [
        "multi-modal training",
        "reward models",
        "multimodal benchmark",
        "preference pairs",
        "LLM-as-a-judge",
        "Best-of-N sampling",
        "ensemble filtering"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Multimodal RewardBench 2 (MMRB2), a comprehensive benchmark for evaluating reward models on multimodal tasks involving interleaved text and image sequences. It finds that current models like Gemini 3 Pro achieve 75-80% accuracy, which is still below human performance (&gt;90%), and that benchmark performance strongly correlates with downstream task success.",
      "mindmap": ""
    },
    {
      "title": "In-Context Algebra",
      "authors": "Eric Todd, Jannik Brinkmann, Rohit Gandikota, David Bau",
      "institution": "Northeastern University, TU Clausthal",
      "link": "https://arxiv.org/pdf/2512.16902",
      "code": null,
      "tags": [
        "transformer interpretability",
        "transformers",
        "in-context learning",
        "algebraic groups",
        "symbolic reasoning",
        "causal tests",
        "attention mechanisms"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper trains small transformers on a novel arithmetic task where token meanings are variable and defined only within each sequence. It finds that, instead of learning geometric embeddings, the models develop symbolic reasoning mechanisms like commutative copying and closure-based cancellation. This demonstrates that transformer reasoning strategies shift from geometric to symbolic when deprived of fixed token embeddings.",
      "mindmap": ""
    },
    {
      "title": "Impacts of Racial Bias in Historical Training Data for News AI",
      "authors": "Rahul Bhargava, Malene Hornstrup Jespersen, Emily Boardman Ndulue, Vivica Dsouza",
      "institution": "Northeastern University, University of Copenhagen, Media Ecosystems Analysis Group",
      "link": "https://arxiv.org/pdf/2512.16901",
      "code": null,
      "tags": [
        "algorithmic auditing",
        "multi-label classifier",
        "explainable AI",
        "word2vec",
        "New York Times Annotated Corpus"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper investigates racial bias in a multi-label text classifier trained on the New York Times Annotated Corpus using word2vec and explainable AI methods. It finds that a problematic \"blacks\" label acts as a general \"racism detector\" but fails on modern examples, demonstrating how historical training data embeds biases into AI models. The study highlights the tension for newsrooms in adopting AI tools while mitigating the reproduction of historical stereotypes in news coverage.",
      "mindmap": ""
    },
    {
      "title": "Exploration v.s. Exploitation: Rethinking RLVR through Clipping, Entropy, and Spurious Reward",
      "authors": "Peter Chen, Xiaopeng Li, Ziniu Li, Wotao Yin, Xi Chen, Tianyi Lin",
      "institution": "Columbia University, The Chinese University of Hong Kong, Shenzhen, Alibaba DAMO Academy, New York University Stern School of Business",
      "link": "https://arxiv.org/pdf/2512.16912",
      "code": null,
      "tags": [
        "reinforcement learning",
        "RLVR",
        "GRPO",
        "policy entropy",
        "spurious rewards",
        "clipping bias",
        "exploration-exploitation trade-off"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates the exploration-exploitation trade-off in Reinforcement Learning with Verifiable Rewards (RLVR) for improving LLM reasoning. It finds that spurious rewards, combined with clipping bias, reduce policy entropy to produce more confident outputs, which enhances performance, while entropy minimization alone is insufficient. The authors propose a reward-misalignment model to explain why spurious rewards can be beneficial beyond simple data contamination.",
      "mindmap": ""
    },
    {
      "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning",
      "authors": "Qihao Liu, Luoxin Ye, Wufei Ma, Yu-Cheng Chou, Alan Yuille",
      "institution": "Johns Hopkins University",
      "link": "https://arxiv.org/pdf/2512.16917",
      "code": null,
      "tags": [
        "post-training",
        "adversarial reinforcement learning",
        "process reward models",
        "step-level rewards",
        "reasoning chain partitioning",
        "joint training",
        "discriminator"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces Generative Adversarial Reasoner, a framework that jointly trains an LLM reasoner and an LLM-based discriminator using adversarial reinforcement learning to provide dense, step-level rewards for improving reasoning. This method enhances sample efficiency and reasoning quality by co-evolving the models to detect and correct process errors. It demonstrates consistent performance gains on mathematical benchmarks over standard RL post-training baselines.",
      "mindmap": ""
    },
    {
      "title": "LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts",
      "authors": "Krunal Jesani, Dmitry Ignatov, Radu Timofte",
      "institution": "University of Würzburg",
      "link": "https://arxiv.org/pdf/2512.14706",
      "code": null,
      "tags": [
        "multi-modal training",
        "neural architecture search",
        "large language models",
        "image captioning",
        "prompt engineering",
        "CNN encoder",
        "LSTM",
        "GRU",
        "Transformer",
        "BLEU-4"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper presents NN-Caption, a pipeline that uses a large language model (LLM) to automatically generate runnable image-captioning model architectures by composing CNN encoders and sequence decoders under a strict API. The method successfully produced dozens of models, with over half training successfully, demonstrating the promise of LLM-guided neural architecture search while highlighting challenges like code hallucinations.",
      "mindmap": ""
    },
    {
      "title": "SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI",
      "authors": "Ryan Cartularo",
      "institution": "The University of Texas at Austin",
      "link": "https://arxiv.org/pdf/2512.14712",
      "code": null,
      "tags": [
        "multi-modal training",
        "Mixture-of-Experts (MoE)",
        "Hierarchical Gated Attention Network",
        "CatBoost meta-learner",
        "multimodal fusion",
        "deep fusion",
        "expert stacking",
        "Quad-Modal Ensemble"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper compares two multimodal AI architectures for sepsis prediction and antibiotic selection: a complex end-to-end deep fusion model (SepsisFusionFormer) and a leaner, context-aware Mixture-of-Experts stacking model (SepsisLateFusion). The main conclusion is that for this high-stakes, data-sparse clinical domain, the interpretable expert stacking approach, which treats modalities as orthogonal experts and uses a CatBoost meta-learner, significantly outperformed the deep fusion model, achieving state-of-the-art predictive performance and enabling a prescriptive window for intervention.",
      "mindmap": ""
    },
    {
      "title": "SoMe: A Realistic Benchmark for LLM-based Social Media Agents",
      "authors": "Dizhan Xue, Jing Cui, Shengsheng Qian, Chuanrui Hu, Changsheng Xu",
      "institution": "Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Tianjin University of Technology; Nanjing University of Posts and Telecommunications; Peng Cheng Laboratory",
      "link": "https://arxiv.org/pdf/2512.14720",
      "code": null,
      "tags": [
        "others",
        "SoMe benchmark",
        "social media agents",
        "LLM-based agents",
        "agent tools",
        "task evaluation",
        "quantitative analysis",
        "qualitative analysis"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces SoMe, a comprehensive benchmark for evaluating LLM-based social media agents across diverse tasks using real social media data and agent tools. The evaluation shows that current LLMs, both closed and open-source, perform unsatisfactorily on these realistic social media agent tasks. SoMe serves as a challenging testbed to advance future social media agent development.",
      "mindmap": ""
    },
    {
      "title": "NoveltyRank: Estimating Conceptual Novelty of AI Papers",
      "authors": "Zhengxu Yan, Han Li, Yuming Feng",
      "institution": "Stanford University",
      "link": "https://arxiv.org/pdf/2512.14738",
      "code": null,
      "tags": [
        "natural language processing",
        "binary classification",
        "pairwise comparison",
        "semantic similarity",
        "SPECTER2",
        "fine-tuning",
        "Qwen3-4B-Instruct-2507",
        "SciBERT"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes NoveltyRank, a model that estimates the conceptual novelty of AI papers using title, abstract, and semantic similarity to prior literature, evaluated through binary classification and pairwise comparison tasks. It fine-tunes Qwen3-4B-Instruct-2507 and SciBERT, benchmarking against GPT-5.1, and finds that task formulation and modeling choices significantly impact performance, with the implementation made publicly available.",
      "mindmap": ""
    },
    {
      "title": "Revisiting the Reliability of Language Models in Instruction-Following",
      "authors": "Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu",
      "institution": "Tsinghua University, Ant Group",
      "link": "https://arxiv.org/pdf/2512.14754",
      "code": null,
      "tags": [
        "llm evaluation",
        "instruction-following",
        "reliability",
        "data augmentation",
        "benchmark",
        "IFEval++",
        "reliable@k"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate \"cousin prompts\" for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.",
      "mindmap": ""
    },
    {
      "title": "Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis",
      "authors": "Richard Ackermann, Simeon Emanuilov",
      "institution": "RA Software, Sofia University “St. Kliment Ohridski”",
      "link": "https://arxiv.org/pdf/2512.14801",
      "code": null,
      "tags": [
        "large language models",
        "transformer architecture",
        "structural hallucination",
        "Licensing Oracle",
        "hybrid systems",
        "statistical ontology"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper argues that hallucination in LLMs is an architectural inevitability of transformers, which model token co-occurrence rather than the world, and demonstrates through a Licensing Oracle that external truth-validation modules are required for reliable abstention. It concludes that hallucination is a structural property, not a correctable incentive problem, necessitating hybrid systems to separate linguistic fluency from epistemic responsibility.",
      "mindmap": ""
    },
    {
      "title": "Audio MultiChallenge: A Multi-Turn Evaluation of Spoken Dialogue Systems on Natural Human Interaction",
      "authors": "Advait Gosai, Tyler Vuong, Utkarsh Tyagi, Steven Li, Wenjia You, Miheer Bavare, Arda Uçar, Zhongwang Fang, Brian Jang, Bing Liu, Yunzhong He",
      "institution": "Scale AI",
      "link": "https://arxiv.org/pdf/2512.14865",
      "code": null,
      "tags": [
        "multi-modal inference",
        "end-to-end spoken dialogue systems",
        "audio language models",
        "multi-turn evaluation",
        "speech-to-speech",
        "audio-native benchmark",
        "inference memory",
        "instruction retention",
        "self coherence",
        "voice editing"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces Audio MultiChallenge, a benchmark for evaluating end-to-end spoken dialogue systems on natural, multi-turn conversations. It extends a text-based framework with a new \"Voice Editing\" axis and audio-specific augmentations, using a hybrid pipeline to curate conversations with natural disfluencies. The evaluation shows even top models like Gemini 3 Pro Preview struggle, highlighting difficulties in tracking audio edits, cues, and long context in spoken dialogue.",
      "mindmap": ""
    },
    {
      "title": "Task Matrices: Linear Maps for Cross-Model Finetuning Transfer",
      "authors": "Darrin O' Brien, Dhikshith Gajulapalli, Eric Xia",
      "institution": "Algoverse AI Research, Brown University",
      "link": "https://arxiv.org/pdf/2512.14880",
      "code": null,
      "tags": [
        "model adaptation",
        "task matrix",
        "linear transformation",
        "finetuning",
        "linear probe",
        "embedding space"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces the concept of a \"task matrix,\" a linear transformation that maps a base model's embedding state to a finetuned model's state. It demonstrates that applying this matrix to a base model can outperform linear probes and sometimes approach full finetuning performance across vision and text models on various datasets. The results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures.",
      "mindmap": ""
    },
    {
      "title": "Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media",
      "authors": "Massimiliano Fadda, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino",
      "institution": "University of Cagliari, The Open University",
      "link": "https://arxiv.org/pdf/2512.14887",
      "code": null,
      "tags": [
        "llm inference",
        "large language models",
        "knowledge graphs",
        "viewpoint classification",
        "fine-tuning",
        "wikidata",
        "semantic enrichment"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper improves a pipeline for analyzing political viewpoints in news by fine-tuning Large Language Models for classification and enriching claim representations with semantic actor descriptions from Wikidata. The integrated approach, evaluated on UK immigration debate data, shows that combining fine-tuned LLMs with knowledge graph context yields the best performance, particularly with models capable of processing long inputs.",
      "mindmap": ""
    },
    {
      "title": "DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline",
      "authors": "Houman Kazemzadeh, Kiarash Mokhtari Dizaji, Seyed Reza Tavakoli, Farbod Davoodi, MohammadReza KarimiNejad, Parham Abed Azad, Ali Sabzi, Armin Khosravi, Siavash Ahmadi, Mohammad Hossein Rohban, Glolamali Aminian, Tahereh Javaheri",
      "institution": "Tehran University of Medical Sciences, Sharif University of Technology, Amir Kabir University of Technology, Missouri University of Science and Technology, The Alan Turing Institute, Boston University",
      "link": "https://arxiv.org/pdf/2512.14896",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation",
        "structured drug knowledge",
        "pharmacy question-answering",
        "external knowledge integration"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces DrugRAG, a three-step retrieval-augmented generation pipeline that integrates external structured drug knowledge into LLM prompts to improve accuracy on pharmacy QA tasks. It demonstrates that this external method enhances performance across multiple models without modifying their architecture, providing a practical approach for evidence-based AI in pharmacy.",
      "mindmap": ""
    },
    {
      "title": "Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models",
      "authors": "George-Andrei Dima, Dumitru-Clementin Cercel",
      "institution": "National University of Science and Technology POLITEHNICA Bucharest",
      "link": "https://arxiv.org/pdf/2512.14926",
      "code": null,
      "tags": [
        "multi-modal training",
        "LoRA",
        "dataset translation",
        "visual question answering",
        "instruction tuning",
        "parameter-efficient fine-tuning"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a parameter-efficient method for adapting vision-language models to Romanian by translating the Flickr30k dataset and generating QA pairs, then fine-tuning models like LLaMA, LLaVA, and Qwen2 using LoRA. The results show significant improvements in Romanian visual QA and image captioning, with the Qwen2-VL-RoVQA model achieving the best performance and reduced grammatical errors.",
      "mindmap": ""
    },
    {
      "title": "Cross-Tokenizer Likelihood Scoring Algorithms for Language Model Distillation",
      "authors": "Buu Phan, Ashish Khisti, Karen Ullrich",
      "institution": "University of Toronto, Meta AI",
      "link": "https://arxiv.org/pdf/2512.14954",
      "code": null,
      "tags": [
        "llm training",
        "knowledge distillation",
        "byte-pair encoding",
        "cross-tokenizer likelihood scoring",
        "vocabulary misalignment",
        "next-token probability"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a method for cross-tokenizer likelihood scoring to enable knowledge distillation between language models with different vocabularies. It leverages the recursive structure of Byte-Pair Encoding to compute exact or approximate next-token probabilities. The approach reduces memory footprint and improves model performance on tasks like mathematical reasoning compared to baseline distillation methods.",
      "mindmap": ""
    },
    {
      "title": "Prompt Repetition Improves Non-Reasoning LLMs",
      "authors": "Yaniv Leviathan, Matan Kalman, Yossi Matias",
      "institution": "Google Research",
      "link": "https://arxiv.org/pdf/2512.14982",
      "code": null,
      "tags": [
        "llm inference",
        "prompt repetition",
        "causal language model",
        "attention mechanism",
        "non-reasoning tasks"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a simple method of repeating the input prompt to improve the performance of LLMs on non-reasoning tasks. This technique allows all prompt tokens to attend to each other within the causal attention mechanism, addressing order sensitivity. The authors demonstrate that this method boosts accuracy for models like Gemini, GPT, Claude, and Deepseek without increasing output length or latency.",
      "mindmap": ""
    },
    {
      "title": "Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams",
      "authors": "Yiming Cui, Xin Yao, Yuxuan Qin, Xin Li, Shijin Wang, Guoping Hu",
      "institution": "State Key Laboratory of Cognitive Intelligence, iFLYTEK AI Research",
      "link": "https://arxiv.org/pdf/2512.14989",
      "code": null,
      "tags": [
        "multi-modal inference",
        "multimodal reasoning",
        "chain-of-thought prompting",
        "ablation studies",
        "occlusion-based interpretability",
        "benchmark evaluation",
        "modality fusion"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically evaluates 40 multimodal large language models on a benchmark of chemistry Olympiad questions requiring visual and textual reasoning. The core method involves using chain-of-thought prompting and interpretability techniques like ablation and occlusion. The main conclusion is that current models struggle with modality fusion, but chain-of-thought improves both accuracy and visual grounding, revealing critical limitations in scientific reasoning.",
      "mindmap": ""
    },
    {
      "title": "DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding",
      "authors": "Ruiyi Zhang, Peijia Qin, Qi Cao, Pengtao Xie",
      "institution": "University of California, San Diego",
      "link": "https://arxiv.org/pdf/2512.15000",
      "code": null,
      "tags": [
        "post-training",
        "Process Reward Model (PRM)",
        "Chain-of-Function",
        "meta-learning",
        "label correction",
        "bi-level optimization",
        "test-time scaling",
        "LiveCodeBench"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes DreamPRM-Code, a process reward model for coding that treats functions as reasoning steps using a Chain-of-Function strategy and employs a meta-learning-based label correction mechanism to refine noisy intermediate training labels. It achieves state-of-the-art performance on LiveCodeBench, surpassing OpenAI o4-mini.",
      "mindmap": ""
    },
    {
      "title": "HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles",
      "authors": "Yunheng Wang, Yixiao Feng, Yuetong Fang, Shuning Zhang, Tan Jing, Jian Li, Xiangrui Jiang, Renjing Xu",
      "institution": "The Hong Kong University of Science and Technology (Guangzhou)",
      "link": "https://arxiv.org/pdf/2512.15047",
      "code": null,
      "tags": [
        "embodied navigation",
        "3D scene graphs",
        "hierarchical traversable graphs",
        "movable obstacles",
        "path planning",
        "scene understanding"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes HERO, a framework for building Hierarchical Traversable 3D Scene Graphs that model movable obstacles as pathways by capturing their interactivity and semantics. This redefinition of traversability allows for more efficient navigation planning in obstructed environments. The results show HERO significantly reduces path length in partially obstructed scenes and increases success rate in fully obstructed ones compared to baselines.",
      "mindmap": ""
    },
    {
      "title": "The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops",
      "authors": "Fanzhe Fu",
      "institution": "Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.15053",
      "code": null,
      "tags": [
        "llm inference",
        "Meta-Prompting Protocol",
        "Adversarial Trinity",
        "DSPy",
        "TextGrad",
        "textual gradients",
        "semantic computation graph"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic \"Observable Software Engineering\" for probabilistic models.",
      "mindmap": ""
    },
    {
      "title": "SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification",
      "authors": "Hongbo Wang, MaungMaung AprilPyone, Isao Echizen",
      "institution": "The University of Tokyo, National Institute of Informatics",
      "link": "https://arxiv.org/pdf/2512.15052",
      "code": null,
      "tags": [
        "multi-modal inference",
        "neuron-level intervention",
        "expertise-weighted soft suppression",
        "MM-TOXIC-QA",
        "white-box detoxification",
        "SGM*"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes SGM, a neuron-level intervention method that selectively recalibrates toxic expert neurons in multimodal large language models (MLLMs) using expertise-weighted soft suppression to reduce harmful outputs. Experiments show SGM significantly cuts toxicity rates from 48.2% to 2.5% while preserving model fluency and reasoning, and it can be combined with other methods for stronger safety.",
      "mindmap": ""
    },
    {
      "title": "The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems",
      "authors": "Debu Sinha",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15068",
      "code": null,
      "tags": [
        "retrieval-augmented generation",
        "conformal prediction",
        "semantic similarity",
        "natural language inference",
        "hallucination detection",
        "text embeddings"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper applies conformal prediction to provide statistical guarantees for hallucination detection in RAG systems, rigorously evaluating embedding-based methods. It finds that while these methods work on synthetic data, they fail on real benchmarks due to the \"semantic illusion,\" where plausible hallucinations remain semantically similar to source documents. The study concludes that embedding-based detection is insufficient for production, as reasoning-based methods like GPT-4 as a judge perform significantly better.",
      "mindmap": ""
    },
    {
      "title": "Quantifying Return on Security Controls in LLM Systems",
      "authors": "Richard Helder Moulton, Austin O'Brien, John D. Hastings",
      "institution": "Dakota State University",
      "link": "https://arxiv.org/pdf/2512.15081",
      "code": null,
      "tags": [
        "llm inference",
        "retrieval-augmented generation (RAG)",
        "Monte Carlo simulation",
        "loss exceedance curves",
        "Laplace's Rule of Succession",
        "adversarial probing",
        "Garak",
        "attribute-based access control (ABAC)",
        "named entity recognition (NER) redaction",
        "NeMo Guardrails"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a framework to quantify the financial return on security controls for LLM systems by simulating attacks on a RAG service, estimating attack success probabilities, and modeling potential losses with Monte Carlo methods. The main conclusion is that controls like ABAC and NER redaction significantly reduce expected financial losses and offer high return-on-control, whereas NeMo Guardrails provides minimal benefit in the tested scenarios.",
      "mindmap": ""
    },
    {
      "title": "From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?",
      "authors": "Aaron Mueller, Andrew Lee, Shruti Joshi, Ekdeep Singh Lubana, Dhanya Sridhar, Patrik Reizinger",
      "institution": "Boston University, Harvard University, Mila – Quebec AI Institute, Goodfire, University of Tübingen",
      "link": "https://arxiv.org/pdf/2512.15134",
      "code": null,
      "tags": [
        "interpretability",
        "sparse autoencoders",
        "sparse probes",
        "concept disentanglement",
        "steering experiments",
        "multi-concept evaluation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a multi-concept evaluation framework to test whether interpretability methods like sparse autoencoders and sparse probes recover disentangled and independently manipulable concept representations. It finds that features often correspond to single concepts, but concepts are distributed across many features, and steering one feature typically affects multiple concepts, indicating a lack of true independence. The results highlight that correlational metrics are insufficient for proving disentanglement and underscore the need for compositional evaluations in interpretability research.",
      "mindmap": ""
    },
    {
      "title": "MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers",
      "authors": "Xuanjun Zong, Zhiqi Shen, Lei Wang, Yunshi Lan, Chao Yang",
      "institution": "East China Normal University, National University of Singapore, Singapore Management University, Shanghai AI Laboratory",
      "link": "https://arxiv.org/pdf/2512.15163",
      "code": null,
      "tags": [
        "llm inference",
        "MCP (Model Context Protocol)",
        "safety benchmark",
        "multi-turn evaluation",
        "multi-server workflows",
        "attack taxonomy",
        "agentic systems"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces MCP-SafetyBench, a benchmark built on real Model Context Protocol servers to evaluate the safety of LLMs operating as agents across tools and services. It systematically tests models on multi-step, multi-server tasks across five domains, revealing significant safety vulnerabilities that escalate with task complexity. The results highlight the urgent need for improved defenses in real-world LLM agent deployments.",
      "mindmap": ""
    },
    {
      "title": "RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA",
      "authors": "Chao Zhang, Minghan Li, Tianrui Lv, Guodong Zhou",
      "institution": "Soochow University",
      "link": "https://arxiv.org/pdf/2512.15219",
      "code": null,
      "tags": [
        "knowledge-aware question answering",
        "knowledge graph",
        "chain-of-thought",
        "few-shot in-context learning",
        "relation-driven adaptive hop-count selection",
        "path guidance"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes RFKG-CoT, a method that enhances knowledge-aware question answering by dynamically selecting reasoning steps in a knowledge graph based on relations and using few-shot examples to guide large language models in understanding reasoning paths. It improves answer accuracy over previous methods by making the integration of knowledge graph evidence more adaptive and guided. Experiments show significant accuracy gains on multiple benchmarks.",
      "mindmap": ""
    },
    {
      "title": "Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024",
      "authors": "Yash Bhaskar, Parameswari Krishnamurthy",
      "institution": "IIIT Hyderabad",
      "link": "https://arxiv.org/pdf/2512.15226",
      "code": null,
      "tags": [
        "llm training",
        "fine-tuning",
        "LoRA",
        "zero-shot prompting",
        "few-shot prompting",
        "supervised fine-tuning",
        "transformer models"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper explores various methods for low-resource Indic language translation, including fine-tuning models like mT5 and IndicBart, using LoRA with IndicTrans2 and Llama 3, and prompting LLMs like Llama 3 and Mixtral. The results highlight the challenges of data scarcity and demonstrate the potential of fine-tuned large language models for these translation tasks.",
      "mindmap": ""
    },
    {
      "title": "Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning",
      "authors": "Yiliu Sun, Zicheng Zhao, Yang Wei, Yanfang Zhang, Chen Gong",
      "institution": "Nanjing University of Science and Technology, North University of China, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.15274",
      "code": null,
      "tags": [
        "llm training",
        "reinforcement learning with verifiable rewards",
        "progressive prefix-token policy optimization",
        "beginning lock-in effect",
        "prefix optimization",
        "continuation accumulated reward"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes Progressive Prefix-token Policy Optimization (PPPO), a reinforcement learning method that focuses on optimizing the initial prefix tokens of an LLM's reasoning output, based on the identified Beginning Lock-in Effect. It introduces strategies like Progressive Prefix Retention and Continuation Accumulated Reward to improve training efficiency. The method achieves significant accuracy improvements on reasoning tasks while using far fewer training tokens compared to standard approaches.",
      "mindmap": ""
    },
    {
      "title": "ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I",
      "authors": "Seok-Hyun Ga, Chun-Yen Chang",
      "institution": "Institute for Research Excellence in Learning Sciences, National Taiwan Normal University, Seoul National University, Universitas Negeri Malang",
      "link": "https://arxiv.org/pdf/2512.15298",
      "code": null,
      "tags": [
        "multi-modal inference",
        "multimodal reasoning",
        "perception-cognition gap",
        "calculation-conceptualization discrepancy",
        "process hallucination",
        "OCR",
        "AI-resistant questions"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This study evaluates the multimodal scientific reasoning of LLMs like GPT-4o and Gemini on the Korean CSAT Earth Science I exam under different input conditions. It finds that models suffer from fundamental cognitive flaws, such as a perception-cognition gap and calculation-conceptualization discrepancy, even with optimized inputs. The paper concludes by suggesting these vulnerabilities can be exploited to design AI-resistant assessment questions to ensure academic integrity.",
      "mindmap": ""
    },
    {
      "title": "Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies",
      "authors": "Charan Prakash Rathore, Saumi Ray, Dhruv Kumar",
      "institution": "Birla Institute of Technology and Science, Pilani",
      "link": "https://arxiv.org/pdf/2512.15312",
      "code": null,
      "tags": [
        "scientific information extraction",
        "zero-shot prompting",
        "few-shot prompting",
        "event-specific prompting",
        "reflection-based prompting",
        "in-context learning",
        "event extraction",
        "argument extraction"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper systematically evaluates six state-of-the-art LLMs using four prompting strategies (zero-shot, few-shot, event-specific, reflection-based) for extracting structured event and argument information from zeolite synthesis procedures. It finds that while LLMs achieve strong performance on high-level event classification, they show modest results on fine-grained parameter extraction, with advanced prompting offering minimal gains over zero-shot approaches. The conclusion is that precise scientific information extraction requires domain-adapted models, as current LLMs have fundamental limitations in capturing synthesis-specific nuances.",
      "mindmap": ""
    },
    {
      "title": "Adversarial versification in portuguese as a jailbreak operator in LLMs",
      "authors": "Joao Queiroz",
      "institution": "Federal University of Juiz de Fora",
      "link": "https://arxiv.org/pdf/2512.15353",
      "code": null,
      "tags": [
        "llm inference",
        "adversarial versification",
        "poetry jailbreak",
        "guardrail vulnerabilities",
        "semiotic-formal variation",
        "latent region displacement"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper investigates using versification, or rewriting prompts as poetry, as a method to bypass safety guardrails in aligned large language models. It concludes that this structural adversarial technique exploits a model's over-reliance on surface patterns, causing significant safety failures, and highlights a critical research gap for Portuguese due to its linguistic complexity.",
      "mindmap": ""
    },
    {
      "title": "Emotion Recognition in Signers",
      "authors": "Kotaro Funakoshi, Yaoxiong Zhu",
      "institution": "Institute of Science Tokyo",
      "link": "https://arxiv.org/pdf/2512.15376",
      "code": null,
      "tags": [
        "multi-modal training",
        "cross-lingual transfer",
        "temporal segment selection",
        "hand motion features",
        "textual emotion recognition",
        "facial expression analysis"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a new dataset for emotion recognition in Japanese Sign Language and addresses the challenges of overlapping grammatical/affective expressions and data scarcity using cross-lingual transfer from textual emotion recognition in spoken language. The authors demonstrate that selecting specific temporal segments and incorporating hand motion features significantly improves emotion recognition performance in signers, establishing a stronger baseline than spoken language LLMs.",
      "mindmap": ""
    },
    {
      "title": "Tracking Temporal Dynamics of Vector Sets with Gaussian Process",
      "authors": "Taichi Aida, Mamoru Komachi, Toshinobu Ogiso, Hiroya Takamura, Daichi Mochihashi",
      "institution": "Tokyo Metropolitan University, Hitotsubashi University, National Institute for Japanese Language and Linguistics, National Institute of Advanced Industrial Science and Technology, The Institute of Statistical Mathematics",
      "link": "https://arxiv.org/pdf/2512.15538",
      "code": null,
      "tags": [
        "temporal analysis",
        "Gaussian Process",
        "Random Fourier Features",
        "vector sets",
        "temporal dynamics",
        "low-dimensional visualization"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a method to model time-varying vector sets using infinite-dimensional Gaussian Processes, approximating the latent function with Random Fourier Features to obtain compact, comparable representations over time. It demonstrates effectiveness in capturing temporal dynamics in crime distributions and word embeddings, providing interpretable, low-dimensional visualizations of structural changes.",
      "mindmap": ""
    },
    {
      "title": "Evaluating Metrics for Safety with LLM-as-Judges",
      "authors": "Kester Clegg, Richard Hawkins, Ibrahim Habli, Tom Lawton",
      "institution": "University of York, Bradford Royal Infirmary",
      "link": "https://arxiv.org/pdf/2512.15617",
      "code": null,
      "tags": [
        "llm inference",
        "LLM-as-Judges",
        "weighted metrics",
        "confidence thresholds",
        "context sensitivity",
        "safety evaluation",
        "human review"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a safety evaluation method for LLMs in critical applications by focusing on evidence from LLM-as-Judges frameworks. It suggests using a basket of weighted metrics and context-sensitive error severity to lower risk, with low-confidence judgments triggering human review. The main conclusion is that such an approach can enhance the reliability of LLMs in safety-critical information flows.",
      "mindmap": ""
    },
    {
      "title": "How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness",
      "authors": "Darshita Rathore, Vineet Kumar, Chetna Bansal, Anindya Moitra",
      "institution": "PayPal",
      "link": "https://arxiv.org/pdf/2512.15634",
      "code": null,
      "tags": [
        "llm training",
        "Low-Rank Adaptation (LoRA)",
        "supervised fine-tuning (SFT)",
        "parameter-efficient fine-tuning (PEFT)",
        "rank sweep",
        "representational drift",
        "attention patterns"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper comprehensively evaluates the trade-offs between full supervised fine-tuning (SFT) and Low-Rank Adaptation (LoRA) for fine-tuning large language models. It finds that LoRA, especially at specific rank values, can achieve competitive or even superior performance to SFT on reasoning tasks, while also analyzing the structural changes in model representations.",
      "mindmap": ""
    },
    {
      "title": "PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning",
      "authors": "Xiaodi Li, Dingcheng Li, Rujun Gao, Mahmoud Zamani, Feng Mi, Latifur Khan",
      "institution": "Mayo Clinic, Google, Texas A&M University, The University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.15658",
      "code": null,
      "tags": [
        "continual learning",
        "energy-based model",
        "progressive parameter selection",
        "pseudo-sample generation",
        "catastrophic forgetting mitigation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces PPSEBM, a framework combining an Energy-Based Model with Progressive Parameter Selection to address catastrophic forgetting in continual learning for NLP tasks. It uses task-specific parameters and generates pseudo-samples from prior tasks to retain past knowledge. Experimental results show PPSEBM outperforms state-of-the-art methods in mitigating forgetting.",
      "mindmap": ""
    },
    {
      "title": "Explaining the Reasoning of Large Language Models Using Attribution Graphs",
      "authors": "Chase Walker, Rickard Ewetz",
      "institution": "University of Florida",
      "link": "https://arxiv.org/pdf/2512.15663",
      "code": null,
      "tags": [
        "interpretability",
        "attribution methods",
        "context attribution",
        "attribution graph",
        "CAGE",
        "faithfulness"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the CAGE framework, which uses an attribution graph to explain autoregressive LLMs by quantifying how each generated token is influenced by both the prompt and all prior tokens, preserving causality and row stochasticity. This approach improves the faithfulness of context attributions by accounting for inter-generational influences, achieving average gains of up to 40% over existing methods.",
      "mindmap": ""
    },
    {
      "title": "VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?",
      "authors": "Hongbo Zhao, Meng Wang, Fei Zhu, Wenzhuo Liu, Bolin Ni, Fanhu Zeng, Gaofeng Meng, Zhaoxiang Zhang",
      "institution": "Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, CAS; Tencent Hunyuan Team",
      "link": "https://arxiv.org/pdf/2512.15649",
      "code": null,
      "tags": [
        "multi-modal inference",
        "vision-text compression",
        "VTCBench",
        "DeepSeek-OCR",
        "Glyph",
        "VTC-Retrieval",
        "VTC-Reasoning",
        "VTC-Memory"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces VTCBench, the first benchmark to evaluate Vision-Language Models' ability to understand long context using Vision-Text Compression (VTC), a technique that converts long text into dense 2D images for token efficiency. The study systematically tests models on retrieval, reasoning, and memory tasks with VTC-compressed inputs. The main conclusion is that most VLMs perform poorly on long-context understanding with VTC, despite good OCR decoding, failing to capture long-range associations in the compressed visual context.",
      "mindmap": ""
    },
    {
      "title": "Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers",
      "authors": "Adam Karvonen, James Chua, Clément Dumas, Kit Fraser-Taliente, Subhash Kantamneni, Julian Minder, Euan Ong, Arnab Sen Sharma, Daniel Wen, Owain Evans, Samuel Marks",
      "institution": "MATS, Truthful AI, EPFL, ENS Paris-Saclay, Northeastern University, Anthropic",
      "link": "https://arxiv.org/pdf/2512.15674",
      "code": null,
      "tags": [
        "llm interpretability",
        "LatentQA",
        "Activation Oracles",
        "activation analysis",
        "fine-tuning detection",
        "natural language queries"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces Activation Oracles, models trained using the LatentQA approach to answer natural language questions about the internal activations of other LLMs. The core finding is that these oracles, especially when trained on diverse datasets, can generalize to out-of-distribution tasks and effectively verbalize hidden information, such as knowledge from fine-tuning, often matching or exceeding prior white-box interpretability methods.",
      "mindmap": ""
    },
    {
      "title": "Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants",
      "authors": "Vincent Huang, Dami Choi, Daniel D. Johnson, Sarah Schwettmann, Jacob Steinhardt",
      "institution": "Transluce",
      "link": "https://arxiv.org/pdf/2512.15712",
      "code": null,
      "tags": [
        "post-training",
        "predictive concept decoder",
        "communication bottleneck",
        "sparse concept list",
        "encoder-decoder",
        "auto-interp score",
        "fine-tuning"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes Predictive Concept Decoders (PCDs), an end-to-end trained architecture where an encoder compresses a model's internal activations into a sparse list of concepts, and a decoder uses this list to answer questions about the model's behavior. The method is pretrained on large datasets and then finetuned, showing that the interpretability and downstream performance of the bottleneck concepts improve with more data.",
      "mindmap": ""
    }
  ]
}