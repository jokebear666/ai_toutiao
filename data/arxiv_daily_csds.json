{
  "label": "cs.DS",
  "slug": "csds",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Weighted Fourier Factorizations: Optimal Gaussian Noise for Differentially Private Marginal and Product Queries",
      "authors": "Christian Janos Lebeda, Aleksandar Nikolov, Haohua Tang",
      "institution": "Inria, Université de Montpellier, INSERM, University of Toronto",
      "link": "https://arxiv.org/pdf/2512.21499",
      "code": null,
      "tags": [
        "differential privacy",
        "factorization mechanism",
        "Fourier basis",
        "marginal queries",
        "product queries",
        "Gaussian noise"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/589c857d3c263098ff5b7608b80fed9cb6cf72f1228f01d3ba136496420444dc_w640_q70.webp",
      "contributions": "1. Proposes a simpler, polynomial-time algorithm for releasing weighted marginal queries under differential privacy using Fourier factorization, achieving exact optimality among factorization mechanisms. 2. Extends the algorithm to a more general class of product queries, maintaining exact optimality. 3. Shows the mechanism is almost optimal for extended marginal queries with threshold predicates, achieving optimal noise variance up to lower-order terms.",
      "summary": "This paper proposes a new algorithm for releasing marginal and product queries under differential privacy by adding correlated Gaussian noise. The method works by releasing queries in the Fourier basis with independent, carefully calibrated noise and then reconstructing the answers, which is proven to be exactly optimal among factorization mechanisms and runs in polynomial time. It simplifies and improves upon prior work, extending optimality to more general query classes.",
      "mindmap": "graph TB\n        A[Weighted Fourier Factorizations<br>加权傅里叶分解] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Releasing marginal queries<br>with differential privacy<br>在差分隐私下发布边际查询]\n        C --> C1[Use Fourier basis &<br>independent Gaussian noise<br>使用傅里叶基和独立高斯噪声]\n        C --> C2[Reconstruct via<br>inverse Fourier transform<br>通过逆傅里叶变换重构]\n        D --> D1[Exactly optimal for<br>marginal & product queries<br>对边际和乘积查询精确最优]\n        D --> D2[Polynomial-time algorithm<br>多项式时间算法]\n        D --> D3[Simpler & better than<br>prior work (Xiao et al.)<br>比先前工作更简单更好]"
    },
    {
      "title": "Fully Dynamic Spectral Sparsification for Directed Hypergraphs",
      "authors": "Sebastian Forster, Gramoz Goranci, Ali Momeni",
      "institution": "University of Salzburg, University of Vienna",
      "link": "https://arxiv.org/pdf/2512.21671",
      "code": null,
      "tags": [
        "graph algorithms",
        "spectral sparsification",
        "dynamic algorithm",
        "hypergraph sparsification",
        "spectral sparsifier",
        "batch-dynamic",
        "directed hypergraph"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937b0b2537d04995b1374f1ced0beb227f0a00fd203eff507e7b317f98955a49_w640_q70.webp",
      "contributions": "1. Presents the first fully dynamic algorithm for maintaining spectral sparsifiers of directed hypergraphs with near-optimal size and efficient update time. 2. Achieves an amortized update time of O(r^2 log^3 m) and a sparsifier size of O(n^2 / ε^2 log^7 m). 3. Extends the algorithm to the parallel batch-dynamic setting, enabling efficient batch processing of hyperedge updates with low depth.",
      "summary": "This paper introduces a new algorithm for dynamically maintaining spectral sparsifiers for directed hypergraphs. The method supports efficient updates (insertions/deletions of hyperedges) and can also process batches of updates in parallel. The main conclusion is that it provides the first spectral-based sparsification algorithm for this dynamic and parallel setting with near-optimal theoretical guarantees.",
      "mindmap": "graph TB\n        A[Fully Dynamic Spectral Sparsification for Directed Hypergraphs] --> B[核心问题/Problem: 有向超图的动态谱稀疏化/Dynamic Spectral Sparsification for Directed Hypergraphs]\n        A --> C[主要方法/Method: 完全动态算法/Fully Dynamic Algorithm]\n        A --> D[关键结果/Results: 近最优大小与更新时间/Near-Optimal Size & Update Time, 扩展到并行批处理/Extension to Parallel Batch-Dynamic]"
    },
    {
      "title": "BLEST: Blazingly Efficient BFS using Tensor Cores",
      "authors": "Deniz Elbek, Kamer Kaya",
      "institution": "Sabanci University",
      "link": "https://arxiv.org/pdf/2512.21967",
      "code": null,
      "tags": [
        "gpu kernels",
        "BFS",
        "Tensor Cores",
        "SpMSpV",
        "Graph Reordering",
        "Kernel Fusion"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp",
      "contributions": "1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads.",
      "summary": "The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations.",
      "mindmap": "graph TB\n        A[BLEST: Blazingly Efficient BFS using Tensor Cores] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[如何将不规则图BFS映射到密集张量核心/Map irregular BFS to dense Tensor Cores]\n        C --> C1[二值化虚拟切片集/Binarised Virtual Slice Sets (BVSS)]\n        C --> C2[图重排序策略/Graph Reordering Strategies]\n        C --> C3[批处理SpMSpV与核融合/Batched SpMSpV & Kernel Fusion]\n        D --> D1[平均3.58-4.9倍加速/Average 3.58-4.9x Speedup]"
    },
    {
      "title": "A 58-Addition, Rank-23 Scheme for General 3x3 Matrix Multiplication",
      "authors": "A. I. Perminov",
      "institution": "Research Center for TAI, Institute for System Programming",
      "link": "https://arxiv.org/pdf/2512.21980",
      "code": null,
      "tags": [
        "matrix multiplication algorithms",
        "additive complexity",
        "rank-23 scheme",
        "ternary coefficients",
        "flip-graph exploration",
        "common subexpression elimination"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7e38e656e47fa623dbd39700639cd1a83f31aa1372de01a6e4de9f8546d9a92_w640_q70.webp",
      "contributions": "1. A new state-of-the-art algorithm for exact 3x3 matrix multiplication that reduces the additive complexity to 58 scalar additions without a change of basis. 2. The use of an automated search methodology combining ternary-restricted flip-graph exploration with greedy intersection reduction for common subexpression elimination. 3. A scheme that uses only coefficients from \\{-1, 0, 1\\}, ensuring portability and efficiency across arbitrary fields.",
      "summary": "This paper presents a new algorithm for multiplying 3x3 matrices over general non-commutative rings. The method uses an automated search combining flip-graph exploration and greedy reduction to discover a rank-23 scheme requiring only 58 scalar additions, improving the previous best of 60 and reducing the total scalar operation count from 83 to 81.",
      "mindmap": "graph TB\n        Root[”A 58-Addition, Rank-23 Scheme for General 3x3 Matrix Multiplication<br>论文标题”] --> Problem[”降低3x3矩阵乘法的加法复杂度<br>Reduce Additive Complexity for 3x3 Matrix Multiplication”]\n        Root --> Method[”结合三元限制翻转图探索与贪心交集约简的自动搜索<br>Automated Search with Ternary-Restricted Flip-Graph & Greedy Intersection Reduction”]\n        Root --> Results[”58次加法，秩为23的方案，仅使用{-1,0,1}系数<br>58-Addition, Rank-23 Scheme Using Only {-1,0,1} Coefficients”]"
    },
    {
      "title": "In-Place BWT and Lyndon Array Construction in Constant Space",
      "authors": "Felipe A. Louza, Arnaud Lefebvre",
      "institution": "Universidade Federal de Uberlândia, Universidade Estadual de Campinas, Normandie Univ., UNIROUEN, LITIS",
      "link": "https://arxiv.org/pdf/2512.20869",
      "code": null,
      "tags": [
        "string algorithms",
        "Burrows-Wheeler Transform",
        "Lyndon array",
        "in-place algorithm",
        "constant space",
        "suffix array"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1db3edce1ef31a392927b9b901b098a7db0e0c5e4aabc0e2c3494e811ce57596_w640_q70.webp",
      "contributions": "1. Extends the existing in-place BWT algorithm to also construct the Lyndon array. 2. Achieves the construction using only O(1) extra space (constant space). 3. Provides a conceptually simple method that works for unbounded alphabets, though with quadratic time complexity.",
      "summary": "This paper addresses the problem of constructing the Burrows-Wheeler Transform (BWT) and Lyndon array with minimal memory overhead. It proposes an extension to an existing in-place BWT algorithm that incrementally tracks suffix ranks and then applies a next-smaller-value procedure to derive the Lyndon array. The main conclusion is a novel, conceptually simple algorithm that builds both structures in constant extra space, suitable for unbounded alphabets, albeit with a quadratic running time that limits practical use.",
      "mindmap": "graph LR\n    A[In-Place BWT and Lyndon Array Construction<br>in-Place BWT与Lyndon数组构建] --> B(核心问题/Problem: Construct BWT and Lyndon array with minimal memory.<br>核心问题: 以最小内存构建BWT和Lyndon数组)\n    A --> C(主要方法/Method: Extend in-place BWT algorithm, maintain suffix ranks, use next-smaller-value.<br>主要方法: 扩展原地BWT算法, 维护后缀次序, 使用next-smaller-value过程)\n    A --> D(关键结果/Results: Constant-space O(1) algorithm for unbounded alphabets, quadratic time.<br>关键结果: 适用于无界字母表的常数空间O(1)算法, 二次时间)"
    },
    {
      "title": "Time-Bucketed Balance Records: Bounded-Storage Ephemeral Tokens for Resource-Constrained Systems",
      "authors": "Shaun Scovil, Bhargav Chickmagalur Nanjundappa",
      "institution": "Radius Technology Systems",
      "link": "https://arxiv.org/pdf/2512.20962",
      "code": null,
      "tags": [
        "smart contracts",
        "time-to-live",
        "bounded storage",
        "denial-of-service resistance",
        "data structure",
        "fungible tokens"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b51be242f266cabc91d95594cb0221ca98b4de3e2e562ac90c7dc3881e7c7cd1_w640_q70.webp",
      "contributions": "1. Proposed the time-bucketed balance records data structure that bounds storage to O(k) records per account for fungible tokens with TTL. 2. Proved key properties including bounded storage, guaranteed minimum expiration time, and bounded adversarial cost increase. 3. Provided a practical reference implementation in Solidity with measured gas costs demonstrating efficiency.",
      "summary": "The paper addresses the problem of unbounded storage growth in fungible tokens with time-to-live semantics by proposing a new data structure called time-bucketed balance records. This method discretizes time into buckets to coalesce deposits, guaranteeing tokens never expire early while bounding storage and operation costs. The implementation and analysis show the approach is practical and resistant to denial-of-service attacks.",
      "mindmap": "graph LR\n    A[Time-Bucketed Balance Records] --> B[核心问题/Problem: Unbounded storage & DoS vulnerability for TTL tokens]\n    A --> C[主要方法/Method: Discretize time into k buckets, coalesce deposits]\n    A --> D[关键结果/Results: Bounded O(k) storage, guaranteed TTL, bounded adversarial cost]"
    },
    {
      "title": "Fairness in the k-Server Problem",
      "authors": "Mohammadreza Daneshvaramoli, Helia Karisani, Mohammad Hajiesmaili, Shahin Kamali, Cameron Musco",
      "institution": "University of Massachusetts Amherst, York University",
      "link": "https://arxiv.org/pdf/2512.20960",
      "code": null,
      "tags": [
        "online algorithms",
        "k-server problem",
        "fairness",
        "competitive analysis",
        "Double Coverage Algorithm",
        "oblivious adversary"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d9ce9b45db4e96b8f0700fa006229951ae693c27289e148cbcbc25a0c7ddc81_w640_q70.webp",
      "contributions": "1. Introduced a formal notion of (α, β)-fairness for the k-server problem, aiming to equitably distribute movement costs among servers. 2. Provided deterministic and randomized algorithms that transform optimal/competitive solutions into fair ones with minimal cost increase in offline and online (oblivious adversary) settings. 3. Analyzed the fairness properties of classic algorithms like Double Coverage Algorithm (DCA) and FIFO on specific metrics (line, tree, uniform), showing both positive and negative results.",
      "summary": "This paper formally studies fairness in the k-server problem, introducing a new fairness metric and algorithms to achieve it. The authors show fairness can be added to both offline and online solutions with minimal performance loss against an oblivious adversary, and analyze the fairness of classic deterministic algorithms on specific metric spaces.",
      "mindmap": "graph LR\n    A[Fairness in the k-Server Problem] --> B[核心问题/Problem: 如何在k-server问题中公平分配服务器移动成本?]\n    A --> C[主要方法/Method: 定义(α, β)-公平性; 设计算法将最优/竞争性解转化为公平解]\n    A --> D[关键结果/Results: 离线和在线(非适应性对手)设置下可公平且保持竞争力; DCA在特定度量下公平]"
    },
    {
      "title": "ESCHER: Efficient and Scalable Hypergraph Evolution Representation with Application to Triad Counting",
      "authors": "S. M. Shovan, Arindam Khanda, Sanjukta Bhowmick, Sajal K. Das",
      "institution": "Missouri University of Science and Technology, University of North Texas",
      "link": "https://arxiv.org/pdf/2512.21009",
      "code": null,
      "tags": [
        "parallel computing",
        "hypergraph",
        "GPU",
        "dynamic data structure",
        "triad counting",
        "parallel algorithm"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/335f41f5fe79d6bd117abec93eaf4a43675ba18ef5f201690d075fa6085dfc56_w640_q70.webp",
      "contributions": "1. Proposed ESCHER, a novel GPU-centric parallel data structure for efficient representation and management of large-scale dynamic hypergraphs. 2. Designed a hypergraph triad-count update framework that minimizes redundant computation by leveraging ESCHER's dynamic operation capabilities. 3. Demonstrated significant performance improvements, achieving speedups of up to 104.5x, 473.7x, and 112.5x for different triad counting types on real-world and synthetic datasets.",
      "summary": "The paper addresses the computational challenge of analyzing large, dynamic hypergraphs, which lack efficient specialized data structures. It proposes ESCHER, a GPU-centric data structure for representing hypergraph evolution, and a corresponding triad-counting update framework. The method achieves substantial speedups over state-of-the-art approaches in counting various types of hypergraph triads.",
      "mindmap": "graph LR\n    A[ESCHER: Efficient and Scalable Hypergraph Evolution Representation] --> B[核心问题/Problem: 缺乏分析大规模动态超图的高效数据结构]\n    A --> C[主要方法/Method: 提出GPU并行的ESCHER数据结构与三元组计数更新框架]\n    A --> D[关键结果/Results: 性能显著提升，最高达473.7倍加速]"
    },
    {
      "title": "Approximation Schemes for Planar Graph Connectivity Problems",
      "authors": "Meike Neuwohner, Vera Traub, Rico Zenklusen",
      "institution": "CNRS & DIENS, ENS Paris; ETH Zurich",
      "link": "https://arxiv.org/pdf/2512.21128",
      "code": null,
      "tags": [
        "approximation algorithms",
        "planar graphs",
        "PTAS",
        "connectivity augmentation",
        "k-edge-connected",
        "decomposition technique"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/546114d79c91680ace01463b148cb7f324c4bc0e53497b96d6a60a718d0fbaa2_w640_q70.webp",
      "contributions": "1. A novel decomposition technique for connectivity problems on planar graphs that overcomes the global nature of connectivity constraints. 2. Polynomial-time approximation schemes (PTASs) for finding smallest k-edge-connected and k-vertex-connected spanning subgraphs in planar graphs for any k. 3. A PTAS for planar k-connectivity augmentation for any constant k, complemented by an NP-hardness result showing optimality.",
      "summary": "This paper introduces a new decomposition technique for planar graphs to address classical connectivity problems where standard methods fail due to global connectivity requirements. The technique yields polynomial-time approximation schemes (PTASs) for finding minimum k-edge/vertex-connected spanning subgraphs and for connectivity augmentation in planar graphs. The results are shown to be essentially optimal through a complementary NP-hardness proof.",
      "mindmap": "graph LR\n    A[Approximation Schemes for Planar Graph Connectivity Problems] --> B[核心问题/Problem: APX-hard connectivity problems in general graphs, not well-understood for planar graphs]\n    A --> C[主要方法/Method: Novel decomposition technique for planar graphs to handle global connectivity]\n    A --> D[关键结果/Results: PTAS for k-ECSS/k-VCSS and k-CAP; NP-hardness shows optimality]"
    },
    {
      "title": "An O($nlogn$) approximate knapsack algorithm",
      "authors": "Nick Dawes",
      "institution": "Independent researcher (based on email domain)",
      "link": "https://arxiv.org/pdf/2512.21195",
      "code": null,
      "tags": [
        "algorithms and complexity",
        "knapsack problem",
        "approximation algorithm",
        "dynamic programming",
        "time complexity",
        "error bound"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a8d98bd71c58e9c6b0529f95855f5330675f0b0cd5ce83b05eb143a8cc6588bd_w640_q70.webp",
      "contributions": "1. Proposes a modified dynamic programming algorithm for the 0/1 knapsack problem with O(n log n) time and space complexity. 2. Demonstrates that the algorithm has a predictable maximum error, with accuracy improving faster than linearly with the solution size. 3. Shows experimentally that the algorithm is highly efficient, solving large-scale problems (e.g., n=10^6) in seconds on a desktop computer with very low fractional error.",
      "summary": "This paper introduces a modified dynamic programming algorithm for approximately solving large 0/1 knapsack problems. The algorithm achieves O(n log n) time and space complexity while providing a predictable and rapidly decreasing maximum fractional error as the solution size grows. Experimental results show it can solve problems with millions of items in seconds with high accuracy on common hardware.",
      "mindmap": "graph LR\n    A[An O(nlogn) approximate knapsack algorithm] --> B[核心问题/Problem: 大规模0/1背包问题/Large-scale 0/1 Knapsack Problem]\n    A --> C[主要方法/Method: 改进的动态规划算法/Modified Dynamic Programming Algorithm]\n    A --> D[关键结果/Results: O(n log n)复杂度, 可预测误差, 高效实验性能/O(n log n) complexity, predictable error, efficient performance]"
    },
    {
      "title": "An Allele-Centric Pan-Graph-Matrix Representation for Scalable Pangenome Analysis",
      "authors": "Roberto Garrone",
      "institution": "University of Milano-Bicocca",
      "link": "https://arxiv.org/pdf/2512.21320",
      "code": null,
      "tags": [
        "computational genomics",
        "pangenome representation",
        "allele-centric modeling",
        "sparse-dense hybrid encoding",
        "genomic data compression"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/47769022333474d616f56daabe2a8f15f3f606c9ff2cc86a0693b945b208b031_w640_q70.webp",
      "contributions": "1. Introduces H1, a novel allele-centric pan-graph-matrix representation that treats alleles as first-class objects and uses adaptive per-allele compression for efficient storage. 2. Introduces H2, a path-centric dual representation derived from the same underlying data, which restores explicit haplotype ordering while maintaining information equivalence. 3. Demonstrates that the representation achieves substantial compression gains, particularly for structural variants, while remaining informationally equivalent to pangenome graphs.",
      "summary": "The paper addresses the need for scalable, population-aware pangenome representations that unify different types of genomic variation. It proposes the H1 pan-graph-matrix, an allele-centric representation with adaptive compression, and its dual H2 representation. The method shows significant compression benefits, especially for structural variants, providing a unified foundation for large-scale pangenome analysis.",
      "mindmap": "graph LR\n    A[An Allele-Centric Pan-Graph-Matrix Representation] --> B(核心问题/Problem: Scalable, unified pangenome representation for population-scale analysis)\n    A --> C(主要方法/Method: H1 allele-centric matrix with adaptive compression & H2 path-centric dual)\n    A --> D(关键结果/Results: Substantial compression gains, equivalent information, unified foundation)"
    },
    {
      "title": "Approximation and parameterized algorithms for covering disjointness-compliable set families",
      "authors": "Zeev Nutov, Anael Vaknin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20180",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61bfd54e6f11feacc870c6f3778976645822489b851ab9a285fb40ba464f71f8_w640_q70.webp",
      "contributions": "",
      "summary": "Approximation and parameterized algorithms for covering disjointness-compliable set families",
      "mindmap": ""
    },
    {
      "title": "On the near-tightness of $χ 2r$: a general $σ$-ary construction and a binary case via LFSRs",
      "authors": "Vinicius T. V. Date, Leandro M. Zatesko",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20598",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cecd66244b3c95d4688ec108350aa614b12ddfe3e5cc1a98c8324648761796db_w640_q70.webp",
      "contributions": "",
      "summary": "On the near-tightness of $χ\\leq 2r$: a general $σ$-ary construction and a binary case via LFSRs",
      "mindmap": ""
    },
    {
      "title": "Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods",
      "authors": "Demerson N. Gonçalves, Tharso D. Fernandes, Andrias M. M. Cordeiro, Pedro H. G. Lugao, João T. Dias",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20588",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3376a358771fc30115cfc0c7477ecf025033a36cdd9897d4e03cc089055ce077_w640_q70.webp",
      "contributions": "",
      "summary": "Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods",
      "mindmap": ""
    },
    {
      "title": "Fast Rational Search via Stern-Brocot Tree",
      "authors": "Connor Weyers, N. V. Vinodchandran",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18036",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e022cde1df64a2bb5c2d992e85bd17ba696ad0ca4f85f149de33f252c00b206_w640_q70.webp",
      "contributions": "",
      "summary": "Fast Rational Search via Stern-Brocot Tree",
      "mindmap": ""
    },
    {
      "title": "Graph-based Nearest Neighbors with Dynamic Updates via Random Walks",
      "authors": "Nina Mishra, Yonatan Naamad, Tal Wagner, Lichen Zhang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18060",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09ac9385682bd6e4b07b769afe016fb50f71be5c2b6656f027de335845a16aed_w640_q70.webp",
      "contributions": "",
      "summary": "Graph-based Nearest Neighbors with Dynamic Updates via Random Walks",
      "mindmap": ""
    },
    {
      "title": "Constrained Cuts, Flows, and Lattice-Linearity",
      "authors": "Robert Streit, Vijay K. Garg",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18141",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4988963d0df9feb5d6d93950c8695a282967332a6a2d340e258ed92a056f4c86_w640_q70.webp",
      "contributions": "",
      "summary": "Constrained Cuts, Flows, and Lattice-Linearity",
      "mindmap": ""
    },
    {
      "title": "Learning Dependency Models for Subset Repair",
      "authors": "Haoda Li, Jiahui Chen, Yu Sun, Shaoxu Song, Haiwei Zhang, Xiaojie Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18204",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7424f3f1fd625869734b9d930aac4759dd07b6ddc786315e46a14290748c7a25_w640_q70.webp",
      "contributions": "",
      "summary": "Learning Dependency Models for Subset Repair",
      "mindmap": ""
    },
    {
      "title": "Quantization for Vector Search under Streaming Updates",
      "authors": "Ishaq Aden-Ali, Hakan Ferhatosmanoglu, Alexander Greaves-Tunnell, Nina Mishra, Tal Wagner",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18335",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df7364cc42e5bedb16b340dcf01a52bad1a58565d8131a6b77f0557e9720a68f_w640_q70.webp",
      "contributions": "",
      "summary": "Quantization for Vector Search under Streaming Updates",
      "mindmap": ""
    },
    {
      "title": "Constant Approximation of Arboricity in Near-Optimal Sublinear Time",
      "authors": "Jiangqi Dai, Mohsen Ghaffari, Julian Portmann",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18416",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d2d1e8ab2bfbbad1a54be27fbc6ec9372aee41b02d5dd2fa72764be35a835910_w640_q70.webp",
      "contributions": "",
      "summary": "Constant Approximation of Arboricity in Near-Optimal Sublinear Time",
      "mindmap": ""
    },
    {
      "title": "Fare Zone Assignment",
      "authors": "Martin Hoefer, Lennart Kauther, Philipp Pabst, Britta Peis, Khai Van Tran",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19493",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/899926283ff7970c7b8c198ac7d46da4bc1977bbe2008fb952cdd9f19e25eee5_w640_q70.webp",
      "contributions": "",
      "summary": "Fare Zone Assignment",
      "mindmap": ""
    },
    {
      "title": "Near-optimal streaming approximation for Max-DICUT in sublinear space using two passes",
      "authors": "Santhoshini Velusamy",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19521",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/419df4dd803b778e372141c734a967ae29cca1a12f34441c79ee9bf22c746dd6_w640_q70.webp",
      "contributions": "",
      "summary": "Near-optimal streaming approximation for Max-DICUT in sublinear space using two passes",
      "mindmap": ""
    },
    {
      "title": "Clustering with Label Consistency",
      "authors": "Diptarka Chakraborty, Hendrik Fichtenberger, Bernhard Haeupler, Silvio Lattanzi, Ashkan Norouzi-Fard, Ola Svensson",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19654",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73fc229d3b4fc51718fe8d59f9abfb97c5b0e2d37b67f22dacfc080be54754bb_w640_q70.webp",
      "contributions": "",
      "summary": "Clustering with Label Consistency",
      "mindmap": ""
    },
    {
      "title": "On Factoring and Power Divisor Problems via Rank-3 Lattices and the Second Vector",
      "authors": "Yiming Gao, Yansong Feng, Honggang Hu, Yanbin Pan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19076",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/df17bc838341d48bc4091e7746460983c71413f795cbf8ca3faf3de27c2d6089_w640_q70.webp",
      "contributions": "",
      "summary": "On Factoring and Power Divisor Problems via Rank-3 Lattices and the Second Vector",
      "mindmap": ""
    },
    {
      "title": "Optimizing Text Search: A Novel Pattern Matching Algorithm Based on Ukkonen's Approach",
      "authors": "Xinyu Guan, Shaohua Zhang",
      "institution": "Not specified",
      "link": "https://arxiv.org/pdf/2512.16927",
      "code": null,
      "tags": [
        "pattern matching algorithms",
        "Ukkonen's Algorithm",
        "Suffix Trees",
        "pattern recognition",
        "text-search algorithms"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b065cfa04bf6f3a4b29a1299ffe0b7dd4f84fbabb6368c76abaa339e1a0a77c_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces a novel pattern matching algorithm that combines Ukkonen's Algorithm for constructing Suffix Trees with a new search technique using Python's dynamic link attributes. The optimized algorithm demonstrates linear time and space efficiency, outperforming traditional methods like Naive Search, KMP, and Boyer-Moore, and achieves 100% accuracy in tasks such as genomic sequence pattern recognition.",
      "mindmap": ""
    },
    {
      "title": "Provably Extracting the Features from a General Superposition",
      "authors": "Allen Liu",
      "institution": "UC Berkeley",
      "link": "https://arxiv.org/pdf/2512.15987",
      "code": null,
      "tags": [
        "feature learning",
        "superposition",
        "query algorithm",
        "Fourier space search",
        "overcomplete regime"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents an efficient query algorithm that searches in Fourier space to recover hidden feature directions from a general superposition function. It successfully identifies all non-degenerate features and reconstructs the function, working under more general conditions than prior methods.",
      "mindmap": ""
    },
    {
      "title": "Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery",
      "authors": "Chao Gao, Liren Shan, Vaidehi Srinivas, Aravindan Vijayaraghavan",
      "institution": "University of Chicago, Toyota Technological Institute at Chicago, Northwestern University",
      "link": "https://arxiv.org/pdf/2512.16875",
      "code": null,
      "tags": [
        "robust statistics",
        "confidence ellipsoids",
        "minimum volume estimator",
        "primal-dual structure",
        "geometric Brascamp-Lieb inequality",
        "robust subspace recovery"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents a polynomial-time algorithm for finding confidence ellipsoids with bounded condition number, achieving a volume approximation factor of O(β^(γd)) while covering at least 1-O(α/γ) probability mass. The method leverages the primal-dual structure of minimum volume enclosing ellipsoids and the geometric Brascamp-Lieb inequality. As a key application, this yields the first polynomial-time algorithm with approximation guarantees for worst-case instances of the robust subspace recovery problem.",
      "mindmap": ""
    },
    {
      "title": "Label-consistent clustering for evolving data",
      "authors": "Ameet Gadekar, Aristides Gionis, Thibault Marette",
      "institution": "CISPA Helmholtz Center for Information Security, KTH Royal Institute of Technology, Digital Futures",
      "link": "https://arxiv.org/pdf/2512.15210",
      "code": null,
      "tags": [
        "clustering algorithms",
        "k-center",
        "approximation algorithms",
        "label-consistent clustering"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes the label-consistent k-center problem, which aims to update an existing clustering solution with new data while limiting changes to a given budget. It introduces two constant-factor approximation algorithms for this problem. The experimental evaluation on real-world datasets demonstrates the effectiveness of the proposed methods.",
      "mindmap": ""
    }
  ]
}