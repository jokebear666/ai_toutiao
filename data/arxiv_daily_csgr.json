{
  "label": "cs.GR",
  "slug": "csgr",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces",
      "authors": "Shen Changqing, Xu Bingzhou, Qi Bosong, Zhang Xiaojian, Yan Sijie, Ding Han",
      "institution": "Huazhong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.22502",
      "code": null,
      "tags": [
        "computer-aided manufacturing (CAM)",
        "spiral toolpath planning",
        "scalar field optimization",
        "topology-preserving deformation",
        "conformal slit mapping",
        "boundary-conforming"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8db268a37d6b76e48aa2571b6519b562d7e55bfc3d4e8f7c07120bc4dbfc1315_w640_q70.webp",
      "contributions": "1. Proposes a strategy to enforce boundary conformity and eliminate zero-gradient singularities in scalar-field-based toolpath optimization for multiply connected surfaces. 2. Reformulates the optimization as a topology-preserving mesh deformation with boundary-synchronous updates to achieve globally optimized spacing and smooth transitions. 3. Demonstrates significant improvements in machining efficiency, scallop-height uniformity, and vibration reduction compared to a state-of-the-art method.",
      "summary": "This paper addresses the challenge of generating continuous, boundary-conforming spiral toolpaths for ball-end milling on complex freeform surfaces. The proposed method uses conformal slit mapping to create an initial singularity-free scalar field and then optimizes it via a topology-preserving mesh deformation process. Experimental results show the approach increases machining efficiency by over 14%, improves surface finish uniformity, and reduces vibrations compared to existing methods.",
      "mindmap": "graph TB\n        A[Topology-Preserving Scalar Field Optimization for Boundary-Conforming Spiral Toolpaths on Multiply Connected Freeform Surfaces] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[挑战: 保持边界一致性并消除奇点/Challenge: Maintain boundary conformity & eliminate singularities]\n        C --> C1[使用共形狭缝映射初始化/Use conformal slit mapping for initialization]\n        C --> C2[拓扑保持网格变形优化/Topology-preserving mesh deformation optimization]\n        D --> D1[效率提升 14.24%/Efficiency improved by 14.24%]\n        D --> D2[均匀性提升 5.70%/Uniformity improved by 5.70%]\n        D --> D3[振动减少 >10%/Vibration reduced by >10%]"
    },
    {
      "title": "ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning",
      "authors": "Bangya Liu, Xinyu Gong, Zelin Zhao, Ziyang Song, Yulei Lu, Suhui Wu, Jun Zhang, Suman Banerjee, Hao Zhang",
      "institution": "University of Wisconsin-Madison, ByteDance, Georgia Institute of Technology, The Hong Kong Polytechnic University",
      "link": "https://arxiv.org/pdf/2512.22854",
      "code": "https://neutrinoliu.github.io/byteloom/",
      "tags": [
        "video generation",
        "Human-Object Interaction",
        "Diffusion Transformer",
        "Relative Coordinate Maps",
        "Progressive Curriculum Learning",
        "Geometry Consistency"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b9f5ff16308904b889be6695aafd24bfc28b798f080cc6c723a25066bcdc2bdf_w640_q70.webp",
      "contributions": "1. Proposes ByteLoom, a Diffusion Transformer-based framework for generating realistic HOI videos with geometrically consistent objects. 2. Introduces the RCM-cache mechanism using Relative Coordinate Maps to maintain object geometry consistency and control 6-DoF transformations. 3. Designs a progressive training curriculum to compensate for HOI dataset scarcity and relax the need for fine-grained hand mesh annotations.",
      "summary": "This paper addresses the challenges of poor cross-view consistency and reliance on hand mesh annotations in Human-Object Interaction (HOI) video generation. It proposes ByteLoom, a framework that uses a novel RCM-cache mechanism for geometry consistency and a progressive curriculum learning strategy for training. The method effectively preserves human identity and object geometry while generating smooth motion.",
      "mindmap": "graph TB\n        A[ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有方法缺乏多视图信息注入机制/Existing methods lack multi-view injection]\n        B --> B2[严重依赖手部网格标注/Heavy reliance on hand mesh annotations]\n        C --> C1[提出RCM-cache机制/Propose RCM-cache mechanism]\n        C --> C2[设计渐进式课程学习/Design progressive curriculum learning]\n        D --> D1[保持物体几何一致性/Preserves object geometry consistency]\n        D --> D2[生成平滑运动视频/Generates smooth motion videos]"
    },
    {
      "title": "HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation",
      "authors": "Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao",
      "institution": "Tencent Hunyuan",
      "link": "https://arxiv.org/pdf/2512.23464",
      "code": "https://github.com/Tencent-Hunyuan/HY-Motion-1.0",
      "tags": [
        "motion generation",
        "flow matching",
        "diffusion transformer (DiT)",
        "reinforcement learning from human feedback (RLHF)"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3019219aea0683c229d44ce63a0fed59b5ebb795811dc1b1638ae995c9a8156_w640_q70.webp",
      "contributions": "1. The first successful scaling of DiT-based flow matching models to billion parameters for motion generation. 2. A comprehensive full-stage training paradigm including large-scale pretraining, fine-tuning, and RLHF. 3. A meticulous data processing pipeline enabling extensive coverage of over 200 motion categories.",
      "summary": "This paper introduces HY-Motion 1.0, a large-scale model for generating 3D human motions from text. It scales up Diffusion Transformer-based flow matching and uses a full-stage training pipeline with pretraining, fine-tuning, and RLHF. The model achieves state-of-the-art performance and broad motion coverage, and is released open-source.",
      "mindmap": "graph TB\n        Root[”HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation”]\n        Root --> Problem[”核心问题/Problem: Generating high-quality, text-aligned 3D human motions”]\n        Root --> Method[”主要方法/Method: Scale DiT-based flow matching, Full-stage training (pretrain, fine-tune, RLHF), Meticulous data pipeline”]\n        Root --> Results[”关键结果/Results: SOTA performance, Extensive motion coverage, Open-source release”]"
    },
    {
      "title": "OpenPBR: Novel Features and Implementation Details",
      "authors": "Jamie Portsmouth, Peter Kutz, Stephen Hill",
      "institution": "Autodesk, Adobe, Lucasfilm",
      "link": "https://arxiv.org/pdf/2512.23696",
      "code": null,
      "tags": [
        "computer graphics rendering",
        "physically based rendering",
        "uber-shader",
        "microfacet theory",
        "subsurface scattering",
        "thin-film interference"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/34de1d742b1a9090342372c28b227530e6e3c7bfbebef32f3a6f3cfd4dd32542_w640_q70.webp",
      "contributions": "1. Proposes OpenPBR, a standardized, physically based uber-shader for interoperable material authoring across VFX, animation, and design visualization workflows. 2. Details novel model features including slab-based layering, statistical mixing, and specific physical components like metallic/dielectric substrates, subsurface scattering, and thin-film iridescence layers. 3. Provides in-depth implementation guidance and mathematical derivations for technical topics such as decoupling specular reflectivity from transmission and coat darkening physics.",
      "summary": "This paper introduces OpenPBR, a standardized physically based rendering shader designed for material interoperability across different rendering systems. It details the model's theoretical foundations, layered components, and provides implementation guidance. The work serves as a companion to the official specification, aiming to standardize and improve material workflows in graphics production.",
      "mindmap": "graph TB\n        Root(”OpenPBR: Novel Features and Implementation Details”) --> Problem(”核心问题/Problem: Need for interoperable, physically based material authoring across VFX/animation workflows”)\n        Root --> Method(”主要方法/Method: Standardized uber-shader with slab-based layering, microfacet theory, and multi-layer substrates (metallic, dielectric, subsurface, coat, fuzz, thin-film)”)\n        Root --> Results(”关键结果/Results: Detailed model specification, implementation guidance, and demonstration of interoperability across renderers”)"
    },
    {
      "title": "Domain matters: Towards domain-informed evaluation for link prediction",
      "authors": "Yilin Bi, Junhao Bian, Shuyan Wan, Shuaijia Wang, Tao Zhou",
      "institution": "University of Electronic Science and Technology of China",
      "link": "https://arxiv.org/pdf/2512.23371",
      "code": null,
      "tags": [
        "graph machine learning",
        "link prediction",
        "algorithm evaluation",
        "domain adaptation",
        "complex networks",
        "graph neural networks"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/052f77d6e344a45d0c05f39094686bed2c2049bf461f2d4ea65caf1fbb66f68e_w640_q70.webp",
      "contributions": "1. Conducted a large-scale, systematic evaluation of 12 link prediction algorithms across 740 networks from 7 domains, revealing low consistency in algorithm rankings across domains. 2. Proposed the Winner Score metric to identify domain-specific top-performing algorithms (e.g., NMF for social networks, NeoGNN for economics). 3. Introduced the Ranking Stability Coefficient (RSC) to quantify the number of networks needed for stable evaluation, showing significant variation across domains.",
      "summary": "This paper systematically evaluates link prediction algorithms across diverse network domains, finding that algorithm performance rankings are highly domain-specific rather than universal. It proposes metrics to identify the best algorithm for each domain and to determine the number of networks needed for stable evaluation, emphasizing the importance of aligning algorithmic mechanisms with network structure.",
      "mindmap": "graph TB\n    A[”Domain matters: Towards domain-informed evaluation for link prediction<br>领域重要：面向领域感知的链接预测评估”] --> B[”核心问题/Problem<br>Existing evaluations assume consistent algorithm performance across domains.<br>现有评估假设算法性能在不同领域一致。”]\n    A --> C[”主要方法/Method<br>Large-scale evaluation of 12 algorithms on 740 networks across 7 domains.<br>在7个领域的740个网络上对12种算法进行大规模评估。”]\n    A --> D[”关键结果/Results<br>Algorithm rankings are domain-specific; Proposed Winner Score & RSC metrics.<br>算法排名是领域特定的；提出了Winner Score和RSC指标。”]"
    },
    {
      "title": "ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields",
      "authors": "Albert Barreiro, Roger Marí, Rafael Redondo, Gloria Haro, Carles Bosch",
      "institution": "Eurecat, Centre Tecnològic de Catalunya; Universitat Pompeu Fabra; Universitat de Vic - UCC",
      "link": "https://arxiv.org/pdf/2512.21692",
      "code": null,
      "tags": [
        "neural rendering",
        "Neural Radiance Fields",
        "anisotropic specular reflections",
        "Anisotropic Spherical Gaussian",
        "von Mises-Fisher distribution",
        "material editing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ad12a4dd31b4ec9b89dafef4a6d4d851fe0aa09b5e3d8c6f918d085ee2acda50_w640_q70.webp",
      "contributions": "1. Introduces ShinyNeRF, a novel NeRF framework capable of modeling both isotropic and anisotropic specular reflections. 2. Proposes a method to jointly estimate physical surface properties (normals, tangents, specular concentration, anisotropy) by approximating outgoing radiance with a mixture of isotropic von Mises-Fisher distributions. 3. Achieves state-of-the-art performance in digitizing anisotropic materials and enables interpretable material property editing.",
      "summary": "This paper introduces ShinyNeRF, a novel Neural Radiance Fields framework designed to accurately model anisotropic specular reflections, such as those on brushed metals, which previous methods struggled with. The method learns an approximation of outgoing radiance using a mixture of isotropic von Mises-Fisher distributions to jointly estimate physical surface properties. Experimental results show it achieves state-of-the-art performance and enables plausible material editing.",
      "mindmap": "graph TB\n        A[ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[现有方法难以建模各向异性高光/Existing methods struggle with anisotropic specular reflections]\n        C --> C1[提出ShinyNeRF框架/Propose ShinyNeRF framework]\n        C1 --> C2[使用各向同性vMF混合近似出射辐射度/Use isotropic vMF mixture to approximate outgoing radiance]\n        C2 --> C3[联合估计法线、切线、高光参数/Jointly estimate normals, tangents, specular parameters]\n        D --> D1[实现SOTA性能/Achieves SOTA performance]\n        D --> D2[提供物理解释和材质编辑/Provides physical interpretation and material editing]"
    },
    {
      "title": "Graph Drawing Stress Model with Resistance Distances",
      "authors": "Yosuke Onoue",
      "institution": "Nihon University",
      "link": "https://arxiv.org/pdf/2512.21901",
      "code": null,
      "tags": [
        "graph drawing",
        "resistance distance",
        "stress model",
        "graph Laplacian",
        "stochastic gradient descent",
        "spectral embedding"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90743acf53987a8cc4eeb2edd80f71bfd5deac0b98227953e258bc7a00aa5f41_w640_q70.webp",
      "contributions": "1. Proposes a new stress-based graph drawing paradigm using resistance distance instead of graph-theoretic shortest distance, which better captures global graph structure and admits an isometric embedding in Euclidean space. 2. Introduces Omega, a linear-time graph drawing algorithm that combines fast resistance distance embedding with random node-pair sampling for SGD, achieving more effective and robust optimization than pivot-based methods. 3. Establishes a practical and scalable connection between spectral graph theory and stress-based layouts, demonstrating improved neighborhood preservation and cluster faithfulness in visualizations.",
      "summary": "This paper challenges the conventional use of shortest-path distances in stress-based graph drawing by proposing resistance distance as a superior alternative derived from the graph Laplacian. It introduces the Omega algorithm, which efficiently computes resistance distance embeddings and uses random sampling for SGD to produce more readable layouts with lower stress. The method effectively reveals global graph structures like clusters and maintains linear-time complexity for large networks.",
      "mindmap": "graph TB\n    A[Graph Drawing Stress Model with Resistance Distances] --> B(核心问题/Problem)\n    A --> C(主要方法/Method)\n    A --> D(关键结果/Results)\n    B --> B1[传统应力模型使用最短路径距离，存在理论和计算限制/Traditional stress models use shortest-path distances with theoretical and computational limitations]\n    C --> C1[提出基于电阻距离的新范式，源自拉普拉斯谱/Propose new paradigm based on resistance distance from graph Laplacian spectrum]\n    C --> C2[引入Omega算法：快速电阻距离嵌入与随机节点对采样/Introduce Omega algorithm: fast resistance distance embedding with random node-pair sampling]\n    D --> D1[改进邻域保持和聚类忠实性/Improved neighborhood preservation and cluster faithfulness]\n    D --> D2[更低、更稳定的应力值，线性复杂度/Lower and more stable stress values, linear-time complexity]"
    },
    {
      "title": "Efficient Computation of Integer-constrained Cones for Conformal Parameterizations",
      "authors": "Wei Du, Qing Fang, Ligang Liu, Xiao-Ming Fu",
      "institution": "University of Science and Technology of China",
      "link": "https://arxiv.org/pdf/2512.20904",
      "code": null,
      "tags": [
        "geometric processing",
        "conformal parameterization",
        "cone singularities",
        "discrete optimization",
        "integer-constrained angles",
        "rotationally seamless"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b941a6cb30753aa3bcef47884771c4a878dd646edafc8fcac32cf70713cc6388_w640_q70.webp",
      "contributions": "1. An explicit construction algorithm that drastically reduces the optimization problem scale for determining optimal cone angles, enabling efficient handling of high-genus surfaces., 2. A new derivative formula that allows for the effective movement of cone positions to reduce parameterization distortion., 3. A set of combined strategies (repositioning, adding, pairing cones, adaptive variable selection) to quickly achieve a favorable trade-off between cone count and distortion.",
      "summary": "The paper proposes an efficient method to compute a small set of integer-constrained cone singularities for generating low-distortion, rotationally seamless conformal surface parameterizations. The method alternates optimization of discrete variables and employs novel techniques like an explicit construction algorithm and a new derivative formula to move cones, achieving an order-of-magnitude speedup over prior work while maintaining comparable quality.",
      "mindmap": "graph LR\n    A[Efficient Computation of Integer-constrained Cones] --> B(核心问题/Problem: High distortion in conformal parameterizations)\n    A --> C(主要方法/Method: Alternate optimization of discrete variables, explicit construction, derivative formula, combined strategies)\n    A --> D(关键结果/Results: Order-of-magnitude speedup (30x), low distortion, rotationally seamless parameterizations)"
    },
    {
      "title": "AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences",
      "authors": "Zhe Wang, Jinghang Li, Yifei Zhu",
      "institution": "Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.20943",
      "code": null,
      "tags": [
        "communication & networking",
        "4D Gaussian Splatting",
        "video streaming",
        "integer linear programming",
        "pruning",
        "keyframe selection"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/67fcf9423d5e160d4a5d4e949518213bf3a4f37a910a1c4fe209190f990922dc_w640_q70.webp",
      "contributions": "1. Proposes a streaming-optimized 4DGS framework that converts Gaussian streams into multi-channel 2D formats and uses intelligent keyframe identification to enhance reconstruction quality and reduce training time. 2. Models the 4DGS delivery problem as an integer linear programming problem and designs a lightweight pruning algorithm to adaptively prune Gaussian updates for bandwidth-efficient transmission. 3. Demonstrates significant improvements in quality stability (reducing PSNR deviation by >20%), training speed (6x acceleration), and transmission efficiency (50% size reduction) compared to state-of-the-art methods.",
      "summary": "The paper presents AirGS, a framework that optimizes the training and delivery pipeline for 4D Gaussian Splatting to enable real-time free-viewpoint video streaming. It addresses quality degradation and high bandwidth overhead by introducing a 2D representation format, keyframe selection, and an adaptive pruning algorithm for transmission. Experiments show AirGS significantly improves quality stability, accelerates training, and reduces transmission size.",
      "mindmap": "graph LR\n    A[AirGS: Real-Time 4D Gaussian Streaming] --> B[核心问题/Problem: 4DGS质量下降与高带宽开销/4DGS Quality Degradation & High Bandwidth Overhead]\n    A --> C[主要方法/Method: 流优化框架与自适应剪枝/Streaming-Optimized Framework & Adaptive Pruning]\n    A --> D[关键结果/Results: 质量稳定、训练加速、传输减小/Quality Stable, Training Faster, Transmission Smaller]"
    },
    {
      "title": "A Design Study Process Model for Medical Visualization",
      "authors": "Mengjie Fan, Liang Zhou",
      "institution": "Peking University Health Science Center",
      "link": "https://arxiv.org/pdf/2512.21034",
      "code": null,
      "tags": [
        "visualization",
        "design study",
        "process model",
        "medical visualization",
        "visual analysis",
        "interdisciplinary research"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e5fe74c72d51a03dca133118f52d887d90317100c302c2b1d5fca972d1219ded_w640_q70.webp",
      "contributions": "1. Proposes a novel design study process model specifically tailored for medical visualization, emphasizing stakeholder distinction, stage differentiation by analytic logic, and task classification. 2. Refines previous general visualization design models by incorporating characteristics of medical problems and providing actionable guidance for each step. 3. Demonstrates the model's utility by applying it to guide a new visual analysis method design and by reanalyzing three existing works, validating its practical framework.",
      "summary": "This paper introduces a specialized design study process model for medical visualization, developed through literature review and interdisciplinary experience. The model emphasizes stakeholder analysis, task classification, and provides step-by-step guidance to make visualization design more targeted and adaptable to medical complexity. The authors demonstrate its application and argue it provides a systematic theoretical and practical framework for interdisciplinary medical visualization research.",
      "mindmap": "graph LR\n    A[A Design Study Process Model for Medical Visualization<br>医学可视化设计研究过程模型] --> B(Problem: Lack of systematic methodology for medical visualization design<br>核心问题: 缺乏系统的医学可视化设计方法)\n    A --> C(Method: Propose a tailored design study process model<br>主要方法: 提出定制的设计研究过程模型)\n    A --> D(Results: Model provides theoretical framework and practical guidance<br>关键结果: 模型提供理论框架与实践指导)"
    },
    {
      "title": "TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars",
      "authors": "Jaeseong Lee, Junyeong Ahn, Taewoong Kang, Jaegul Choo",
      "institution": "KAIST, Hanyang University",
      "link": "https://arxiv.org/pdf/2512.21099",
      "code": null,
      "tags": [
        "3D avatar generation",
        "3D Gaussian Splatting",
        "analytic rigging",
        "texel-space deformation",
        "hybrid representation",
        "head reenactment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d8320fd6b1a6f131ad704b82b65143269040ab86b9b67005a1edf15fca8097f6_w640_q70.webp",
      "contributions": "1. A hybrid avatar representation (TexAvatars) that combines analytic rigging for geometric grounding with texel-space neural regression for spatial continuity. 2. A method that predicts Gaussian attributes in UV space via CNNs but drives 3D deformation using mesh-aware Jacobians, enabling smooth transitions across mesh boundaries. 3. The model demonstrates improved generalization, stability, and capture of fine-grained expression details (e.g., wrinkles, mouth cavity) under extreme poses and expressions.",
      "summary": "This paper introduces TexAvatars, a method for creating drivable 3D head avatars by hybridizing analytic rigging with texel-space neural regression to improve generalization to unseen expressions. It predicts local attributes in UV space but uses mesh-aware Jacobians for 3D deformation, separating semantic modeling from geometric control. The approach achieves state-of-the-art performance in challenging reenactment scenarios, capturing fine details with high fidelity.",
      "mindmap": "graph LR\n        A[TexAvatars] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[现有方法泛化性差/Existing methods generalize poorly]\n        B --> B2[难以处理极端表情与姿态/Struggle with extreme expressions & poses]\n        C --> C1[混合表示/Hybrid Representation]\n        C --> C2[UV空间预测，3D网格驱动/UV-space prediction, 3D mesh-driven deformation]\n        D --> D1[泛化能力提升/Improved generalization]\n        D --> D2[高保真细节/High-fidelity details]\n        D --> D3[状态领先性能/State-of-the-art performance]"
    },
    {
      "title": "UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement",
      "authors": "Tanghui Jia, Dongyu Yan, Dehao Hao, Yang Li, Kaiyi Zhang, Xianyi He, Lanjiong Li, Jinnan Chen, Lutao Jiang, Qishen Yin, Long Quan, Ying-Cong Chen, Li Yuan",
      "institution": "Peking University, The Hong Kong University of Science and Technology, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21185",
      "code": null,
      "tags": [
        "3D shape generation",
        "diffusion models",
        "geometric refinement",
        "watertight processing",
        "voxel-based refinement",
        "RoPE"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/73c8cc72abe4a497351656b82b6735dbe1550a6d18e5c93d7aa031162f07f81e_w640_q70.webp",
      "contributions": "1. A comprehensive data processing pipeline for 3D datasets, featuring a novel watertight processing method and high-quality filtering to improve geometric quality. 2. A two-stage 3D diffusion framework that decouples spatial localization from geometric detail synthesis, using voxel-based refinement with RoPE-encoded positional anchors. 3. Training and evaluation demonstrating competitive performance with existing open-source methods using only publicly available datasets and limited resources.",
      "summary": "This paper introduces UltraShape 1.0, a two-stage diffusion framework for generating high-fidelity 3D shapes. It first synthesizes a coarse structure and then refines it using a novel method that decouples spatial localization from detail synthesis via voxel queries and RoPE encoding. The approach, supported by an improved data processing pipeline, achieves competitive geometry generation quality using public datasets.",
      "mindmap": "graph LR\n    A[UltraShape 1.0] --> B(核心问题/Problem: High-fidelity 3D shape generation 高保真3D形状生成)\n    A --> C(主要方法/Method: Two-stage diffusion with geometric refinement 两阶段扩散与几何细化)\n    C --> C1(Stage 1: Coarse structure synthesis 粗结构合成)\n    C --> C2(Stage 2: Voxel-based detail refinement 基于体素的细节细化)\n    A --> D(关键结果/Results: Competitive generation quality 具有竞争力的生成质量)"
    },
    {
      "title": "Generating the Past, Present and Future from a Motion-Blurred Image",
      "authors": "SaiKiran Tedla, Kelly Zhu, Trevor Canham, Felix Taubner, Michael S. Brown, Kiriakos N. Kutulakos, David B. Lindell",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19817",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d34df9bd29ac26646aab435f8fb3761d7ba6f54b4c9919286b04b5436dba1d0_w640_q70.webp",
      "contributions": "",
      "summary": "Generating the Past, Present and Future from a Motion-Blurred Image",
      "mindmap": ""
    },
    {
      "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction",
      "authors": "Hexu Zhao, Xiaoteng Liu, Xiwen Min, Jianhao Huang, Youming Deng, Yanfei Li, Ang Li, Jinyang Li, Aurojit Panda",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20017",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0ce1e013da49adc5236a2b8d6111015f3c345c5b5d1cd6d9c9375d46d54a5c3d_w640_q70.webp",
      "contributions": "",
      "summary": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction",
      "mindmap": ""
    },
    {
      "title": "Anisotropic Green Coordinates",
      "authors": "Dong Xiao, Renjie Chen, Bailin Deng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20386",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3142ca49761ee9bbf0364dc9bc86dd10c0898f07e22220a1a757c13e069379dc_w640_q70.webp",
      "contributions": "",
      "summary": "Anisotropic Green Coordinates",
      "mindmap": ""
    },
    {
      "title": "LLM-Based Authoring of Agent-Based Narratives through Scene Descriptions",
      "authors": "Vinayak Regmi, Christos Mousas",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20550",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8d09b76bd7e8408e9cbe2a9fb304bebde2b7918c5ae2ebfb71d37a7f10f36af5_w640_q70.webp",
      "contributions": "",
      "summary": "LLM-Based Authoring of Agent-Based Narratives through Scene Descriptions",
      "mindmap": ""
    },
    {
      "title": "MatSpray: Fusing 2D Material World Knowledge on 3D Geometry",
      "authors": "Philipp Langsteiner, Jan-Niklas Dihlmann, Hendrik P.A. Lensch",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18314",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc201c384a37d43b2bd10a9944a6df93bc871b921e058d53b3a80eb95aa3784_w640_q70.webp",
      "contributions": "",
      "summary": "MatSpray: Fusing 2D Material World Knowledge on 3D Geometry",
      "mindmap": ""
    },
    {
      "title": "Commercial Vehicle Braking Optimization: A Robust SIFT-Trajectory Approach",
      "authors": "Zhe Li, Kun Cheng, Hanyue Mo, Jintao Lu, Ziwen Kuang, Jianwen Ye, Lixu Xu, Xinya Meng, Jiahui Zhao, Shengda Ji, Shuyuan Liu, Mengyu Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18597",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e804718e966934e64cc22d02e796b1123866e2dd8d037801ef21cbcbee4c0537_w640_q70.webp",
      "contributions": "",
      "summary": "Commercial Vehicle Braking Optimization: A Robust SIFT-Trajectory Approach",
      "mindmap": ""
    },
    {
      "title": "LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer",
      "authors": "Raina Panda, Daniel Fein, Arpita Singhal, Mark Fiore, Maneesh Agrawala, Matyas Bohacek",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18930",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/17d9e52f35a5e302d613cba6423f95b6e9bb58c2b559fbd5a209c0516f8e2326_w640_q70.webp",
      "contributions": "",
      "summary": "LouvreSAE: Sparse Autoencoders for Interpretable and Controllable Style Transfer",
      "mindmap": ""
    },
    {
      "title": "TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation",
      "authors": "Hongwei Fan, Hang Dai, Jiyao Zhang, Jinzhou Li, Qiyang Yan, Yujie Zhao, Mingju Gao, Jinghang Wu, Hao Tang, Hao Dong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19390",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dbf1e9d4003951dba668a306d606416b006b75689695b9667afa58a3ba76ea89_w640_q70.webp",
      "contributions": "",
      "summary": "TwinAligner: Visual-Dynamic Alignment Empowers Physics-aware Real2Sim2Real for Robotic Manipulation",
      "mindmap": ""
    },
    {
      "title": "Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface",
      "authors": "Yujie Zhao, Hongwei Fan, Di Chen, Shengcong Chen, Liliang Chen, Xiaoqi Li, Guanghui Ren, Hao Dong",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19402",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d3585a78a8a01def680be454d4e0abbbbcf24961bd331f0f18d30d4fa2409128_w640_q70.webp",
      "contributions": "",
      "summary": "Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface",
      "mindmap": ""
    },
    {
      "title": "Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations",
      "authors": "Yinhuai Wang, Runyi Yu, Hok Wai Tsui, Xiaoyi Lin, Hui Zhang, Qihan Zhao, Ke Fan, Miao Li, Jie Song, Jingbo Wang, Qifeng Chen, Ping Tan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19583",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50064ac2ceaf4f963ab285d471e35de23cbb546a9b072cfb14bd945c6439276e_w640_q70.webp",
      "contributions": "",
      "summary": "Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations",
      "mindmap": ""
    },
    {
      "title": "LiteGE: Lightweight Geodesic Embedding for Efficient Geodesics Computation and Non-Isometric Shape Correspondence",
      "authors": "Yohanes Yudhi Adikusuma, Qixing Huang, Ying He",
      "institution": "University of Texas at Austin, Nanyang Technological University",
      "link": "https://arxiv.org/pdf/2512.17781",
      "code": null,
      "tags": [
        "others",
        "unsigned distance field",
        "PCA",
        "lightweight embedding",
        "geodesic distance",
        "shape correspondence"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "LiteGE introduces a lightweight method for computing geodesic distances on 3D shapes by constructing compact shape descriptors using PCA on unsigned distance field samples. This approach eliminates the need for large neural networks, enabling significant reductions in memory usage and inference time while maintaining robustness on sparse point clouds. It also facilitates fast and accurate non-isometric shape correspondence, achieving up to 1000x speedup over state-of-the-art mesh-based methods.",
      "mindmap": ""
    },
    {
      "title": "Hierarchical Neural Surfaces for 3D Mesh Compression",
      "authors": "Sai Karthikey Pentapati, Gregoire Phillips, Alan Bovik",
      "institution": "The University of Texas at Austin, Ericsson Research",
      "link": "https://arxiv.org/pdf/2512.15985",
      "code": null,
      "tags": [
        "3D geometry processing",
        "implicit neural representations",
        "spherical parameterization",
        "displacement vector field",
        "hierarchical structure",
        "spherical harmonics"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces a method for 3D mesh compression using a hierarchical implicit neural representation (INR) built upon a spherical parameterization of the mesh. The INR encodes a displacement vector field to reconstruct the original shape, first recovering coarse structure and then adding high-frequency details. The approach achieves a state-of-the-art trade-off between reconstruction quality and compressed representation size, enabling real-time decoding of meshes at arbitrary resolutions.",
      "mindmap": ""
    },
    {
      "title": "Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture",
      "authors": "Haodi He, Jihun Yu, Ronald Fedkiw",
      "institution": "Epic Games, Stanford University",
      "link": "https://arxiv.org/pdf/2512.16397",
      "code": null,
      "tags": [
        "computer vision",
        "computer graphics",
        "Gaussian Splatting",
        "neural radiance fields",
        "triangulated surface",
        "view-dependent neural texture",
        "relightable Gaussian model",
        "albedo texture",
        "segmentation annotations"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a method for creating high-fidelity facial avatars by using Gaussian Splatting, constrained to an underlying triangulated surface, to reconstruct geometry and texture from a small set of uncalibrated images. The approach enables the generation of a standard mesh and a delit, high-resolution albedo texture for use in traditional graphics pipelines. The main conclusion is that this method facilitates scalable and democratized avatar creation, demonstrating utility in applications like text-driven asset generation.",
      "mindmap": ""
    },
    {
      "title": "Multi-scale Attention-Guided Intrinsic Decomposition and Rendering Pass Prediction for Facial Images",
      "authors": "Hossein Javidnia",
      "institution": "Trinity College Dublin",
      "link": "https://arxiv.org/pdf/2512.16511",
      "code": null,
      "tags": [
        "computer vision",
        "multi-scale attention",
        "hierarchical residual encoding",
        "spatial-and-channel attention",
        "adaptive multi-scale feature fusion",
        "Pix2PixHD",
        "masked-MSE",
        "VGG loss",
        "edge loss",
        "patch-LPIPS loss"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces MAGINet, a multi-scale attention-guided network that predicts a light-normalized diffuse albedo map from a single RGB face image and then uses it to generate a full set of physically based rendering passes. The method achieves state-of-the-art performance for intrinsic decomposition, enabling high-quality face relighting and material editing.",
      "mindmap": ""
    },
    {
      "title": "FrameDiffuser: G-Buffer-Conditioned Diffusion for Neural Forward Frame Rendering",
      "authors": "Ole Beisswenger, Jan-Niklas Dihlmann, Hendrik P.A. Lensch",
      "institution": "University of Tübingen",
      "link": "https://arxiv.org/pdf/2512.16670",
      "code": null,
      "tags": [
        "diffusion inference",
        "autoregressive neural rendering",
        "ControlNet",
        "ControlLoRA",
        "G-buffer conditioning",
        "temporal consistency",
        "environment-specific training"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "FrameDiffuser is an autoregressive diffusion framework that generates photorealistic and temporally consistent video frames for interactive applications by conditioning on incoming G-buffer data and its own previous output. It uses a dual-conditioning architecture with ControlNet for structural guidance and ControlLoRA for temporal coherence. The paper concludes that environment-specific training of this model yields superior visual quality and consistency compared to generalized approaches.",
      "mindmap": ""
    },
    {
      "title": "SDFoam: Signed-Distance Foam for explicit surface reconstruction",
      "authors": "Antonella Rech, Nicola Conci, Nicola Garau",
      "institution": "University of Trento, CNIT",
      "link": "https://arxiv.org/pdf/2512.16706",
      "code": null,
      "tags": [
        "others",
        "signed distance field",
        "Voronoi diagram",
        "ray tracing",
        "Eikonal regularization",
        "neural radiance fields",
        "3D Gaussian Splatting",
        "mesh reconstruction"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces SDFoam, a hybrid method that jointly learns an implicit Signed Distance Field (SDF) and an explicit Voronoi Diagram to improve explicit surface reconstruction. It optimizes the scene via ray tracing with Eikonal regularization, aligning Voronoi cell faces with the SDF's zero level set. This approach achieves more accurate mesh reconstruction with comparable rendering speed and visual quality to prior methods.",
      "mindmap": ""
    },
    {
      "title": "Sceniris: A Fast Procedural Scene Generation Framework",
      "authors": "Jinghuan Shang, Harsh Patel, Ran Gong, Karl Schmeckpeper",
      "institution": "Robotics and AI Institute, University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.16896",
      "code": null,
      "tags": [
        "others",
        "procedural scene generation",
        "batch sampling",
        "GPU acceleration",
        "collision checking",
        "robot reachability",
        "cuRobo"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "Sceniris is a fast procedural scene generation framework that uses batch sampling and GPU-accelerated collision checking via cuRobo to create large-scale, collision-free 3D scenes. It achieves at least 234x speed-up over prior methods and includes optional robot reachability checks for manipulation tasks.",
      "mindmap": ""
    },
    {
      "title": "Towards Physically-Based Sky-Modeling For Image Based Lighting",
      "authors": "Ian J. Maquignaz",
      "institution": "Université Laval",
      "link": "https://arxiv.org/pdf/2512.15632",
      "code": null,
      "tags": [
        "computer graphics",
        "image-based lighting",
        "sky-modeling",
        "High Dynamic Range Imagery (HDRI)",
        "Image-Based Lighting (IBL)",
        "Full Dynamic Range (FDR)",
        "deep neural network (DNN)",
        "parametric sky-models",
        "tonemapping"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes AllSky, a physically-based sky-model learned directly from captured HDR imagery to generate accurate environment maps for image-based lighting. It demonstrates that current DNN-based sky-models fail to match the photorealism and full dynamic range of physically captured imagery. The work concludes that AllSky provides intuitive user control and achieves state-of-the-art performance, highlighting the limitations of existing models for accurate scene relighting.",
      "mindmap": ""
    },
    {
      "title": "Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering",
      "authors": "Divam Gupta, Anuj Pahuja, Nemanja Bartolovic, Tomas Simon, Forrest Iandola, Giljoo Nam",
      "institution": "Meta Codec Avatars Lab, Meta Reality Labs, Stellon Labs",
      "link": "https://arxiv.org/pdf/2512.15711",
      "code": null,
      "tags": [
        "others",
        "3D Gaussian Splatting",
        "triangle mesh",
        "hybrid representation",
        "differentiable rendering",
        "volumetric rendering",
        "neural networks"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces Gaussian Pixel Codec Avatars (GPiCA), a hybrid avatar representation that combines a textured triangle mesh and 3D Gaussians within a unified differentiable rendering pipeline. This approach uses neural networks to decode a facial expression code into the mesh, texture, and Gaussians, which are rendered together. The method achieves the realism of Gaussian-based avatars while maintaining the rendering efficiency of mesh-based avatars, enabling photorealistic performance on mobile devices.",
      "mindmap": ""
    }
  ]
}