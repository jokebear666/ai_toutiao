{
  "label": "cs.HC",
  "slug": "cshc",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms",
      "authors": "Himel Ghosh",
      "institution": "Technical University of Munich, Sapienza University of Rome",
      "link": "https://arxiv.org/pdf/2512.23835",
      "code": null,
      "tags": [
        "bias detection",
        "SHAP",
        "transformer",
        "interpretability",
        "false positives",
        "domain adaptation"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3cbe893cabdbb4c14e3f0b2a14a91011067d2ee0ee4225b0a232eb5591a1b743_w640_q70.webp",
      "contributions": "1. Conducted a comparative interpretability study of two transformer-based bias detection models using SHAP to analyze their decision mechanisms. 2. Revealed that a standard bias detector model exhibits a misalignment between attribution strength and prediction correctness, leading to systematic over-flagging, while a domain-adapted model produces significantly fewer false positives. 3. Demonstrated that model errors, particularly false positives, arise from discourse-level ambiguity rather than explicit bias cues, highlighting distinct linguistic failure modes.",
      "summary": "This paper compares how two transformer models detect bias in news text using SHAP-based explanations. It finds that while both models focus on similar evaluative language, a domain-adapted model integrates these signals more reliably, producing far fewer false positives than a standard bias detector. The study concludes that interpretability analysis is crucial for evaluating bias detection systems and that architectural choices critically impact their reliability for journalistic use.",
      "mindmap": "graph TB\n        A[Explaining News Bias Detection] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[How do bias detection models make decisions?]\n        C --> C1[Comparative SHAP analysis of two transformer models]\n        D --> D1[Domain-adapted model has better alignment and fewer false positives]\n        D --> D2[False positives driven by discourse ambiguity]"
    },
    {
      "title": "From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering",
      "authors": "Tao Dong, Harini Sampath, Ja Young Lee, Sherry Y. Shi, Andrew Macvean",
      "institution": "Google LLC",
      "link": "https://arxiv.org/pdf/2512.23844",
      "code": null,
      "tags": [
        "Human-AI Collaboration",
        "AI Agent Evaluation",
        "Behavioral Taxonomy",
        "Context-Adaptive Behavior Framework"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a7ee9d0c9d0b72de4dc6af2921706818c987d2f7c644977698965be6b535d20c_w640_q70.webp",
      "contributions": "1. A foundational taxonomy of desirable AI agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. 2. The Context-Adaptive Behavior (CAB) Framework, which models how behavioral expectations shift based on context. 3. An empirical derivation of two key axes (Time Horizon and Type of Work) that drive behavioral expectation shifts in the CAB Framework.",
      "summary": "This paper argues that current AI evaluation benchmarks focus too narrowly on code correctness and fail to assess the collaborative behaviors needed for AI to be an effective partner in software engineering. To address this, the authors propose a taxonomy of desirable agent behaviors and a Context-Adaptive Behavior (CAB) Framework that models how these expectations change with context. These contributions provide a human-centered foundation for evaluating and designing collaborative AI agents.",
      "mindmap": "graph TB\n        Root[”From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI Agent Behavior in Software Engineering<br/>从正确性到协作：评估软件工程中AI智能体行为的人本框架”] --> Problem\n        Root --> Method\n        Root --> Results\n    \n        Problem[”核心问题/Problem<br/>Current benchmarks fail to capture collaborative AI agent behavior.<br/>当前基准测试无法评估AI智能体的协作行为。”]\n        Method[”主要方法/Method<br/>1. Taxonomy of agent behaviors.<br/>智能体行为分类法。<br/>2. Context-Adaptive Behavior (CAB) Framework.<br/>上下文自适应行为框架。”]\n        Results[”关键结果/Results<br/>Provides a human-centered foundation for evaluating collaborative AI agents.<br/>为评估协作型AI智能体提供了人本基础。”]"
    },
    {
      "title": "Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis",
      "authors": "Leah Hope Ajmani, Arka Ghosh, Benjamin Kaveladze, Eugenia Kim, Keertana Namuduri, Theresa Nguyen, Ebele Okoli, Jessica Schleider, Denae Ford, Jina Suh",
      "institution": "University of Minnesota, Northwestern University, Dartmouth College, Microsoft, Microsoft Research, Mental Health America",
      "link": "https://arxiv.org/pdf/2512.23859",
      "code": null,
      "tags": [
        "conversational ai",
        "mental health crisis",
        "stages of change model",
        "human-AI interaction",
        "testimonial survey",
        "expert interviews"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/557b0c2624da79d40758f334c7d781c4558951ee96a27d54b04a81b3f20ec2ea_w640_q70.webp",
      "contributions": "1. Provides first-person experiential data on using conversational AI during mental health crises via a testimonial survey (n=53). 2. Contrasts user experiences with mental health expert perspectives (n=16) to highlight the essential role of human connection in crisis management. 3. Proposes a responsible design framework for AI crisis intervention, positioning AI as a bridge to human support using the stages of change model.",
      "summary": "This paper investigates how people use conversational AI (e.g., ChatGPT) during mental health crises through a survey and expert interviews. It finds users turn to AI due to gaps in human support, but experts emphasize human connection is crucial. The study concludes that responsible AI should act as a bridge to human help, increasing preparedness for positive action and de-escalating crises.",
      "mindmap": "graph TB\n        A[Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis] --> B(核心问题/Problem: Can conversational AI responsibly support mental health crises?)\n        A --> C(主要方法/Method: Testimonial survey (n=53) & expert interviews (n=16))\n        A --> D(关键结果/Results: AI fills gaps in human support; Human connection is essential; Design AI as a bridge to human help)"
    },
    {
      "title": "Deletion Considered Harmful",
      "authors": "Paul Englefield, Russell Beale",
      "institution": "University of Birmingham",
      "link": "https://arxiv.org/pdf/2512.23907",
      "code": null,
      "tags": [
        "Personal Information Management",
        "deletion",
        "filing",
        "retrieval success",
        "user behaviour",
        "knowledge workers"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/344b922727ad08c44db409e5d258a91eb23a5dd268f6314fc4a64df943271db6_w640_q70.webp",
      "contributions": "1. An empirical study revealing that deletion is consistently under-adopted compared to other Personal Information Management (PIM) tactics like Filing, Coverage, Ontology, and Timeliness. 2. Statistical evidence demonstrating that the practice of deletion is detrimental to retrieval success and user satisfaction, challenging the intuitive belief that decluttering is beneficial. 3. A detailed analysis and clustering of user behaviors that provides insights into the relationship between deletion and other information management strategies.",
      "summary": "This paper investigates the effectiveness of deletion as a Personal Information Management (PIM) tactic through a study of 51 knowledge workers using questionnaires and interviews. The study finds that deletion is less commonly used than other tactics and, contrary to common belief, empirical data shows it harms retrieval success and satisfaction. The authors conclude that deletion has adverse effects on information management outcomes.",
      "mindmap": "graph TB\n        A[Deletion Considered Harmful] --> B[核心问题/Problem: Is deletion helpful for managing information overload?]\n        A --> C[主要方法/Method: Study of 51 knowledge workers via questionnaires & interviews]\n        A --> D[关键结果/Results: Deletion is under-adopted and detrimental to retrieval]"
    },
    {
      "title": "Evaluation of Impression Difference of a Domestic Mobile Manipulator with Autonomous and/or Remote Control in Fetch-and-Carry Tasks",
      "authors": "Takashi Yamamoto, Hiroaki Yaguchi, Shohei Kato, Hiroyuki Okada",
      "institution": "Toyota Motor Corporation, Nagoya Institute of Technology, Tamagawa University, Kushinada Tech. Co., Ltd.",
      "link": "https://arxiv.org/pdf/2512.24029",
      "code": null,
      "tags": [
        "human-robot interaction",
        "autonomous remote control",
        "user-robot-operator triad",
        "mobile manipulation",
        "affinity",
        "fetch-and-carry"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1dd22c33e4c17332f65c8a5900aaa77e84ca89593caec86ae9813719341843f2_w640_q70.webp",
      "contributions": "1. Formalized the dual-agency structure of a service robot as a User-Robot-Operator triad in an autonomous remote-control setting. 2. Developed and evaluated an early-stage prototype interface combining natural-language text chat with freehand sketch annotations over a robot's live camera view for remote intervention. 3. Provided empirical evidence from controlled experiments showing systematic, mode-dependent differences in user-rated affinity (autonomous &gt; hybrid &gt; remote) and perceived security.",
      "summary": "This paper investigates how different control modes (autonomous, remote, hybrid) of a domestic mobile manipulator affect user impressions in fetch-and-carry tasks. The authors formalize the robot's dual agency and evaluate a prototype interface for remote intervention. The results show that user affinity is highest for autonomous mode, followed by hybrid and then remote control, offering guidance for designing human-in-the-loop mobile manipulation.",
      "mindmap": "graph TB\n        Root(”Evaluation of Impression Difference of a Domestic Mobile Manipulator”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”用户对自主/遥控/混合模式机器人的印象差异/User impression differences across robot control modes”)\n        Method --> M1(”形式化用户-机器人-操作员三元组/Formalize User-Robot-Operator triad”)\n        Method --> M2(”开发文本聊天+草图标注远程干预原型/Develop text chat + sketch annotation prototype”)\n        Method --> M3(”在WRS测试场进行受控实验/Conduct controlled experiments on WRS test field”)\n        Results --> R1(”亲和力评级: 自主 > 混合 > 遥控/Affinity rating: Autonomous > Hybrid > Remote”)\n        Results --> R2(”感知安全性存在模式差异/Perceived security differs by mode”)"
    },
    {
      "title": "External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation",
      "authors": "Boya Sun, Haotian Shi, Ying Ni, Shaocheng Jia, Haoyang Liang",
      "institution": "Tongji University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.24166",
      "code": null,
      "tags": [
        "human-vehicle interaction",
        "external human-machine interface",
        "intent recognition",
        "virtual reality",
        "adaptive interaction",
        "pedestrian crossing"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0a5c67d9a5913ccbcc68501e3dadf9e83996015c48d390f03d584b668ea07ea8_w640_q70.webp",
      "contributions": "1. Proposes IR-eHMI, an adaptive external human-machine interface framework that dynamically recognizes pedestrian and AV intent to improve interaction. 2. Introduces a mechanism to identify cooperation states between AVs and pedestrians for real-time intent inference. 3. Validates the framework using a VR experimental platform, showing significant improvements in crossing efficiency and reduced gaze distraction compared to traditional fixed eHMIs.",
      "summary": "This paper proposes IR-eHMI, an adaptive external interface for autonomous vehicles that recognizes pedestrian intent to improve interaction. The framework dynamically infers cooperation states and adjusts communication cues. Experimental validation in VR shows it enhances crossing efficiency and reduces distraction while maintaining safety.",
      "mindmap": "graph TB\n        Root(”External Human-Machine Interface based on Intent Recognition: Framework Design and Experimental Validation”) --> Problem(”核心问题/Problem: Ineffective AV-pedestrian interaction leads to safety risks and inefficiency”)\n        Root --> Method(”主要方法/Method: Propose IR-eHMI, an adaptive interface using intent recognition and cooperation state detection”)\n        Root --> Results(”关键结果/Results: Improves crossing efficiency, reduces gaze distraction, maintains safety”)"
    },
    {
      "title": "A Framing and Analysis of Applicative Tangible Interfaces",
      "authors": "Guillaume Riviere",
      "institution": "Univ. Bordeaux, ESTIA Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.24237",
      "code": null,
      "tags": [
        "Human-Computer Interaction (HCI)",
        "tangible user interfaces",
        "tangible components",
        "interaction model",
        "taxonomy",
        "roles"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7b4a0690743a298ebd026c9ac78b0d5d8de9878f07808bbf252b930b5fb1e309_w640_q70.webp",
      "contributions": "1. Proposes a new interaction model for applicative tangible user interfaces based on four distinct component roles. 2. Successfully classifies 159 physical items from 35 representative applications into the proposed four-role framework. 3. Identifies three main future research paths to realize the commercial potential of tangible interfaces, aligning with historical phases of the field.",
      "summary": "This paper proposes a component-based analysis for applicative tangible user interfaces (TUIs), introducing a new interaction model with four roles to categorize physical items. The model is validated by classifying items from 35 applications, and the analysis identifies key future research directions to advance the field towards commercialization.",
      "mindmap": "graph TB\n        A[A Framing and Analysis of Applicative Tangible Interfaces] --> B[核心问题/Problem: TUI领域成熟，需探索商业化潜力/TUI field is mature, need to explore commercial potential]\n        A --> C[主要方法/Method: 提出基于四角色的交互模型和组件化分析/Propose a four-role interaction model and component-based analysis]\n        A --> D[关键结果/Results: 成功分类159个物品，识别未来三大研究方向/Successfully classified 159 items, identified three main future research paths]"
    },
    {
      "title": "Language Model Agents Under Attack: A Cross Model-Benchmark of Profit-Seeking Behaviors in Customer Service",
      "authors": "Jingyu Zhang",
      "institution": "University of Washington",
      "link": "https://arxiv.org/pdf/2512.24415",
      "code": null,
      "tags": [
        "agent system",
        "prompt injection attack",
        "customer-service agents",
        "cross-domain benchmark",
        "uncertainty reporting"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6779572a24da1e0c74a9dfbfb9709e2eded3ecfb7b6ce939ef10467a1fe6647f_w640_q70.webp",
      "contributions": "1. Introduced a cross-domain benchmark for evaluating profit-seeking direct prompt injection attacks against customer-service LLM agents, spanning 10 service domains and 100 realistic attack scripts. 2. Conducted a systematic evaluation across five widely used models, revealing that attack success is highly dependent on both the service domain and the specific attack technique used. 3. Released data and evaluation code to support reproducible auditing and to inform the design of oversight and recovery workflows for more trustworthy agent interfaces.",
      "summary": "This paper investigates how customer-service LLM agents can be exploited through direct prompt injection attacks to obtain unauthorized concessions. The authors propose a cross-domain benchmark to evaluate these attacks and find that their success varies significantly by domain and technique, with airline support being most vulnerable. The study concludes by releasing resources to help audit and build more robust, human-centered agent systems.",
      "mindmap": "graph TB\n        Root[”Language Model Agents Under Attack<br>语言模型智能体攻击研究”] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[”核心问题/Problem<br>Customer-service LLM agents can be exploited for unauthorized profit<br>客服LLM智能体可能被利用谋取不当利益”]\n        Method[”主要方法/Method<br>Cross-domain benchmark of direct prompt injection attacks<br>跨领域直接提示注入攻击基准”]\n        Results[”关键结果/Results<br>Attacks are domain & technique dependent; Airline support most exploitable<br>攻击效果因领域和技术而异；航空客服最易受攻击”]"
    },
    {
      "title": "IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback",
      "authors": "Titas Ramancauskas, Kotryna Ramancauske",
      "institution": "(Institution not explicitly stated in provided content; inferred from author names as potentially independent researchers)",
      "link": "https://arxiv.org/pdf/2512.24460",
      "code": null,
      "tags": [
        "automated essay scoring",
        "DistilBERT",
        "regression head",
        "Design-Based Research (DBR)",
        "adaptive feedback",
        "transformer model"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cd49db97d083a1a08542b5c9894656f76ab161b46611cfa6c1b0426b21442e9_w640_q70.webp",
      "contributions": "1. Development of an IELTS writing revision platform with a dedicated UI that separates conversational guidance from the writing interface to reduce cognitive load. 2. Implementation of an Automated Essay Scoring (AES) system using a DistilBERT transformer model with a regression head, achieving improved scoring accuracy (MAE 0.66, positive R²) over rule-based methods. 3. Design and evaluation of adaptive feedback tailored to the IELTS rubric, which demonstrated statistically significant score improvements (mean +0.060 bands) and identified conservative surface-level corrections as more reliable than aggressive structural interventions.",
      "summary": "This paper addresses the lack of personalized feedback in IELTS writing preparation by developing a revision platform featuring an Automated Essay Scoring system and adaptive feedback. The core method involves iterative Design-Based Research, transitioning from rule-based scoring to a more accurate DistilBERT transformer model with a regression head. The main conclusion is that such automated feedback is best used as a supplement to human instruction, with surface-level corrections proving more effective for IELTS contexts than deep structural interventions.",
      "mindmap": "graph TB\n        A[IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[传统方法缺乏个性化反馈/Traditional methods lack personalized feedback]\n        C --> C1[基于设计的研究迭代/Iterative Design-Based Research (DBR)]\n        C1 --> C2[从规则到Transformer/From rule-based to transformer-based (DistilBERT)]\n        C2 --> C3[带回归头的评分模型/Scoring model with regression head]\n        C --> C4[自适应反馈系统/Adaptive feedback system]\n        D --> D1[评分准确率提升/Improved scoring accuracy (MAE 0.66, positive R²)]\n        D --> D2[分数显著提高/Statistically significant score improvement (mean +0.060 bands)]\n        D --> D3[结论: 自动化反馈是人工教学的补充/Conclusion: Automated feedback is a supplement to human instruction]"
    },
    {
      "title": "ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness",
      "authors": "Md Nazmus Sakib, Naga Manogna Rayasam, Ishika Tarin, Sanorita Dey",
      "institution": "University of Maryland, Baltimore County",
      "link": "https://arxiv.org/pdf/2512.24632",
      "code": null,
      "tags": [
        "human-computer interaction",
        "AI-assisted interface",
        "reflective prompting",
        "collaborative preparedness",
        "structured reflection",
        "mixed-method study"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7da9ba42bc2107a047b7b9218f6722321d70aa36bc6752ceb5bb9701a0247d1_w640_q70.webp",
      "contributions": "1. The design and development of ReflecToMeet, an AI-assisted system that integrates theory-driven reflective prompts with a mechanism for sharing teammates' reflections to enhance collaborative preparedness. 2. The execution of a formative interview study and a five-day mixed-method user study comparing three reflection conditions (deeper, regular, control) to evaluate the system's impact. 3. The identification of key findings that structured reflection improves organization and progress, while deeper reflection boosts confidence and teamwork at the cost of higher cognitive load, leading to design implications for AI agents in collaborative settings.",
      "summary": "The paper addresses the problem of task drift and reduced preparedness between collaborative meetings. It proposes ReflecToMeet, an AI-assisted system that uses structured reflective prompts and shared reflections. The study found that structured reflection improves team organization and progress, with deeper reflection further enhancing confidence and idea generation, albeit with increased cognitive load.",
      "mindmap": "graph TB\n        A[ReflecToMeet: An AI-Assisted Reflection Based System to Enhance Collaborative Preparedness] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[任务漂移与准备不足/Task Drift & Reduced Preparedness]\n        C --> C1[AI辅助反思系统/AI-Assisted Reflection System]\n        C --> C2[结构化反思提示/Structured Reflective Prompts]\n        C --> C3[共享队友反思/Sharing Teammates' Reflections]\n        D --> D1[结构化反思改善组织与进度/Structured Reflection Improves Organization & Progress]\n        D --> D2[深度反思提升信心与团队合作/Deeper Reflection Boosts Confidence & Teamwork]\n        D --> D3[深度反思增加认知负荷/Deeper Reflection Increases Cognitive Load]"
    },
    {
      "title": "Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences",
      "authors": "Emmanuel Fashae, Michael Burke, Leimin Tian, Lingheng Meng, Pamela Carreno-Medrano",
      "institution": "Monash University, CSIRO Robotics",
      "link": "https://arxiv.org/pdf/2512.24829",
      "code": null,
      "tags": [
        "human-robot interaction",
        "object rearrangement",
        "human preference modeling",
        "Monte Carlo Tree Search",
        "psychological constructs",
        "user study"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c0c9201484194f4f746f05eae7a288356c0e53c3a3a9d4683db5313924455a5a_w640_q70.webp",
      "contributions": "1. Proposes a novel, interpretable formulation of human object arrangement preferences based on four psychological constructs (spatial practicality, habitual convenience, semantic coherence, commonsense appropriateness). 2. Designs and validates a self-report questionnaire to capture these constructs through a 63-participant online study. 3. Demonstrates the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner to generate arrangements that align with human preferences.",
      "summary": "This paper addresses the lack of interpretability in robotic object rearrangement models by identifying four explicit psychological constructs that guide human organizational preferences. The authors designed a questionnaire to measure these constructs and integrated them into a Monte Carlo Tree Search planner. The results show that the planner, guided by these interpretable preferences, can generate arrangements closely matching those created by human participants.",
      "mindmap": "graph TB\n        A[Explaining Why Things Go Where They Go<br>解释物品为何归位] --> B(Problem: 机器人重排模型缺乏可解释性<br>Problem: Robotic rearrangement models lack interpretability)\n        A --> C(Method: 提出四个可解释偏好构念与问卷<br>Method: Four interpretable preference constructs & questionnaire)\n        A --> D(Results: 基于MCTS的规划器能生成符合人类偏好的布局<br>Results: MCTS planner generates human-aligned arrangements)"
    },
    {
      "title": "Vibe Coding, Interface Flattening",
      "authors": "Hongrui Jin",
      "institution": "University of Amsterdam",
      "link": "https://arxiv.org/pdf/2512.24939",
      "code": null,
      "tags": [
        "human-computer interaction",
        "large language models",
        "interface flattening",
        "vibe coding",
        "Model Context Protocol",
        "symbolic labour"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f7d80b187b5915d1a8220a2cb617bff9a959789d5181355291a3d22991715d25_w640_q70.webp",
      "contributions": "1. Proposes a critical framework for understanding \"vibe coding\" as \"interface flattening,\" where distinct modalities converge into a conversational surface while the underlying translation chain thickens. 2. Conducts a materialist reconstruction of the vibe-coding stack, analyzing how remote compute, structured outputs, and protocols like MCP relocate control to model providers. 3. Demonstrates how LLM-mediated development redistributes symbolic power, obscures responsibility, and privatizes competencies, offering a critical lens on the political economy of AI-mediated interaction.",
      "summary": "This paper analyzes the phenomenon of \"vibe coding,\" where software is developed through natural language interaction with LLMs. It conceptualizes this as \"interface flattening,\" arguing that while the user experience appears simplified, the underlying infrastructure and dependencies become more complex and concentrated. The main conclusion is that this apparent democratization of programming creates new dependencies, redistributes power to model providers, and privatizes competencies previously held by the programming community.",
      "mindmap": "graph TB\n        A[Vibe Coding, Interface Flattening] --> B[核心问题/Problem: How to understand the shift in programming via LLMs?]\n        A --> C[主要方法/Method: Critical analysis using media theory & materialist reconstruction of the stack]\n        A --> D[关键结果/Results: Interface flattening obscures complexity, redistributes power, creates new dependencies]"
    },
    {
      "title": "ShowUI-$π$: Flow-based Generative Models as GUI Dexterous Hands",
      "authors": "Siyuan Hu, Kevin Qinghong Lin, Mike Zheng Shou",
      "institution": "Show Lab, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.24965",
      "code": "https://github.com/showlab/showui-pi",
      "tags": [
        "human-computer interaction",
        "flow-based generative model",
        "GUI automation",
        "continuous trajectory prediction",
        "unified discrete-continuous actions",
        "ScreenDrag benchmark"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bd6391f609bd9b67bc717f5e3756501bf8f4dedd5a207352ff5b4f02bc902207_w640_q70.webp",
      "contributions": "1. Proposed ShowUI-π, the first flow-based generative model for GUI dexterous manipulation, unifying discrete clicks and continuous drags in a shared model. 2. Introduced a flow-based action generation method for drag modeling, predicting incremental cursor adjustments from continuous visual observations. 3. Created ScreenDrag, a benchmark with 20K drag trajectories across five domains and comprehensive evaluation protocols to assess GUI agents' drag capabilities.",
      "summary": "This paper addresses the limitation of existing GUI agents that only perform discrete clicks, lacking the ability for continuous, closed-loop drag interactions. The authors propose ShowUI-π, a flow-based generative model that unifies discrete and continuous actions and generates smooth drag trajectories from visual observations. Experiments show ShowUI-π outperforms proprietary GUI agents on the new ScreenDrag benchmark, demonstrating effective dexterous control for GUI automation.",
      "mindmap": "graph TB\n    A[ShowUI-π: Flow-based Generative Models as GUI Dexterous Hands] --> B[核心问题/Problem: Existing GUI agents only support discrete clicks, lacking continuous drag capability for closed-loop trajectories]\n    A --> C[主要方法/Method: Flow-based generative model with unified discrete-continuous actions and incremental trajectory prediction]\n    A --> D[关键结果/Results: Outperforms proprietary agents on ScreenDrag benchmark (score 26.98), demonstrating effective dexterous control]"
    },
    {
      "title": "Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings",
      "authors": "Tianzhi He, Farrokh Jazizadeh",
      "institution": "The University of Texas at San Antonio, Virginia Polytechnic Institute and State University",
      "link": "https://arxiv.org/pdf/2512.25055",
      "code": null,
      "tags": [
        "agent system",
        "Large Language Model",
        "Building Energy Management System",
        "AI Agents",
        "Human-Building Interaction",
        "Context-aware"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d46efc47f789043b6987c8068e21aecb4ec53b645c2c1a61c1880ed06029103b_w640_q70.webp",
      "contributions": "1. Proposes a conceptual framework for LLM-based AI agents in BEMS, featuring a closed-loop system with perception, central control, and action modules. 2. Develops and benchmarks a prototype using real-world datasets and diverse metrics (latency, functionality, accuracy, cost-effectiveness), formalizing the assessment of such agents. 3. Demonstrates the framework's performance and generalizability, identifying strengths (e.g., high accuracy in device control) and areas for improvement (e.g., complex cost estimation).",
      "summary": "This paper proposes a framework for LLM-based AI agents to manage energy in smart buildings through natural language. The agent uses a closed-loop system to analyze data and control devices, and its evaluation shows promising accuracy in tasks like device control but highlights challenges in complex cost estimation.",
      "mindmap": "graph TB\n        Root[”Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings”] --> Problem[”核心问题/Problem: Existing BEMS lack context-aware, natural language interaction for energy management”]\n        Root --> Method[”主要方法/Method: Proposes a three-module LLM-based AI agent framework (perception, central control, action) for closed-loop management”]\n        Root --> Results[”关键结果/Results: Prototype shows high accuracy in device control (86%) and memory tasks (97%), but lower accuracy in cost estimation (49%)”]"
    },
    {
      "title": "Power Analysis is Essential: High-Powered Tests Suggest Minimal to No Effect of Rounded Shapes on Click-Through Rates",
      "authors": "Ron Kohavi, Jakub Linowski, Lukas Vermeer, Fabrice Boisseranc, Joachim Furuseth, Andrew Gelman, Guido Imbens, Ravikiran Rajagopal",
      "institution": "Columbia University, Stanford University, Kameleoon, Coop Norway, United Parks & Resorts, Linowski Interaction Design, Inc.",
      "link": "https://arxiv.org/pdf/2512.24521",
      "code": null,
      "tags": [
        "experimental methodology",
        "A/B testing",
        "statistical power",
        "effect size",
        "replication",
        "confidence intervals"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6ec6e142f87864b111174c551c26259c2ffd929885b106bd50ef48d9a1e2b9b8_w640_q70.webp",
      "contributions": "1. Conducted three high-powered A/B tests with massive sample sizes to rigorously evaluate a prior claim. 2. Demonstrated that the originally reported large effect of rounded button corners on click-through rates is likely a statistical artifact of an underpowered study. 3. Emphasized the critical importance of power analysis and experimental design for ensuring result reproducibility and trust in digital experimentation.",
      "summary": "This paper critiques a prior study that claimed a 55% increase in click-through rates from rounding button corners, arguing the finding is implausible due to low statistical power. The authors conducted three much larger, high-powered A/B tests, finding effect sizes nearly 100 times smaller and statistically insignificant. The main conclusion is that underpowered studies exaggerate effects, highlighting the essential role of power analysis for reliable and reproducible research.",
      "mindmap": "graph TB\n        Root[”Power Analysis is Essential<br>高功率测试表明圆角形状对点击率影响甚微”]\n        Root --> Problem[”核心问题/Problem<br>Underpowered studies exaggerate effects<br>低统计功效研究夸大效应”]\n        Root --> Method[”主要方法/Method<br>Conduct high-powered A/B tests<br>进行高统计功效的A/B测试”]\n        Root --> Results[”关键结果/Results<br>Effect is two orders of magnitude smaller & not significant<br>效应小两个数量级且不显著”]"
    },
    {
      "title": "No Vision, No Wearables: 5G-based 2D Human Pose Recognition with Integrated Sensing and Communications",
      "authors": "Haojin Li, Dongzhe Li, Anbang Zhang, Wenqi Zhang, Chen Sun, Haijun Zhang",
      "institution": "University of Science and Technology Beijing, Sony China Research Laboratory, Shandong University",
      "link": "https://arxiv.org/pdf/2512.24923",
      "code": null,
      "tags": [
        "wireless sensing",
        "Integrated Sensing and Communication (ISAC)",
        "5G",
        "human pose recognition (HPR)",
        "sounding reference signals (SRS)",
        "multi-domain feature fusion"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9561da2eb11d118db62da20265273bb621f421eae2106c649b1696a1a1a243d6_w640_q70.webp",
      "contributions": "1. Proposes a practical 5G-based ISAC system for 2D human pose recognition using standard uplink SRS signals, eliminating the need for vision or dedicated sensing hardware. 2. Introduces a method to extract and align rich features from multiple domains into a unified latent space representation for pose inference. 3. Demonstrates through experiments that the proposed system significantly outperforms current mainstream baseline solutions (e.g., vision-based, WiFi-based, radar-based) in HPR performance in typical indoor environments.",
      "summary": "This paper addresses the limitations of current contactless human pose recognition methods (e.g., privacy, occlusion) by proposing a novel system that leverages 5G Integrated Sensing and Communication (ISAC) technology. The method infers 2D human poses from standard 5G uplink reference signals by extracting and fusing multi-domain features. Experimental results show the system outperforms existing vision and RF-based solutions, providing a foundation for universal human-computer interaction.",
      "mindmap": "graph TB\n        Root[No Vision, No Wearables: 5G-based 2D Human Pose Recognition] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[现有方案挑战/Challenges of Existing Solutions]\n        P1 --> P1_1[隐私担忧/Privacy Concerns]\n        P1 --> P1_2[易受遮挡/Susceptible to Occlusion]\n        P1 --> P1_3[专用设备/Dedicated Equipment]\n        Method[主要方法/Method] --> M1[5G ISAC 系统/5G ISAC System]\n        M1 --> M1_1[使用上行探测参考信号/Uses Uplink SRS]\n        M1 --> M1_2[多域特征提取与对齐/Multi-domain Feature Extraction & Alignment]\n        M1 --> M1_3[低维特征融合/Low-dim Feature Fusion]\n        Results[关键结果/Results] --> R1[显著优于主流基线/Significantly Outperforms Baselines]\n        R1 --> R1_1[为普适人机交互奠基/Foundation for Universal HCI]"
    },
    {
      "title": "SoDA: An Efficient Interaction Paradigm for the Agentic Web",
      "authors": "Zicai Cui, Zhouyuan Jian, Weiwen Liu, Weinan Zhang",
      "institution": "Shanghai Jiao Tong University, Shanghai Innovation Institute",
      "link": "https://arxiv.org/pdf/2512.22135",
      "code": null,
      "tags": [
        "agent system",
        "Sovereign Digital Avatar",
        "Intent-Permission Handshake",
        "orthogonal decoupling",
        "A2A protocols",
        "dual-factor adaptive routing"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ef4bb1bba1b84bcf1102a80dc39b16d212412d68a7abea9ab0aac1dc9e23dedb_w640_q70.webp",
      "contributions": "1. Proposes a user sovereignty interaction paradigm for the Agentic Web, decoupling memory from application logic to break data lock-in and shifting from explicit instruction to implicit intent alignment to reduce cognitive load. 2. Implements the paradigm via the Sovereign Digital Avatar (SoDA) with an orthogonal decoupling design of storage, computation, and interaction, establishing the principle of \"data as a persistent asset, model as a transient tool\". 3. Designs an Intent-Permission Handshake Mechanism based on A2A protocols with dual-factor adaptive routing for active risk governance in zero-trust environments.",
      "summary": "This paper proposes the Sovereign Digital Avatar (SoDA), a new interaction paradigm for the Agentic Web that decouples user memory from applications and uses intent alignment to reduce cognitive load. It introduces an architecture with orthogonal decoupling and a secure handshake mechanism for zero-trust environments. Empirical results show it significantly reduces token consumption and user cognitive load compared to existing methods.",
      "mindmap": "graph TB\n        A[SoDA: An Efficient Interaction Paradigm for the Agentic Web] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[数据锁定/Data Lock-in]\n        B --> B2[认知过载/Cognitive Overload]\n        C --> C1[主权数字化身/Sovereign Digital Avatar (SoDA)]\n        C --> C2[正交解耦设计/Orthogonal Decoupling Design]\n        C --> C3[意图-权限握手机制/Intent-Permission Handshake Mechanism]\n        D --> D1[降低令牌消耗/Reduces Token Consumption by 27-35%]\n        D --> D2[降低认知负载/Reduces Cognitive Load by 72% vs RAG, 88% vs Manual]"
    },
    {
      "title": "Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware",
      "authors": "Vesal Ahsani, Babak Hossein Khalaj",
      "institution": "Sharif University of Technology",
      "link": "https://arxiv.org/pdf/2512.22298",
      "code": null,
      "tags": [
        "human activity recognition",
        "driver monitoring systems",
        "edge AI",
        "quantization",
        "temporal decision head",
        "confounder-aware labeling"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bd52e06dc77080ab346fc3d6fe46b900bf06b5c1eaeb6ae89801ac125ee7c51_w640_q70.webp",
      "contributions": "1. A deployable single-camera driver behavior recognition pipeline optimized for low-cost edge hardware (Raspberry Pi 5 and Google Coral Edge TPU). 2. A confounder-aware label design to reduce false positives from visually similar actions. 3. A temporal decision head that generates stable alerts based on sustained, confident predictions rather than noisy per-frame outputs.",
      "summary": "This paper presents a real-time driver behavior recognition system designed for low-cost edge hardware to address the challenges of compute, power, and cost constraints in vehicles. The method combines a compact vision model, confounder-aware labeling, and a temporal decision head to recognize 17 distraction and drowsiness-related behaviors. The optimized system achieves 16 FPS on a Raspberry Pi 5 and 25 FPS on a Coral Edge TPU, enabling practical deployment for in-cabin monitoring.",
      "mindmap": "graph TB\n        A[Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[实时DMS需求 / Real-time DMS needs low latency, low cost, low power]\n        C --> C1[紧凑单摄像头系统 / Compact single-camera pipeline]\n        C1 --> C2[紧凑视觉模型 / Compact per-frame vision model]\n        C1 --> C3[抗混淆标签设计 / Confounder-aware label design]\n        C1 --> C4[时序决策头 / Temporal decision head]\n        D --> D1[性能: 16 FPS (RPi5), 25 FPS (Edge TPU) / Performance: 16 FPS (RPi5), 25 FPS (Edge TPU)]\n        D --> D2[验证: 真实车辆测试 / Validation: Real in-vehicle tests]"
    },
    {
      "title": "Emotion classification using EEG headset signals and Random Forest",
      "authors": "Ricardo Vasquez, Diego Riofrío-Luzcando, Joe Carrion-Jumbo, Cesar Guevara",
      "institution": "Universidad Internacional SEK, Universidad Indoamérica, The Institute of Mathematical Sciences (ICMAT-CSIC)",
      "link": "https://arxiv.org/pdf/2512.22333",
      "code": null,
      "tags": [
        "affective computing",
        "EEG",
        "Random Forest",
        "emotion classification",
        "brain-computer interface",
        "real-time prediction"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2e19385b22eca0965c66f7006e387468776c757a86a9b784693bc7b77b3c7533_w640_q70.webp",
      "contributions": "1. Developed a model for classifying human emotions (happiness, sadness, relaxation) using EEG signals from a consumer-grade headset (EMOTIV EPOC). 2. Applied the Random Forest algorithm to achieve high accuracy, particularly for happiness (97.21%). 3. Implemented a real-time emotion prediction system that captures EEG signals, processes them, and visually displays the predicted emotion.",
      "summary": "This paper proposes a system to classify human emotions (happiness, sadness, relaxation) from EEG signals using a Random Forest model. The model was trained on data from 50 participants and achieved high accuracy, especially for happiness. The work was extended to create a real-time prediction algorithm that outputs the result with representative images.",
      "mindmap": "graph TB\n        A[Emotion classification using EEG headset signals and Random Forest] --> B(核心问题/Problem: 如何从EEG信号中检测和分类情绪？/How to detect and classify emotions from EEG signals?)\n        A --> C(主要方法/Method: 使用EMOTIV EPOC采集EEG数据，并应用随机森林模型进行分类/Use EMOTIV EPOC to collect EEG data and apply Random Forest model for classification)\n        A --> D(关键结果/Results: 快乐分类准确率97.21%，实现实时情绪预测算法/Happiness classification accuracy 97.21%, implemented a real-time emotion prediction algorithm)"
    },
    {
      "title": "Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data",
      "authors": "Alaa Alahmadi, Mohamed Hasan",
      "institution": "Newcastle University, University of Leeds",
      "link": "https://arxiv.org/pdf/2512.22349",
      "code": null,
      "tags": [
        "medical image analysis",
        "pseudo-colouring",
        "few-shot learning",
        "prototypical networks",
        "ResNet-18",
        "explainability"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4573948678ad6f25faec7ec6be8baccee385ce760fef63e3980935e84e21be0_w640_q70.webp",
      "contributions": "1. Introduces a perception-informed pseudo-colouring technique to encode clinically salient temporal ECG features (like QT-interval) into structured colour representations. 2. Demonstrates that this technique enables effective few-shot and one-shot learning for a complex physiological data task (drug-induced LQTS) using prototypical networks and ResNet-18. 3. Shows that the method improves model explainability by guiding attention to clinically meaningful features and that aggregating multiple cardiac cycles (mirroring human perceptual averaging) further boosts performance.",
      "summary": "This paper addresses the problems of data inefficiency and poor interpretability in deep learning models for physiological signal analysis. It proposes a human-inspired pseudo-colouring technique to encode ECG features, enabling effective few-shot learning and improving model explainability by focusing on clinically relevant signal components. The results demonstrate that incorporating human-like perceptual encoding can bridge data efficiency and interpretability in medical AI.",
      "mindmap": "graph TB\n        A[Human-like visual computing advances explainability and few-shot learning in deep neural networks for complex physiological data] --> B1\n        A --> B2\n        A --> B3\n        B1[核心问题/Problem] --> C1[数据效率低/Lack of data efficiency]\n        B1 --> C2[可解释性差/Limited explainability]\n        B1 --> C3[临床可靠性受限/Constrained clinical reliability]\n        B2[主要方法/Method] --> D1[感知启发的伪着色技术/Perception-informed pseudo-colouring]\n        D1 --> E1[编码临床特征/Encode clinical features (e.g., QT-interval)]\n        D1 --> E2[结构化颜色表示/Structured colour representations]\n        B2 --> D2[原型网络与ResNet-18/Prototypical networks & ResNet-18]\n        B2 --> D3[聚合多个心跳周期/Aggregate multiple cardiac cycles]\n        B3[关键结果/Results] --> F1[实现少样本与单样本学习/Achieve few-shot & one-shot learning]\n        B3 --> F2[提升可解释性/Improve explainability (guide attention)]\n        B3 --> F3[桥接数据效率与因果推理/Bridge data efficiency & causal reasoning]"
    },
    {
      "title": "Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection",
      "authors": "Quanzhi Fu, Qiyu Wu, Dan Williams",
      "institution": "Virginia Tech",
      "link": "https://arxiv.org/pdf/2512.22404",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent LLM framework",
        "knowledge gap detection",
        "student-AI dialogue analysis",
        "QueryQuilt",
        "educational technology"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/346f14200e9375ed815220f7c720c8952c5109e4bcf1c3f206a9c517e2f80947_w640_q70.webp",
      "contributions": "1. Proposes QueryQuilt, a novel multi-agent LLM framework for automated detection of common student knowledge gaps in large lectures. 2. Introduces a two-agent design: a Dialogue Agent that engages students with probing questions and a Knowledge Gap Identification Agent that analyzes chat logs. 3. Demonstrates the system's potential with high accuracy (100%) on simulated data and high completeness (95%) on real student-AI dialogue data.",
      "summary": "This paper proposes QueryQuilt, a multi-agent LLM framework that analyzes student-AI chat logs to automatically identify common knowledge gaps in large-scale lectures. The system uses a Dialogue Agent to interact with students and a Knowledge Gap Identification Agent to analyze the dialogues, providing instructors with insights into class-wide understanding. Initial evaluation shows promising accuracy and completeness, indicating its potential for improving teaching in real classroom environments.",
      "mindmap": "graph TB\n    A[Mining the Gold: Student-AI Chat Logs as Rich Sources for Automated Knowledge Gap Detection] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[大班教学难以及时发现学生的知识缺口/Large lectures make timely knowledge gap identification challenging]\n    C --> C1[提出QueryQuilt: 一个多智能体LLM框架/Propose QueryQuilt: a multi-agent LLM framework]\n    C1 --> C2[对话智能体: 回答并探查学生问题/Dialogue Agent: responds and probes student questions]\n    C1 --> C3[知识缺口识别智能体: 分析对话识别共同缺口/Knowledge Gap Identification Agent: analyzes dialogues to identify common gaps]\n    D --> D1[模拟学生数据: 100%准确率/Simulated student data: 100% accuracy]\n    D --> D2[真实学生-AI对话数据: 95%完整性/Real student-AI dialogue data: 95% completeness]"
    },
    {
      "title": "Learning to Program != \"One-Size-Fits-All\": Exploring Variations of Parsons Problems as Scaffolding",
      "authors": "Carl Christopher Haynes-Magyar",
      "institution": "University of Pittsburgh",
      "link": "https://arxiv.org/pdf/2512.22407",
      "code": null,
      "tags": [
        "computing education",
        "Parsons Problems",
        "Scaffolding",
        "Faded Parsons",
        "Pseudocode Parsons",
        "Codespec"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dd341a2988c4238f96b98f47c543fa98eabbcc1469d134da8c7bac8729ea9026_w640_q70.webp",
      "contributions": "1. Explored learner perceptions of two novel Parsons problem variations (Faded Parsons and Pseudocode Parsons) as optional scaffolding in a new programming environment called Codespec. 2. Provided empirical evidence that offering these optional scaffolds supports comprehension monitoring, strategy formation, and knowledge refinement, with learners selectively using them for different purposes (syntax/structure vs. high-level reasoning). 3. Identified both benefits (e.g., desirable challenge of Faded Parsons) and costs (e.g., time, potential confusion) of using these problem types as scaffolding techniques.",
      "summary": "This study investigates how variations of Parsons problems can scaffold learning to program. It introduces the Codespec environment, offering optional Faded Parsons and Pseudocode Parsons problems, and finds through interviews that learners selectively use these scaffolds for different cognitive tasks, supporting learning but also noting some usability costs.",
      "mindmap": "graph TB\n        Root(”Learning to Program != 'One-Size-Fits-All'”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”如何有效搭建编程学习脚手架？/How to effectively scaffold programming learning?”)\n        Method --> M1(”开发Codespec环境/Develop Codespec environment”)\n        Method --> M2(”提供两种Parsons问题变体作为可选脚手架/Offer two Parsons problem variants as optional scaffolds”)\n        Method --> M3(”进行回顾性有声思维访谈/Conduct retrospective think-aloud interviews”)\n        Results --> R1(”脚手架支持理解监控与策略形成/Scaffolds support comprehension monitoring & strategy formation”)\n        Results --> R2(”学习者选择性使用不同变体/Learners selectively use different variants”)\n        Results --> R3(”Faded Parsons被视为理想挑战/Faded Parsons perceived as desirable challenge”)"
    },
    {
      "title": "Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding",
      "authors": "Yi-Hung Chou, Boyuan Jiang, Yi Wen Chen, Mingyue Weng, Victoria Jackson, Thomas Zimmermann, James A. Jones",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2512.22418",
      "code": null,
      "tags": [
        "human aspects of software engineering",
        "vibe coding",
        "large language models",
        "grounded theory",
        "prompt engineering",
        "software development practices"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/eab8ec990fa93b887bf7f5945d43ce53b02d7e23a90f66d7421522c4fb50f07c_w640_q70.webp",
      "contributions": "1. Conducted a grounded theory study of \"vibe coding\" practices through analysis of 20 videos, providing empirical data on this emerging phenomenon. 2. Identified a spectrum of developer behaviors, from full reliance on AI without code inspection to active examination and adaptation of generated outputs. 3. Revealed that developers must contend with the stochastic nature of LLM generation, framing debugging as \"rolling the dice,\" and that divergent mental models influence prompting, evaluation, and trust.",
      "summary": "This paper investigates the emerging practice of \"vibe coding,\" where developers build software primarily by prompting LLMs. Through a qualitative grounded theory study of 20 videos, the research reveals a spectrum of developer behaviors and the central challenge of dealing with stochastic AI outputs, described as \"rolling the dice.\" The findings highlight how developers' mental models shape their interaction with AI and point to new research directions for the future of software engineering.",
      "mindmap": "graph TB\n        A[Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM驱动的”氛围编码”实践如何定义与进行?/How is LLM-driven ”vibe coding” defined and practiced?]\n        C --> C1[对20个视频进行扎根理论研究/Grounded theory study of 20 videos]\n        C --> C2[分析直播与观点视频/Analyze live-streamed & opinion videos]\n        D --> D1[行为谱系: 从完全依赖到检查适配/Spectrum of behaviors: from full reliance to inspection & adaptation]\n        D --> D2[核心挑战: 生成的随机性/”掷骰子”/Core challenge: stochastic generation / ”rolling the dice”]\n        D --> D3[心智模型影响策略与信任/Mental models influence strategies & trust]"
    },
    {
      "title": "Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy",
      "authors": "Jiatao Quan, Ziyue Li, Tian Qi Zhu, Yuxuan Li, Baoying Wang, Wanda Pratt, Nan Gao",
      "institution": "University of Washington, The Hong Kong Polytechnic University, Nankai University",
      "link": "https://arxiv.org/pdf/2512.22462",
      "code": null,
      "tags": [
        "human-ai interaction",
        "boundary objects",
        "relational mediation",
        "marginalized clients",
        "therapeutic systems",
        "dynamic framework"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f8695c76e0392473389276989f78ab825dab06f2e38bdd785d2418d8ca9a1d80_w640_q70.webp",
      "contributions": "1. Identifies enduring relational challenges in psychotherapy for marginalized clients, such as trust-building and self-disclosure burdens. 2. Proposes the Dynamic Boundary Mediation Framework, which re-conceptualizes LLMs as adaptive boundary objects. 3. Delineates three specific forms of mediation (Epistemic, Relational, Contextual) to address knowledge gaps, power asymmetries, and therapy-life discontinuities.",
      "summary": "This paper argues that current framings of LLMs in mental health overlook their potential to mediate complex therapeutic relationships. Based on interviews with therapists and marginalized clients in China, the authors propose the Dynamic Boundary Mediation Framework, which positions LLM chatbots as adaptive boundary objects to bridge knowledge, power, and contextual gaps. This offers a pathway for designing AI systems that more effectively and accountably support therapeutic relationships for marginalized users.",
      "mindmap": "graph TB\n        Root[”Relational Mediators: LLM Chatbots as Boundary Objects in Psychotherapy”] --> Problem[”核心问题/Problem”]\n        Root --> Method[”主要方法/Method”]\n        Root --> Results[”关键结果/Results”]\n        Problem --> P1[”现有视角的局限/Current Framing Limitations”]\n        Problem --> P2[”边缘化客户的关系挑战/Relational Challenges for Marginalized Clients”]\n        Method --> M1[”动态边界调解框架/Dynamic Boundary Mediation Framework”]\n        Method --> M2[”作为边界对象的LLM/LLMs as Boundary Objects”]\n        Results --> R1[”三种调解形式/Three Forms of Mediation”]\n        Results --> R2[”关系问责的AI系统/Relationally Accountable AI Systems”]"
    },
    {
      "title": "SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding for Fine-Grained sEMG-Based Movement Decoding",
      "authors": "Zihan Weng, Chanlin Yi, Pouya Bashivan, Jing Lu, Fali Li, Dezhong Yao, Jingming Hou, Yangsong Zhang, Peng Xu",
      "institution": "University of Electronic Science and Technology of China",
      "link": "https://arxiv.org/pdf/2512.22481",
      "code": null,
      "tags": [
        "biomedical signal processing",
        "self-supervised learning",
        "surface electromyography",
        "rotary position encoding",
        "spectral pre-training",
        "movement decoding"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a5801cbdcbac93bf7df15e18531c5ff2653259e25003568da5b53b240d06d32c_w640_q70.webp",
      "contributions": "1. A novel self-supervised pre-training task that uses masked prediction of clustered STFT pseudo-labels to learn robust, physiologically relevant frequency patterns from sEMG signals. 2. A novel Cylindrical Rotary Position Embedding (CyRoPE) that factorizes embeddings along temporal and annular spatial dimensions to explicitly model the cylindrical topology of forearm electrode arrays. 3. The SPECTRE framework, which integrates these contributions to establish a new state-of-the-art for fine-grained movement decoding, validated on multiple datasets including data from individuals with amputation.",
      "summary": "The paper introduces SPECTRE, a domain-specific self-supervised learning framework for decoding fine-grained movements from surface electromyography (sEMG) signals. It proposes a spectral pre-training task using masked pseudo-label prediction and a novel cylindrical rotary position encoding to model sensor topology. Evaluations show SPECTRE significantly outperforms existing supervised and generic self-supervised baselines, providing a robust foundation for practical myoelectric interfaces.",
      "mindmap": "graph TB\n        A[SPECTRE: Spectral Pre-training Embeddings with Cylindrical Temporal Rotary Position Encoding] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Decoding fine-grained movement from noisy, non-stationary sEMG signals for prosthetic control]\n        C[主要方法/Method: Domain-specific SSL with spectral pre-training and Cylindrical Rotary Position Embedding (CyRoPE)]\n        D[关键结果/Results: New SOTA performance, outperforms supervised & generic SSL baselines, validated on amputation data]"
    },
    {
      "title": "Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification",
      "authors": "Argha Kamal Samanta, Deepak Mewada, Monalisa Sarma, Debasis Samanta",
      "institution": "Indian Institute of Technology, Kharagpur",
      "link": "https://arxiv.org/pdf/2512.22656",
      "code": null,
      "tags": [
        "medical signal processing",
        "electroencephalography",
        "multi-disorder classification",
        "sensitivity-oriented modeling",
        "clinical calibration",
        "feature importance analysis"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/636894ed25045336665fcbac593a58130411dff99c5d2a3e5a0cd50067ee44ec_w640_q70.webp",
      "contributions": "1. Proposes a clinically calibrated, sensitivity-prioritized machine learning framework for classifying eleven diverse neurological disorders from EEG data, addressing severe class imbalance. 2. Establishes realistic performance baselines for multi-disorder EEG classification, demonstrating recall exceeding 80% for most disorders with significant gains for low-prevalence conditions after threshold calibration. 3. Provides physiologically plausible feature importance analysis that aligns with established clinical EEG markers, validating the model's clinical relevance.",
      "summary": "This study addresses the challenge of automated, multi-disorder screening from clinical EEG data by developing disorder-aware machine learning models with decision thresholds explicitly calibrated to prioritize diagnostic sensitivity. The method uses a multi-domain feature set and is evaluated on a large, heterogeneous dataset, achieving high recall for most neurological disorder categories. The results establish performance baselines and demonstrate that sensitivity-prioritized automated analysis can support scalable EEG screening and triage in clinical practice.",
      "mindmap": "graph TB\n        A[Clinically Calibrated Machine Learning Benchmarks for Large-Scale Multi-Disorder EEG Classification] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem: Manual EEG interpretation is slow and variable; existing automation lacks multi-disorder support.]\n        C[主要方法/Method: Use multi-domain EEG features and train sensitivity-calibrated models under class imbalance.]\n        D[关键结果/Results: High recall (>80%) for most disorders; feature importance aligns with clinical knowledge.]"
    },
    {
      "title": "What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews",
      "authors": "Jaclyn Ocumpaugh, Zhanlan Wei, Amanda Barany, Xiner Liu, Andres Felipe Zambrano, Ryan Baker, Camille Gioradno",
      "institution": "University of Houston, University of Pennsylvania, Adelaide University",
      "link": "https://arxiv.org/pdf/2512.22747",
      "code": null,
      "tags": [
        "educational data mining",
        "Data-Driven Classroom Interviews (DDCIs)",
        "Ordered Network Analysis (ONA)",
        "rhetorical strategies"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c87056237d276d00b024d3b9369defa22ffde3d2c95bf0eaf093a1cbb2c5720c_w640_q70.webp",
      "contributions": "1. Proposes a novel method for analyzing interview sequences using Ordered Network Analysis (ONA) to re-examine data from a prior Epistemic Network Analysis study. 2. Investigates the relationship between interviewer rhetorical strategies and student response strategies in real-time classroom interviews. 3. Provides empirical evidence on how students with different levels of situational interest respond differently to interview prompts, confirming the reliability of interviewer protocols.",
      "summary": "This study investigates student responses in Data-Driven Classroom Interviews (DDCIs) by applying Ordered Network Analysis (ONA) to analyze the sequence of rhetorical strategies used by interviewers and students. It finds minor differences in responses based on student situational interest but overall confirms that interviewer-driven differences are minimal and guidelines are followed.",
      "mindmap": "graph TB\n        A[What do you say? A pilot study investigating student responses in Data Driven Classroom Interviews] --> B[核心问题/Problem: How do rhetorical strategies sequence in student interviews?]\n        A --> C[主要方法/Method: Use Ordered Network Analysis (ONA) to reanalyze interview data]\n        A --> D[关键结果/Results: Minor response differences by interest level; interviewers follow open-ended guidelines]"
    },
    {
      "title": "ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support",
      "authors": "Geoff Kimm, Linus Tan",
      "institution": "Swinburne University of Technology",
      "link": "https://arxiv.org/pdf/2512.22790",
      "code": null,
      "tags": [
        "human-computer interaction",
        "reflective practice",
        "agentic llm",
        "visual conversation interface",
        "non-linear dialogue",
        "multi-path reflection"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e0a7e3705fa584edc6bed6f2a636ce9e0b4f314e3e0c63213afc64d0d876a48f_w640_q70.webp",
      "contributions": "1. The design of a node-link, agentic LLM interface for reflective dialogue. 2. Transferable design knowledge on balancing structure and AI support to sustain reflection in complex, open-ended tasks. 3. An interactive tool that visualizes dialogue as a map, enabling branching, merging, and editing of past messages.",
      "summary": "This paper addresses the limitation of linear LLM interfaces in supporting reflective practice by introducing ChatGraPhT, a visual tool that represents dialogue as a non-linear, editable map and provides guidance from two agentic LLM assistants. The study finds that making conversation structure visible, allowing branching/merging, and suggesting idea combinations deepens user reflective engagement.",
      "mindmap": "graph TB\n        A[ChatGraPhT: A Visual Conversation Interface for Multi-Path Reflection with Agentic LLM Support] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[线性对话界面限制反思/Linear interfaces limit reflection support]\n        C --> C1[可视化对话地图/Visual dialogue map]\n        C --> C2[支持分支与合并/Supports branching & merging]\n        C --> C3[智能体LLM提供指导/Agentic LLMs provide guidance]\n        D --> D1[增强用户反思参与度/Deepened user reflective engagement]\n        D --> D2[提供可转移的设计知识/Provides transferable design knowledge]"
    },
    {
      "title": "Towards the analysis of team members well-being",
      "authors": "Zan Xu, Sari Nurfauziyyah, Anastasia Romanova, Kaamesh G S, Yiqun Gao, Maria Spichkova",
      "institution": "RMIT University",
      "link": "https://arxiv.org/pdf/2512.22845",
      "code": null,
      "tags": [
        "software development team well-being",
        "well-being",
        "software development",
        "team members",
        "positive feedback",
        "prototype"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44b6ecf51f08897fa2d6ed662014dae0fe49b0c593bf9e815394b288ffd9d465_w640_q70.webp",
      "contributions": "1. Presents the results of a project focused on analyzing the well-being of software development team members. 2. Identifies the feeling of being appreciated and acknowledged as a critical factor for team member well-being. 3. Describes the development of a prototype tool-supported framework aimed at providing personalized positive feedback without creating significant additional workload.",
      "summary": "This paper addresses the growing concern for the well-being of software development team members, emphasizing the importance of feeling appreciated. It presents a project that developed a prototype for a tool-supported, personalized framework to provide positive feedback. The goal is to improve well-being without adding substantial extra work for team members.",
      "mindmap": "graph TB\n        A[Towards the analysis of team members well-being] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[软件团队成员幸福感/Software Team Member Well-being]\n        B1 --> B2[关键因素：被赞赏与认可/Critical Factor: Feeling Appreciated & Acknowledged]\n        C --> C1[项目分析与原型开发/Project Analysis & Prototype Development]\n        D --> D1[提出工具支持的个性化框架/Proposed Tool-supported Personalized Framework]"
    },
    {
      "title": "Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation",
      "authors": "Shuntian Zheng, Guangming Wang, Jiaqi Li, Minzhe Ni, Yu Guan",
      "institution": "University of Warwick, University of Cambridge",
      "link": "https://arxiv.org/pdf/2512.23054",
      "code": null,
      "tags": [
        "human pose estimation",
        "millimeter-wave",
        "differentiable physics",
        "Gaussian representation",
        "human representation",
        "pose estimation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ace172569ea466a63abf72680293895dbb1d21feeae095f32ec879439596ed2f_w640_q70.webp",
      "contributions": "1. Proposes a novel Differentiable Physics-driven Human Representation (DIPR) as an alternative input paradigm for mmWave-based HPE, representing humans as an ensemble of Gaussian distributions. 2. Introduces a method to incorporate kinematic priors for DIPR initialization and multi-faceted optimization to ensure biomechanical validity. 3. Designs a strategy to simulate the mmWave processing pipeline and re-render a Heatmap from DIPR for comparison, preventing overfitting to kinematic constraints and spurious noise.",
      "summary": "This paper addresses the limitations of existing Heatmap and Point Cloud input paradigms for millimeter-wave-based human pose estimation by proposing a Differentiable Physics-driven Human Representation (DIPR). DIPR uses Gaussian distributions with kinematic and electromagnetic parameters, enhanced by kinematic priors and a physics-based re-rendering strategy to mitigate noise and improve feature quality. Experiments show that existing methods can easily integrate DIPR to achieve superior performance.",
      "mindmap": "graph TB\n        Root[”Differentiable Physics-Driven Human Representation for Millimeter-Wave Based Pose Estimation”] --> Problem[”核心问题/Problem: Limitations of Heatmap (noise) and Point Cloud (sparsity) in mmWave-based HPE”]\n        Root --> Method[”主要方法/Method: Proposes Differentiable Physics-driven Human Representation (DIPR) using Gaussian distributions with kinematic priors and physics simulation”]\n        Root --> Results[”关键结果/Results: DIPR integrates with existing methods and achieves superior performance”]"
    },
    {
      "title": "Reimagining the Traditional Flight Computer: E6BJA as a Modern, Multi-Platform Tool for Flight Calculations and Training",
      "authors": "Jamie J. Alnasir",
      "institution": "None (Inferred from author's email domain: al-nasir.com, which appears to be a personal domain)",
      "link": "https://arxiv.org/pdf/2512.23055",
      "code": null,
      "tags": [
        "human-computer interaction",
        "flight computer",
        "multi-platform software",
        "aviation training",
        "educational monographs",
        "weight and balance"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/728f903c57bf352d1339c863c7cb1986de9a626a56f8a15516317cf7068bcb83_w640_q70.webp",
      "contributions": "1. Development of E6BJA, a modern, multi-platform (iOS, Android, Windows, web) software flight computer that replicates and extends traditional flight calculations. 2. Integration of enhanced modeling capabilities (e.g., 1976 International Standard Atmosphere, carburetor icing risk) and aircraft-specific calculators with embedded educational explanations. 3. A comparative analysis demonstrating the tool's improvements over traditional devices in accuracy, error reduction, discoverability, and educational value for pilot training.",
      "summary": "This paper addresses the limitations of traditional mechanical and electronic flight computers by proposing E6BJA, a modern multi-platform software tool. E6BJA replicates core flight calculations while adding enhanced models and embedded educational content. The work concludes that this approach represents a meaningful evolution in pilot tools, improving safety, intuition, and instructional value in aviation training contexts.",
      "mindmap": "graph TB\n        Root(”Reimagining the Traditional Flight Computer”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”传统飞行计算机的局限性/Limitations of Traditional Flight Computers”)\n        Method --> M1(”开发多平台软件E6BJA/Develop Multi-Platform Software E6BJA”)\n        Method --> M2(”扩展计算与教育功能/Extend Calculations & Educational Features”)\n        Results --> R1(”证明在准确性等方面的改进/Demonstrate Improvements in Accuracy, etc.”)\n        Results --> R2(”支持更安全的飞行规划/Support Safer Flight Planning”)"
    },
    {
      "title": "Multimodal Functional Maximum Correlation for Emotion Recognition",
      "authors": "Deyang Zheng, Tianyi Zhang, Wenming Zheng, Shujian Yu",
      "institution": "Southeast University, Westlake University, Vrije Universiteit Amsterdam",
      "link": "https://arxiv.org/pdf/2512.23076",
      "code": "https://github.com/DY9910/MFMC",
      "tags": [
        "multimodal learning",
        "self-supervised learning",
        "dual total correlation",
        "functional maximum correlation analysis",
        "affective computing",
        "physiological signals"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/369b23e1c7a17085940402e88d2347afb3386819a237c48ac347be73127aea2a_w640_q70.webp",
      "contributions": "1. Proposes a novel self-supervised learning framework (MFMC) that maximizes higher-order multimodal dependence using a Dual Total Correlation objective. 2. Derives a tight sandwich bound and optimizes it using a functional maximum correlation analysis-based trace surrogate to capture joint interactions. 3. Demonstrates state-of-the-art or competitive performance on affective computing benchmarks, showing robustness to inter-subject variability.",
      "summary": "The paper addresses the challenge of learning joint dynamics from scarce and subjective emotion labels by proposing a self-supervised learning framework called MFMC. It captures higher-order multimodal dependencies beyond pairwise alignment, leading to improved emotion recognition performance on physiological signal benchmarks. The results show significant accuracy gains, particularly in subject-independent settings, highlighting the method's effectiveness.",
      "mindmap": "graph TB\n        A[MFMC for Emotion Recognition] --> B[核心问题/Problem: 情感状态表现为跨系统的协调但异质的生理反应，现有自监督方法难以捕捉多模态高阶交互。]\n        A --> C[主要方法/Method: 提出MFMC框架，通过Dual Total Correlation目标和Functional Maximum Correlation Analysis最大化高阶多模态依赖性。]\n        A --> D[关键结果/Results: 在多个基准测试中达到SOTA或竞争性性能，显著提升CEAP-360VR数据集上的准确率，对主体间变异性鲁棒。]"
    },
    {
      "title": "Cogniscope: Modeling Social Media Interactions as Digital Biomarkers for Early Detection of Cognitive Decline",
      "authors": "Ananya Drishti, Mahfuza Farooque",
      "institution": "Pennsylvania State University",
      "link": "https://arxiv.org/pdf/2512.23093",
      "code": null,
      "tags": [
        "digital health / computational social science",
        "digital biomarkers",
        "simulation framework",
        "multimodal fusion",
        "cognitive decline",
        "social media interactions"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/512eb1289cb5884089bd596bddf1510fefedfecb88019690b90dd2e6b6c77243_w640_q70.webp",
      "contributions": "1) A configurable simulation framework (Cogniscope) that generates social-media-style interaction data for studying digital biomarkers of cognitive health. 2) A method for modeling synthetic users with heterogeneous cognitive trajectories and embedding micro-tasks (e.g., video summarization, Q&A) into content streams to produce linguistic and behavioral signals. 3) The release of open-source tools, including generator code and synthetic datasets, to provide a controllable, ethically safe testbed for systematic investigation and benchmarking.",
      "summary": "The paper introduces Cogniscope, a simulation framework that generates synthetic social media interaction data to model digital biomarkers for early detection of cognitive decline. It fuses linguistic and behavioral signals from simulated user interactions to evaluate early detection models. The framework is released as an open-source tool to provide a benchmark for studying multimodal cognitive markers.",
      "mindmap": "graph TB\n        A[Cogniscope: Modeling Social Media Interactions as Digital Biomarkers] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统诊断工具成本高、侵入性强/Traditional diagnostic tools are invasive and costly]\n        B --> B2[需要大规模、生态有效的认知监测/Need for population-scale, ecologically valid monitoring]\n        C --> C1[模拟生成社交媒体交互数据/Simulate social-media-style interaction data]\n        C --> C2[嵌入微任务并提取多模态特征/Embed micro-tasks and extract multimodal features]\n        C --> C3[构建可控的合成用户测试平台/Build a controllable synthetic user testbed]\n        D --> D1[展示了检测性能的敏感性分析/Demonstrates sensitivity analysis of detection performance]\n        D --> D2[发布代码与数据集以支持可复现性/Releases code and datasets for reproducibility]\n        D --> D3[为社区提供基准资源/Provides a benchmark resource for the community]"
    },
    {
      "title": "ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions",
      "authors": "Mengyao Guo, Kexin Nie, Jinda Han, Guanyou Li, Adrian Wong",
      "institution": "Harbin Institute of Technology, Shenzhen; The University of Sydney; University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.23118",
      "code": null,
      "tags": [
        "human-computer interaction",
        "virtual reality",
        "AI-generated content",
        "emotional support",
        "extreme isolation",
        "concept validation"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/994a1c291c0ccdd72311f02214224ba7a2666234ccc35cb8193843b103cbd5ae_w640_q70.webp",
      "contributions": "1) A technically feasible future-oriented installation concept integrating transparent OLED displays with spaceship windows for real-time Earth connectivity. 2) A functional VR prototype for simulating astronaut isolation to test AI-generated content effectiveness in space HCI research. 3) Empirical insights and validated design implications (emotional pacing, explainable biophysical feedback, collective affective infrastructure) for AI-driven emotional support systems in extreme isolation.",
      "summary": "This paper addresses astronaut homesickness by proposing ReHome Earth, a dual-component approach featuring a futuristic space installation concept and a VR prototype for testing AI-generated emotional content. Since real astronauts were unavailable, the concept was validated with 84 terrestrial participants experiencing displacement, demonstrating strong emotional resonance and yielding key design principles for affective computing in isolated environments.",
      "mindmap": "graph TB\n        A[ReHome Earth: A VR-Based Concept Validation for AI-Driven Space Homesickness Interventions] --> B[核心问题/Problem: Emotional needs of astronauts on long-duration missions are underexplored.]\n        A --> C[主要方法/Method: Dual-component design: 1) Future installation concept with transparent OLED displays. 2) Functional VR prototype for testing AI content.]\n        A --> D[关键结果/Results: Strong emotional resonance validated with proxy participants. Three design implications identified.]"
    },
    {
      "title": "It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents",
      "authors": "Karolina Korgul, Yushi Yang, Arkadiusz Drohomirecki, Piotr Błaszczyk, Will Howard, Lukas Aichberger, Chris Russell, Philip H.S. Torr, Adam Mahdi, Adel Bibi",
      "institution": "University of Oxford, SoftServe, Johannes Kepler University Linz",
      "link": "https://arxiv.org/pdf/2512.23128",
      "code": null,
      "tags": [
        "prompt injection",
        "prompt injection",
        "web agents",
        "social-engineering",
        "benchmark",
        "autonomous agents"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c246d5b23e99374a1d754ec870b203d23f214abac92f8d20d849cc98d00e86ca_w640_q70.webp",
      "contributions": "1. Introduces the Task-Redirecting Agent Persuasion Benchmark (TRAP) for evaluating prompt injection vulnerabilities in web-based LLM agents. 2. Provides a modular social-engineering injection framework for controlled experiments on high-fidelity website clones. 3. Demonstrates systemic vulnerabilities, showing agents are susceptible to injection in 25% of tasks on average, with small interface changes often doubling success rates.",
      "summary": "The paper addresses the vulnerability of web-based LLM agents to prompt injection attacks, where hidden adversarial instructions can divert agents from their tasks. It introduces the TRAP benchmark, built on realistic website clones, to evaluate these vulnerabilities. The study finds significant susceptibility across models, revealing systemic, psychologically driven weaknesses in current agents.",
      "mindmap": "graph TB\n        Root[It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Web agents vulnerable to prompt injection attacks] --> Problem_Detail[问题详情/Problem Detail: Adversarial instructions in web content can divert agents from original tasks]\n        Method[主要方法/Method: Introduce TRAP benchmark & modular injection framework] --> Method_Detail[方法详情/Method Detail: Evaluation on high-fidelity website clones using social-engineering techniques]\n        Results[关键结果/Results: Agents susceptible in 25% of tasks on average] --> Results_Detail[结果详情/Results Detail: Small interface changes can double success rates, revealing systemic vulnerabilities]"
    },
    {
      "title": "Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice",
      "authors": "Junyeong Park, Jieun Han, Yeon Su Park, Youngbin Lee, Suin Kim, Juho Kim, Alice Oh, So-Yeon Ahn",
      "institution": "KAIST, Elice Inc.",
      "link": "https://arxiv.org/pdf/2512.23136",
      "code": null,
      "tags": [
        "language education",
        "code-switching",
        "large language models",
        "pedagogical design",
        "bilingual tutoring",
        "scaffolding"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/98df50b7ead70be4f32b9ae0c16ed0921a98d1c0003ee904a7fa9763956c75ae_w640_q70.webp",
      "contributions": "1. Conducted a six-week empirical study with 20 Korean EFL learners to understand their code-switching behaviors in LLM-mediated speaking practice. 2. Performed a qualitative study with nine English teachers to analyze and refine pedagogical strategies for responding to learner code-switching. 3. Derived design implications for bilingual LLM-powered tutors that leverage teacher expertise to transform code-switching into learning opportunities.",
      "summary": "This paper investigates how EFL learners use code-switching and how teachers can pedagogically respond within LLM-supported speaking practice. Through a six-week study with learners and a qualitative study with teachers, it finds learners use CSW for lexical, cultural, and emotional expression, prompting teachers to use selective and dynamic strategies. The work concludes with design implications for creating bilingual LLM tutors that effectively scaffold learning from code-switching.",
      "mindmap": "graph TB\n        A[Understanding EFL Learners' Code-Switching and Teachers' Pedagogical Approaches in LLM-Supported Speaking Practice] --> B[核心问题/Problem]\n        A --> C[主要方法/Method]\n        A --> D[关键结果/Results]\n        B --> B1[EFL学习者口语练习中代码转换(CSW)的教学设计不足/Underexplored pedagogical design for CSW in EFL speaking practice]\n        C --> C1[对20名韩国EFL学习者进行为期六周的LLM中介口语实践研究/Six-week LLM-mediated speaking study with 20 Korean EFL learners]\n        C --> C2[对9名英语教师进行定性研究，设计对CSW的回应/Qualitative study with 9 teachers designing responses to CSW]\n        D --> D1[学习者使用CSW表达词汇、文化和情感细微差别/Learners use CSW for lexical, cultural, emotional nuance]\n        D --> D2[教师采用选择性干预和动态支架策略/Teachers employ selective interventions & dynamic scaffolding]\n        D --> D3[提出双语LLM导师的设计启示/Design implications for bilingual LLM-powered tutors]"
    },
    {
      "title": "A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics",
      "authors": "Tobias Stähle, Matthijs Jansen op de Haar, Sophia Boyer, Rita Sevastjanova, Arpit Narechania, Mennatallah El-Assady",
      "institution": "ETH Zürich, The Hong Kong University of Science and Technology",
      "link": "https://arxiv.org/pdf/2512.23372",
      "code": null,
      "tags": [
        "agent system",
        "mixed-initiative visual analytics",
        "intelligent agents",
        "design space",
        "multi-agents",
        "human-AI collaboration"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d494dd1a9aa6a9f007780b691ff276d02fbb3b9060ca4a9fe9bf8ae5bb1fd9d_w640_q70.webp",
      "contributions": "1. Conducted a systematic review of 90 mixed-initiative visual analytics systems and 207 unique agents. 2. Proposed a novel design space for intelligent agents characterized by six dimensions (Configuration and Logic, World Model, Observations, Communication, Actions, Infrastructure). 3. Provided a framework for researchers and designers to explore design choices and situate new systems within the existing landscape.",
      "summary": "This paper addresses the lack of overarching design principles for intelligent agents in mixed-initiative visual analytics systems. Through a systematic review, the authors propose a six-dimensional design space that characterizes an agent's perception, understanding, action, and communication capabilities. They conclude by offering a framework for future system design and identifying research opportunities.",
      "mindmap": "graph TB\n        Root[A Design Space for Intelligent Agents in Mixed-Initiative Visual Analytics] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[缺乏智能代理的总体设计原则/Lack of overarching design principles for intelligent agents]\n        Method[主要方法/Method] --> M1[对90个系统进行系统综述/Systematic review of 90 systems]\n        Method --> M2[提出六维设计空间/Propose a six-dimensional design space]\n        Results[关键结果/Results] --> R1[用于探索设计选择的框架/Framework for exploring design choices]\n        Results --> R2[定位现有系统的景观/Situate systems in current landscape]"
    },
    {
      "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
      "authors": "Anh Nguyen, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "University of Adelaide",
      "link": "https://arxiv.org/pdf/2512.23385",
      "code": null,
      "tags": [
        "AI Security",
        "AI supply chain",
        "security taxonomy",
        "distilBERT classifier"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c00453e76598d08a965d2a15fe6e7b197cf1f19518d88f46a334b638da6327dc_w640_q70.webp",
      "contributions": "1. Developed a pipeline combining keyword matching with a fine-tuned distilBERT classifier to identify 312,868 security discussions from Hugging Face and GitHub. 2. Conducted a thematic analysis to create a fine-grained taxonomy of 32 security issues and 24 solutions across four themes (System/Software, External Tools/Ecosystem, Model, Data). 3. Provided empirical insights revealing that security issues stem from complex dependencies and black-box AI components, with Model and Data challenges often lacking concrete solutions.",
      "summary": "This paper investigates security issues in the AI supply chain by analyzing developer discussions from Hugging Face and GitHub. The authors use a keyword and classifier pipeline to build a large dataset and perform a thematic analysis to create a taxonomy of issues and solutions. They conclude that many security problems arise from dependencies and the black-box nature of AI, with solutions for Model and Data issues being particularly scarce.",
      "mindmap": "graph TB\n        Root[Securing the AI Supply Chain] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem] --> P1[AI供应链安全格局复杂/Complex AI supply chain security landscape]\n        Problem --> P2[缺乏对常见问题与解决方案的了解/Lack of knowledge on common issues & solutions]\n        Method[主要方法/Method] --> M1[实证调查/Empirical investigation]\n        M1 --> M1_1[数据源: Hugging Face, GitHub/Data Sources: Hugging Face, GitHub]\n        M1 --> M1_2[构建分类管道/Build classification pipeline]\n        M1_2 --> M1_2_1[关键词匹配+微调distilBERT/Keyword matching + fine-tuned distilBERT]\n        Results[关键结果/Results] --> R1[数据集: 312,868个安全讨论/Dataset: 312,868 security discussions]\n        Results --> R2[分类法: 32个问题, 24个解决方案/Taxonomy: 32 issues, 24 solutions]\n        Results --> R3[洞察: 依赖复杂性和黑盒性导致问题/Insight: Issues from dependencies & black-box nature]"
    },
    {
      "title": "Soft Robotic Technological Probe for Speculative Fashion Futures",
      "authors": "Amy Ingold, Loong Yi Lee, Richard Suphapol Diteesawat, Ajmal Roshan, Yael Zekaria, Edith-Clare Hall, Enrico Werner, Nahian Rahman, Elaine Czech, Jonathan Rossiter",
      "institution": "University of Bristol",
      "link": "https://arxiv.org/pdf/2512.23570",
      "code": null,
      "tags": [
        "human-robot interaction",
        "soft robotics",
        "wearable technology",
        "speculative design",
        "pneumatic actuation",
        "technological probe"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/961ff66eaf860636f7951016c0465ba6020b516e266f501287c6b78b23a9fafa_w640_q70.webp",
      "contributions": "1. The design and fabrication of \"Sumbrella,\" a novel soft robotic garment integrating origami-inspired bistable units, fabric pneumatic actuators, and computer vision. 2. The use of Sumbrella as a technological probe in a focus group study to explore public interpretation, interaction, and ethical concerns regarding future soft robotic wearables. 3. The contribution of key considerations for HRI, including kinesic communication, social dynamics, and ethical guidelines, and a reflection on the value of speculative design for evaluating social acceptability.",
      "summary": "This paper presents \"Sumbrella,\" a soft robotic garment designed as a speculative fashion probe to explore the social implications of wearable robotics. Through a focus group study, the authors used the prototype to gather insights on how people imagine future interactions with such technology, revealing both expressive potential and significant ethical concerns. The work contributes design considerations and a methodological reflection on using speculative design in Human-Robot Interaction research to address social meaning alongside functionality.",
      "mindmap": "graph TB\n        A[Soft Robotic Technological Probe for Speculative Fashion Futures] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[新兴可穿戴机器人需兼顾功能与社会意义/Emerging wearable robotics demand design addressing function and social meaning]\n        C --> C1[设计并制造Sumbrella软体机器人服装/Design and fabricate Sumbrella soft robotic garment]\n        C --> C2[作为技术探针进行焦点小组研究/Use as a technological probe in a focus group study]\n        D --> D1[引发对表达潜力与伦理风险的丰富讨论/Surfaced discussions on expressive potential and ethical risks]\n        D --> D2[为HRI贡献设计考量与伦理指南/Contributed HRI design considerations and ethical guidelines]\n        D --> D3[反思推测性设计方法的价值/Reflected on the value of speculative design]"
    },
    {
      "title": "Training AI Co-Scientists Using Rubric Rewards",
      "authors": "Shashwat Goel, Rishi Hazra, Dulhan Jayalath, Timon Willi, Parag Jain, William F. Shen, Ilias Leontiadis, Francesco Barbieri, Yoram Bachrach, Jonas Geiping, Chenxi Whitehouse",
      "institution": "Meta Superintelligence Labs, ELLIS Institute Tübingen, Max Planck Institute for Intelligent Systems, University of Oxford, University of Cambridge",
      "link": "https://arxiv.org/pdf/2512.23707",
      "code": null,
      "tags": [
        "reinforcement learning",
        "research plan generation",
        "self-grading",
        "rubric rewards"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/360be253dbca068ab35e1e7dcf794f5e43ae1d6fd7478850692d4a8ffc057d14_w640_q70.webp",
      "contributions": "1. A scalable method to automatically extract research goals and goal-specific grading rubrics from existing papers to build a training corpus. 2. A reinforcement learning framework with self-grading, where a frozen initial model acts as the grader using rubrics, enabling unsupervised improvement. 3. Demonstration of significant performance gains (12-22% relative improvement) and cross-domain generalization (e.g., to medical research) validated by human experts and frontier model juries.",
      "summary": "This paper addresses the challenge of training language models to generate high-quality, constraint-following research plans. The proposed method uses reinforcement learning with self-grading, where rubrics automatically extracted from research papers provide reward signals. The approach shows significant improvements in plan quality and generalizes across domains like machine learning and medicine, validated by human expert preference.",
      "mindmap": "graph TB\n        Root[”Training AI Co-Scientists Using Rubric Rewards”] --> Problem[”核心问题/Problem: LMs struggle to generate research plans that follow all constraints.”]\n        Root --> Method[”主要方法/Method: RL with self-grading using automatically extracted rubrics.”]\n        Root --> Results[”关键结果/Results: Human experts prefer finetuned model's plans; method generalizes across domains.”]"
    },
    {
      "title": "MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs for Health and Behavioral Understanding",
      "authors": "Aiwei Zhang, Arvind Pillai, Andrew Campbell, Nicholas C. Jacobson",
      "institution": "Dartmouth College",
      "link": "https://arxiv.org/pdf/2512.21506",
      "code": null,
      "tags": [
        "multi-modal training",
        "wearable sensing",
        "actigraphy encoder",
        "projection module",
        "frozen LLM",
        "behavioral summarization"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2a567cc66ec70f31b5dc9bb11a80d73d42749b10088a54744f9b87f208526ccd_w640_q70.webp",
      "contributions": "1. Introduces MotionTeller, a generative framework that natively integrates minute-level wearable activity data with large language models (LLMs) for free-text generation of daily behavioral summaries. 2. Constructs a novel, large-scale dataset of 54,383 (actigraphy, text) pairs derived from real-world NHANES recordings. 3. Demonstrates superior performance over prompt-based baselines in semantic fidelity and lexical accuracy, with qualitative analysis showing the model captures circadian structure and behavioral transitions.",
      "summary": "The paper addresses the challenge of generating natural language summaries from raw physiological signals like actigraphy. It proposes MotionTeller, a framework that integrates a pretrained actigraphy encoder with a frozen LLM via a projection module. The model, trained on a novel dataset, outperforms baselines in generating fluent, human-centered descriptions of daily behavior.",
      "mindmap": "graph TB\n        A[MotionTeller: Multi-modal Integration of Wearable Time-Series with LLMs] --> B[核心问题/Problem: How to generate natural language summaries from raw physiological signals like actigraphy?]\n        A --> C[主要方法/Method: Combines a pretrained actigraphy encoder and a projection module to map behavioral embeddings into a frozen LLM's token space.]\n        A --> D[关键结果/Results: Achieves high semantic fidelity (BERTScore-F1=0.924) and lexical accuracy (ROUGE-1=0.722), outperforming baselines by 7%.]"
    },
    {
      "title": "Human-AI Interaction Alignment: Designing, Evaluating, and Evolving Value-Centered AI For Reciprocal Human-AI Futures",
      "authors": "Hua Shen, Tiffany Knearem, Divy Thakkar, Pat Pataranutaporn, Anoop Sinha, Yike, Jenny T. Liang, Lama Ahmad, Tanu Mitra, Brad A. Myers, Yang Li",
      "institution": "NYU Shanghai, MBZUAI, Google, Massachusetts Institute of Technology, Carnegie Mellon University, OpenAI, University of Washington, Google DeepMind",
      "link": "https://arxiv.org/pdf/2512.21551",
      "code": null,
      "tags": [
        "human-ai interaction",
        "bidirectional alignment",
        "value-centered design",
        "interactive alignment"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/acbc6d9188f5aaa4289d9a01fb321cc29a9a54b03061c38e31010c7988a9ca12_w640_q70.webp",
      "contributions": "1. Proposes a shift from unidirectional to bidirectional human-AI alignment, framing it as a dynamic, reciprocal co-adaptation process. 2. Emphasizes embedding human and societal values into AI alignment research through value-centered design. 3. Aims to establish an interdisciplinary research agenda for responsible, reciprocal human-AI futures through collaborative workshop activities.",
      "summary": "This workshop paper identifies the inadequacy of traditional, one-way AI alignment and proposes a bidirectional human-AI alignment framework where humans and AI co-adapt through interaction and value-centered design. It aims to bring together interdisciplinary researchers to explore methods for interactive alignment and societal impact evaluation. The main conclusion is the need for a shared agenda to advance responsible, reciprocal collaboration between humans and AI systems.",
      "mindmap": "graph TB\n        A[Human-AI Interaction Alignment] --> B[核心问题/Problem: Unidirectional AI alignment is inadequate for dynamic human-AI interaction]\n        A --> C[主要方法/Method: Bidirectional alignment via value-centered design, interaction, and evaluation]\n        A --> D[关键结果/Results: Establishes agenda for reciprocal, responsible human-AI futures]"
    },
    {
      "title": "Bidirectional Human-AI Alignment in Education for Trustworthy Learning Environments",
      "authors": "Hua Shen",
      "institution": "NYU Shanghai, New York University",
      "link": "https://arxiv.org/pdf/2512.21552",
      "code": null,
      "tags": [
        "ai for education",
        "human-ai alignment",
        "trustworthy ai",
        "adaptive learning",
        "educational technology",
        "ai ethics"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b7f40fe114da7bae34b09e44db18fa32bb4f64e57bd01e75e96afc80c2ddc136_w640_q70.webp",
      "contributions": "1. Proposes the novel concept of \"bidirectional human-AI alignment\" for education, emphasizing mutual adaptation between humans and AI systems. 2. Explores the evolution of AI's role in education from a support tool to a collaborative partner, analyzing its impact on teacher roles and student agency. 3. Provides actionable strategies for policymakers, developers, and educators to ensure AI advances equity, transparency, and human flourishing in learning environments.",
      "summary": "This paper addresses the risks of AI in education, such as bias and loss of autonomy, by proposing the concept of bidirectional human-AI alignment. The method involves not only embedding human values into AI but also equipping educators and students to guide these technologies. It concludes that reframing AI adoption as a process of mutual adaptation is key to creating trustworthy learning environments where humans and AI can grow together.",
      "mindmap": "graph TB\n        A[论文标题: Bidirectional Human-AI Alignment in Education] --> B[核心问题/Problem: AI in education introduces risks to equity, privacy, and autonomy.]\n        A --> C[主要方法/Method: Proposes bidirectional alignment: embedding human values into AI and equipping humans to interpret/guide AI.]\n        A --> D[关键结果/Results: Envisions a future of mutual adaptation where AI advances equity, transparency, and human flourishing.]"
    },
    {
      "title": "Emotion-Aware Smart Home Automation Based on the eBICA Model",
      "authors": "Masaaki Yamauchi, Yiyuan Liang, Hiroko Hara, Hideyuki Shimonishi, Masayuki Murata",
      "institution": "The University of Osaka",
      "link": "https://arxiv.org/pdf/2512.21589",
      "code": null,
      "tags": [
        "affective computing",
        "eBICA",
        "emotion-aware automation",
        "psychological safety",
        "STAI-S",
        "smart home"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5260e7567742ea94b88d5dab934224f8814c9ad506e334dbc2220c01eec9093d_w640_q70.webp",
      "contributions": "1. Proposed an emotion-aware smart home automation framework guided by the eBICA model for dynamic control based on emotional state. 2. Conducted a proof-of-concept experiment demonstrating a significant reduction in state anxiety (STAI-S) through comfort-inducing automation. 3. Found that individual personality and anxiety traits modulate the relief effect, indicating a pathway for personalized emotion-adaptive systems.",
      "summary": "This study proposes a smart home automation framework that uses the eBICA model to adapt to a user's emotional state. A proof-of-concept experiment showed that anxiety-inducing automation significantly reduced user anxiety, demonstrating the framework's effectiveness in promoting psychological safety and its potential for personalization.",
      "mindmap": "graph TB\n        A[Emotion-Aware Smart Home Automation Based on the eBICA Model] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统自动化缺乏情感适应<br/>Traditional automation lacks emotional adaptation]\n        C --> C1[基于eBICA的框架<br/>eBICA-based framework]\n        C --> C2[概念验证实验<br/>Proof-of-concept experiment]\n        D --> D1[焦虑显著降低<br/>Significant anxiety reduction]\n        D --> D2[个性化潜力<br/>Personalization potential]"
    },
    {
      "title": "Ghostcrafting AI: Under the Rug of Platform Labor",
      "authors": "ATM Mizanur Rahman, Sharifa Sultana",
      "institution": "University of Illinois Urbana-Champaign",
      "link": "https://arxiv.org/pdf/2512.21649",
      "code": null,
      "tags": [
        "human-computer interaction",
        "platform labor",
        "ghostcrafting",
        "ethnography",
        "ethical AI",
        "situated learning"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49785e109f95da7d4a140badf3830b8bc2770c67e7d5e4a226476af7aecf0903_w640_q70.webp",
      "contributions": "1. Proposes the novel conceptual framework of \"Ghostcrafting AI\" to describe the invisible and essential labor of platform workers in building and sustaining AI systems. 2. Provides an in-depth ethnographic account of the situated learning practices and coping tactics of platform workers in Bangladesh, revealing their resourcefulness and agency. 3. Highlights the structural precarity and exploitation faced by these workers, arguing for urgent design, policy, and governance interventions to ensure fairness and recognition.",
      "summary": "This paper investigates the hidden labor of platform workers in the Global South who build and sustain AI systems. Through an eight-month ethnography in Bangladesh, it conceptualizes this as \"Ghostcrafting AI\" and documents how workers learn and cope with exploitative conditions. The study concludes that AI is fundamentally dependent on this invisible labor and calls for interventions to ensure fairness and sustainability in platform work.",
      "mindmap": "graph TB\n        Root[”Ghostcrafting AI: Under the Rug of Platform Labor”]\n        Root --> Problem[”核心问题/Problem: Platform laborers are indispensable yet invisible in building AI systems.”]\n        Root --> Method[”主要方法/Method: Eight-month ethnography in Bangladesh's platform labor industry.”]\n        Root --> Results[”关键结果/Results: Reveals workers' situated learning, coping tactics, and the need for fairness interventions.”]"
    },
    {
      "title": "Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG",
      "authors": "Gourav Siddhad, Anurag Singh, Rajkumar Saini, Partha Pratim Roy",
      "institution": "Indian Institute of Technology Roorkee, OP Jindal University, Luleå University of Technology, Indian Institute of Technology Dhanbad",
      "link": "https://arxiv.org/pdf/2512.21747",
      "code": null,
      "tags": [
        "brain-computer interface (BCI)",
        "EEG",
        "TSception",
        "Adaptive Average Pooling",
        "spatiotemporal features",
        "drowsiness detection"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43d71afc9fcee5064adfe94f1fb1d9f8a1c55ccd8d1c759dcd1b5801b9d23f46_w640_q70.webp",
      "contributions": "1. Proposed a Modified TSception architecture with a five-layer temporal refinement strategy to capture multi-scale brain dynamics. 2. Introduced Adaptive Average Pooling for structural flexibility to handle varying EEG input dimensions and a two-stage fusion mechanism for optimized spatiotemporal feature integration. 3. Demonstrated improved performance stability (reduced confidence interval) on the SEED-VIG dataset and state-of-the-art generalizability on the STEW mental workload dataset.",
      "summary": "This paper proposes a Modified TSception deep learning model for robust EEG-based detection of driver drowsiness and mental workload. The key modifications include a multi-layer temporal refinement strategy and Adaptive Average Pooling, which improve the model's stability and ability to handle varying input sizes. The model achieves comparable accuracy with significantly better stability on a drowsiness dataset and state-of-the-art results on a mental workload dataset, demonstrating its effectiveness for reliable cognitive state monitoring.",
      "mindmap": "graph TB\n        A[Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG] --> B(核心问题/Problem: Driver drowsiness detection for road safety)\n        A --> C(主要方法/Method: Modified TSception with temporal refinement & Adaptive Average Pooling)\n        A --> D(关键结果/Results: Improved stability on SEED-VIG, SOTA on STEW)"
    },
    {
      "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
      "authors": "Ting-Hao K.Huang, Ryan A. Rossi, Sungchul Kim, Tong Yu, Ting-Yao E. Hsu, Ho Yin, C. Lee Giles",
      "institution": "The Pennsylvania State University, Adobe Research",
      "link": "https://arxiv.org/pdf/2512.21789",
      "code": null,
      "tags": [
        "image captioning",
        "scientific figure captioning",
        "large-scale dataset",
        "domain-specific training",
        "human evaluation",
        "large language models (LLMs)"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3f7ba728eef6969e957e00de058f6caa0b6756df68bc13251efae06aa946322b_w640_q70.webp",
      "contributions": "1. Creation and continuous updating of a large-scale, real-world dataset of scientific figure-caption pairs from arXiv papers. 2. Conducting extensive evaluations, both automatic and human, on generated and author-written captions to assess quality. 3. Developing interactive systems and launching annual challenges to advance the field and help scientists write better captions.",
      "summary": "This paper reviews the SciCap project's first five years, which focused on generating and evaluating captions for scientific figures. The core method involved building a large-scale dataset from arXiv and exploring domain-specific training, similar to models like SciBERT, for captioning. The conclusion outlines key lessons learned and proposes future research directions to address unsolved challenges in the field.",
      "mindmap": "graph TB\n        Root[Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[科学图表说明质量差/Poor quality of scientific figure captions]\n        Problem --> P2[缺乏大规模真实数据集/Lack of large-scale real-world dataset]\n        Method --> M1[构建arXiv图表-说明对数据集/Construct arXiv figure-caption dataset]\n        Method --> M2[领域特定训练与评估/Domain-specific training & evaluation]\n        Method --> M3[应对大语言模型兴起/Navigate rise of LLMs]\n        Results --> R1[总结技术方法经验/Summarize technical & methodological lessons]\n        Results --> R2[提出未来挑战与方向/Outline future challenges & directions]"
    },
    {
      "title": "Generative Lecture: Making Lecture Videos Interactive with LLMs and AI Clone Instructors",
      "authors": "Hye-Young Jo, Ada Zhao, Xiaoan Liu, Ryo Suzuki",
      "institution": "University of Colorado Boulder",
      "link": "https://arxiv.org/pdf/2512.21796",
      "code": null,
      "tags": [
        "Human-Computer Interaction (HCI)",
        "interactive videos",
        "personalized learning",
        "AI clone instructor",
        "on-demand content generation",
        "generative AI"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/047a789db6b06e8758007487ecf18eb3b59ea0d4d56a243c23b590b8ad50497f_w640_q70.webp",
      "contributions": "1) Introduces the \"Generative Lecture\" concept for transforming passive lecture videos into interactive, two-way learning experiences using AI. 2) Proposes a system architecture that integrates an AI clone instructor (via HeyGen, ElevenLabs, GPT-5) with on-demand content generation to respond to student queries. 3) Identifies and implements eight key system features (e.g., on-demand clarification, adaptive quiz) based on a design study, and validates the system's usability and effectiveness through user studies.",
      "summary": "This paper introduces Generative Lecture, a system that uses generative AI and AI clone instructors to make existing lecture videos interactive, allowing students to ask questions and receive personalized, generated explanations. The system was developed based on user goals and features like on-demand clarification and adaptive quizzes. User studies suggest it enables effective two-way communication and supports personalized learning.",
      "mindmap": "graph TB\n        Root(”Generative Lecture<br>生成式讲座”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Lecture videos are passive<br>讲座视频是被动的”)\n        Method --> M1(”Use AI Clone Instructor & LLMs<br>使用AI克隆讲师和LLMs”)\n        Method --> M2(”Generate on-demand content<br>生成按需内容”)\n        Results --> R1(”Enables two-way communication<br>实现双向交流”)\n        Results --> R2(”Supports personalized learning<br>支持个性化学习”)"
    },
    {
      "title": "Conserved active information",
      "authors": "Yanchen Chen, Daniel Andrés Díaz-Pachón",
      "institution": "University of Miami",
      "link": "https://arxiv.org/pdf/2512.21834",
      "code": null,
      "tags": [
        "information theory",
        "conserved active information",
        "No-Free-Lunch",
        "KL divergence",
        "search space",
        "information conservation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1371f9cf2f5be050a2495fc2f2b19865fddd5c4a8834df1cd98fc2da7eea7111_w640_q70.webp",
      "contributions": "1. Introduces conserved active information (I⊕), a symmetric measure of net information gain/loss across a search space that respects No-Free-Lunch conservation. 2. Demonstrates that I⊕ can reveal regimes (e.g., strong knowledge reducing global disorder) that are hidden from traditional measures like KL divergence. 3. Applies the framework to resolve a longstanding critique of active information and illustrates its utility in domains like Markov chains and cosmological fine-tuning.",
      "summary": "This paper proposes a new information-theoretic measure called conserved active information (I⊕) to quantify net information change in search problems while respecting conservation laws. It shows that I⊕ uncovers scenarios, such as strong knowledge imposing order, which are missed by standard divergence measures. The work resolves a key critique of active information and enables applications in search and optimization.",
      "mindmap": "graph TB\n        Root[Conserved active information] --> Problem[核心问题/Problem: Limitations of average-focused information measures like KL divergence]\n        Root --> Method[主要方法/Method: Introduce conserved active information I⊕, a symmetric extension respecting No-Free-Lunch]\n        Root --> Results[关键结果/Results: I⊕ reveals hidden regimes (e.g., strong knowledge reduces disorder), resolves critique of active information]"
    },
    {
      "title": "Positive Narrativity Enhances Sense of Agency toward a VR Avatar",
      "authors": "Kureha Hamagashira, Miyuki Azuma, Sotaro Shimada",
      "institution": "Meiji University",
      "link": "https://arxiv.org/pdf/2512.21968",
      "code": null,
      "tags": [
        "virtual reality and embodiment",
        "full-body illusion",
        "sense of agency",
        "avatar narrativity",
        "Proteus effect",
        "bodily self-consciousness"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4d658df90fd7ef654f1504e1b44262071ad05b5dab0737598e4b949dd3f39383_w640_q70.webp",
      "contributions": "1. Investigated the explicit manipulation of avatar impressions using narrative context (positive vs. negative stories) to modulate the full-body illusion. 2. Demonstrated that positive narratives significantly enhance the sense of agency toward a VR avatar. 3. Found a positive correlation between the sense of agency and participants' perceived personal familiarity with the avatar.",
      "summary": "This study explores how narrative context affects embodiment in VR by having participants embody an avatar after hearing either a positive or negative story about it. The results show that positive narratives significantly increase the user's sense of agency over the avatar, and this feeling is linked to how familiar the avatar feels. This suggests that storytelling can be a tool to modulate virtual embodiment experiences.",
      "mindmap": "graph TB\n        A[Positive Narrativity Enhances Sense of Agency toward a VR Avatar] --> B(核心问题/Problem: How does narrative context affect the full-body illusion?);\n        A --> C(主要方法/Method: Participants embodied an avatar after listening to a positive or negative narrative about it.);\n        A --> D(关键结果/Results: Positive narratives enhanced sense of agency, which correlated with perceived familiarity.);"
    },
    {
      "title": "SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching",
      "authors": "Xiangwen Zhang, Xiaowei Dai, Runnan Chen, Xiaoming Chen, Zeke Zexi Hu",
      "institution": "Beijing Technology and Business University, The University of Sydney",
      "link": "https://arxiv.org/pdf/2512.22016",
      "code": null,
      "tags": [
        "Human-Computer Interaction (HCI)",
        "Gestural Interaction",
        "Physics Simulation",
        "Air-drawn Sketches",
        "VR Content Creation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/79eefb65bc566df3d83196a3500892e4d09f26b4aa064a68193142a9ec59b0c0_w640_q70.webp",
      "contributions": "1. A novel VR interaction framework (SketchPlay) that combines air-drawn sketches and gestures to create dynamic, physically realistic scenes. 2. A method that uses sketches to capture object/scene structure and gestures to convey physical cues (velocity, force) for defining motion and behavior. 3. Enables the generation of complex physical phenomena (rigid body motion, elastic deformation, cloth dynamics) through an intuitive, controller-free creation process.",
      "summary": "The paper proposes SketchPlay, a VR framework that allows users to create physically realistic dynamic scenes by sketching objects in the air and using gestures to define their motion. This method combines structural and dynamic intent to simulate phenomena like rigid body and cloth dynamics. The approach is shown to be more expressive and offer a better user experience than text-driven methods, lowering the barrier for non-expert creators.",
      "mindmap": "graph TB\n        A[SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching] --> B[核心问题/Problem: Creating physically realistic VR content is complex and requires expert tools, creating barriers for non-expert users.]\n        A --> C[主要方法/Method: A novel VR framework that transforms air-drawn sketches (for structure) and gestures (for physical cues like velocity/force) into dynamic, physically realistic scenes.]\n        A --> D[关键结果/Results: Offers significant advantages in expressiveness and user experience over traditional methods, lowering the entry barrier and showing potential for education, art, and storytelling.]"
    },
    {
      "title": "Context-Aware Intelligent Chatbot Framework Leveraging Mobile Sensing",
      "authors": "Ziyan Zhang, Nan Gao, Zhiqiang Nie, Shantanu Pal, Haining Zhang",
      "institution": "Nankai University, Tsinghua University, Deakin University",
      "link": "https://arxiv.org/pdf/2512.22032",
      "code": null,
      "tags": [
        "agent system",
        "mobile sensing",
        "context-aware",
        "large language models",
        "structured prompting",
        "digital health"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2ee41bc75f2109be1e0a7714aeb8ea0c7f389bba53adcab3bd17db8b8d415623_w640_q70.webp",
      "contributions": "1. Proposes a context-sensitive conversational assistant framework that integrates mobile sensing data with large language models. 2. Abstracts raw mobile sensing signals into 16 contextual scenarios and translates them into natural language prompts. 3. Designs a structured prompting system to guide the LLM in generating personalized and contextually relevant dialogue.",
      "summary": "This paper addresses the limitation of LLMs in understanding real-world user behavior by proposing a chatbot framework that uses mobile sensing data. The method abstracts sensor data into contextual scenarios and converts them into natural language prompts to guide the LLM. The work demonstrates the potential of passive behavioral data for creating personalized, context-aware conversational agents, particularly for digital health applications.",
      "mindmap": "graph TB\n        A[Context-Aware Intelligent Chatbot Framework<br>上下文感知智能聊天机器人框架] --> B[Problem: LLMs lack real-world user context<br>问题：大语言模型缺乏现实用户情境]\n        A --> C[Method: Integrate mobile sensing & structured prompts<br>方法：集成移动感知与结构化提示]\n        A --> D[Results: Personalized, context-relevant dialogue<br>结果：个性化、情境相关的对话]"
    },
    {
      "title": "StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars",
      "authors": "Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu",
      "institution": "Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University",
      "link": "https://arxiv.org/pdf/2512.22065",
      "code": "https://streamavatar.github.io",
      "tags": [
        "diffusion models",
        "autoregressive distillation",
        "adversarial refinement",
        "real-time streaming",
        "reference-anchored positional re-encoding",
        "consistency-aware discriminator"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp",
      "contributions": "1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.",
      "summary": "This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.",
      "mindmap": "graph TB\n        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]\n        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]\n        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]"
    },
    {
      "title": "Cooperation Through Indirect Reciprocity in Child-Robot Interactions",
      "authors": "Isabel Neto, Alexandre S. Pires, Filipa Correia, Fernando P. Santos",
      "institution": "Universidade de Lisboa, University of Amsterdam, Instituto Superior Técnico",
      "link": "https://arxiv.org/pdf/2512.20621",
      "code": null,
      "tags": [
        "human-robot interaction",
        "indirect reciprocity",
        "multi-armed bandit",
        "coordination dilemmas"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b4a49edd2299eeb19bce07b564c8061c35b829f55eb48557d15dbeabbbd028e0_w640_q70.webp",
      "contributions": "1. Demonstrated that the mechanism of indirect reciprocity can be successfully transposed from human-human interactions to child-robot interactions. 2. Showed that children's behavioral strategies provide a sufficient signal for multi-armed bandit algorithms to learn cooperative actions. 3. Analyzed how differences in learning algorithms impact the dynamics and outcomes of human-AI cooperation.",
      "summary": "This paper investigates whether indirect reciprocity, a mechanism for sustaining cooperation, applies to child-robot interactions. The authors combine laboratory experiments with theoretical modeling, using multi-armed bandit algorithms for the robots. They find that indirect reciprocity does extend to these interactions and that robots can learn to cooperate based on children's strategies, though this learning is highly dependent on the human strategies revealed.",
      "mindmap": "graph LR\n    A[Cooperation Through Indirect Reciprocity in Child-Robot Interactions] --> B(核心问题/Problem: Can indirect reciprocity enable cooperation between children and robots?)\n    A --> C(主要方法/Method: Laboratory experiments and theoretical modeling with multi-armed bandit algorithms)\n    A --> D(关键结果/Results: IR extends to child-robot groups; robots can learn cooperation from children's strategies)"
    },
    {
      "title": "Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps",
      "authors": "Jacqueline Yau, Katherine J. Mimnaugh, Evan G. Center, Timo Ojala, Steven M. LaValle, Wenzhen Yuan, Nancy Amato, Minje Kim, Kara Federmeier",
      "institution": "University of Illinois Urbana-Champaign, University of Oulu",
      "link": "https://arxiv.org/pdf/2512.20620",
      "code": null,
      "tags": [
        "brain-computer interface",
        "EEG",
        "cybersickness",
        "interpretability maps",
        "convolutional neural networks",
        "event-related potentials"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5601623e3cdfb620242f065ddf726ad49d48b3d131d2e3cc1f6fa48032be9946_w640_q70.webp",
      "contributions": "1. Introduced a method using CNNs and transformers with interpretability maps (integrated gradients and class activation) to identify EEG features for cybersickness classification. 2. Identified a consistent and surprising pattern: amplitudes near the left prefrontal cortex electrode are important for cybersickness classification. 3. Proposed using the identified scalp location as a tagged feature for better real-time cybersickness classification with EEG.",
      "summary": "This paper addresses the challenge of detecting cybersickness from EEG data by using event-related potentials to isolate sickness-related brain activity from visual stimulus confounds. The authors employ trained convolutional neural networks and transformer models with interpretability maps to identify key EEG features. The main finding is that amplitudes recorded near the left prefrontal cortex are consistently important for classification, suggesting this location as a valuable feature for real-time detection.",
      "mindmap": "graph LR\n        A[Uncovering Patterns of Brain Activity from EEG Data Consistently Associated with Cybersickness Using Neural Network Interpretability Maps] --> B(核心问题/Problem: Cybersickness detection in VR using EEG is confounded by visual stimulus processing.)\n        A --> C(主要方法/Method: Use ERPs, CNNs/Transformers, and interpretability maps (integrated gradients/class activation) to analyze EEG data.)\n        A --> D(关键结果/Results: Left prefrontal cortex electrode amplitudes are consistently important for cybersickness classification.)"
    },
    {
      "title": "Signal, Noise, and Burnout: A Human-Information Interaction Analysis of Voter Verification in a High-Volatility Environment",
      "authors": "Kijung Lee",
      "institution": "(Institution not explicitly stated in provided content; author name \"Kijung Lee\" present but no affiliation/email domain. Based on data source, likely an academic institution collaborating with Pew Research Center.)",
      "link": "https://arxiv.org/pdf/2512.20679",
      "code": null,
      "tags": [
        "human-information interaction",
        "epistemic self-efficacy",
        "information fatigue",
        "algorithmic filtering theory"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75e84ec2c80314744bb65f09fdbb5472f486e9a21a743399f645a4b93420c8f3_w640_q70.webp",
      "contributions": "1. Empirically tests the relationship between information source (social media vs. mainstream news) and perceived verification difficulty (epistemic self-efficacy) during a high-volatility election. 2. Identifies perceived exposure to inaccurate information as a mediator and information fatigue as a key moderator in the verification process. 3. Challenges platform-deterministic theories by finding that demographics and universal information fatigue, not platform type, are primary drivers of epistemic burden in volatile environments.",
      "summary": "This study analyzes how voters perceive their ability to verify news (epistemic self-efficacy) during the volatile 2024 U.S. election, using survey data to test hypotheses about information sources, misinformation exposure, and fatigue. Contrary to expectations, it finds no significant difference in verification difficulty between social media and mainstream news users, concluding that cognitive factors like universal information fatigue are more critical than platform choice.",
      "mindmap": "graph LR\n    A[Signal, Noise, and Burnout<br/>信号、噪声与倦怠] --> B(核心问题/Problem: Voter verification in high-volatility info environment<br/>高波动信息环境中的选民验证);\n    A --> C(主要方法/Method: Survey analysis (Pew Research data), tests mediation & moderation<br/>调查分析，检验中介与调节效应);\n    A --> D(关键结果/Results: No platform difference; burden driven by demographics & fatigue<br/>无平台差异；负担由人口统计与疲劳驱动);"
    },
    {
      "title": "From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education",
      "authors": "Iman Reihanian, Yunfei Hou, Qingquan Sun",
      "institution": "California State University, San Bernardino",
      "link": "https://arxiv.org/pdf/2512.20714",
      "code": null,
      "tags": [
        "educational technology",
        "generative AI",
        "personalization",
        "adaptive learning",
        "large language models",
        "intelligent tutoring systems"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8e46f313e494a41a4a12873eddb6320db4cd59b6fb958bb008fd6f6512729af4_w640_q70.webp",
      "contributions": "1. Identified and analyzed five key application domains for GenAI-enabled personalization in CS education: intelligent tutoring, personalized materials, formative feedback, AI-augmented assessment, and code review. 2. Synthesized four design patterns for successful implementations: context-aware tutoring anchored in student artifacts, multi-level hint structures, composition with traditional CS infrastructure, and human-in-the-loop quality assurance. 3. Proposed an exploration-first adoption framework for integrating GenAI, emphasizing piloting, instrumentation, learning-preserving defaults, and evidence-based scaling, while pairing recurrent risks with operational mitigations.",
      "summary": "This scoping review maps how generative AI enables personalized computer science education. It analyzes design choices across 32 studies and finds that structured implementations with explanation-first guidance and artifact grounding lead to more positive learning outcomes than unconstrained chat interfaces. The paper concludes that generative AI can provide precision scaffolding when embedded in audit-ready workflows that preserve productive struggle.",
      "mindmap": "graph LR\n    A[From Pilots to Practices: A Scoping Review of GenAI-Enabled Personalization in Computer Science Education] --> B[核心问题/Problem: Does GenAI personalization support or undermine CS learning?]\n    A --> C[主要方法/Method: Scoping review of 32 studies; Analysis of design choices & patterns]\n    A --> D[关键结果/Results: Structured designs (e.g., hint ladders, artifact grounding) are more effective; Proposes an exploration-first adoption framework]"
    },
    {
      "title": "YCB-Handovers Dataset: Analyzing Object Weight Impact on Human Handovers to Adapt Robotic Handover Motion",
      "authors": "Parag Khanna, Karen Jane Dsouza, Chunyu Wang, Mårten Björkman, Christian Smith",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.20847",
      "code": null,
      "tags": [
        "human-robot interaction",
        "motion capture",
        "dataset",
        "handover",
        "weight adaptation",
        "YCB dataset"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/af98ffe543cfd02847143e303696cbfb3dbc3991e06d43e1e59dda76a0ca8a49_w640_q70.webp",
      "contributions": "1. Introduces the novel YCB-Handovers dataset, capturing 2771 human-human handover motions with varied object weights., 2. Provides an analysis of the impact of object weight on human reaching motion during handovers., 3. Bridges a gap in human-robot collaboration research by enabling data-driven, human-inspired models for weight-sensitive robotic motion planning.",
      "summary": "This paper introduces the YCB-Handovers dataset, a motion capture dataset of human-human handovers with objects of varying weights. The dataset is built upon the YCB object set and aims to provide insights for developing intuitive, weight-adaptive robotic handover motions. The analysis shows that object weight significantly impacts human reaching motion, which can inform more natural and safe robotic handover behaviors.",
      "mindmap": "graph LR\n    A[YCB-Handovers Dataset] --> B(核心问题/Problem: Lack of data on weight impact in handovers for HRI);\n    A --> C(主要方法/Method: Capture human-human handover motions with varied weights);\n    A --> D(关键结果/Results: Dataset & analysis for weight-adaptive robotic motion);"
    },
    {
      "title": "Pioneering Multimodal Emotion Recognition in the Era of Large Models: From Closed Sets to Open Vocabularies",
      "authors": "Jing Han, Zhiqiang Gao, Shihao Gao, Jialing Liu, Hongyu Chen, Zixing Zhang, Björn W. Schuller",
      "institution": "Hunan University, University of Cambridge, Imperial College London",
      "link": "https://arxiv.org/pdf/2512.20938",
      "code": null,
      "tags": [
        "multimodal emotion recognition",
        "multimodal large language models",
        "open-vocabulary",
        "benchmarking",
        "fusion strategies",
        "prompt engineering"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5f45d32d66d378f46ef5f60f8b0f7b530f5e3f17019ab0a207910d809d72b3e5_w640_q70.webp",
      "contributions": "1. Conducted the first large-scale benchmarking study of open-vocabulary multimodal emotion recognition (MER-OV) using 19 mainstream MLLMs. 2. Systematically analyzed key factors affecting MLLM performance in MER-OV, including reasoning capacity, fusion strategies, and prompt design. 3. Identified that a two-stage, trimodal (audio, video, text) fusion approach with video as the most critical modality yields optimal performance, and found a narrow performance gap between open- and closed-source LLMs.",
      "summary": "This paper addresses the underexplored potential of Multimodal Large Language Models (MLLMs) for fine-grained, open-vocabulary emotion recognition. It presents a comprehensive benchmark on the OV-MERD dataset, evaluating 19 MLLMs and analyzing factors like fusion strategies and prompt design. The key findings are that a two-stage trimodal fusion works best, video is the most critical modality, and the performance gap between open- and closed-source models is surprisingly small.",
      "mindmap": "graph LR\n        A[Pioneering Multimodal Emotion Recognition<br>多模态情感识别前沿] --> B(核心问题/Problem: MLLMs在细粒度开放词汇情感理解中潜力未充分探索<br>MLLMs' potential for fine-grained, open-vocabulary emotion understanding is underexplored)\n        A --> C(主要方法/Method: 在OV-MERD数据集上对19个主流MLLMs进行首次大规模基准测试<br>First large-scale benchmark of 19 mainstream MLLMs on OV-MERD dataset)\n        A --> D(关键结果/Results: 两阶段三模态融合最优，视频最关键，开源与闭源模型差距小<br>Two-stage trimodal fusion is optimal, video is most critical, narrow gap between open- and closed-source LLMs)"
    },
    {
      "title": "From Human Bias to Robot Choice: How Occupational Contexts and Racial Priming Shape Robot Selection",
      "authors": "Jiangen He, Wanqi Zhang, Jessica Barfield",
      "institution": "The University of Tennessee, University of Kentucky",
      "link": "https://arxiv.org/pdf/2512.20951",
      "code": null,
      "tags": [
        "human-robot interaction",
        "racial bias",
        "occupational stereotypes",
        "stereotype priming",
        "skin tone discrimination",
        "anthropomorphism"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e05e8cac9fadcb40ef8a6f45c93ec8405326df2cb55fbb423081a31a9baebd6a_w640_q70.webp",
      "contributions": "1. Demonstrated that human occupational biases and skin-tone-based discrimination directly transfer to robot selection decisions. 2. Revealed distinct, context-dependent patterns of robot preference, with lighter-skinned agents favored in healthcare/education and darker-toned agents in construction/athletics. 3. Showed that exposure to human professionals of specific races can prime and systematically shift subsequent robot preferences in stereotype-consistent directions.",
      "summary": "This paper investigates how societal biases influence human decisions when selecting robots for professional roles. Through two experiments with over 1000 participants, the study found that preferences for robots with different skin tones vary by occupational context and can be primed by exposure to human racial stereotypes. The main conclusion is that robotic deployment risks perpetuating existing social inequalities by inheriting human biases from human-human evaluation contexts.",
      "mindmap": "graph LR\n    A[From Human Bias to Robot Choice<br>从人类偏见到机器人选择] --> B[核心问题/Problem<br>How societal biases influence robot selection<br>社会偏见如何影响机器人选择];\n    A --> C[主要方法/Method<br>Two experiments (N=1038) across four occupational contexts<br>两个实验，涵盖四种职业场景];\n    A --> D[关键结果/Results<br>Bias transfer & context-dependent preferences<br>偏见转移与情境依赖的偏好];"
    },
    {
      "title": "A Design Study Process Model for Medical Visualization",
      "authors": "Mengjie Fan, Liang Zhou",
      "institution": "Peking University Health Science Center",
      "link": "https://arxiv.org/pdf/2512.21034",
      "code": null,
      "tags": [
        "visualization",
        "design study",
        "process model",
        "medical visualization",
        "visual analysis",
        "interdisciplinary research"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e5fe74c72d51a03dca133118f52d887d90317100c302c2b1d5fca972d1219ded_w640_q70.webp",
      "contributions": "1. Proposes a novel design study process model specifically tailored for medical visualization, emphasizing stakeholder distinction, stage differentiation by analytic logic, and task classification. 2. Refines previous general visualization design models by incorporating characteristics of medical problems and providing actionable guidance for each step. 3. Demonstrates the model's utility by applying it to guide a new visual analysis method design and by reanalyzing three existing works, validating its practical framework.",
      "summary": "This paper introduces a specialized design study process model for medical visualization, developed through literature review and interdisciplinary experience. The model emphasizes stakeholder analysis, task classification, and provides step-by-step guidance to make visualization design more targeted and adaptable to medical complexity. The authors demonstrate its application and argue it provides a systematic theoretical and practical framework for interdisciplinary medical visualization research.",
      "mindmap": "graph LR\n    A[A Design Study Process Model for Medical Visualization<br>医学可视化设计研究过程模型] --> B(Problem: Lack of systematic methodology for medical visualization design<br>核心问题: 缺乏系统的医学可视化设计方法)\n    A --> C(Method: Propose a tailored design study process model<br>主要方法: 提出定制的设计研究过程模型)\n    A --> D(Results: Model provides theoretical framework and practical guidance<br>关键结果: 模型提供理论框架与实践指导)"
    },
    {
      "title": "When LLMs fall short in Deductive Coding: Model Comparison and Human AI Collaboration Workflow Design",
      "authors": "Zijian Li, Luzhen Tang, Mengyu Xia, Xinyu Li, Naping Chen, Dragan Gašević, Yizhou Fan",
      "institution": "Peking University, Monash University, Shantou University",
      "link": "https://arxiv.org/pdf/2512.21041",
      "code": null,
      "tags": [
        "text classification",
        "deductive coding",
        "large language models",
        "human-AI collaboration",
        "BERT",
        "learning analytics"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39f7b78a482db70949a4efca7f09dde7775d6e85ff7942e944bb807ed535f120_w640_q70.webp",
      "contributions": "1. Conducted a comparative performance evaluation of LLMs and BERT-based models for deductive coding, revealing LLMs' limitations in handling imbalanced data and theoretical interpretation. 2. Identified systematic errors and biases exhibited by LLMs in theory-driven coding tasks, highlighting their difficulty with semantic similarity. 3. Designed and evaluated a novel human-AI collaborative workflow that improves coding efficiency while maintaining reliability, demonstrating a practical path for scaling such tasks.",
      "summary": "This paper investigates the use of Large Language Models (LLMs) for automated, theory-driven (deductive) coding of educational dialogue data. It finds that LLMs do not outperform smaller BERT-based classifiers and exhibit systematic biases, leading to the design of a human-AI collaborative workflow. The main conclusion is that while LLMs have limitations in this specific task, a human-AI partnership offers a promising approach to maintain reliability while improving efficiency.",
      "mindmap": "graph LR\n    A[当LLMs在演绎编码中表现不足<br/>When LLMs Fall Short in Deductive Coding] --> B(核心问题/Problem: 自动化编码难以处理稀有代码，人工编码效率低<br/>Auto-coding struggles with rare codes, human coding is inefficient)\n    A --> C(主要方法/Method: 比较LLMs与BERT模型，设计人机协作工作流<br/>Compare LLMs vs. BERT, design Human-AI workflow)\n    A --> D(关键结果/Results: LLMs未超越BERT，存在系统误差；人机协作提升效率与可靠性<br/>LLMs underperform BERT, have biases; Human-AI collaboration improves efficiency & reliability)"
    },
    {
      "title": "DexAvatar: 3D Sign Language Reconstruction with Hand and Body Pose Priors",
      "authors": "Kaustubh Kundu, Hrishav Bakul Barua, Lucy Robertson-Bell, Zhixi Cai, Kalin Stefanov",
      "institution": "Monash University, TCS Research",
      "link": "https://arxiv.org/pdf/2512.21054",
      "code": "https://github.com/kaustesseract/DexAvatar",
      "tags": [
        "3D human pose estimation",
        "3D sign language reconstruction",
        "biomechanical accuracy",
        "hand and body pose priors",
        "monocular video",
        "SMPL-X"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/594bef871fe9a00d58a9f3f12c9a0b4bf4f66d3d738bd3f02dedcbad04bdcd25_w640_q70.webp",
      "contributions": "1. A novel framework (DexAvatar) for reconstructing biomechanically accurate 3D hand and body poses from monocular sign language videos. 2. The use of learned 3D hand and body pose priors to guide the reconstruction and overcome challenges like self-occlusion and motion blur. 3. Demonstrating strong performance on the SGNify benchmark, achieving a 35.11% improvement over the state-of-the-art.",
      "summary": "The paper introduces DexAvatar, a framework that uses learned 3D hand and body pose priors to reconstruct accurate 3D sign language poses from monocular videos. It addresses the limitations of existing 2D datasets and noisy 3D estimations. The method significantly outperforms prior work on the SGNify motion capture benchmark.",
      "mindmap": "graph LR\n        A[DexAvatar] --> B[核心问题/Problem: 手语视频缺乏准确3D数据，现有3D姿态估计质量差]\n        A --> C[主要方法/Method: 利用学习到的3D手部和身体姿态先验，从单目视频重建]\n        A --> D[关键结果/Results: 在SGNify数据集上性能提升35.11%]"
    },
    {
      "title": "Making AI Work: An Autoethnography of a Workaround in Higher Education",
      "authors": "Shang Chieh Lee, Bhuva Narayan, Simon Buckingham Shum, Stella Ng, A. Baki Kocaballi",
      "institution": "University of Technology Sydney",
      "link": "https://arxiv.org/pdf/2512.21055",
      "code": null,
      "tags": [
        "Information Systems",
        "Autoethnography",
        "Invisible Labour",
        "Workaround",
        "Sociotechnical Systems",
        "User Innovation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8c38d81a4b275e82620a51814d2cbc6d349963475ab4224ec58e70714de1ab37_w640_q70.webp",
      "contributions": "1. Provides an insider, autoethnographic account of the sociotechnical friction and \"invisible labour\" required to make enterprise GenAI functional in higher education. 2. Applies and extends Alter's theory of workarounds to interpret user-driven adaptations as integral acts of sociotechnical integration, not mere deviations. 3. Highlights the central paradox of GenAI workarounds: they enable functionality but can create unofficial \"shadow\" systems and obscure the crucial, politically charged labour involved.",
      "summary": "This study uses analytic autoethnography to examine a workaround developed when an institutional goal of empowering staff with GenAI clashed with technical and political constraints. It argues such workarounds are essential acts of sociotechnical integration that reveal the \"invisible labour\" needed to make AI functional, but this labour is often obscured, creating a paradox. The findings position this invisible labour as a core, rather than peripheral, component of practical GenAI implementation.",
      "mindmap": "graph LR\n        A[Making AI Work: An Autoethnography of a Workaround in Higher Education] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[GenAI实施中的社会技术摩擦与隐性劳动/Sociotechnical Friction & Invisible Labour in GenAI Implementation]\n        C --> C1[分析性自我民族志与工作区理论/Analytic Autoethnography & Workaround Theory]\n        D --> D1[工作区是核心的社会技术整合行为/Workarounds as Integral Sociotechnical Integration]\n        D --> D2[揭示了GenAI的整合悖论/Reveals GenAI Integration Paradox]"
    },
    {
      "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
      "authors": "Tomoaki Yamaguchi, Yutong Zhou, Masahiro Ryo, Keisuke Katsura",
      "institution": "Gifu University, Leibniz Centre for Agricultural Landscape Research (ZALF), Brandenburg University of Technology Cottbus–Senftenberg, Kyoto University",
      "link": "https://arxiv.org/pdf/2512.21066",
      "code": null,
      "tags": [
        "agent system",
        "Agentic AI",
        "SHAP",
        "Large Language Model",
        "Iterative Refinement",
        "Bias-Variance Trade-off"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/76e69e3950a2d09bc883a9cee931300bdfbeacc4e1e6094150a08db35366449e_w640_q70.webp",
      "contributions": "1. Proposes a novel Agentic XAI framework integrating SHAP-based explainability with multimodal LLM-driven iterative refinement for generating progressively enhanced explanations. 2. Demonstrates the framework's application and evaluation in a real-world agricultural recommendation system using rice yield data. 3. Identifies a bias-variance trade-off in iterative refinement, showing that early stopping (regularization) is crucial for optimizing explanation quality, challenging assumptions of monotonic improvement.",
      "summary": "This paper proposes an Agentic Explainable AI (XAI) framework that combines SHAP analysis with iterative refinement by a multimodal Large Language Model (LLM) to generate better explanations. The framework was tested as an agricultural recommendation system, and evaluations by both human experts and LLMs showed that explanation quality improved over initial rounds but declined with excessive refinement, revealing a bias-variance trade-off. The findings indicate that strategic early stopping is necessary to optimize the practical utility of such agentic XAI systems.",
      "mindmap": "graph LR\n        A[Agentic XAI Approach] --> B[核心问题/Problem: 向非专业人士解释XAI输出困难/Hard to communicate XAI outputs to laypersons]\n        A --> C[主要方法/Method: SHAP + 多模态LLM迭代优化/SHAP + Multimodal LLM Iterative Refinement]\n        A --> D[关键结果/Results: 早期迭代提升质量，过度优化导致下降/Early rounds improve quality, excessive refinement causes drop]"
    },
    {
      "title": "Volatile Organic Compounds for Stress Detection: A Scoping Review and Exploratory Feasibility Study with Low-Cost Sensors",
      "authors": "Nicolai Plintz, Marcus Vetter, Dirk Ifenthaler",
      "institution": "University of Mannheim, Technische Hochschule Mannheim, Curtis University",
      "link": "https://arxiv.org/pdf/2512.21105",
      "code": null,
      "tags": [
        "affective computing",
        "volatile organic compounds (VOCs)",
        "multimodal classification",
        "low-cost sensors",
        "stress detection",
        "Random Forest"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e1d1525e62afe978f13051c6114b1fe52c0caad526ab1d3c2dfb71cd0f5c3f29_w640_q70.webp",
      "contributions": "1. Comprehensive mapping of VOC biomarker evidence and technological gaps for emotion recognition. 2. Initial demonstration that low-cost sensors can capture stress-related VOC patterns in multimodal fusion. 3. Identification of key implementation challenges, such as interindividual variability and the need for individual calibration.",
      "summary": "This paper investigates the use of volatile organic compounds (VOCs) for stress detection by conducting a scoping review and an exploratory feasibility study with low-cost sensors. The study combines low-cost TVOC sensors with physiological monitoring and uses Random Forest for multimodal classification to detect laboratory-induced stress. The results show that VOC sensors contribute to model performance, but substantial interindividual variability highlights the need for larger samples and individual calibration.",
      "mindmap": "graph LR\n    A[Volatile Organic Compounds for Stress Detection] --> B[核心问题/Problem: VOC-based emotion recognition is underexplored with low-cost sensors]\n    A --> C[主要方法/Method: Scoping review + feasibility study with low-cost TVOC & physiological sensors, multimodal Random Forest]\n    A --> D[关键结果/Results: VOC patterns detectable, 77.3% accuracy, high variability, need for individual calibration]"
    },
    {
      "title": "Learning Factors in AI-Augmented Education: A Comparative Study of Middle and High School Students",
      "authors": "Gaia Ebli, Bianca Raimondi, Maurizio Gabbrielli",
      "institution": "University of Bologna",
      "link": "https://arxiv.org/pdf/2512.21246",
      "code": null,
      "tags": [
        "educational technology",
        "learning analytics",
        "correlation analysis",
        "text mining",
        "student perceptions",
        "human-ai interaction"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/37485735380aa9bf03e242b5a0fe4f8958c120a691a693af44376fb7f27c2b0b_w640_q70.webp",
      "contributions": "1. Investigated the interrelationships of four key learning factors (experience, clarity, comfort, motivation) in AI-augmented education, a gap in prior research. 2. Revealed a developmental moderator by comparing middle and high school students, finding holistic vs. differentiated evaluation patterns between age groups. 3. Established a foundation for age-specific AI integration strategies by showing perception dimensions actively mediate learning and their structure varies with developmental stage.",
      "summary": "This study investigates how key learning factors relate to each other in AI-augmented programming education for middle and high school students. Using a multimethod analysis combining correlation analysis and text mining on classroom data, it finds that middle school students evaluate AI tools holistically, while high school students assess different factors independently. The conclusion is that the structure of student perceptions is moderated by developmental stage, which should inform age-appropriate AI integration strategies.",
      "mindmap": "graph LR\n    A[论文标题: Learning Factors in AI-Augmented Education<br>Title: Learning Factors in AI-Augmented Education] --> B(核心问题/Problem: How do learning factor relationships vary by age in AI education?<br>核心问题/Problem: 学习因素关系在AI教育中如何随年龄变化？)\n    A --> C(主要方法/Method: Multimethod quantitative analysis (correlation & text mining)<br>主要方法/Method: 多方法定量分析（相关性与文本挖掘）)\n    A --> D(关键结果/Results: Middle school: holistic evaluation; High school: differentiated evaluation<br>关键结果/Results: 初中生: 整体性评估; 高中生: 差异性评估)"
    },
    {
      "title": "Quadrupped-Legged Robot Movement Plan Generation using Large Language Model",
      "authors": "Muhtadin, Vincentius Gusti Putu A. B. M., Ahmad Zaini, Mauridhi Hery Purnomo, I Ketut Eddy Purnama, Chastine Fatichah",
      "institution": "Institut Teknologi Sepuluh Nopember (ITS)",
      "link": "https://arxiv.org/pdf/2512.21293",
      "code": null,
      "tags": [
        "agent system",
        "Large Language Model",
        "quadruped robot",
        "ROS navigation",
        "sensor fusion",
        "offloaded inference"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70190e79023c7f7dad391e0e2059aa027ac578d23c266728acc6d3e205234b01_w640_q70.webp",
      "contributions": "1. A novel distributed control architecture that offloads LLM-based high-level planning to an external server to overcome the computational constraints of a lightweight quadruped robot platform. 2. A system that grounds natural language instructions into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, Odometry). 3. Experimental validation in a structured indoor environment demonstrating over 90% aggregate success rate, proving the feasibility of the offloaded LLM planning approach for real-world deployment.",
      "summary": "This paper proposes a distributed control framework that uses a Large Language Model (LLM) to generate navigation plans for a quadruped robot from natural language commands. The computationally intensive LLM inference is offloaded to an external server, while the robot executes the plans locally using ROS and sensor data. Experiments in indoor environments showed the system is robust, achieving over 90% success rate and validating the approach for intuitive robot control.",
      "mindmap": "graph LR\n    A[Quadrupped-Legged Robot Movement Plan Generation using Large Language Model] --> B(核心问题/Problem: High barrier to entry for robot control)\n    A --> C(主要方法/Method: Offloaded LLM planning + ROS navigation with sensor fusion)\n    A --> D(关键结果/Results: >90% success rate in indoor navigation)"
    },
    {
      "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks",
      "authors": "Ali Merali",
      "institution": "Yale University",
      "link": "https://arxiv.org/pdf/2512.21316",
      "code": null,
      "tags": [
        "large language models",
        "scaling laws",
        "economic productivity",
        "agentic workflows",
        "compute scaling",
        "algorithmic progress"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f148c34bb4d8aa66926afe66d00135fb826ae28f1253bfed833d9ff39c8b046d_w640_q70.webp",
      "contributions": "1. Derives empirical scaling laws linking LLM training compute to professional productivity gains. 2. Quantifies the relative contributions of increased compute (56%) versus algorithmic progress (44%) to annual productivity improvements. 3. Identifies a significant disparity in productivity gains between non-agentic analytical tasks and agentic workflows requiring tool use.",
      "summary": "This paper investigates the relationship between LLM capabilities and professional productivity through a preregistered experiment with over 500 professionals. It finds that each year of AI progress reduces task time by 8%, driven by both compute and algorithmic scaling, but gains are larger for analytical tasks than for agentic ones. The results suggest continued model scaling could significantly boost U.S. productivity over the next decade.",
      "mindmap": "graph LR\n    A[Scaling Laws for Economic Productivity<br/>经济生产力缩放定律] --> B(核心问题/Problem: LLM compute vs. professional productivity<br/>LLM计算与专业生产力的关系);\n    A --> C(主要方法/Method: Preregistered experiment with 500+ professionals using 13 LLMs<br/>使用13个LLM对500多名专业人员的预注册实验);\n    A --> D(关键结果/Results: 8% annual time reduction, 56% compute vs. 44% algorithm gains, larger gains for non-agentic tasks<br/>每年任务时间减少8%，56%源于计算，44%源于算法，非智能体任务收益更大);"
    },
    {
      "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "authors": "James K Ruffle, Samia Mohinta, Guilherme Pombo, Asthik Biswas, Alan Campbell, Indran Davagnanam, David Doig, Ahmed Hamman, Harpreet Hyare, Farrah Jabeen, Emma Lim, Dermot Mallon, Stephanie Owen, Sophie Wilkinson, Sebastian Brandner, Parashkev Nachev",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19707",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e098f2b53a5d94739b784dac1a98f71b53ab4d9f759c65700bc9e1f9500bbafd_w640_q70.webp",
      "contributions": "",
      "summary": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "mindmap": ""
    },
    {
      "title": "Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches",
      "authors": "Taoran Sheng, Manfred Huber",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19713",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8069c49480aa4056d903366d9a07ef262001809b60e89caaaab99b1ab6318bb6_w640_q70.webp",
      "contributions": "",
      "summary": "Reducing Label Dependency in Human Activity Recognition with Wearables: From Supervised Learning to Novel Weakly Self-Supervised Approaches",
      "mindmap": ""
    },
    {
      "title": "Predicting Student Actions in a Procedural Training Environment",
      "authors": "Diego Riofrío-Luzcando, Jaime Ramírez, Marta Berrocal-Lobo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19810",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5170ec33c553e90c5b65d0bc5448598b91b9a44fd63a92b56fd0d690965f3002_w640_q70.webp",
      "contributions": "",
      "summary": "Predicting Student Actions in a Procedural Training Environment",
      "mindmap": ""
    },
    {
      "title": "How Tech Workers Contend with Hazards of Humanlikeness in Generative AI",
      "authors": "Mark Díaz, Renee Shelby, Eric Corbett, Andrew Smart",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19832",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8537a350df62ef095164c7748f634e18b0a4279fffa1f30668439646406288e2_w640_q70.webp",
      "contributions": "",
      "summary": "How Tech Workers Contend with Hazards of Humanlikeness in Generative AI",
      "mindmap": ""
    },
    {
      "title": "Visualizing a Collective Student Model for Procedural Training Environments",
      "authors": "Diego Riofrío-Luzcando, Jaime RamÍrez, Cristian Moral, Angélica de Antonio, Marta Berrocal-Lobo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19885",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cdb96b3b8530271a31011b3f10e569cebea1d14b4385eb418b43cd79244a07f4_w640_q70.webp",
      "contributions": "",
      "summary": "Visualizing a Collective Student Model for Procedural Training Environments",
      "mindmap": ""
    },
    {
      "title": "Detecting cyberbullying in Spanish texts through deep learning techniques",
      "authors": "Paúl Cumba-Armijos, Diego Riofrío-Luzcando, Verónica Rodríguez-Arboleda, Joe Carrión-Jumbo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19899",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5d2f7ccac215958604ec2bafb628962c08cfada143b59dda8159af7e4af21661_w640_q70.webp",
      "contributions": "",
      "summary": "Detecting cyberbullying in Spanish texts through deep learning techniques",
      "mindmap": ""
    },
    {
      "title": "Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling",
      "authors": "Hanna Noyce, Emily Olejniczak, Vaskar Raychoudhury, Roger O. Smith, Md Osman Gani",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19898",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94f45bbd3f136fa9ca9486c93a06494dfae76a62569d1f5464b47a9b2a351451_w640_q70.webp",
      "contributions": "",
      "summary": "Free-Will vs Free-Wheel: Understanding Community Accessibility Requirements of Wheelchair Users through Interviews, Participatory Action, and Modeling",
      "mindmap": ""
    },
    {
      "title": "Developers' Experience with Generative AI -- First Insights from an Empirical Mixed-Methods Field Study",
      "authors": "Charlotte Brandebusemeyer, Tobias Schimmer, Bert Arnrich",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19926",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b805b7a034106a6a896aa4fa59536e4c24c1b4390bbad36d9762174995633c68_w640_q70.webp",
      "contributions": "",
      "summary": "Developers' Experience with Generative AI -- First Insights from an Empirical Mixed-Methods Field Study",
      "mindmap": ""
    },
    {
      "title": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "authors": "Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19950",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25282dd436ce0f7a5fabd0438ec9d8be57567585d626e71c9a9af6d0ac8451b9_w640_q70.webp",
      "contributions": "",
      "summary": "Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems",
      "mindmap": ""
    },
    {
      "title": "Stories That Teach: Eastern Wisdom for Human-AI Creative Partnerships",
      "authors": "Kexin Nie, Xin Tang, Mengyao Guo, Ze Gao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19999",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/10e9f9340ffb8b63217712d4aa9b0cc137057244e1829ea40c95f6374ff796aa_w640_q70.webp",
      "contributions": "",
      "summary": "Stories That Teach: Eastern Wisdom for Human-AI Creative Partnerships",
      "mindmap": ""
    },
    {
      "title": "/UnmuteAll: Modeling Verbal Communication Patterns of Collaborative Contexts in MOBA Games",
      "authors": "Yongchan Son, Jahun Jang, Been An, Jimoon Kang, Eunji Park",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20116",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/50853e5216c134f7f20eb67d59c4cc443da21824aa6454f1a64a094910c9658a_w640_q70.webp",
      "contributions": "",
      "summary": "/UnmuteAll: Modeling Verbal Communication Patterns of Collaborative Contexts in MOBA Games",
      "mindmap": ""
    },
    {
      "title": "Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs",
      "authors": "Cyrus Vachha, Yixiao Kang, Zach Dive, Ashwat Chidambaram, Anik Gupta, Eunice Jun, Bjoern Hartmann",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20129",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8400f1033a93635b0a5b706c568585f557f04cf8533a2b77ce1c55f08e14bef6_w640_q70.webp",
      "contributions": "",
      "summary": "Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs",
      "mindmap": ""
    },
    {
      "title": "Competing or Collaborating? The Role of Hackathon Formats in Shaping Team Dynamics and Project Choices",
      "authors": "Sadia Nasrin Tisha, Md Nazmus Sakib, Sanorita Dey",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20181",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dadc4f214409965b0df1005c180cb9f7bf76c16e776028372175b81d9eed7768_w640_q70.webp",
      "contributions": "",
      "summary": "Competing or Collaborating? The Role of Hackathon Formats in Shaping Team Dynamics and Project Choices",
      "mindmap": ""
    },
    {
      "title": "RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making",
      "authors": "Dan Chen, Heye Huang, Tiantian Chen, Zheng Li, Yongji Li, Yuhui Xu, Sikai Chen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20179",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/ba879d80c9d58b4f8d7942ebda77c8c4b993bb9018f484a08adfe360eb40c02c_w640_q70.webp",
      "contributions": "",
      "summary": "RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making",
      "mindmap": ""
    },
    {
      "title": "The Effect of Empathic Expression Levels in Virtual Human Interaction: A Controlled Experiment",
      "authors": "Sung Park, Daeho Yoon, Jungmin Lee",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20221",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e8f259bc1362a522f2cf043a9f6b686f7f77b7e14bfd0671a5c5cba5ec63c8af_w640_q70.webp",
      "contributions": "",
      "summary": "The Effect of Empathic Expression Levels in Virtual Human Interaction: A Controlled Experiment",
      "mindmap": ""
    },
    {
      "title": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "authors": "Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20298",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e46ae09622d9142a3896f2528685617edcbaae96bc105754e16929ed630e3f0_w640_q70.webp",
      "contributions": "",
      "summary": "Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives",
      "mindmap": ""
    },
    {
      "title": "Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback",
      "authors": "Péter Ferenc Gyarmati, Dominik Moritz, Torsten Möller, Laura Koesten",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20306",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6e3c684df7664b2bee4d03afb8801d141ceb15c7e18014fd3e28b28a59515f72_w640_q70.webp",
      "contributions": "",
      "summary": "Structured Visualization Design Knowledge for Grounding Generative Reasoning and Situated Feedback",
      "mindmap": ""
    },
    {
      "title": "A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry",
      "authors": "Sharareh Mirzaei, Stephanie Bunt, Susan M Bogus",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20584",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/510c6ffa270afe4e2d7d2de70c289fafe8fd64d4a4f5f29123b3c70e64963e1e_w640_q70.webp",
      "contributions": "",
      "summary": "A human-centered approach to reframing job satisfaction in the BIM-enabled construction industry",
      "mindmap": ""
    },
    {
      "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "authors": "Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20586",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39917d1df3de96bd690d947b78c3c6d1ac037b54cc0591faa464cbc08cd8c729_w640_q70.webp",
      "contributions": "",
      "summary": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
      "mindmap": ""
    },
    {
      "title": "Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots",
      "authors": "Jacqueline Borgstedt, Jake Bhattacharyya, Matteo Iovino, Frank E. Pollick, Stephen Brewster",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18032",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bab5ccc615f8631e1cb919fee6836987e7793d4803a41430b431092ecd0b25ec_w640_q70.webp",
      "contributions": "",
      "summary": "Design and Integration of Thermal and Vibrotactile Feedback for Lifelike Touch in Social Robots",
      "mindmap": ""
    },
    {
      "title": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "authors": "Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18080",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp",
      "contributions": "",
      "summary": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "mindmap": ""
    },
    {
      "title": "Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling",
      "authors": "Ohoud Alzahrani, Russell Beale, Robert J. Hendley",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18077",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ecf679a26dc73049a43a2ec8c3b4b9a5b43ae16a82684041393594d146210f5_w640_q70.webp",
      "contributions": "",
      "summary": "Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling",
      "mindmap": ""
    },
    {
      "title": "Dimensionality Reduction Considered Harmful (Some of the Time)",
      "authors": "Hyeon Jeon",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18230",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f6c2d73af1d47933ab3fe41a060a175bd40e436f32af5added065941e07d0688_w640_q70.webp",
      "contributions": "",
      "summary": "Dimensionality Reduction Considered Harmful (Some of the Time)",
      "mindmap": ""
    },
    {
      "title": "The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics",
      "authors": "Lixiang Yan, Xibin Han, Yu Zhang, Samuel Greiff, Inge Molenaar, Roberto Martinez-Maldonado, Yizhou Fan, Linxuan Zhao, Xinyu Li, Yueqiao Jin, Dragan Gašević",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18234",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/08ef726a4410ec8749e604356b03b8afe29560606553bd2e895fa2e42f8a4d5a_w640_q70.webp",
      "contributions": "",
      "summary": "The Social Blindspot in Human-AI Collaboration: How Undetected AI Personas Reshape Team Dynamics",
      "mindmap": ""
    },
    {
      "title": "Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction",
      "authors": "Yueqiao Jin, Roberto Martinez-Maldonado, Dragan Gašević, Lixiang Yan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18239",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/90be08528a89abf308b5f3179521424f35d5720259e534256a475d02ffe5b615_w640_q70.webp",
      "contributions": "",
      "summary": "Emergent Learner Agency in Implicit Human-AI Collaboration: How AI Personas Reshape Creative-Regulatory Interaction",
      "mindmap": ""
    },
    {
      "title": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "authors": "M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18261",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp",
      "contributions": "",
      "summary": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "mindmap": ""
    },
    {
      "title": "MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity",
      "authors": "Giuseppe Desolda, Francesco Greco, Rosa Lanzilotti, Cesare Tucci",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18303",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/013fffaf0ed613ccbcc22a6990caf81327b42deac91bfb1c67c73cad88e1ab96_w640_q70.webp",
      "contributions": "",
      "summary": "MORPHEUS: A Multidimensional Framework for Modeling, Measuring, and Mitigating Human Factors in Cybersecurity",
      "mindmap": ""
    },
    {
      "title": "Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback",
      "authors": "Alvaro Becerra, Ruth Cobos",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18306",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5aea301733440fbfacf134ac6fba24972e030dde31a68ce5c51ab92a244cc90b_w640_q70.webp",
      "contributions": "",
      "summary": "Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback",
      "mindmap": ""
    },
    {
      "title": "Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models",
      "authors": "Chao Wen, Tung Phung, Pronita Mehrotra, Sumit Gulwani, Tomohiro Nagashima, Adish Singla",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18388",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/26ae3275661776caa174169c0f345d17624c81b4d8a6d11a881528d1b3ebbea4_w640_q70.webp",
      "contributions": "",
      "summary": "Exploration vs. Fixation: Scaffolding Divergent and Convergent Thinking for Human-AI Co-Creation with Generative Models",
      "mindmap": ""
    },
    {
      "title": "Towards Scalable Visual Data Wrangling via Direct Manipulation",
      "authors": "El Kindi Rezig, Mir Mahathir Mohammad, Nicolas Baret, Ricardo Mayerhofer, Andrew McNutt, Paul Rosen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18405",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/790118e217a177acb4ecd824d816066f84640176a4ebb5ada4193f1841afa44c_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Scalable Visual Data Wrangling via Direct Manipulation",
      "mindmap": ""
    },
    {
      "title": "Listening to the Mind: Earable Acoustic Sensing of Cognitive Load",
      "authors": "Xijia Wei, Ting Dang, Khaldoon Al-Naimi, Yang Liu, Fahim Kawsar, Alessandro Montanari",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18413",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fe6c29fe2181ae377bd035ff882e6e32ace02c50f40c9f4359bd37cc647e34d7_w640_q70.webp",
      "contributions": "",
      "summary": "Listening to the Mind: Earable Acoustic Sensing of Cognitive Load",
      "mindmap": ""
    },
    {
      "title": "When Robots Say No: The Empathic Ethical Disobedience Benchmark",
      "authors": "Dmytro Kuzmenko, Nadiya Shvai",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18474",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/083ac27bf9c1ba565d26a4c6417b20f994336e4ffb3cb410b3b93d3ef36fb6aa_w640_q70.webp",
      "contributions": "",
      "summary": "When Robots Say No: The Empathic Ethical Disobedience Benchmark",
      "mindmap": ""
    },
    {
      "title": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "authors": "Amit Barman, Atanu Mandal, Sudip Kumar Naskar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18593",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c4841f825fcb7cf75a5d51e2769fdede7c9af6b25f2faafea290804903c41f40_w640_q70.webp",
      "contributions": "",
      "summary": "From Scratch to Fine-Tuned: A Comparative Study of Transformer Training Strategies for Legal Machine Translation",
      "mindmap": ""
    },
    {
      "title": "DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System",
      "authors": "Zelin Wan, Han Jun Yoon, Nithin Alluru, Terrence J. Moore, Frederica F. Nelson, Seunghyun Yoon, Hyuk Lim, Dan Dongseong Kim, Jin-Hee Cho",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18616",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fabd2c171e25c623bc7edccb8e1ef0506a926726f1d2a534aaa0d5113899beef_w640_q70.webp",
      "contributions": "",
      "summary": "DASH: Deception-Augmented Shared Mental Model for a Human-Machine Teaming System",
      "mindmap": ""
    },
    {
      "title": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "authors": "Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18622",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06b3e9f87e02f31154a7925036d456a7d4454e03d1f54e60c44ca1f788fae13_w640_q70.webp",
      "contributions": "",
      "summary": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
      "mindmap": ""
    },
    {
      "title": "\"Even GPT Can Reject Me\": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)",
      "authors": "Yang Ni, Tong Yang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18776",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4c436bec45a43d86e53531d2849399bd87e6bf3d4305bd5fa2744e56f7b83352_w640_q70.webp",
      "contributions": "",
      "summary": "\"Even GPT Can Reject Me\": Conceptualizing Abrupt Refusal Secondary Harm (ARSH) and Reimagining Psychological AI Safety with Compassionate Completion Standard (CCS)",
      "mindmap": ""
    },
    {
      "title": "VizDefender: Unmasking Visualization Tampering through Proactive Localization and Intent Inference",
      "authors": "Sicheng Song, Yanjie Zhang, Zixin Chen, Huamin Qu, Changbo Wang, Chenhui Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18853",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6df051754b8f594a7ef88a46e4855d2eb43c4c662b1afbca9997caf2b4fbad53_w640_q70.webp",
      "contributions": "",
      "summary": "VizDefender: Unmasking Visualization Tampering through Proactive Localization and Intent Inference",
      "mindmap": ""
    },
    {
      "title": "Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers",
      "authors": "Bruno Campello de Souza",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18871",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/446f3fb717e9b018a154458859c845d2583ea717613eb2a7397f53ffedb8700f_w640_q70.webp",
      "contributions": "",
      "summary": "Psychometric Validation of the Sophotechnic Mediation Scale and a New Understanding of the Development of GenAI Mastery: Lessons from 3,392 Adult Brazilian Workers",
      "mindmap": ""
    },
    {
      "title": "Household Plastic Recycling: Empirical Insights and Design Explorations",
      "authors": "Ashley Colley, Emma Kirjavainen, Sari Tapio, Jonna Häkkilä",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18889",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9e98f1d82cd1fbc384d43ddf57fd109888b3f5c78ff0d869daa0ef5d4c713eb3_w640_q70.webp",
      "contributions": "",
      "summary": "Household Plastic Recycling: Empirical Insights and Design Explorations",
      "mindmap": ""
    },
    {
      "title": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "authors": "Shaokang Jiang, Daye Nam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18925",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp",
      "contributions": "",
      "summary": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "mindmap": ""
    },
    {
      "title": "Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration",
      "authors": "Oliver Huang, Muhammad Fatir, Steven Luo, Sangho Suh, Hariharan Subramonyam, Carolina Nobre",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18920",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a117e0515b80f1075c391fa0ed128ff0ec8754654d3747ba533f99d3d9311e6f_w640_q70.webp",
      "contributions": "",
      "summary": "Narrative Scaffolding: Transforming Data-Driven Sensemaking Through Narrative-First Exploration",
      "mindmap": ""
    },
    {
      "title": "Advancing Accessibility: Augmented Reality Solutions for the Blind and Disabled in Bangladesh",
      "authors": "Md Minhazul Islam Munna, Al Amin, Xin Wang, Hongbin Ma",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19047",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e57af16bdaba33a67888f0850a24ef71eead80c5314fcfb4dde2288280f7820e_w640_q70.webp",
      "contributions": "",
      "summary": "Advancing Accessibility: Augmented Reality Solutions for the Blind and Disabled in Bangladesh",
      "mindmap": ""
    },
    {
      "title": "Towards a collaborative digital platform for railway infrastructure projects",
      "authors": "Pierre Jehel, Pierre-Étienne Gautier, Judicaël Dehotin, Flavien Viguier",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19169",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3874b7105990b7eea9564e4b1e9114f5f53c8e95ba6b7ddfc4422d6b9542ed5a_w640_q70.webp",
      "contributions": "",
      "summary": "Towards a collaborative digital platform for railway infrastructure projects",
      "mindmap": ""
    },
    {
      "title": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "authors": "Walter Quattrociocchi, Valerio Capraro, Matjaž Perc",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19466",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0e38aa1bf279d77f222964e2fa6eaf6b1a85cc9955ae786124894e9ed3fb93c1_w640_q70.webp",
      "contributions": "",
      "summary": "Epistemological Fault Lines Between Human and Artificial Intelligence",
      "mindmap": ""
    },
    {
      "title": "The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge",
      "authors": "Angjelin Hila",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19570",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/14053cd17ec2f7fbfad183ca144e70fb650f93b135eca28453bda97a810f7db4_w640_q70.webp",
      "contributions": "",
      "summary": "The Epistemological Consequences of Large Language Models: Rethinking collective intelligence and institutional knowledge",
      "mindmap": ""
    },
    {
      "title": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "authors": "Gabrielle O'Brien, Alexis Parker, Nasir Eisty, Jeffrey Carver",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19644",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa42c82b2739bd1b4c7111c0c7d29876d12dbca90ed48e9b300fd1778d6e033_w640_q70.webp",
      "contributions": "",
      "summary": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "mindmap": ""
    },
    {
      "title": "Adversarial VR: An Open-Source Testbed for Evaluating Adversarial Robustness of VR Cybersickness Detection and Mitigation",
      "authors": "Istiak Ahmed, Ripan Kumar Kundu, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.17029",
      "code": null,
      "tags": [
        "others",
        "adversarial attacks",
        "deep learning",
        "cybersickness detection",
        "visual tunneling",
        "MI-FGSM",
        "PGD",
        "C&W",
        "DeepTCN",
        "Transformer"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3a313962e09ceaa54a617d0e446a38a50ffa44d10894d76830f87cd1e74c0749_w640_q70.webp",
      "contributions": "",
      "summary": "This paper introduces Adversarial-VR, an open-source Unity testbed that integrates DeepTCN and Transformer models for real-time cybersickness detection and mitigation, and evaluates their robustness against adversarial attacks like MI-FGSM, PGD, and C&W. The results show these attacks can successfully fool the system, significantly degrading model accuracy and preventing correct mitigation.",
      "mindmap": ""
    },
    {
      "title": "Bots Don't Sit Still: A Longitudinal Study of Bot Behaviour Change, Temporal Drift, and Feature-Structure Evolution",
      "authors": "Ohoud Alzahrani, Russell Beale, Bob Hendley",
      "institution": "University of Birmingham",
      "link": "https://arxiv.org/pdf/2512.17067",
      "code": null,
      "tags": [
        "social media analysis",
        "Augmented Dickey-Fuller test",
        "KPSS test",
        "Spearman correlation",
        "Chi-square test",
        "time series analysis",
        "stationarity testing"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper conducts a longitudinal study analyzing the temporal behavior of promotional Twitter bots using time series analysis and statistical tests on ten content-based meta-features. It finds that bot behavior is non-stationary, with individual features and their interdependencies evolving systematically over time and across bot generations. The conclusion is that bot-detection systems must account for this dynamic adaptation and avoid treating behavioral features as static.",
      "mindmap": ""
    },
    {
      "title": "PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases",
      "authors": "Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.17172",
      "code": null,
      "tags": [
        "llm inference",
        "large language model",
        "explainable ai",
        "augmented reality",
        "personalized explanations",
        "real-time object detection",
        "user study"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7767a7bc851a49f82148423782803913a5c377f60c4ce3a9cc7383c22a6d08a4_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes PILAR, a framework that uses a pre-trained large language model (LLM) to generate unified, context-aware, and personalized explanations for AI-driven augmented reality systems. A user study on a recipe recommendation prototype showed that the LLM-based explanation interface significantly improved user task performance and perceived transparency compared to a traditional template-based approach.",
      "mindmap": ""
    },
    {
      "title": "Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation",
      "authors": "Alexandre Personnic, Mihai Bâce",
      "institution": "KU Leuven",
      "link": "https://arxiv.org/pdf/2512.17673",
      "code": null,
      "tags": [
        "computer vision",
        "spatio-temporal feature representation",
        "channel attention",
        "self-attention",
        "recurrent neural networks",
        "video-based gaze estimation"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes the Spatio-Temporal Gaze Network (ST-Gaze), which combines a CNN backbone with channel and self-attention modules to fuse eye and face features, then models intra- and inter-frame dynamics by treating features as a spatial sequence propagated through time. The method achieves state-of-the-art performance on the EVE dataset, demonstrating that preserving intra-frame spatial context is superior to premature spatial pooling for robust video-based gaze estimation.",
      "mindmap": ""
    },
    {
      "title": "ShareChat: A Dataset of Chatbot Conversations in the Wild",
      "authors": "Yueru Yan, Tuc Nguyen, Bo Su, Melissa Lieffers, Thai Le",
      "institution": "Indiana University",
      "link": "https://arxiv.org/pdf/2512.17843",
      "code": null,
      "tags": [
        "others",
        "dataset collection",
        "multi-turn conversations",
        "platform affordances",
        "source citations",
        "temporal analysis",
        "cross-platform corpus"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces ShareChat, a large-scale dataset of real-world chatbot conversations collected from five major platforms, preserving interface-specific features like reasoning traces and source links. It demonstrates the dataset's utility through analyses of user intent satisfaction, citation behaviors, and evolving usage patterns, providing a resource for studying authentic user-LLM interactions.",
      "mindmap": ""
    },
    {
      "title": "Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life",
      "authors": "Corey M. Abramson",
      "institution": "Rice University, UC San Francisco",
      "link": "https://arxiv.org/pdf/2512.17850",
      "code": null,
      "tags": [
        "computational social science",
        "computational text analysis",
        "machine learning (ML)",
        "natural language processing (NLP)",
        "ethnography",
        "in-depth interviews",
        "mixed-methods"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper demonstrates how computational social science tools like machine learning and natural language processing can be integrated with traditional qualitative methods (e.g., ethnography, interviews) to study aging. It concludes that these computational methods can broaden qualitative research by streamlining workflows, scaling up projects, and enabling new multi-method insights, rather than replacing its foundational approaches.",
      "mindmap": ""
    },
    {
      "title": "Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes",
      "authors": "Shrinivass Arunachalam Balasubramanian",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15775",
      "code": null,
      "tags": [
        "others",
        "Finite Exponential Continuous State Machine (FECSM)",
        "Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA)",
        "Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU)",
        "HDBSCAN",
        "min-max normalization",
        "User Interface Change Prediction Index (UICPI)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a dynamic web UI optimization method that uses a Finite Exponential Continuous State Machine for cross-device responsiveness assessment and a novel Quokka Nonlinear Difference Swarm Optimization Algorithm for design optimization. The core technique involves classifying user experience changes with a Bidirectional Gated Luong and Mish Recurrent Unit model. The main conclusion is that this integrated approach achieves an average fitness of 98.5632% for optimal UI design by incorporating cross-responsiveness assessment and user behavior patterns.",
      "mindmap": ""
    },
    {
      "title": "A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis",
      "authors": "Qidi Xu, Nuzha Amjad, Grace Giles, Alexa Cumming, De'angelo Hermesky, Alexander Wen, Min Ji Kwak, Yejin Kim",
      "institution": "UTHealth Houston, University of Texas Health Sciences Center Houston",
      "link": "https://arxiv.org/pdf/2512.16063",
      "code": null,
      "tags": [
        "llm inference",
        "multi-agent framework",
        "large language model",
        "qualitative thematic analysis",
        "Collaborative Theme Identification Agent (CoTI)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces CoTI, a multi-agent LLM framework with three specialized agents to automate qualitative thematic analysis of patient interviews. The framework was applied to heart failure patient data and produced results more aligned with a senior investigator's analysis than with junior investigators or baseline NLP models. However, collaboration between the AI and junior investigators showed limited gains, suggesting a risk of over-reliance that may hinder independent critical thinking.",
      "mindmap": ""
    },
    {
      "title": "Scaling Text2SQL via LLM-efficient Schema Filtering with Functional Dependency Graph Rerankers",
      "authors": "Thanh Dat Hoang, Thanh Tam Nguyen, Thanh Trung Huynh, Hongzhi Yin, Quoc Viet Hung Nguyen",
      "institution": "Griffith University, VinUniversity, The University of Queensland",
      "link": "https://arxiv.org/pdf/2512.16083",
      "code": null,
      "tags": [
        "llm inference",
        "schema filtering",
        "functional dependency graph",
        "graph transformer",
        "Steiner-tree heuristic",
        "query-aware LLM encoder"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces GRAST-SQL, a framework for scaling Text2SQL systems by efficiently filtering and compacting database schemas before prompting an LLM. It uses a query-aware LLM encoder, a graph transformer over functional dependencies, and a Steiner-tree heuristic to select a relevant, connectivity-preserving sub-schema. The method achieves high recall and precision while maintaining low latency and scaling to schemas with over 23,000 columns.",
      "mindmap": ""
    },
    {
      "title": "Evaluation of Generative Models for Emotional 3D Animation Generation in VR",
      "authors": "Kiran Chhatre, Renan Guarese, Andrii Matviienko, Christopher Peters",
      "institution": "KTH Royal Institute of Technology",
      "link": "https://arxiv.org/pdf/2512.16081",
      "code": null,
      "tags": [
        "multi-modal inference",
        "generative models",
        "speech-driven 3D animation",
        "virtual reality (VR)",
        "user study",
        "emotional arousal",
        "reconstruction-based method",
        "UV mapping",
        "OpenXR",
        "Blender"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper evaluates generative models for creating emotional 3D animations synchronized with speech in a VR environment using a user study. The main conclusion is that models explicitly modeling emotions achieve higher recognition accuracy than those focusing only on speech synchrony, but current models struggle with subtle emotions and underperform compared to reconstruction-based methods in facial expression quality.",
      "mindmap": ""
    },
    {
      "title": "ParamExplorer: A framework for exploring parameters in generative art",
      "authors": "Julien Gachadoat, Guillaume Lagarde",
      "institution": "University of Bordeaux",
      "link": "https://arxiv.org/pdf/2512.16529",
      "code": null,
      "tags": [
        "generative art",
        "reinforcement learning",
        "parameter exploration",
        "human-in-the-loop",
        "p5.js"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ParamExplorer, an interactive and modular framework inspired by reinforcement learning to help explore the high-dimensional parameter spaces of generative art algorithms. It allows for exploration guided by human feedback and integrates with existing p5.js projects. The framework implements and evaluates several automated exploration strategies, referred to as agents, to discover aesthetically compelling outputs more efficiently than manual trial-and-error.",
      "mindmap": ""
    },
    {
      "title": "OMG-Bench: A New Challenging Benchmark for Skeleton-based Online Micro Hand Gesture Recognition",
      "authors": "Haochen Chang, Pengfei Ren, Buyuan Zhang, Da Li, Tianhao Han, Haoyang Zhang, Liang Xie, Hongbo Chen, Erwei Yin",
      "institution": "Sun Yat-sen University, Beijing University of Posts and Telecommunications, Shanghai Jiao Tong University, Nankai University, Academy of Military Sciences, Tianjin Artificial Intelligence Innovation Center",
      "link": "https://arxiv.org/pdf/2512.16727",
      "code": null,
      "tags": [
        "computer vision",
        "transformer",
        "memory banks",
        "self-supervised learning",
        "multi-view hand pose estimation",
        "online gesture recognition"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces OMG-Bench, a large-scale benchmark for skeleton-based online micro hand gesture recognition, and proposes HMATr, a hierarchical memory-augmented transformer framework that unifies gesture detection and classification. HMATr leverages memory banks to preserve historical context and uses learnable queries to encode gesture positions, outperforming state-of-the-art methods by 7.6% in detection rate.",
      "mindmap": ""
    },
    {
      "title": "Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error",
      "authors": "Claudia Vale Oliveira, Nelson Zagalo, Filipe Silva, Anabela Brandao, Syeda Faryal Hussain Khurrum, Joaquim Santos",
      "institution": "University of Aveiro",
      "link": "https://arxiv.org/pdf/2512.16750",
      "code": null,
      "tags": [
        "human-ai interaction",
        "human evaluation",
        "epistemic failure",
        "plausibility",
        "hermeneutic error",
        "co-construction",
        "verification burden",
        "cognitive drift"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper uses a multi-round, multi-LLM evaluation with interdisciplinary tasks to study how humans interpret model responses. It concludes that LLM errors are co-constructed through model-generated plausibility and human interpretive shortcuts, shifting error analysis from predictive metrics to a relational, hermeneutic process.",
      "mindmap": ""
    },
    {
      "title": "PrivateXR: Defending Privacy Attacks in Extended Reality Through Explainable AI-Guided Differential Privacy",
      "authors": "Ripan Kumar Kundu, Istiak Ahmed, Khaza Anuarul Hoque",
      "institution": "University of Missouri-Columbia",
      "link": "https://arxiv.org/pdf/2512.16851",
      "code": null,
      "tags": [
        "others",
        "explainable AI",
        "differential privacy",
        "membership inference attack",
        "re-identification attack",
        "post-hoc explanations",
        "feature selection",
        "transformer models"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes a framework that uses explainable AI (XAI) to identify the most influential features in AI-XR models and selectively applies differential privacy (DP) to those features during inference to defend against privacy attacks. This XAI-guided DP approach reduces the success rates of membership inference and re-identification attacks while preserving model accuracy and improving inference time compared to traditional DP. The method is deployed as a system called PrivateXR on an HTC VIVE Pro headset, allowing users to adjust privacy levels in real-time during XR gameplay.",
      "mindmap": ""
    },
    {
      "title": "TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge",
      "authors": "Matteo Fasulo, Giusy Spacone, Thorir Mar Ingolfsson, Yawei Li, Luca Benini, Andrea Cossettini",
      "institution": "ETH Zurich, University of Bologna",
      "link": "https://arxiv.org/pdf/2512.15729",
      "code": null,
      "tags": [
        "others",
        "transformer encoder",
        "self-supervised learning",
        "foundation model",
        "edge deployment",
        "ultra-low-power microcontroller",
        "gesture classification",
        "kinematic regression"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces TinyMyo, a lightweight Transformer-based foundation model pre-trained with self-supervised learning for EMG signal processing. It demonstrates strong generalization across multiple tasks like gesture classification and speech recognition while being deployable on an ultra-low-power microcontroller. The work provides an open-source, efficient model for edge-based EMG applications.",
      "mindmap": ""
    },
    {
      "title": "I am here for you\": How relational conversational AI appeals to adolescents, especially those who are socially and emotionally vulnerable",
      "authors": "Pilyoung Kim, Yun Xie, Sujin Yang",
      "institution": "University of Denver, Ewha Womans University",
      "link": "https://arxiv.org/pdf/2512.15117",
      "code": null,
      "tags": [
        "human-computer interaction",
        "conversational AI",
        "relational style",
        "transparent style",
        "anthropomorphism",
        "emotional reliance",
        "online experiment",
        "adolescent psychology"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper uses a preregistered online experiment with adolescent-parent dyads to compare how relational versus transparent conversational styles in AI chatbots affect adolescents' perceptions. It finds that a relational style increases anthropomorphism, trust, and emotional closeness, and is especially preferred by socially and emotionally vulnerable adolescents, highlighting a design consideration for youth AI safety.",
      "mindmap": ""
    },
    {
      "title": "Managing Ambiguity: A Proof of Concept of Human-AI Symbiotic Sense-making based on Quantum-Inspired Cognitive Mechanism of Rogue Variable Detection",
      "authors": "Agnieszka Bienkowska, Jacek Malecki, Alexander Mathiesen-Ohman, Katarzyna Tworek",
      "institution": "Not explicitly stated in provided text",
      "link": "https://arxiv.org/pdf/2512.15325",
      "code": null,
      "tags": [
        "others",
        "Quantum-Inspired Rogue Variable Modeling (QRVM)",
        "Human-in-the-Loop Decoherence",
        "Collective Cognitive Inference",
        "proof of concept",
        "VUCA"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper presents a proof of concept for the LAIZA human-AI symbiotic system, which uses a quantum-inspired cognitive mechanism to detect \"rogue variables\" and manage ambiguity by preserving interpretive plurality and activating structured human clarification. The main conclusion is that this approach enables proactive scenario-based preparation and decisive action in VUCA environments, reframing ambiguity as a key construct for organizational resilience.",
      "mindmap": ""
    },
    {
      "title": "Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality",
      "authors": "Efe Bozkir, Enkelejda Kasneci",
      "institution": "Technical University of Munich",
      "link": "https://arxiv.org/pdf/2512.15343",
      "code": null,
      "tags": [
        "others",
        "crowdsourcing",
        "user study",
        "extended reality",
        "conversational agents",
        "privacy",
        "technology acceptance model"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper conducted a large-scale crowdsourcing study with 1036 participants to explore user acceptance and concerns regarding LLM-powered conversational agents in Extended Reality (XR). The study found that while users generally accept these technologies, they express significant concerns about security, privacy, social implications, and trust, with location data being the most sensitive. The results highlight the importance of practitioner transparency and that familiarity with generative AI increases acceptance, while prior XR device ownership is linked to lower acceptance.",
      "mindmap": ""
    },
    {
      "title": "Intent-Driven UAM Rescheduling",
      "authors": "Jeongseok Kim, Kangjin Kim",
      "institution": "Cleverplant, Chodang University",
      "link": "https://arxiv.org/pdf/2512.15462",
      "code": null,
      "tags": [
        "scheduling optimization",
        "Mixed Integer Linear Programming (MILP)",
        "Answer Set Programming (ASP)",
        "three-valued logic",
        "decision tree",
        "Resource-Constrained Project Scheduling Problem (RCPSP)"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes an intent-driven rescheduling system for Urban Air Mobility (UAM) that combines Answer Set Programming (ASP) with Mixed Integer Linear Programming (MILP) to handle ambiguous human requests. It uses a three-valued logic and a decision tree to interpret vague user intents for transparent schedule adjustments. The main conclusion is that this integrated framework provides a robust, explainable, and adaptive structure for UAM scheduling.",
      "mindmap": ""
    }
  ]
}