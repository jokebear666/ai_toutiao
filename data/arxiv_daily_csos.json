{
  "label": "cs.OS",
  "slug": "csos",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "MSched: GPU Multitasking via Proactive Memory Scheduling",
      "authors": "Weihang Shen, Yinqiu Chen, Rong Chen, Haibo Chen",
      "institution": "Institute of Parallel and Distributed Systems, Shanghai Jiao Tong University",
      "link": "https://arxiv.org/pdf/2512.24637",
      "code": null,
      "tags": [
        "memory & caching",
        "GPU multitasking",
        "memory oversubscription",
        "proactive scheduling",
        "demand paging",
        "context switching"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/81aa7999cea2218215dd44a0f4318762fd750cf330b1155dde0203d7d1437b8c_w640_q70.webp",
      "contributions": "1. Proposes MSched, an OS-level scheduler that extends GPU context switching with proactive working set preparation to coalesce expensive page faults into a single efficient migration. 2. Introduces a template-based approach to predict GPU memory access patterns with near-perfect accuracy using kernel launch arguments. 3. Presents a co-design between the task scheduler and memory manager to enforce a globally optimal page placement policy.",
      "summary": "The paper addresses the bottleneck of limited GPU HBM capacity for multitasking by proposing MSched, a proactive memory scheduler. MSched predicts memory access patterns to prepare working sets during context switches, replacing fragmented demand paging with efficient bulk migrations. Evaluation shows it outperforms demand paging by up to 11.05x for DL workloads and 57.88x for LLM inference under memory oversubscription.",
      "mindmap": "graph TB\n        Root[”MSched: GPU Multitasking via Proactive Memory Scheduling”] --> Problem[”核心问题/Problem: Limited HBM capacity bottleneck for GPU multitasking”]\n        Root --> Method[”主要方法/Method: Proactive OS scheduler with template-based prediction & co-design”]\n        Root --> Results[”关键结果/Results: Outperforms demand paging by up to 57.88x”]"
    },
    {
      "title": "Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search",
      "authors": "Rohit Dwivedula, Divyanshu Saxena, Sujay Yadalam, Daehyeok Kim, Aditya Akella",
      "institution": "The University of Texas at Austin",
      "link": "https://arxiv.org/pdf/2512.25065",
      "code": null,
      "tags": [
        "memory & caching",
        "heuristic synthesis",
        "evolutionary search",
        "instance-optimal",
        "LLM code generation",
        "cache eviction"
      ],
      "day": "2026-01-01",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8daf2ac9cf0548fb6b41e5cb643f8b78cc3001bcb2d8b95b8ade5ced5201e53a_w640_q70.webp",
      "contributions": "1. Proposes Vulcan, a framework that recasts heuristic design as an automated search problem using LLMs to synthesize instance-optimal heuristics tailored to specific deployment contexts. 2. Introduces LLM-friendly, task-agnostic interfaces that separate policy and mechanism, making the synthesis tractable and enabling even small LLMs to generate correct code. 3. Demonstrates the framework's effectiveness by synthesizing heuristics for cache eviction and memory tiering that outperform state-of-the-art human-designed algorithms.",
      "summary": "The paper proposes Vulcan, a framework that uses LLM-driven evolutionary search to automatically synthesize instance-optimal system heuristics, tailored to specific workloads and hardware. It introduces task-agnostic interfaces to separate policy from mechanism, enabling efficient code generation. The synthesized heuristics for cache eviction and memory tiering were shown to outperform existing state-of-the-art algorithms.",
      "mindmap": "graph TB\n        Root[Vulcan: Instance-Optimal Systems Heuristics Through LLM-Driven Search] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Manual heuristic design is slow and cannot adapt to changing hardware and workloads.]\n        Method[主要方法/Method: Use LLM-driven evolutionary search over task-agnostic interfaces to synthesize instance-optimal heuristics.]\n        Results[关键结果/Results: Synthesized heuristics outperform state-of-the-art algorithms in cache eviction and memory tiering.]"
    },
    {
      "title": "A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers",
      "authors": "Mohammad Nasirzadeh, Jafar Tahmoresnezhad, Parviz Rashidi-Khazaee",
      "institution": "Urmia University of Technology",
      "link": "https://arxiv.org/pdf/2512.23380",
      "code": "https://github.com/your-repo/CoLog",
      "tags": [
        "log anomaly detection",
        "collaborative transformers",
        "multi-head impressed attention",
        "modality adaptation layer"
      ],
      "day": "2025-12-30",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c23025b6b24d4efc5cb993659def89fe785700fbc818c9cc638fe55cdfc5b75e_w640_q70.webp",
      "contributions": "1. Proposes CoLog, a unified framework for detecting both point and collective anomalies in OS logs by applying multimodal sentiment analysis concepts. 2. Introduces collaborative transformers and multi-head impressed attention to learn interactions between different log data modalities. 3. Incorporates a modality adaptation layer to handle heterogeneity and adapt representations from different log modalities.",
      "summary": "The paper addresses the challenge of log anomaly detection, where existing methods struggle with the multimodal nature of log data and the interactions between these modalities. It proposes CoLog, a framework that uses collaborative transformers and a modality adaptation layer to learn nuanced patterns across log modalities for comprehensive anomaly detection. Extensive experiments show CoLog achieves state-of-the-art performance, with mean precision, recall, and F1 scores over 99.5% across seven benchmark datasets.",
      "mindmap": "graph TB\n        Root[”A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers”] --> Problem[”核心问题/Problem: Unimodal & multimodal methods fail to handle log data modalities and their interactions”]\n        Root --> Method[”主要方法/Method: CoLog framework with collaborative transformers, multi-head impressed attention, and modality adaptation layer”]\n        Root --> Results[”关键结果/Results: Achieves ~99.6% mean precision, recall, F1 on 7 datasets; superior to SOTA”]"
    },
    {
      "title": "LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems",
      "authors": "Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao",
      "institution": "University of York, Sun Yat-sen University",
      "link": "https://arxiv.org/pdf/2512.21701",
      "code": null,
      "tags": [
        "real-time systems",
        "lock-free",
        "fault-tolerance",
        "resource sharing",
        "multicore",
        "worst-case response time analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp",
      "contributions": "1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol.",
      "summary": "The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability.",
      "mindmap": "graph TB\n        Root[LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: Faults in critical sections cause error propagation; locking protocols lack fault tolerance, increasing blocking.]\n        Method[主要方法/Method: LEFT-RS protocol enables concurrent read access and parallel critical section entry for fault resilience.]\n        Results[关键结果/Results: Up to 84.5% average schedulability improvement over existing approaches.]"
    },
    {
      "title": "pokiSEC: A Multi-Architecture, Containerized Ephemeral Malware Detonation Sandbox",
      "authors": "Alejandro Avina, Yashas Hariprasad, Naveen Kumar Chaudhary",
      "institution": "California State University, East Bay, National Forensic Sciences University",
      "link": "https://arxiv.org/pdf/2512.20860",
      "code": "https://github.com/PanLuvme/pokiSEC",
      "tags": [
        "malware analysis",
        "Docker",
        "QEMU",
        "KVM",
        "Universal Entrypoint",
        "ephemeral container"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/58898439e3246ec551b562bfb2380c7db3d016ac4d87b780a7f10e905d0bdaef_w640_q70.webp",
      "contributions": "1. A lightweight, ephemeral malware detonation sandbox packaged entirely inside a Docker container, integrating QEMU with hardware acceleration and a browser-based workflow. 2. A Universal Entrypoint that performs runtime host-architecture detection and selects validated hypervisor configurations, enabling a single container to launch Windows guests on both ARM64 and x86_64 hosts. 3. Validation of the system on Apple Silicon (ARM64) and Ubuntu (AMD64), demonstrating interactive performance suitable for analyst workflows and consistent teardown via ephemeral container lifecycles.",
      "summary": "This paper presents pokiSEC, a containerized sandbox for dynamic malware analysis that packages QEMU and a browser interface into a Docker container to improve portability and automation. Its key innovation is a Universal Entrypoint that detects the host architecture and configures the hypervisor accordingly, allowing the same container to run on both ARM64 and x86_64 systems. The system was validated on Apple Silicon and Ubuntu, showing it provides interactive performance and clean isolation through ephemeral containers.",
      "mindmap": "graph LR\n    A[pokiSEC: 多架构容器化恶意软件引爆沙盒] --> B[核心问题/Problem]\n    A --> C[主要方法/Method]\n    A --> D[关键结果/Results]\n    B --> B1[恶意软件动态分析环境笨重且缺乏跨架构可移植性/Dynamic malware analysis environments are heavyweight and lack cross-architecture portability]\n    C --> C1[基于Docker的轻量级沙盒，集成QEMU与KVM/Lightweight sandbox in Docker container with QEMU and KVM]\n    C --> C2[通用入口点进行运行时架构检测与配置/Universal Entrypoint for runtime host-architecture detection and configuration]\n    D --> D1[在ARM64和x86_64主机上验证成功/Validated on ARM64 and x86_64 hosts]\n    D --> D2[提供交互式性能与一致的临时容器生命周期/Provides interactive performance and consistent ephemeral container lifecycle]"
    },
    {
      "title": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "authors": "Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18436",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp",
      "contributions": "",
      "summary": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "mindmap": ""
    },
    {
      "title": "EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving",
      "authors": "Shaoting Feng, Yuhan Liu, Hanchen Li, Xiaokun Chen, Samuel Shen, Kuntai Du, Zhuohan Gu, Rui Zhang, Yuyang Huang, Yihua Cheng, Jiayi Yao, Qizheng Zhang, Ganesh Ananthanarayanan, Junchen Jiang",
      "institution": "University of Chicago, UC Berkeley, Tensormesh, Inc., MIT, UC Santa Cruz, Stanford, Microsoft",
      "link": "https://arxiv.org/pdf/2512.14946",
      "code": null,
      "tags": [
        "llm inference",
        "KV-cache management",
        "lossy compression",
        "adaptive eviction",
        "utility function",
        "multi-tier storage"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "EVICPRESS is a KV-cache management system that jointly optimizes lossy compression and adaptive eviction across multiple storage tiers using a unified utility function. It improves LLM inference efficiency by maximizing fast-tier cache hit rates while preserving generation quality through context-aware compression. Evaluations show it achieves up to 2.19x faster time-to-first-token at equivalent quality compared to baselines.",
      "mindmap": ""
    }
  ]
}