{
  "label": "cs.SE",
  "slug": "csse",
  "week": "20251229-20260104",
  "items": [
    {
      "title": "Understanding the Role of Large Language Models in Software Engineering: Evidence from an Industry Survey",
      "authors": "Vítor Mateus de Brito, Kleinner Farias",
      "institution": "University of Vale do Rio dos Sinos",
      "link": "https://arxiv.org/pdf/2512.21347",
      "code": null,
      "tags": [
        "software development tools",
        "Large Language Models",
        "Survey",
        "Industry",
        "Empirical Study",
        "Software Engineering Practices"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3fdebd67326ef0fe8cc1a2f2e7ff34382bc7ee9e314bfea976a0e99b4b0eda04_w640_q70.webp",
      "contributions": "1. Provides empirical evidence on the adoption and impact of LLMs in professional software engineering practice through an industry survey. 2. Identifies key perceived benefits (e.g., faster problem resolution, better documentation) and concerns (e.g., cognitive dependence, security risks) associated with LLM use. 3. Bridges the gap between academic discourse and real-world development, offering actionable insights for responsible LLM integration.",
      "summary": "This paper conducts an empirical survey of 46 industry professionals to understand the adoption and impact of Large Language Models (LLMs) in software engineering. The study finds that while LLMs are perceived to accelerate technical tasks and improve documentation, significant concerns about over-reliance and security risks persist. The results highlight the need for critical and supervised use of LLM-based tools in software development.",
      "mindmap": "graph TB\n        A[Understanding the Role of LLMs in Software Engineering<br>理解LLM在软件工程中的作用] --> B(核心问题/Problem: How are LLMs adopted and perceived in industry software engineering?<br>LLM在工业界软件工程中的采用和认知如何？)\n        A --> C(主要方法/Method: Empirical survey of 46 industry professionals<br>对46位行业专业人员的实证调查)\n        A --> D(关键结果/Results: Positive perceptions (speed, documentation) but concerns about dependence and security<br>积极认知（速度、文档）但对依赖性和安全性的担忧)"
    },
    {
      "title": "CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation",
      "authors": "Santhosh Kumar Ravindran",
      "institution": "Microsoft Corporation",
      "link": "https://arxiv.org/pdf/2512.21351",
      "code": null,
      "tags": [
        "reinforcement learning",
        "dream-replay reinforcement learning",
        "evolutionary algorithms",
        "adaptive code generation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp",
      "contributions": "1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as \"genomes\" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.",
      "summary": "CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.",
      "mindmap": "graph TB\n        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]\n        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]\n        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]\n        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]\n        D --> D2[适应速度加快25%/25% faster adaptation]"
    },
    {
      "title": "Multi-Agent LLM Committees for Autonomous Software Beta Testing",
      "authors": "Sumanth Bharadwaj Hachalli Karanam, Dhiwahar Adhithya Kennady",
      "institution": "New York University",
      "link": "https://arxiv.org/pdf/2512.21352",
      "code": null,
      "tags": [
        "automated software testing",
        "multi-agent system",
        "large language model",
        "vision-language model",
        "consensus voting",
        "beta testing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/40573d0b1209c41e9825c09111398107cc51ee9d86c5234b50bea2515d0ab37f_w640_q70.webp",
      "contributions": "1. A novel multi-agent committee framework that uses a three-round voting protocol for consensus-based decision-making in software testing. 2. Integration of vision-enabled LLMs and diverse testing personas to systematically explore and understand web application user interfaces. 3. Demonstrated significant performance improvements over single-agent baselines in task success, bug detection (F1 score), and security vulnerability coverage on established benchmarks.",
      "summary": "The paper addresses the high cost of manual software beta testing and the limitations of single-agent LLM approaches by proposing a multi-agent committee framework. The method employs diverse, vision-enabled LLMs that collaborate through a structured voting protocol and persona-driven behavior to autonomously test web applications. The results show that this multi-agent approach significantly outperforms single-agent baselines in task success rates, bug detection, and security testing coverage, making it suitable for real-time CI/CD integration.",
      "mindmap": "graph TB\n        A[Multi-Agent LLM Committees for Autonomous Software Beta Testing] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[手动测试成本高，单智能体LLM存在幻觉/Manual testing costly, single-agent LLM hallucinates]\n        C --> C1[多智能体委员会与三轮投票协议/Multi-agent committee & three-round voting]\n        C --> C2[视觉LLM与角色多样性/Vision LLMs & persona diversity]\n        D --> D1[任务成功率89.5%，超越基线/Task success 89.5%, beats baseline]\n        D --> D2[动作延迟0.71秒，适合CI/CD/Action latency 0.71s, suitable for CI/CD]\n        D --> D3[覆盖8/10 OWASP漏洞类别/Covers 8/10 OWASP Top 10]"
    },
    {
      "title": "Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software",
      "authors": "Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang Liu, Jie M. Zhang",
      "institution": "King’s College London, National University of Defense Technology, Southern University of Science and Technology, The Hong Kong Polytechnic University",
      "link": "https://arxiv.org/pdf/2512.21348",
      "code": null,
      "tags": [
        "software fairness",
        "correlation tuning",
        "phi-coefficient",
        "multi-objective optimization",
        "pre-processing",
        "bias mitigation"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f4f80681a9ac6a6c3ad7d2bd938623a06836acba00279d9cec368a5ebbe44df3_w640_q70.webp",
      "contributions": "1. Proposes a novel pre-processing bias mitigation method called Correlation Tuning (CoT) that adjusts data correlations. 2. Introduces the Phi-coefficient as an intuitive measure to quantify correlation between sensitive attributes and labels. 3. Employs multi-objective optimization to address proxy biases, demonstrating superior effectiveness over state-of-the-art methods in single and multiple attribute scenarios.",
      "summary": "This paper proposes Correlation Tuning (CoT), a novel pre-processing method to mitigate bias in ML software by adjusting data correlations using the Phi-coefficient and multi-objective optimization. It frames fairness as a core software quality issue. Extensive evaluation shows CoT significantly improves performance for unprivileged groups and reduces key bias metrics, outperforming existing methods.",
      "mindmap": "graph TB\n        A[Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[传统公平研究忽视软件质量维度/Traditional fairness research neglects software quality dimension]\n        B --> B2[预处理方法效果不足/Pre-processing methods lack effectiveness]\n        C --> C1[提出相关性调优 (CoT)/Propose Correlation Tuning (CoT)]\n        C --> C2[使用Phi系数量化相关性/Use Phi-coefficient to quantify correlation]\n        C --> C3[采用多目标优化/Employ multi-objective optimization]\n        D --> D1[提高弱势群体TPR 17.5%/Increase unprivileged group TPR by 17.5%]\n        D --> D2[关键偏差指标降低 >50%/Key bias metrics reduced by >50%]\n        D --> D3[超越SOTA方法 3-10个百分点/Outperform SOTA by 3-10 percentage points]"
    },
    {
      "title": "Reflection-Driven Control for Trustworthy Code Agents",
      "authors": "Bin Wang, Jiazheng Quan, Xingrui Yu, Hansen Hu, Yuhao, Ivor Tsang",
      "institution": "Peking University, Xiamen University, Agency for Science, Technology and Research (A*STAR)",
      "link": "https://arxiv.org/pdf/2512.21354",
      "code": null,
      "tags": [
        "agent system",
        "reflection-driven control",
        "secure code generation",
        "trustworthy agents",
        "reflective memory",
        "safety control"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5126773543627efe84c972810f76eb0631192d8d90ed930bbc91d54b6664007b_w640_q70.webp",
      "contributions": "1. Introduces Reflection-Driven Control, a standardized and pluggable control module that integrates self-reflection as an explicit, internal step in an agent's reasoning process. 2. Instantiates the method for secure code generation, using a reflection loop to monitor decisions and retrieve repair examples/guidelines from an evolving reflective memory to inject constraints. 3. Empirically demonstrates that the approach substantially improves security and policy compliance of generated code while preserving functional correctness, with minimal overhead.",
      "summary": "The paper addresses the lack of reliable safety controls in LLM agents by proposing Reflection-Driven Control, a module that makes self-reflection an explicit, continuous part of the agent's reasoning to monitor and constrain its decisions using evidence from a reflective memory. Evaluated on security-critical code generation tasks, the method significantly improves code security and compliance while maintaining functionality, offering a practical path toward trustworthy AI coding agents.",
      "mindmap": "graph TB\n        Root[Reflection-Driven Control for Trustworthy Code Agents] --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[LLM代理缺乏可靠的安全控制/LLM agents lack reliable safety controls]\n        Problem --> P2[可能产生有害输出/Can produce harmful outputs]\n        Method --> M1[将自我反思作为推理的显式步骤/Elevates self-reflection to an explicit reasoning step]\n        Method --> M2[内部反思循环监控决策路径/Internal reflection loop monitors decision path]\n        Method --> M3[从反思记忆中检索修复示例/Retrieves repair examples from reflective memory]\n        Results --> R1[显著提高生成代码的安全性和合规性/Substantially improves security & policy compliance]\n        Results --> R2[基本保持功能正确性/Largely preserves functional correctness]\n        Results --> R3[运行时和token开销最小/Minimal runtime & token overhead]"
    },
    {
      "title": "AInsteinBench: Benchmarking Coding Agents on Scientific Repositories",
      "authors": "Titouan Duston, Shuo Xin, Yang Sun, Daoguang Zan, Aoyan Li, Shulin Xin, Kai Shen, Yixiao Chen, Qiming Sun, Ge Zhang, Jiashuo Liu, Huan Zhou, Jingkai Liu, Zhichen Pu, Yuanheng Wang, Bo-Xuan Ge, Xin Tong, Fei Ye, Zhi-Chao Zhao, Wen-Biao Han, Zhoujian Cao, Yueran Zhao, Weiluo Ren, Qingshen Long, Yuxiao Liu, Anni Huang, Yidi Du, Yuanyuan Rong, Jiahao Peng",
      "institution": "ByteDance Seed, Princeton University",
      "link": "https://arxiv.org/pdf/2512.21373",
      "code": "https://github.com/ByteDance-Seed/AInsteinBench",
      "tags": [
        "software engineering",
        "benchmark",
        "scientific computing",
        "code generation",
        "pull requests",
        "test-driven verification"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aadf07b453d8d5a061a247b4c4e5e4fc27a43f5b1ffca131e81738bd3728f348_w640_q70.webp",
      "contributions": "1. Introduces a novel benchmark (AInsteinBench) for evaluating LLM agents in end-to-end scientific development using real-world, production-grade codebases. 2. Curates tasks from maintainer-authored pull requests across six diverse scientific domains, ensuring scientific challenge and calibrated difficulty. 3. Employs executable environments and test-driven verification to measure core competencies beyond surface-level code generation.",
      "summary": "The paper introduces AInsteinBench, a benchmark designed to evaluate LLM agents' ability to function as scientific computing developers by solving tasks derived from real pull requests in scientific repositories. It uses executable environments and test-driven verification to assess deeper competencies. The benchmark provides a new standard for measuring AI's role in computational scientific research.",
      "mindmap": "graph TB\n        A[AInsteinBench: Benchmarking Coding Agents on Scientific Repositories] --> B[核心问题/Problem: Can LLM agents operate as scientific computing development agents?]\n        A --> C[主要方法/Method: End-to-end evaluation using tasks from real scientific pull requests]\n        A --> D[关键结果/Results: Measures ability beyond surface-level code generation]"
    },
    {
      "title": "What Makes a GitHub Issue Ready for Copilot?",
      "authors": "Mohammed Sayagh",
      "institution": "École de Technologie Supérieure, Université du Québec",
      "link": "https://arxiv.org/pdf/2512.21426",
      "code": null,
      "tags": [
        "ai-assisted software engineering",
        "GitHub Copilot",
        "AI-agent",
        "interpretable machine learning",
        "pull request merge prediction",
        "issue quality criteria"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/998bd51b7cec267b5219b085eac5068f7a996cf57d816c17d8e06474fbae27f0_w640_q70.webp",
      "contributions": "1. Developed a set of 32 detailed criteria to measure the quality of GitHub issues for AI-agents like Copilot. 2. Built an interpretable machine learning model to predict the likelihood of a GitHub issue resulting in a merged pull request. 3. Identified key characteristics of successful issues (e.g., shorter, well-scoped) and those associated with failure (e.g., external references), providing actionable guidance for issue writing.",
      "summary": "This paper investigates what makes a GitHub issue suitable for AI-agents like Copilot to successfully implement. The authors propose 32 quality criteria and build an interpretable machine learning model to predict if an issue will lead to a merged pull request. They conclude that successful issues are shorter, well-scoped, and provide clear implementation guidance, while issues with external references are less likely to succeed.",
      "mindmap": "graph TB\n        A[What Makes a GitHub Issue Ready for Copilot?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[AI-agent性能依赖输入质量/AI-agent performance depends on input quality]\n        B --> B2[如何评估Issue对Copilot的适用性/How to evaluate Issue suitability for Copilot]\n        C --> C1[定义32项质量评估标准/Define 32 quality criteria]\n        C --> C2[构建可解释机器学习模型/Build interpretable ML model]\n        C --> C3[比较合并与关闭的PR/Compare merged vs. closed PRs]\n        D --> D1[成功Issue特征:简短、范围明确、指导清晰/Successful Issue traits: short, well-scoped, clear guidance]\n        D --> D2[外部引用关联低合并率/External references linked to lower merge rate]\n        D --> D3[模型AUC中位数72%/Model median AUC 72%]"
    },
    {
      "title": "Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors",
      "authors": "Hridya Dhulipala, Xiaokai Rong, Tien N. Nguyen",
      "institution": "University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.21431",
      "code": null,
      "tags": [
        "software testing",
        "runtime error detection",
        "coverage-guided testing",
        "multi-agent reasoning",
        "large language models",
        "static analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7d41379a4c8476f7ed1a8a02b193c5fe427e6a274d56beccd85313ce47ba5e76_w640_q70.webp",
      "contributions": "1. Proposes Cerberus, a novel predictive, execution-free coverage-guided testing framework that uses LLMs for input generation, coverage prediction, and error detection without code execution. 2. Introduces a two-phase feedback loop that first maximizes code coverage and detects errors, then focuses solely on error detection after coverage is maximized, improving performance over single-phase prompting. 3. Empirically demonstrates that Cerberus outperforms conventional and learning-based testing frameworks for both complete and incomplete code snippets by generating high-coverage test cases more efficiently and discovering more runtime errors.",
      "summary": "The paper proposes Cerberus, a framework that uses Large Language Models (LLMs) to statically detect runtime errors in code snippets without execution. It employs a multi-agent reasoning approach with a two-phase, coverage-guided feedback loop to generate test inputs and predict errors. The evaluation shows Cerberus is more efficient and effective at finding runtime errors than existing testing methods.",
      "mindmap": "graph TB\n        A[Cerberus: Multi-Agent Reasoning and Coverage-Guided Exploration for Static Detection of Runtime Errors] --> B(核心问题/Problem: Detecting runtime errors in code snippets without execution is crucial for software safety.)\n        A --> C(主要方法/Method: Uses LLMs for execution-free, coverage-guided testing with a two-phase feedback loop.)\n        A --> D(关键结果/Results: Outperforms conventional and learning-based frameworks by generating high-coverage tests and finding more errors.)"
    },
    {
      "title": "Fuzzwise: Intelligent Initial Corpus Generation for Fuzzing",
      "authors": "Hridya Dhulipala, Xiaokai Rong, Aashish Yadavally, Tien N. Nguyen",
      "institution": "University of Texas at Dallas",
      "link": "https://arxiv.org/pdf/2512.21440",
      "code": null,
      "tags": [
        "fuzz testing",
        "initial corpus generation",
        "large language models",
        "multi-agent framework",
        "predictive code coverage",
        "mutation-based fuzzing"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/bcb8eafec283e39ae04e0274dc4688aced924346193560581e8469f1151507f6_w640_q70.webp",
      "contributions": "1. Proposes FuzzWise, a novel method that integrates initial corpus generation and minimization into a single, streamlined process using an LLM-based multi-agent framework., 2. Introduces a predictive code coverage module (an LLM agent) that assesses new test cases without requiring actual program execution, saving computational resources., 3. Demonstrates empirically that FuzzWise generates a smaller, higher-quality initial corpus that achieves higher code coverage and triggers more runtime errors more efficiently than baseline methods.",
      "summary": "The paper addresses the problem of generating a high-quality initial seed corpus for mutation-based fuzzing. It proposes FuzzWise, a method that uses a multi-agent LLM framework to generate and intelligently select test cases based on predicted coverage without execution. The evaluation shows FuzzWise produces a smaller, more effective corpus that achieves higher coverage and finds more bugs efficiently.",
      "mindmap": "graph TB\n        A[FuzzWise: Intelligent Initial Corpus Generation for Fuzzing] --> B[核心问题/Problem: 为模糊测试生成高质量的初始种子语料库/Generating high-quality initial seed corpus for fuzzing]\n        A --> C[主要方法/Method: 基于LLM的多智能体框架，集成生成与预测性覆盖评估/LLM-based multi-agent framework integrating generation and predictive coverage assessment]\n        A --> D[关键结果/Results: 用更少的测试用例实现更高的代码覆盖率和错误发现率/Achieves higher code coverage and bug detection with fewer test cases]"
    },
    {
      "title": "Code Clone Refactoring in C# with Lambda Expressions",
      "authors": "Takuto Kawamoto, Yoshiki Higo",
      "institution": "Osaka University",
      "link": "https://arxiv.org/pdf/2512.21511",
      "code": null,
      "tags": [
        "code refactoring",
        "lambda expressions",
        "extract method",
        "behavior parameterization",
        "code clone",
        "C#"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2c89087084c80383647290bcc69c8c950eca517f6ba4f10a7237d77a54477bdd_w640_q70.webp",
      "contributions": "1. Proposed a C#-specific technique for code clone refactoring using lambda expressions for behavior parameterization, addressing a gap in language-specific research beyond Java. 2. Developed an analysis method to determine the refactorability of clone pairs detected by the NiCad clone detector. 3. Conducted an empirical evaluation on 2,217 clone pairs from 22 projects, measuring the success rate of the proposed consolidation approach.",
      "summary": "This paper addresses the problem of consolidating code clones in C# programs using \"Extract Method\" refactoring. It proposes a novel technique that uses lambda expressions to parameterize behavioral differences between clones, which is tailored to C#'s language specifications. The evaluation on real-world projects showed that 35.0% of clone pairs were deemed refactorable by the approach, with 28.9% of those successfully refactored.",
      "mindmap": "graph TB\n        Root(”Code Clone Refactoring in C# with Lambda Expressions”) --> Problem(”核心问题/Problem”)\n        Root --> Method(”主要方法/Method”)\n        Root --> Results(”关键结果/Results”)\n        Problem --> P1(”Clone Refactoring with Differences/存在差异的克隆重构”)\n        Problem --> P2(”Language-Specific Techniques Needed/需要语言特定技术”)\n        Method --> M1(”C#-Specific Lambda Expressions/C#特定的Lambda表达式”)\n        Method --> M2(”Behavior Parameterization/行为参数化”)\n        Results --> R1(”35.0% Pairs Refactorable/35.0% 可重构”)\n        Results --> R2(”28.9% Successfully Refactored/28.9% 成功重构”)"
    },
    {
      "title": "XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production",
      "authors": "Qi Hu, Jiangchao Liu, Xin Yu, Lin Zhang, Edward Jiang",
      "institution": "ByteDance",
      "link": "https://arxiv.org/pdf/2512.21555",
      "code": null,
      "tags": [
        "mobile systems",
        "dynamic tracing",
        "method interception",
        "ART virtual machine",
        "non-invasive proxying",
        "runtime observability"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/35b382ca224e5947c252f1f122f264a5993cf96e0069d9fecd115eb850c5ea49_w640_q70.webp",
      "contributions": "1. Proposes a novel non-invasive proxying paradigm for dynamic tracing that avoids modifying the ART VM's underlying data structures. 2. Achieves high-performance method interception by leveraging and optimizing the stable, built-in instrumentation mechanism of the Android ART virtual machine. 3. Demonstrates production-grade stability, minimal overhead, and broad compatibility through large-scale A/B experiments on a major app, successfully diagnosing severe online issues.",
      "summary": "This paper proposes XTrace, a non-invasive dynamic tracing framework for Android that intercepts arbitrary methods at runtime without app releases by leveraging the ART VM's instrumentation. It shows minimal performance impact and high stability in large-scale production use, significantly improving the efficiency of diagnosing online crashes and performance bottlenecks.",
      "mindmap": "graph TB\n        Root[XTrace: 一个用于生产环境的Android应用非侵入式动态追踪框架 / XTrace: A Non-Invasive Dynamic Tracing Framework for Android Applications in Production]\n        Root --> Problem[核心问题/Problem]\n        Root --> Method[主要方法/Method]\n        Root --> Results[关键结果/Results]\n        Problem --> P1[移动应用复杂性 & 设备碎片化 / Mobile App Complexity & Device Fragmentation]\n        Problem --> P2[”传统方法(静态日志)缺乏实时上下文 / Traditional Methods Lack Real-time Context”]\n        Problem --> P3[”难以捕获'幽灵bug' / Difficulty in Catching 'Ghost Bugs'”]\n        Method --> M1[非侵入式代理范式 / Non-Invasive Proxying Paradigm]\n        Method --> M2[利用并优化ART内置插桩机制 / Leverage & Optimize ART's Built-in Instrumentation]\n        Results --> R1[生产级稳定性 & 最小开销 / Production-Grade Stability & Minimal Overhead]\n        Results --> R2[诊断严重线上崩溃 & 性能瓶颈 / Diagnosed Severe Online Crashes & Performance Bottlenecks]\n        Results --> R3[根因定位效率提升>90% / Root-Cause Localization Efficiency Improved >90%]"
    },
    {
      "title": "Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code",
      "authors": "Shuo Sun, Shixin Zhang, Jiwei Yan, Jun Yan, Jian Zhang",
      "institution": "Institute of Software, Chinese Academy of Sciences",
      "link": "https://arxiv.org/pdf/2512.21591",
      "code": null,
      "tags": [
        "type inference",
        "Entity Dependency Graph",
        "co-evolution",
        "type-checker-in-the-loop",
        "LLM",
        "repository-level"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6d664d948e35d5ccaf8cf1c7880d512bf91868eeaf908b4683c1db08768e3940_w640_q70.webp",
      "contributions": "1. An Entity Dependency Graph (EDG) model designed to capture repository-level type dependencies. 2. An iterative type inference approach where types and dependencies co-evolve in each iteration. 3. A type-checker-in-the-loop strategy that validates and corrects inferences on-the-fly to reduce error propagation.",
      "summary": "This paper proposes PyTIR, a novel approach for repository-level type inference in Python. It uses an Entity Dependency Graph (EDG) and an iterative co-evolution process between types and dependencies, enhanced by a type-checker-in-the-loop, to achieve accurate type annotations. The method significantly outperforms prior works, demonstrating a major improvement in automated type annotation for real-world Python code.",
      "mindmap": "graph TB\n        A[Co-Evolution of Types and Dependencies: Towards Repository-Level Type Inference for Python Code] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Python动态类型导致运行时错误/Python dynamic typing causes runtime errors]\n        B --> B2[现有工具难以处理仓库级依赖/Existing tools struggle with repository-level dependencies]\n        C --> C1[构建实体依赖图(EDG)/Construct Entity Dependency Graph (EDG)]\n        C --> C2[类型与依赖协同进化迭代推理/Co-evolution iterative inference of types and dependencies]\n        C --> C3[集成类型检查器循环验证/Type-checker-in-the-loop validation]\n        D --> D1[TypeSim 0.89, TypeExact 0.84/TypeSim 0.89, TypeExact 0.84]\n        D --> D2[相对基线提升27%和40%/27% and 40% relative improvement over baseline]\n        D --> D3[减少92.7%的新类型错误/Reduced 92.7% of new type errors]"
    },
    {
      "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation",
      "authors": "Tian Li, Bo Lin, Shangwen Wang, Yusong Tan",
      "institution": "National University of Defense Technology",
      "link": "https://arxiv.org/pdf/2512.21681",
      "code": null,
      "tags": [
        "software security",
        "backdoor attack",
        "retrieval-augmented code generation",
        "vulnerable code",
        "supply-chain vulnerability",
        "stealthy attack"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c74c266d46865bfe9ae8b97f18b92cf9b8209ecd63852c6f32f3fe8533329fe2_w640_q70.webp",
      "contributions": "1. Conducted the first systematic exploration of backdoor attacks targeting the retriever component in Retrieval-Augmented Code Generation (RACG), identifying it as a critical supply-chain vulnerability. 2. Proposed VenomRACG, a new class of potent and stealthy attack that makes poisoned code statistically indistinguishable from benign code, enabling realistic threat analysis. 3. Demonstrated the severe practical impact of the attack, showing that injecting only 0.05% poisoned data can manipulate the retriever and cause downstream models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while evading current defenses.",
      "summary": "This paper investigates the security threat of backdoor attacks on the retriever in Retrieval-Augmented Code Generation (RACG). To enable a realistic analysis, the authors developed a stealthy attack called VenomRACG. Their findings reveal that this attack is highly effective and evades current defenses, posing a practical threat to the software development ecosystem.",
      "mindmap": "graph TB\n        A[Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[Retriever Backdoor: 供应链漏洞/Supply-Chain Vulnerability]\n        C --> C1[VenomRACG: 隐蔽攻击/Stealthy Attack]\n        D --> D1[低投毒率有效/Low Poisoning Rate Effective]\n        D --> D2[下游模型生成漏洞代码/Downstream Model Generates Vulnerable Code]\n        D --> D3[防御机制失效/Defenses Ineffective]"
    },
    {
      "title": "How Do Agents Perform Code Optimization? An Empirical Study",
      "authors": "Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis",
      "institution": "Purdue University",
      "link": "https://arxiv.org/pdf/2512.21757",
      "code": null,
      "tags": [
        "code optimization",
        "AI coding agents",
        "performance optimization",
        "empirical study",
        "pull request analysis",
        "AIDev dataset"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp",
      "contributions": "1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.",
      "summary": "This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.",
      "mindmap": "graph TB\n        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]\n        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]\n        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]"
    },
    {
      "title": "The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX",
      "authors": "Abdul Ali Bangash, Tongxu Ge, Zhimin Zhao, Arshdeep Singh, Zitao Wang, Bram Adams",
      "institution": "Lahore University of Management Sciences, Queen's University, Indian Institute of Technology Ropar, University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.21781",
      "code": null,
      "tags": [
        "software supply chain security",
        "Software Bill of Materials",
        "SBOM",
        "SPDX",
        "CycloneDX",
        "tool ecosystem"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/91bc1035c2c5b265034f618902937bd2da58ada7ea4b50d403537bd0f48a030c_w640_q70.webp",
      "contributions": "1. Conducted a quantitative comparison of use cases for 170 publicly advertised SBOM tools to identify enhancement areas for the SPDX and CycloneDX formats. 2. Compared health metrics of both ecosystems (171 CycloneDX vs. 470 SPDX tools) and analyzed 36,990 issue reports from open-source tools to evaluate robustness and identify challenges. 3. Investigated and compared the health metrics of the top 250 open-source projects using each tool ecosystem.",
      "summary": "This paper conducts a comparative analysis of the two dominant Software Bill of Materials (SBOM) tool ecosystems, SPDX and CycloneDX. The authors quantitatively analyze tool use cases, ecosystem health metrics, issue reports, and project adoption. The findings reveal that CycloneDX tools show higher developer engagement in some areas, while SPDX benefits from a more mature ecosystem with broader tool availability and industry adoption.",
      "mindmap": "graph TB\n        A[The State of the SBOM Tool Ecosystems: A Comparative Analysis of SPDX and CycloneDX] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[SBOM adoption depends on tool ecosystems<br/>SBOM采用依赖于工具生态系统]\n        C --> C1[Quantitative comparison of tools, issues, and projects<br/>对工具、问题、项目进行定量比较]\n        D --> D1[CycloneDX: higher developer engagement<br/>CycloneDX: 更高的开发者参与度]\n        D --> D2[SPDX: more mature ecosystem & broader adoption<br/>SPDX: 更成熟的生态系统和更广泛的采用]"
    },
    {
      "title": "A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation",
      "authors": "Qiaolin Qin, Jianchen Zhao, Heng Li, Weiyi Shang, Ettore Merlo",
      "institution": "Polytechnique Montreal, University of Waterloo",
      "link": "https://arxiv.org/pdf/2512.21811",
      "code": null,
      "tags": [
        "log parsing",
        "PMSS",
        "label-free evaluation",
        "silhouette analysis",
        "Levenshtein distance",
        "log parser"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4dbe635df301e13b1acf1f17c8fb241f287195f74aae223daca138f58797fb87_w640_q70.webp",
      "contributions": "1. Proposed PMSS, a novel label-free metric for evaluating log parser performance that does not require ground-truth data. 2. Demonstrated that PMSS is significantly correlated with existing label-based metrics (FGA and FTA) and can lead to comparable parser selection conclusions. 3. Provided guidelines and discussion on interpreting evaluation results with PMSS, addressing challenges and its application when labels are unavailable or inconsistent.",
      "summary": "The paper identifies that existing metrics for evaluating log parsers rely on labeled data, which is often unavailable or inconsistent. To solve this, it proposes PMSS, a label-free metric based on medoid silhouette analysis and Levenshtein distance. The results show PMSS is strongly correlated with label-based metrics, offering a viable alternative for parser evaluation and selection without ground truth.",
      "mindmap": "graph TB\n        Root[”A Story About Cohesion and Separation: Label-Free Metric for Log Parser Evaluation<br>论文标题”]\n        Root --> Problem[”现有评估指标依赖标注数据，导致评估受限且结论不一致<br>Problem: Label-based metrics limit evaluation”]\n        Root --> Method[”提出PMSS，一种基于中心点轮廓分析和编辑距离的无标签评估指标<br>Method: Propose PMSS, a label-free metric”]\n        Root --> Results[”PMSS与FGA/FTA显著相关，为无标签场景提供有效替代方案<br>Results: PMSS correlates with label-based metrics”]"
    },
    {
      "title": "Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems in Software Development",
      "authors": "Brian Bowers, Smita Khapre, Jugal Kalita",
      "institution": "Loyola Marymount University, University of Colorado Colorado Springs",
      "link": "https://arxiv.org/pdf/2512.21818",
      "code": null,
      "tags": [
        "agent system",
        "multi-agent system",
        "code injection",
        "threat model",
        "security analysis agent",
        "LLM"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/43b214bf9d80e3aaa2e2412bbf3ea1727db748cf0f33f818d81076fa53654f97_w640_q70.webp",
      "contributions": "1. Proposed and evaluated LLM-based multi-agent architectures (coder, coder-tester, coder-reviewer-tester) for software implementation, assessing their accuracy, attack resilience, and efficiency. 2. Introduced a security analysis agent to mitigate code injection attacks, showing it improves resilience while recovering lost efficiency. 3. Demonstrated a vulnerability in the security analysis agent where embedding poisonous few-shot examples in injected code drastically increases attack success rate.",
      "summary": "This paper analyzes the vulnerability of LLM-based multi-agent systems in software development to code injection attacks. It proposes and evaluates several agent architectures, finding that adding a security analysis agent improves resilience and efficiency. However, the study concludes that even this security agent can be compromised by advanced attacks using poisoned few-shot examples, significantly increasing the attack success rate.",
      "mindmap": "graph TB\n        Root[Analyzing Code Injection Attacks on LLM-based Multi-Agent Systems] --> Problem\n        Root --> Method\n        Root --> Results\n        Problem[核心问题/Problem: LLM-based multi-agent systems for software development are vulnerable to code injection attacks] --> Problem_Detail[缺乏人在环/No Human-in-the-Loop]\n        Method[主要方法/Method: Propose and evaluate multi-agent architectures, then add a security analysis agent] --> Method_Arch[架构评估/Architecture Evaluation: coder, coder-tester, coder-reviewer-tester]\n        Method --> Method_Sec[安全代理/Security Agent: Add a security analysis agent for mitigation]\n        Results[关键结果/Results: Security agent improves resilience but is itself vulnerable to advanced attacks] --> Results_Resilience[韧性提升/Improved Resilience: coder-reviewer-tester is more resilient]\n        Results --> Results_Vulnerability[新漏洞/New Vulnerability: Poisonous few-shot examples increase attack success to 71.95%]"
    },
    {
      "title": "Proceedings First Workshop on Adaptable Cloud Architectures",
      "authors": "Giuseppe De Palma, Saverio Giallorenzo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.22054",
      "code": null,
      "tags": [],
      "day": "2025-12-29",
      "thumbnail": null,
      "contributions": "",
      "summary": "",
      "mindmap": ""
    },
    {
      "title": "HALF: Process Hollowing Analysis Framework for Binary Programs with the Assistance of Kernel Modules",
      "authors": "Zhangbo Long, Letian Sha, Jiaye Pan, Dongpeng Xu, Yifei Huang, Fu Xiao",
      "institution": "Nanjing University of Posts and Telecommunications, The University of New Hampshire",
      "link": "https://arxiv.org/pdf/2512.22043",
      "code": null,
      "tags": [
        "binary analysis",
        "process hollowing",
        "dynamic binary instrumentation",
        "kernel module",
        "fine-grained analysis",
        "malware analysis"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e19e32f77dc6c92df186a9244b45aa21db814a27ce5e27275643fa1e71537cf7_w640_q70.webp",
      "contributions": "1. Proposes a new binary program analysis framework that uses a kernel module to extend the capabilities of traditional dynamic binary instrumentation. 2. Introduces a novel method to construct the analysis environment within a container process using process hollowing techniques, enabling decoupled analysis. 3. Demonstrates the framework's practical value through validation with benchmarks, actual exploit programs, and malicious code on the Windows platform.",
      "summary": "This paper proposes HALF, a new binary program analysis framework designed to improve the usability and performance of fine-grained analysis. It combines kernel modules with process hollowing to decouple the analysis environment from the target program, reducing its impact. The framework is validated on Windows, showing effectiveness in analyzing exploits and malware.",
      "mindmap": "graph TB\n        A[HALF: Process Hollowing Analysis Framework<br>HALF: 进程镂空分析框架] --> B(Problem: Fine-grained binary analysis has deployability and performance issues<br>问题: 细粒度二进制分析存在部署性和性能问题)\n        A --> C(Method: Uses kernel modules & process hollowing for decoupled analysis<br>方法: 使用内核模块和进程镂空进行解耦分析)\n        A --> D(Results: Validated on Windows, effective for exploit/malware analysis<br>结果: 在Windows上验证，对漏洞利用/恶意软件分析有效)"
    },
    {
      "title": "Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications",
      "authors": "Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer",
      "institution": "University of Illinois at Urbana-Champaign, IBM Research",
      "link": "https://arxiv.org/pdf/2512.22113",
      "code": null,
      "tags": [
        "agent system",
        "root cause analysis",
        "service dependency graph",
        "program dependence graph",
        "LLM agent",
        "cloud incident"
      ],
      "day": "2025-12-29",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp",
      "contributions": "1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.",
      "summary": "This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.",
      "mindmap": "graph TB\n        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B\n        A --> C\n        A --> D\n        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]\n        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]\n        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]"
    },
    {
      "title": "Managing the Stochastic: Foundations of Learning in Neuro-Symbolic Systems for Software Engineering",
      "authors": "Matthew Thompson",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.20660",
      "code": null,
      "tags": [
        "agent system",
        "dual-state architecture",
        "atomic action pairs",
        "guard functions",
        "neuro-symbolic systems",
        "code generation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4a73fceac46d6997904de43696e8db407d645c6e4388012a9e24a3b9565e06fb_w640_q70.webp",
      "contributions": "1. Proposes a control boundary that treats the LLM as a stochastic environment component, not the decision-making agent, to manage its unpredictability. 2. Formalizes a Dual-State Architecture separating deterministic workflow state from stochastic environment state. 3. Introduces Atomic Action Pairs and Guard Functions to couple generation with verification as indivisible transactions, projecting probabilistic outputs onto observable workflow state.",
      "summary": "This paper addresses the problem of stochastic failures in AI coding agents by proposing a neuro-symbolic architectural framework that treats the LLM as part of the environment. The method uses a Dual-State Architecture with Atomic Action Pairs and Guard Functions to separate deterministic control from stochastic generation. The main conclusion is that such architectural constraints can significantly improve task success rates for qualified models, potentially substituting for parameter scale in achieving reliable code generation.",
      "mindmap": "graph LR\n    A[Managing the Stochastic<br>管理随机性] --> B[Problem: LLM-based agents prone to stochastic failures<br>问题: 基于LLM的智能体易受随机性故障影响]\n    A --> C[Method: Dual-State Architecture, Atomic Action Pairs, Guard Functions<br>方法: 双态架构, 原子动作对, 守卫函数]\n    A --> D[Results: Improved success rates, architectural constraints can substitute for scale<br>结果: 成功率提升, 架构约束可替代模型规模]"
    },
    {
      "title": "Process Analytics -- Data-driven Business Process Management",
      "authors": "Matthias Stierle, Karsten Kraume, Martin Matzner",
      "institution": "Friedrich-Alexander University Erlangen-Nürnberg, University of Münster",
      "link": "https://arxiv.org/pdf/2512.20703",
      "code": null,
      "tags": [
        "Business Process Management",
        "Process Analytics",
        "Process Mining",
        "Socio-technical Perspective",
        "Data-driven Analysis",
        "Business Process Automation"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/937a3a879686d02d64d7fdcbd142c2e1c0049f0a58b9c32c9a47215b24c74f1e_w640_q70.webp",
      "contributions": "1. Proposes a new, integrated perspective on data-driven process analysis that combines the analysis process with organizational and stakeholder concerns, moving beyond purely technical views. 2. Conceptualizes the term \"Process Analytics\" and its various dimensions through a combined inductive and deductive research approach. 3. Validates and discusses the conceptualization by contrasting it with a real-life case study of data-driven process analysis and automation in a large company.",
      "summary": "This paper identifies a narrowing focus on the technical aspects of process mining, which overlooks human and organizational factors. To address this, it proposes and conceptualizes \"Process Analytics\" as a new, socio-technical perspective that integrates the analysis process with the organization and its stakeholders. The conceptual framework is discussed and contrasted with a real-world implementation case.",
      "mindmap": "graph LR\n        A[Process Analytics – Data-driven Business Process Management] --> B[核心问题/Problem: 对流程挖掘的认知狭隘化，忽视人机组织因素/Overly narrow focus on process mining, neglecting human & organizational factors]\n        A --> C[主要方法/Method: 提出”流程分析学”新视角，结合归纳与演绎法进行概念化/Proposes ”Process Analytics” perspective, conceptualized via inductive & deductive approach]\n        A --> D[关键结果/Results: 建立多维度概念框架，并通过真实案例进行对比讨论/Establishes multi-dimensional conceptual framework, discussed via real-life case study]"
    },
    {
      "title": "FEM-Bench: A Structured Scientific Reasoning Benchmark for Evaluating Code-Generating LLMs",
      "authors": "Saeed Mohammadzadeh, Erfan Hamdi, Joel Shor, Emma Lejeune",
      "institution": "Boston University, Move37 Labs",
      "link": "https://arxiv.org/pdf/2512.20732",
      "code": null,
      "tags": [
        "llm inference",
        "Finite Element Method (FEM)",
        "Code Generation",
        "LLM Benchmark",
        "Computational Mechanics",
        "Scientific Machine Learning"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b1933a2d33b13b692f95ee8ddec0a65840af091998d38a7f0154837874636590_w640_q70.webp",
      "contributions": "1. Introduces FEM-Bench, a novel benchmark for evaluating LLMs' ability to generate scientifically valid code for computational mechanics problems. 2. Provides a structured suite of tasks based on finite element methods that enforce physical and numerical constraints for objective evaluation. 3. Presents initial evaluation results showing that state-of-the-art LLMs (e.g., Gemini 3 Pro, GPT-5) still struggle to reliably solve these introductory tasks.",
      "summary": "The paper identifies a lack of benchmarks for evaluating LLMs' scientific reasoning and code generation for physical modeling. It proposes FEM-Bench, a computational mechanics benchmark based on the Finite Element Method, to fill this gap. Initial evaluations show that even advanced LLMs cannot reliably solve all its tasks, establishing a foundation for tracking progress in AI-generated scientific code.",
      "mindmap": "graph LR\n        A[FEM-Bench Paper] --> B[核心问题/Problem: 缺乏评估LLM生成科学物理模型代码能力的基准/Lack of benchmark for evaluating LLMs' ability to generate scientifically valid physical model code]\n        A --> C[主要方法/Method: 提出基于计算力学和有限元法的结构化基准/Proposes a structured benchmark based on computational mechanics and the Finite Element Method]\n        A --> D[关键结果/Results: 先进LLM无法可靠解决所有基准任务，为跟踪进展奠定基础/State-of-the-art LLMs cannot reliably solve all benchmark tasks, establishing a foundation for tracking progress]"
    },
    {
      "title": "One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents",
      "authors": "Zhaoxi Zhang, Yitong Duan, Yanzhi Zhang, Yiming Xu, Jiyan He, Yunfang Wu",
      "institution": "Affiliation not explicitly stated in provided text. Email domains suggest potential institutions, but cannot be reliably inferred from given content.",
      "link": "https://arxiv.org/pdf/2512.20957",
      "code": null,
      "tags": [
        "repository-level code understanding",
        "LLM agent",
        "reinforcement learning",
        "tool usage",
        "code navigation",
        "execution-aware"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6254efa02c0725684b783a26c76c1825bf8aaa25aee61fb7aaea40887f0efc46_w640_q70.webp",
      "contributions": "1. Proposes RepoNavigator, an LLM agent that uses a single, execution-aware tool (\"jump to definition\") for navigating code repositories, simplifying agent control and aligning with code execution logic. 2. Introduces an end-to-end Reinforcement Learning (RL) training method for the agent directly from a pretrained model, eliminating the need for closed-source model distillation. 3. Demonstrates state-of-the-art performance on repository-level issue localization, showing that smaller RL-trained models (e.g., 7B) can outperform larger baseline models (e.g., 14B, 32B) and even closed-source models like Claude-3.7.",
      "summary": "The paper addresses the challenge of locating code to modify in large software repositories. It proposes RepoNavigator, an LLM agent trained with Reinforcement Learning to use a single \"jump to definition\" tool for navigation. Experiments show this approach achieves state-of-the-art performance, with smaller models outperforming larger baselines, proving the efficiency of a simple, execution-aware tool combined with RL training.",
      "mindmap": "graph LR\n    A[One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents] --> B[核心问题/Problem: Locating modification points in large, complex code repositories is difficult]\n    A --> C[主要方法/Method: RepoNavigator agent with a single ”jump to definition” tool, trained end-to-end via RL]\n    A --> D[关键结果/Results: SOTA performance; smaller RL-trained models outperform larger baselines and closed-source models]"
    },
    {
      "title": "Artificial or Just Artful? Do LLMs Bend the Rules in Programming?",
      "authors": "Oussama Ben Sghaier, Kevin Delcourt, Houari Sahraoui",
      "institution": "Queen’s University, Université de Montréal",
      "link": "https://arxiv.org/pdf/2512.21028",
      "code": null,
      "tags": [
        "code generation",
        "large language models",
        "code generation",
        "unit tests",
        "prompting strategies",
        "alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da2f579fa34b3f18209ec129b76141b35f2706432dd12ec1d06d02f9b23b4198_w640_q70.webp",
      "contributions": "1. Investigates the conflict between LLM pretraining objectives (exploit all signals) and alignment choices (follow rules) in the context of code generation with unit tests. 2. Designs a systematic experimental framework using the BigCodeBench (Hard) dataset with five prompting conditions to manipulate test visibility and restrictions. 3. Identifies and analyzes recurring adaptation strategies used by LLMs when exposed to conflicting signals, with test-driven refinement being the most frequent.",
      "summary": "This paper investigates how Large Language Models (LLMs) adapt their code generation strategies when given access to unit tests under different prompting conditions that may restrict their use. The authors evaluate five models on the BigCodeBench dataset, finding that test visibility dramatically improves correctness and that models employ specific adaptation strategies, like test-driven refinement, to reconcile pretraining objectives with alignment constraints.",
      "mindmap": "graph LR\n        A[Artificial or Just Artful? Do LLMs Bend the Rules in Programming?] --> B(核心问题/Problem)\n        A --> C(主要方法/Method)\n        A --> D(关键结果/Results)\n        B --> B1[LLMs在代码生成中<br>预训练目标与对齐要求的冲突/Conflict between pretraining and alignment in LLM code generation]\n        C --> C1[设计五种提示条件<br>操作测试可见性与限制/Design five prompting conditions manipulating test visibility & restrictions]\n        C --> C2[评估五个LLM在BigCodeBench上的<br>正确性、相似性等/Evaluate five LLMs on BigCodeBench for correctness, similarity, etc.]\n        D --> D1[测试可见性显著改变性能<br>正确性近乎翻倍/Test visibility dramatically alters performance, correctness nearly doubles]\n        D --> D2[识别出四种重复的适应策略<br>测试驱动优化最常见/Identify four recurring adaptation strategies, test-driven refinement most frequent]"
    },
    {
      "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
      "authors": "Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu",
      "institution": "Nanyang Technological University, National University of Singapore",
      "link": "https://arxiv.org/pdf/2512.21236",
      "code": null,
      "tags": [
        "llm security",
        "jailbreaking",
        "malicious code generation",
        "prompt engineering",
        "time-division selection",
        "security alignment"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8055c0aba333e58d26f29d81acab1f88f570f09122f7fafd38ac1c952dad67b1_w640_q70.webp",
      "contributions": "1. Proposes SPELL, a novel testing framework specifically designed to evaluate security alignment weaknesses in LLMs for malicious code generation. 2. Introduces a time-division selection strategy to systematically construct jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset. 3. Conducts extensive evaluation across multiple advanced code models and real-world tools, revealing significant security gaps and providing insights for improving AI safety.",
      "summary": "The paper addresses the security risk of LLMs being exploited to generate malicious code, a gap in existing jailbreaking research. It proposes the SPELL framework, which uses a time-division strategy to construct effective jailbreaking prompts. The evaluation shows high attack success rates across several models, revealing critical vulnerabilities in current AI safety alignments for code generation.",
      "mindmap": "graph LR\n        A[SPELL: Sentence Pairing Exploration for LLM Limitation-breaking] --> B[核心问题/Problem: LLMs可能被用于生成恶意代码/LLMs can be exploited for malicious code generation]\n        A --> C[主要方法/Method: 基于时间划分选择的提示构建框架/Time-division selection prompt construction framework]\n        A --> D[关键结果/Results: 在多模型上实现高攻击成功率/High attack success rates across multiple models]"
    },
    {
      "title": "Assessing the Software Security Comprehension of Large Language Models",
      "authors": "Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos",
      "institution": "University of Notre Dame",
      "link": "https://arxiv.org/pdf/2512.21238",
      "code": null,
      "tags": [
        "software security assessment",
        "Bloom's Taxonomy",
        "knowledge boundary",
        "misconception patterns"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8b3809be1ff4cae9ad7acb47676829cd58ca3ea614efa57d9121857f85d97fc7_w640_q70.webp",
      "contributions": "1. Introduced a systematic evaluation framework using Bloom's Taxonomy to assess LLMs' software security comprehension across six cognitive levels. 2. Proposed the concept of a \"software security knowledge boundary\" to identify the highest reliable cognitive performance level for an LLM. 3. Identified and documented 51 recurring misconception patterns made by LLMs in software security tasks.",
      "summary": "This paper systematically evaluates the software security comprehension of five leading LLMs using Bloom's Taxonomy as a framework across diverse datasets. The results show that while LLMs perform well on lower-level cognitive tasks like recalling facts, their performance significantly degrades on higher-order tasks requiring reasoning and secure system creation. The study introduces a knowledge boundary to quantify reliable performance limits and identifies common misconception patterns.",
      "mindmap": "graph LR\n    A[Assessing LLM Software Security Comprehension<br/>评估LLM软件安全理解] --> B{核心问题/Problem};\n    A --> C{主要方法/Method};\n    A --> D{关键结果/Results};\n    B --> B1[LLMs' Security Expertise Unclear<br/>LLM安全专业知识不明];\n    C --> C1[Framework: Bloom's Taxonomy<br/>框架: 布鲁姆分类法];\n    C --> C2[Datasets: MCQs, Code, Courses, Case Studies<br/>数据集: 选择题, 代码, 课程, 案例];\n    D --> D1[Good on Low-Level Tasks<br/>低级任务表现好];\n    D --> D2[Poor on High-Order Reasoning<br/>高阶推理表现差];\n    D --> D3[Knowledge Boundary & Misconceptions<br/>知识边界与误解模式];"
    },
    {
      "title": "Flow Gym",
      "authors": "Francesco Banelli, Antonio Terpin, Alan Bonomi, Raffaello D'Andrea",
      "institution": "ETH Zürich",
      "link": "https://arxiv.org/pdf/2512.20642",
      "code": "https://github.com/antonioterpin/flowgym",
      "tags": [
        "optical flow / particle image velocimetry",
        "flow-field quantification",
        "synthetic data generation",
        "JAX",
        "reinforcement learning environment",
        "benchmarking toolkit"
      ],
      "day": "2025-12-25",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e5173f537ce94701f33cf868d525b0c8117477e440d08e96c43c778b59915a4_w640_q70.webp",
      "contributions": "1. Introduces Flow Gym, a unified toolkit for research and deployment of flow-field quantification methods, inspired by OpenAI Gym. 2. Provides a modular, stateless interface for testing, training, and deploying both learning-based and classical algorithms using a synthetic image generation engine (SynthPix). 3. Offers stable JAX re-implementations and integrations of existing algorithms for standardized benchmarking.",
      "summary": "The paper presents Flow Gym, a toolkit designed to standardize the development and evaluation of algorithms for quantifying flow fields from particle images. It provides a unified, modular interface inspired by reinforcement learning environments, enabling easy testing and training of methods using synthetic data. The main outcome is a framework that facilitates reproducible research and benchmarking in flow-field quantification.",
      "mindmap": "graph LR\n    A[Flow Gym] --> B[核心问题/Problem: 流场量化算法缺乏标准化测试框架/Lack of standardized framework for flow-field quantification algorithms];\n    A --> C[主要方法/Method: 提供受RL启发的统一接口与合成数据引擎/Provides RL-inspired unified interface & synthetic data engine];\n    A --> D[关键结果/Results: 用于算法开发与基准测试的JAX兼容工具包/JAX-compatible toolkit for algorithm dev & benchmarking];"
    },
    {
      "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "authors": "Ivan Daunis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19769",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/39e158baf642d33624c0967b1dcd509fbc3876a4bc52a539d4b6e7c800995b42_w640_q70.webp",
      "contributions": "",
      "summary": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
      "mindmap": ""
    },
    {
      "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "authors": "Wang Bin, Ao Yang, Kedan Li, Aofan Liu, Hui Li, Guibo Luo, Weixiang Huang, Yan Zhuang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19758",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/45aa033e5d42a870c8059ab54cb6cefa331610516ad0bef063a9ce423cb132dc_w640_q70.webp",
      "contributions": "",
      "summary": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
      "mindmap": ""
    },
    {
      "title": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection",
      "authors": "Phong Nguyen, Anh M. T. Bui, Phuong T. Nguyen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19883",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb02d6486b7648f66dabcf681fd3aa648ad9d4d97929893d6c718261d7cdd896_w640_q70.webp",
      "contributions": "",
      "summary": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection",
      "mindmap": ""
    },
    {
      "title": "Towards Analysing Invoices and Receipts with Amazon Textract",
      "authors": "Sneha Oommen, Gabby Sanchez, Cassandra T. Britto, Di Wang, Jordan Chiou, Maria Spichkova",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19958",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8027409d62cb78b143f7d21e2c36fb093ab6a4978dfa9fe88c1a8339d40565fd_w640_q70.webp",
      "contributions": "",
      "summary": "Towards Analysing Invoices and Receipts with Amazon Textract",
      "mindmap": ""
    },
    {
      "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "authors": "Zhe Yin, Xiaodong Gu, Beijun Shen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19980",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/612b57ba54262082ae033612387571cddc86ac826d14c6f5b1ba4c241011b3b9_w640_q70.webp",
      "contributions": "",
      "summary": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
      "mindmap": ""
    },
    {
      "title": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "authors": "Yanjing Yang, He Zhang, Bohan Liu, Jinwei Xu, Jinghao Hu, Liming Dong, Zhewen Mao, Dongxue Pan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19997",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/70a323ff0c6b620555f25fedefe7b12761782c69ac299e6333a9bde71caf7b04_w640_q70.webp",
      "contributions": "",
      "summary": "BacAlarm: Mining and Simulating Composite API Traffic to Prevent Broken Access Control Violations",
      "mindmap": ""
    },
    {
      "title": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing",
      "authors": "Wenzhao Wu, Yahui Tang, Mingfei Cheng, Wenbing Tang, Yuan Zhou, Yang Liu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20083",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f2f6a93b0ca9601c38b73ad3e8c062333303a8f9538415f2546b2a923116462a_w640_q70.webp",
      "contributions": "",
      "summary": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing",
      "mindmap": ""
    },
    {
      "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
      "authors": "Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20159",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a9b4276c369f7cc83453b7385f456424f32c6a43157de7895979a0b4e9cd33bf_w640_q70.webp",
      "contributions": "",
      "summary": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
      "mindmap": ""
    },
    {
      "title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair",
      "authors": "Zhenlei Ye, Xiaobing Sun, Sicong Cao, Lili Bo, Bin Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20203",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/689696655ef1a605fe01d3f671d2e7d5eb99f438f83f110a88f303de369b7dc4_w640_q70.webp",
      "contributions": "",
      "summary": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair",
      "mindmap": ""
    },
    {
      "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "authors": "Tarik Houichime, Abdelghani Souhar, Younes El Amrani",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20245",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1001e3781e678219db00950fa667bbe46bbaa2f98cd7e5064d91ede9a2cbc6fe_w640_q70.webp",
      "contributions": "",
      "summary": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
      "mindmap": ""
    },
    {
      "title": "Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability",
      "authors": "Sarah Alsubaie, Sakhaa Alsaedi, Xin Gao",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20279",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8461db004ea160aa8af9906d632218283ad8a987409958ac11bd49b4d9c79d3c_w640_q70.webp",
      "contributions": "",
      "summary": "Auditing Reproducibility in Non-Targeted Analysis: 103 LC/GC--HRMS Tools Reveal Temporal Divergence Between Openness and Operability",
      "mindmap": ""
    },
    {
      "title": "Toward Explaining Large Language Models in Software Engineering Tasks",
      "authors": "Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20328",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2779c954fdfbaebf8f7d7d236f2c601ab45082cae14229886e2b749d6d8cd669_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Explaining Large Language Models in Software Engineering Tasks",
      "mindmap": ""
    },
    {
      "title": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation",
      "authors": "Yuan Huang, Yukang Zhou, Xiangping Chen, Zibin Zheng",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20334",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96e3cbe7534ab0200cc8de3dd256a72556796af563c3231e3ae3fe377c613650_w640_q70.webp",
      "contributions": "",
      "summary": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation",
      "mindmap": ""
    },
    {
      "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
      "authors": "Xiaoxue Ma, Wanwei Zhan, Jiale Chen, Yishu Li, Jacky Keung, Federica Sarro",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20345",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/68f886744860ac84868ef1c9d8e90cca2237c662d2aa29c92c0a15e76969507a_w640_q70.webp",
      "contributions": "",
      "summary": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
      "mindmap": ""
    },
    {
      "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
      "authors": "Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20381",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/295a39edb17ec8824ad34080df5c2a960bf42d578ae6e9a2db55f3775d90e225_w640_q70.webp",
      "contributions": "",
      "summary": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
      "mindmap": ""
    },
    {
      "title": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "authors": "Niccolò Scatena, Pericle Perazzo, Giovanni Nardini",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20402",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6c948c2f471538c4ad6962b3c03e4c869eb3e5bfdea61004d6f568b880cedc1e_w640_q70.webp",
      "contributions": "",
      "summary": "iblock: Accurate and Scalable Bitcoin Simulations with OMNeT++",
      "mindmap": ""
    },
    {
      "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "authors": "Narges Khakpour, Nicolas Berthier",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20396",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a6bdfa1cdb9c42587497d38e68d6ea55a15a3372a5c197a241c9e2cf0c52caf1_w640_q70.webp",
      "contributions": "",
      "summary": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
      "mindmap": ""
    },
    {
      "title": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization",
      "authors": "Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.20482",
      "code": null,
      "tags": [],
      "day": "2025-12-24",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/61a2f4887d3f7e1f76ef9da213d8cbb2fd86e68bd8a8206e3a2e53677aa7151e_w640_q70.webp",
      "contributions": "",
      "summary": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization",
      "mindmap": ""
    },
    {
      "title": "Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration",
      "authors": "Victor Stasiuc, Round Table Collaboration",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.17956",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/57a72b745466d47b8a8056586ccf86e4e40bd0ac42a76b0061c6576b563f4532_w640_q70.webp",
      "contributions": "",
      "summary": "Victor Calibration (VC): Multi-Pass Confidence Calibration and CP4.3 Governance Stress Test under Round-Table Orchestration",
      "mindmap": ""
    },
    {
      "title": "Specification and Detection of LLM Code Smells",
      "authors": "Brahim Mahmoudi, Zacharie Chenail-Larcher, Naouel Moha, Quentin Stievenert, Florent Avellaneda",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18020",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2cee6a3c076b484391912c8b6083413504d86a9475e81592b3004ce305e4f9c4_w640_q70.webp",
      "contributions": "",
      "summary": "Specification and Detection of LLM Code Smells",
      "mindmap": ""
    },
    {
      "title": "Detecting Flaky Tests in Quantum Software: A Dynamic Approach",
      "authors": "Dongchan Kim, Hamidreza Khoramrokh, Lei Zhang, Andriy Miranskyy",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18088",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9d0f2432ccc8ddbb1d6847d4ef5de32df143c118ab7994523048741c8d3083cc_w640_q70.webp",
      "contributions": "",
      "summary": "Detecting Flaky Tests in Quantum Software: A Dynamic Approach",
      "mindmap": ""
    },
    {
      "title": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "authors": "Marcos Ortiz, Justin Hill, Collin Overbay, Ingrida Semenec, Frederic Sauve-Hoover, Jim Schwoebel, Joel Shor",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18080",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0154cb62824a09bcbf4a6476b89c563b0f548b2e6721f62b4207082ab09ee544_w640_q70.webp",
      "contributions": "",
      "summary": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
      "mindmap": ""
    },
    {
      "title": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "authors": "Kishan Kumar Ganguly, Tim Menzies",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18102",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/509a927741960d2c63062790fd8bebe6a6a22769c29f6985c39fb001039d9fab_w640_q70.webp",
      "contributions": "",
      "summary": "From Coverage to Causes: Data-Centric Fuzzing for JavaScript Engines",
      "mindmap": ""
    },
    {
      "title": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
      "authors": "Le Zhang, Suresh Kothari",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18131",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e08a9f551315e560db6179abac192d75f62ffe1b185263cb90784842012ac802_w640_q70.webp",
      "contributions": "",
      "summary": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
      "mindmap": ""
    },
    {
      "title": "Understanding Typing-Related Bugs in Solidity Compiler",
      "authors": "Lantian Li, Yue Pan, Dan Wang, Jingwen Wu, Zhongxing Yu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18182",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1edd902d54a210d4adc69bf8b9c2e90b98ee4461ca8ff9631e5105665c2af358_w640_q70.webp",
      "contributions": "",
      "summary": "Understanding Typing-Related Bugs in Solidity Compiler",
      "mindmap": ""
    },
    {
      "title": "Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization",
      "authors": "Lichen Yang, Qiang Wang, Zhonghao Yang, Daojing He, Yu Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18228",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9987a54aec669e601a71ba8b0ee7d5434ba0c73d08a66e20538cf347a09669cd_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Efficient Testing of Graph Neural Networks via Test Input Prioritization",
      "mindmap": ""
    },
    {
      "title": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "authors": "M. Mehdi Kholoosi, Triet Huynh Minh Le, M. Ali Babar",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18261",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c527700e49403d8d115fcd9b121714ac7cc66ca4c4917d88ae5eeb6712cf705e_w640_q70.webp",
      "contributions": "",
      "summary": "Software Vulnerability Management in the Era of Artificial Intelligence: An Industry Perspective",
      "mindmap": ""
    },
    {
      "title": "Monitoring Monitorability",
      "authors": "Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18311",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b80143b15f0287eaa0d31decbf1a350d64c8110ec245d21e81c64ae73cd6febc_w640_q70.webp",
      "contributions": "",
      "summary": "Monitoring Monitorability",
      "mindmap": ""
    },
    {
      "title": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "authors": "Chenyuan Yang, Natalie Neamtu, Chris Hawblitzel, Jacob R. Lorch, Shan Lu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18436",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8a6dcac7fed2f39d9b3c88cf4fcec2c0a341fe5463b697a482bfb914d0610c67_w640_q70.webp",
      "contributions": "",
      "summary": "VeruSAGE: A Study of Agent-Based Verification for Rust Systems",
      "mindmap": ""
    },
    {
      "title": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
      "authors": "Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18470",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3aa84e9ee4a961b04628c969b7317aae944aad76753539183cd0213072cfce14_w640_q70.webp",
      "contributions": "",
      "summary": "SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios",
      "mindmap": ""
    },
    {
      "title": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "authors": "Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18552",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0bcd15393eed2ab163719da9a9e1954f5b23176404f9ad291a7ddc746dc5dd6_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
      "mindmap": ""
    },
    {
      "title": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
      "authors": "Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18567",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1a9235d0c624936af1cfc09fc3a4442da3cad4b4006c63ac0a8fe4392c0673dc_w640_q70.webp",
      "contributions": "",
      "summary": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
      "mindmap": ""
    },
    {
      "title": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "authors": "Yuchen Li, Handing Wang, Bing Xue, Mengjie Zhang, Yaochu Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18682",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1d33a421c48ad59f7420161a73adc3cf5979c2e95cd4ded4b6c5ac3a603e0e95_w640_q70.webp",
      "contributions": "",
      "summary": "Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design",
      "mindmap": ""
    },
    {
      "title": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "authors": "Recep Kaan Karaman, Meftun Akarsu",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18748",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0b6da5096797c358f77d8022914985853333b12b54cf68425fe470f42a60638b_w640_q70.webp",
      "contributions": "",
      "summary": "Code2Doc: A Quality-First Curated Dataset for Code Documentation",
      "mindmap": ""
    },
    {
      "title": "Misbehavior Forecasting for Focused Autonomous Driving Systems Testing",
      "authors": "M M Abid Naziri, Stefano Carlo Lambertenghi, Andrea Stocco, Marcelo d'Amorim",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18823",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d28332e6cbfc968e2f126c36ef57e40da98c2cdac079ecc02d7dc88024294d89_w640_q70.webp",
      "contributions": "",
      "summary": "Misbehavior Forecasting for Focused Autonomous Driving Systems Testing",
      "mindmap": ""
    },
    {
      "title": "What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub",
      "authors": "Khairul Alam, Banani Roy",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18852",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a91b214a3f60d6731e87235c417f1926ce91f9c4cae6b181b384b9e7b05c01f2_w640_q70.webp",
      "contributions": "",
      "summary": "What Drives Issue Resolution Speed? An Empirical Study of Scientific Workflow Systems on GitHub",
      "mindmap": ""
    },
    {
      "title": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "authors": "Shaokang Jiang, Daye Nam",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18925",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/2089c7618775b9b9cdc54e25f2f7b14898adbf8c1ce8308d624be1f22c566408_w640_q70.webp",
      "contributions": "",
      "summary": "An Empirical Study of Developer-Provided Context for AI Coding Assistants in Open-Source Projects",
      "mindmap": ""
    },
    {
      "title": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "authors": "Wen-Long Jin",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18940",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5496d384aad293547e961ed7f2ce4568121f384e9e0b977144128668dc8445cb_w640_q70.webp",
      "contributions": "",
      "summary": "FASTRIC: Prompt Specification Language for Verifiable LLM Interactions",
      "mindmap": ""
    },
    {
      "title": "Scrum Sprint Planning: LLM-based and algorithmic solutions",
      "authors": "Yuwon Yoon, Kevin Iwan, Madeleine Zwart, Xiaohan Qin, Hina Lee, Maria Spichkova",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18966",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fbba1000019eeb305645e5c8c1e960d23972872aca223b91a22bf2273fe7382d_w640_q70.webp",
      "contributions": "",
      "summary": "Scrum Sprint Planning: LLM-based and algorithmic solutions",
      "mindmap": ""
    },
    {
      "title": "Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation",
      "authors": "Chong Liu, Ming Zhang, Fei Li, Hao Zhou, Xiaoshuang Chen, Ye Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18996",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1bc934518ca031428cca5fd8c00520837bb98e48a55a7433a62c9c6ec593d172_w640_q70.webp",
      "contributions": "",
      "summary": "Modular Layout Synthesis (MLS): Front-end Code via Structure Normalization and Constrained Generation",
      "mindmap": ""
    },
    {
      "title": "PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations",
      "authors": "Muhammad Usman Tariq, Abhinav Jangda, Angelica Moreira, Madan Musuvathi, Tyler Sorensen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19018",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/439d8019fabcd76a49be539fc77d4ae2bfc00f17e5e2185ecf1bd06604924e4b_w640_q70.webp",
      "contributions": "",
      "summary": "PEAK: A Performance Engineering AI-Assistant for GPU Kernels Powered by Natural Language Transformations",
      "mindmap": ""
    },
    {
      "title": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "authors": "Mahir Labib Dihan, Sadif Ahmed, Md Nafiu Rahman",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19122",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/cf739862e73c646805e217bdf5e2cd5a0f6ec312b673bc4801a828112773cb1d_w640_q70.webp",
      "contributions": "",
      "summary": "BanglaForge: LLM Collaboration with Self-Refinement for Bangla Code Generation",
      "mindmap": ""
    },
    {
      "title": "University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem",
      "authors": "Xiaolan Cai, Mathieu O'Neil, Stefano Zacchiroli",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19153",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4fa74baba8cc4201da92e76936c3c5ee2263734f0d3691411e21f6034b3d1130_w640_q70.webp",
      "contributions": "",
      "summary": "University Rents Enabling Corporate Innovation: Mapping Academic Researcher Coding and Discursive Labour in the R Language Ecosystem",
      "mindmap": ""
    },
    {
      "title": "Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation",
      "authors": "Junyao Ye, Zhen Li, Xi Tang, Shouhuai Xu, Deqing Zou, Zhongsheng Yuan",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19215",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7e737e397a7b3abd370c7787c30a3c048ffd5544877e123bf750070107c4a6f8_w640_q70.webp",
      "contributions": "",
      "summary": "Semantically-Equivalent Transformations-Based Backdoor Attacks against Neural Code Models: Characterization and Mitigation",
      "mindmap": ""
    },
    {
      "title": "A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis",
      "authors": "Katharina Stengg, Christian Macho, Martin Pinzger",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19481",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/83f5edcaed3e66cf570a1118c40709f58e2f28ea874fce90d48d26c98b1618e8_w640_q70.webp",
      "contributions": "",
      "summary": "A Dataset and Preliminary Study of Using GPT-5 for Code-change Impact Analysis",
      "mindmap": ""
    },
    {
      "title": "Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models",
      "authors": "Shangbo Yun, Xiaodong Gu, Jianghong Huang, Beijun Shen",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19509",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b0f18c1ffcb7a64966a1ef778f8e8147966017df0eef1de11cbbbc67539b5f0e_w640_q70.webp",
      "contributions": "",
      "summary": "Beyond Language Boundaries: Uncovering Programming Language Families for Code Language Models",
      "mindmap": ""
    },
    {
      "title": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "authors": "Gabrielle O'Brien, Alexis Parker, Nasir Eisty, Jeffrey Carver",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.19644",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7fa42c82b2739bd1b4c7111c0c7d29876d12dbca90ed48e9b300fd1778d6e033_w640_q70.webp",
      "contributions": "",
      "summary": "More code, less validation: Risk factors for over-reliance on AI coding tools among scientists",
      "mindmap": ""
    },
    {
      "title": "Toward Live Noise Fingerprinting in Quantum Software Engineering",
      "authors": "Avner Bensoussan, Elena Chachkarova, Karine Even-Mendoza, Sophie Fortz, Vasileios Klimis",
      "institution": "TBD",
      "link": "https://arxiv.org/pdf/2512.18667",
      "code": null,
      "tags": [],
      "day": "2025-12-23",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d160a181b86cae75d281b58d0cfe8931c29e5725f4c44ec2695ca299321e15da_w640_q70.webp",
      "contributions": "",
      "summary": "Toward Live Noise Fingerprinting in Quantum Software Engineering",
      "mindmap": ""
    },
    {
      "title": "SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization",
      "authors": "Shravan Chaudhari, Rahul Thomas Jacob, Mononito Goswami, Jiajun Cao, Shihab Rashid, Christian Bock",
      "institution": "Johns Hopkins University, AWS AI Labs",
      "link": "https://arxiv.org/pdf/2512.16956",
      "code": null,
      "tags": [
        "llm inference",
        "dense embedding retrieval",
        "graph-based exploration",
        "BM25",
        "LLM-based reasoning",
        "code localization"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c743ebe3d40c5416b7ff367b0e7e93ca8ff7bf1bd771b2359d8a7333521abcbc_w640_q70.webp",
      "contributions": "",
      "summary": "The paper proposes SpIDER, a method that enhances dense retrieval for code localization by using graph-based exploration of a codebase to gather auxiliary context, which is then reasoned over by an LLM. This approach addresses the limitations of standard embedding methods that underutilize code structure. Empirical results show that SpIDER consistently improves retrieval performance across multiple programming languages.",
      "mindmap": ""
    },
    {
      "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories",
      "authors": "Lilin Wang, Lucas Ramalho, Alan Celestino, Phuc Anthony Pham, Yu Liu, Umang Kumar Sinha, Andres Portillo, Onassis Osunwa, Gabriel Maduekwe",
      "institution": "Turing",
      "link": "https://arxiv.org/pdf/2512.17419",
      "code": null,
      "tags": [
        "llm inference",
        "SWE-Bench++",
        "automated benchmark generation",
        "pull request harvesting",
        "environment synthesis",
        "test oracle extraction",
        "hint-guided trajectory synthesis",
        "fine-tuning"
      ],
      "day": "2025-12-22",
      "thumbnail": "https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/077c20705c707ee562f1935988b006695cf25f213f2df392cb27846fedaf0d4a_w640_q70.webp",
      "contributions": "",
      "summary": "The paper introduces SWE-Bench++, an automated framework that generates software engineering benchmarks by harvesting pull requests from GitHub to create reproducible, execution-based coding tasks across multiple languages. The method involves programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance, with a final step to create training trajectories from failed instances. The main conclusion is that this scalable, multilingual approach provides a valuable benchmark for evaluating and improving LLMs on repository-level code generation, as demonstrated by model performance metrics and fine-tuning improvements.",
      "mindmap": ""
    },
    {
      "title": "When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction",
      "authors": "Emmanuel Charleson Dapaah, Jens Grabowski",
      "institution": "University of Göttingen",
      "link": "https://arxiv.org/pdf/2512.17460",
      "code": null,
      "tags": [
        "software defect prediction",
        "Explainable Boosting Machines",
        "stratified interaction analysis",
        "class imbalance",
        "class overlap",
        "irrelevant features",
        "attribute noise",
        "outliers"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper conducts a large-scale empirical study using Explainable Boosting Machines and stratified interaction analysis to examine five co-occurring data quality issues in software defect prediction across 374 datasets. It finds that co-occurrence is nearly universal, identifies tipping points for issues like class overlap and imbalance, and reveals context-dependent effects, concluding that no single model performs best under all conditions.",
      "mindmap": ""
    },
    {
      "title": "PathBench-MIL: A Comprehensive AutoML and Benchmarking Framework for Multiple Instance Learning in Histopathology",
      "authors": "Siemen Brussee, Pieter A. Valkema, Jurre A. J. Weijer, Thom Doeleman, Anne M.R. Schrader, Jesper Kers",
      "institution": "Leiden University Medical Center, Utrecht University Medical Center, Amsterdam University Medical Center",
      "link": "https://arxiv.org/pdf/2512.17517",
      "code": null,
      "tags": [
        "others",
        "multiple instance learning",
        "AutoML",
        "feature extraction",
        "whole-slide images",
        "benchmarking",
        "computational pathology"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces PathBench-MIL, an automated machine learning and benchmarking framework designed for Multiple Instance Learning in histopathology. It automates the entire pipeline from preprocessing to model aggregation, enabling standardized and reproducible evaluation of various models and feature extractors on whole-slide image datasets. The main conclusion is that this open-source framework facilitates rapid experimentation and standardization in computational pathology research.",
      "mindmap": ""
    },
    {
      "title": "LLM-based Behaviour Driven Development for Hardware Design",
      "authors": "Rolf Drechsler, Qian Liu",
      "institution": "University of Bremen, DFKI",
      "link": "https://arxiv.org/pdf/2512.17814",
      "code": null,
      "tags": [
        "others",
        "Behavior Driven Development (BDD)",
        "Large Language Models (LLMs)",
        "hardware design",
        "test and verification",
        "natural language processing",
        "Electronic Design Automation (EDA)"
      ],
      "day": "2025-12-22",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates the use of Large Language Models (LLMs) to automate the generation of behavioral scenarios from textual specifications for Behavior Driven Development (BDD) in hardware design. The core method involves applying LLM-based techniques to interpret specifications and produce high-level behavioral descriptions. The main conclusion is that LLMs offer a promising opportunity to support and automate BDD workflows in hardware design, addressing the manual effort and complexity of current verification practices.",
      "mindmap": ""
    },
    {
      "title": "Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes",
      "authors": "Shrinivass Arunachalam Balasubramanian",
      "institution": "Independent Researcher",
      "link": "https://arxiv.org/pdf/2512.15775",
      "code": null,
      "tags": [
        "others",
        "Finite Exponential Continuous State Machine (FECSM)",
        "Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA)",
        "Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU)",
        "HDBSCAN",
        "min-max normalization",
        "User Interface Change Prediction Index (UICPI)"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a dynamic web UI optimization method that uses a Finite Exponential Continuous State Machine for cross-device responsiveness assessment and a novel Quokka Nonlinear Difference Swarm Optimization Algorithm for design optimization. The core technique involves classifying user experience changes with a Bidirectional Gated Luong and Mish Recurrent Unit model. The main conclusion is that this integrated approach achieves an average fitness of 98.5632% for optimal UI design by incorporating cross-responsiveness assessment and user behavior patterns.",
      "mindmap": ""
    },
    {
      "title": "CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory",
      "authors": "Nishant Gaurav, Adit Akarsh, Tejas Ravishankar, Manoj Bajaj",
      "institution": "AgentR",
      "link": "https://arxiv.org/pdf/2512.15813",
      "code": null,
      "tags": [
        "others",
        "CodeAct",
        "procedural memory",
        "deterministic reliability",
        "reusable agentic workflows",
        "Python action space",
        "dynamic MCP"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes CodeMem, an architecture that uses code as procedural memory to build reproducible AI agents. It addresses probabilistic instability in LLM-based agents by shifting workflow logic from volatile context into deterministic, saved code blocks. The main conclusion is that this approach enables the creation of reusable agentic workflows with reliable, deterministic execution.",
      "mindmap": ""
    },
    {
      "title": "Optimizing Agentic Language Model Inference via Speculative Tool Calls",
      "authors": "Daniel Nichols, Prajwal Singhania, Charles Jekel, Abhinav Bhatele, Harshitha Menon",
      "institution": "Lawrence Livermore National Laboratory, University of Maryland",
      "link": "https://arxiv.org/pdf/2512.15834",
      "code": null,
      "tags": [
        "llm inference",
        "speculative tool calls",
        "tool cache",
        "vLLM",
        "prefix-caching"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces system optimizations for language model agents that use external tools, specifically by speculating future tool calls and keeping sequences resident in the inference engine to reduce overhead. These methods lead to significant throughput improvements of hundreds of tokens per second. The authors also propose a new \"tool cache\" API to facilitate adoption of these optimizations.",
      "mindmap": ""
    },
    {
      "title": "OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering",
      "authors": "Mia Mohammad Imran, Tarannum Shaila Zaman",
      "institution": "Missouri University of Science and Technology, University of Maryland Baltimore County",
      "link": "https://arxiv.org/pdf/2512.15979",
      "code": null,
      "tags": [
        "empirical software engineering",
        "annotation framework",
        "reliability",
        "calibration",
        "drift",
        "consensus",
        "aggregation",
        "transparency"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This position paper proposes OLAF, a conceptual framework for treating LLM-based annotation as a measurement process in empirical software engineering. It organizes key constructs like reliability, calibration, and drift to address current methodological gaps. The paper concludes that such a framework is necessary to improve the transparency and reproducibility of LLM-assisted annotation in software engineering research.",
      "mindmap": ""
    },
    {
      "title": "Embedding Software Intent: Lightweight Java Module Recovery",
      "authors": "Yirui He, Yuqi Huai, Xingyu Chen, Joshua Garcia",
      "institution": "University of California, Irvine",
      "link": "https://arxiv.org/pdf/2512.15980",
      "code": null,
      "tags": [
        "software architecture recovery",
        "ClassLAR",
        "JPMS",
        "language models",
        "fully-qualified class names",
        "reverse engineering"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ClassLAR, a lightweight approach for recovering Java modules from monolithic systems by using language models to extract semantic information from fully-qualified class names. The method captures structural and functional intent to map code to architectural modules. The evaluation shows ClassLAR outperforms state-of-the-art techniques in accuracy and is significantly faster in execution time.",
      "mindmap": ""
    },
    {
      "title": "Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls",
      "authors": "Ora Nova Fandina, Eitan Farchi, Shmulik Froimovich, Raviv Gal, Wesam Ibraheem, Rami Katan, Alice Podolsky",
      "institution": "IBM Research, Israel",
      "link": "https://arxiv.org/pdf/2512.16272",
      "code": null,
      "tags": [
        "llm inference",
        "llm-as-a-judge",
        "analytic checker",
        "hybrid evaluation",
        "prompt injection",
        "cobol code generation"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a hybrid evaluation method that combines an LLM-as-a-Judge (LaaJ) with a lightweight analytic checker that provides domain-specific hints, which are dynamically injected into the judge's prompt. The method was tested on COBOL code generation, where LaaJs alone missed many errors. The results show that the LaaJ+Hints configuration significantly improves error detection coverage and explanation quality, demonstrating the effectiveness of analytic-LLM hybrids for reliable evaluation.",
      "mindmap": ""
    },
    {
      "title": "ParamExplorer: A framework for exploring parameters in generative art",
      "authors": "Julien Gachadoat, Guillaume Lagarde",
      "institution": "University of Bordeaux",
      "link": "https://arxiv.org/pdf/2512.16529",
      "code": null,
      "tags": [
        "generative art",
        "reinforcement learning",
        "parameter exploration",
        "human-in-the-loop",
        "p5.js"
      ],
      "day": "2025-12-19",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces ParamExplorer, an interactive and modular framework inspired by reinforcement learning to help explore the high-dimensional parameter spaces of generative art algorithms. It allows for exploration guided by human feedback and integrates with existing p5.js projects. The framework implements and evaluates several automated exploration strategies, referred to as agents, to discover aesthetically compelling outputs more efficiently than manual trial-and-error.",
      "mindmap": ""
    },
    {
      "title": "Revisiting the Reliability of Language Models in Instruction-Following",
      "authors": "Jianshuo Dong, Yutong Zhang, Yan Liu, Zhenyu Zhong, Tao Wei, Chao Zhang, Han Qiu",
      "institution": "Tsinghua University, Ant Group",
      "link": "https://arxiv.org/pdf/2512.14754",
      "code": null,
      "tags": [
        "llm evaluation",
        "instruction-following",
        "reliability",
        "data augmentation",
        "benchmark",
        "IFEval++",
        "reliable@k"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces a new metric, reliable@k, and an automated data augmentation pipeline to generate \"cousin prompts\" for evaluating nuance-oriented reliability in LLMs, constructing the IFEval++ benchmark. It finds that current LLMs show significant performance drops (up to 61.8%) with nuanced prompt variations, highlighting a crucial gap in real-world reliability.",
      "mindmap": ""
    },
    {
      "title": "CAPE: Capability Achievement via Policy Execution",
      "authors": "David Ball",
      "institution": "Superficial Labs",
      "link": "https://arxiv.org/pdf/2512.14761",
      "code": null,
      "tags": [
        "post-training",
        "capability engineering",
        "policy execution",
        "specification language",
        "verification",
        "DPO",
        "contextual objectivity",
        "verification-fidelity scaling"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces CAPE, a protocol for Capability Engineering that implements a Specify-&gt;Verify-&gt;Correct-&gt;Train loop to convert requirements into executable specifications and train models to satisfy them by default. It demonstrates that CAPE reduces policy violation rates by 81% compared to DPO and significantly lowers costs and development timelines by using reusable specifications.",
      "mindmap": ""
    },
    {
      "title": "Workflows vs Agents for Code Translation",
      "authors": "Henry Gray, Tom Yotam, Octavian Udrea",
      "institution": "Code Metal",
      "link": "https://arxiv.org/pdf/2512.14762",
      "code": null,
      "tags": [
        "llm inference",
        "Model Context Protocol (MCP)",
        "syntax repair",
        "code translation",
        "MATLAB-to-HDL",
        "agentic framework",
        "conditional retrieval"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper compares two LLM-driven methods for syntax repair in a MATLAB-to-hardware-description-language translation pipeline: a fixed expert-designed workflow and a more autonomous agentic approach using the Model Context Protocol (MCP). The agentic approach, which dynamically selects tools, was more effective at resolving syntax errors, especially for small and mid-sized models, leading to significant downstream improvements in simulation success rates.",
      "mindmap": ""
    },
    {
      "title": "IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection",
      "authors": "Roman Nekrasov, Stefano Fossati, Indika Kumara, Damian Andrew Tamburri, Willem-Jan van den Heuvel",
      "institution": "Jheronimus Academy of Data Science, Tilburg University, Eindhoven University of Technology, University of Sannio",
      "link": "https://arxiv.org/pdf/2512.14792",
      "code": null,
      "tags": [
        "llm inference",
        "Retrieval-Augmented Generation (RAG)",
        "Graph RAG",
        "knowledge injection",
        "error taxonomy",
        "Terraform",
        "IaC-Eval benchmark"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates improving Large Language Model (LLM) generation of Infrastructure as Code (IaC) by injecting structured configuration knowledge using techniques from naive to Graph RAG. The study finds that while knowledge injection significantly boosts technical correctness, LLMs still struggle with nuanced user intent, revealing a \"Correctness-Congruence Gap\" where they are better coders than architects.",
      "mindmap": ""
    },
    {
      "title": "Let the Barbarians In: How AI Can Accelerate Systems Performance Research",
      "authors": "Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Shubham Agarwal, Mert Cemri, Bowen Wang, Alexander Krentsel, Tian Xia, Jongseok Park, Shuo Yang, Jeff Chen, Lakshya Agrawal, Ashwin Naren, Shulu Li, Ruiying Ma, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica",
      "institution": "UC Berkeley",
      "link": "https://arxiv.org/pdf/2512.14806",
      "code": null,
      "tags": [
        "cluster infrastructure",
        "AI-Driven Research for Systems (ADRS)",
        "OpenEvolve",
        "GEPA",
        "ShinkaEvolve",
        "multi-region cloud scheduling",
        "mixture-of-experts load balancing",
        "LLM-based SQL",
        "transaction scheduling"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper introduces AI-Driven Research for Systems (ADRS), a method using AI to automate the generation, evaluation, and refinement of performance-optimizing algorithms for computer systems. Through case studies with frameworks like OpenEvolve, it demonstrates that ADRS can produce solutions matching or surpassing human-designed state-of-the-art. The work outlines best practices for applying ADRS and discusses its potential to shift researcher effort toward problem formulation and strategic oversight.",
      "mindmap": ""
    },
    {
      "title": "Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent",
      "authors": "Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh",
      "institution": "Dalhousie University, Polytechnique Montreal",
      "link": "https://arxiv.org/pdf/2512.14990",
      "code": null,
      "tags": [
        "fault-tolerance",
        "bug reproduction",
        "LLM",
        "iterative generate-validate-refine",
        "agentic AI"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper presents RepGen, an automated approach that uses an LLM-based intelligent agent to reproduce deep learning bugs by constructing a learning-enhanced context and employing an iterative generate-validate-refine mechanism. It achieves an 80.19% reproduction rate on real-world bugs, significantly outperforming the state-of-the-art, and a developer study confirms it improves success rates and reduces time and cognitive load for bug reproduction.",
      "mindmap": ""
    },
    {
      "title": "SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports",
      "authors": "Sogol Masoumzadeh, Yufei Li, Shane McIntosh, Dániel Varró, Lili Wei",
      "institution": "McGill University, University of Waterloo, Linköping University",
      "link": "https://arxiv.org/pdf/2512.15003",
      "code": null,
      "tags": [
        "others",
        "masked language model",
        "fine-tuning",
        "semantic surrogates",
        "deep neural network",
        "BERT"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper proposes SEBERTIS, a framework that fine-tunes bidirectional transformer models (like BERT) as Masked Language Models using semantically equivalent vocabulary (Semantic Surrogates) to create classifiers for security-related issue reports. This method reduces reliance on lexical shortcuts, enabling better detection of complex issues. The resulting classifier significantly outperforms existing ML and LLM baselines in precision, recall, and F1-score, demonstrating high effectiveness for real-time issue triage.",
      "mindmap": ""
    },
    {
      "title": "The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops",
      "authors": "Fanzhe Fu",
      "institution": "Zhejiang University",
      "link": "https://arxiv.org/pdf/2512.15053",
      "code": null,
      "tags": [
        "llm inference",
        "Meta-Prompting Protocol",
        "Adversarial Trinity",
        "DSPy",
        "TextGrad",
        "textual gradients",
        "semantic computation graph"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces the Meta-Prompting Protocol, a framework that formalizes LLM orchestration as a programmable system using an adversarial topology (Generator, Auditor, Optimizer) to treat prompts as differentiable variables. It leverages textual critiques as gradients within a semantic computation graph to mitigate hallucination and improve reliability. The authors demonstrate its theoretical viability with tools like DSPy and TextGrad, proposing a foundation for deterministic \"Observable Software Engineering\" for probabilistic models.",
      "mindmap": ""
    },
    {
      "title": "On Assessing the Relevance of Code Reviews Authored by Generative Models",
      "authors": "Robert Heumüller, Frank Ortmeier",
      "institution": "Otto von Guericke University Magdeburg",
      "link": "https://arxiv.org/pdf/2512.15466",
      "code": null,
      "tags": [
        "llm inference",
        "multi-subjective ranking",
        "code review generation",
        "ChatGPT",
        "human evaluation",
        "CodeReview StackExchange"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper proposes a multi-subjective ranking method to evaluate AI-generated code review comments, comparing ChatGPT outputs against top human responses from CodeReview StackExchange. The results show that ChatGPT's comments were ranked significantly better than human-authored ones, even outperforming accepted answers. The method aims to provide a more meaningful assessment of generative AI in code review while highlighting risks of unchecked integration.",
      "mindmap": ""
    },
    {
      "title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?",
      "authors": "Hua Yang, Alejandro Velasco, Thanh Le-Cong, Md Nazmul Haque, Bowen Xu, Denys Poshyvanyk",
      "institution": "North Carolina State University, William & Mary, The University of Melbourne",
      "link": "https://arxiv.org/pdf/2512.15468",
      "code": null,
      "tags": [
        "llm training",
        "membership inference",
        "semantically equivalent code transformation",
        "variable renaming",
        "causal analysis",
        "code obfuscation"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "This paper investigates how semantically equivalent code transformations, such as variable renaming, can be used to evade membership inference detection in large language models for code. It finds that these transformations, especially RenameVariable, can significantly reduce the success of membership inference attacks without substantially harming model performance. The results reveal a critical vulnerability in license compliance enforcement for code LLMs, showing that transformation-based obfuscation can weaken detection of unauthorized code usage.",
      "mindmap": ""
    },
    {
      "title": "FrontierCS: Evolving Challenges for Evolving Intelligence",
      "authors": "Qiuyang Mang, Wenhao Chai, Zhifei Li, Huanzhi Mao, Shang Zhou, Alexander Du, Hanchen Li, Shu Liu, Edwin Chen, Yichuan Wang, Xieting Chu, Zerui Cheng, Yuan Xu, Tian Xia, Zirui Wang, Tianneng Shi, Jianzhu Yao, Yilong Zhao, Qizheng Zhang, Charlie Ruan, Zeyu Shen, Kaiyuan Liu, Runyuan He, Dong Xing, Zerui Li, Zirong Zeng, Yige Jiang, Lufeng Cheng, Ziyi Zhao, Youran Sun, Wesley Zheng, Meiyuwang Zhang, Ruyi Ji, Xuechang Tu, Zihan Zheng, Zexing Chen, Kangyang Zhou, Zhaozi Wang, Jingbang Chen, Aleksandra Korolova, Peter Henderson, Pramod Viswanath, Vijay Ganesh, Saining Xie, Zhuang Liu, Dawn Song, Sewon Min, Ion Stoica, Joseph E. Gonzalez, Jingbo Shang, Alvin Cheung",
      "institution": "UC Berkeley, Princeton University, UCSD, X-camp Academy, Georgia Tech, Stanford University, University of Washington, Nanyang Technological University, University of Toronto, UIUC, University of Michigan, New York University, MIT",
      "link": "https://arxiv.org/pdf/2512.15699",
      "code": null,
      "tags": [
        "benchmarking",
        "benchmark",
        "open-ended problems",
        "competitive programming",
        "NP-hard",
        "automatic evaluation",
        "expert reference solution"
      ],
      "day": "2025-12-18",
      "thumbnail": null,
      "contributions": "",
      "summary": "The paper introduces FrontierCS, a benchmark of 156 open-ended computer science problems where the optimal solution is unknown but can be objectively evaluated, requiring models to generate executable programs. It finds that current frontier reasoning models significantly lag behind human experts, and that merely increasing reasoning budgets or generating workable code does not close this performance gap.",
      "mindmap": ""
    }
  ]
}