# 20251229-20260104

## 2025-12-29

**cs.DC total: 16**

- **[arXiv251229] Harnessing Data Spaces to Build Intelligent Smart City Infrastructures Across the Cloud-Edge Continuum**
  - **tags:** [mlsys], [on-device ai], [data spaces, cloud-edge continuum, containerized microservices, edge AI, intelligent infrastructure monitoring]
  - **authors:** Dimitrios Amaxilatis, Themistoklis Sarantakos, Nikolaos Tsironis, Souvik Sengupta, Kostas Ramantas, Jhofre Ojeda
  - **institution:** Spark Works Ltd., IONOS SE, Iquadrat Informática S.L.
  - **link:** https://arxiv.org/pdf/2512.21340
  - **contributions:** 1. A real-world implementation of intelligent infrastructure monitoring within a data space-enabled cloud-edge framework, demonstrating practical integration. 2. Leveraging edge computing, containerized microservices, and interoperable data sharing to address challenges like sensor integration, data privacy, and scalability. 3. Showcasing the training and deployment of AI/ML services directly at the edge for optimized resource use and timely decision-making in smart city applications.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5ae37cae2dac445e3682b661f116dd30e5d680105ac5070eb7b48c049ab9aff3_w640_q70.webp
  - **Simple LLM Summary:** This paper presents a real-world use case for smart cities, implementing an intelligent climate monitoring system within a cloud-edge continuum framework enabled by data spaces. The method combines edge computing, containerized microservices, and secure data sharing to facilitate localized analytics and AI deployment. The conclusion highlights the transformative potential of integrating AI, edge computing, and data spaces for building efficient and resilient smart city infrastructures.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Harnessing Data Spaces for Smart City Infrastructures] --> B[核心问题/Problem: Enhancing smart city efficiency, sustainability, and resilience with secure, interoperable data exchange]
        A --> C[主要方法/Method: Data space-enabled cloud-edge framework with edge computing, containerized microservices, and edge AI/ML]
        A --> D[关键结果/Results: Demonstrates practical use case for intelligent monitoring, enabling localized analytics, real-time inference, and trusted data collaboration]
    ```

- **[arXiv251229] DeepCQ: General-Purpose Deep-Surrogate Framework for Lossy Compression Quality Prediction**
  - **tags:** [mlsys], [model compression (quantization/pruning)], [lossy compression, quality prediction, deep-surrogate, mixture-of-experts, feature-extraction]
  - **authors:** Khondoker Mirazul Mumenin, Robert Underwood, Dong Dai, Jinzhen Wang, Sheng Di, Zarija Lukić, Franck Cappello
  - **institution:** University of North Carolina at Charlotte, Argonne National Laboratory, University of Delaware, Lawrence Berkeley National Laboratory
  - **link:** https://arxiv.org/pdf/2512.21433
  - **contributions:** 1) A generalizable surrogate model for predicting compression quality across different compressors, quality metrics, and datasets. 2) A novel two-stage design that decouples expensive feature extraction from lightweight prediction for efficient training and modular inference. 3) A mixture-of-experts design to optimize performance and robustness for time-evolving scientific data.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d06e831f83754144a92a117a184fdcc51da0584d4163390cf94b34d4175b77a1_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes DeepCQ, a deep-surrogate framework to efficiently predict the quality of data after lossy compression, which is traditionally computationally expensive to assess. The method uses a two-stage and mixture-of-experts design for generalizability and robustness across different compressors, metrics, and time-evolving datasets. The framework achieves high predictive accuracy (errors under 10%) on real-world applications, enabling informed compression decisions and reducing I/O and computational overhead.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DeepCQ: 通用深度代理框架用于有损压缩质量预测] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[评估压缩后数据质量的计算成本高/Expensive to assess post-compression data quality]
        C --> C1[两阶段设计: 特征提取 + 轻量预测/Two-stage design: feature extraction + lightweight prediction]
        C --> C2[专家混合设计处理时变数据/Mixture-of-experts for time-evolving data]
        D --> D1[预测误差普遍低于10%/Prediction errors generally under 10%]
        D --> D2[显著优于现有方法/Significantly outperforms existing methods]
    ```

- **[arXiv251229] Demystifying ARM SME to Optimize General Matrix Multiplications**
  - **tags:** [mlsys], [gpu kernels], [ARM SME, GEMM, cache-aware partitioning, micro-kernels, on-the-fly transposition]
  - **authors:** Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong
  - **institution:** College of Computer Science and Technology, National University of Defense Technology
  - **link:** https://arxiv.org/pdf/2512.21473
  - **contributions:** 1. A systematic characterization of the ARM SME architecture that derives optimization guidelines for GEMM. 2. The design and implementation of MpGEMM, an open-source library featuring cache-aware partitioning and efficient data packing with on-the-fly transposition. 3. Specialized micro-kernels that fully utilize SME's multi-vector loads and all available tile registers to maximize performance.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/3bc3a0f3452bf6376dcfa53f5f9e56a621c5b526537a2008e7f55c112b765095_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the underutilization of ARM's Scalable Matrix Extension (SME) hardware for large-scale General Matrix Multiplication (GEMM). It proposes MpGEMM, an open-source library that optimizes GEMM through cache-aware partitioning, efficient data packing, and specialized micro-kernels tailored for SME. Evaluations on an Apple M4 Pro show MpGEMM achieves a 1.23x speedup over the vendor-optimized Apple Accelerate library.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Demystifying ARM SME to Optimize General Matrix Multiplications") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("现有库未能充分利用ARM SME硬件/Existing libraries fail to exploit ARM SME")
        Problem --> P2("大规模GEMM性能瓶颈/Large-scale GEMM performance bottlenecks")
        Method --> M1("系统化架构分析/Systematic SME characterization")
        Method --> M2("设计MpGEMM库/Design MpGEMM library")
        M2 --> M2a("缓存感知分区/Cache-aware partitioning")
        M2 --> M2b("高效数据打包/Efficient data packing")
        M2 --> M2c("专用微内核/Specialized micro-kernels")
        Results --> R1("性能超越Apple Accelerate库/Outperforms Apple Accelerate")
        Results --> R2("显著优于其他开源方案/Significantly beats other open-source alternatives")
    ```

- **[arXiv251229] Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism**
  - **tags:** [mlsys], [llm inference], [mixture-of-experts (MoE), disaggregated expert parallelism (DEP), task scheduling, inference throughput, fine-grained pipelining]
  - **authors:** Xinglin Pan, Shaohuai Shi, Wenxiang Lin, Yuxin Wang, Zhenheng Tang, Wei Wang, Xiaowen Chu
  - **institution:** The Hong Kong University of Science and Technology (Guangzhou), Harbin Institute of Technology (Shenzhen), Hong Kong Baptist University, The Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.21487
  - **contributions:** 1) Partitioning intensive computation and communication tasks into smaller, fine-grained tasks to enable pipelining, including support for shared experts. 2) Formulating a fine-grained task scheduling optimization problem that supports variable task granularity and ordering. 3) Developing an efficient solver to navigate the large solution space and derive a near-optimal task schedule.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/44cc55e59c66470ffb4e47c93ad8e48f60e8377f30eff6289fbad1cfcb862c96_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the memory-intensive inference problem in Mixture-of-Experts (MoE) models by proposing FinDEP, a fine-grained task scheduling algorithm for Disaggregated Expert Parallelism (DEP). FinDEP improves inference throughput by maximizing task overlap through computational partitioning and optimized scheduling. Experiments on systems with up to 32 GPUs show throughput improvements of up to 1.61x over prior methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[FinDEP: Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[MoE推理内存密集，现有DEP调度效率低/MoE inference is memory-intensive, existing DEP scheduling is inefficient]
        C --> C1[细粒度任务划分与调度优化/Fine-grained task partitioning and scheduling optimization]
        D --> D1[吞吐量最高提升1.61倍/Throughput improved by up to 1.61x]
    ```

- **[arXiv251229] nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures**
  - **tags:** [mlsys], [compiler & ir], [e-graph, term rewriting, phase ordering, NUMA abstraction, auto vectorize]
  - **authors:** Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang
  - **institution:** Canaan Inc.
  - **link:** https://arxiv.org/pdf/2512.21571
  - **code:** https://github.com/kendryte/nncase
  - **contributions:** 1. Proposes an end-to-end compilation framework (nncase) that unifies LLM deployment across heterogeneous memory architectures using a NUMA abstraction for a "compile once, adapt everywhere" capability. 2. Introduces an e-graph-based term rewriting engine with equality saturation to mitigate the phase ordering problem and enable global optimization of computation and data movement. 3. Integrates three key automated optimization modules: Auto Vectorize for heterogeneous computing units, Auto Distribution for parallel strategies with communication optimization, and Auto Schedule for on-chip cache locality.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5a555b38ecd80e8c11606362e5402405bbf0053e11754e06f720d50ce213ee0d_w640_q70.webp
  - **Simple LLM Summary:** The paper presents nncase, an end-to-end compiler framework designed to tackle the challenge of efficiently deploying large language models on heterogeneous memory architectures. Its core innovation is an e-graph-based rewriting engine that avoids the phase ordering problem, enabling unified optimization across diverse hardware targets. Evaluations show nncase outperforms frameworks like MLC LLM and Intel IPEX, achieving performance close to hand-optimized llama.cpp, demonstrating the viability of automated compilation for high-performance LLM deployment.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures] --> B[核心问题/Problem: LLM部署受限于内存架构异构性，传统编译器流程碎片化/Memory architecture heterogeneity hinders efficient LLM deployment, traditional compilers have fragmented workflows.]
        A --> C[主要方法/Method: 基于e-graph的项重写引擎，统一NUMA抽象，集成自动向量化、分布、调度模块/E-graph-based term rewriting engine, unified NUMA abstraction, integrates Auto Vectorize, Distribution, Schedule modules.]
        A --> D[关键结果/Results: 性能超越MLC LLM和Intel IPEX，接近手工优化的llama.cpp/Outperforms MLC LLM & Intel IPEX, achieves performance comparable to hand-optimized llama.cpp.]
    ```

- **[arXiv251229] Embedding Samples Dispatching for Recommendation Model Training in Edge Environments**
  - **tags:** [mlsys], [memory & caching], [edge computing, embedding cache, parameter server, sample dispatching, transmission cost]
  - **authors:** Guopeng Li, Haisheng Tan, Chi Zhang, Hongqiu Ni, Zilong Wang, Xinyue Zhang, Yang Xu, Han Tian
  - **institution:** University of Science and Technology of China (USTC), Hefei University of Technology
  - **link:** https://arxiv.org/pdf/2512.21615
  - **contributions:** 1. Proposed ESD, a novel mechanism to optimize the dispatch of input embedding samples to edge workers to minimize embedding transmission cost. 2. Designed HybridDis, a dispatch decision method that combines an optimal algorithm and a heuristic to balance decision quality and resource consumption. 3. Implemented a prototype and demonstrated significant reductions in transmission cost (up to 36.76%) and training speedup (up to 1.74x) on real-world workloads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f94cc43f65f5fd909f8762bda535a33eea94f879931ebe1a563280cb0db1be81_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the high communication cost of embedding transmission during Deep Learning Recommendation Model (DLRM) training in edge environments. It proposes ESD, a mechanism that dispatches input samples to edge workers to minimize expected transmission cost, using a hybrid decision method called HybridDis. Experimental results show that ESD significantly reduces transmission cost and speeds up end-to-end training compared to state-of-the-art methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Embedding Samples Dispatching for Recommendation Model Training in Edge Environments<br>边缘环境中推荐模型训练的嵌入样本调度"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>DLRM边缘训练中嵌入传输成本高"] --> P1["挑战/Challenges<br>异构网络，资源受限"]
        Method["主要方法/Method<br>ESD机制与HybridDis调度"] --> M1["方法核心/Core<br>基于预期传输成本的样本调度"]
        Results["关键结果/Results<br>减少传输成本，加速训练"] --> R1["性能提升/Improvement<br>成本降低36.76%，速度提升1.74倍"]
    ```

- **[arXiv251229] LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol for Multicore Real-Time Systems**
  - **tags:** [sys], [real-time systems], [lock-free, fault-tolerance, resource sharing, multicore, worst-case response time analysis]
  - **authors:** Nan Chen, Xiaotian Dai, Tong Cheng, Alan Burns, Iain Bate, Shuai Zhao
  - **institution:** University of York, Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.21701
  - **contributions:** 1. Proposes the LEFT-RS protocol, a lock-free design that allows concurrent read access to global resources and parallel entry into critical sections, improving efficiency. 2. Enhances fault resilience by limiting overhead and enabling tasks to complete earlier if others experience faults, reducing blocking. 3. Provides a comprehensive worst-case response time analysis to ensure timing guarantees for the proposed protocol.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fb19a780f9199527b92c55981536e4b4108e6135efe187882739942a46ebf5ed_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes LEFT-RS, a lock-free and fault-tolerant resource sharing protocol for multicore real-time systems. It allows tasks to concurrently access resources and enter critical sections in parallel, improving efficiency and resilience to transient faults. Evaluation shows it significantly outperforms existing methods, achieving up to an 84.5% average improvement in schedulability.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LEFT-RS: A Lock-Free Fault-Tolerant Resource Sharing Protocol] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: Faults in critical sections cause error propagation; locking protocols lack fault tolerance, increasing blocking.]
        Method[主要方法/Method: LEFT-RS protocol enables concurrent read access and parallel critical section entry for fault resilience.]
        Results[关键结果/Results: Up to 84.5% average schedulability improvement over existing approaches.]
    ```

- **[arXiv251229] Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference**
  - **tags:** [mlsys], [multi-modal inference], [vision transformer, cloud-device collaboration, dynamic scheduling, patch-level importance, weighted ensembling]
  - **authors:** Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li
  - **institution:** Shanghai Jiao Tong University, Tsinghua University, Hong Kong University of Science and Technology
  - **link:** https://arxiv.org/pdf/2512.21730
  - **contributions:** 1. A collaboration-aware importance scorer that identifies critical regions at the patch level for selective processing. 2. A dynamic scheduler that adaptively adjusts patch transmission quality to balance latency and accuracy under changing network conditions. 3. A weighted ensembler that fuses edge and cloud inference results to improve overall accuracy.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/883099a5be7486c0821b7ffc4858fa9de1fb7c6f3487310e5eb913db9f04c63e_w640_q70.webp
  - **Simple LLM Summary:** This paper presents Hyperion, a cloud-device collaborative framework designed to enable low-latency inference on Ultra-HD video using off-the-shelf vision transformers. It tackles computational and transmission bottlenecks by selectively processing critical patches, dynamically adjusting transmission quality, and fusing results. Experiments show Hyperion improves frame processing rate by up to 1.61x and accuracy by up to 20.2% compared to baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Hyperion: Low-Latency Ultra-HD Video Analytics<br>Hyperion: 低延迟超高清视频分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Ultra-HD视频处理的计算与传输瓶颈<br>Computational & Transmission Bottleneck for Ultra-HD Video]
        C[主要方法/Method<br>云-端协作的Vision Transformer推理框架<br>Cloud-Device Collaborative ViT Inference Framework]
        D[关键结果/Results<br>处理率提升1.61倍，准确率提升20.2%<br>1.61x Faster Frame Rate, 20.2% Higher Accuracy]
    ```

- **[arXiv251229] Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers**
  - **tags:** [mlsys], [cluster infrastructure], [LSTM, Random Forest, MQTT, InfluxDB, Streamlit]
  - **authors:** Krishna Chaitanya Sunkara, Rambabu Konakanchi
  - **institution:** Oracle, Charles Schwab
  - **link:** https://arxiv.org/pdf/2512.21801
  - **contributions:** 1. Probabilistic LSTM forecasting validated within ±30-minute windows for coolant leaks, 2. 96.5% F1-score Random Forest detection for immediate leak identification, 3. Integrated smart IoT architecture design with MQTT streaming, InfluxDB storage, and Streamlit dashboards for energy-efficient data center operations.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/aa113d59b2dc6ec7a3bf00f9eebc8541689a6235867cf59ce376cdcfa30a2a5c_w640_q70.webp
  - **Simple LLM Summary:** The paper proposes a smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting and Random Forest classifiers for instant detection in liquid-cooled AI data centers. The system, tested on synthetic data, achieves 96.5% detection accuracy and 87% forecasting accuracy, potentially preventing significant energy waste through proactive maintenance.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Smart IoT-Based Leak Forecasting and Detection] --> B[核心问题/Problem: Coolant leaks cause energy loss in AI data centers]
        A --> C[主要方法/Method: LSTM for forecasting + Random Forest for detection with IoT sensors]
        A --> D[关键结果/Results: 96.5% detection accuracy, 87% forecasting accuracy, 1,500 kWh energy saved]
    ```

- **[arXiv251229] LIME:Accelerating Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices**
  - **tags:** [mlsys], [llm inference], [collaborative inference, pipeline parallelism, model offloading, memory adaptation, edge computing]
  - **authors:** Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu
  - **institution:** Shandong University
  - **link:** https://arxiv.org/pdf/2512.21835
  - **contributions:** 1. Proposes LIME, a collaborative system for lossless LLM inference across multiple memory-constrained edge devices under limited bandwidth. 2. Employs an interleaved pipeline parallelism with model offloading to dynamically balance computation and communication. 3. Introduces a fine-grained offline allocation scheduler and an online memory adaptation strategy to optimize resource usage and minimize inference latency.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/a4d2da6a7be206646ebc1b92d8a0053408a991ec073254f89b4182ecdc54fe1b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes LIME, a system that enables lossless, collaborative LLM inference on multiple memory-constrained edge devices by using interleaved pipeline parallelism and model offloading, along with offline scheduling and online memory adaptation. Experiments on four Nvidia Jetson devices with LLaMA3.3-70B show that LIME achieves significant speedups over baselines without accuracy loss.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[LIME: 协作式无损LLM推理 / Collaborative Lossless LLM Inference] --> Problem[边缘设备内存受限 / Memory-Constrained Edge Devices]
        Root --> Method[交织流水线并行与模型卸载 / Interleaved Pipeline Parallelism & Offloading]
        Root --> Results[实现无损加速 / Achieves Lossless Speedup]
    ```

- **[arXiv251229] Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models**
  - **tags:** [mlsys], [llm inference], [distributed inference, block placement, request routing, performance modeling, resource allocation]
  - **authors:** Tingyang Sun, Ting He, Bo Ji, Parimal Parag
  - **institution:** Pennsylvania State University, Virginia Tech, Indian Institute of Science
  - **link:** https://arxiv.org/pdf/2512.21884
  - **contributions:** 1. Developed experimentally validated performance models for distributed LLM inference under given block placement and request routing decisions. 2. Formulated the offline optimization problem as a MILP, proved its NP-hardness, and designed a polynomial-complexity algorithm with performance guarantees. 3. Adapted the offline algorithm for the online setting with the same performance guarantee under bounded load.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/25938e1be55cbd072ba066aea4bb0e492f8b8c2a83e48eaa7e09e800b8697383_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the resource allocation problem for geographically-distributed LLM inference, focusing on optimizing block placement and request routing. It proposes performance models, offline and online algorithms with theoretical guarantees, and a lightweight CPU-only simulator. The solution significantly reduces inference time compared to the state-of-the-art in diverse distributed settings.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models] --> B
        A --> C
        A --> D
        B[核心问题/Problem: 分布式LLM推理的资源分配优化/Optimizing resource allocation for distributed LLM inference]
        C[主要方法/Method: 性能建模与优化算法/Performance modeling and optimization algorithms]
        D[关键结果/Results: 显著降低推理时间/Substantially reduces inference time]
    ```

- **[arXiv251229] BLEST: Blazingly Efficient BFS using Tensor Cores**
  - **tags:** [mlsys], [gpu kernels], [BFS, Tensor Cores, SpMSpV, Graph Reordering, Kernel Fusion]
  - **authors:** Deniz Elbek, Kamer Kaya
  - **institution:** Sabanci University
  - **link:** https://arxiv.org/pdf/2512.21967
  - **contributions:** 1. Introduces Binarised Virtual Slice Sets (BVSS) for warp-level load balancing and eliminating frontier-oblivious work assignment in BFS., 2. Applies two complementary graph reordering strategies (compression-oriented and bandwidth-reducing) to improve memory efficiency and update locality., 3. Develops a batched SpMSpV multiplication pattern using bitwise Tensor Core tiles and combines kernel fusion with a lazy vertex update scheme to reduce synchronization and atomic overheads.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/da59a50541aea7cf054914628e80911f7ca77a9353af15a6a412588e726ca791_w640_q70.webp
  - **Simple LLM Summary:** The paper presents BLEST, a framework that accelerates Breadth-First Search (BFS) on GPUs by efficiently mapping the irregular computation onto dense-math Tensor Cores. The method reformulates the BFS pipeline using a bitmap-oriented structure, specialized load balancing, graph reordering, and kernel fusion. Experiments show that BLEST achieves significant speedups (3.58x to 4.9x) over state-of-the-art GPU-based BFS implementations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[BLEST: Blazingly Efficient BFS using Tensor Cores] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[如何将不规则图BFS映射到密集张量核心/Map irregular BFS to dense Tensor Cores]
        C --> C1[二值化虚拟切片集/Binarised Virtual Slice Sets (BVSS)]
        C --> C2[图重排序策略/Graph Reordering Strategies]
        C --> C3[批处理SpMSpV与核融合/Batched SpMSpV & Kernel Fusion]
        D --> D1[平均3.58-4.9倍加速/Average 3.58-4.9x Speedup]
    ```

- **[arXiv251229] Proceedings First Workshop on Adaptable Cloud Architectures**
  - **tags:** TBD
  - **authors:** Giuseppe De Palma, Saverio Giallorenzo
  - **institution:** TBD
  - **link:** https://arxiv.org/pdf/2512.22054

- **[arXiv251229] FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion**
  - **tags:** [mlsys], [communication & networking], [Mixture-of-Experts, expert parallelism, data shuffling, transformation-communication fusion, collective communication]
  - **authors:** Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang
  - **institution:** Tsinghua University, Infinigence AI, University of Southern California, Zhongguancun Academy, Shanghai Jiao Tong University
  - **link:** https://arxiv.org/pdf/2512.22036
  - **contributions:** 1. Identifies the root cause of inefficiency in MoE data shuffling as the misalignment between expert-major and device-major data layouts, requiring disaggregated transformation and communication. 2. Proposes FUSCO, a communication library that fuses data transformation and communication operations into a single, efficient pipeline to eliminate redundant data movement. 3. Introduces lightweight planning and load-balancing mechanisms to eliminate redundant communication and disperse traffic, further optimizing the shuffling process.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/7cf69e647d44d7f0b5d2cdef643280359c8d359bbdf2f836c065bb3b6fb214ae_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the performance bottleneck of distributed data shuffling in Mixture-of-Experts (MoE) model training and inference. It proposes FUSCO, a communication library that fuses data transformation and communication to align expert-major and device-major data layouts efficiently. Evaluations show FUSCO achieves significant speedups over existing libraries like NCCL and DeepEP, reducing both training and inference latency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[FUSCO: High-Performance Distributed Data Shuffling] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem: MoE专家并行中的数据混洗开销大/High overhead of data shuffling in MoE expert parallelism]
        Method[主要方法/Method: 通过融合数据转换与通信实现高效混洗/Efficient shuffling via transformation-communication fusion]
        Results[关键结果/Results: 相比NCCL和DeepEP实现显著加速/Significant speedups over NCCL and DeepEP]
    ```

- **[arXiv251229] Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View**
  - **tags:** [mlsys], [federated learning], [federated fine-tuning, connection failures, adaptive aggregation, data heterogeneity, convergence guarantee]
  - **authors:** Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang
  - **institution:** The affiliations include IEEE members, suggesting multiple institutions. Based on common patterns, likely institutions include The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen) and/or other Chinese universities/tech institutes, given authors like Tsung-Hui Chang and Tony Q. S. Quek are affiliated with such institutions.
  - **link:** https://arxiv.org/pdf/2512.22035
  - **contributions:** 1. Proposes FedAuto, a novel Federated Fine-Tuning framework that mitigates the combined effects of unreliable connections and data heterogeneity via adaptive aggregation, requiring no prior knowledge of network conditions. 2. Establishes a rigorous, per-round convergence guarantee for FedAuto that holds for each individual realization, removing common assumptions on failure probabilities or client selection. 3. Demonstrates through extensive experiments that FedAuto outperforms state-of-the-art baselines under diverse failure scenarios for both full and partial-parameter fine-tuning (e.g., LoRA).
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09b9295640a8e9a219a19de76effe76cb1ea0696845676f4a5d9a059161538fb_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the performance degradation of Federated Fine-Tuning (FFT) in real-world networks with unreliable connections and heterogeneous data. It proposes FedAuto, a framework that uses adaptive aggregation to handle these issues without prior network knowledge or infrastructure changes. Experiments show FedAuto consistently outperforms existing methods and provides stronger theoretical convergence guarantees.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[FFT性能受不可靠连接和数据异构性影响/FFT performance degraded by unreliable connections & data heterogeneity]
        C --> C1[FedAuto: 通过自适应聚合的FFT框架/FedAuto: FFT framework with adaptive aggregation]
        C --> C2[无需先验网络知识/No prior network knowledge needed]
        D --> D1[实验表现超越SOTA/Outperforms SOTA baselines]
        D --> D2[提供严格收敛保证/Provides rigorous convergence guarantee]
    ```

- **[arXiv251229] Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications**
  - **tags:** [mlsys], [agent system], [root cause analysis, service dependency graph, program dependence graph, LLM agent, cloud incident]
  - **authors:** Shengkun Cui, Rahul Krishna, Saurabh Jha, Ravishankar K. Iyer
  - **institution:** University of Illinois at Urbana-Champaign, IBM Research
  - **link:** https://arxiv.org/pdf/2512.22113
  - **contributions:** 1. PRAXIS, an agentic approach for cloud incident RCA with structured, LLM-driven graph reasoning and traversal over microservice and program dependency graphs. 2. An application of the hammock block program dependence graph for agentic RCA, leveraging its hierarchical structure for multi-granular code analysis. 3. A Code-Cloud-RCA Benchmark consisting of 30 real-world incident scenarios injected in a live Kubernetes environment.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62ebd8a01fd966235e0d8d40581cb8352024a391331fada8ea23868c2235ada9_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces PRAXIS, an orchestrator that uses an LLM-driven agent to traverse service dependency graphs and program dependence graphs to diagnose the root cause of code- and configuration-related cloud incidents. Compared to ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x, as demonstrated on a benchmark of 30 real-world incidents.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Agentic Structured Graph Traversal for Root Cause Analysis<br/>基于智能体结构化图遍历的云应用根因分析] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br/>High cost of unresolved cloud incidents; Need for effective root cause analysis]
        C[主要方法/Method<br/>PRAXIS: LLM-driven traversal over Service Dependency Graph and Program Dependence Graph]
        D[关键结果/Results<br/>3.1x higher RCA accuracy, 3.8x lower token consumption vs. ReAct baselines]
    ```


**cs.AI/cs.LG contains "reinforcement learning" total: 17**
- **[arXiv251229] CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation**
  - **tags:** [ai], [reinforcement learning], [dream-replay reinforcement learning, evolutionary algorithms, adaptive code generation]
  - **authors:** Santhosh Kumar Ravindran
  - **institution:** Microsoft Corporation
  - **link:** https://arxiv.org/pdf/2512.21351
  - **contributions:** 1. Introduces CosmoCore-Evo, an extension of CosmoCore that integrates evolutionary algorithms into the dream-replay reinforcement learning framework for code generation, 2. Proposes treating RL trajectories as "genomes" that undergo mutation and selection during nocturnal replay to enhance adaptability and novelty, 3. Develops enterprise-tuned fitness functions incorporating efficiency, compliance, and scalability metrics, and demonstrates improved performance on benchmarks with distribution shifts.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/318e081ebd83b7b451c47feed4db9ca1fa830f70f86844ea65dc8e8551ea3656_w640_q70.webp
  - **Simple LLM Summary:** CosmoCore-Evo enhances the affective dream-replay reinforcement learning framework by incorporating evolutionary algorithms to improve adaptability in code generation. It treats RL trajectories as genomes for mutation and selection, enabling agents to break free from trained patterns and adapt to changing environments like API updates. The method achieves higher novelty and faster adaptation compared to baselines, as validated on benchmarks including HumanEval variants and BigCodeBench.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[CosmoCore-Evo: Evolutionary Dream-Replay Reinforcement Learning for Adaptive Code Generation] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[LLM代码生成缺乏适应性，难以应对API变化/LLM code generation lacks adaptability to API changes]
        C --> C1[将RL轨迹视为基因组进行进化操作/Treat RL trajectories as genomes for evolutionary operations]
        C --> C2[在夜间回放阶段进行突变与选择/Mutation and selection during nocturnal replay]
        D --> D1[解决方案新颖性提升35%/35% higher novelty in solutions]
        D --> D2[适应速度加快25%/25% faster adaptation]
    ```

- **[arXiv251229] A Reinforcement Learning Approach to Synthetic Data Generation**
  - **tags:** [ai], [reinforcement learning], [synthetic data generation, reinforcement learning, proximal policy optimization, privacy, biomedical data]
  - **authors:** Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin
  - **institution:** Princeton University, Vanderbilt University Medical Center, Washington University in St. Louis
  - **link:** https://arxiv.org/pdf/2512.21395
  - **contributions:** 1. Reframes synthetic data generation (SDG) as a reinforcement learning problem, introducing a novel perspective. 2. Proposes RLSyn, a framework that models the data generator as a stochastic policy optimized via Proximal Policy Optimization with discriminator-derived rewards for stable, data-efficient training. 3. Demonstrates the effectiveness of the RL approach, showing it performs comparably to or better than GANs and diffusion models, especially in data-scarce regimes on biomedical datasets.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/75d9e0c3d2cba88654d16f9652042680f0037508065d6d94fba27208a6199969_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes RLSyn, a reinforcement learning framework for generating synthetic biomedical data by modeling the generator as a policy optimized with PPO. It shows that this approach achieves performance comparable to or better than GANs and diffusion models, particularly when training data is limited, offering a stable and data-efficient alternative for privacy-preserving data sharing.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Reinforcement Learning Approach to Synthetic Data Generation] --> B
        A --> C
        A --> D
        B[核心问题/Problem: State-of-the-art generative models need large datasets and complex training, limiting use in small-sample settings.]
        C[主要方法/Method: Reframe SDG as RL; introduce RLSyn (stochastic policy optimized via PPO with discriminator rewards).]
        D[关键结果/Results: RLSyn performs comparably to/better than GANs & diffusion models, especially on smaller datasets.]
    ```

- **[arXiv251229] A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning**
  - **tags:** [sys], [wireless networking], [Age of Information (AoI), reinforcement learning, freshness optimization, wireless networks, multi-agent systems]
  - **authors:** Alimu Alibotaiken, Suyang Wang, Oluwaseun T. Ajayi, Yu Cheng
  - **institution:** Illinois Institute of Technology, California State University, San Bernardino
  - **link:** https://arxiv.org/pdf/2512.21412
  - **contributions:** 1. Proposes a novel taxonomy for Age of Information (AoI) and its variants, categorizing them into native, function-based, and application-oriented families to clarify freshness modeling for B5G/6G systems. 2. Introduces a policy-centric taxonomy for reinforcement learning in freshness-aware networks, consisting of update-control RL, medium-access RL, risk-sensitive RL, and multi-agent RL. 3. Synthesizes recent RL-driven freshness control progress and highlights open challenges like delayed decision processes and cross-layer design to establish a unified foundation for learning-based freshness optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b58e6fe193d4299ab0beca4eb949d8b13e21e8198c223c3dd6c0ca64896bbf7d_w640_q70.webp
  - **Simple LLM Summary:** This survey addresses the gap between classical Age of Information (AoI) studies and broad reinforcement learning (RL) discussions in wireless networks by examining RL specifically for freshness optimization. It organizes AoI variants and introduces a policy-centric RL taxonomy to provide a coherent framework for freshness-aware decision-making in next-generation wireless systems. The paper aims to establish a unified foundation for learning-based freshness control and highlights key open challenges for future research.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[A Survey of Freshness-Aware Wireless Networking with Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[现有综述的不足: 经典AoI与泛化RL研究分离 / Gap: Classical AoI vs. Broad RL]
        C --> C1[提出以AoI为中心的RL综述框架 / Propose AoI-centric RL Survey Framework]
        C --> C2[构建AoI变体分类与策略中心分类法 / Build AoI Variant & Policy-Centric Taxonomies]
        D --> D1[为B5G/6G建立学习式新鲜度优化的统一基础 / Establish Unified Foundation for Learning-based Freshness Optimization]
        D --> D2[识别开放挑战: 延迟决策、随机性、跨层设计 / Identify Open Challenges: Delayed Decisions, Stochasticity, Cross-layer]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO**
  - **tags:** [cv], [diffusion models], [GRPO, mode collapse, diversity-aware reward, spectral clustering, structure-aware regularization]
  - **authors:** Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji
  - **institution:** Tsinghua University, Kuaishou Technology (Kling Team), Sun Yat-sen University
  - **link:** https://arxiv.org/pdf/2512.21514
  - **contributions:** 1. Identifies and analyzes the mode collapse problem in GRPO-based image generation from both reward modeling and generation dynamics perspectives. 2. Proposes a distributional creativity bonus reward based on semantic grouping via spectral clustering to encourage novel visual modes. 3. Introduces a structure-aware regularization that applies stronger constraints during early-stage denoising to preserve diversity without sacrificing quality optimization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/862e58c2beed3d5383235af01560a2dc06bc384250083e4027ddff5a3aa32368_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the mode collapse problem in GRPO-based image generation, where models produce homogenized outputs. The proposed DiverseGRPO method introduces a diversity-aware reward based on semantic clustering and a structure-aware regularization to preserve generation diversity. Experiments show the method significantly improves semantic diversity while maintaining image quality, establishing a better quality-diversity trade-off.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DiverseGRPO: Mitigating Mode Collapse] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[GRPO导致模式崩溃/GRPO causes mode collapse]
        B1 --> B2[缺乏视觉多样性/Lacks visual diversity]
        C --> C1[奖励层面: 分布创造力奖励/Reward Level: Distributional Creativity Bonus]
        C --> C2[生成层面: 结构感知正则化/Generation Level: Structure-Aware Regularization]
        C1 --> C3[基于语义分组的谱聚类/Spectral Clustering for Semantic Grouping]
        D --> D1[语义多样性提升13%-18%/13%-18% Semantic Diversity Improvement]
        D --> D2[建立新的帕累托前沿/Establishes New Pareto Frontier]
    ```

- **[arXiv251229] Generative Actor Critic**
  - **tags:** [ai], [reinforcement learning], [generative modeling, policy evaluation, latent plan, offline-to-online, actor-critic]
  - **authors:** Aoyang Qin, Deqian Kong, Wei Wang, Ying Nian Wu, Song-Chun Zhu, Sirui Xie
  - **institution:** Tsinghua University, Beijing Institute of General Artificial Intelligence (BIGAI), UCLA, Peking University
  - **link:** https://arxiv.org/pdf/2512.21527
  - **code:** github.com/qayqaq/Generative-Actor-Critic
  - **contributions:** 1. Proposes the Generative Actor Critic (GAC) framework that reframes policy evaluation as learning a generative model of the joint distribution over trajectories and returns, decoupling decision-making. 2. Introduces a specific instantiation using a latent variable model with continuous latent plan vectors and novel inference strategies for exploitation and exploration. 3. Demonstrates strong offline performance and significantly enhanced offline-to-online improvement on benchmarks, even without step-wise rewards.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/62b697a3a1c4a1b559c19af7d65fd19d2eed0bb097eccecdd9008a509a0456c0_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces Generative Actor Critic (GAC), a novel reinforcement learning framework that decouples sequential decision-making by learning a generative model of trajectories and returns and then performing inference on it. It shows strong performance in offline learning and significantly improves when fine-tuned online, even in sparse-reward environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Generative Actor Critic] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统RL在线改进离线预训练模型存在挑战/Challenges in refining offline models online]
        C --> C1[将策略评估重构为学习轨迹与回报的联合生成模型/Reframe policy evaluation as learning p(τ, y)]
        C --> C2[将策略改进重构为在模型上进行多样化推理/Reframe policy improvement as versatile inference]
        C --> C3[基于潜变量模型的实例化与新颖推理策略/Instantiation with latent plans & novel inference]
        D --> D1[离线性能强大/Strong offline performance]
        D --> D2[离线到在线改进显著/Enhanced offline-to-online improvement]
    ```

- **[arXiv251229] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model**
  - **tags:** [mlsys], [llm inference], [adaptive length penalty, reinforcement learning, constrained optimization, Lagrangian primal-dual, reasoning efficiency]
  - **authors:** Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo
  - **institution:** Peking University, Harbin Institute of Technology, Shenzhen
  - **link:** https://arxiv.org/pdf/2512.21540
  - **contributions:** 1. Proposes Leash, a reinforcement learning framework that formulates length control as a constrained optimization problem and uses a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. 2. Introduces an adaptive mechanism that intensifies the penalty when generations exceed the target length and relaxes it when they are shorter, guiding models toward concise reasoning without sacrificing performance. 3. Demonstrates experimentally that Leash reduces average reasoning length by 60% across diverse tasks while maintaining competitive performance, offering a practical paradigm for efficient LLMs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8ec5b3e2930213678e6d04b060a50d89faaaacded209387c96170a775f9db310_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the problem of LLMs producing overly long reasoning traces, which increases computational cost. It proposes Leash, an adaptive reinforcement learning framework that dynamically adjusts length penalties using a Lagrangian method to balance conciseness and accuracy. Experiments show it reduces reasoning length by 60% while maintaining performance, providing an effective approach for efficient LLM reasoning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[LEASH: Adaptive Length Penalty and Reward Shaping] --> B[核心问题/Problem: LLMs生成过长推理链，计算成本高/Fixed penalties fail to adapt, leading to suboptimal accuracy-conciseness trade-offs]
        A --> C[主要方法/Method: 自适应强化学习框架，使用拉格朗日对偶方法动态调整惩罚系数/Adaptive RL framework with Lagrangian primal-dual for dynamic penalty adjustment]
        A --> D[关键结果/Results: 平均推理长度减少60%，性能保持竞争力/Average reasoning length reduced by 60% while maintaining competitive performance across tasks]
    ```

- **[arXiv251229] Towards Learning-Based Formula 1 Race Strategies**
  - **tags:** [ai], [reinforcement learning], [mixed-integer nonlinear programming, reinforcement learning, energy allocation, tire wear, pit stop]
  - **authors:** Giona Fieni, Joschua Wüthrich, Marc-Philippe Neumann, Mohammad M. Moradi, Christopher H. Onder
  - **institution:** Institute for Dynamic Systems and Control, ETH Zürich
  - **link:** https://arxiv.org/pdf/2512.21570
  - **contributions:** 1. Proposes a comprehensive race scenario model for Formula 1 that jointly accounts for energy allocation, tire wear, and pit stop timing using lap time maps and a dynamic tire wear model. 2. Develops and solves the strategy optimization problem using a Mixed-Integer Nonlinear Program (MINLP) to handle the integer decisions of pit stops. 3. Implements a complementary Reinforcement Learning (RL) framework trained on the same scenario, providing a fast-inference solution suitable for real-time human decision support during races.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/63fe52e5bd2040f57f04a5b1222af84097ec60d1ba7e39ef15695eb7f5b3c59f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes two complementary frameworks to optimize Formula 1 race strategies by jointly managing energy, tire wear, and pit stops. It uses a Mixed-Integer Nonlinear Program for optimal offline planning and a Reinforcement Learning agent for fast, real-time inference. The RL agent achieves suboptimality of only about 5 seconds in a 1.5-hour race, demonstrating its potential for real-time strategic assistance.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Towards Learning-Based Formula 1 Race Strategies<br/>基于学习的F1比赛策略"] --> Problem["核心问题/Problem<br/>Optimize F1 race strategy (energy, tires, pit stops)<br/>优化F1比赛策略(能量、轮胎、进站)"]
        Root --> Method["主要方法/Method<br/>Two complementary frameworks<br/>两个互补框架"]
        Root --> Results["关键结果/Results<br/>RL agent ~5s suboptimal in 1.5h race<br/>RL智能体在1.5小时比赛中表现接近最优(约5秒差距)"]
        Method --> M1["MINLP for optimal solution<br/>混合整数非线性规划求最优解"]
        Method --> M2["Reinforcement Learning for fast inference<br/>强化学习用于快速推理"]
    ```

- **[arXiv251229] Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations**
  - **tags:** [ai], [imitation learning], [behavior cloning, latent representation, self-supervised learning, sample efficiency]
  - **authors:** Xin Liu, Haoran Li, Dongbin Zhao
  - **institution:** Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences
  - **link:** https://arxiv.org/pdf/2512.21586
  - **contributions:** 1. Proposes a novel, unsupervised framework (BCV-LR) for imitation learning from videos (ILV) that learns latent actions from visual inputs. 2. Introduces an iterative policy improvement loop that aligns pre-trained latent actions with the real action space online, enabling highly sample-efficient learning. 3. Demonstrates state-of-the-art sample efficiency, outperforming existing ILV and RL methods on a wide range of visual control tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1c96d71be701998ebf55ef6ed2a0c0a001a306b44f3555239559ced527b17559_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes BCV-LR, a framework for learning policies from videos without action labels. It uses self-supervised learning to extract latent actions and an iterative alignment process for sample-efficient behavior cloning. The method achieves expert-level performance on many tasks with minimal interaction, showing videos can be highly effective supervision for policy learning.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Videos are Sample-Efficient Supervisions: Behavior Cloning from Videos via Latent Representations] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1["从视频模仿学习的挑战 / Challenges of Imitation Learning from Videos"]
        C --> C1["BCV-LR框架 / BCV-LR Framework"]
        C1 --> C2["自监督提取潜在特征 / Self-supervised Latent Feature Extraction"]
        C1 --> C3["基于动态的潜在动作预测 / Dynamics-based Latent Action Prediction"]
        C1 --> C4["在线对齐与迭代策略改进 / Online Alignment & Iterative Policy Improvement"]
        D --> D1["高样本效率 / High Sample Efficiency"]
        D --> D2["超越SOTA方法 / Outperforms SOTA Baselines"]
        D --> D3["首次证明视频可作为高效监督 / First to Show Videos as Efficient Supervision"]
    ```

- **[arXiv251229] Rethinking Sample Polarity in Reinforcement Learning with Verifiable Rewards**
  - **tags:** [ai], [reinforcement learning], [RLVR, sample polarity, advantage shaping, policy optimization, reasoning models]
  - **authors:** Xinyu Tang, Yuliang Zhan, Zhixun Li, Wayne Xin Zhao, Zhenduo Zhang, Zujie Wen, Zhiqiang Zhang, Jun Zhou
  - **institution:** Renmin University of China, The Chinese University of Hong Kong, Ant Group
  - **link:** https://arxiv.org/pdf/2512.21625
  - **contributions:** 1. A systematic investigation into the distinct roles of positive and negative samples (sample polarity) in RLVR training dynamics, showing positive samples sharpen existing patterns while negative samples encourage exploration. 2. An exploration of how adjusting advantage values for different sample polarities at both the sample and token levels affects training. 3. The proposal of A3PO, an Adaptive and Asymmetric token-level Advantage shaping method for Policy Optimization, which precisely allocates advantage signals to key tokens.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/66a5d8d013ee86ee35c80048dbd4d2b03bd023a52b180e92f678fb36aa1f6018_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates the distinct roles of positive and negative samples in Reinforcement Learning with Verifiable Rewards (RLVR) for training large reasoning models. It finds positive samples refine correct patterns while negative samples promote exploration, and proposes a new method called A3PO for adaptive, asymmetric token-level advantage shaping. Experiments on five reasoning benchmarks demonstrate the effectiveness of the proposed approach.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Rethinking Sample Polarity in RLVR] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题/Problem] --> P1[RLVR中正负样本的角色?/Roles of +/- samples in RLVR?]
        Method[主要方法/Method] --> M1[分析样本极性/Analyze Sample Polarity]
        Method --> M2[提出A3PO方法/Propose A3PO Method]
        Results[关键结果/Results] --> R1[正样本锐化模式/Positive samples sharpen patterns]
        Results --> R2[负样本鼓励探索/Negative samples encourage exploration]
        Results --> R3[A3PO有效/A3PO is effective]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities**
  - **tags:** [sys], [communication & networking], [multiconnectivity, SAGIN, resource allocation, agentic reinforcement learning, heterogeneous networks]
  - **authors:** Abd Ullah Khan, Adnan Shahid, Haejoon Jung, Hyundong Shin
  - **institution:** Kyung Hee University, Ghent University
  - **link:** https://arxiv.org/pdf/2512.21717
  - **contributions:** 1. Provides a comprehensive review of current developments and key implementation challenges in SAGIN-enabled multiconnectivity. 2. Highlights the transformative potential of AI-driven approaches, particularly agentic reinforcement learning, for resource optimization in heterogeneous SAGIN environments. 3. Presents a case study demonstrating that learning-based methods can effectively enhance network performance (latency, capacity) with a moderate trade-off in power consumption.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/31a130dffac74abb8ad0616817d555bf857333050b690554853596eda30c2fa7_w640_q70.webp
  - **Simple LLM Summary:** This paper reviews the challenges of implementing multiconnectivity in heterogeneous Space-Air-Ground Integrated Networks (SAGIN) and proposes AI-driven solutions, specifically agentic reinforcement learning, for optimal resource allocation. A case study shows these methods significantly improve latency and capacity, albeit with a moderate increase in power consumption as a trade-off. The work concludes by outlining open research problems for realizing efficient SAGIN-enabled multiconnectivity.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem: Heterogeneous SAGIN complicates multiconnectivity and resource allocation"]
        Method["主要方法/Method: Use AI-driven approaches, specifically agentic reinforcement learning"]
        Results["关键结果/Results: Enhanced network performance (latency, capacity) with moderate power trade-off"]
    ```

- **[arXiv251229] Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection**
  - **tags:** [ai], [reinforcement learning], [Quantum Reinforcement Learning, Asynchronous Advantage Actor-Critic (A3C), Variational Quantum Circuits (VQCs), Time-series Dynamic Clustering, ETF Stock Selection]
  - **authors:** Yen-Ku Liu, Yun-Cheng Tsai, Samuel Yen-Chi Chen
  - **institution:** National Taiwan Normal University, Wells Fargo Bank
  - **link:** https://arxiv.org/pdf/2512.21819
  - **contributions:** 1. Proposes Q-A3C2, a novel quantum-enhanced A3C framework integrated with time-series dynamic clustering for adaptive financial decision-making. 2. Embeds Variational Quantum Circuits (VQCs) into the policy network to enhance nonlinear feature representation and mitigate overfitting in high-dimensional financial data. 3. Demonstrates superior performance through experiments on S&P 500 constituents, achieving significantly higher cumulative returns compared to benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/24772abde7bff15c10d7b6e86ca20b5510d1c2c86dce26245e814a93d8ce5afd_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Q-A3C2, a quantum reinforcement learning framework that combines a quantum-enhanced A3C algorithm with time-series dynamic clustering to adaptively select ETF stocks. The method uses Variational Quantum Circuits to improve feature learning and dynamic clustering to capture evolving market regimes. Experimental results on S&P 500 data show Q-A3C2 achieves a 17.09% cumulative return, outperforming the benchmark's 7.09%, demonstrating its effectiveness in dynamic financial environments.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Q-A3C2: Quantum Reinforcement Learning with Time-Series Dynamic Clustering for Adaptive ETF Stock Selection] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[传统方法问题/Traditional Methods' Issues]
        B1 --> B11[高维特征与过拟合/High-dimensional Features & Overfitting]
        B1 --> B12[静态聚类无法适应市场变化/Static Clustering Fails to Adapt]
        C --> C1[量子增强A3C/Quantum-enhanced A3C]
        C1 --> C11[策略网络嵌入VQC/Embed VQC in Policy Network]
        C --> C2[集成时序动态聚类/Integrate Time-series Dynamic Clustering]
        D --> D1[累计收益17.09%/Cumulative Return 17.09%]
        D --> D2[超越基准7.09%/Outperforms Benchmark 7.09%]
    ```

- **[arXiv251229] A Comedy of Estimators: On KL Regularization in RL Training of LLMs**
  - **tags:** [ai], [reinforcement learning], [KL divergence, policy gradient, on-policy sampling, off-policy training, gradient bias]
  - **authors:** Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, Nikolay Malkin, Moksh Jain, Siddarth Venkatraman, Aaron Courville
  - **institution:** Mila – Quebec AI Institute, Université de Montréal, McGill University, LLNL, University of Edinburgh, CIFAR
  - **link:** https://arxiv.org/pdf/2512.21852
  - **contributions:** 1. Systematic analysis of KL divergence estimator configurations in RL for LLMs, revealing how design choices introduce gradient bias. 2. Empirical demonstration that estimator configurations with unbiased gradients lead to better and more stable performance on both in-domain and out-of-domain tasks. 3. Investigation showing KL regularization can stabilize off-policy RL training in asynchronous setups.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/96999f081bc421143202d98f560b5d13a6fb0c09613b8c160b121158bce3811a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes the use of various estimators for the KL divergence regularization term in RL fine-tuning of LLMs, finding that common practices introduce biased gradients. Through experiments on models like Qwen2.5-7B, the study shows that using estimator configurations with unbiased gradients improves training stability and downstream task performance. The work also finds that KL regularization helps stabilize off-policy RL training.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["A Comedy of Estimators: On KL Regularization in RL Training of LLMs<br>论文标题"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>KL正则化估计器配置缺乏系统研究，梯度存在偏差"] --> P1["实践问题/Practical Issue<br>广泛使用但实现与目标不一致"]
        Problem --> P2["理论问题/Theoretical Issue<br>梯度偏差影响训练稳定性"]
        Method["主要方法/Method<br>分析梯度偏差并进行实证验证"] --> M1["分析/Analysis<br>研究多种估计器配置的梯度"]
        Method --> M2["实验/Experiments<br>RL微调多个LLM并评估性能"]
        Results["关键结果/Results<br>无偏梯度配置带来更好性能"] --> R1["在线策略/On-Policy<br>无偏梯度配置提升稳定性和性能"]
        Results --> R2["离线策略/Off-Policy<br>KL正则化有助于稳定异步训练"]
    ```

- **[arXiv251229] SWE-RM: Execution-free Feedback For Software Engineering Agents**
  - **tags:** [se], [software engineering agents], [reward model, test-time scaling, reinforcement learning, mixture-of-experts, SWE-Bench]
  - **authors:** KaShun Shum, Binyuan Hui, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, Junxian He
  - **institution:** The Hong Kong University of Science and Technology, Alibaba Group (Qwen Team)
  - **link:** https://arxiv.org/pdf/2512.21919
  - **contributions:** 1. Identified that high TTS performance does not guarantee effective RL training, and introduced classification accuracy and calibration as crucial metrics for robust reward models. 2. Conducted comprehensive experiments to analyze factors (data scale, policy mixtures, data source) impacting reward model training for SWE agents. 3. Proposed SWE-RM, a large-scale mixture-of-experts reward model that significantly improves agent performance on both TTS and RL, achieving new SOTA on SWE-Bench Verified.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/dcb1e3e885f771ebf5ee27ef70da96ceb4c030de77fdee247afd5d854761a72f_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the limitations of execution-based feedback for software engineering agents by proposing an execution-free reward model. It introduces SWE-RM, a robust reward model trained with insights from controlled experiments, which substantially improves agent performance on both test-time scaling and reinforcement learning, setting a new state-of-the-art on the SWE-Bench benchmark.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["SWE-RM: Execution-free Feedback For Software Engineering Agents"] --> Problem["核心问题/Problem"]
        Root --> Method["主要方法/Method"]
        Root --> Results["关键结果/Results"]
        Problem --> P1["执行反馈的局限性/Limitations of Execution-based Feedback"]
        Problem --> P2["无执行反馈未被充分探索/Execution-free Feedback Underexplored"]
        Method --> M1["识别RL关键指标/Identify Key RL Metrics (Accuracy, Calibration)"]
        Method --> M2["可控实验分析/Controlled Experiments on Training Factors"]
        Method --> M3["提出SWE-RM模型/Propose SWE-RM (MoE Reward Model)"]
        Results --> R1["提升TTS性能/Improves TTS Performance (e.g., Qwen3-Coder-Max to 74.6%)"]
        Results --> R2["提升RL性能/Improves RL Performance (+3 points)"]
        Results --> R3["开源模型SOTA/New SOTA Among Open-Source Models"]
    ```

- **[arXiv251229] Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning**
  - **tags:** [mlsys], [memory & caching], [forward-backward MDP, multi-objective reinforcement learning, orthogonal multipoint multicast, wireless caching, latency optimization]
  - **authors:** Mohsen Amidzadeh
  - **institution:** Aalto University
  - **link:** https://arxiv.org/pdf/2512.21954
  - **contributions:** 1. Introduces a novel forward-backward Markov decision process (FB-MDP) model that captures both the forward dynamics of user preferences and the backward dynamics of latency in a cache-aided multicast network. 2. Proposes a forward-backward multi-objective reinforcement learning (FB-MORL) algorithm to optimize for expected latency, outage probability, and resource consumption simultaneously. 3. Demonstrates through simulation that the proposed FB-MORL algorithm can find a promising dynamic cache policy for latency-optimal streaming.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5e067ef983249e0d5eda55e0e5e41b6159895affdd536e8f8f4b116a2dac1058_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the problem of optimizing streaming latency in a cellular network with cache-enabled base stations using multicast. The authors propose a novel forward-backward reinforcement learning framework that models the network's temporal dynamics as a multi-objective Markov decision process. Simulation results show their method is effective in finding a dynamic cache policy that reduces latency.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Latency-Optimal Cache-aided Multicast Streaming via Forward-Backward Reinforcement Learning"] --> Problem["核心问题/Problem: Optimizing latency in cache-aided cellular multicast networks"]
        Root --> Method["主要方法/Method: Forward-Backward MDP modeling and FB-MORL algorithm"]
        Root --> Results["关键结果/Results: Proposed algorithm finds promising dynamic cache policy"]
    ```

- **[arXiv251229] Meta-Learning-Based Handover Management in NextG O-RAN**
  - **tags:** [sys], [communication & networking], [Conditional Handovers, O-RAN, Meta-Learning, Mobility Management, xApp]
  - **authors:** Michail Kalntis, George Iosifidis, José Suárez-Varela, Andra Lutu, Fernando A. Kuipers
  - **institution:** Delft University of Technology, Telefónica Research
  - **link:** https://arxiv.org/pdf/2512.22022
  - **contributions:** 1. Introduces CONTRA, the first framework to jointly optimize Traditional and Conditional Handovers within the O-RAN architecture. 2. Proposes a practical meta-learning algorithm for adaptive, on-the-fly handover type selection, guaranteeing universal no-regret performance. 3. Provides and analyzes unique, countrywide mobility management datasets from a top-tier mobile network operator, offering fresh insights into handover trade-offs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d76dc23b355711f7c28f6efbb425c914a47fa4ebefd3807c4f00b61b58aedb3e_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitations of traditional and conditional handovers in mobile networks by proposing CONTRA, a meta-learning-based framework for O-RAN that dynamically selects and optimizes handover types. It is designed as a near-real-time xApp and is evaluated using real-world datasets. The results show that CONTRA improves user throughput and reduces switching costs, outperforming standard and RL-based baselines.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Meta-Learning-Based Handover Management in NextG O-RAN] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统切换延迟与失败/Traditional HO delays & failures]
        B --> B2[切换类型间的权衡/Trade-offs between HO types]
        C --> C1[CONTRA框架: 联合优化THO与CHO/CONTRA: Jointly optimizes THOs & CHOs]
        C --> C2[元学习算法动态选择/Meta-learning for dynamic selection]
        C --> C3[O-RAN xApp部署/O-RAN xApp deployment]
        D --> D1[提升用户吞吐量/Improves user throughput]
        D --> D2[降低切换成本/Reduces HO switching costs]
        D --> D3[优于3GPP与RL基线/Outperforms 3GPP & RL baselines]
    ```


**cs.AI/cs.LG contains "accelerate" total: 19**
- **[arXiv251229] Satellite Cybersecurity Across Orbital Altitudes: Analyzing Ground-Based Threats to LEO, MEO, and GEO**
  - **tags:** [sec], [satellite cybersecurity], [Telemetry, Tracking, and Command (TT&C), encryption weaknesses, radio-frequency (RF) links]
  - **authors:** Mark Ballard, Guanqun Song, Ting Zhu
  - **institution:** The Ohio State University
  - **link:** https://arxiv.org/pdf/2512.21367
  - **contributions:** 1. Presents a comparative analysis of satellite cybersecurity threats across LEO, MEO, and GEO orbital regimes, linking orbital altitude to attack feasibility and impact. 2. Synthesizes data from 60 publicly documented security incidents to characterize distinct threat profiles for different orbits (e.g., GEO uplink exposure vs. LEO hardware constraints). 3. Bridges the gap between cybersecurity and space sustainability, arguing that unmitigated cyber vulnerabilities accelerate hardware obsolescence and debris accumulation.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/4da0532aaeff7ad43c2dda46bb5cd140bdaf45dbb5cc4ea6d38bb3da30c3ce9a_w640_q70.webp
  - **Simple LLM Summary:** This paper analyzes ground-based cybersecurity threats to satellites in different orbital altitudes (LEO, MEO, GEO). By synthesizing data from 60 security incidents and analyzing vulnerability proxies like TT&C anomalies and encryption, it characterizes how altitude dictates distinct threat profiles and concludes that weak encryption and command path irregularities are the most consistent predictors of adversarial success across all orbits.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Satellite Cybersecurity Across Orbital Altitudes] --> B(核心问题/Problem)
    A --> C(主要方法/Method)
    A --> D(关键结果/Results)
    B --> B1[轨道高度如何影响卫星网络安全/How orbital altitude dictates satellite cybersecurity]
    C --> C1[分析60起安全事件与漏洞代理/Analyze 60 security incidents & vulnerability proxies]
    D --> D1[不同轨道有独特的威胁特征/Distinct threat profiles per orbit]
    D --> D2[弱加密和指令异常是主要预测因子/Weak encryption & command irregularities are key predictors]
    ```

- **[arXiv251229] dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning**
  - **tags:** [mlsys], [diffusion models], [masked diffusion language models, reinforcement learning, parallel decoding, on-policy optimization, unmasking planner]
  - **authors:** Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu
  - **institution:** University of Washington, University of California, Berkeley
  - **link:** https://arxiv.org/pdf/2512.21446
  - **contributions:** 1. Proposes dUltra, an on-policy RL framework (GRPO-based) for learning efficient unmasking strategies in MDLMs. 2. Introduces a joint optimization scheme for the base diffusion model and a new unmasking planner head using a composite reward. 3. Demonstrates improved accuracy-efficiency trade-off over heuristic and distillation baselines in reasoning and code generation tasks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/f5f1e67e2dde4b6b9e98e4e3c5574326f0e2d63114afe47049e17c2ae04bb41b_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the slow sampling speed of masked diffusion language models (MDLMs) by proposing dUltra, a reinforcement learning framework that learns an optimal strategy for parallel token unmasking. The method jointly optimizes the diffusion model and a planner head using rewards for correctness, distillation, and step count. The results show dUltra achieves a better trade-off between accuracy and efficiency than existing methods, advancing towards "diffusion supremacy" over autoregressive models.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[MDLMs解码慢，速度优势有限/MDLMs decode slowly, limiting speed advantage]
        C --> C1[基于GRPO的在线强化学习框架/On-policy RL framework based on GRPO]
        C --> C2[联合优化扩散模型与解掩码规划器/Jointly optimize diffusion model & unmasking planner]
        D --> D1[提升精度-效率权衡/Improves accuracy-efficiency trade-off]
        D --> D2[迈向"扩散霸权"/Moving towards "diffusion supremacy"]
    ```

- **[arXiv251229] Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism**
  - **tags:** [cv], [object detection], [Ground Penetrating Radar (GPR), Multi-modal Chain Feature Fusion (MCFF), Global Attention Mechanism (GAM), DCGAN, transfer learning]
  - **authors:** Haotian Lv, Yuhui Zhang, Jiangbo Dai, Hanli Wu, Jiaji Wang, Dawei Wang
  - **institution:** Harbin Institute of Technology
  - **link:** https://arxiv.org/pdf/2512.21452
  - **contributions:** 1. Proposed a DCGAN-based data augmentation strategy to synthesize high-fidelity GPR images, mitigating data scarcity. 2. Designed a novel Multi-modal Chain and Global Attention Network (MCGA-Net) integrating Multi-modal Chain Feature Fusion (MCFF) and a Global Attention Mechanism (GAM) for enhanced defect representation. 3. Utilized MS COCO transfer learning to fine-tune the backbone network, accelerating convergence and improving model generalization.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/d4debe9b33028e70ed06ab5d1f340e5cb76dcb8d09f7adf0d8195a2422c90668_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the subjective and inefficient interpretation of Ground Penetrating Radar (GPR) images for road defect detection by proposing a comprehensive framework. The method combines DCGAN-based data augmentation, a novel MCGA-Net architecture with feature fusion and attention mechanisms, and transfer learning. The proposed model achieves high precision, recall, and robustness, establishing a new paradigm for automated GPR-based defect detection.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Intelligent recognition of GPR road hidden defect images <br/> GPR道路隐蔽病害图像智能识别") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
    
        Problem --> P1("Subjective & inefficient GPR interpretation <br/> GPR图像解释主观且低效")
        Problem --> P2("Data scarcity <br/> 数据稀缺")
    
        Method --> M1("DCGAN-based Data Augmentation <br/> 基于DCGAN的数据增强")
        Method --> M2("MCGA-Net (MCFF + GAM) <br/> MCGA-Net网络")
        Method --> M3("MS COCO Transfer Learning <br/> MS COCO迁移学习")
    
        Results --> R1("High Performance (Precision 92.8%, mAP@50 95.9%) <br/> 高性能")
        Results --> R2("Robust to noise & weak signals <br/> 对噪声和弱信号鲁棒")
        Results --> R3("New paradigm for automated detection <br/> 自动化检测新范式")
    ```

- **[arXiv251229] GoldenFuzz: Generative Golden Reference Hardware Fuzzing**
  - **tags:** [sec], [hardware security verification], [hardware fuzzing, golden reference model, RISC-V, test case refinement, vulnerability discovery]
  - **authors:** Lichao Wu, Mohamadreza Rostami, Huimin Li, Nikhilesh Singh, Ahmad-Reza Sadeghi
  - **institution:** Technical University of Darmstadt
  - **link:** https://arxiv.org/pdf/2512.21524
  - **contributions:** 1. Introduces a novel two-stage hardware fuzzing framework that decouples test refinement from coverage exploration using a fast Golden Reference Model (GRM) as a "digital twin". 2. Proposes a method to iteratively construct test cases by concatenating instruction blocks, balancing inter- and intra-instruction quality, and uses a feedback mechanism from high- and low-coverage samples. 3. Demonstrates superior performance over existing fuzzers on RISC-V processors, discovering new severe vulnerabilities and achieving higher coverage with lower computational overhead.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/09394f35e843baddb3a3fd346211157d9ffa5c355bc0197928c36b50febc37bf_w640_q70.webp
  - **Simple LLM Summary:** This paper presents GoldenFuzz, a hardware fuzzing framework that uses a fast Golden Reference Model to refine test cases efficiently before exploring the actual device. It employs a feedback-driven mechanism for instruction block selection to enhance state exploration. The evaluation shows GoldenFuzz achieves higher coverage with less overhead and discovers new severe vulnerabilities in RISC-V processors.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[GoldenFuzz: Generative Golden Reference Hardware Fuzzing] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[硬件模糊测试存在语义感知有限、测试低效、计算开销大的问题/Hardware fuzzing suffers from limited semantic awareness, inefficiency, and high overhead]
        C --> C1[使用快速黄金参考模型(GRM)作为数字孪生进行两阶段模糊测试/Two-stage fuzzing using a fast Golden Reference Model (GRM) as a digital twin]
        C --> C2[通过连接指令块和反馈机制构建测试用例/Constructing test cases via instruction block concatenation and feedback]
        D --> D1[在RISC-V处理器上实现最高覆盖率和最小开销/Achieves highest coverage with minimal overhead on RISC-V processors]
        D --> D2[发现新的高危漏洞/Uncovers new high-severity vulnerabilities]
    ```

- **[arXiv251229] AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification**
  - **tags:** [ai], [bioinformatics], [adaptive gating mechanism, contrastive learning, transfer learning]
  - **authors:** Xinru Wen, Weizhong Lin, Xuan Xiao
  - **institution:** JCI (inferred from email domain `jci.edu.cn`)
  - **link:** https://arxiv.org/pdf/2512.21544
  - **contributions:** 1. Proposes a two-stage deep learning framework (AVP-Fusion) for antiviral peptide identification and subclass prediction. 2. Introduces an Adaptive Gating Mechanism to dynamically fuse local (CNN) and global (BiLSTM) sequence features. 3. Employs a contrastive learning strategy with OHEM and BLOSUM62-based data augmentation to sharpen decision boundaries and handle hard samples.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/b72c58b1c8ae5a53950bfc6d9e8fcca6dc27fc849f514d47d4a2cdff795cb10b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes AVP-Fusion, a two-stage deep learning framework that integrates adaptive feature fusion and contrastive learning for identifying antiviral peptides (AVPs). The method dynamically fuses multi-modal sequence features and uses contrastive learning to improve classification, achieving state-of-the-art accuracy and enabling precise prediction of antiviral activity against specific viral families.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[AVP-Fusion: 抗病毒肽识别 / Antiviral Peptide Identification] --> Problem
        Root --> Method
        Root --> Results
        Problem[核心问题 / Problem] --> P1[现有方法难以捕捉复杂序列依赖 / Current methods struggle with sequence dependencies]
        Problem --> P2[难以处理模糊样本 / Hard to handle ambiguous samples]
        Method[主要方法 / Method] --> M1[构建全景特征空间 / Construct panoramic feature space]
        Method --> M2[自适应门控机制融合特征 / Adaptive Gating Mechanism for feature fusion]
        Method --> M3[对比学习与数据增强 / Contrastive learning & data augmentation]
        Results[关键结果 / Results] --> R1[准确率0.9531, MCC 0.9064 / Accuracy 0.9531, MCC 0.9064]
        Results --> R2[优于现有方法 / Outperforms SOTA]
        Results --> R3[实现病毒家族亚类预测 / Enables viral family subclass prediction]
    ```

- **[arXiv251229] Discovering Sparse Recovery Algorithms Using Neural Architecture Search**
  - **tags:** [ai], [sparse recovery], [neural architecture search, meta-learning, iterative shrinkage thresholding algorithm, sparse optimization, algorithm discovery]
  - **authors:** Patrick Yubeaton, Sarthak Gupta, M. Salman Asif, Chinmay Hegde
  - **institution:** New York University, University of California, Riverside
  - **link:** https://arxiv.org/pdf/2512.21563
  - **contributions:** 1. Proposes a meta-learning framework using Neural Architecture Search (NAS) for automated discovery of sparse recovery algorithms. 2. Demonstrates the framework's capability to rediscover key elements of ISTA and FISTA from a search space of over 50,000 variables. 3. Shows the framework's applicability to various data distributions and algorithms beyond ISTA/FISTA.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/49f1d5d0a89c3d52b36f1e443675494175442f0930725fc8a763e525ca05243a_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces a meta-learning framework that uses Neural Architecture Search (NAS) to automatically discover sparse recovery algorithms. It successfully rediscovers components of ISTA and FISTA from a large search space and demonstrates generalizability to other algorithms and data distributions.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Discovering Sparse Recovery Algorithms Using Neural Architecture Search] --> B[核心问题/Problem: Automated discovery of sparse optimization algorithms is difficult and heuristic-driven]
    A --> C[主要方法/Method: Meta-learning framework using Neural Architecture Search (NAS) for algorithm rediscovery]
    A --> D[关键结果/Results: Rediscovered ISTA/FISTA elements; framework applies to various data and algorithms]
    ```

- **[arXiv251229] Variance-Aware Prior-Based Tree Policies for Monte Carlo Tree Search**
  - **tags:** [ai], [reinforcement learning], [Monte Carlo Tree Search, Upper Confidence Bound, Variance-Aware, Prior-Based Tree Policy, Inverse-RPO]
  - **authors:** Maximilian Weichart
  - **institution:** University of Regensburg
  - **link:** https://arxiv.org/pdf/2512.21648
  - **code:** https://github.com/Max-We/inverse-rpo
  - **contributions:** 1. Introduces Inverse-RPO, a general methodology to systematically derive prior-based UCTs from any prior-free UCB., 2. Applies Inverse-RPO to UCB-V to create two new variance-aware prior-based tree policies., 3. Provides an extension to the mctx library for variance-aware UCTs, showing minimal code changes and improved performance over PUCT in benchmarks.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/c2c9098504a8a9013ab805fffa4a23f04af76e28f5d8b8a0353e1e7d5583f589_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of extending prior-based tree policies in Monte Carlo Tree Search beyond the empirically derived PUCT. The authors propose Inverse-RPO, a principled method to derive prior-based UCTs from any prior-free UCB, and apply it to create variance-aware policies. Their new policies outperform the standard PUCT across multiple benchmarks without added computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Variance-Aware Prior-Based Tree Policies for MCTS] --> B
        A --> C
        A --> D
        B[核心问题/Problem: Extending prior-based UCTs from other UCBs is challenging]
        C[主要方法/Method: Propose Inverse-RPO to derive prior-based UCTs; apply to UCB-V]
        D[关键结果/Results: New policies outperform PUCT without extra cost]
    ```

- **[arXiv251229] How Do Agents Perform Code Optimization? An Empirical Study**
  - **tags:** [se], [code optimization], [AI coding agents, performance optimization, empirical study, pull request analysis, AIDev dataset]
  - **authors:** Huiyun Peng, Antonio Zhong, Ricardo Andrés Calvo Méndez, Kelechi G. Kalu, James C. Davis
  - **institution:** Purdue University
  - **link:** https://arxiv.org/pdf/2512.21757
  - **contributions:** 1. Conducts the first empirical study comparing AI-agent-authored and human-authored performance optimization commits using real-world PR data. 2. Identifies a significant gap in explicit performance validation between AI-authored (45.7%) and human-authored (63.6%) PRs. 3. Finds that AI agents largely employ the same optimization patterns as humans, suggesting they learn from existing code but lack rigorous validation practices.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e44d9c47004517dbb7baa5f42b9023e94e10fbf2a09070a4a953b43ded2bf802_w640_q70.webp
  - **Simple LLM Summary:** This paper presents an empirical study comparing how AI coding agents and humans perform code optimization by analyzing performance-related pull requests from the AIDev dataset. The study finds that while AI agents use similar optimization patterns as humans, they are significantly less likely to include explicit performance validation in their commits. This highlights a key limitation in current agentic code optimization and an opportunity for improvement.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[How Do Agents Perform Code Optimization? An Empirical Study] --> B[核心问题/Problem: AI coding agents' effectiveness on real-world performance optimization tasks is unknown.]
        A --> C[主要方法/Method: Empirical comparison of 324 agent-generated and 83 human-authored performance PRs from AIDev dataset.]
        A --> D[关键结果/Results: AI-authored PRs use similar patterns but include less explicit performance validation (45.7% vs 63.6%).]
    ```

- **[arXiv251229] UniLabOS: An AI-Native Operating System for Autonomous Laboratories**
  - **tags:** [mlsys], [agent system], [autonomous laboratory, operating system, distributed edge-cloud architecture, CRUTD protocol, A/R/A&R model]
  - **authors:** Jing Gao, Junhan Chang, Haohui Que, Yanfei Xiong, Shixiang Zhang, Xianwei Qi, Zhen Liu, Jun-Jie Wang, Qianjun Ding, Xinyu Li, Ziwei Pan, Qiming Xie, Zhuang Yan, Junchi Yan, Linfeng Zhang
  - **institution:** DP Technology, Shanghai Jiao Tong University, Peking University, AI for Science Institute, Beijing
  - **link:** https://arxiv.org/pdf/2512.21766
  - **contributions:** 1. Proposes UniLabOS, an AI-native operating system that bridges high-level planning and low-level robotic execution for autonomous labs using typed, stateful abstractions and transactional safeguards. 2. Introduces a unified Action/Resource/Action&Resource (A/R/A&R) model and a dual-topology representation for lab structure, enabling protocol mobility across reconfigurable hardware. 3. Implements a transactional CRUTD protocol and a distributed edge-cloud architecture to reconcile digital state with physical motion and support robust, decentralized orchestration of heterogeneous instruments.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/94c14a317a7f4c0283c03fbbdb64bfa6d4f6990a787d704f45dddd3134c96d9a_w640_q70.webp
  - **Simple LLM Summary:** The paper presents UniLabOS, an AI-native operating system designed to unify fragmented software in autonomous laboratories. It uses a novel A/R/A&R model, dual-topology representation, and a transactional CRUTD protocol on a distributed architecture to enable robust, reproducible, and agent-ready experimentation. The system is demonstrated across four real-world settings, establishing a scalable foundation for closed-loop scientific discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[UniLabOS: An AI-Native Operating System for Autonomous Laboratories] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[软件碎片化阻碍自主实验室采用/Fragmented software hinders adoption of autonomous labs]
        C --> C1[AI原生操作系统/AI-native operating system]
        C1 --> C2[统一模型: A/R/A&R/Unified A/R/A&R model]
        C1 --> C3[双重拓扑结构/Dual-topology representation]
        C1 --> C4[事务性CRUTD协议/Transactional CRUTD protocol]
        C1 --> C5[分布式边云架构/Distributed edge-cloud architecture]
        D --> D1[四个真实场景验证/Four real-world demonstrations]
        D --> D2[异构仪器稳健编排/Robust orchestration across heterogeneous instruments]
        D --> D3[为可复现、可溯源的实验奠定基础/Foundation for reproducible, provenance-aware experimentation]
    ```

- **[arXiv251229] BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization**
  - **tags:** [cv], [3d medical image analysis], [Masked Autoencoder, Swin Transformer, Self-Supervised Learning, 3D Vision Transformer, Structural Priority Loss]
  - **authors:** Evgeny Alves Limarenko, Anastasiia Studenikina
  - **institution:** Moscow Institute of Physics and Technology
  - **link:** https://arxiv.org/pdf/2512.21769
  - **contributions:** 1. Proposed BertsWin, a hybrid architecture combining full BERT-style token masking with Swin Transformer windows to preserve 3D spatial topology during SSL pre-training. 2. Introduced a structural priority loss function to enhance learning. 3. Demonstrated significant acceleration in semantic convergence (5.8x) and a 15-fold reduction in training epochs to reach SOTA fidelity when combined with the GradientConductor optimizer, without increasing computational FLOPs.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/18d8b6d7f8a20f3bce77706daf18b554423899bdff962eb21fde56292e0c3fde_w640_q70.webp
  - **Simple LLM Summary:** The paper addresses the difficulty of applying standard Masked Autoencoders to 3D medical images, which lose spatial context. It proposes BertsWin, a hybrid architecture that maintains a full 3D token grid using Swin Transformer windows and a structural loss. The method achieves much faster convergence and state-of-the-art reconstruction fidelity for 3D CBCT scans without extra computational cost.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("BertsWin: 3D MAE优化") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("3D MAE拓扑稀疏性/Topological Sparsity in 3D MAE")
        Problem --> P2("破坏空间关系/Destroys Spatial Context")
        Method --> M1("BertsWin混合架构/BertsWin Hybrid Architecture")
        Method --> M2("完整3D令牌网格/Full 3D Token Grid")
        Method --> M3("Swin窗口 & 结构损失/Swin Windows & Structural Loss")
        Results --> R1("5.8x语义收敛加速/5.8x Faster Convergence")
        Results --> R2("15倍训练轮次减少/15x Fewer Epochs")
        Results --> R3("FLOPs持平，总资源减少/FLOP Parity, Net Resource Reduction")
    ```

- **[arXiv251229] Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees**
  - **tags:** [mlsys], [multi-modal inference], [speculative decoding, draft tree, inference acceleration, autoregressive image generation, dynamic tree structure]
  - **authors:** Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou
  - **institution:** Southeast University, Institute of Automation Chinese Academy of Sciences, Singapore Management University
  - **link:** https://arxiv.org/pdf/2512.21857
  - **code:** https://github.com/Haodong-Lei-Ray/ADT-Tree
  - **contributions:** 1. Identified the key obstacle of applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to spatially varying token prediction difficulty. 2. Proposed ADT-Tree, an adjacency-adaptive dynamic draft tree that dynamically adjusts tree depth and width based on adjacent token states and prior acceptance rates. 3. Demonstrated significant speedups (over 3x) on benchmarks and seamless integration with relaxed sampling methods for further acceleration.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/9b9ff13149fa2d6733868b2125e7af2ae06239a529152a057b80d0d6f357ccf3_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow inference of visual autoregressive models by proposing ADT-Tree, a dynamic draft tree method that adapts its structure to image region complexity. It achieves over 3x speedup on standard benchmarks and can be combined with other sampling techniques for additional gains.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Fast Inference of Visual AR Model with ADT-Tree<br>视觉自回归模型快速推理与ADT-Tree"]
        Root --> Problem["核心问题/Problem<br>Visual AR models have slow sequential inference.<br>视觉AR模型推理慢"]
        Root --> Method["主要方法/Method<br>Propose Adjacency-Adaptive Dynamical Draft Trees (ADT-Tree).<br>提出邻接自适应动态草稿树"]
        Root --> Results["关键结果/Results<br>Achieves 3.13x/3.05x speedup on benchmarks.<br>在基准测试上实现3.13x/3.05x加速"]
        Problem --> P1["Spatially varying token prediction difficulty.<br>空间变化的token预测难度"]
        Method --> M1["Dynamically adjusts tree depth & width.<br>动态调整树深度与宽度"]
        Method --> M2["Leverages adjacency & prior acceptance rates.<br>利用邻接关系和先验接受率"]
        Results --> R1["Integrates with relaxed sampling.<br>可与松弛采样方法结合"]
    ```

- **[arXiv251229] Accelerate Speculative Decoding with Sparse Computation in Verification**
  - **tags:** [mlsys], [llm inference], [speculative decoding, sparse computation, verification stage, mixture-of-experts (MoE), efficiency-accuracy trade-off]
  - **authors:** Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang
  - **institution:** Soochow University, Meituan
  - **link:** https://arxiv.org/pdf/2512.21911
  - **contributions:** 1. Systematically analyzes and identifies structured computational redundancy across attention, FFN, and MoE components during the verification stage of speculative decoding. 2. Proposes a sparse verification framework that jointly sparsifies these components to reduce the dominant computation cost. 3. Introduces an inter-draft token and inter-layer retrieval reuse strategy to further reduce redundant computation without additional training.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/0540488d64a1ff85171c147d2e74adf0477a0d2787eadf86a76357c955ab86be_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the computational bottleneck in the verification stage of speculative decoding for LLMs, especially for long-context and MoE models. It proposes a framework that applies sparse computation techniques to the verification stage and employs a retrieval reuse strategy to reduce redundant calculations. Experiments show the method achieves a favorable efficiency-accuracy trade-off while maintaining stable acceptance length.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[Accelerate Speculative Decoding with Sparse Computation in Verification] --> B[核心问题/Problem]
        A --> C[主要方法/Method]
        A --> D[关键结果/Results]
        B --> B1[验证阶段成为瓶颈/Verification stage is bottleneck]
        B1 --> B2[长上下文与MoE模型/Long-context & MoE models]
        C --> C1[稀疏验证框架/Sparse Verification Framework]
        C1 --> C2[联合稀疏化注意力、FFN、MoE/Jointly sparsifies Attention, FFN, MoE]
        C1 --> C3[检索重用策略/Retrieval Reuse Strategy]
        D --> D1[有利的效率-精度权衡/Favorable efficiency-accuracy trade-off]
        D --> D2[稳定的接受长度/Stable acceptance length]
    ```

- **[arXiv251229] Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms**
  - **tags:** [ai], [multi-armed bandits], [combinatorial multi-armed bandits, probabilistically triggered arms, hybrid learning, offline data, online interaction]
  - **authors:** Kongchang Zhou, Tingyu Zhang, Wei Chen, Fang Kong
  - **institution:** Southern University of Science and Technology, Microsoft Research
  - **link:** https://arxiv.org/pdf/2512.21925
  - **contributions:** 1. Proposes a new hybrid CMAB-T framework that integrates offline data with online interaction to address the complementary weaknesses of purely online or offline methods. 2. Introduces the hybrid CUCB algorithm, which leverages offline data to guide exploration and strategically uses online interactions to correct dataset bias. 3. Provides theoretical regret guarantees and empirical results demonstrating the algorithm's consistent advantage over purely online or offline baselines.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/e97b8cf09a0691d48238a8272fecd32791ddc20b9ba00115a757d778b1e2017f_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes a hybrid framework for combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) that combines offline data with online interaction. The core method is the hybrid CUCB algorithm, which uses offline data to accelerate learning and online interaction to correct for dataset limitations. Theoretical and empirical results show this hybrid approach outperforms purely online or offline methods.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root("Hybrid CMAB-T<br>混合组合多臂老虎机") --> Problem("核心问题/Problem")
        Root --> Method("主要方法/Method")
        Root --> Results("关键结果/Results")
        Problem --> P1("在线方法成本高、适应慢<br>Online: High Cost, Slow")
        Problem --> P2("离线方法受数据质量限制<br>Offline: Data Quality Limits")
        Method --> M1("提出混合CMAB-T框架<br>Propose Hybrid CMAB-T Framework")
        Method --> M2("设计混合CUCB算法<br>Design Hybrid CUCB Algorithm")
        M2 --> M2a("利用离线数据引导探索<br>Use Offline Data to Guide")
        M2 --> M2b("结合在线交互纠正偏差<br>Use Online to Correct Bias")
        Results --> R1("理论悔恨界保证<br>Theoretical Regret Guarantee")
        Results --> R2("实验显示一致优势<br>Empirical Consistent Advantage")
    ```

- **[arXiv251229] StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision**
  - **tags:** [cv], [robotic vision], [stereo vision, vision-language-action models, geometric-semantic fusion, depth estimation, robotic manipulation]
  - **authors:** Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang
  - **institution:** Peking University, The University of Hong Kong, Institute of Automation, Chinese Academy of Sciences, Beijing Academy of Artificial Intelligence
  - **link:** https://arxiv.org/pdf/2512.21970
  - **code:** https://shengliangd.github.io/StereoVLA-Webpage
  - **contributions:** 1. Proposed StereoVLA, a novel Vision-Language-Action model that leverages stereo vision for enhanced spatial perception. 2. Introduced a Geometric-Semantic Feature Extraction module to fuse geometric cues from stereo differences with semantic features from a monocular view. 3. Designed an auxiliary Interaction-Region Depth Estimation task to improve spatial understanding and accelerate model convergence.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/5fbd07a25a843958488215748e8162f92542370bba173316326de44d4be3c65f_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the limitation of single-view input in Vision-Language-Action (VLA) models for robotic manipulation by introducing StereoVLA, which utilizes stereo vision. The core method involves a novel module to extract and fuse geometric and semantic features, along with an auxiliary depth estimation task. Experiments show the model significantly outperforms baselines in stereo-based tasks and is robust to camera pose variations.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1(单目VLA模型缺乏精确的几何感知/Single-view VLAs lack accurate geometry perception)
        C --> C1(提出StereoVLA模型/Propose StereoVLA model)
        C1 --> C2(几何-语义特征提取模块/Geometric-Semantic Feature Extraction)
        C2 --> C3(从立体视图提取几何特征/Extract geometric features from stereo views)
        C2 --> C4(从单目视图提取语义特征/Extract semantic features from monocular view)
        C1 --> C5(辅助交互区域深度估计任务/Auxiliary Interaction-Region Depth Estimation task)
        D --> D1(在立体设置下大幅超越基线/Large margin outperforms baselines under stereo setting)
        D --> D2(对相机位姿变化具有强鲁棒性/Strong robustness to camera pose variations)
    ```

- **[arXiv251229] DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction**
  - **tags:** [ai], [computational biology], [protein language model, ESM-2, dual-stream architecture, 1D CNN, transformer encoder]
  - **authors:** Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar
  - **institution:** National School of Artificial Intelligence (ENSIA)
  - **link:** https://arxiv.org/pdf/2512.22007
  - **contributions:** 1. Proposes DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for antigen-antibody affinity prediction using a dual-stream hybrid architecture. 2. Integrates pre-trained ESM-2 embeddings with 1D CNNs for local motifs and Transformer encoders for global context, followed by a fusion module. 3. Demonstrates superior performance over single-branch models and existing SOTA methods, even surpassing some structure-sequence hybrid models, proving the efficacy of sequence-only high-fidelity embeddings.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/1985304be62407b10b5e5be53aea80fe4ff1468be03e261847b49774ddd937a8_w640_q70.webp
  - **Simple LLM Summary:** This paper introduces DuaDeep-SeqAffinity, a deep learning framework that predicts antigen-antibody binding affinity using only amino acid sequences. It combines ESM-2 embeddings with a dual-stream architecture of 1D CNNs and Transformers to capture local and global features. The model outperforms existing methods, showing that sequence-only models can effectively capture binding patterns and accelerate therapeutic discovery.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[DuaDeep-SeqAffinity: 序列抗原-抗体亲和力预测 / Sequence-Only Antigen-Antibody Affinity Prediction] --> B(核心问题/Problem)
        A --> C(主要方法/Method)
        A --> D(关键结果/Results)
        B --> B1[传统方法依赖稀缺的3D结构 / Traditional methods rely on scarce 3D structures]
        C --> C1[双流混合架构 / Dual-Stream Hybrid Architecture]
        C1 --> C2[使用ESM-2嵌入 / Uses ESM-2 Embeddings]
        C1 --> C3[1D CNN检测局部模式 / 1D CNN for Local Motifs]
        C1 --> C4[Transformer编码全局上下文 / Transformer for Global Context]
        C1 --> C5[融合模块整合特征 / Fusion Module Integrates Features]
        D --> D1[性能超越SOTA / Outperforms SOTA]
        D --> D2[皮尔逊相关: 0.688 / Pearson: 0.688]
        D --> D3[AUC: 0.890]
        D --> D4[证明序列嵌入的有效性 / Proves Efficacy of Sequence Embeddings]
    ```

- **[arXiv251229] StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars**
  - **tags:** [mlsys], [diffusion models], [autoregressive distillation, adversarial refinement, real-time streaming, reference-anchored positional re-encoding, consistency-aware discriminator]
  - **authors:** Zhiyao Sun, Ziqiao Peng, Yifeng Ma, Yi Chen, Zhengguang Zhou, Zixiang Zhou, Guozhen Zhang, Youliang Zhang, Yuan Zhou, Qinglin Lu, Yong-Jin Liu
  - **institution:** Tsinghua University, Renmin University of China, Tencent Hunyuan, Nanjing University
  - **link:** https://arxiv.org/pdf/2512.22065
  - **code:** https://streamavatar.github.io
  - **contributions:** 1. A two-stage autoregressive adaptation and acceleration framework (autoregressive distillation + adversarial refinement) to adapt a non-causal human video diffusion model for real-time, interactive streaming. 2. Three novel components to ensure long-term stability and consistency: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. 3. A one-shot, interactive human avatar model capable of generating both natural talking and listening behaviors with coherent full-body gestures, surpassing existing methods in quality, efficiency, and interaction naturalness.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/fdfab379af0573f473d87dcf0d615682a378ca15f3e5158289e25ba256124414_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the challenge of making diffusion-based human avatar generation suitable for real-time, interactive streaming. It proposes StreamAvatar, a two-stage framework that adapts a high-fidelity human video diffusion model using autoregressive distillation and adversarial refinement, incorporating novel components for long-term consistency. The method achieves state-of-the-art performance in generating high-resolution, full-body interactive avatars with natural talking/listening behaviors in real-time.
  - **Mindmap:**

    ```mermaid
    graph TB
        A[StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars] --> B
        A --> C
        A --> D
        B[核心问题/Problem<br>Non-causal, high-cost diffusion models unsuitable for real-time streaming; Limited to head-and-shoulder, lacking gestures.]
        C[主要方法/Method<br>Two-stage autoregressive adaptation (distillation + refinement) with Reference Sink, RAPR, Consistency-Aware Discriminator.]
        D[关键结果/Results<br>State-of-the-art real-time, interactive full-body avatar with natural talking/listening and gestures.]
    ```

- **[arXiv251229] Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling**
  - **tags:** [mlsys], [llm inference], [SRAM, frequency scaling, energy-delay product, systolic array, memory bandwidth]
  - **authors:** Hannah Atmer, Yuan Yao, Thiemo Voigt, Stefanos Kaxiras
  - **institution:** Uppsala University
  - **link:** https://arxiv.org/pdf/2512.22066
  - **contributions:** 1. Quantified the distinct energy and performance impacts of SRAM size and operating frequency on the compute-bound prefill and memory-bound decode phases of LLM inference. 2. Demonstrated a counter-intuitive result: high compute frequency can reduce total energy by shortening execution time and reducing static energy more than the dynamic power increase. 3. Identified an optimal hardware configuration (high frequency, small SRAM buffer) that minimizes the energy-delay product, providing concrete design insights for energy-efficient accelerators.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/52c2db009cb44a92a388e1684ea0d1bdb9ae27c0c4a4e683651eb7bd091bbe93_w640_q70.webp
  - **Simple LLM Summary:** This paper investigates how on-chip SRAM size and operating frequency affect the energy efficiency of LLM inference. Using a simulation methodology combining OpenRAM, LLMCompass, and ScaleSIM, it finds that a high-frequency, small-SRAM configuration optimizes the energy-delay product, as memory bandwidth caps decode phase improvements. The analysis provides architectural guidance for designing efficient LLM accelerators.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root["Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling"] --> Problem
        Root --> Method
        Root --> Results
        Problem["核心问题/Problem<br>LLM推理能耗高，Prefill与Decode阶段瓶颈不同"] --> Problem_Sub1["SRAM大小与频率如何影响能效？"]
        Problem --> Problem_Sub2["内存带宽如何限制性能？"]
        Method["主要方法/Method<br>结合OpenRAM, LLMCompass, ScaleSIM的模拟方法"] --> Method_Sub1["能耗建模/Energy Modeling"]
        Method --> Method_Sub2["延迟模拟/Latency Simulation"]
        Method --> Method_Sub3["操作强度分析/Operational Intensity"]
        Results["关键结果/Results"] --> Results_Sub1["总能耗主要由SRAM大小决定<br>大缓存增加静态能耗"]
        Results --> Results_Sub2["高频可降低总能耗<br>（减少静态能耗）"]
        Results --> Results_Sub3["最优配置：高频(1200-1400MHz) + 小缓存(32-64KB)"]
    ```

- **[arXiv251229] Yume-1.5: A Text-Controlled Interactive World Generation Model**
  - **tags:** [mlsys], [diffusion models], [interactive world generation, long-video generation, attention distillation, context compression, text-controlled generation]
  - **authors:** Xiaofeng Mao, Zhen Li, Chuanhao Li, Xiaojie Xu, Kaining Ying, Tong He, Jiangmiao Pang, Yu Qiao, Kaipeng Zhang
  - **institution:** Shanghai AI Laboratory, Fudan University, Shanghai Innovation Institute
  - **link:** https://arxiv.org/pdf/2512.22096
  - **code:** https://github.com/stdstu12/YUME
  - **contributions:** 1. A long-video generation framework integrating unified context compression with linear attention. 2. A real-time streaming acceleration strategy using bidirectional attention distillation and an enhanced text embedding scheme. 3. A text-controlled method for generating world events.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/8f7ffd3f0a90ba67551ade4e28abf8e27d5d08c106e463f85f9447011008416b_w640_q70.webp
  - **Simple LLM Summary:** This paper proposes Yume-1.5, a framework to address challenges in generating interactive, explorable worlds using diffusion models, such as large model size and slow inference. The method introduces a novel architecture combining context compression, attention distillation, and text-based event control to enable real-time, keyboard-controlled world generation from text or images. The work concludes with a public codebase demonstrating the feasibility of text-controlled interactive world creation.
  - **Mindmap:**

    ```mermaid
    graph TB
        Root[Yume-1.5: A Text-Controlled Interactive World Generation Model] --> Problem(核心问题/Problem)
        Root --> Method(主要方法/Method)
        Root --> Results(关键结果/Results)
        Problem --> P1[大模型参数与慢推理/Large Model & Slow Inference]
        Problem --> P2[缺乏文本控制/Lack of Text Control]
        Method --> M1[长视频生成框架/Long-Video Gen Framework]
        Method --> M2[实时流加速策略/Real-time Streaming]
        Method --> M3[文本控制事件生成/Text-Controlled Events]
        M1 --> M1_Sub[统一上下文压缩与线性注意力/Unified Context Compression & Linear Attention]
        M2 --> M2_Sub[双向注意力蒸馏与文本嵌入/Bidirectional Attention Distillation & Text Embedding]
        Results --> R1[生成交互式世界/Generates Interactive Worlds]
        Results --> R2[支持键盘探索/Supports Keyboard Exploration]
        Results --> R3[公开代码库/Public Codebase]
    ```

- **[arXiv251229] Enabling Ultra-Fast Cardiovascular Imaging Across Heterogeneous Clinical Environments with a Generalist Foundation Model and Multimodal Database**
  - **tags:** [cv], [medical image reconstruction], [foundation model, k-space, multimodal database, zero-shot generalization, accelerated imaging]
  - **authors:** Zi Wang, Mingkai Huang, Zhang Shi, Hongjie Hu, Lan Lan, Hui Zhang, Yan Li, Xi Hu, Qing Lu, Zongming Zhu, Qiong Yao, Yuxiang Dai, Fanwen Wang, Yinzhe Wu, Jun Lyu, Qianqian Gao, Guangming Xu, Zhenxuan Zhang, Haosen Zhang, Qing Li, Guangming Wang, Tianxing He, Lizhen Lan, Siyue Li, Le Xue, Mengting Sun, Yuntong Lyu, Junpu Hu, Jiayu Zhu, Rizwan Ahmad, Zhengyu Bu, Xianling Qian, Guanke Cai, Ruiyu Cao, Weirui Cai, Chang Xu, Yuyang Ren, Feidan Yu, Siying Ma, Ziqiang Xu, Xinran Chen, Sha Hua, Daniel Kim, Yajing Zhang, Chen Ouyang, Wenjia Bai, Jing Qin, Yucheng Yang, Daniel Rueckert, He Wang, Qian Tao, Claudia Prieto, Michael Markl, Alistair Young, Lianming Wu, Shuo Wang, Chen Qin, Mengsu Zeng, Xihong Hu, Haibo Xu, Xiaobo Qu, Hao Li, Guang Yang, Chengyan Wang
  - **institution:** Imperial College London, Fudan University, Xiamen University
  - **link:** https://arxiv.org/pdf/2512.21652
  - **contributions:** 1. The curation of MMCMR-427K, the largest and most comprehensive multimodal cardiovascular magnetic resonance (CMR) k-space database. 2. The introduction of CardioMM, a generalist reconstruction foundation model that unifies semantic understanding with physics-informed data consistency for robust, accelerated imaging. 3. Demonstrating state-of-the-art performance and strong zero-shot generalization across heterogeneous clinical settings, enabling up to 24x acceleration without compromising clinical integrity.
  - **thumbnail:** https://pub-9ba4a5dae3bf4fc7b7d26411a74e92db.r2.dev/thumbnails/6001c34604e8bff7b6e1efa31a4faa67e7e43e6efb18e01ea880e43095344349_w640_q70.webp
  - **Simple LLM Summary:** This paper addresses the slow scan times and environmental heterogeneity limiting clinical cardiovascular MRI. It proposes CardioMM, a generalist foundation model trained on a large multimodal k-space database (MMCMR-427K), which achieves robust, ultra-fast reconstructions across diverse scanners and protocols. The results show that CardioMM enables high acceleration (up to 24x) while preserving diagnostic quality and generalizing to unseen clinical environments.
  - **Mindmap:**

    ```mermaid
    graph TB
    A[Enabling Ultra-Fast Cardiovascular Imaging...] --> B[核心问题/Problem]
    A --> C[主要方法/Method]
    A --> D[关键结果/Results]
    B --> B1[CMR扫描时间长/CMR Scan Time Long]
    B --> B2[临床环境异质性高/High Clinical Heterogeneity]
    C --> C1[构建多模态数据库MMCMR-427K/Build Multimodal DB MMCMR-427K]
    C --> C2[提出通用基础模型CardioMM/Propose Generalist Foundation Model CardioMM]
    D --> D1[实现24倍加速成像/Achieve 24x Accelerated Imaging]
    D --> D2[零样本泛化至新环境/Zero-shot Generalization to New Settings]
    D --> D3[保持诊断质量/Preserve Diagnostic Quality]
    ```
